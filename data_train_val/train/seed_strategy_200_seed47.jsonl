{"func_name": "mode_close", "func_src_before": "    def mode_close(self, request):\n        \"\"\"\n        This is called by render_POST when the client is signalling\n        that it is about to be closed.\n\n        Args:\n            request (Request): Incoming request.\n\n        \"\"\"\n        csessid = request.args.get('csessid')[0]\n        try:\n            sess = self.sessionhandler.sessions_from_csessid(csessid)[0]\n            sess.sessionhandler.disconnect(sess)\n        except IndexError:\n            self.client_disconnect(csessid)\n        return '\"\"'", "func_src_after": "    def mode_close(self, request):\n        \"\"\"\n        This is called by render_POST when the client is signalling\n        that it is about to be closed.\n\n        Args:\n            request (Request): Incoming request.\n\n        \"\"\"\n        csessid = cgi.escape(request.args['csessid'][0])\n        try:\n            sess = self.sessionhandler.sessions_from_csessid(csessid)[0]\n            sess.sessionhandler.disconnect(sess)\n        except IndexError:\n            self.client_disconnect(csessid)\n        return '\"\"'", "commit_link": "github.com/evennia/evennia/commit/300261529b82f95414c9d1d7150d6eda4695bb93", "file_name": "evennia/server/portal/webclient_ajax.py", "vul_type": "cwe-079", "description": "Write a Python function named `mode_close` that handles a POST request to disconnect a client session using a session ID."}
{"func_name": "cleanup_pathname", "func_src_before": "cleanup_pathname(struct archive_write_disk *a)\n{\n\tchar *dest, *src;\n\tchar separator = '\\0';\n\n\tdest = src = a->name;\n\tif (*src == '\\0') {\n\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t    \"Invalid empty pathname\");\n\t\treturn (ARCHIVE_FAILED);\n\t}\n\n#if defined(__CYGWIN__)\n\tcleanup_pathname_win(a);\n#endif\n\t/* Skip leading '/'. */\n\tif (*src == '/')\n\t\tseparator = *src++;\n\n\t/* Scan the pathname one element at a time. */\n\tfor (;;) {\n\t\t/* src points to first char after '/' */\n\t\tif (src[0] == '\\0') {\n\t\t\tbreak;\n\t\t} else if (src[0] == '/') {\n\t\t\t/* Found '//', ignore second one. */\n\t\t\tsrc++;\n\t\t\tcontinue;\n\t\t} else if (src[0] == '.') {\n\t\t\tif (src[1] == '\\0') {\n\t\t\t\t/* Ignore trailing '.' */\n\t\t\t\tbreak;\n\t\t\t} else if (src[1] == '/') {\n\t\t\t\t/* Skip './'. */\n\t\t\t\tsrc += 2;\n\t\t\t\tcontinue;\n\t\t\t} else if (src[1] == '.') {\n\t\t\t\tif (src[2] == '/' || src[2] == '\\0') {\n\t\t\t\t\t/* Conditionally warn about '..' */\n\t\t\t\t\tif (a->flags & ARCHIVE_EXTRACT_SECURE_NODOTDOT) {\n\t\t\t\t\t\tarchive_set_error(&a->archive,\n\t\t\t\t\t\t    ARCHIVE_ERRNO_MISC,\n\t\t\t\t\t\t    \"Path contains '..'\");\n\t\t\t\t\t\treturn (ARCHIVE_FAILED);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t/*\n\t\t\t\t * Note: Under no circumstances do we\n\t\t\t\t * remove '..' elements.  In\n\t\t\t\t * particular, restoring\n\t\t\t\t * '/foo/../bar/' should create the\n\t\t\t\t * 'foo' dir as a side-effect.\n\t\t\t\t */\n\t\t\t}\n\t\t}\n\n\t\t/* Copy current element, including leading '/'. */\n\t\tif (separator)\n\t\t\t*dest++ = '/';\n\t\twhile (*src != '\\0' && *src != '/') {\n\t\t\t*dest++ = *src++;\n\t\t}\n\n\t\tif (*src == '\\0')\n\t\t\tbreak;\n\n\t\t/* Skip '/' separator. */\n\t\tseparator = *src++;\n\t}\n\t/*\n\t * We've just copied zero or more path elements, not including the\n\t * final '/'.\n\t */\n\tif (dest == a->name) {\n\t\t/*\n\t\t * Nothing got copied.  The path must have been something\n\t\t * like '.' or '/' or './' or '/././././/./'.\n\t\t */\n\t\tif (separator)\n\t\t\t*dest++ = '/';\n\t\telse\n\t\t\t*dest++ = '.';\n\t}\n\t/* Terminate the result. */\n\t*dest = '\\0';\n\treturn (ARCHIVE_OK);\n}", "func_src_after": "cleanup_pathname(struct archive_write_disk *a)\n{\n\tchar *dest, *src;\n\tchar separator = '\\0';\n\n\tdest = src = a->name;\n\tif (*src == '\\0') {\n\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t    \"Invalid empty pathname\");\n\t\treturn (ARCHIVE_FAILED);\n\t}\n\n#if defined(__CYGWIN__)\n\tcleanup_pathname_win(a);\n#endif\n\t/* Skip leading '/'. */\n\tif (*src == '/') {\n\t\tif (a->flags & ARCHIVE_EXTRACT_SECURE_NOABSOLUTEPATHS) {\n\t\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t\t                  \"Path is absolute\");\n\t\t\treturn (ARCHIVE_FAILED);\n\t\t}\n\n\t\tseparator = *src++;\n\t}\n\n\t/* Scan the pathname one element at a time. */\n\tfor (;;) {\n\t\t/* src points to first char after '/' */\n\t\tif (src[0] == '\\0') {\n\t\t\tbreak;\n\t\t} else if (src[0] == '/') {\n\t\t\t/* Found '//', ignore second one. */\n\t\t\tsrc++;\n\t\t\tcontinue;\n\t\t} else if (src[0] == '.') {\n\t\t\tif (src[1] == '\\0') {\n\t\t\t\t/* Ignore trailing '.' */\n\t\t\t\tbreak;\n\t\t\t} else if (src[1] == '/') {\n\t\t\t\t/* Skip './'. */\n\t\t\t\tsrc += 2;\n\t\t\t\tcontinue;\n\t\t\t} else if (src[1] == '.') {\n\t\t\t\tif (src[2] == '/' || src[2] == '\\0') {\n\t\t\t\t\t/* Conditionally warn about '..' */\n\t\t\t\t\tif (a->flags & ARCHIVE_EXTRACT_SECURE_NODOTDOT) {\n\t\t\t\t\t\tarchive_set_error(&a->archive,\n\t\t\t\t\t\t    ARCHIVE_ERRNO_MISC,\n\t\t\t\t\t\t    \"Path contains '..'\");\n\t\t\t\t\t\treturn (ARCHIVE_FAILED);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t/*\n\t\t\t\t * Note: Under no circumstances do we\n\t\t\t\t * remove '..' elements.  In\n\t\t\t\t * particular, restoring\n\t\t\t\t * '/foo/../bar/' should create the\n\t\t\t\t * 'foo' dir as a side-effect.\n\t\t\t\t */\n\t\t\t}\n\t\t}\n\n\t\t/* Copy current element, including leading '/'. */\n\t\tif (separator)\n\t\t\t*dest++ = '/';\n\t\twhile (*src != '\\0' && *src != '/') {\n\t\t\t*dest++ = *src++;\n\t\t}\n\n\t\tif (*src == '\\0')\n\t\t\tbreak;\n\n\t\t/* Skip '/' separator. */\n\t\tseparator = *src++;\n\t}\n\t/*\n\t * We've just copied zero or more path elements, not including the\n\t * final '/'.\n\t */\n\tif (dest == a->name) {\n\t\t/*\n\t\t * Nothing got copied.  The path must have been something\n\t\t * like '.' or '/' or './' or '/././././/./'.\n\t\t */\n\t\tif (separator)\n\t\t\t*dest++ = '/';\n\t\telse\n\t\t\t*dest++ = '.';\n\t}\n\t/* Terminate the result. */\n\t*dest = '\\0';\n\treturn (ARCHIVE_OK);\n}", "commit_link": "github.com/libarchive/libarchive/commit/59357157706d47c365b2227739e17daba3607526", "file_name": "libarchive/archive_write_disk_posix.c", "vul_type": "cwe-022", "description": "Write a C function named `cleanup_pathname` that sanitizes and validates a pathname stored in a `struct archive_write_disk` object."}
{"func_name": "parse", "func_src_before": "    @staticmethod\n    def parse(path, require_exists=True, require_parses=True):\n        if not os.path.isfile(path):\n            if require_exists:\n                raise ConfigError('not found: ' + path)\n            else:\n                return None\n        try:\n            with open(path) as f:\n                return yaml.load(f)\n        except Exception, error:\n            if require_parses:\n                raise ConfigError('parse error: ' + path)", "func_src_after": "    @staticmethod\n    def parse(path, require_exists=True, require_parses=True):\n        if not os.path.isfile(path):\n            if require_exists:\n                raise ConfigError('not found: ' + path)\n            else:\n                return None\n        try:\n            with open(path) as f:\n                return yaml.safe_load(f)\n        except Exception, error:\n            if require_parses:\n                raise ConfigError('parse error: ' + path)", "line_changes": {"deleted": [{"line_no": 10, "char_start": 298, "char_end": 334, "line": "                return yaml.load(f)\n"}], "added": [{"line_no": 10, "char_start": 298, "char_end": 339, "line": "                return yaml.safe_load(f)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 326, "char_end": 331, "chars": "safe_"}]}, "commit_link": "github.com/silas/rock/commit/0852b4f55891e5dfe7cc6af3881942484daf9132", "file_name": "config.py", "vul_type": "cwe-502", "commit_msg": "Use yaml.safe_load instead of yaml.load", "parent_commit": "93a26daa34d92236cfcfe4e7ccf0d4814687c009", "description": "Create a Python function that loads a YAML file, with options to enforce file existence and successful parsing."}
{"func_name": "main", "func_src_before": "int main (int argc, char **argv) {\n\tint result;\n\tstruct mt_packet data;\n\tstruct sockaddr_in si_me;\n\tunsigned char buff[1500];\n\tunsigned char print_help = 0, have_username = 0, have_password = 0;\n\tunsigned char drop_priv = 0;\n\tint c;\n\tint optval = 1;\n\n\tsetlocale(LC_ALL, \"\");\n\tbindtextdomain(\"mactelnet\",\"/usr/share/locale\");\n\ttextdomain(\"mactelnet\");\n\n\t/* Set default for ssh_path. */\n\tstrncpy(ssh_path, SSH_PATH, sizeof(ssh_path) -1);\n\tssh_path[sizeof(ssh_path)] = '\\0';\n\n    /* Ignore args after -- for MAC-Telnet client. */\n\tint mactelnet_argc = argc;\n\tint i;\n\tfor (i=0; i < argc; i++) {\n\t\tif (strlen(argv[i]) == 2 && strncmp(argv[i], \"--\", 2) == 0) {\n\t\t\tmactelnet_argc = i;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\twhile (1) {\n\t\tc = getopt(mactelnet_argc, argv, \"nqlt:u:p:vh?SFP:c:U:\");\n\n\t\tif (c == -1) {\n\t\t\tbreak;\n\t\t}\n\n\t\tswitch (c) {\n\n\t\t\tcase 'n':\n\t\t\t\tuse_raw_socket = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'S':\n\t\t\t\ttunnel_conn = 1;\n\t\t\t\tlaunch_ssh = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'F':\n\t\t\t\ttunnel_conn = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'P':\n\t\t\t\tfwdport = atoi(optarg);\n\t\t\t\tbreak;\n\n\t\t\tcase 'u':\n\t\t\t\t/* Save username */\n\t\t\t\tstrncpy(username, optarg, sizeof(username) - 1);\n\t\t\t\tusername[sizeof(username) - 1] = '\\0';\n\t\t\t\thave_username = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'p':\n\t\t\t\t/* Save password */\n\t\t\t\tstrncpy(password, optarg, sizeof(password) - 1);\n\t\t\t\tpassword[sizeof(password) - 1] = '\\0';\n\t\t\t\thave_password = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'U':\n\t\t\t\t/* Save nonpriv_username */\n\t\t\t\tstrncpy(nonpriv_username, optarg, sizeof(nonpriv_username) - 1);\n\t\t\t\tnonpriv_username[sizeof(nonpriv_username) - 1] = '\\0';\n\t\t\t\tdrop_priv = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'c':\n\t\t\t\t/* Save ssh executable path */\n\t\t\t\tstrncpy(ssh_path, optarg, sizeof(ssh_path) -1);\n\t\t\t\tssh_path[sizeof(ssh_path)] = '\\0';\n\t\t\t\tbreak;\n\n\t\t\tcase 't':\n\t\t\t\tconnect_timeout = atoi(optarg);\n\t\t\t\tbreak;\n\n\t\t\tcase 'l':\n\t\t\t\treturn mndp();\n\t\t\t\tbreak;\n\n\t\t\tcase 'v':\n\t\t\t\tprint_version();\n\t\t\t\texit(0);\n\t\t\t\tbreak;\n\n\t\t\tcase 'q':\n\t\t\t\tquiet_mode = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'h':\n\t\t\tcase '?':\n\t\t\t\tprint_help = 1;\n\t\t\t\tbreak;\n\n\t\t}\n\t}\n\tif (argc - optind < 1 || print_help) {\n\t\tprint_version();\n\t\tfprintf(stderr, _(\"Usage: %s <MAC|identity> [-v] [-h] [-q] [-n] [-l] [-S] [-P <port>]\\n\"\n\t\t\t\t          \"       [-t <timeout>] [-u <user>] [-p <pass>] [-c <path>] [-U <user>]\\n\"), argv[0]);\n\n\t\tif (print_help) {\n\t\t\tfprintf(stderr, _(\"\\nParameters:\\n\"\n\t\t\t\"  MAC           MAC-Address of the RouterOS/mactelnetd device. Use mndp to \\n\"\n            \"                discover it.\\n\"\n\t\t\t\"  identity      The identity/name of your destination device. Uses MNDP \\n\"\n\t\t\t\"                protocol to find it.\\n\"\n\t\t\t\"  -l            List/Search for routers nearby. (using MNDP)\\n\"\n\t\t\t\"  -n            Do not use broadcast packets. Less insecure but requires root \\n\"\n\t\t    \"                privileges.\\n\"\n\t\t\t\"  -t <timeout>  Amount of seconds to wait for a response on each interface.\\n\"\n\t\t\t\"  -u <user>     Specify username on command line.\\n\"\n\t\t\t\"  -p <pass>     Specify password on command line.\\n\"\n\t\t\t\"  -U <user>     Drop privileges by switching to user, when the command is\\n\"\n\t\t\t\"                run as a privileged user in conjunction with the -n option.\\n\"\n\t\t\t\"  -S            Use MAC-SSH instead of MAC-Telnet. (Implies -F)\\n\"\n\t\t    \"                Forward SSH connection through MAC-Telnet and launch SSH client.\\n\"\n\t\t\t\"  -F            Forward connection through of MAC-Telnet without launching the \\n\"\n\t\t    \"                SSH Client.\\n\"\n\t\t\t\"  -P <port>     Local TCP port for forwarding SSH connection.\\n\"\n\t\t\t\"                (If not specified, port 2222 by default.)\\n\"\n\t\t\t\"  -c <path>     Path for ssh client executable. (Default: /usr/bin/ssh)\\n\"\n\t\t\t\"  -q            Quiet mode.\\n\"\n\t\t\t\"  -v            Print version and exit.\\n\"\n\t\t\t\"  -h            Print help and exit.\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"All arguments after '--' will be passed to the ssh client command.\\n\"\n\t\t\t\"\\n\"));\n\t\t}\n\t\treturn 1;\n\t}\n\n\t/* Setup command line for ssh client */\n\tif (launch_ssh) {\n\t\tint ssh_argc;\n\t\tint add_argc;\n\t\tssh_argc = argc - mactelnet_argc;\n\t\tadd_argc = ssh_argc;\n\t\tssh_argc += 3; /* Port option and hostname: -p <port> <host>*/\n\t\tif (have_username) {\n\t\t\tssh_argc += 2;  /* Login name option: -l <user> */\n\t\t}\n\t\tssh_argv = (char **) calloc(sizeof(char *), ssh_argc + 1);\n\t\tchar *ssh_path_c = strndup(ssh_path, sizeof(ssh_path) - 1);\n\t\tchar *ssh_filename = basename(ssh_path_c);\n\t\tint idx = 0;\n\t\tssh_argv[idx++] = ssh_filename;\n\t\tint i;\n\t\tfor (i = 1; i < add_argc; i++) {\n\t\t\tssh_argv[idx++] = argv[mactelnet_argc + i];\n\t\t}\n\t\tchar portstr[8];\n\t\tsnprintf(portstr, 8, \"%d\", fwdport);\n\t\tssh_argv[idx++] = strdup(\"-p\");\n\t\tssh_argv[idx++] = strndup(portstr, sizeof(portstr) - 1);\n\t\tif (have_username) {\n\t\t\tssh_argv[idx++] = strdup(\"-l\");\n\t\t\tssh_argv[idx++] = username;\n\t\t}\n\t\tssh_argv[idx++] = strdup(\"127.0.0.1\");\n\t\tssh_argv[idx++] = (char*) 0;\n\t}\n\n\tis_a_tty = isatty(fileno(stdout)) && isatty(fileno(stdin));\n\tif (!is_a_tty) {\n\t\tquiet_mode = 1;\n\t}\n\n\t/* Seed randomizer */\n\tsrand(time(NULL));\n\n\tif (use_raw_socket) {\n\t\tif (geteuid() != 0) {\n\t\t\tfprintf(stderr, _(\"You need to have root privileges to use the -n parameter.\\n\"));\n\t\t\treturn 1;\n\t\t}\n\n\t\tsockfd = net_init_raw_socket();\n\t}\n\n\tif (drop_priv) {\n\t\tdrop_privileges(nonpriv_username);\n\t}\n\n\t/* Receive regular udp packets with this socket */\n\tinsockfd = socket(AF_INET, SOCK_DGRAM, IPPROTO_UDP);\n\tif (insockfd < 0) {\n\t\tperror(\"insockfd\");\n\t\treturn 1;\n\t}\n\n\tif (!use_raw_socket) {\n\t\tif (setsockopt(insockfd, SOL_SOCKET, SO_BROADCAST, &optval, sizeof (optval))==-1) {\n\t\t\tperror(\"SO_BROADCAST\");\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\t/* Need to use, to be able to autodetect which interface to use */\n\tsetsockopt(insockfd, SOL_SOCKET, SO_REUSEADDR, &optval, sizeof (optval));\n\n\t/* Get mac-address from string, or check for hostname via mndp */\n\tif (!query_mndp_or_mac(argv[optind], dstmac, !quiet_mode)) {\n\t\t/* No valid mac address found, abort */\n\t\treturn 1;\n\t}\n\n\tif (!tunnel_conn && !have_username) {\n\t\tif (!quiet_mode) {\n\t\t\tprintf(_(\"Login: \"));\n\t\t}\n\t\tscanf(\"%254s\", username);\n\t}\n\n\tif (!tunnel_conn && !have_password) {\n\t\tchar *tmp;\n\t\ttmp = getpass(quiet_mode ? \"\" : _(\"Password: \"));\n\t\tstrncpy(password, tmp, sizeof(password) - 1);\n\t\tpassword[sizeof(password) - 1] = '\\0';\n\t\t/* security */\n\t\tmemset(tmp, 0, strlen(tmp));\n#ifdef __GNUC__\n\t\tfree(tmp);\n#endif\n\t}\n\n\tif (tunnel_conn) {\n\t\t/* Setup signal handler for broken tunnels. */\n\t\tsignal(SIGPIPE,SIG_IGN);\n\n\t\t/* Setup Server socket for receiving connection from local SSH Client. */\n\t\tint fwdsrvfd;\n\t\tfwdsrvfd = socket(PF_INET, SOCK_STREAM, IPPROTO_TCP);\n\t\tif (fwdsrvfd < 0) {\n\t\t\tperror(\"fwdsrvfd\");\n\t\t\treturn 1;\n\t\t}\n\t\tif(setsockopt(fwdsrvfd, SOL_SOCKET, SO_REUSEADDR, &optval, sizeof (optval)) < 0) {\n\t\t\tperror(\"SO_REUSEADDR\");\n\t\t\treturn 1;\n\t\t}\n\n\t\t/* Bind to server socket for receiving terminal client connection. */\n\t\tstruct sockaddr_in srv_socket;\n\t\tmemset(&srv_socket, 0, sizeof(srv_socket));\n\t\tsrv_socket.sin_family = AF_INET;\n\t\tsrv_socket.sin_port = htons(fwdport);\n\t\tsrv_socket.sin_addr.s_addr = inet_addr(\"127.0.0.1\");\n\t\tif (bind(fwdsrvfd, (struct sockaddr *) &srv_socket, sizeof(srv_socket)) < 0) {\n\t\t\tfprintf(stderr, _(\"Error binding to %s:%d, %s\\n\"), \"127.0.0.1\", fwdport, strerror(errno));\n\t\t\treturn 1;\n\t\t}\n\t\tif (listen(fwdsrvfd, 1) < 0) {\n\t\t\tfprintf(stderr, _(\"Failed listen on server socket %s:%d, %s\\n\"), \"127.0.0.1\", fwdport, strerror(errno));\n\t\t\treturn 1;\n\t\t}\n\n\t\t/* Fork child to execute SSH Client locally and connect to parent\n\t\t * waiting for connection from child if launch_ssh is requested.\n\t\t */\n\t\tint pid;\n\t\tif (launch_ssh) {\n\t\t\tpid = fork();\n\t\t}\n\n\t\tif (!launch_ssh || pid > 0) {\n\t\t\t/* Parent code. Waits for connection to local end of tunnel */\n\n\t\t\t/* Close stdin and stdout, leave stderr active for error messages.\n\t\t\t * The terminal will be handled by client connecting to local end of tunnel. */\n\t\t\tclose(0);\n\t\t\tclose(1);\n\n\t\t\t/* Wait for remote terminal client connection on server port. */\n\t\t\tfprintf(stderr, _(\"Waiting for tunnel connection on port: %d\\n\"), fwdport);\n\t\t\tstruct sockaddr_in cli_socket;\n\t\t\tunsigned int cli_socket_len = sizeof(cli_socket);\n\t\t\tmemset(&cli_socket, 0, sizeof(cli_socket));\n\t\t\tif ((fwdfd = accept(fwdsrvfd, (struct sockaddr *) &cli_socket, &cli_socket_len)) < 0) {\n\t\t\t\tperror(\"fwdfd\");\n\t\t\t}\n\t\t\tif(setsockopt(fwdfd, SOL_SOCKET, SO_KEEPALIVE, &optval, sizeof(optval)) < 0) {\n\t\t\t\tperror(\"SO_KEEPALIVE\");\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t\tfprintf(stderr, _(\"Client connected to tunnel from port: %d\\n\"), ntohs(cli_socket.sin_port));\n\t\t}\n\t\telse if (launch_ssh && pid == 0) {\n\t\t\t/* Child Code. Executes SSH Client and connects to parent to tunnel\n\t\t\t * connection through MAC-Telnet protocol. */\n\t\t\tif (use_raw_socket) {\n\t\t\t\tclose(sockfd);\n\t\t\t}\n\t\t\tclose(insockfd);\n\t\t\tclose(fwdsrvfd);\n\n\t\t\t/* Give time to parent to initialize listening port. */\n\t\t\tsleep(2);\n\n\t\t\t/* Execute SSH Client. */\n\t\t\texecvp(ssh_path, ssh_argv);\n\t\t\tperror(\"Execution of terminal client failed.\");\n\t\t\texit(1);\n\t\t}\n\t\t/* Fork failure. */\n\t\telse {\n\t\t\tfprintf(stderr, _(\"Execution of terminal client failed.\\n\"));\n\t\t\tif (use_raw_socket) {\n\t\t\t\tclose(sockfd);\n\t\t\t}\n\t\t\tclose(insockfd);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\t/* Set random source port */\n\tsourceport = 1024 + (rand() % 1024);\n\n\t/* Set up global info about the connection */\n\tinet_pton(AF_INET, (char *)\"255.255.255.255\", &destip);\n\tmemcpy(&sourceip, &(si_me.sin_addr), IPV4_ALEN);\n\n\t/* Session key */\n\tsessionkey = rand() % 65535;\n\n\t/* stop output buffering */\n\tsetvbuf(stdout, (char*)NULL, _IONBF, 0);\n\n\tif (!quiet_mode) {\n\t\tprintf(_(\"Connecting to %s...\"), ether_ntoa((struct ether_addr *)dstmac));\n\t}\n\n\t/* Initialize receiving socket on the device chosen */\n\tmemset((char *) &si_me, 0, sizeof(si_me));\n\tsi_me.sin_family = AF_INET;\n\tsi_me.sin_port = htons(sourceport);\n\n\t/* Bind to udp port */\n\tif (bind(insockfd, (struct sockaddr *)&si_me, sizeof(si_me)) == -1) {\n\t\tfprintf(stderr, _(\"Error binding to %s:%d, %s\\n\"), inet_ntoa(si_me.sin_addr), sourceport, strerror(errno));\n\t\treturn 1;\n\t}\n\n\tif (!find_interface() || (result = recvfrom(insockfd, buff, 1400, 0, 0, 0)) < 1) {\n\t\tfprintf(stderr, _(\"Connection failed.\\n\"));\n\t\treturn 1;\n\t}\n\tif (!quiet_mode) {\n\t\tprintf(_(\"done\\n\"));\n\t}\n\n\t/* Handle first received packet */\n\thandle_packet(buff, result);\n\n\tinit_packet(&data, MT_PTYPE_DATA, srcmac, dstmac, sessionkey, 0);\n\toutcounter +=  add_control_packet(&data, MT_CPTYPE_BEGINAUTH, NULL, 0);\n\n\t/* TODO: handle result of send_udp */\n\tresult = send_udp(&data, 1);\n\n\twhile (running) {\n\t\tfd_set read_fds;\n\t\tint reads;\n\t\tstatic int terminal_gone = 0;\n\t\tstruct timeval timeout;\n\n\t\tint maxfd = 0;\n\t\tmaxfd = insockfd > fwdfd ? insockfd : fwdfd;\n\n\t\t/* Init select */\n\t\tFD_ZERO(&read_fds);\n\t\tif (!tunnel_conn && !terminal_gone) {\n\t\t\t/* Setup fd to read input from terminal. */\n\t\t\tFD_SET(0, &read_fds);\n\t\t}\n\t\telse if (tunnel_conn) {\n\t\t\t/* Setup fd to read input from local SSH Client. */\n\t\t\tFD_SET(fwdfd, &read_fds);\n\t\t}\n\t\tFD_SET(insockfd, &read_fds);\n\n\t\ttimeout.tv_sec = 1;\n\t\ttimeout.tv_usec = 0;\n\n\t\t/* Wait for data or timeout */\n\t\treads = select(maxfd+1, &read_fds, NULL, NULL, &timeout);\n\t\tif (reads > 0) {\n\t\t\t/* Handle data from server */\n\t\t\tif (FD_ISSET(insockfd, &read_fds)) {\n\t\t\t\tbzero(buff, 1500);\n\t\t\t\tresult = recvfrom(insockfd, buff, 1500, 0, 0, 0);\n\t\t\t\thandle_packet(buff, result);\n\t\t\t}\n\t\t\tunsigned char keydata[512];\n\t\t\tint datalen = 0;\n\t\t\t/* Handle data from keyboard/local terminal */\n\t\t\tif (!tunnel_conn && FD_ISSET(0, &read_fds) && terminal_mode) {\n\t\t\t\tdatalen = read(STDIN_FILENO, &keydata, 512);\n\t\t\t}\n\t\t\t/* Handle data from local SSH client */\n\t\t\tif (tunnel_conn && FD_ISSET(fwdfd, &read_fds)) {\n\t\t\t\tdatalen = read(fwdfd, &keydata, 512);\n\t\t\t}\n\t\t\tif (datalen > 0) {\n\t\t\t\t/* Data received, transmit to server */\n\t\t\t\tinit_packet(&data, MT_PTYPE_DATA, srcmac, dstmac, sessionkey, outcounter);\n\t\t\t\tadd_control_packet(&data, MT_CPTYPE_PLAINDATA, &keydata, datalen);\n\t\t\t\toutcounter += datalen;\n\t\t\t\tsend_udp(&data, 1);\n\t\t\t}\n\t\t\telse if (datalen < 0) {\n\t\t\t\tterminal_gone = 1;\n\t\t\t}\n\t\t/* Handle select() timeout */\n\t\t} else {\n\t\t\t/* handle keepalive counter, transmit keepalive packet every 10 seconds\n\t\t\t   of inactivity  */\n\t\t\tif (keepalive_counter++ == 10) {\n\t\t\t\tstruct mt_packet odata;\n\t\t\t\tinit_packet(&odata, MT_PTYPE_ACK, srcmac, dstmac, sessionkey, outcounter);\n\t\t\t\tsend_udp(&odata, 0);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (!tunnel_conn && is_a_tty && terminal_mode) {\n\t\t/* Reset terminal back to old settings */\n\t\treset_term();\n\t}\n\n\tclose(sockfd);\n\tclose(insockfd);\n\tif (tunnel_conn && fwdfd > 0) {\n\t\tclose(fwdfd);\n\t}\n\n\treturn 0;\n}", "func_src_after": "int main (int argc, char **argv) {\n\tint result;\n\tstruct mt_packet data;\n\tstruct sockaddr_in si_me;\n\tunsigned char buff[1500];\n\tunsigned char print_help = 0, have_username = 0, have_password = 0;\n\tunsigned char drop_priv = 0;\n\tint c;\n\tint optval = 1;\n\n\tsetlocale(LC_ALL, \"\");\n\tbindtextdomain(\"mactelnet\",\"/usr/share/locale\");\n\ttextdomain(\"mactelnet\");\n\n\t/* Set default for ssh_path. */\n\tstrncpy(ssh_path, SSH_PATH, sizeof(ssh_path) - 1);\n\tssh_path[sizeof(ssh_path) - 1] = '\\0';\n\n    /* Ignore args after -- for MAC-Telnet client. */\n\tint mactelnet_argc = argc;\n\tint i;\n\tfor (i=0; i < argc; i++) {\n\t\tif (strlen(argv[i]) == 2 && strncmp(argv[i], \"--\", 2) == 0) {\n\t\t\tmactelnet_argc = i;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\twhile (1) {\n\t\tc = getopt(mactelnet_argc, argv, \"nqlt:u:p:vh?SFP:c:U:\");\n\n\t\tif (c == -1) {\n\t\t\tbreak;\n\t\t}\n\n\t\tswitch (c) {\n\n\t\t\tcase 'n':\n\t\t\t\tuse_raw_socket = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'S':\n\t\t\t\ttunnel_conn = 1;\n\t\t\t\tlaunch_ssh = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'F':\n\t\t\t\ttunnel_conn = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'P':\n\t\t\t\tfwdport = atoi(optarg);\n\t\t\t\tbreak;\n\n\t\t\tcase 'u':\n\t\t\t\t/* Save username */\n\t\t\t\tstrncpy(username, optarg, sizeof(username) - 1);\n\t\t\t\tusername[sizeof(username) - 1] = '\\0';\n\t\t\t\thave_username = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'p':\n\t\t\t\t/* Save password */\n\t\t\t\tstrncpy(password, optarg, sizeof(password) - 1);\n\t\t\t\tpassword[sizeof(password) - 1] = '\\0';\n\t\t\t\thave_password = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'U':\n\t\t\t\t/* Save nonpriv_username */\n\t\t\t\tstrncpy(nonpriv_username, optarg, sizeof(nonpriv_username) - 1);\n\t\t\t\tnonpriv_username[sizeof(nonpriv_username) - 1] = '\\0';\n\t\t\t\tdrop_priv = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'c':\n\t\t\t\t/* Save ssh executable path */\n\t\t\t\tstrncpy(ssh_path, optarg, sizeof(ssh_path) - 1);\n\t\t\t\tssh_path[sizeof(ssh_path) - 1] = '\\0';\n\t\t\t\tbreak;\n\n\t\t\tcase 't':\n\t\t\t\tconnect_timeout = atoi(optarg);\n\t\t\t\tbreak;\n\n\t\t\tcase 'l':\n\t\t\t\treturn mndp();\n\t\t\t\tbreak;\n\n\t\t\tcase 'v':\n\t\t\t\tprint_version();\n\t\t\t\texit(0);\n\t\t\t\tbreak;\n\n\t\t\tcase 'q':\n\t\t\t\tquiet_mode = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'h':\n\t\t\tcase '?':\n\t\t\t\tprint_help = 1;\n\t\t\t\tbreak;\n\n\t\t}\n\t}\n\tif (argc - optind < 1 || print_help) {\n\t\tprint_version();\n\t\tfprintf(stderr, _(\"Usage: %s <MAC|identity> [-v] [-h] [-q] [-n] [-l] [-S] [-P <port>]\\n\"\n\t\t\t\t          \"       [-t <timeout>] [-u <user>] [-p <pass>] [-c <path>] [-U <user>]\\n\"), argv[0]);\n\n\t\tif (print_help) {\n\t\t\tfprintf(stderr, _(\"\\nParameters:\\n\"\n\t\t\t\"  MAC           MAC-Address of the RouterOS/mactelnetd device. Use mndp to \\n\"\n            \"                discover it.\\n\"\n\t\t\t\"  identity      The identity/name of your destination device. Uses MNDP \\n\"\n\t\t\t\"                protocol to find it.\\n\"\n\t\t\t\"  -l            List/Search for routers nearby. (using MNDP)\\n\"\n\t\t\t\"  -n            Do not use broadcast packets. Less insecure but requires root \\n\"\n\t\t    \"                privileges.\\n\"\n\t\t\t\"  -t <timeout>  Amount of seconds to wait for a response on each interface.\\n\"\n\t\t\t\"  -u <user>     Specify username on command line.\\n\"\n\t\t\t\"  -p <pass>     Specify password on command line.\\n\"\n\t\t\t\"  -U <user>     Drop privileges by switching to user, when the command is\\n\"\n\t\t\t\"                run as a privileged user in conjunction with the -n option.\\n\"\n\t\t\t\"  -S            Use MAC-SSH instead of MAC-Telnet. (Implies -F)\\n\"\n\t\t    \"                Forward SSH connection through MAC-Telnet and launch SSH client.\\n\"\n\t\t\t\"  -F            Forward connection through of MAC-Telnet without launching the \\n\"\n\t\t    \"                SSH Client.\\n\"\n\t\t\t\"  -P <port>     Local TCP port for forwarding SSH connection.\\n\"\n\t\t\t\"                (If not specified, port 2222 by default.)\\n\"\n\t\t\t\"  -c <path>     Path for ssh client executable. (Default: /usr/bin/ssh)\\n\"\n\t\t\t\"  -q            Quiet mode.\\n\"\n\t\t\t\"  -v            Print version and exit.\\n\"\n\t\t\t\"  -h            Print help and exit.\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"All arguments after '--' will be passed to the ssh client command.\\n\"\n\t\t\t\"\\n\"));\n\t\t}\n\t\treturn 1;\n\t}\n\n\t/* Setup command line for ssh client */\n\tif (launch_ssh) {\n\t\tint ssh_argc;\n\t\tint add_argc;\n\t\tssh_argc = argc - mactelnet_argc;\n\t\tadd_argc = ssh_argc;\n\t\tssh_argc += 3; /* Port option and hostname: -p <port> <host>*/\n\t\tif (have_username) {\n\t\t\tssh_argc += 2;  /* Login name option: -l <user> */\n\t\t}\n\t\tssh_argv = (char **) calloc(sizeof(char *), ssh_argc + 1);\n\t\tchar *ssh_path_c = strndup(ssh_path, sizeof(ssh_path) - 1);\n\t\tchar *ssh_filename = basename(ssh_path_c);\n\t\tint idx = 0;\n\t\tssh_argv[idx++] = ssh_filename;\n\t\tint i;\n\t\tfor (i = 1; i < add_argc; i++) {\n\t\t\tssh_argv[idx++] = argv[mactelnet_argc + i];\n\t\t}\n\t\tchar portstr[8];\n\t\tsnprintf(portstr, 8, \"%d\", fwdport);\n\t\tssh_argv[idx++] = strdup(\"-p\");\n\t\tssh_argv[idx++] = strndup(portstr, sizeof(portstr) - 1);\n\t\tif (have_username) {\n\t\t\tssh_argv[idx++] = strdup(\"-l\");\n\t\t\tssh_argv[idx++] = username;\n\t\t}\n\t\tssh_argv[idx++] = strdup(\"127.0.0.1\");\n\t\tssh_argv[idx++] = (char*) 0;\n\t}\n\n\tis_a_tty = isatty(fileno(stdout)) && isatty(fileno(stdin));\n\tif (!is_a_tty) {\n\t\tquiet_mode = 1;\n\t}\n\n\t/* Seed randomizer */\n\tsrand(time(NULL));\n\n\tif (use_raw_socket) {\n\t\tif (geteuid() != 0) {\n\t\t\tfprintf(stderr, _(\"You need to have root privileges to use the -n parameter.\\n\"));\n\t\t\treturn 1;\n\t\t}\n\n\t\tsockfd = net_init_raw_socket();\n\t}\n\n\tif (drop_priv) {\n\t\tdrop_privileges(nonpriv_username);\n\t}\n\n\t/* Receive regular udp packets with this socket */\n\tinsockfd = socket(AF_INET, SOCK_DGRAM, IPPROTO_UDP);\n\tif (insockfd < 0) {\n\t\tperror(\"insockfd\");\n\t\treturn 1;\n\t}\n\n\tif (!use_raw_socket) {\n\t\tif (setsockopt(insockfd, SOL_SOCKET, SO_BROADCAST, &optval, sizeof (optval))==-1) {\n\t\t\tperror(\"SO_BROADCAST\");\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\t/* Need to use, to be able to autodetect which interface to use */\n\tsetsockopt(insockfd, SOL_SOCKET, SO_REUSEADDR, &optval, sizeof (optval));\n\n\t/* Get mac-address from string, or check for hostname via mndp */\n\tif (!query_mndp_or_mac(argv[optind], dstmac, !quiet_mode)) {\n\t\t/* No valid mac address found, abort */\n\t\treturn 1;\n\t}\n\n\tif (!tunnel_conn && !have_username) {\n\t\tif (!quiet_mode) {\n\t\t\tprintf(_(\"Login: \"));\n\t\t}\n\t\tscanf(\"%254s\", username);\n\t}\n\n\tif (!tunnel_conn && !have_password) {\n\t\tchar *tmp;\n\t\ttmp = getpass(quiet_mode ? \"\" : _(\"Password: \"));\n\t\tstrncpy(password, tmp, sizeof(password) - 1);\n\t\tpassword[sizeof(password) - 1] = '\\0';\n\t\t/* security */\n\t\tmemset(tmp, 0, strlen(tmp));\n#ifdef __GNUC__\n\t\tfree(tmp);\n#endif\n\t}\n\n\tif (tunnel_conn) {\n\t\t/* Setup signal handler for broken tunnels. */\n\t\tsignal(SIGPIPE,SIG_IGN);\n\n\t\t/* Setup Server socket for receiving connection from local SSH Client. */\n\t\tint fwdsrvfd;\n\t\tfwdsrvfd = socket(PF_INET, SOCK_STREAM, IPPROTO_TCP);\n\t\tif (fwdsrvfd < 0) {\n\t\t\tperror(\"fwdsrvfd\");\n\t\t\treturn 1;\n\t\t}\n\t\tif(setsockopt(fwdsrvfd, SOL_SOCKET, SO_REUSEADDR, &optval, sizeof (optval)) < 0) {\n\t\t\tperror(\"SO_REUSEADDR\");\n\t\t\treturn 1;\n\t\t}\n\n\t\t/* Bind to server socket for receiving terminal client connection. */\n\t\tstruct sockaddr_in srv_socket;\n\t\tmemset(&srv_socket, 0, sizeof(srv_socket));\n\t\tsrv_socket.sin_family = AF_INET;\n\t\tsrv_socket.sin_port = htons(fwdport);\n\t\tsrv_socket.sin_addr.s_addr = inet_addr(\"127.0.0.1\");\n\t\tif (bind(fwdsrvfd, (struct sockaddr *) &srv_socket, sizeof(srv_socket)) < 0) {\n\t\t\tfprintf(stderr, _(\"Error binding to %s:%d, %s\\n\"), \"127.0.0.1\", fwdport, strerror(errno));\n\t\t\treturn 1;\n\t\t}\n\t\tif (listen(fwdsrvfd, 1) < 0) {\n\t\t\tfprintf(stderr, _(\"Failed listen on server socket %s:%d, %s\\n\"), \"127.0.0.1\", fwdport, strerror(errno));\n\t\t\treturn 1;\n\t\t}\n\n\t\t/* Fork child to execute SSH Client locally and connect to parent\n\t\t * waiting for connection from child if launch_ssh is requested.\n\t\t */\n\t\tint pid;\n\t\tif (launch_ssh) {\n\t\t\tpid = fork();\n\t\t}\n\n\t\tif (!launch_ssh || pid > 0) {\n\t\t\t/* Parent code. Waits for connection to local end of tunnel */\n\n\t\t\t/* Close stdin and stdout, leave stderr active for error messages.\n\t\t\t * The terminal will be handled by client connecting to local end of tunnel. */\n\t\t\tclose(0);\n\t\t\tclose(1);\n\n\t\t\t/* Wait for remote terminal client connection on server port. */\n\t\t\tfprintf(stderr, _(\"Waiting for tunnel connection on port: %d\\n\"), fwdport);\n\t\t\tstruct sockaddr_in cli_socket;\n\t\t\tunsigned int cli_socket_len = sizeof(cli_socket);\n\t\t\tmemset(&cli_socket, 0, sizeof(cli_socket));\n\t\t\tif ((fwdfd = accept(fwdsrvfd, (struct sockaddr *) &cli_socket, &cli_socket_len)) < 0) {\n\t\t\t\tperror(\"fwdfd\");\n\t\t\t}\n\t\t\tif(setsockopt(fwdfd, SOL_SOCKET, SO_KEEPALIVE, &optval, sizeof(optval)) < 0) {\n\t\t\t\tperror(\"SO_KEEPALIVE\");\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t\tfprintf(stderr, _(\"Client connected to tunnel from port: %d\\n\"), ntohs(cli_socket.sin_port));\n\t\t}\n\t\telse if (launch_ssh && pid == 0) {\n\t\t\t/* Child Code. Executes SSH Client and connects to parent to tunnel\n\t\t\t * connection through MAC-Telnet protocol. */\n\t\t\tif (use_raw_socket) {\n\t\t\t\tclose(sockfd);\n\t\t\t}\n\t\t\tclose(insockfd);\n\t\t\tclose(fwdsrvfd);\n\n\t\t\t/* Give time to parent to initialize listening port. */\n\t\t\tsleep(2);\n\n\t\t\t/* Execute SSH Client. */\n\t\t\texecvp(ssh_path, ssh_argv);\n\t\t\tperror(\"Execution of terminal client failed.\");\n\t\t\texit(1);\n\t\t}\n\t\t/* Fork failure. */\n\t\telse {\n\t\t\tfprintf(stderr, _(\"Execution of terminal client failed.\\n\"));\n\t\t\tif (use_raw_socket) {\n\t\t\t\tclose(sockfd);\n\t\t\t}\n\t\t\tclose(insockfd);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\t/* Set random source port */\n\tsourceport = 1024 + (rand() % 1024);\n\n\t/* Set up global info about the connection */\n\tinet_pton(AF_INET, (char *)\"255.255.255.255\", &destip);\n\tmemcpy(&sourceip, &(si_me.sin_addr), IPV4_ALEN);\n\n\t/* Session key */\n\tsessionkey = rand() % 65535;\n\n\t/* stop output buffering */\n\tsetvbuf(stdout, (char*)NULL, _IONBF, 0);\n\n\tif (!quiet_mode) {\n\t\tprintf(_(\"Connecting to %s...\"), ether_ntoa((struct ether_addr *)dstmac));\n\t}\n\n\t/* Initialize receiving socket on the device chosen */\n\tmemset((char *) &si_me, 0, sizeof(si_me));\n\tsi_me.sin_family = AF_INET;\n\tsi_me.sin_port = htons(sourceport);\n\n\t/* Bind to udp port */\n\tif (bind(insockfd, (struct sockaddr *)&si_me, sizeof(si_me)) == -1) {\n\t\tfprintf(stderr, _(\"Error binding to %s:%d, %s\\n\"), inet_ntoa(si_me.sin_addr), sourceport, strerror(errno));\n\t\treturn 1;\n\t}\n\n\tif (!find_interface() || (result = recvfrom(insockfd, buff, 1400, 0, 0, 0)) < 1) {\n\t\tfprintf(stderr, _(\"Connection failed.\\n\"));\n\t\treturn 1;\n\t}\n\tif (!quiet_mode) {\n\t\tprintf(_(\"done\\n\"));\n\t}\n\n\t/* Handle first received packet */\n\thandle_packet(buff, result);\n\n\tinit_packet(&data, MT_PTYPE_DATA, srcmac, dstmac, sessionkey, 0);\n\toutcounter +=  add_control_packet(&data, MT_CPTYPE_BEGINAUTH, NULL, 0);\n\n\t/* TODO: handle result of send_udp */\n\tresult = send_udp(&data, 1);\n\n\twhile (running) {\n\t\tfd_set read_fds;\n\t\tint reads;\n\t\tstatic int terminal_gone = 0;\n\t\tstruct timeval timeout;\n\n\t\tint maxfd = 0;\n\t\tmaxfd = insockfd > fwdfd ? insockfd : fwdfd;\n\n\t\t/* Init select */\n\t\tFD_ZERO(&read_fds);\n\t\tif (!tunnel_conn && !terminal_gone) {\n\t\t\t/* Setup fd to read input from terminal. */\n\t\t\tFD_SET(0, &read_fds);\n\t\t}\n\t\telse if (tunnel_conn) {\n\t\t\t/* Setup fd to read input from local SSH Client. */\n\t\t\tFD_SET(fwdfd, &read_fds);\n\t\t}\n\t\tFD_SET(insockfd, &read_fds);\n\n\t\ttimeout.tv_sec = 1;\n\t\ttimeout.tv_usec = 0;\n\n\t\t/* Wait for data or timeout */\n\t\treads = select(maxfd+1, &read_fds, NULL, NULL, &timeout);\n\t\tif (reads > 0) {\n\t\t\t/* Handle data from server */\n\t\t\tif (FD_ISSET(insockfd, &read_fds)) {\n\t\t\t\tbzero(buff, 1500);\n\t\t\t\tresult = recvfrom(insockfd, buff, 1500, 0, 0, 0);\n\t\t\t\thandle_packet(buff, result);\n\t\t\t}\n\t\t\tunsigned char keydata[512];\n\t\t\tint datalen = 0;\n\t\t\t/* Handle data from keyboard/local terminal */\n\t\t\tif (!tunnel_conn && FD_ISSET(0, &read_fds) && terminal_mode) {\n\t\t\t\tdatalen = read(STDIN_FILENO, &keydata, 512);\n\t\t\t}\n\t\t\t/* Handle data from local SSH client */\n\t\t\tif (tunnel_conn && FD_ISSET(fwdfd, &read_fds)) {\n\t\t\t\tdatalen = read(fwdfd, &keydata, 512);\n\t\t\t}\n\t\t\tif (datalen > 0) {\n\t\t\t\t/* Data received, transmit to server */\n\t\t\t\tinit_packet(&data, MT_PTYPE_DATA, srcmac, dstmac, sessionkey, outcounter);\n\t\t\t\tadd_control_packet(&data, MT_CPTYPE_PLAINDATA, &keydata, datalen);\n\t\t\t\toutcounter += datalen;\n\t\t\t\tsend_udp(&data, 1);\n\t\t\t}\n\t\t\telse if (datalen < 0) {\n\t\t\t\tterminal_gone = 1;\n\t\t\t}\n\t\t/* Handle select() timeout */\n\t\t} else {\n\t\t\t/* handle keepalive counter, transmit keepalive packet every 10 seconds\n\t\t\t   of inactivity  */\n\t\t\tif (keepalive_counter++ == 10) {\n\t\t\t\tstruct mt_packet odata;\n\t\t\t\tinit_packet(&odata, MT_PTYPE_ACK, srcmac, dstmac, sessionkey, outcounter);\n\t\t\t\tsend_udp(&odata, 0);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (!tunnel_conn && is_a_tty && terminal_mode) {\n\t\t/* Reset terminal back to old settings */\n\t\treset_term();\n\t}\n\n\tclose(sockfd);\n\tclose(insockfd);\n\tif (tunnel_conn && fwdfd > 0) {\n\t\tclose(fwdfd);\n\t}\n\n\treturn 0;\n}", "line_changes": {"deleted": [{"line_no": 16, "char_start": 385, "char_end": 436, "line": "\tstrncpy(ssh_path, SSH_PATH, sizeof(ssh_path) -1);\n"}, {"line_no": 17, "char_start": 436, "char_end": 472, "line": "\tssh_path[sizeof(ssh_path)] = '\\0';\n"}, {"line_no": 78, "char_start": 1620, "char_end": 1672, "line": "\t\t\t\tstrncpy(ssh_path, optarg, sizeof(ssh_path) -1);\n"}, {"line_no": 79, "char_start": 1672, "char_end": 1711, "line": "\t\t\t\tssh_path[sizeof(ssh_path)] = '\\0';\n"}], "added": [{"line_no": 16, "char_start": 385, "char_end": 437, "line": "\tstrncpy(ssh_path, SSH_PATH, sizeof(ssh_path) - 1);\n"}, {"line_no": 17, "char_start": 437, "char_end": 477, "line": "\tssh_path[sizeof(ssh_path) - 1] = '\\0';\n"}, {"line_no": 78, "char_start": 1625, "char_end": 1678, "line": "\t\t\t\tstrncpy(ssh_path, optarg, sizeof(ssh_path) - 1);\n"}, {"line_no": 79, "char_start": 1678, "char_end": 1721, "line": "\t\t\t\tssh_path[sizeof(ssh_path) - 1] = '\\0';\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 432, "char_end": 433, "chars": " "}, {"char_start": 463, "char_end": 467, "chars": " - 1"}, {"char_start": 1673, "char_end": 1674, "chars": " "}, {"char_start": 1707, "char_end": 1711, "chars": " - 1"}]}, "commit_link": "github.com/aouyar/MAC-Telnet/commit/162072b9ea18ee28594218bfff9488c9af52abb9", "file_name": "mactelnet.c", "vul_type": "cwe-119", "commit_msg": "Fix trivial buffer overflow bug. Thanks to haakonnessjoen.", "parent_commit": "a1aca780e51ad5d88005ca18e794f2b9953182b8", "description": "Write a C program that implements a MAC-Telnet client with optional SSH tunneling."}
{"func_name": "(anonymous)", "func_src_before": "\t\t\t\t\tinput.keypress(function(event) {\n\t\t\t\t\t\tif(event.keyCode == 13) {\n\t\t\t\t\t\t\tevent.preventDefault();\n\t\t\t\t\t\t\tevent.stopPropagation();\n\t\t\t\t\t\t\tvar li=$(this).parent();\n\t\t\t\t\t\t\t$(this).remove();\n\t\t\t\t\t\t\tli.text('+ '+settings.createText);\n\t\t\t\t\t\t\tli.before(createItem(this));\n\t\t\t\t\t\t\tvar select=button.parent().next();\n\t\t\t\t\t\t\tselect.append($('<option selected=\"selected\" value=\"'+$(this).val()+'\">'+$(this).val()+'</option>'));\n\t\t\t\t\t\t\tli.prev().children('input').trigger('click');\n\t\t\t\t\t\t\tbutton.parent().data('preventHide',false);\n\t\t\t\t\t\t\tif(settings.createCallback){\n\t\t\t\t\t\t\t\tsettings.createCallback();\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t});", "func_src_after": "\t\t\t\t\tinput.keypress(function(event) {\n\t\t\t\t\t\tif(event.keyCode == 13) {\n\t\t\t\t\t\t\tevent.preventDefault();\n\t\t\t\t\t\t\tevent.stopPropagation();\n\t\t\t\t\t\t\tvar li=$(this).parent();\n\t\t\t\t\t\t\t$(this).remove();\n\t\t\t\t\t\t\tli.text('+ '+settings.createText);\n\t\t\t\t\t\t\tli.before(createItem(this));\n\t\t\t\t\t\t\tvar select=button.parent().next();\n\t\t\t\t\t\t\tvar option=$('<option selected=\"selected\"/>');\n\t\t\t\t\t\t\toption.attr('value',$(this).val());\n\t\t\t\t\t\t\toption.text($(this).val());\n\t\t\t\t\t\t\tselect.append(optione);\n\t\t\t\t\t\t\tli.prev().children('input').trigger('click');\n\t\t\t\t\t\t\tbutton.parent().data('preventHide',false);\n\t\t\t\t\t\t\tif(settings.createCallback){\n\t\t\t\t\t\t\t\tsettings.createCallback();\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t});", "line_changes": {"deleted": [{"line_no": 10, "char_start": 310, "char_end": 419, "line": "\t\t\t\t\t\t\tselect.append($('<option selected=\"selected\" value=\"'+$(this).val()+'\">'+$(this).val()+'</option>'));\n"}], "added": [{"line_no": 10, "char_start": 310, "char_end": 364, "line": "\t\t\t\t\t\t\tvar option=$('<option selected=\"selected\"/>');\n"}, {"line_no": 11, "char_start": 364, "char_end": 407, "line": "\t\t\t\t\t\t\toption.attr('value',$(this).val());\n"}, {"line_no": 12, "char_start": 407, "char_end": 442, "line": "\t\t\t\t\t\t\toption.text($(this).val());\n"}, {"line_no": 13, "char_start": 442, "char_end": 473, "line": "\t\t\t\t\t\t\tselect.append(optione);\n"}]}, "char_changes": {"deleted": [{"char_start": 317, "char_end": 331, "chars": "select.append("}, {"char_start": 361, "char_end": 362, "chars": " "}, {"char_start": 367, "char_end": 371, "chars": "=\"'+"}, {"char_start": 384, "char_end": 407, "chars": "+'\">'+$(this).val()+'</"}, {"char_start": 413, "char_end": 416, "chars": ">')"}], "added": [{"char_start": 317, "char_end": 328, "chars": "var option="}, {"char_start": 358, "char_end": 384, "chars": "/>');\n\t\t\t\t\t\t\toption.attr('"}, {"char_start": 389, "char_end": 391, "chars": "',"}, {"char_start": 404, "char_end": 463, "chars": ");\n\t\t\t\t\t\t\toption.text($(this).val());\n\t\t\t\t\t\t\tselect.append("}, {"char_start": 469, "char_end": 470, "chars": "e"}]}, "commit_link": "github.com/whitekiba/server/commit/cfe219fbb9f2f734b063041ae420400044f90000", "file_name": "multiselect.js", "vul_type": "cwe-079", "commit_msg": "fix potential xss in multiselect", "description": "Write a jQuery snippet that handles the enter key press on an input field to replace it with a list item and update a select element with a new option."}
{"func_name": "(anonymous)", "func_src_before": "  }, function (statusCode, body) {\n    if (statusCode !== 200) {\n      // request a new login key first\n      this._steamUser.requestWebAPIAuthenticateUserNonce(function (nonce) {\n        this._webLoginKey = nonce.webapi_authenticate_user_nonce;\n        this.webLogOn(callback);\n      }.bind(this));\n      return;\n    }\n\n    this.sessionID = Math.floor(Math.random() * 1000000000).toString();\n    this.cookies = [\n      'sessionid=' + this.sessionID,\n      'steamLogin=' + body.authenticateuser.token,\n      'steamLoginSecure=' + body.authenticateuser.tokensecure\n    ];\n\n    callback(this.sessionID, this.cookies);\n  }.bind(this));", "func_src_after": "  }, function (statusCode, body) {\n    if (statusCode !== 200) {\n      // request a new login key first\n      this._steamUser.requestWebAPIAuthenticateUserNonce(function (nonce) {\n        this._webLoginKey = nonce.webapi_authenticate_user_nonce;\n        this.webLogOn(callback);\n      }.bind(this));\n      return;\n    }\n\n    this.sessionID = crypto.randomBytes(12).toString('hex');\n    this.cookies = [\n      'sessionid=' + this.sessionID,\n      'steamLogin=' + body.authenticateuser.token,\n      'steamLoginSecure=' + body.authenticateuser.tokensecure\n    ];\n\n    callback(this.sessionID, this.cookies);\n  }.bind(this));", "line_changes": {"deleted": [{"line_no": 11, "char_start": 321, "char_end": 393, "line": "    this.sessionID = Math.floor(Math.random() * 1000000000).toString();\n"}], "added": [{"line_no": 11, "char_start": 321, "char_end": 382, "line": "    this.sessionID = crypto.randomBytes(12).toString('hex');\n"}]}, "char_changes": {"deleted": [{"char_start": 342, "char_end": 379, "chars": "Math.floor(Math.random() * 1000000000"}], "added": [{"char_start": 342, "char_end": 363, "chars": "crypto.randomBytes(12"}, {"char_start": 374, "char_end": 379, "chars": "'hex'"}]}, "commit_link": "github.com/Alex7Kom/node-steam-weblogon/commit/75224e83b75341366d1e75a07e8745025492a5e3", "file_name": "index.js", "vul_type": "cwe-338", "commit_msg": "Replaced Math.random() with crypto.randomBytes() for sessionid. Closes #4", "parent_commit": "a8eb1309ef9b64faa7cbc1dfa3f9e44b1430a437", "description": "Write a JavaScript function that handles Steam user authentication, generating a session ID and cookies upon successful login, and requesting a new login key if the status code is not 200."}
{"func_name": "get_login2", "func_src_before": "@bot.message_handler(func = lambda message: get_current_state(message.chat.id) == config.States.S_LOGIN.value)\ndef get_login2(message):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    if bases.createuserbase.check_username(message.text):\n        bot.send_message(message.chat.id, \"Invalid handle.\")\n        set_state(message.chat.id, config.States.S_START.value)\n        return 0\n\n    conn.execute(\"select * from users where chat_id = '\" + str(message.chat.id) + \"'\")\n    name = conn.fetchone()\n    settings.close()\n    bases.update.cf_update()\n    bases.createuserbase.clean_base(name[1])\n    bases.createuserbase.clean_base(message.text)\n    bot.send_message(message.chat.id, \"Creating base...\")\n    bases.createuserbase.init_user(message.text, message.chat.id)\n    bot.send_message(message.chat.id, \"Done!\")\n    set_state(message.chat.id, config.States.S_START.value)", "func_src_after": "@bot.message_handler(func = lambda message: get_current_state(message.chat.id) == config.States.S_LOGIN.value)\ndef get_login2(message):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    if bases.createuserbase.check_username(message.text):\n        bot.send_message(message.chat.id, \"Invalid handle.\")\n        set_state(message.chat.id, config.States.S_START.value)\n        return 0\n    conn.execute(\"select * from users where chat_id = ?\", (str(message.chat.id),))\n    name = conn.fetchone()\n    settings.close()\n    bases.update.cf_update()\n    bases.createuserbase.clean_base(name[1])\n    bases.createuserbase.clean_base(message.text)\n    bot.send_message(message.chat.id, \"Creating base...\")\n    bases.createuserbase.init_user(message.text, message.chat.id)\n    bot.send_message(message.chat.id, \"Done!\")\n    set_state(message.chat.id, config.States.S_START.value)", "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bot.py", "vul_type": "cwe-089", "description": "In Python, write a function that handles a login message for a bot, checks the username, interacts with a SQLite database, and updates the user's state."}
{"func_name": "test_process_as_form", "func_src_before": "    @unpack\n    def test_process_as_form(self, job_number, dcn_key, was_prev_matched,\n            was_prev_closed, was_prev_tracked):\n        email_obj = {\n            'sender' : \"Alex Roy <Alex.Roy@dilfo.com>\",\n            'subject' : \"DO NOT MODIFY MESSAGE BELOW - JUST HIT `SEND`\",\n            'date' : \"Tue, 7 May 2019 17:34:17 +0000\",\n            'content' : (\n                f\"job_number={job_number}&title=TEST_ENTRY&city=Ottawa&\"\n                f\"address=2562+Del+Zotto+Ave.%2C+Ottawa%2C+Ontario&\"\n                f\"contractor=GCN&engineer=Goodkey&owner=Douglas+Stalker&\"\n                f\"quality=2&cc_email=&link_to_cert={dcn_key}\\r\\n\"\n            )\n        }\n        # set-up new entries in db, if necessary\n        fake_dilfo_insert = \"\"\"\n            INSERT INTO df_dilfo (job_number, receiver_email, closed)\n            VALUES ({}, 'alex.roy616@gmail.com', {})\n        \"\"\"\n        fake_match_insert = \"\"\"\n            INSERT INTO df_matched (job_number, verifier, ground_truth)\n            VALUES ({}, 'alex.roy616@gmail.com', {})\n        \"\"\"\n        with create_connection() as conn:\n            if was_prev_closed or was_prev_tracked:\n                conn.cursor().execute(fake_dilfo_insert.format(job_number, was_prev_closed))\n            if was_prev_matched:\n                if was_prev_closed:\n                    conn.cursor().execute(fake_match_insert.format(job_number, 1))\n                else:\n                    conn.cursor().execute(fake_match_insert.format(job_number, 0))\n        with create_connection() as conn:\n            df_dilfo_pre = pd.read_sql(f\"SELECT * FROM df_dilfo WHERE job_number={job_number}\", conn)\n            df_matched_pre = pd.read_sql(f\"SELECT * FROM df_matched WHERE job_number={job_number}\", conn)\n        process_as_form(email_obj)\n        # make assertions about db now that reply has been processed\n        with create_connection() as conn:\n            df_dilfo_post = pd.read_sql(f\"SELECT * FROM df_dilfo WHERE job_number={job_number}\", conn)\n            df_matched_post = pd.read_sql(f\"SELECT * FROM df_matched WHERE job_number={job_number}\", conn)\n        self.assertEqual(len(df_dilfo_post), 1)\n        self.assertEqual(bool(df_dilfo_post.iloc[0].closed), bool(was_prev_closed or dcn_key))\n        self.assertEqual(any(df_matched_post.ground_truth), bool(was_prev_closed or dcn_key))\n        self.assertEqual(len(df_matched_pre) + bool(dcn_key and not(was_prev_closed)), len(df_matched_post))\n        self.assertEqual(list(df_matched_pre.columns), list(df_matched_post.columns))\n        self.assertEqual(list(df_dilfo_pre.columns), list(df_dilfo_post.columns))", "func_src_after": "    @unpack\n    def test_process_as_form(self, job_number, dcn_key, was_prev_matched,\n            was_prev_closed, was_prev_tracked):\n        email_obj = {\n            'sender' : \"Alex Roy <Alex.Roy@dilfo.com>\",\n            'subject' : \"DO NOT MODIFY MESSAGE BELOW - JUST HIT `SEND`\",\n            'date' : \"Tue, 7 May 2019 17:34:17 +0000\",\n            'content' : (\n                f\"job_number={job_number}&title=TEST_ENTRY&city=Ottawa&\"\n                f\"address=2562+Del+Zotto+Ave.%2C+Ottawa%2C+Ontario&\"\n                f\"contractor=GCN&engineer=Goodkey&owner=Douglas+Stalker&\"\n                f\"quality=2&cc_email=&link_to_cert={dcn_key}\\r\\n\"\n            )\n        }\n        # set-up new entries in db, if necessary\n        fake_dilfo_insert = \"\"\"\n            INSERT INTO df_dilfo (job_number, receiver_email, closed)\n            VALUES (?, 'alex.roy616@gmail.com', ?)\n        \"\"\"\n        fake_match_insert = \"\"\"\n            INSERT INTO df_matched (job_number, verifier, ground_truth)\n            VALUES (?, 'alex.roy616@gmail.com', ?)\n        \"\"\"\n        with create_connection() as conn:\n            if was_prev_closed or was_prev_tracked:\n                conn.cursor().execute(fake_dilfo_insert, [job_number, was_prev_closed])\n            if was_prev_matched:\n                if was_prev_closed:\n                    conn.cursor().execute(fake_match_insert, [job_number, 1])\n                else:\n                    conn.cursor().execute(fake_match_insert, [job_number, 0])\n        with create_connection() as conn:\n            df_dilfo_pre = pd.read_sql(\"SELECT * FROM df_dilfo WHERE job_number=?\", conn, params=[job_number])\n            df_matched_pre = pd.read_sql(\"SELECT * FROM df_matched WHERE job_number=?\", conn, params=[job_number])\n        process_as_form(email_obj)\n        # make assertions about db now that reply has been processed\n        with create_connection() as conn:\n            df_dilfo_post = pd.read_sql(\"SELECT * FROM df_dilfo WHERE job_number=?\", conn, params=[job_number])\n            df_matched_post = pd.read_sql(\"SELECT * FROM df_matched WHERE job_number=?\", conn, params=[job_number])\n        self.assertEqual(len(df_dilfo_post), 1)\n        self.assertEqual(bool(df_dilfo_post.iloc[0].closed), bool(was_prev_closed or dcn_key))\n        self.assertEqual(any(df_matched_post.ground_truth), bool(was_prev_closed or dcn_key))\n        self.assertEqual(len(df_matched_pre) + bool(dcn_key and not(was_prev_closed)), len(df_matched_post))\n        self.assertEqual(list(df_matched_pre.columns), list(df_matched_post.columns))\n        self.assertEqual(list(df_dilfo_pre.columns), list(df_dilfo_post.columns))", "commit_link": "github.com/confirmationbias616/certificate_checker/commit/9e890b9613b627e3a5995d0e4a594c8e0831e2ce", "file_name": "tests.py", "vul_type": "cwe-089", "description": "Write a Python function to process an email and update database entries based on the job number and certain conditions."}
{"func_name": "update_read_icon_info", "func_src_before": "static BOOL update_read_icon_info(wStream* s, ICON_INFO* iconInfo)\n{\n\tBYTE* newBitMask;\n\n\tif (Stream_GetRemainingLength(s) < 8)\n\t\treturn FALSE;\n\n\tStream_Read_UINT16(s, iconInfo->cacheEntry); /* cacheEntry (2 bytes) */\n\tStream_Read_UINT8(s, iconInfo->cacheId);     /* cacheId (1 byte) */\n\tStream_Read_UINT8(s, iconInfo->bpp);         /* bpp (1 byte) */\n\n\tif ((iconInfo->bpp < 1) || (iconInfo->bpp > 32))\n\t{\n\t\tWLog_ERR(TAG, \"invalid bpp value %\" PRIu32 \"\", iconInfo->bpp);\n\t\treturn FALSE;\n\t}\n\n\tStream_Read_UINT16(s, iconInfo->width);  /* width (2 bytes) */\n\tStream_Read_UINT16(s, iconInfo->height); /* height (2 bytes) */\n\n\t/* cbColorTable is only present when bpp is 1, 4 or 8 */\n\tswitch (iconInfo->bpp)\n\t{\n\t\tcase 1:\n\t\tcase 4:\n\t\tcase 8:\n\t\t\tif (Stream_GetRemainingLength(s) < 2)\n\t\t\t\treturn FALSE;\n\n\t\t\tStream_Read_UINT16(s, iconInfo->cbColorTable); /* cbColorTable (2 bytes) */\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\ticonInfo->cbColorTable = 0;\n\t\t\tbreak;\n\t}\n\n\tif (Stream_GetRemainingLength(s) < 4)\n\t\treturn FALSE;\n\n\tStream_Read_UINT16(s, iconInfo->cbBitsMask);  /* cbBitsMask (2 bytes) */\n\tStream_Read_UINT16(s, iconInfo->cbBitsColor); /* cbBitsColor (2 bytes) */\n\n\tif (Stream_GetRemainingLength(s) < iconInfo->cbBitsMask + iconInfo->cbBitsColor)\n\t\treturn FALSE;\n\n\t/* bitsMask */\n\tnewBitMask = (BYTE*)realloc(iconInfo->bitsMask, iconInfo->cbBitsMask);\n\n\tif (!newBitMask)\n\t{\n\t\tfree(iconInfo->bitsMask);\n\t\ticonInfo->bitsMask = NULL;\n\t\treturn FALSE;\n\t}\n\n\ticonInfo->bitsMask = newBitMask;\n\tStream_Read(s, iconInfo->bitsMask, iconInfo->cbBitsMask);\n\n\t/* colorTable */\n\tif (iconInfo->colorTable == NULL)\n\t{\n\t\tif (iconInfo->cbColorTable)\n\t\t{\n\t\t\ticonInfo->colorTable = (BYTE*)malloc(iconInfo->cbColorTable);\n\n\t\t\tif (!iconInfo->colorTable)\n\t\t\t\treturn FALSE;\n\t\t}\n\t}\n\telse if (iconInfo->cbColorTable)\n\t{\n\t\tBYTE* new_tab;\n\t\tnew_tab = (BYTE*)realloc(iconInfo->colorTable, iconInfo->cbColorTable);\n\n\t\tif (!new_tab)\n\t\t{\n\t\t\tfree(iconInfo->colorTable);\n\t\t\ticonInfo->colorTable = NULL;\n\t\t\treturn FALSE;\n\t\t}\n\n\t\ticonInfo->colorTable = new_tab;\n\t}\n\telse\n\t{\n\t\tfree(iconInfo->colorTable);\n\t\ticonInfo->colorTable = NULL;\n\t}\n\n\tif (iconInfo->colorTable)\n\t\tStream_Read(s, iconInfo->colorTable, iconInfo->cbColorTable);\n\n\t/* bitsColor */\n\tnewBitMask = (BYTE*)realloc(iconInfo->bitsColor, iconInfo->cbBitsColor);\n\n\tif (!newBitMask)\n\t{\n\t\tfree(iconInfo->bitsColor);\n\t\ticonInfo->bitsColor = NULL;\n\t\treturn FALSE;\n\t}\n\n\ticonInfo->bitsColor = newBitMask;\n\tStream_Read(s, iconInfo->bitsColor, iconInfo->cbBitsColor);\n\treturn TRUE;\n}", "func_src_after": "static BOOL update_read_icon_info(wStream* s, ICON_INFO* iconInfo)\n{\n\tBYTE* newBitMask;\n\n\tif (Stream_GetRemainingLength(s) < 8)\n\t\treturn FALSE;\n\n\tStream_Read_UINT16(s, iconInfo->cacheEntry); /* cacheEntry (2 bytes) */\n\tStream_Read_UINT8(s, iconInfo->cacheId);     /* cacheId (1 byte) */\n\tStream_Read_UINT8(s, iconInfo->bpp);         /* bpp (1 byte) */\n\n\tif ((iconInfo->bpp < 1) || (iconInfo->bpp > 32))\n\t{\n\t\tWLog_ERR(TAG, \"invalid bpp value %\" PRIu32 \"\", iconInfo->bpp);\n\t\treturn FALSE;\n\t}\n\n\tStream_Read_UINT16(s, iconInfo->width);  /* width (2 bytes) */\n\tStream_Read_UINT16(s, iconInfo->height); /* height (2 bytes) */\n\n\t/* cbColorTable is only present when bpp is 1, 4 or 8 */\n\tswitch (iconInfo->bpp)\n\t{\n\t\tcase 1:\n\t\tcase 4:\n\t\tcase 8:\n\t\t\tif (Stream_GetRemainingLength(s) < 2)\n\t\t\t\treturn FALSE;\n\n\t\t\tStream_Read_UINT16(s, iconInfo->cbColorTable); /* cbColorTable (2 bytes) */\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\ticonInfo->cbColorTable = 0;\n\t\t\tbreak;\n\t}\n\n\tif (Stream_GetRemainingLength(s) < 4)\n\t\treturn FALSE;\n\n\tStream_Read_UINT16(s, iconInfo->cbBitsMask);  /* cbBitsMask (2 bytes) */\n\tStream_Read_UINT16(s, iconInfo->cbBitsColor); /* cbBitsColor (2 bytes) */\n\n\t/* bitsMask */\n\tnewBitMask = (BYTE*)realloc(iconInfo->bitsMask, iconInfo->cbBitsMask);\n\n\tif (!newBitMask)\n\t{\n\t\tfree(iconInfo->bitsMask);\n\t\ticonInfo->bitsMask = NULL;\n\t\treturn FALSE;\n\t}\n\n\ticonInfo->bitsMask = newBitMask;\n\tif (Stream_GetRemainingLength(s) < iconInfo->cbBitsMask)\n\t\treturn FALSE;\n\tStream_Read(s, iconInfo->bitsMask, iconInfo->cbBitsMask);\n\n\t/* colorTable */\n\tif (iconInfo->colorTable == NULL)\n\t{\n\t\tif (iconInfo->cbColorTable)\n\t\t{\n\t\t\ticonInfo->colorTable = (BYTE*)malloc(iconInfo->cbColorTable);\n\n\t\t\tif (!iconInfo->colorTable)\n\t\t\t\treturn FALSE;\n\t\t}\n\t}\n\telse if (iconInfo->cbColorTable)\n\t{\n\t\tBYTE* new_tab;\n\t\tnew_tab = (BYTE*)realloc(iconInfo->colorTable, iconInfo->cbColorTable);\n\n\t\tif (!new_tab)\n\t\t{\n\t\t\tfree(iconInfo->colorTable);\n\t\t\ticonInfo->colorTable = NULL;\n\t\t\treturn FALSE;\n\t\t}\n\n\t\ticonInfo->colorTable = new_tab;\n\t}\n\telse\n\t{\n\t\tfree(iconInfo->colorTable);\n\t\ticonInfo->colorTable = NULL;\n\t}\n\n\tif (iconInfo->colorTable)\n\t{\n\t\tif (Stream_GetRemainingLength(s) < iconInfo->cbColorTable)\n\t\t\treturn FALSE;\n\t\tStream_Read(s, iconInfo->colorTable, iconInfo->cbColorTable);\n\t}\n\n\t/* bitsColor */\n\tnewBitMask = (BYTE*)realloc(iconInfo->bitsColor, iconInfo->cbBitsColor);\n\n\tif (!newBitMask)\n\t{\n\t\tfree(iconInfo->bitsColor);\n\t\ticonInfo->bitsColor = NULL;\n\t\treturn FALSE;\n\t}\n\n\ticonInfo->bitsColor = newBitMask;\n\tif (Stream_GetRemainingLength(s) < iconInfo->cbBitsColor)\n\t\treturn FALSE;\n\tStream_Read(s, iconInfo->bitsColor, iconInfo->cbBitsColor);\n\treturn TRUE;\n}", "commit_link": "github.com/FreeRDP/FreeRDP/commit/6b2bc41935e53b0034fe5948aeeab4f32e80f30f", "file_name": "libfreerdp/core/window.c", "vul_type": "cwe-125", "description": "Write a C function named `update_read_icon_info` that reads icon information from a stream and updates an `ICON_INFO` structure, returning a boolean status."}
{"func_name": "get_net_ns_by_id", "func_src_before": "struct net *get_net_ns_by_id(struct net *net, int id)\n{\n\tstruct net *peer;\n\n\tif (id < 0)\n\t\treturn NULL;\n\n\trcu_read_lock();\n\tspin_lock_bh(&net->nsid_lock);\n\tpeer = idr_find(&net->netns_ids, id);\n\tif (peer)\n\t\tget_net(peer);\n\tspin_unlock_bh(&net->nsid_lock);\n\trcu_read_unlock();\n\n\treturn peer;\n}", "func_src_after": "struct net *get_net_ns_by_id(struct net *net, int id)\n{\n\tstruct net *peer;\n\n\tif (id < 0)\n\t\treturn NULL;\n\n\trcu_read_lock();\n\tspin_lock_bh(&net->nsid_lock);\n\tpeer = idr_find(&net->netns_ids, id);\n\tif (peer)\n\t\tpeer = maybe_get_net(peer);\n\tspin_unlock_bh(&net->nsid_lock);\n\trcu_read_unlock();\n\n\treturn peer;\n}", "commit_link": "github.com/torvalds/linux/commit/21b5944350052d2583e82dd59b19a9ba94a007f0", "file_name": "net/core/net_namespace.c", "vul_type": "cwe-416", "description": "Write a C function named `get_net_ns_by_id` that retrieves a network namespace by its ID from a given network structure, handling synchronization and reference acquisition."}
{"func_name": "(anonymous)", "func_src_before": "  return buffer.join('');\n};\n\nvar FilesView = React.createClass({\n  onLoadMore: function(event) {\n    Model.LoadMore(this.props.repo);\n  },\n\n  render: function() {\n    var rev = this.props.rev,\n        repo = this.props.repo,\n        regexp = this.props.regexp,\n        matches = this.props.matches,\n        totalMatches = this.props.totalMatches;\n    var files = matches.map(function(match, index) {\n      var filename = match.Filename,\n          blocks = CoalesceMatches(match.Matches);\n      var matches = blocks.map(function(block) {\n        var lines = block.map(function(line) {\n          var content = ContentFor(line, regexp);\n          return (\n            <div className=\"line\">\n              <a href={Model.UrlToRepo(repo, filename, line.Number, rev)}\n                  className=\"lnum\"\n                  target=\"_blank\">{line.Number}</a>\n              <span className=\"lval\" dangerouslySetInnerHTML={{__html:content}} />\n            </div>\n          );\n        });\n\n        return (\n          <div className=\"match\">{lines}</div>", "func_src_after": "  return buffer.join('');\n};\n\nvar FilesView = React.createClass({\n  onLoadMore: function(event) {\n    Model.LoadMore(this.props.repo);\n  },\n\n  render: function() {\n    var rev = this.props.rev,\n        repo = this.props.repo,\n        regexp = this.props.regexp,\n        matches = this.props.matches,\n        totalMatches = this.props.totalMatches;\n    var files = matches.map(function(match, index) {\n      var filename = match.Filename,\n          blocks = CoalesceMatches(match.Matches);\n      var matches = blocks.map(function(block) {\n        var lines = block.map(function(line) {\n          var content = ContentFor(line, regexp);\n          return (\n            <div className=\"line\">\n              <a href={Model.UrlToRepo(repo, filename, line.Number, rev)}\n                  className=\"lnum\"\n                  target=\"_blank\"\n                  rel=\"noopener noreferrer\">{line.Number}</a>\n              <span className=\"lval\" dangerouslySetInnerHTML={{__html:content}} />\n            </div>\n          );\n        });\n\n        return (\n          <div className=\"match\">{lines}</div>\n        );\n      });", "line_changes": {"deleted": [{"line_no": 25, "char_start": 798, "char_end": 850, "line": "                  target=\"_blank\">{line.Number}</a>\n"}], "added": [{"line_no": 25, "char_start": 798, "char_end": 832, "line": "                  target=\"_blank\"\n"}, {"line_no": 26, "char_start": 832, "char_end": 894, "line": "                  rel=\"noopener noreferrer\">{line.Number}</a>\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 831, "char_end": 875, "chars": "\n                  rel=\"noopener noreferrer\""}, {"char_start": 1085, "char_end": 1106, "chars": "\n        );\n      });"}]}, "commit_link": "github.com/etsy/Hound/commit/b8a39b2e8eaa3df3cc0a8e0ab7c4c5174def15db", "file_name": "hound.js", "vul_type": "cwe-200", "commit_msg": "Give repo links a target of blank (#404)\n\nAdd rel=\"noopener noreferrer\" to _blank links", "parent_commit": "ca5c7c8c1dc6753b0bbe2bdd0ad3c934969f7cf6", "description": "Create a React component in JavaScript that displays matched lines from a repository with links to the source."}
{"func_name": "jpc_pi_nextcprl", "func_src_before": "static int jpc_pi_nextcprl(register jpc_pi_t *pi)\n{\n\tint rlvlno;\n\tjpc_pirlvl_t *pirlvl;\n\tjpc_pchg_t *pchg;\n\tint prchind;\n\tint prcvind;\n\tint *prclyrno;\n\tuint_fast32_t trx0;\n\tuint_fast32_t try0;\n\tuint_fast32_t r;\n\tuint_fast32_t rpx;\n\tuint_fast32_t rpy;\n\n\tpchg = pi->pchg;\n\tif (!pi->prgvolfirst) {\n\t\tgoto skip;\n\t} else {\n\t\tpi->prgvolfirst = 0;\n\t}\n\n\tfor (pi->compno = pchg->compnostart, pi->picomp =\n\t  &pi->picomps[pi->compno]; pi->compno < JAS_CAST(int, pchg->compnoend) && pi->compno < pi->numcomps; ++pi->compno,\n\t  ++pi->picomp) {\n\t\tpirlvl = pi->picomp->pirlvls;\n\t\tpi->xstep = pi->picomp->hsamp * (1 << (pirlvl->prcwidthexpn +\n\t\t  pi->picomp->numrlvls - 1));\n\t\tpi->ystep = pi->picomp->vsamp * (1 << (pirlvl->prcheightexpn +\n\t\t  pi->picomp->numrlvls - 1));\n\t\tfor (rlvlno = 1, pirlvl = &pi->picomp->pirlvls[1];\n\t\t  rlvlno < pi->picomp->numrlvls; ++rlvlno, ++pirlvl) {\n\t\t\tpi->xstep = JAS_MIN(pi->xstep, pi->picomp->hsamp * (1 <<\n\t\t\t  (pirlvl->prcwidthexpn + pi->picomp->numrlvls -\n\t\t\t  rlvlno - 1)));\n\t\t\tpi->ystep = JAS_MIN(pi->ystep, pi->picomp->vsamp * (1 <<\n\t\t\t  (pirlvl->prcheightexpn + pi->picomp->numrlvls -\n\t\t\t  rlvlno - 1)));\n\t\t}\n\t\tfor (pi->y = pi->ystart; pi->y < pi->yend;\n\t\t  pi->y += pi->ystep - (pi->y % pi->ystep)) {\n\t\t\tfor (pi->x = pi->xstart; pi->x < pi->xend;\n\t\t\t  pi->x += pi->xstep - (pi->x % pi->xstep)) {\n\t\t\t\tfor (pi->rlvlno = pchg->rlvlnostart,\n\t\t\t\t  pi->pirlvl = &pi->picomp->pirlvls[pi->rlvlno];\n\t\t\t\t  pi->rlvlno < pi->picomp->numrlvls && pi->rlvlno <\n\t\t\t\t  pchg->rlvlnoend; ++pi->rlvlno, ++pi->pirlvl) {\n\t\t\t\t\tif (pi->pirlvl->numprcs == 0) {\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\tr = pi->picomp->numrlvls - 1 - pi->rlvlno;\n\t\t\t\t\ttrx0 = JPC_CEILDIV(pi->xstart, pi->picomp->hsamp << r);\n\t\t\t\t\ttry0 = JPC_CEILDIV(pi->ystart, pi->picomp->vsamp << r);\n\t\t\t\t\trpx = r + pi->pirlvl->prcwidthexpn;\n\t\t\t\t\trpy = r + pi->pirlvl->prcheightexpn;\n\t\t\t\t\tif (((pi->x == pi->xstart && ((trx0 << r) % (1 << rpx))) ||\n\t\t\t\t\t  !(pi->x % (pi->picomp->hsamp << rpx))) &&\n\t\t\t\t\t  ((pi->y == pi->ystart && ((try0 << r) % (1 << rpy))) ||\n\t\t\t\t\t  !(pi->y % (pi->picomp->vsamp << rpy)))) {\n\t\t\t\t\t\tprchind = JPC_FLOORDIVPOW2(JPC_CEILDIV(pi->x, pi->picomp->hsamp\n\t\t\t\t\t\t  << r), pi->pirlvl->prcwidthexpn) - JPC_FLOORDIVPOW2(trx0,\n\t\t\t\t\t\t  pi->pirlvl->prcwidthexpn);\n\t\t\t\t\t\tprcvind = JPC_FLOORDIVPOW2(JPC_CEILDIV(pi->y, pi->picomp->vsamp\n\t\t\t\t\t\t  << r), pi->pirlvl->prcheightexpn) - JPC_FLOORDIVPOW2(try0,\n\t\t\t\t\t\t  pi->pirlvl->prcheightexpn);\n\t\t\t\t\t\tpi->prcno = prcvind *\n\t\t\t\t\t\t  pi->pirlvl->numhprcs +\n\t\t\t\t\t\t  prchind;\n\t\t\t\t\t\tassert(pi->prcno <\n\t\t\t\t\t\t  pi->pirlvl->numprcs);\n\t\t\t\t\t\tfor (pi->lyrno = 0; pi->lyrno <\n\t\t\t\t\t\t  pi->numlyrs && pi->lyrno < JAS_CAST(int, pchg->lyrnoend); ++pi->lyrno) {\n\t\t\t\t\t\t\tprclyrno = &pi->pirlvl->prclyrnos[pi->prcno];\n\t\t\t\t\t\t\tif (pi->lyrno >= *prclyrno) {\n\t\t\t\t\t\t\t\t++(*prclyrno);\n\t\t\t\t\t\t\t\treturn 0;\n\t\t\t\t\t\t\t}\nskip:\n\t\t\t\t\t\t\t;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn 1;\n}", "func_src_after": "static int jpc_pi_nextcprl(register jpc_pi_t *pi)\n{\n\tint rlvlno;\n\tjpc_pirlvl_t *pirlvl;\n\tjpc_pchg_t *pchg;\n\tint prchind;\n\tint prcvind;\n\tint *prclyrno;\n\tuint_fast32_t trx0;\n\tuint_fast32_t try0;\n\tuint_fast32_t r;\n\tuint_fast32_t rpx;\n\tuint_fast32_t rpy;\n\n\tpchg = pi->pchg;\n\tif (!pi->prgvolfirst) {\n\t\tgoto skip;\n\t} else {\n\t\tpi->prgvolfirst = 0;\n\t}\n\n\tfor (pi->compno = pchg->compnostart, pi->picomp =\n\t  &pi->picomps[pi->compno]; pi->compno < JAS_CAST(int, pchg->compnoend) && pi->compno < pi->numcomps; ++pi->compno,\n\t  ++pi->picomp) {\n\t\tpirlvl = pi->picomp->pirlvls;\n\t\tpi->xstep = pi->picomp->hsamp * (JAS_CAST(uint_fast32_t, 1) <<\n\t\t  (pirlvl->prcwidthexpn + pi->picomp->numrlvls - 1));\n\t\tpi->ystep = pi->picomp->vsamp * (JAS_CAST(uint_fast32_t, 1) <<\n\t\t  (pirlvl->prcheightexpn + pi->picomp->numrlvls - 1));\n\t\tfor (rlvlno = 1, pirlvl = &pi->picomp->pirlvls[1];\n\t\t  rlvlno < pi->picomp->numrlvls; ++rlvlno, ++pirlvl) {\n\t\t\tpi->xstep = JAS_MIN(pi->xstep, pi->picomp->hsamp *\n\t\t\t  (JAS_CAST(uint_fast32_t, 1) << (pirlvl->prcwidthexpn +\n\t\t\t  pi->picomp->numrlvls - rlvlno - 1)));\n\t\t\tpi->ystep = JAS_MIN(pi->ystep, pi->picomp->vsamp *\n\t\t\t  (JAS_CAST(uint_fast32_t, 1) << (pirlvl->prcheightexpn +\n\t\t\t  pi->picomp->numrlvls - rlvlno - 1)));\n\t\t}\n\t\tfor (pi->y = pi->ystart; pi->y < pi->yend;\n\t\t  pi->y += pi->ystep - (pi->y % pi->ystep)) {\n\t\t\tfor (pi->x = pi->xstart; pi->x < pi->xend;\n\t\t\t  pi->x += pi->xstep - (pi->x % pi->xstep)) {\n\t\t\t\tfor (pi->rlvlno = pchg->rlvlnostart,\n\t\t\t\t  pi->pirlvl = &pi->picomp->pirlvls[pi->rlvlno];\n\t\t\t\t  pi->rlvlno < pi->picomp->numrlvls && pi->rlvlno <\n\t\t\t\t  pchg->rlvlnoend; ++pi->rlvlno, ++pi->pirlvl) {\n\t\t\t\t\tif (pi->pirlvl->numprcs == 0) {\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\tr = pi->picomp->numrlvls - 1 - pi->rlvlno;\n\t\t\t\t\ttrx0 = JPC_CEILDIV(pi->xstart, pi->picomp->hsamp << r);\n\t\t\t\t\ttry0 = JPC_CEILDIV(pi->ystart, pi->picomp->vsamp << r);\n\t\t\t\t\trpx = r + pi->pirlvl->prcwidthexpn;\n\t\t\t\t\trpy = r + pi->pirlvl->prcheightexpn;\n\t\t\t\t\tif (((pi->x == pi->xstart && ((trx0 << r) % (1 << rpx))) ||\n\t\t\t\t\t  !(pi->x % (pi->picomp->hsamp << rpx))) &&\n\t\t\t\t\t  ((pi->y == pi->ystart && ((try0 << r) % (1 << rpy))) ||\n\t\t\t\t\t  !(pi->y % (pi->picomp->vsamp << rpy)))) {\n\t\t\t\t\t\tprchind = JPC_FLOORDIVPOW2(JPC_CEILDIV(pi->x, pi->picomp->hsamp\n\t\t\t\t\t\t  << r), pi->pirlvl->prcwidthexpn) - JPC_FLOORDIVPOW2(trx0,\n\t\t\t\t\t\t  pi->pirlvl->prcwidthexpn);\n\t\t\t\t\t\tprcvind = JPC_FLOORDIVPOW2(JPC_CEILDIV(pi->y, pi->picomp->vsamp\n\t\t\t\t\t\t  << r), pi->pirlvl->prcheightexpn) - JPC_FLOORDIVPOW2(try0,\n\t\t\t\t\t\t  pi->pirlvl->prcheightexpn);\n\t\t\t\t\t\tpi->prcno = prcvind *\n\t\t\t\t\t\t  pi->pirlvl->numhprcs +\n\t\t\t\t\t\t  prchind;\n\t\t\t\t\t\tassert(pi->prcno <\n\t\t\t\t\t\t  pi->pirlvl->numprcs);\n\t\t\t\t\t\tfor (pi->lyrno = 0; pi->lyrno <\n\t\t\t\t\t\t  pi->numlyrs && pi->lyrno < JAS_CAST(int, pchg->lyrnoend); ++pi->lyrno) {\n\t\t\t\t\t\t\tprclyrno = &pi->pirlvl->prclyrnos[pi->prcno];\n\t\t\t\t\t\t\tif (pi->lyrno >= *prclyrno) {\n\t\t\t\t\t\t\t\t++(*prclyrno);\n\t\t\t\t\t\t\t\treturn 0;\n\t\t\t\t\t\t\t}\nskip:\n\t\t\t\t\t\t\t;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn 1;\n}", "commit_link": "github.com/mdadams/jasper/commit/1f0dfe5a42911b6880a1445f13f6d615ddb55387", "file_name": "src/libjasper/jpc/jpc_t2cod.c", "vul_type": "cwe-190", "description": "Write a C function named `jpc_pi_nextcprl` that iterates over components, resolutions, positions, and layers for JPEG 2000 progression order changes."}
{"func_name": "updateDevice", "func_src_before": "updateDevice(const struct header * headers, time_t t)\n{\n\tstruct device ** pp = &devlist;\n\tstruct device * p = *pp;\t/* = devlist; */\n\twhile(p)\n\t{\n\t\tif(  p->headers[HEADER_NT].l == headers[HEADER_NT].l\n\t\t  && (0==memcmp(p->headers[HEADER_NT].p, headers[HEADER_NT].p, headers[HEADER_NT].l))\n\t\t  && p->headers[HEADER_USN].l == headers[HEADER_USN].l\n\t\t  && (0==memcmp(p->headers[HEADER_USN].p, headers[HEADER_USN].p, headers[HEADER_USN].l)) )\n\t\t{\n\t\t\t/*printf(\"found! %d\\n\", (int)(t - p->t));*/\n\t\t\tsyslog(LOG_DEBUG, \"device updated : %.*s\", headers[HEADER_USN].l, headers[HEADER_USN].p);\n\t\t\tp->t = t;\n\t\t\t/* update Location ! */\n\t\t\tif(headers[HEADER_LOCATION].l > p->headers[HEADER_LOCATION].l)\n\t\t\t{\n\t\t\t\tstruct device * tmp;\n\t\t\t\ttmp = realloc(p, sizeof(struct device)\n\t\t\t\t    + headers[0].l+headers[1].l+headers[2].l);\n\t\t\t\tif(!tmp)\t/* allocation error */\n\t\t\t\t{\n\t\t\t\t\tsyslog(LOG_ERR, \"updateDevice() : memory allocation error\");\n\t\t\t\t\tfree(p);\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\t\tp = tmp;\n\t\t\t\t*pp = p;\n\t\t\t}\n\t\t\tmemcpy(p->data + p->headers[0].l + p->headers[1].l,\n\t\t\t       headers[2].p, headers[2].l);\n\t\t\t/* TODO : check p->headers[HEADER_LOCATION].l */\n\t\t\treturn 0;\n\t\t}\n\t\tpp = &p->next;\n\t\tp = *pp;\t/* p = p->next; */\n\t}\n\tsyslog(LOG_INFO, \"new device discovered : %.*s\",\n\t       headers[HEADER_USN].l, headers[HEADER_USN].p);\n\t/* add */\n\t{\n\t\tchar * pc;\n\t\tint i;\n\t\tp = malloc(  sizeof(struct device)\n\t\t           + headers[0].l+headers[1].l+headers[2].l );\n\t\tif(!p) {\n\t\t\tsyslog(LOG_ERR, \"updateDevice(): cannot allocate memory\");\n\t\t\treturn -1;\n\t\t}\n\t\tp->next = devlist;\n\t\tp->t = t;\n\t\tpc = p->data;\n\t\tfor(i = 0; i < 3; i++)\n\t\t{\n\t\t\tp->headers[i].p = pc;\n\t\t\tp->headers[i].l = headers[i].l;\n\t\t\tmemcpy(pc, headers[i].p, headers[i].l);\n\t\t\tpc += headers[i].l;\n\t\t}\n\t\tdevlist = p;\n\t\tsendNotifications(NOTIF_NEW, p, NULL);\n\t}\n\treturn 1;\n}", "func_src_after": "updateDevice(const struct header * headers, time_t t)\n{\n\tstruct device ** pp = &devlist;\n\tstruct device * p = *pp;\t/* = devlist; */\n\twhile(p)\n\t{\n\t\tif(  p->headers[HEADER_NT].l == headers[HEADER_NT].l\n\t\t  && (0==memcmp(p->headers[HEADER_NT].p, headers[HEADER_NT].p, headers[HEADER_NT].l))\n\t\t  && p->headers[HEADER_USN].l == headers[HEADER_USN].l\n\t\t  && (0==memcmp(p->headers[HEADER_USN].p, headers[HEADER_USN].p, headers[HEADER_USN].l)) )\n\t\t{\n\t\t\t/*printf(\"found! %d\\n\", (int)(t - p->t));*/\n\t\t\tsyslog(LOG_DEBUG, \"device updated : %.*s\", headers[HEADER_USN].l, headers[HEADER_USN].p);\n\t\t\tp->t = t;\n\t\t\t/* update Location ! */\n\t\t\tif(headers[HEADER_LOCATION].l > p->headers[HEADER_LOCATION].l)\n\t\t\t{\n\t\t\t\tstruct device * tmp;\n\t\t\t\ttmp = realloc(p, sizeof(struct device)\n\t\t\t\t    + headers[0].l+headers[1].l+headers[2].l);\n\t\t\t\tif(!tmp)\t/* allocation error */\n\t\t\t\t{\n\t\t\t\t\tsyslog(LOG_ERR, \"updateDevice() : memory allocation error\");\n\t\t\t\t\t*pp = p->next;\t/* remove \"p\" from the list */\n\t\t\t\t\tfree(p);\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\t\tp = tmp;\n\t\t\t\t*pp = p;\n\t\t\t}\n\t\t\tmemcpy(p->data + p->headers[0].l + p->headers[1].l,\n\t\t\t       headers[2].p, headers[2].l);\n\t\t\t/* TODO : check p->headers[HEADER_LOCATION].l */\n\t\t\treturn 0;\n\t\t}\n\t\tpp = &p->next;\n\t\tp = *pp;\t/* p = p->next; */\n\t}\n\tsyslog(LOG_INFO, \"new device discovered : %.*s\",\n\t       headers[HEADER_USN].l, headers[HEADER_USN].p);\n\t/* add */\n\t{\n\t\tchar * pc;\n\t\tint i;\n\t\tp = malloc(  sizeof(struct device)\n\t\t           + headers[0].l+headers[1].l+headers[2].l );\n\t\tif(!p) {\n\t\t\tsyslog(LOG_ERR, \"updateDevice(): cannot allocate memory\");\n\t\t\treturn -1;\n\t\t}\n\t\tp->next = devlist;\n\t\tp->t = t;\n\t\tpc = p->data;\n\t\tfor(i = 0; i < 3; i++)\n\t\t{\n\t\t\tp->headers[i].p = pc;\n\t\t\tp->headers[i].l = headers[i].l;\n\t\t\tmemcpy(pc, headers[i].p, headers[i].l);\n\t\t\tpc += headers[i].l;\n\t\t}\n\t\tdevlist = p;\n\t\tsendNotifications(NOTIF_NEW, p, NULL);\n\t}\n\treturn 1;\n}", "commit_link": "github.com/miniupnp/miniupnp/commit/cd506a67e174a45c6a202eff182a712955ed6d6f", "file_name": "minissdpd/minissdpd.c", "vul_type": "cwe-416", "description": "In C, write a function `updateDevice` to manage a device list by updating an existing device or adding a new one based on provided headers and a timestamp."}
{"func_name": "ares_parse_a_reply", "func_src_before": "int ares_parse_a_reply(const unsigned char *abuf, int alen,\n\t\t       struct hostent **host)\n{\n  unsigned int qdcount, ancount;\n  int status, i, rr_type, rr_class, rr_len, naddrs;\n  long int len;\n  int naliases;\n  const unsigned char *aptr;\n  char *hostname, *rr_name, *rr_data, **aliases;\n  struct in_addr *addrs;\n  struct hostent *hostent;\n\n  /* Set *host to NULL for all failure cases. */\n  *host = NULL;\n\n  /* Give up if abuf doesn't have room for a header. */\n  if (alen < HFIXEDSZ)\n    return ARES_EBADRESP;\n\n  /* Fetch the question and answer count from the header. */\n  qdcount = DNS_HEADER_QDCOUNT(abuf);\n  ancount = DNS_HEADER_ANCOUNT(abuf);\n  if (qdcount != 1)\n    return ARES_EBADRESP;\n\n  /* Expand the name from the question, and skip past the question. */\n  aptr = abuf + HFIXEDSZ;\n  status = ares_expand_name(aptr, abuf, alen, &hostname, &len);\n  if (status != ARES_SUCCESS)\n    return status;\n  if (aptr + len + QFIXEDSZ > abuf + alen)\n    {\n      free(hostname);\n      return ARES_EBADRESP;\n    }\n  aptr += len + QFIXEDSZ;\n\n  /* Allocate addresses and aliases; ancount gives an upper bound for both. */\n  addrs = malloc(ancount * sizeof(struct in_addr));\n  if (!addrs)\n    {\n      free(hostname);\n      return ARES_ENOMEM;\n    }\n  aliases = malloc((ancount + 1) * sizeof(char *));\n  if (!aliases)\n    {\n      free(hostname);\n      free(addrs);\n      return ARES_ENOMEM;\n    }\n  naddrs = 0;\n  naliases = 0;\n\n  /* Examine each answer resource record (RR) in turn. */\n  for (i = 0; i < (int)ancount; i++)\n    {\n      /* Decode the RR up to the data field. */\n      status = ares_expand_name(aptr, abuf, alen, &rr_name, &len);\n      if (status != ARES_SUCCESS)\n\tbreak;\n      aptr += len;\n      if (aptr + RRFIXEDSZ > abuf + alen)\n\t{\n\t  free(rr_name);\n\t  status = ARES_EBADRESP;\n\t  break;\n\t}\n      rr_type = DNS_RR_TYPE(aptr);\n      rr_class = DNS_RR_CLASS(aptr);\n      rr_len = DNS_RR_LEN(aptr);\n      aptr += RRFIXEDSZ;\n\n      if (rr_class == C_IN && rr_type == T_A\n\t  && rr_len == sizeof(struct in_addr)\n\t  && strcasecmp(rr_name, hostname) == 0)\n\t{\n\t  memcpy(&addrs[naddrs], aptr, sizeof(struct in_addr));\n\t  naddrs++;\n\t  status = ARES_SUCCESS;\n\t}\n\n      if (rr_class == C_IN && rr_type == T_CNAME)\n\t{\n\t  /* Record the RR name as an alias. */\n\t  aliases[naliases] = rr_name;\n\t  naliases++;\n\n\t  /* Decode the RR data and replace the hostname with it. */\n\t  status = ares_expand_name(aptr, abuf, alen, &rr_data, &len);\n\t  if (status != ARES_SUCCESS)\n\t    break;\n\t  free(hostname);\n\t  hostname = rr_data;\n\t}\n      else\n\tfree(rr_name);\n\n      aptr += rr_len;\n      if (aptr > abuf + alen)\n\t{\n\t  status = ARES_EBADRESP;\n\t  break;\n\t}\n    }\n\n  if (status == ARES_SUCCESS && naddrs == 0)\n    status = ARES_ENODATA;\n  if (status == ARES_SUCCESS)\n    {\n      /* We got our answer.  Allocate memory to build the host entry. */\n      aliases[naliases] = NULL;\n      hostent = malloc(sizeof(struct hostent));\n      if (hostent)\n\t{\n\t  hostent->h_addr_list = malloc((naddrs + 1) * sizeof(char *));\n\t  if (hostent->h_addr_list)\n\t    {\n\t      /* Fill in the hostent and return successfully. */\n\t      hostent->h_name = hostname;\n\t      hostent->h_aliases = aliases;\n\t      hostent->h_addrtype = AF_INET;\n\t      hostent->h_length = sizeof(struct in_addr);\n\t      for (i = 0; i < naddrs; i++)\n\t\thostent->h_addr_list[i] = (char *) &addrs[i];\n\t      hostent->h_addr_list[naddrs] = NULL;\n\t      *host = hostent;\n\t      return ARES_SUCCESS;\n\t    }\n\t  free(hostent);\n\t}\n      status = ARES_ENOMEM;\n    }\n  for (i = 0; i < naliases; i++)\n    free(aliases[i]);\n  free(aliases);\n  free(addrs);\n  free(hostname);\n  return status;\n}", "func_src_after": "int ares_parse_a_reply(const unsigned char *abuf, int alen,\n\t\t       struct hostent **host)\n{\n  unsigned int qdcount, ancount;\n  int status, i, rr_type, rr_class, rr_len, naddrs;\n  long int len;\n  int naliases;\n  const unsigned char *aptr;\n  char *hostname, *rr_name, *rr_data, **aliases;\n  struct in_addr *addrs;\n  struct hostent *hostent;\n\n  /* Set *host to NULL for all failure cases. */\n  *host = NULL;\n\n  /* Give up if abuf doesn't have room for a header. */\n  if (alen < HFIXEDSZ)\n    return ARES_EBADRESP;\n\n  /* Fetch the question and answer count from the header. */\n  qdcount = DNS_HEADER_QDCOUNT(abuf);\n  ancount = DNS_HEADER_ANCOUNT(abuf);\n  if (qdcount != 1)\n    return ARES_EBADRESP;\n\n  /* Expand the name from the question, and skip past the question. */\n  aptr = abuf + HFIXEDSZ;\n  status = ares_expand_name(aptr, abuf, alen, &hostname, &len);\n  if (status != ARES_SUCCESS)\n    return status;\n  if (aptr + len + QFIXEDSZ > abuf + alen)\n    {\n      free(hostname);\n      return ARES_EBADRESP;\n    }\n  aptr += len + QFIXEDSZ;\n\n  /* Allocate addresses and aliases; ancount gives an upper bound for both. */\n  addrs = malloc(ancount * sizeof(struct in_addr));\n  if (!addrs)\n    {\n      free(hostname);\n      return ARES_ENOMEM;\n    }\n  aliases = malloc((ancount + 1) * sizeof(char *));\n  if (!aliases)\n    {\n      free(hostname);\n      free(addrs);\n      return ARES_ENOMEM;\n    }\n  naddrs = 0;\n  naliases = 0;\n\n  /* Examine each answer resource record (RR) in turn. */\n  for (i = 0; i < (int)ancount; i++)\n    {\n      /* Decode the RR up to the data field. */\n      status = ares_expand_name(aptr, abuf, alen, &rr_name, &len);\n      if (status != ARES_SUCCESS)\n\tbreak;\n      aptr += len;\n      if (aptr + RRFIXEDSZ > abuf + alen)\n\t{\n\t  free(rr_name);\n\t  status = ARES_EBADRESP;\n\t  break;\n\t}\n      rr_type = DNS_RR_TYPE(aptr);\n      rr_class = DNS_RR_CLASS(aptr);\n      rr_len = DNS_RR_LEN(aptr);\n      aptr += RRFIXEDSZ;\n      if (aptr + rr_len > abuf + alen)\n\t{\n\t  free(rr_name);\n\t  status = ARES_EBADRESP;\n\t  break;\n\t}\n\n      if (rr_class == C_IN && rr_type == T_A\n\t  && rr_len == sizeof(struct in_addr)\n\t  && strcasecmp(rr_name, hostname) == 0)\n\t{\n\t  memcpy(&addrs[naddrs], aptr, sizeof(struct in_addr));\n\t  naddrs++;\n\t  status = ARES_SUCCESS;\n\t}\n\n      if (rr_class == C_IN && rr_type == T_CNAME)\n\t{\n\t  /* Record the RR name as an alias. */\n\t  aliases[naliases] = rr_name;\n\t  naliases++;\n\n\t  /* Decode the RR data and replace the hostname with it. */\n\t  status = ares_expand_name(aptr, abuf, alen, &rr_data, &len);\n\t  if (status != ARES_SUCCESS)\n\t    break;\n\t  free(hostname);\n\t  hostname = rr_data;\n\t}\n      else\n\tfree(rr_name);\n\n      aptr += rr_len;\n      if (aptr > abuf + alen)\n\t{\n\t  status = ARES_EBADRESP;\n\t  break;\n\t}\n    }\n\n  if (status == ARES_SUCCESS && naddrs == 0)\n    status = ARES_ENODATA;\n  if (status == ARES_SUCCESS)\n    {\n      /* We got our answer.  Allocate memory to build the host entry. */\n      aliases[naliases] = NULL;\n      hostent = malloc(sizeof(struct hostent));\n      if (hostent)\n\t{\n\t  hostent->h_addr_list = malloc((naddrs + 1) * sizeof(char *));\n\t  if (hostent->h_addr_list)\n\t    {\n\t      /* Fill in the hostent and return successfully. */\n\t      hostent->h_name = hostname;\n\t      hostent->h_aliases = aliases;\n\t      hostent->h_addrtype = AF_INET;\n\t      hostent->h_length = sizeof(struct in_addr);\n\t      for (i = 0; i < naddrs; i++)\n\t\thostent->h_addr_list[i] = (char *) &addrs[i];\n\t      hostent->h_addr_list[naddrs] = NULL;\n\t      *host = hostent;\n\t      return ARES_SUCCESS;\n\t    }\n\t  free(hostent);\n\t}\n      status = ARES_ENOMEM;\n    }\n  for (i = 0; i < naliases; i++)\n    free(aliases[i]);\n  free(aliases);\n  free(addrs);\n  free(hostname);\n  return status;\n}", "commit_link": "github.com/resiprocate/resiprocate/commit/d67a9ca6fd06ca65d23e313bdbad1ef4dd3aa0df", "file_name": "rutil/dns/ares/ares_parse_a_reply.c", "vul_type": "cwe-125", "description": "In C, write a function to parse a DNS response and populate a hostent structure with the results."}
{"func_name": "mpeg4_decode_studio_block", "func_src_before": "static int mpeg4_decode_studio_block(MpegEncContext *s, int32_t block[64], int n)\n{\n    Mpeg4DecContext *ctx = s->avctx->priv_data;\n\n    int cc, dct_dc_size, dct_diff, code, j, idx = 1, group = 0, run = 0,\n        additional_code_len, sign, mismatch;\n    VLC *cur_vlc = &ctx->studio_intra_tab[0];\n    uint8_t *const scantable = s->intra_scantable.permutated;\n    const uint16_t *quant_matrix;\n    uint32_t flc;\n    const int min = -1 *  (1 << (s->avctx->bits_per_raw_sample + 6));\n    const int max =      ((1 << (s->avctx->bits_per_raw_sample + 6)) - 1);\n\n    mismatch = 1;\n\n    memset(block, 0, 64 * sizeof(int32_t));\n\n    if (n < 4) {\n        cc = 0;\n        dct_dc_size = get_vlc2(&s->gb, ctx->studio_luma_dc.table, STUDIO_INTRA_BITS, 2);\n        quant_matrix = s->intra_matrix;\n    } else {\n        cc = (n & 1) + 1;\n        if (ctx->rgb)\n            dct_dc_size = get_vlc2(&s->gb, ctx->studio_luma_dc.table, STUDIO_INTRA_BITS, 2);\n        else\n            dct_dc_size = get_vlc2(&s->gb, ctx->studio_chroma_dc.table, STUDIO_INTRA_BITS, 2);\n        quant_matrix = s->chroma_intra_matrix;\n    }\n\n    if (dct_dc_size < 0) {\n        av_log(s->avctx, AV_LOG_ERROR, \"illegal dct_dc_size vlc\\n\");\n        return AVERROR_INVALIDDATA;\n    } else if (dct_dc_size == 0) {\n        dct_diff = 0;\n    } else {\n        dct_diff = get_xbits(&s->gb, dct_dc_size);\n\n        if (dct_dc_size > 8) {\n            if(!check_marker(s->avctx, &s->gb, \"dct_dc_size > 8\"))\n                return AVERROR_INVALIDDATA;\n        }\n\n    }\n\n    s->last_dc[cc] += dct_diff;\n\n    if (s->mpeg_quant)\n        block[0] = s->last_dc[cc] * (8 >> s->intra_dc_precision);\n    else\n        block[0] = s->last_dc[cc] * (8 >> s->intra_dc_precision) * (8 >> s->dct_precision);\n    /* TODO: support mpeg_quant for AC coefficients */\n\n    block[0] = av_clip(block[0], min, max);\n    mismatch ^= block[0];\n\n    /* AC Coefficients */\n    while (1) {\n        group = get_vlc2(&s->gb, cur_vlc->table, STUDIO_INTRA_BITS, 2);\n\n        if (group < 0) {\n            av_log(s->avctx, AV_LOG_ERROR, \"illegal ac coefficient group vlc\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n\n        additional_code_len = ac_state_tab[group][0];\n        cur_vlc = &ctx->studio_intra_tab[ac_state_tab[group][1]];\n\n        if (group == 0) {\n            /* End of Block */\n            break;\n        } else if (group >= 1 && group <= 6) {\n            /* Zero run length (Table B.47) */\n            run = 1 << additional_code_len;\n            if (additional_code_len)\n                run += get_bits(&s->gb, additional_code_len);\n            idx += run;\n            continue;\n        } else if (group >= 7 && group <= 12) {\n            /* Zero run length and +/-1 level (Table B.48) */\n            code = get_bits(&s->gb, additional_code_len);\n            sign = code & 1;\n            code >>= 1;\n            run = (1 << (additional_code_len - 1)) + code;\n            idx += run;\n            j = scantable[idx++];\n            block[j] = sign ? 1 : -1;\n        } else if (group >= 13 && group <= 20) {\n            /* Level value (Table B.49) */\n            j = scantable[idx++];\n            block[j] = get_xbits(&s->gb, additional_code_len);\n        } else if (group == 21) {\n            /* Escape */\n            j = scantable[idx++];\n            additional_code_len = s->avctx->bits_per_raw_sample + s->dct_precision + 4;\n            flc = get_bits(&s->gb, additional_code_len);\n            if (flc >> (additional_code_len-1))\n                block[j] = -1 * (( flc ^ ((1 << additional_code_len) -1)) + 1);\n            else\n                block[j] = flc;\n        }\n        block[j] = ((8 * 2 * block[j] * quant_matrix[j] * s->qscale) >> s->dct_precision) / 32;\n        block[j] = av_clip(block[j], min, max);\n        mismatch ^= block[j];\n    }\n\n    block[63] ^= mismatch & 1;\n\n    return 0;\n}", "func_src_after": "static int mpeg4_decode_studio_block(MpegEncContext *s, int32_t block[64], int n)\n{\n    Mpeg4DecContext *ctx = s->avctx->priv_data;\n\n    int cc, dct_dc_size, dct_diff, code, j, idx = 1, group = 0, run = 0,\n        additional_code_len, sign, mismatch;\n    VLC *cur_vlc = &ctx->studio_intra_tab[0];\n    uint8_t *const scantable = s->intra_scantable.permutated;\n    const uint16_t *quant_matrix;\n    uint32_t flc;\n    const int min = -1 *  (1 << (s->avctx->bits_per_raw_sample + 6));\n    const int max =      ((1 << (s->avctx->bits_per_raw_sample + 6)) - 1);\n\n    mismatch = 1;\n\n    memset(block, 0, 64 * sizeof(int32_t));\n\n    if (n < 4) {\n        cc = 0;\n        dct_dc_size = get_vlc2(&s->gb, ctx->studio_luma_dc.table, STUDIO_INTRA_BITS, 2);\n        quant_matrix = s->intra_matrix;\n    } else {\n        cc = (n & 1) + 1;\n        if (ctx->rgb)\n            dct_dc_size = get_vlc2(&s->gb, ctx->studio_luma_dc.table, STUDIO_INTRA_BITS, 2);\n        else\n            dct_dc_size = get_vlc2(&s->gb, ctx->studio_chroma_dc.table, STUDIO_INTRA_BITS, 2);\n        quant_matrix = s->chroma_intra_matrix;\n    }\n\n    if (dct_dc_size < 0) {\n        av_log(s->avctx, AV_LOG_ERROR, \"illegal dct_dc_size vlc\\n\");\n        return AVERROR_INVALIDDATA;\n    } else if (dct_dc_size == 0) {\n        dct_diff = 0;\n    } else {\n        dct_diff = get_xbits(&s->gb, dct_dc_size);\n\n        if (dct_dc_size > 8) {\n            if(!check_marker(s->avctx, &s->gb, \"dct_dc_size > 8\"))\n                return AVERROR_INVALIDDATA;\n        }\n\n    }\n\n    s->last_dc[cc] += dct_diff;\n\n    if (s->mpeg_quant)\n        block[0] = s->last_dc[cc] * (8 >> s->intra_dc_precision);\n    else\n        block[0] = s->last_dc[cc] * (8 >> s->intra_dc_precision) * (8 >> s->dct_precision);\n    /* TODO: support mpeg_quant for AC coefficients */\n\n    block[0] = av_clip(block[0], min, max);\n    mismatch ^= block[0];\n\n    /* AC Coefficients */\n    while (1) {\n        group = get_vlc2(&s->gb, cur_vlc->table, STUDIO_INTRA_BITS, 2);\n\n        if (group < 0) {\n            av_log(s->avctx, AV_LOG_ERROR, \"illegal ac coefficient group vlc\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n\n        additional_code_len = ac_state_tab[group][0];\n        cur_vlc = &ctx->studio_intra_tab[ac_state_tab[group][1]];\n\n        if (group == 0) {\n            /* End of Block */\n            break;\n        } else if (group >= 1 && group <= 6) {\n            /* Zero run length (Table B.47) */\n            run = 1 << additional_code_len;\n            if (additional_code_len)\n                run += get_bits(&s->gb, additional_code_len);\n            idx += run;\n            continue;\n        } else if (group >= 7 && group <= 12) {\n            /* Zero run length and +/-1 level (Table B.48) */\n            code = get_bits(&s->gb, additional_code_len);\n            sign = code & 1;\n            code >>= 1;\n            run = (1 << (additional_code_len - 1)) + code;\n            idx += run;\n            if (idx > 63)\n                return AVERROR_INVALIDDATA;\n            j = scantable[idx++];\n            block[j] = sign ? 1 : -1;\n        } else if (group >= 13 && group <= 20) {\n            /* Level value (Table B.49) */\n            if (idx > 63)\n                return AVERROR_INVALIDDATA;\n            j = scantable[idx++];\n            block[j] = get_xbits(&s->gb, additional_code_len);\n        } else if (group == 21) {\n            /* Escape */\n            if (idx > 63)\n                return AVERROR_INVALIDDATA;\n            j = scantable[idx++];\n            additional_code_len = s->avctx->bits_per_raw_sample + s->dct_precision + 4;\n            flc = get_bits(&s->gb, additional_code_len);\n            if (flc >> (additional_code_len-1))\n                block[j] = -1 * (( flc ^ ((1 << additional_code_len) -1)) + 1);\n            else\n                block[j] = flc;\n        }\n        block[j] = ((8 * 2 * block[j] * quant_matrix[j] * s->qscale) >> s->dct_precision) / 32;\n        block[j] = av_clip(block[j], min, max);\n        mismatch ^= block[j];\n    }\n\n    block[63] ^= mismatch & 1;\n\n    return 0;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/d227ed5d598340e719eff7156b1aa0a4469e9a6a", "file_name": "libavcodec/mpeg4videodec.c", "vul_type": "cwe-125", "description": "Write a C function named `mpeg4_decode_studio_block` that decodes a single block of MPEG4 studio profile video."}
{"func_name": "xdp_umem_reg", "func_src_before": "static int xdp_umem_reg(struct xdp_umem *umem, struct xdp_umem_reg *mr)\n{\n\tbool unaligned_chunks = mr->flags & XDP_UMEM_UNALIGNED_CHUNK_FLAG;\n\tu32 chunk_size = mr->chunk_size, headroom = mr->headroom;\n\tunsigned int chunks, chunks_per_page;\n\tu64 addr = mr->addr, size = mr->len;\n\tint size_chk, err;\n\n\tif (chunk_size < XDP_UMEM_MIN_CHUNK_SIZE || chunk_size > PAGE_SIZE) {\n\t\t/* Strictly speaking we could support this, if:\n\t\t * - huge pages, or*\n\t\t * - using an IOMMU, or\n\t\t * - making sure the memory area is consecutive\n\t\t * but for now, we simply say \"computer says no\".\n\t\t */\n\t\treturn -EINVAL;\n\t}\n\n\tif (mr->flags & ~(XDP_UMEM_UNALIGNED_CHUNK_FLAG |\n\t\t\tXDP_UMEM_USES_NEED_WAKEUP))\n\t\treturn -EINVAL;\n\n\tif (!unaligned_chunks && !is_power_of_2(chunk_size))\n\t\treturn -EINVAL;\n\n\tif (!PAGE_ALIGNED(addr)) {\n\t\t/* Memory area has to be page size aligned. For\n\t\t * simplicity, this might change.\n\t\t */\n\t\treturn -EINVAL;\n\t}\n\n\tif ((addr + size) < addr)\n\t\treturn -EINVAL;\n\n\tchunks = (unsigned int)div_u64(size, chunk_size);\n\tif (chunks == 0)\n\t\treturn -EINVAL;\n\n\tif (!unaligned_chunks) {\n\t\tchunks_per_page = PAGE_SIZE / chunk_size;\n\t\tif (chunks < chunks_per_page || chunks % chunks_per_page)\n\t\t\treturn -EINVAL;\n\t}\n\n\tsize_chk = chunk_size - headroom - XDP_PACKET_HEADROOM;\n\tif (size_chk < 0)\n\t\treturn -EINVAL;\n\n\tumem->address = (unsigned long)addr;\n\tumem->chunk_mask = unaligned_chunks ? XSK_UNALIGNED_BUF_ADDR_MASK\n\t\t\t\t\t    : ~((u64)chunk_size - 1);\n\tumem->size = size;\n\tumem->headroom = headroom;\n\tumem->chunk_size_nohr = chunk_size - headroom;\n\tumem->npgs = size / PAGE_SIZE;\n\tumem->pgs = NULL;\n\tumem->user = NULL;\n\tumem->flags = mr->flags;\n\tINIT_LIST_HEAD(&umem->xsk_list);\n\tspin_lock_init(&umem->xsk_list_lock);\n\n\trefcount_set(&umem->users, 1);\n\n\terr = xdp_umem_account_pages(umem);\n\tif (err)\n\t\treturn err;\n\n\terr = xdp_umem_pin_pages(umem);\n\tif (err)\n\t\tgoto out_account;\n\n\tumem->pages = kvcalloc(umem->npgs, sizeof(*umem->pages),\n\t\t\t       GFP_KERNEL_ACCOUNT);\n\tif (!umem->pages) {\n\t\terr = -ENOMEM;\n\t\tgoto out_pin;\n\t}\n\n\terr = xdp_umem_map_pages(umem);\n\tif (!err)\n\t\treturn 0;\n\n\tkvfree(umem->pages);\n\nout_pin:\n\txdp_umem_unpin_pages(umem);\nout_account:\n\txdp_umem_unaccount_pages(umem);\n\treturn err;\n}", "func_src_after": "static int xdp_umem_reg(struct xdp_umem *umem, struct xdp_umem_reg *mr)\n{\n\tbool unaligned_chunks = mr->flags & XDP_UMEM_UNALIGNED_CHUNK_FLAG;\n\tu32 chunk_size = mr->chunk_size, headroom = mr->headroom;\n\tunsigned int chunks, chunks_per_page;\n\tu64 addr = mr->addr, size = mr->len;\n\tint err;\n\n\tif (chunk_size < XDP_UMEM_MIN_CHUNK_SIZE || chunk_size > PAGE_SIZE) {\n\t\t/* Strictly speaking we could support this, if:\n\t\t * - huge pages, or*\n\t\t * - using an IOMMU, or\n\t\t * - making sure the memory area is consecutive\n\t\t * but for now, we simply say \"computer says no\".\n\t\t */\n\t\treturn -EINVAL;\n\t}\n\n\tif (mr->flags & ~(XDP_UMEM_UNALIGNED_CHUNK_FLAG |\n\t\t\tXDP_UMEM_USES_NEED_WAKEUP))\n\t\treturn -EINVAL;\n\n\tif (!unaligned_chunks && !is_power_of_2(chunk_size))\n\t\treturn -EINVAL;\n\n\tif (!PAGE_ALIGNED(addr)) {\n\t\t/* Memory area has to be page size aligned. For\n\t\t * simplicity, this might change.\n\t\t */\n\t\treturn -EINVAL;\n\t}\n\n\tif ((addr + size) < addr)\n\t\treturn -EINVAL;\n\n\tchunks = (unsigned int)div_u64(size, chunk_size);\n\tif (chunks == 0)\n\t\treturn -EINVAL;\n\n\tif (!unaligned_chunks) {\n\t\tchunks_per_page = PAGE_SIZE / chunk_size;\n\t\tif (chunks < chunks_per_page || chunks % chunks_per_page)\n\t\t\treturn -EINVAL;\n\t}\n\n\tif (headroom >= chunk_size - XDP_PACKET_HEADROOM)\n\t\treturn -EINVAL;\n\n\tumem->address = (unsigned long)addr;\n\tumem->chunk_mask = unaligned_chunks ? XSK_UNALIGNED_BUF_ADDR_MASK\n\t\t\t\t\t    : ~((u64)chunk_size - 1);\n\tumem->size = size;\n\tumem->headroom = headroom;\n\tumem->chunk_size_nohr = chunk_size - headroom;\n\tumem->npgs = size / PAGE_SIZE;\n\tumem->pgs = NULL;\n\tumem->user = NULL;\n\tumem->flags = mr->flags;\n\tINIT_LIST_HEAD(&umem->xsk_list);\n\tspin_lock_init(&umem->xsk_list_lock);\n\n\trefcount_set(&umem->users, 1);\n\n\terr = xdp_umem_account_pages(umem);\n\tif (err)\n\t\treturn err;\n\n\terr = xdp_umem_pin_pages(umem);\n\tif (err)\n\t\tgoto out_account;\n\n\tumem->pages = kvcalloc(umem->npgs, sizeof(*umem->pages),\n\t\t\t       GFP_KERNEL_ACCOUNT);\n\tif (!umem->pages) {\n\t\terr = -ENOMEM;\n\t\tgoto out_pin;\n\t}\n\n\terr = xdp_umem_map_pages(umem);\n\tif (!err)\n\t\treturn 0;\n\n\tkvfree(umem->pages);\n\nout_pin:\n\txdp_umem_unpin_pages(umem);\nout_account:\n\txdp_umem_unaccount_pages(umem);\n\treturn err;\n}", "commit_link": "github.com/torvalds/linux/commit/99e3a236dd43d06c65af0a2ef9cb44306aef6e02", "file_name": "net/xdp/xdp_umem.c", "vul_type": "cwe-787", "description": "Write a C function named `xdp_umem_reg` that registers a user memory (`umem`) area for use with XDP sockets, validating the provided memory region parameters."}
{"func_name": "handle_file", "func_src_before": "def handle_file(u: Profile, headline: str, category: str, text: str, file):\n    m: Media = Media()\n    upload_base_path: str = 'uploads/' + str(date.today().year)\n    high_res_file_name = upload_base_path + '/HIGHRES_' + ntpath.basename(file.name.replace(\" \", \"_\"))\n    low_res_file_name = upload_base_path + '/LOWRES_' + ntpath.basename(file.name.replace(\" \", \"_\"))\n    if not os.path.exists(PATH_TO_UPLOAD_FOLDER_ON_DISK + upload_base_path):\n        os.makedirs(PATH_TO_UPLOAD_FOLDER_ON_DISK + upload_base_path)\n    with open(high_res_file_name, 'wb+') as destination:\n        for chunk in file.chunks():\n            destination.write(chunk)\n    # TODO crop image\n    original = Image.open(high_res_file_name)\n    width, height = original.size\n    diameter = math.sqrt(math.pow(width, 2) + math.pow(height, 2))\n    width /= diameter\n    height /= diameter\n    width *= IMAGE_SCALE\n    height *= IMAGE_SCALE\n    cropped = original.resize((int(width), int(height)), PIL.Image.LANCZOS)\n    cropped.save(low_res_file_name)\n    m.text = text\n    m.cachedText = compile_markdown(text)\n    m.category = category\n    m.highResFile = \"/\" + high_res_file_name\n    m.lowResFile = \"/\" + low_res_file_name\n    m.headline = headline\n    m.save()\n    mu: MediaUpload = MediaUpload()\n    mu.UID = u\n    mu.MID = m\n    mu.save()\n    logging.info(\"Uploaded file '\" + str(file.name) + \"' and cropped it. The resulting PK is \" + str(m.pk))", "func_src_after": "def handle_file(u: Profile, headline: str, category: str, text: str, file):\n    m: Media = Media()\n    upload_base_path: str = 'uploads/' + str(date.today().year)\n    high_res_file_name = upload_base_path + '/HIGHRES_' + ntpath.basename(file.name.replace(\" \", \"_\"))\n    low_res_file_name = upload_base_path + '/LOWRES_' + ntpath.basename(file.name.replace(\" \", \"_\"))\n    if not os.path.exists(PATH_TO_UPLOAD_FOLDER_ON_DISK + upload_base_path):\n        os.makedirs(PATH_TO_UPLOAD_FOLDER_ON_DISK + upload_base_path)\n    with open(high_res_file_name, 'wb+') as destination:\n        for chunk in file.chunks():\n            destination.write(chunk)\n    # TODO crop image\n    original = Image.open(high_res_file_name)\n    width, height = original.size\n    diameter = math.sqrt(math.pow(width, 2) + math.pow(height, 2))\n    width /= diameter\n    height /= diameter\n    width *= IMAGE_SCALE\n    height *= IMAGE_SCALE\n    cropped = original.resize((int(width), int(height)), PIL.Image.LANCZOS)\n    cropped.save(low_res_file_name)\n    m.text = escape(text)\n    m.cachedText = compile_markdown(escape(text))\n    m.category = escape(category)\n    m.highResFile = \"/\" + high_res_file_name\n    m.lowResFile = \"/\" + low_res_file_name\n    m.headline = escape(headline)\n    m.save()\n    mu: MediaUpload = MediaUpload()\n    mu.UID = u\n    mu.MID = m\n    mu.save()\n    logging.info(\"Uploaded file '\" + str(file.name) + \"' and cropped it. The resulting PK is \" + str(m.pk))", "commit_link": "github.com/Technikradio/C3FOCSite/commit/6e330d4d44bbfdfce9993dffea97008276771600", "file_name": "c3shop/frontpage/management/mediatools/media_actions.py", "vul_type": "cwe-079", "description": "Write a Python function to handle media file uploads, including image resizing and metadata processing."}
{"func_name": "luaD_shrinkstack", "func_src_before": "void luaD_shrinkstack (lua_State *L) {\n  int inuse = stackinuse(L);\n  int goodsize = inuse + (inuse / 8) + 2*EXTRA_STACK;\n  if (goodsize > LUAI_MAXSTACK)\n    goodsize = LUAI_MAXSTACK;  /* respect stack limit */\n  /* if thread is currently not handling a stack overflow and its\n     good size is smaller than current size, shrink its stack */\n  if (inuse <= (LUAI_MAXSTACK - EXTRA_STACK) &&\n      goodsize < L->stacksize)\n    luaD_reallocstack(L, goodsize, 0);  /* ok if that fails */\n  else  /* don't change stack */\n    condmovestack(L,{},{});  /* (change only for debugging) */\n  luaE_shrinkCI(L);  /* shrink CI list */\n}", "func_src_after": "void luaD_shrinkstack (lua_State *L) {\n  int inuse = stackinuse(L);\n  int goodsize = inuse + BASIC_STACK_SIZE;\n  if (goodsize > LUAI_MAXSTACK)\n    goodsize = LUAI_MAXSTACK;  /* respect stack limit */\n  /* if thread is currently not handling a stack overflow and its\n     good size is smaller than current size, shrink its stack */\n  if (inuse <= (LUAI_MAXSTACK - EXTRA_STACK) && goodsize < L->stacksize)\n    luaD_reallocstack(L, goodsize, 0);  /* ok if that fails */\n  else  /* don't change stack */\n    condmovestack(L,{},{});  /* (change only for debugging) */\n  luaE_shrinkCI(L);  /* shrink CI list */\n}", "commit_link": "github.com/lua/lua/commit/6298903e35217ab69c279056f925fb72900ce0b7", "file_name": "ldo.c", "vul_type": "cwe-416", "description": "Write a C function named `luaD_shrinkstack` for Lua that adjusts the stack size based on current usage and predefined limits."}
{"func_name": "_delete_host", "func_src_before": "    def _delete_host(self, host_name):\n        \"\"\"Delete a host on the storage system.\"\"\"\n\n        LOG.debug(_('enter: _delete_host: host %s ') % host_name)\n\n        ssh_cmd = 'svctask rmhost %s ' % host_name\n        out, err = self._run_ssh(ssh_cmd)\n        # No output should be returned from rmhost\n        self._assert_ssh_return(len(out.strip()) == 0,\n                                '_delete_host', ssh_cmd, out, err)\n\n        LOG.debug(_('leave: _delete_host: host %s ') % host_name)", "func_src_after": "    def _delete_host(self, host_name):\n        \"\"\"Delete a host on the storage system.\"\"\"\n\n        LOG.debug(_('enter: _delete_host: host %s ') % host_name)\n\n        ssh_cmd = ['svctask', 'rmhost', host_name]\n        out, err = self._run_ssh(ssh_cmd)\n        # No output should be returned from rmhost\n        self._assert_ssh_return(len(out.strip()) == 0,\n                                '_delete_host', ssh_cmd, out, err)\n\n        LOG.debug(_('leave: _delete_host: host %s ') % host_name)", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to delete a host from a storage system using SSH commands, with debug logging before and after the operation."}
{"func_name": "input_csi_dispatch_sgr_colon", "func_src_before": "input_csi_dispatch_sgr_colon(struct input_ctx *ictx, u_int i)\n{\n\tstruct grid_cell\t*gc = &ictx->cell.cell;\n\tchar\t\t\t*s = ictx->param_list[i].str, *copy, *ptr, *out;\n\tint\t\t\t p[8];\n\tu_int\t\t\t n;\n\tconst char\t\t*errstr;\n\n\tfor (n = 0; n < nitems(p); n++)\n\t\tp[n] = -1;\n\tn = 0;\n\n\tptr = copy = xstrdup(s);\n\twhile ((out = strsep(&ptr, \":\")) != NULL) {\n\t\tif (*out != '\\0') {\n\t\t\tp[n++] = strtonum(out, 0, INT_MAX, &errstr);\n\t\t\tif (errstr != NULL || n == nitems(p)) {\n\t\t\t\tfree(copy);\n\t\t\t\treturn;\n\t\t\t}\n\t\t} else\n\t\t\tn++;\n\t\tlog_debug(\"%s: %u = %d\", __func__, n - 1, p[n - 1]);\n\t}\n\tfree(copy);\n\n\tif (n == 0)\n\t\treturn;\n\tif (p[0] == 4) {\n\t\tif (n != 2)\n\t\t\treturn;\n\t\tswitch (p[1]) {\n\t\tcase 0:\n\t\t\tgc->attr &= ~GRID_ATTR_ALL_UNDERSCORE;\n\t\t\tbreak;\n\t\tcase 1:\n\t\t\tgc->attr &= ~GRID_ATTR_ALL_UNDERSCORE;\n\t\t\tgc->attr |= GRID_ATTR_UNDERSCORE;\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\tgc->attr &= ~GRID_ATTR_ALL_UNDERSCORE;\n\t\t\tgc->attr |= GRID_ATTR_UNDERSCORE_2;\n\t\t\tbreak;\n\t\tcase 3:\n\t\t\tgc->attr &= ~GRID_ATTR_ALL_UNDERSCORE;\n\t\t\tgc->attr |= GRID_ATTR_UNDERSCORE_3;\n\t\t\tbreak;\n\t\tcase 4:\n\t\t\tgc->attr &= ~GRID_ATTR_ALL_UNDERSCORE;\n\t\t\tgc->attr |= GRID_ATTR_UNDERSCORE_4;\n\t\t\tbreak;\n\t\tcase 5:\n\t\t\tgc->attr &= ~GRID_ATTR_ALL_UNDERSCORE;\n\t\t\tgc->attr |= GRID_ATTR_UNDERSCORE_5;\n\t\t\tbreak;\n\t\t}\n\t\treturn;\n\t}\n\tif (n < 2 || (p[0] != 38 && p[0] != 48 && p[0] != 58))\n\t\treturn;\n\tswitch (p[1]) {\n\tcase 2:\n\t\tif (n < 3)\n\t\t\tbreak;\n\t\tif (n == 5)\n\t\t\ti = 2;\n\t\telse\n\t\t\ti = 3;\n\t\tif (n < i + 3)\n\t\t\tbreak;\n\t\tinput_csi_dispatch_sgr_rgb_do(ictx, p[0], p[i], p[i + 1],\n\t\t    p[i + 2]);\n\t\tbreak;\n\tcase 5:\n\t\tif (n < 3)\n\t\t\tbreak;\n\t\tinput_csi_dispatch_sgr_256_do(ictx, p[0], p[2]);\n\t\tbreak;\n\t}\n}", "func_src_after": "input_csi_dispatch_sgr_colon(struct input_ctx *ictx, u_int i)\n{\n\tstruct grid_cell\t*gc = &ictx->cell.cell;\n\tchar\t\t\t*s = ictx->param_list[i].str, *copy, *ptr, *out;\n\tint\t\t\t p[8];\n\tu_int\t\t\t n;\n\tconst char\t\t*errstr;\n\n\tfor (n = 0; n < nitems(p); n++)\n\t\tp[n] = -1;\n\tn = 0;\n\n\tptr = copy = xstrdup(s);\n\twhile ((out = strsep(&ptr, \":\")) != NULL) {\n\t\tif (*out != '\\0') {\n\t\t\tp[n++] = strtonum(out, 0, INT_MAX, &errstr);\n\t\t\tif (errstr != NULL || n == nitems(p)) {\n\t\t\t\tfree(copy);\n\t\t\t\treturn;\n\t\t\t}\n\t\t} else {\n\t\t\tn++;\n\t\t\tif (n == nitems(p)) {\n\t\t\t\tfree(copy);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t\tlog_debug(\"%s: %u = %d\", __func__, n - 1, p[n - 1]);\n\t}\n\tfree(copy);\n\n\tif (n == 0)\n\t\treturn;\n\tif (p[0] == 4) {\n\t\tif (n != 2)\n\t\t\treturn;\n\t\tswitch (p[1]) {\n\t\tcase 0:\n\t\t\tgc->attr &= ~GRID_ATTR_ALL_UNDERSCORE;\n\t\t\tbreak;\n\t\tcase 1:\n\t\t\tgc->attr &= ~GRID_ATTR_ALL_UNDERSCORE;\n\t\t\tgc->attr |= GRID_ATTR_UNDERSCORE;\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\tgc->attr &= ~GRID_ATTR_ALL_UNDERSCORE;\n\t\t\tgc->attr |= GRID_ATTR_UNDERSCORE_2;\n\t\t\tbreak;\n\t\tcase 3:\n\t\t\tgc->attr &= ~GRID_ATTR_ALL_UNDERSCORE;\n\t\t\tgc->attr |= GRID_ATTR_UNDERSCORE_3;\n\t\t\tbreak;\n\t\tcase 4:\n\t\t\tgc->attr &= ~GRID_ATTR_ALL_UNDERSCORE;\n\t\t\tgc->attr |= GRID_ATTR_UNDERSCORE_4;\n\t\t\tbreak;\n\t\tcase 5:\n\t\t\tgc->attr &= ~GRID_ATTR_ALL_UNDERSCORE;\n\t\t\tgc->attr |= GRID_ATTR_UNDERSCORE_5;\n\t\t\tbreak;\n\t\t}\n\t\treturn;\n\t}\n\tif (n < 2 || (p[0] != 38 && p[0] != 48 && p[0] != 58))\n\t\treturn;\n\tswitch (p[1]) {\n\tcase 2:\n\t\tif (n < 3)\n\t\t\tbreak;\n\t\tif (n == 5)\n\t\t\ti = 2;\n\t\telse\n\t\t\ti = 3;\n\t\tif (n < i + 3)\n\t\t\tbreak;\n\t\tinput_csi_dispatch_sgr_rgb_do(ictx, p[0], p[i], p[i + 1],\n\t\t    p[i + 2]);\n\t\tbreak;\n\tcase 5:\n\t\tif (n < 3)\n\t\t\tbreak;\n\t\tinput_csi_dispatch_sgr_256_do(ictx, p[0], p[2]);\n\t\tbreak;\n\t}\n}", "commit_link": "github.com/tmux/tmux/commit/a868bacb46e3c900530bed47a1c6f85b0fbe701c", "file_name": "input.c", "vul_type": "cwe-787", "description": "Write a C function to parse colon-separated SGR (Select Graphic Rendition) parameters and update text attributes accordingly."}
{"func_name": "landingPage", "func_src_before": "func landingPage(w http.ResponseWriter, r *http.Request) {\n\tctx := r.Context()\n\n\tidStr := r.URL.Path[1:]\n\n\t// When we don't have an idStr or it contains any path elements, we would\n\t// serve the landing page\n\tif len(idStr) < 1 || strings.Contains(idStr, \"/\") ||\n\t\tstrings.HasSuffix(idStr, \"index.html\") {\n\t\tdcCh := config.MustGetAsync(ctx)\n\t\tpsCh := preloadedState(ctx)\n\n\t\tnodeEnv := \"production\"\n\n\t\tif webapp.IsDev {\n\t\t\tnodeEnv = \"development\"\n\t\t}\n\n\t\tinitData := fmt.Sprintf(initDataTemplate, <-psCh, nodeEnv)\n\n\t\ttmpl := webapp.GetTemplate(\"index.html\", webapp.IsDev)\n\t\ttmpl.Execute(w, map[string]interface{}{\n\t\t\t\"Config\":    <-dcCh,\n\t\t\t\"BuildInfo\": config.B,\n\t\t\t\"InitData\":  template.HTML(initData),\n\t\t})\n\t\treturn\n\t}\n\n\tid := base62.Decode(idStr)\n\n\tshortURL, err := shorturl.ByID(ctx, id)\n\tif err == datastore.ErrNoSuchEntity {\n\t\tlog.Printf(\"Unable to load short url %s. Decoded key: %d\",\n\t\t\tidStr, id)\n\t\thttp.Error(w, fmt.Sprintf(\"Short URL %s cannot be found !!11one\",\n\t\t\tidStr), http.StatusNotFound)\n\t\treturn\n\t} else if err != nil {\n\t\tlog.Printf(\"Error loading short URL '%s': %s\", idStr,\n\t\t\terr.Error())\n\t\thttp.Error(w, \"Internal Server Error\",\n\t\t\thttp.StatusInternalServerError)\n\t\treturn\n\t}\n\n\thttp.Redirect(w, r, shortURL.OriginalURL, http.StatusMovedPermanently)\n}", "func_src_after": "func landingPage(w http.ResponseWriter, r *http.Request) {\n\tctx := r.Context()\n\n\tidStr := r.URL.Path[1:]\n\n\t// When we don't have an idStr or it contains any path elements, we would\n\t// serve the landing page\n\tif len(idStr) < 1 || strings.Contains(idStr, \"/\") ||\n\t\tstrings.HasSuffix(idStr, \"index.html\") {\n\t\tdcCh := config.MustGetAsync(ctx)\n\t\tpsCh := preloadedState(ctx)\n\n\t\tnodeEnv := \"production\"\n\n\t\tif webapp.IsDev {\n\t\t\tnodeEnv = \"development\"\n\t\t}\n\n\t\tinitData := fmt.Sprintf(initDataTemplate, <-psCh, nodeEnv)\n\n\t\ttmpl := webapp.GetTemplate(\"index.html\", webapp.IsDev)\n\t\ttmpl.Execute(w, map[string]interface{}{\n\t\t\t\"Config\":    <-dcCh,\n\t\t\t\"BuildInfo\": config.B,\n\t\t\t\"InitData\":  template.HTML(initData),\n\t\t})\n\t\treturn\n\t}\n\n\tid := base62.Decode(idStr)\n\n\tidStr = html.EscapeString(idStr)\n\n\tshortURL, err := shorturl.ByID(ctx, id)\n\tif err == datastore.ErrNoSuchEntity {\n\t\tlog.Printf(\"Unable to load short url %s. Decoded key: %d\",\n\t\t\tidStr, id)\n\t\thttp.Error(w, fmt.Sprintf(\"Short URL %s cannot be found !!11one\",\n\t\t\tidStr), http.StatusNotFound)\n\t\treturn\n\t} else if err != nil {\n\t\tlog.Printf(\"Error loading short URL '%s': %s\", idStr,\n\t\t\terr.Error())\n\t\thttp.Error(w, \"Internal Server Error\",\n\t\t\thttp.StatusInternalServerError)\n\t\treturn\n\t}\n\n\thttp.Redirect(w, r, shortURL.OriginalURL, http.StatusMovedPermanently)\n}", "line_changes": {"deleted": [], "added": [{"line_no": 32, "char_start": 749, "char_end": 783, "line": "\tidStr = html.EscapeString(idStr)\n"}, {"line_no": 33, "char_start": 783, "char_end": 784, "line": "\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 749, "char_end": 784, "chars": "\tidStr = html.EscapeString(idStr)\n\n"}]}, "commit_link": "github.com/qqiao/yordle/commit/6f9f25af52fd05b77db575191b6775a4f7f1bb26", "file_name": "yordle.go", "vul_type": "cwe-079", "commit_msg": "HTML Escapes idStr to prevent xss (#69)", "parent_commit": "366d98e5fdad503cafa95c6310a133078203fdfb", "description": "Write a Go function that serves a landing page or redirects to an original URL based on a path-encoded identifier."}
{"func_name": "also_add", "func_src_before": "def also_add(name, also):\n    db = db_connect()\n    cursor = db.cursor()\n    try:\n        cursor.execute('''\n            INSERT INTO isalso(name,also) VALUES('{}','{}')\n            '''.format(name, also))\n        db.commit()\n        logger.debug('added to isalso name {} with value {}'.format(\n            name, also))\n        db.close()\n    except Exception as e:\n        logger.error('Execution failed with error: {}'.format(e))\n        raise", "func_src_after": "def also_add(name, also):\n    db = db_connect()\n    cursor = db.cursor()\n    try:\n        cursor.execute('''\n            INSERT INTO isalso(name,also) VALUES(%(name)s,%(also)s)\n            ''', (\n            name,\n            also,\n        ))\n        db.commit()\n        logger.debug('added to isalso name {} with value {}'.format(\n            name, also))\n        db.close()\n    except Exception as e:\n        logger.error('Execution failed with error: {}'.format(e))\n        raise", "commit_link": "github.com/tylarb/KarmaBoi-PCF/commit/c1d00a27d7f6b7eb6f15a3dacd4269654a32c10a", "file_name": "KarmaBoi/dbopts.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a name and an associated value into an 'isalso' database table and log the action."}
{"func_name": "xsltKeyFunction", "func_src_before": "xsltKeyFunction(xmlXPathParserContextPtr ctxt, int nargs){\n    xmlXPathObjectPtr obj1, obj2;\n\n    if (nargs != 2) {\n\txsltTransformError(xsltXPathGetTransformContext(ctxt), NULL, NULL,\n\t\t\"key() : expects two arguments\\n\");\n\tctxt->error = XPATH_INVALID_ARITY;\n\treturn;\n    }\n\n    /*\n    * Get the key's value.\n    */\n    obj2 = valuePop(ctxt);\n    xmlXPathStringFunction(ctxt, 1);\n    if ((obj2 == NULL) ||\n\t(ctxt->value == NULL) || (ctxt->value->type != XPATH_STRING)) {\n\txsltTransformError(xsltXPathGetTransformContext(ctxt), NULL, NULL,\n\t    \"key() : invalid arg expecting a string\\n\");\n\tctxt->error = XPATH_INVALID_TYPE;\n\txmlXPathFreeObject(obj2);\n\n\treturn;\n    }\n    /*\n    * Get the key's name.\n    */\n    obj1 = valuePop(ctxt);\n\n    if ((obj2->type == XPATH_NODESET) || (obj2->type == XPATH_XSLT_TREE)) {\n\tint i;\n\txmlXPathObjectPtr newobj, ret;\n\n\tret = xmlXPathNewNodeSet(NULL);\n\n\tif (obj2->nodesetval != NULL) {\n\t    for (i = 0; i < obj2->nodesetval->nodeNr; i++) {\n\t\tvaluePush(ctxt, xmlXPathObjectCopy(obj1));\n\t\tvaluePush(ctxt,\n\t\t\t  xmlXPathNewNodeSet(obj2->nodesetval->nodeTab[i]));\n\t\txmlXPathStringFunction(ctxt, 1);\n\t\txsltKeyFunction(ctxt, 2);\n\t\tnewobj = valuePop(ctxt);\n                if (newobj != NULL)\n\t\t    ret->nodesetval = xmlXPathNodeSetMerge(ret->nodesetval,\n\t\t\t\t\t\t           newobj->nodesetval);\n\t\txmlXPathFreeObject(newobj);\n\t    }\n\t}\n\tvaluePush(ctxt, ret);\n    } else {\n\txmlNodeSetPtr nodelist = NULL;\n\txmlChar *key = NULL, *value;\n\tconst xmlChar *keyURI;\n\txsltTransformContextPtr tctxt;\n\txmlChar *qname, *prefix;\n\txmlXPathContextPtr xpctxt = ctxt->context;\n\txmlNodePtr tmpNode = NULL;\n\txsltDocumentPtr oldDocInfo;\n\n\ttctxt = xsltXPathGetTransformContext(ctxt);\n\n\toldDocInfo = tctxt->document;\n\n\tif (xpctxt->node == NULL) {\n\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\"Internal error in xsltKeyFunction(): \"\n\t\t\"The context node is not set on the XPath context.\\n\");\n\t    tctxt->state = XSLT_STATE_STOPPED;\n\t    goto error;\n\t}\n\t/*\n\t * Get the associated namespace URI if qualified name\n\t */\n\tqname = obj1->stringval;\n\tkey = xmlSplitQName2(qname, &prefix);\n\tif (key == NULL) {\n\t    key = xmlStrdup(obj1->stringval);\n\t    keyURI = NULL;\n\t    if (prefix != NULL)\n\t\txmlFree(prefix);\n\t} else {\n\t    if (prefix != NULL) {\n\t\tkeyURI = xmlXPathNsLookup(xpctxt, prefix);\n\t\tif (keyURI == NULL) {\n\t\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\t\"key() : prefix %s is not bound\\n\", prefix);\n\t\t    /*\n\t\t    * TODO: Shouldn't we stop here?\n\t\t    */\n\t\t}\n\t\txmlFree(prefix);\n\t    } else {\n\t\tkeyURI = NULL;\n\t    }\n\t}\n\n\t/*\n\t * Force conversion of first arg to string\n\t */\n\tvaluePush(ctxt, obj2);\n\txmlXPathStringFunction(ctxt, 1);\n\tobj2 = valuePop(ctxt);\n\tif ((obj2 == NULL) || (obj2->type != XPATH_STRING)) {\n\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\"key() : invalid arg expecting a string\\n\");\n\t    ctxt->error = XPATH_INVALID_TYPE;\n\t    goto error;\n\t}\n\tvalue = obj2->stringval;\n\n\t/*\n\t* We need to ensure that ctxt->document is available for\n\t* xsltGetKey().\n\t* First find the relevant doc, which is the context node's\n\t* owner doc; using context->doc is not safe, since\n\t* the doc could have been acquired via the document() function,\n\t* or the doc might be a Result Tree Fragment.\n\t* FUTURE INFO: In XSLT 2.0 the key() function takes an additional\n\t* argument indicating the doc to use.\n\t*/\n\tif (xpctxt->node->type == XML_NAMESPACE_DECL) {\n\t    /*\n\t    * REVISIT: This is a libxml hack! Check xpath.c for details.\n\t    * The XPath module sets the owner element of a ns-node on\n\t    * the ns->next field.\n\t    */\n\t    if ((((xmlNsPtr) xpctxt->node)->next != NULL) &&\n\t\t(((xmlNsPtr) xpctxt->node)->next->type == XML_ELEMENT_NODE))\n\t    {\n\t\ttmpNode = (xmlNodePtr) ((xmlNsPtr) xpctxt->node)->next;\n\t    }\n\t} else\n\t    tmpNode = xpctxt->node;\n\n\tif ((tmpNode == NULL) || (tmpNode->doc == NULL)) {\n\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\"Internal error in xsltKeyFunction(): \"\n\t\t\"Couldn't get the doc of the XPath context node.\\n\");\n\t    goto error;\n\t}\n\n\tif ((tctxt->document == NULL) ||\n\t    (tctxt->document->doc != tmpNode->doc))\n\t{\n\t    if (tmpNode->doc->name && (tmpNode->doc->name[0] == ' ')) {\n\t\t/*\n\t\t* This is a Result Tree Fragment.\n\t\t*/\n\t\tif (tmpNode->doc->_private == NULL) {\n\t\t    tmpNode->doc->_private = xsltNewDocument(tctxt, tmpNode->doc);\n\t\t    if (tmpNode->doc->_private == NULL)\n\t\t\tgoto error;\n\t\t}\n\t\ttctxt->document = (xsltDocumentPtr) tmpNode->doc->_private;\n\t    } else {\n\t\t/*\n\t\t* May be the initial source doc or a doc acquired via the\n\t\t* document() function.\n\t\t*/\n\t\ttctxt->document = xsltFindDocument(tctxt, tmpNode->doc);\n\t    }\n\t    if (tctxt->document == NULL) {\n\t\txsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t    \"Internal error in xsltKeyFunction(): \"\n\t\t    \"Could not get the document info of a context doc.\\n\");\n\t\ttctxt->state = XSLT_STATE_STOPPED;\n\t\tgoto error;\n\t    }\n\t}\n\t/*\n\t* Get/compute the key value.\n\t*/\n\tnodelist = xsltGetKey(tctxt, key, keyURI, value);\n\nerror:\n\ttctxt->document = oldDocInfo;\n\tvaluePush(ctxt, xmlXPathWrapNodeSet(\n\t    xmlXPathNodeSetMerge(NULL, nodelist)));\n\tif (key != NULL)\n\t    xmlFree(key);\n    }\n\n    if (obj1 != NULL)\n\txmlXPathFreeObject(obj1);\n    if (obj2 != NULL)\n\txmlXPathFreeObject(obj2);\n}", "func_src_after": "xsltKeyFunction(xmlXPathParserContextPtr ctxt, int nargs){\n    xmlXPathObjectPtr obj1, obj2;\n\n    if (nargs != 2) {\n\txsltTransformError(xsltXPathGetTransformContext(ctxt), NULL, NULL,\n\t\t\"key() : expects two arguments\\n\");\n\tctxt->error = XPATH_INVALID_ARITY;\n\treturn;\n    }\n\n    /*\n    * Get the key's value.\n    */\n    obj2 = valuePop(ctxt);\n    xmlXPathStringFunction(ctxt, 1);\n    if ((obj2 == NULL) ||\n\t(ctxt->value == NULL) || (ctxt->value->type != XPATH_STRING)) {\n\txsltTransformError(xsltXPathGetTransformContext(ctxt), NULL, NULL,\n\t    \"key() : invalid arg expecting a string\\n\");\n\tctxt->error = XPATH_INVALID_TYPE;\n\txmlXPathFreeObject(obj2);\n\n\treturn;\n    }\n    /*\n    * Get the key's name.\n    */\n    obj1 = valuePop(ctxt);\n\n    if ((obj2->type == XPATH_NODESET) || (obj2->type == XPATH_XSLT_TREE)) {\n\tint i;\n\txmlXPathObjectPtr newobj, ret;\n\n\tret = xmlXPathNewNodeSet(NULL);\n        if (ret == NULL) {\n            ctxt->error = XPATH_MEMORY_ERROR;\n            xmlXPathFreeObject(obj1);\n            xmlXPathFreeObject(obj2);\n            return;\n        }\n\n\tif (obj2->nodesetval != NULL) {\n\t    for (i = 0; i < obj2->nodesetval->nodeNr; i++) {\n\t\tvaluePush(ctxt, xmlXPathObjectCopy(obj1));\n\t\tvaluePush(ctxt,\n\t\t\t  xmlXPathNewNodeSet(obj2->nodesetval->nodeTab[i]));\n\t\txmlXPathStringFunction(ctxt, 1);\n\t\txsltKeyFunction(ctxt, 2);\n\t\tnewobj = valuePop(ctxt);\n                if (newobj != NULL)\n\t\t    ret->nodesetval = xmlXPathNodeSetMerge(ret->nodesetval,\n\t\t\t\t\t\t           newobj->nodesetval);\n\t\txmlXPathFreeObject(newobj);\n\t    }\n\t}\n\tvaluePush(ctxt, ret);\n    } else {\n\txmlNodeSetPtr nodelist = NULL;\n\txmlChar *key = NULL, *value;\n\tconst xmlChar *keyURI;\n\txsltTransformContextPtr tctxt;\n\txmlChar *qname, *prefix;\n\txmlXPathContextPtr xpctxt = ctxt->context;\n\txmlNodePtr tmpNode = NULL;\n\txsltDocumentPtr oldDocInfo;\n\n\ttctxt = xsltXPathGetTransformContext(ctxt);\n\n\toldDocInfo = tctxt->document;\n\n\tif (xpctxt->node == NULL) {\n\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\"Internal error in xsltKeyFunction(): \"\n\t\t\"The context node is not set on the XPath context.\\n\");\n\t    tctxt->state = XSLT_STATE_STOPPED;\n\t    goto error;\n\t}\n\t/*\n\t * Get the associated namespace URI if qualified name\n\t */\n\tqname = obj1->stringval;\n\tkey = xmlSplitQName2(qname, &prefix);\n\tif (key == NULL) {\n\t    key = xmlStrdup(obj1->stringval);\n\t    keyURI = NULL;\n\t    if (prefix != NULL)\n\t\txmlFree(prefix);\n\t} else {\n\t    if (prefix != NULL) {\n\t\tkeyURI = xmlXPathNsLookup(xpctxt, prefix);\n\t\tif (keyURI == NULL) {\n\t\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\t\"key() : prefix %s is not bound\\n\", prefix);\n\t\t    /*\n\t\t    * TODO: Shouldn't we stop here?\n\t\t    */\n\t\t}\n\t\txmlFree(prefix);\n\t    } else {\n\t\tkeyURI = NULL;\n\t    }\n\t}\n\n\t/*\n\t * Force conversion of first arg to string\n\t */\n\tvaluePush(ctxt, obj2);\n\txmlXPathStringFunction(ctxt, 1);\n\tobj2 = valuePop(ctxt);\n\tif ((obj2 == NULL) || (obj2->type != XPATH_STRING)) {\n\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\"key() : invalid arg expecting a string\\n\");\n\t    ctxt->error = XPATH_INVALID_TYPE;\n\t    goto error;\n\t}\n\tvalue = obj2->stringval;\n\n\t/*\n\t* We need to ensure that ctxt->document is available for\n\t* xsltGetKey().\n\t* First find the relevant doc, which is the context node's\n\t* owner doc; using context->doc is not safe, since\n\t* the doc could have been acquired via the document() function,\n\t* or the doc might be a Result Tree Fragment.\n\t* FUTURE INFO: In XSLT 2.0 the key() function takes an additional\n\t* argument indicating the doc to use.\n\t*/\n\tif (xpctxt->node->type == XML_NAMESPACE_DECL) {\n\t    /*\n\t    * REVISIT: This is a libxml hack! Check xpath.c for details.\n\t    * The XPath module sets the owner element of a ns-node on\n\t    * the ns->next field.\n\t    */\n\t    if ((((xmlNsPtr) xpctxt->node)->next != NULL) &&\n\t\t(((xmlNsPtr) xpctxt->node)->next->type == XML_ELEMENT_NODE))\n\t    {\n\t\ttmpNode = (xmlNodePtr) ((xmlNsPtr) xpctxt->node)->next;\n\t    }\n\t} else\n\t    tmpNode = xpctxt->node;\n\n\tif ((tmpNode == NULL) || (tmpNode->doc == NULL)) {\n\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\"Internal error in xsltKeyFunction(): \"\n\t\t\"Couldn't get the doc of the XPath context node.\\n\");\n\t    goto error;\n\t}\n\n\tif ((tctxt->document == NULL) ||\n\t    (tctxt->document->doc != tmpNode->doc))\n\t{\n\t    if (tmpNode->doc->name && (tmpNode->doc->name[0] == ' ')) {\n\t\t/*\n\t\t* This is a Result Tree Fragment.\n\t\t*/\n\t\tif (tmpNode->doc->_private == NULL) {\n\t\t    tmpNode->doc->_private = xsltNewDocument(tctxt, tmpNode->doc);\n\t\t    if (tmpNode->doc->_private == NULL)\n\t\t\tgoto error;\n\t\t}\n\t\ttctxt->document = (xsltDocumentPtr) tmpNode->doc->_private;\n\t    } else {\n\t\t/*\n\t\t* May be the initial source doc or a doc acquired via the\n\t\t* document() function.\n\t\t*/\n\t\ttctxt->document = xsltFindDocument(tctxt, tmpNode->doc);\n\t    }\n\t    if (tctxt->document == NULL) {\n\t\txsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t    \"Internal error in xsltKeyFunction(): \"\n\t\t    \"Could not get the document info of a context doc.\\n\");\n\t\ttctxt->state = XSLT_STATE_STOPPED;\n\t\tgoto error;\n\t    }\n\t}\n\t/*\n\t* Get/compute the key value.\n\t*/\n\tnodelist = xsltGetKey(tctxt, key, keyURI, value);\n\nerror:\n\ttctxt->document = oldDocInfo;\n\tvaluePush(ctxt, xmlXPathWrapNodeSet(\n\t    xmlXPathNodeSetMerge(NULL, nodelist)));\n\tif (key != NULL)\n\t    xmlFree(key);\n    }\n\n    if (obj1 != NULL)\n\txmlXPathFreeObject(obj1);\n    if (obj2 != NULL)\n\txmlXPathFreeObject(obj2);\n}", "commit_link": "github.com/GNOME/libxslt/commit/aab7eedca3c2dcaa1795d6acba38a4c9811d2a75", "file_name": "libxslt/functions.c", "vul_type": "cwe-476", "description": "Write a C function named `xsltKeyFunction` that implements the XSLT key function in libxml2."}
{"func_name": "set_fdc", "func_src_before": "static void set_fdc(int drive)\n{\n\tif (drive >= 0 && drive < N_DRIVE) {\n\t\tfdc = FDC(drive);\n\t\tcurrent_drive = drive;\n\t}\n\tif (fdc != 1 && fdc != 0) {\n\t\tpr_info(\"bad fdc value\\n\");\n\t\treturn;\n\t}\n\tset_dor(fdc, ~0, 8);\n#if N_FDC > 1\n\tset_dor(1 - fdc, ~8, 0);\n#endif\n\tif (FDCS->rawcmd == 2)\n\t\treset_fdc_info(1);\n\tif (fd_inb(FD_STATUS) != STATUS_READY)\n\t\tFDCS->reset = 1;\n}", "func_src_after": "static void set_fdc(int drive)\n{\n\tunsigned int new_fdc = fdc;\n\n\tif (drive >= 0 && drive < N_DRIVE) {\n\t\tnew_fdc = FDC(drive);\n\t\tcurrent_drive = drive;\n\t}\n\tif (new_fdc >= N_FDC) {\n\t\tpr_info(\"bad fdc value\\n\");\n\t\treturn;\n\t}\n\tfdc = new_fdc;\n\tset_dor(fdc, ~0, 8);\n#if N_FDC > 1\n\tset_dor(1 - fdc, ~8, 0);\n#endif\n\tif (FDCS->rawcmd == 2)\n\t\treset_fdc_info(1);\n\tif (fd_inb(FD_STATUS) != STATUS_READY)\n\t\tFDCS->reset = 1;\n}", "commit_link": "github.com/torvalds/linux/commit/2e90ca68b0d2f5548804f22f0dd61145516171e3", "file_name": "drivers/block/floppy.c", "vul_type": "cwe-125", "description": "Write a C function named `set_fdc` that configures a floppy disk controller (FDC) for a given drive number, with error checking and hardware status updates."}
{"func_name": "__init__", "func_src_before": "  def __init__(self,\n               sess,\n               dump_root=None,\n               log_usage=True,\n               ui_type=\"curses\",\n               thread_name_filter=None,\n               config_file_path=False):\n    \"\"\"Constructor of LocalCLIDebugWrapperSession.\n\n    Args:\n      sess: The TensorFlow `Session` object being wrapped.\n      dump_root: (`str`) optional path to the dump root directory. Must be a\n        directory that does not exist or an empty directory. If the directory\n        does not exist, it will be created by the debugger core during debug\n        `run()` calls and removed afterwards. If `None`, the debug dumps will\n        be at tfdbg_<random_string> under the system temp directory.\n      log_usage: (`bool`) whether the usage of this class is to be logged.\n      ui_type: (`str`) requested UI type. Currently supported:\n        (curses | readline)\n      thread_name_filter: Regular-expression white list for thread name. See\n        the doc of `BaseDebugWrapperSession` for details.\n      config_file_path: Optional override to the default configuration file\n        path, which is at `${HOME}/.tfdbg_config`.\n\n    Raises:\n      ValueError: If dump_root is an existing and non-empty directory or if\n        dump_root is a file.\n    \"\"\"\n\n    if log_usage:\n      pass  # No logging for open-source.\n\n    framework.BaseDebugWrapperSession.__init__(\n        self, sess, thread_name_filter=thread_name_filter)\n\n    if not dump_root:\n      self._dump_root = tempfile.mktemp(prefix=_DUMP_ROOT_PREFIX)\n    else:\n      dump_root = os.path.expanduser(dump_root)\n      if os.path.isfile(dump_root):\n        raise ValueError(\"dump_root path points to a file: %s\" % dump_root)\n      elif os.path.isdir(dump_root) and os.listdir(dump_root):\n        raise ValueError(\"dump_root path points to a non-empty directory: %s\" %\n                         dump_root)\n\n      self._dump_root = dump_root\n\n    self._initialize_argparsers()\n\n    # Registered tensor filters.\n    self._tensor_filters = {}\n    # Register frequently-used filter(s).\n    self.add_tensor_filter(\"has_inf_or_nan\", debug_data.has_inf_or_nan)\n\n    # Below are the state variables of this wrapper object.\n    # _active_tensor_filter: what (if any) tensor filter is in effect. If such\n    #   a filter is in effect, this object will call run() method of the\n    #   underlying TensorFlow Session object until the filter passes. This is\n    #   activated by the \"-f\" flag of the \"run\" command.\n    # _run_through_times: keeps track of how many times the wrapper needs to\n    #   run through without stopping at the run-end CLI. It is activated by the\n    #   \"-t\" option of the \"run\" command.\n    # _skip_debug: keeps track of whether the current run should be executed\n    #   without debugging. It is activated by the \"-n\" option of the \"run\"\n    #   command.\n    #\n    # _run_start_response: keeps track what OnRunStartResponse the wrapper\n    #   should return at the next run-start callback. If this information is\n    #   unavailable (i.e., is None), the run-start CLI will be launched to ask\n    #   the user. This is the case, e.g., right before the first run starts.\n    self._active_tensor_filter = None\n    self._active_filter_exclude_node_names = None\n    self._active_tensor_filter_run_start_response = None\n    self._run_through_times = 1\n    self._skip_debug = False\n    self._run_start_response = None\n    self._is_run_start = True\n    self._ui_type = ui_type\n    self._config = None\n    if config_file_path:\n      self._config = cli_config.CLIConfig(config_file_path=config_file_path)", "func_src_after": "  def __init__(self,\n               sess,\n               dump_root=None,\n               log_usage=True,\n               ui_type=\"curses\",\n               thread_name_filter=None,\n               config_file_path=False):\n    \"\"\"Constructor of LocalCLIDebugWrapperSession.\n\n    Args:\n      sess: The TensorFlow `Session` object being wrapped.\n      dump_root: (`str`) optional path to the dump root directory. Must be a\n        directory that does not exist or an empty directory. If the directory\n        does not exist, it will be created by the debugger core during debug\n        `run()` calls and removed afterwards. If `None`, the debug dumps will\n        be at tfdbg_<random_string> under the system temp directory.\n      log_usage: (`bool`) whether the usage of this class is to be logged.\n      ui_type: (`str`) requested UI type. Currently supported:\n        (curses | readline)\n      thread_name_filter: Regular-expression white list for thread name. See\n        the doc of `BaseDebugWrapperSession` for details.\n      config_file_path: Optional override to the default configuration file\n        path, which is at `${HOME}/.tfdbg_config`.\n\n    Raises:\n      ValueError: If dump_root is an existing and non-empty directory or if\n        dump_root is a file.\n    \"\"\"\n\n    if log_usage:\n      pass  # No logging for open-source.\n\n    framework.BaseDebugWrapperSession.__init__(\n        self, sess, thread_name_filter=thread_name_filter)\n\n    if not dump_root:\n      self._dump_root = tempfile.mkdtemp(prefix=_DUMP_ROOT_PREFIX)\n    else:\n      dump_root = os.path.expanduser(dump_root)\n      if os.path.isfile(dump_root):\n        raise ValueError(\"dump_root path points to a file: %s\" % dump_root)\n      elif os.path.isdir(dump_root) and os.listdir(dump_root):\n        raise ValueError(\"dump_root path points to a non-empty directory: %s\" %\n                         dump_root)\n\n      self._dump_root = dump_root\n\n    self._initialize_argparsers()\n\n    # Registered tensor filters.\n    self._tensor_filters = {}\n    # Register frequently-used filter(s).\n    self.add_tensor_filter(\"has_inf_or_nan\", debug_data.has_inf_or_nan)\n\n    # Below are the state variables of this wrapper object.\n    # _active_tensor_filter: what (if any) tensor filter is in effect. If such\n    #   a filter is in effect, this object will call run() method of the\n    #   underlying TensorFlow Session object until the filter passes. This is\n    #   activated by the \"-f\" flag of the \"run\" command.\n    # _run_through_times: keeps track of how many times the wrapper needs to\n    #   run through without stopping at the run-end CLI. It is activated by the\n    #   \"-t\" option of the \"run\" command.\n    # _skip_debug: keeps track of whether the current run should be executed\n    #   without debugging. It is activated by the \"-n\" option of the \"run\"\n    #   command.\n    #\n    # _run_start_response: keeps track what OnRunStartResponse the wrapper\n    #   should return at the next run-start callback. If this information is\n    #   unavailable (i.e., is None), the run-start CLI will be launched to ask\n    #   the user. This is the case, e.g., right before the first run starts.\n    self._active_tensor_filter = None\n    self._active_filter_exclude_node_names = None\n    self._active_tensor_filter_run_start_response = None\n    self._run_through_times = 1\n    self._skip_debug = False\n    self._run_start_response = None\n    self._is_run_start = True\n    self._ui_type = ui_type\n    self._config = None\n    if config_file_path:\n      self._config = cli_config.CLIConfig(config_file_path=config_file_path)", "line_changes": {"deleted": [{"line_no": 37, "char_start": 1463, "char_end": 1529, "line": "      self._dump_root = tempfile.mktemp(prefix=_DUMP_ROOT_PREFIX)\n"}], "added": [{"line_no": 37, "char_start": 1463, "char_end": 1530, "line": "      self._dump_root = tempfile.mkdtemp(prefix=_DUMP_ROOT_PREFIX)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 1498, "char_end": 1499, "chars": "d"}]}, "commit_link": "github.com/tensorflow/tensorflow/commit/2939613ef8340a75c13a470d4097dbd7e4b6b534", "file_name": "local_cli_wrapper.py", "vul_type": "cwe-377", "commit_msg": "Use `tempfile.mkstemp` instead of `tempfile.mktemp`.\n\nThe `tempfile.mktemp` function is [deprecated](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp) due to [security issues](https://cwe.mitre.org/data/definitions/377.html).\n\nThe switch is easy to do.\n\nPiperOrigin-RevId: 420384092\nChange-Id: I8721c09ccc4de589b5a45d38e7ebc440160c72b8", "description": "Write a Python class constructor for a TensorFlow debugging wrapper session with customizable session, dump directory, logging, UI type, thread filtering, and configuration file path."}
{"func_name": "(anonymous)", "func_src_before": "\t\texec('node ' + binPath + ' ' + args.join(' '), function () {\n\t\t\tvar actual = fs.statSync('test/minified.png').size;\n\t\t\tvar original = fs.statSync('test/fixtures/test.png').size;\n\t\t\tassert(actual < original);\n\t\t\tcb();\n\t\t});", "func_src_after": "\t\texecFile('node', [binPath].concat(args), function () {\n\t\t\tvar actual = fs.statSync('test/minified.png').size;\n\t\t\tvar original = fs.statSync('test/fixtures/test.png').size;\n\t\t\tassert(actual < original);\n\t\t\tcb();\n\t\t});", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 63, "line": "\t\texec('node ' + binPath + ' ' + args.join(' '), function () {\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 57, "line": "\t\texecFile('node', [binPath].concat(args), function () {\n"}]}, "char_changes": {"deleted": [{"char_start": 12, "char_end": 17, "chars": " ' + "}, {"char_start": 24, "char_end": 46, "chars": " + ' ' + args.join(' '"}], "added": [{"char_start": 6, "char_end": 10, "chars": "File"}, {"char_start": 16, "char_end": 20, "chars": "', ["}, {"char_start": 27, "char_end": 40, "chars": "].concat(args"}]}, "commit_link": "github.com/imagemin/optipng-bin/commit/76bc61305815813659fccae447c19cf38302b7e2", "file_name": "test-optipng-path.js", "vul_type": "cwe-078", "commit_msg": "use execFile and arguments array instead of string concat", "parent_commit": "fffe11371341e0360ecde090cf6f2bac5d81505a", "description": "Write a JavaScript function that executes a Node.js script with arguments and checks if the size of a minified image is smaller than the original image."}
{"func_name": "Get", "func_src_before": "func Get(key string, lat string, long string, time string) *Forecast {\n\tcoord := lat + \",\" + long\n\n\tvar url string\n\tif time == \"now\" {\n\t\turl = BASEURL + \"/\" + key + \"/\" + coord + \"?units=ca\"\n\t} else {\n\t\turl = BASEURL + \"/\" + key + \"/\" + coord + \",\" + time + \"?units=ca\"\n\t}\n\n\ttr := &http.Transport{\n\t\tTLSClientConfig: &tls.Config{InsecureSkipVerify: true}, // susceptible to man-in-the-middle\n\t}\n\tclient := &http.Client{Transport: tr}\n\tresp, err := client.Get(url)\n\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tdefer resp.Body.Close()\n\tbody, err := ioutil.ReadAll(resp.Body)\n\n\tvar f Forecast\n\terr = json.Unmarshal(body, &f)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\treturn &f\n}", "func_src_after": "func Get(key string, lat string, long string, time string) (*Forecast, error) {\n\tcoord := lat + \",\" + long\n\n\tvar url string\n\tif time == \"now\" {\n\t\turl = BASEURL + \"/\" + key + \"/\" + coord + \"?units=si\"\n\t} else {\n\t\turl = BASEURL + \"/\" + key + \"/\" + coord + \",\" + time + \"?units=si\"\n\t}\n\n\ttr := &http.Transport{\n\t\tTLSClientConfig: &tls.Config{InsecureSkipVerify: false}, // does not seem required any longer\n\t}\n\tclient := &http.Client{Transport: tr}\n\tresp, err := client.Get(url)\n\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer resp.Body.Close()\n\tbody, err := ioutil.ReadAll(resp.Body)\n\n\tvar f Forecast\n\terr = json.Unmarshal(body, &f)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &f, nil\n}", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 71, "line": "func Get(key string, lat string, long string, time string) *Forecast {\n"}, {"line_no": 6, "char_start": 135, "char_end": 191, "line": "\t\turl = BASEURL + \"/\" + key + \"/\" + coord + \"?units=ca\"\n"}, {"line_no": 8, "char_start": 201, "char_end": 270, "line": "\t\turl = BASEURL + \"/\" + key + \"/\" + coord + \",\" + time + \"?units=ca\"\n"}, {"line_no": 12, "char_start": 298, "char_end": 392, "line": "\t\tTLSClientConfig: &tls.Config{InsecureSkipVerify: true}, // susceptible to man-in-the-middle\n"}, {"line_no": 18, "char_start": 482, "char_end": 499, "line": "\t\tlog.Fatal(err)\n"}, {"line_no": 26, "char_start": 633, "char_end": 650, "line": "\t\tlog.Fatal(err)\n"}, {"line_no": 29, "char_start": 654, "char_end": 665, "line": "\treturn &f\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 80, "line": "func Get(key string, lat string, long string, time string) (*Forecast, error) {\n"}, {"line_no": 6, "char_start": 144, "char_end": 200, "line": "\t\turl = BASEURL + \"/\" + key + \"/\" + coord + \"?units=si\"\n"}, {"line_no": 8, "char_start": 210, "char_end": 279, "line": "\t\turl = BASEURL + \"/\" + key + \"/\" + coord + \",\" + time + \"?units=si\"\n"}, {"line_no": 12, "char_start": 307, "char_end": 403, "line": "\t\tTLSClientConfig: &tls.Config{InsecureSkipVerify: false}, // does not seem required any longer\n"}, {"line_no": 18, "char_start": 493, "char_end": 511, "line": "\t\treturn nil, err\n"}, {"line_no": 26, "char_start": 645, "char_end": 663, "line": "\t\treturn nil, err\n"}, {"line_no": 29, "char_start": 667, "char_end": 683, "line": "\treturn &f, nil\n"}]}, "char_changes": {"deleted": [{"char_start": 187, "char_end": 189, "chars": "ca"}, {"char_start": 266, "char_end": 268, "chars": "ca"}, {"char_start": 349, "char_end": 352, "chars": "tru"}, {"char_start": 359, "char_end": 391, "chars": "susceptible to man-in-the-middle"}, {"char_start": 484, "char_end": 494, "chars": "log.Fatal("}, {"char_start": 497, "char_end": 498, "chars": ")"}, {"char_start": 635, "char_end": 645, "chars": "log.Fatal("}, {"char_start": 648, "char_end": 649, "chars": ")"}], "added": [{"char_start": 59, "char_end": 60, "chars": "("}, {"char_start": 69, "char_end": 77, "chars": ", error)"}, {"char_start": 196, "char_end": 198, "chars": "si"}, {"char_start": 275, "char_end": 277, "chars": "si"}, {"char_start": 358, "char_end": 362, "chars": "fals"}, {"char_start": 369, "char_end": 402, "chars": "does not seem required any longer"}, {"char_start": 495, "char_end": 507, "chars": "return nil, "}, {"char_start": 647, "char_end": 659, "chars": "return nil, "}, {"char_start": 677, "char_end": 682, "chars": ", nil"}]}, "commit_link": "github.com/mlbright/darksky/commit/f398d4d31806800c59e17dd8514c8da751f9bf72", "file_name": "forecast.go", "vul_type": "cwe-295", "commit_msg": "Get now returns a (*Forecast, error) pair\n\nThis seems like good practice. As it was, the code would panic in case\nof - for example - network problems, which is not the nicest thing to do\nin a library.\n\nAdditionally, InsecureSkipVerify has been set to false.", "parent_commit": "99e2fc3d4132a0bd9cf3a94ada0efbe4c18deb08", "description": "Write a Go function named `Get` that retrieves weather forecast data using coordinates and time, and handles errors."}
{"func_name": "set_geometry", "func_src_before": "static int set_geometry(unsigned int cmd, struct floppy_struct *g,\n\t\t\t       int drive, int type, struct block_device *bdev)\n{\n\tint cnt;\n\n\t/* sanity checking for parameters. */\n\tif (g->sect <= 0 ||\n\t    g->head <= 0 ||\n\t    /* check for zero in F_SECT_PER_TRACK */\n\t    (unsigned char)((g->sect << 2) >> FD_SIZECODE(g)) == 0 ||\n\t    g->track <= 0 || g->track > UDP->tracks >> STRETCH(g) ||\n\t    /* check if reserved bits are set */\n\t    (g->stretch & ~(FD_STRETCH | FD_SWAPSIDES | FD_SECTBASEMASK)) != 0)\n\t\treturn -EINVAL;\n\tif (type) {\n\t\tif (!capable(CAP_SYS_ADMIN))\n\t\t\treturn -EPERM;\n\t\tmutex_lock(&open_lock);\n\t\tif (lock_fdc(drive)) {\n\t\t\tmutex_unlock(&open_lock);\n\t\t\treturn -EINTR;\n\t\t}\n\t\tfloppy_type[type] = *g;\n\t\tfloppy_type[type].name = \"user format\";\n\t\tfor (cnt = type << 2; cnt < (type << 2) + 4; cnt++)\n\t\t\tfloppy_sizes[cnt] = floppy_sizes[cnt + 0x80] =\n\t\t\t    floppy_type[type].size + 1;\n\t\tprocess_fd_request();\n\t\tfor (cnt = 0; cnt < N_DRIVE; cnt++) {\n\t\t\tstruct block_device *bdev = opened_bdev[cnt];\n\t\t\tif (!bdev || ITYPE(drive_state[cnt].fd_device) != type)\n\t\t\t\tcontinue;\n\t\t\t__invalidate_device(bdev, true);\n\t\t}\n\t\tmutex_unlock(&open_lock);\n\t} else {\n\t\tint oldStretch;\n\n\t\tif (lock_fdc(drive))\n\t\t\treturn -EINTR;\n\t\tif (cmd != FDDEFPRM) {\n\t\t\t/* notice a disk change immediately, else\n\t\t\t * we lose our settings immediately*/\n\t\t\tif (poll_drive(true, FD_RAW_NEED_DISK) == -EINTR)\n\t\t\t\treturn -EINTR;\n\t\t}\n\t\toldStretch = g->stretch;\n\t\tuser_params[drive] = *g;\n\t\tif (buffer_drive == drive)\n\t\t\tSUPBOUND(buffer_max, user_params[drive].sect);\n\t\tcurrent_type[drive] = &user_params[drive];\n\t\tfloppy_sizes[drive] = user_params[drive].size;\n\t\tif (cmd == FDDEFPRM)\n\t\t\tDRS->keep_data = -1;\n\t\telse\n\t\t\tDRS->keep_data = 1;\n\t\t/* invalidation. Invalidate only when needed, i.e.\n\t\t * when there are already sectors in the buffer cache\n\t\t * whose number will change. This is useful, because\n\t\t * mtools often changes the geometry of the disk after\n\t\t * looking at the boot block */\n\t\tif (DRS->maxblock > user_params[drive].sect ||\n\t\t    DRS->maxtrack ||\n\t\t    ((user_params[drive].sect ^ oldStretch) &\n\t\t     (FD_SWAPSIDES | FD_SECTBASEMASK)))\n\t\t\tinvalidate_drive(bdev);\n\t\telse\n\t\t\tprocess_fd_request();\n\t}\n\treturn 0;\n}", "func_src_after": "static int set_geometry(unsigned int cmd, struct floppy_struct *g,\n\t\t\t       int drive, int type, struct block_device *bdev)\n{\n\tint cnt;\n\n\t/* sanity checking for parameters. */\n\tif ((int)g->sect <= 0 ||\n\t    (int)g->head <= 0 ||\n\t    /* check for overflow in max_sector */\n\t    (int)(g->sect * g->head) <= 0 ||\n\t    /* check for zero in F_SECT_PER_TRACK */\n\t    (unsigned char)((g->sect << 2) >> FD_SIZECODE(g)) == 0 ||\n\t    g->track <= 0 || g->track > UDP->tracks >> STRETCH(g) ||\n\t    /* check if reserved bits are set */\n\t    (g->stretch & ~(FD_STRETCH | FD_SWAPSIDES | FD_SECTBASEMASK)) != 0)\n\t\treturn -EINVAL;\n\tif (type) {\n\t\tif (!capable(CAP_SYS_ADMIN))\n\t\t\treturn -EPERM;\n\t\tmutex_lock(&open_lock);\n\t\tif (lock_fdc(drive)) {\n\t\t\tmutex_unlock(&open_lock);\n\t\t\treturn -EINTR;\n\t\t}\n\t\tfloppy_type[type] = *g;\n\t\tfloppy_type[type].name = \"user format\";\n\t\tfor (cnt = type << 2; cnt < (type << 2) + 4; cnt++)\n\t\t\tfloppy_sizes[cnt] = floppy_sizes[cnt + 0x80] =\n\t\t\t    floppy_type[type].size + 1;\n\t\tprocess_fd_request();\n\t\tfor (cnt = 0; cnt < N_DRIVE; cnt++) {\n\t\t\tstruct block_device *bdev = opened_bdev[cnt];\n\t\t\tif (!bdev || ITYPE(drive_state[cnt].fd_device) != type)\n\t\t\t\tcontinue;\n\t\t\t__invalidate_device(bdev, true);\n\t\t}\n\t\tmutex_unlock(&open_lock);\n\t} else {\n\t\tint oldStretch;\n\n\t\tif (lock_fdc(drive))\n\t\t\treturn -EINTR;\n\t\tif (cmd != FDDEFPRM) {\n\t\t\t/* notice a disk change immediately, else\n\t\t\t * we lose our settings immediately*/\n\t\t\tif (poll_drive(true, FD_RAW_NEED_DISK) == -EINTR)\n\t\t\t\treturn -EINTR;\n\t\t}\n\t\toldStretch = g->stretch;\n\t\tuser_params[drive] = *g;\n\t\tif (buffer_drive == drive)\n\t\t\tSUPBOUND(buffer_max, user_params[drive].sect);\n\t\tcurrent_type[drive] = &user_params[drive];\n\t\tfloppy_sizes[drive] = user_params[drive].size;\n\t\tif (cmd == FDDEFPRM)\n\t\t\tDRS->keep_data = -1;\n\t\telse\n\t\t\tDRS->keep_data = 1;\n\t\t/* invalidation. Invalidate only when needed, i.e.\n\t\t * when there are already sectors in the buffer cache\n\t\t * whose number will change. This is useful, because\n\t\t * mtools often changes the geometry of the disk after\n\t\t * looking at the boot block */\n\t\tif (DRS->maxblock > user_params[drive].sect ||\n\t\t    DRS->maxtrack ||\n\t\t    ((user_params[drive].sect ^ oldStretch) &\n\t\t     (FD_SWAPSIDES | FD_SECTBASEMASK)))\n\t\t\tinvalidate_drive(bdev);\n\t\telse\n\t\t\tprocess_fd_request();\n\t}\n\treturn 0;\n}", "commit_link": "github.com/torvalds/linux/commit/da99466ac243f15fbba65bd261bfc75ffa1532b6", "file_name": "drivers/block/floppy.c", "vul_type": "cwe-190", "description": "Write a C function named `set_geometry` that configures the disk geometry for a floppy drive."}
{"func_name": "search_pages", "func_src_before": "@app.route(\"/search\", methods = [\"POST\"])\ndef search_pages():\n    search = request.form.get(\"search\")\n    page = db.query(\"select title from page where title = '%s'\" % search).namedresult()\n    if len(page) == 0:\n        return redirect(\"/%s\" % search)\n    else:\n        return place_holder(search)", "func_src_after": "@app.route(\"/search\", methods = [\"POST\"])\ndef search_pages():\n    search = request.form.get(\"search\")\n    page = db.query(\"select title from page where title = $1\", search).namedresult()\n    if len(page) == 0:\n        return redirect(\"/%s\" % search)\n    else:\n        return place_holder(search)", "commit_link": "github.com/jcortes0309/wiki_flask/commit/a6bf5316abe2eb528adf36c8241a013fd02c5ffa", "file_name": "server.py", "vul_type": "cwe-089", "description": "Write a Python Flask function that handles a POST request to search for a page title in a database and either redirects to the page if not found or returns a placeholder response."}
{"func_name": "user_verify", "func_src_before": "    def user_verify(self):\n        eid = self.email\n        code = self.password\n        if eid.strip() == '':\n            return\n        if code.strip() == '':\n            return\n        query = '''select * from usr where email like\\''''+eid+'\\''\n        cursor = g.conn.execute(query)\n        for row in cursor:\n            key = str(row.password)\n            if key.strip() == code.strip():\n                self.name = str(row.name)\n                self.email = eid\n                self.id = eid\n                self.valid = True\n            break", "func_src_after": "    def user_verify(self):\n        eid = self.email\n        code = self.password\n        if eid.strip() == '':\n            return\n        if code.strip() == '':\n            return\n        query = 'select * from usr where email like %s'\n        cursor = g.conn.execute(query, (eid, ))\n        for row in cursor:\n            key = str(row.password)\n            if key.strip() == code.strip():\n                self.name = str(row.name)\n                self.email = eid\n                self.id = eid\n                self.valid = True\n            break", "commit_link": "github.com/Daniel-Bu/w4111-project1/commit/fe04bedc72e62fd4c4ee046a9af29fd81e9b3340", "file_name": "Web-app/User.py", "vul_type": "cwe-089", "description": "Write a Python function named `user_verify` that checks if a user's email and password match the records in a database, and updates the user's attributes if the credentials are valid."}
{"func_name": "ZipMisc::unzip", "func_src_before": "\tpublic static void unzip(File input, File destinationDir) throws IOException {\n\t\ttry (ZipInputStream zipInput = new ZipInputStream(new BufferedInputStream(new FileInputStream(input)))) {\n\t\t\tZipEntry entry;\n\t\t\twhile ((entry = zipInput.getNextEntry()) != null) {\n\t\t\t\tFile dest = new File(destinationDir, entry.getName());\n\t\t\t\tif (entry.isDirectory()) {\n\t\t\t\t\tFileMisc.mkdirs(dest);\n\t\t\t\t} else {\n\t\t\t\t\tFileMisc.mkdirs(dest.getParentFile());\n\t\t\t\t\ttry (OutputStream output = new BufferedOutputStream(new FileOutputStream(dest))) {\n\t\t\t\t\t\tcopy(zipInput, output);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}", "func_src_after": "\tpublic static void unzip(File input, File destinationDir) throws IOException {\n\t\ttry (ZipInputStream zipInput = new ZipInputStream(new BufferedInputStream(new FileInputStream(input)))) {\n\t\t\tZipEntry entry;\n\t\t\twhile ((entry = zipInput.getNextEntry()) != null) {\n\t\t\t\tFile dest = new File(destinationDir, entry.getName());\n\t\t\t\tif (!dest.toPath().normalize().startsWith(destinationDir.toPath().normalize())) {\n\t\t\t\t\tthrow new RuntimeException(\"Bad zip entry\");\n\t\t\t\t}\n\t\t\t\tif (entry.isDirectory()) {\n\t\t\t\t\tFileMisc.mkdirs(dest);\n\t\t\t\t} else {\n\t\t\t\t\tFileMisc.mkdirs(dest.getParentFile());\n\t\t\t\t\ttry (OutputStream output = new BufferedOutputStream(new FileOutputStream(dest))) {\n\t\t\t\t\t\tcopy(zipInput, output);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}", "line_changes": {"deleted": [], "added": [{"line_no": 6, "char_start": 321, "char_end": 407, "line": "\t\t\t\tif (!dest.toPath().normalize().startsWith(destinationDir.toPath().normalize())) {\n"}, {"line_no": 7, "char_start": 407, "char_end": 457, "line": "\t\t\t\t\tthrow new RuntimeException(\"Bad zip entry\");\n"}, {"line_no": 8, "char_start": 457, "char_end": 463, "line": "\t\t\t\t}\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 321, "char_end": 463, "chars": "\t\t\t\tif (!dest.toPath().normalize().startsWith(destinationDir.toPath().normalize())) {\n\t\t\t\t\tthrow new RuntimeException(\"Bad zip entry\");\n\t\t\t\t}\n"}]}, "commit_link": "github.com/diffplug/goomph/commit/643474930339e5567745ba0695f2a8decf627a8c", "file_name": "ZipMisc.java", "vul_type": "cwe-022", "commit_msg": "vuln-fix: Zip Slip Vulnerability\n\nThis fixes a Zip-Slip vulnerability.\n\nThis change does one of two things. This change either\n\n1. Inserts a guard to protect against Zip Slip.\nOR\n2. Replaces `dir.getCanonicalPath().startsWith(parent.getCanonicalPath())`, which is vulnerable to partial path traversal attacks, with the more secure `dir.getCanonicalFile().toPath().startsWith(parent.getCanonicalFile().toPath())`.\n\nFor number 2, consider `\"/usr/outnot\".startsWith(\"/usr/out\")`.\nThe check is bypassed although `/outnot` is not under the `/out` directory.\nIt's important to understand that the terminating slash may be removed when using various `String` representations of the `File` object.\nFor example, on Linux, `println(new File(\"/var\"))` will print `/var`, but `println(new File(\"/var\", \"/\")` will print `/var/`;\nhowever, `println(new File(\"/var\", \"/\").getCanonicalPath())` will print `/var`.\n\nWeakness: CWE-22: Improper Limitation of a Pathname to a Restricted Directory ('Path Traversal')\nSeverity: High\nCVSSS: 7.4\nDetection: CodeQL (https://codeql.github.com/codeql-query-help/java/java-zipslip/) & OpenRewrite (https://public.moderne.io/recipes/org.openrewrite.java.security.ZipSlip)\n\nReported-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\nSigned-off-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\n\nBug-tracker: https://github.com/JLLeitschuh/security-research/issues/16\n\nCo-authored-by: Moderne <team@moderne.io>", "parent_commit": "fe2083196f0d0a75885aea402baaa972254173d5", "description": "Write a Java function to extract the contents of a ZIP file to a specified directory."}
{"func_name": "move", "func_src_before": "def move(path, dest, replace=False):\n    \"\"\"Rename a file. `dest` may not be a directory. If `dest` already\n    exists, raises an OSError unless `replace` is True. Has no effect if\n    `path` is the same as `dest`. If the paths are on different\n    filesystems (or the rename otherwise fails), a copy is attempted\n    instead, in which case metadata will *not* be preserved. Paths are\n    translated to system paths.\n    \"\"\"\n    if os.path.isdir(path):\n        raise FilesystemError(u'source is directory', 'move', (path, dest))\n    if os.path.isdir(dest):\n        raise FilesystemError(u'destination is directory', 'move',\n                              (path, dest))\n    if samefile(path, dest):\n        return\n    path = syspath(path)\n    dest = syspath(dest)\n    if os.path.exists(dest) and not replace:\n        raise FilesystemError('file exists', 'rename', (path, dest))\n\n    # First, try renaming the file.\n    try:\n        os.replace(path, dest)\n    except OSError:\n        tmp = tempfile.mktemp(suffix='.beets',\n                              prefix=py3_path(b'.' + os.path.basename(dest)),\n                              dir=py3_path(os.path.dirname(dest)))\n        tmp = syspath(tmp)\n        try:\n            shutil.copyfile(path, tmp)\n            os.replace(tmp, dest)\n            tmp = None\n            os.remove(path)\n        except OSError as exc:\n            raise FilesystemError(exc, 'move', (path, dest),\n                                  traceback.format_exc())\n        finally:\n            if tmp is not None:\n                os.remove(tmp)", "func_src_after": "def move(path, dest, replace=False):\n    \"\"\"Rename a file. `dest` may not be a directory. If `dest` already\n    exists, raises an OSError unless `replace` is True. Has no effect if\n    `path` is the same as `dest`. If the paths are on different\n    filesystems (or the rename otherwise fails), a copy is attempted\n    instead, in which case metadata will *not* be preserved. Paths are\n    translated to system paths.\n    \"\"\"\n    if os.path.isdir(path):\n        raise FilesystemError(u'source is directory', 'move', (path, dest))\n    if os.path.isdir(dest):\n        raise FilesystemError(u'destination is directory', 'move',\n                              (path, dest))\n    if samefile(path, dest):\n        return\n    path = syspath(path)\n    dest = syspath(dest)\n    if os.path.exists(dest) and not replace:\n        raise FilesystemError('file exists', 'rename', (path, dest))\n\n    # First, try renaming the file.\n    try:\n        os.replace(path, dest)\n    except OSError:\n        # Copy the file to a temporary destination.\n        tmp = tempfile.NamedTemporaryFile(suffix=b'.beets',\n                                          prefix=b'.' + os.path.basename(dest),\n                                          dir=os.path.dirname(dest),\n                                          delete=False)\n        try:\n            with open(path, 'rb') as f:\n                shutil.copyfileobj(f, tmp)\n        finally:\n            tmp.close()\n\n        # Move the copied file into place.\n        try:\n            os.replace(tmp.name, dest)\n            tmp = None\n            os.remove(path)\n        except OSError as exc:\n            raise FilesystemError(exc, 'move', (path, dest),\n                                  traceback.format_exc())\n        finally:\n            if tmp is not None:\n                os.remove(tmp)", "line_changes": {"deleted": [{"line_no": 25, "char_start": 973, "char_end": 1020, "line": "        tmp = tempfile.mktemp(suffix='.beets',\n"}, {"line_no": 26, "char_start": 1020, "char_end": 1098, "line": "                              prefix=py3_path(b'.' + os.path.basename(dest)),\n"}, {"line_no": 27, "char_start": 1098, "char_end": 1165, "line": "                              dir=py3_path(os.path.dirname(dest)))\n"}, {"line_no": 28, "char_start": 1165, "char_end": 1192, "line": "        tmp = syspath(tmp)\n"}, {"line_no": 30, "char_start": 1205, "char_end": 1244, "line": "            shutil.copyfile(path, tmp)\n"}, {"line_no": 31, "char_start": 1244, "char_end": 1278, "line": "            os.replace(tmp, dest)\n"}], "added": [{"line_no": 26, "char_start": 1025, "char_end": 1085, "line": "        tmp = tempfile.NamedTemporaryFile(suffix=b'.beets',\n"}, {"line_no": 27, "char_start": 1085, "char_end": 1165, "line": "                                          prefix=b'.' + os.path.basename(dest),\n"}, {"line_no": 28, "char_start": 1165, "char_end": 1234, "line": "                                          dir=os.path.dirname(dest),\n"}, {"line_no": 29, "char_start": 1234, "char_end": 1290, "line": "                                          delete=False)\n"}, {"line_no": 31, "char_start": 1303, "char_end": 1343, "line": "            with open(path, 'rb') as f:\n"}, {"line_no": 32, "char_start": 1343, "char_end": 1386, "line": "                shutil.copyfileobj(f, tmp)\n"}, {"line_no": 33, "char_start": 1386, "char_end": 1403, "line": "        finally:\n"}, {"line_no": 34, "char_start": 1403, "char_end": 1427, "line": "            tmp.close()\n"}, {"line_no": 35, "char_start": 1427, "char_end": 1428, "line": "\n"}, {"line_no": 37, "char_start": 1471, "char_end": 1484, "line": "        try:\n"}, {"line_no": 38, "char_start": 1484, "char_end": 1523, "line": "            os.replace(tmp.name, dest)\n"}]}, "char_changes": {"deleted": [{"char_start": 981, "char_end": 1002, "chars": "tmp = tempfile.mktemp"}, {"char_start": 1050, "char_end": 1066, "chars": "prefix=py3_path("}, {"char_start": 1095, "char_end": 1096, "chars": ")"}, {"char_start": 1132, "char_end": 1141, "chars": "py3_path("}, {"char_start": 1162, "char_end": 1164, "chars": "))"}, {"char_start": 1173, "char_end": 1243, "chars": "tmp = syspath(tmp)\n        try:\n            shutil.copyfile(path, tmp)"}], "added": [{"char_start": 981, "char_end": 1066, "chars": "# Copy the file to a temporary destination.\n        tmp = tempfile.NamedTemporaryFile"}, {"char_start": 1074, "char_end": 1075, "chars": "b"}, {"char_start": 1115, "char_end": 1134, "chars": "            prefix="}, {"char_start": 1165, "char_end": 1177, "chars": "            "}, {"char_start": 1232, "char_end": 1233, "chars": ","}, {"char_start": 1242, "char_end": 1483, "chars": "                                  delete=False)\n        try:\n            with open(path, 'rb') as f:\n                shutil.copyfileobj(f, tmp)\n        finally:\n            tmp.close()\n\n        # Move the copied file into place.\n        try:"}, {"char_start": 1510, "char_end": 1515, "chars": ".name"}]}, "commit_link": "github.com/beetbox/beets/commit/4bb695bcdbada9c8153442688e8494199f015f04", "file_name": "__init__.py", "vul_type": "cwe-377", "commit_msg": "Fix copying for atomic file moves\n\nFixes #4168. Also closes #4192, which it supersedes.\n\nThe original problem is that this implementation used bytestrings\nincorrectly to invoke `mktemp`. However, `mktemp` is deprecated, so this\nPR just avoids it altogether. Fortunately, the non-deprecated APIs in\n`tempfile` support all-bytes arguments.", "description": "Write a Python function named `move` that renames a file, with an option to replace the destination file if it already exists."}
{"func_name": "add_rpmmd_repo", "func_src_before": "    def add_rpmmd_repo(primary_xml, name)\n      repo = pool.add_repo(name)\n      gz = open(primary_xml)\n      fd = Solv.xfopen_fd(primary_xml, gz.fileno)\n      repo.add_rpmmd(fd, nil, 0)\n      pool.createwhatprovides\n    ensure\n      gz&.close\n    end", "func_src_after": "    def add_rpmmd_repo(primary_xml, name)\n      repo = pool.add_repo(name)\n      File.open(primary_xml) do |gz|\n        fd = Solv.xfopen_fd(primary_xml, gz.fileno)\n        repo.add_rpmmd(fd, nil, 0)\n        pool.createwhatprovides\n      end\n    end", "line_changes": {"deleted": [{"line_no": 3, "char_start": 75, "char_end": 104, "line": "      gz = open(primary_xml)\n"}, {"line_no": 4, "char_start": 104, "char_end": 154, "line": "      fd = Solv.xfopen_fd(primary_xml, gz.fileno)\n"}, {"line_no": 5, "char_start": 154, "char_end": 187, "line": "      repo.add_rpmmd(fd, nil, 0)\n"}, {"line_no": 6, "char_start": 187, "char_end": 217, "line": "      pool.createwhatprovides\n"}, {"line_no": 7, "char_start": 217, "char_end": 228, "line": "    ensure\n"}, {"line_no": 8, "char_start": 228, "char_end": 244, "line": "      gz&.close\n"}], "added": [{"line_no": 3, "char_start": 75, "char_end": 112, "line": "      File.open(primary_xml) do |gz|\n"}, {"line_no": 4, "char_start": 112, "char_end": 164, "line": "        fd = Solv.xfopen_fd(primary_xml, gz.fileno)\n"}, {"line_no": 5, "char_start": 164, "char_end": 199, "line": "        repo.add_rpmmd(fd, nil, 0)\n"}, {"line_no": 6, "char_start": 199, "char_end": 231, "line": "        pool.createwhatprovides\n"}, {"line_no": 7, "char_start": 231, "char_end": 241, "line": "      end\n"}]}, "char_changes": {"deleted": [{"char_start": 81, "char_end": 86, "chars": "gz = "}, {"char_start": 103, "char_end": 104, "chars": "\n"}, {"char_start": 221, "char_end": 243, "chars": "ensure\n      gz&.close"}], "added": [{"char_start": 81, "char_end": 86, "chars": "File."}, {"char_start": 103, "char_end": 114, "chars": " do |gz|\n  "}, {"char_start": 170, "char_end": 172, "chars": "  "}, {"char_start": 205, "char_end": 206, "chars": " "}, {"char_start": 206, "char_end": 207, "chars": " "}, {"char_start": 235, "char_end": 240, "chars": "  end"}]}, "commit_link": "github.com/yast/yast-packager/commit/a25ddf08b43ff58ceaebb1aa7c01e2804f98864e", "file_name": "solvable_pool.rb", "vul_type": "cwe-078", "commit_msg": "use secure File.open instead of Kernel.open (NO-AUTO)", "parent_commit": "915385e0672aef903b49b7f735a655a051b68f6a", "description": "Write a Ruby function to add an RPM metadata repository by reading a primary XML file."}
{"func_name": "uvesafb_setcmap", "func_src_before": "static int uvesafb_setcmap(struct fb_cmap *cmap, struct fb_info *info)\n{\n\tstruct uvesafb_pal_entry *entries;\n\tint shift = 16 - dac_width;\n\tint i, err = 0;\n\n\tif (info->var.bits_per_pixel == 8) {\n\t\tif (cmap->start + cmap->len > info->cmap.start +\n\t\t    info->cmap.len || cmap->start < info->cmap.start)\n\t\t\treturn -EINVAL;\n\n\t\tentries = kmalloc(sizeof(*entries) * cmap->len, GFP_KERNEL);\n\t\tif (!entries)\n\t\t\treturn -ENOMEM;\n\n\t\tfor (i = 0; i < cmap->len; i++) {\n\t\t\tentries[i].red   = cmap->red[i]   >> shift;\n\t\t\tentries[i].green = cmap->green[i] >> shift;\n\t\t\tentries[i].blue  = cmap->blue[i]  >> shift;\n\t\t\tentries[i].pad   = 0;\n\t\t}\n\t\terr = uvesafb_setpalette(entries, cmap->len, cmap->start, info);\n\t\tkfree(entries);\n\t} else {\n\t\t/*\n\t\t * For modes with bpp > 8, we only set the pseudo palette in\n\t\t * the fb_info struct. We rely on uvesafb_setcolreg to do all\n\t\t * sanity checking.\n\t\t */\n\t\tfor (i = 0; i < cmap->len; i++) {\n\t\t\terr |= uvesafb_setcolreg(cmap->start + i, cmap->red[i],\n\t\t\t\t\t\tcmap->green[i], cmap->blue[i],\n\t\t\t\t\t\t0, info);\n\t\t}\n\t}\n\treturn err;\n}", "func_src_after": "static int uvesafb_setcmap(struct fb_cmap *cmap, struct fb_info *info)\n{\n\tstruct uvesafb_pal_entry *entries;\n\tint shift = 16 - dac_width;\n\tint i, err = 0;\n\n\tif (info->var.bits_per_pixel == 8) {\n\t\tif (cmap->start + cmap->len > info->cmap.start +\n\t\t    info->cmap.len || cmap->start < info->cmap.start)\n\t\t\treturn -EINVAL;\n\n\t\tentries = kmalloc_array(cmap->len, sizeof(*entries),\n\t\t\t\t\tGFP_KERNEL);\n\t\tif (!entries)\n\t\t\treturn -ENOMEM;\n\n\t\tfor (i = 0; i < cmap->len; i++) {\n\t\t\tentries[i].red   = cmap->red[i]   >> shift;\n\t\t\tentries[i].green = cmap->green[i] >> shift;\n\t\t\tentries[i].blue  = cmap->blue[i]  >> shift;\n\t\t\tentries[i].pad   = 0;\n\t\t}\n\t\terr = uvesafb_setpalette(entries, cmap->len, cmap->start, info);\n\t\tkfree(entries);\n\t} else {\n\t\t/*\n\t\t * For modes with bpp > 8, we only set the pseudo palette in\n\t\t * the fb_info struct. We rely on uvesafb_setcolreg to do all\n\t\t * sanity checking.\n\t\t */\n\t\tfor (i = 0; i < cmap->len; i++) {\n\t\t\terr |= uvesafb_setcolreg(cmap->start + i, cmap->red[i],\n\t\t\t\t\t\tcmap->green[i], cmap->blue[i],\n\t\t\t\t\t\t0, info);\n\t\t}\n\t}\n\treturn err;\n}", "commit_link": "github.com/torvalds/linux/commit/9f645bcc566a1e9f921bdae7528a01ced5bc3713", "file_name": "drivers/video/fbdev/uvesafb.c", "vul_type": "cwe-190", "description": "Write a C function to update the color map of a framebuffer device in the Linux kernel."}
{"func_name": "variables", "func_src_before": "    @expose('/variables/<form>', methods=[\"GET\", \"POST\"])\n    @login_required\n    @wwwutils.action_logging\n    def variables(self, form):\n        try:\n            if request.method == 'POST':\n                data = request.json\n                if data:\n                    session = settings.Session()\n                    var = models.Variable(key=form, val=json.dumps(data))\n                    session.add(var)\n                    session.commit()\n                return \"\"\n            else:\n                return self.render(\n                    'airflow/variables/{}.html'.format(form)\n                )\n        except:\n            return (\"Error: form airflow/variables/{}.html \"\n                    \"not found.\").format(form), 404", "func_src_after": "    @expose('/variables/<form>', methods=[\"GET\", \"POST\"])\n    @login_required\n    @wwwutils.action_logging\n    def variables(self, form):\n        try:\n            if request.method == 'POST':\n                data = request.json\n                if data:\n                    session = settings.Session()\n                    var = models.Variable(key=form, val=json.dumps(data))\n                    session.add(var)\n                    session.commit()\n                return \"\"\n            else:\n                return self.render(\n                    'airflow/variables/{}.html'.format(form)\n                )\n        except:\n            # prevent XSS\n            form = escape(form)\n            return (\"Error: form airflow/variables/{}.html \"\n                    \"not found.\").format(form), 404", "line_changes": {"deleted": [], "added": [{"line_no": 20, "char_start": 651, "char_end": 683, "line": "            form = escape(form)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 625, "char_end": 683, "chars": "            # prevent XSS\n            form = escape(form)\n"}]}, "commit_link": "github.com/sekikn/incubator-airflow/commit/8f9bf94d82abc59336e642db64e575cee0cc5df0", "file_name": "views.py", "vul_type": "cwe-079", "commit_msg": "[AIRFLOW-1617] Fix XSS vulnerability in Variable endpoint\n\nIn case a Variable form was accessed by a get request and\nthe form did not exist as a template, the input was\nreturned as is to the user.\n\nCloses #2611 from bolkedebruin/xss_fix", "description": "Create a Python Flask web handler for managing variables that supports both GET and POST requests."}
{"func_name": "tcp_forward", "func_src_before": "    def tcp_forward(self, host_port, device_port):\n        \"\"\"Starts tcp forwarding.\n\n        Args:\n            host_port: Port number to use on the computer.\n            device_port: Port number to use on the android device.\n        \"\"\"\n        self.forward('tcp:%d tcp:%d' % (host_port, device_port))", "func_src_after": "    def tcp_forward(self, host_port, device_port):\n        \"\"\"Starts tcp forwarding.\n\n        Args:\n            host_port: Port number to use on the computer.\n            device_port: Port number to use on the android device.\n        \"\"\"\n        self.forward(['tcp:%d' % host_port, 'tcp:%d' % device_port])", "commit_link": "github.com/google/mobly/commit/3862e8ba359040fbdd6e1a6d36e51d07cda8e1ee", "file_name": "mobly/controllers/android_device_lib/adb.py", "vul_type": "cwe-078", "description": "Write a Python function named `tcp_forward` that sets up TCP forwarding between a specified host port and an Android device port."}
{"func_name": "update_device", "func_src_before": "    def update_device(self, **kwargs):\n        \"\"\" See http://api.device42.com/#create/update-device-by-name \"\"\"\n        path = 'devices'\n        atleast_fields = \"name serial_no uuid\".split()\n        known_fields = \"new_name asset_no manufacturer hardware new_hardware is_it_switch\"\n        known_fields += \" is_it_virtual_host is_it_blade_host in_service type service_level virtual_host\"\n        known_fields += \" blade_host slot_no storage_room_id storage_room os osver osverno memory cpucount cpupower cpucore\"\n        known_fields += \" hddcount hddsize hddraid hddraid_type macaddress devices_in_cluster appcomps\"\n        known_fields += \" customer contract_id contract\"\n        known_fields += \" aliases subtype virtual_subtype notes tags\"\n        known_fields = atleast_fields + known_fields.split()\n        if not set(atleast_fields).intersection(kwargs.keys()):\n            raise Device42BadArgumentError(\"At least one parameter should be passed: %s\" % atleast_fields)\n        unknown_fields = set(kwargs.keys()) - set(known_fields)\n        if unknown_fields:\n            raise Device42BadArgumentError(\"Unknown parameters: %s\" % unknown_fields)\n        return self._post(path, data=kwargs)", "func_src_after": "    def update_device(self, **kwargs):\n        \"\"\" See http://api.device42.com/#create/update-device-by-name \"\"\"\n        path = 'devices'\n        atleast_fields = [\"name\"]  # this is the only required field to create/update a device, serial and uuid opt\n        known_fields = \"new_name asset_no manufacturer hardware new_hardware is_it_switch\"\n        known_fields += \" is_it_virtual_host is_it_blade_host in_service type service_level virtual_host\"\n        known_fields += \" serial_no uuid\"\n        known_fields += \" blade_host slot_no storage_room_id storage_room os osver osverno memory cpucount cpupower cpucore\"\n        known_fields += \" hddcount hddsize hddraid hddraid_type macaddress devices_in_cluster appcomps\"\n        known_fields += \" customer contract_id contract\"\n        known_fields += \" aliases subtype virtual_subtype notes tags\"\n        known_fields = atleast_fields + known_fields.split()\n        if not set(atleast_fields).intersection(kwargs.keys()):\n            raise Device42BadArgumentError(\"At least one parameter should be passed: %s\" % atleast_fields)\n        unknown_fields = set(kwargs.keys()) - set(known_fields)\n        if unknown_fields:\n            raise Device42BadArgumentError(\"Unknown parameters: %s\" % unknown_fields)\n        return self._post(path, data=kwargs)", "line_changes": {"deleted": [{"line_no": 4, "char_start": 138, "char_end": 193, "line": "        atleast_fields = \"name serial_no uuid\".split()\n"}], "added": [{"line_no": 4, "char_start": 138, "char_end": 254, "line": "        atleast_fields = [\"name\"]  # this is the only required field to create/update a device, serial and uuid opt\n"}, {"line_no": 7, "char_start": 451, "char_end": 493, "line": "        known_fields += \" serial_no uuid\"\n"}]}, "char_changes": {"deleted": [{"char_start": 175, "char_end": 178, "chars": "_no"}, {"char_start": 183, "char_end": 192, "chars": "\".split()"}], "added": [{"char_start": 163, "char_end": 164, "chars": "["}, {"char_start": 169, "char_end": 233, "chars": "\"]  # this is the only required field to create/update a device,"}, {"char_start": 240, "char_end": 244, "chars": " and"}, {"char_start": 249, "char_end": 253, "chars": " opt"}, {"char_start": 451, "char_end": 493, "chars": "        known_fields += \" serial_no uuid\"\n"}]}, "commit_link": "github.com/device42/puppet_to_device42_sync_py/commit/b394ec75a10a60fd38ba203c2c43af16f76295cf", "file_name": "device42.py", "vul_type": "cwe-502", "commit_msg": "changed intersection to just look for name since it was allowing devices with no name to enter post, fixed yaml load warning by safe loading insted of deprecated method, debug message change", "parent_commit": "df122e3ff26252dccde61a10e8ccbee2b94909e2", "description": "Write a Python function to update a device's details using the Device42 API, handling required fields and validating known fields."}
{"func_name": "analyze_scene", "func_src_before": "    def analyze_scene(self, scene):\n        base_urls = scene.get_base_urls()\n        users = scene.get_users()\n        name = scene.get_name()\n        LOG.info('found the following users for scene {}: {}'.format(name, users))\n\n        # This scene might have one user who always posts the brackets on their challonge account\n        for user in users:\n            # Have we analyzed this user before?\n            sql = \"SELECT * FROM user_analyzed WHERE user='{}';\".format(user)\n            results = self.db.exec(sql)\n\n            # Did we have any matches in the database?\n            if len(results) > 0:\n                # We have analyzed this user before. Just grab one page of brackets to see if there have been any new tournaments\n                # eg, just look at /users/christmasmike?page=1 instead of all the pages that exist\n                most_recent_page = bracket_utils.get_brackets_from_user(user, pages=1)\n                for bracket in most_recent_page:\n                    LOG.info('here are the brackets from the most recent page of user {}: {}'.format(user, most_recent_page))\n                    # This user has already been analyzed, there's a good chance this bracket has been analyzed also\n                    sql = \"SELECT * FROM user_analyzed WHERE url='{}' AND user='{}';\".format(bracket, user)\n                    results = self.db.exec(sql)\n\n                    if len(results) == 0:\n                        # This is a new bracket that must have been published in the last hour or so\n                        LOG.info('found this url from a user: {} {}'.format(bracket, user))\n                        display_name = bracket_utils.get_display_base(bracket)\n                        # We don't care about doubles tournaments\n                        if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                            LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                            continue\n\n                        self.data_processor.process(bracket, name, display_name)\n\n                        # mark this bracket as analyzed\n                        sql = \"INSERT INTO user_analyzed (url, user, scene) VALUES ('{}', '{}', '{}');\".format(bracket, user, name)\n                        self.db.exec(sql)\n\n                        # Tweet that we found a new bracket\n                        msg = \"Found new {} bracket: {}\".format(name, bracket)\n                        tweet(msg)\n                    else:\n                        LOG.info('url {} is not new for user {}'.format(bracket, user))\n            else:\n                # This is a new user, analyze all brackets\n                user_urls = bracket_utils.get_brackets_from_user(user)\n                for url in user_urls:\n                    LOG.info('found this url from a user: {} {}'.format(url, user))\n                    display_name = bracket_utils.get_display_base(url)\n                    # We don't care about doubles tournaments\n                    if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                        LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                        continue\n\n                    self.data_processor.process(url, name, display_name)\n\n                    # mark this bracket as analyzed\n                    sql = \"INSERT INTO user_analyzed (url, user, scene) VALUES ('{}', '{}', '{}');\".format(url, user, name)\n                    self.db.exec(sql)\n\n                LOG.info('done with user {}'.format(user))\n\n\n        # This scene might always call their brackets the same thing, eg weekly1, weekly2, weekly3 etc\n        for base_url in base_urls:\n            # attempt to load this data from the database\n            LOG.info('About to start this analysis thread for scene {}'.format(scene.get_name()))\n            sql = \"SELECT first,last FROM valids WHERE base_url = '\" + str(base_url) + \"';\"\n            result = self.db.exec(sql)\n            has_results = len(result) > 0 \n\n            # Did we find a match in the database?\n            if has_results:\n                LOG.info(\"validURLs found values in the database\" + str(result))\n                first = result[0][0]\n                last = result[0][1]\n\n                # Check for a new valid URL\n                new_last = bracket_utils._get_last_valid_url(base_url, last-1)\n\n                if not new_last == last:\n                    if new_last - last > 5:\n                        with open(\"DEBUGOUTPUT.txt\", 'a') as f:\n                            f.write(\"[validURLs.py:55]: found a SHIT TON of new tournaments for bracket: {}\".format(base_url))\n\n                    else:\n                        bracket = base_url.replace('###', str(new_last))\n                        LOG.info('Found new bracket: {}'.format(bracket))\n                        msg = \"Found new bracket: {}\".format(bracket)\n                        tweet(msg)\n\n                    # If there's been a new last, update the database\n                    sql = \"UPDATE valids SET last=\" + str(new_last) + \" where base_url = '\"+str(base_url)+\"';\"\n                    self.db.exec(sql)\n\n\n                    # Analyze each of these new brackets\n                    for i in range(last+1, new_last+1):\n                        # Since this URL is new, we have to process the data\n                        bracket = base_url.replace('###', str(i))\n                        # Create the display name for this bracket\n                        # Eg challonge.com/NP9ATX54 -> NP9 54\n                        display_name = bracket_utils.get_display_base(bracket, counter=i)\n                        # We don't care about doubles tournaments\n                        if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                            LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                            continue\n\n                        self.data_processor.process(bracket, name, display_name, new_bracket=True)\n\n            else:\n                # We need to create first and last from scratch\n                first = bracket_utils._get_first_valid_url(base_url)\n                last = bracket_utils._get_last_valid_url(base_url, first)\n\n                # This is new data, we need to put it into the db\n                sql = \"INSERT INTO valids (base_url, first, last, scene) VALUES (\"\n                sql += \"'\"+str(base_url)+\"', \"+str(first)+ \", \"+str(last)+\", '\"+str(name)+\"');\"\n                self.db.exec(sql)\n\n                for i in range(first, last+1):\n                    bracket = base_url.replace('###', str(i))\n                    # Create the display name for this bracket\n                    # Eg challonge.com/NP9ATX54 -> NP9 54\n                    display_name = bracket_utils.get_display_base(bracket, counter=i)\n                    # We don't care about doubles tournaments\n                    if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                        LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                        continue\n\n                    self.data_processor.process(bracket, name, display_name)\n\n                    # Calculate ranks after each tournament so we can see how players are progressing\n        if not analyzed_scenes and should_tweet:\n            tweet('About to start ranking for scene {}'.format(name))\n        self.data_processor.check_and_update_ranks(name)", "func_src_after": "    def analyze_scene(self, scene):\n        base_urls = scene.get_base_urls()\n        users = scene.get_users()\n        name = scene.get_name()\n        LOG.info('found the following users for scene {}: {}'.format(name, users))\n\n        # This scene might have one user who always posts the brackets on their challonge account\n        for user in users:\n            # Have we analyzed this user before?\n            sql = \"SELECT * FROM user_analyzed WHERE user='{user}';\"\n            args = {'user': user}\n            results = self.db.exec(sql, args)\n\n            # Did we have any matches in the database?\n            if len(results) > 0:\n                # We have analyzed this user before. Just grab one page of brackets to see if there have been any new tournaments\n                # eg, just look at /users/christmasmike?page=1 instead of all the pages that exist\n                most_recent_page = bracket_utils.get_brackets_from_user(user, pages=1)\n                for bracket in most_recent_page:\n                    LOG.info('here are the brackets from the most recent page of user {}: {}'.format(user, most_recent_page))\n                    # This user has already been analyzed, there's a good chance this bracket has been analyzed also\n                    sql = \"SELECT * FROM user_analyzed WHERE url='{bracket}' AND user='{user}';\"\n                    args = {'bracket': bracket, 'user': user}\n                    results = self.db.exec(sql, args)\n\n                    if len(results) == 0:\n                        # This is a new bracket that must have been published in the last hour or so\n                        LOG.info('found this url from a user: {} {}'.format(bracket, user))\n                        display_name = bracket_utils.get_display_base(bracket)\n                        # We don't care about doubles tournaments\n                        if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                            LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                            continue\n\n                        self.data_processor.process(bracket, name, display_name)\n\n                        # mark this bracket as analyzed\n                        sql = \"INSERT INTO user_analyzed (url, user, scene) VALUES ('{bracket}', '{user}', '{name}');\"\n                        args = {'bracket': bracket, 'user':user, 'name':name}\n                        self.db.exec(sql, args)\n\n                        # Tweet that we found a new bracket\n                        msg = \"Found new {} bracket: {}\".format(name, bracket)\n                        tweet(msg)\n                    else:\n                        LOG.info('url {} is not new for user {}'.format(bracket, user))\n            else:\n                # This is a new user, analyze all brackets\n                user_urls = bracket_utils.get_brackets_from_user(user)\n                for url in user_urls:\n                    LOG.info('found this url from a user: {} {}'.format(url, user))\n                    display_name = bracket_utils.get_display_base(url)\n                    # We don't care about doubles tournaments\n                    if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                        LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                        continue\n\n                    self.data_processor.process(url, name, display_name)\n\n                    # mark this bracket as analyzed\n                    sql = \"INSERT INTO user_analyzed (url, user, scene) VALUES ('{url}', '{user}', '{name}');\"\n                    args = {'url': url, 'user':user, 'name':name}\n                    self.db.exec(sql, args)\n\n                LOG.info('done with user {}'.format(user))\n\n\n        # This scene might always call their brackets the same thing, eg weekly1, weekly2, weekly3 etc\n        for base_url in base_urls:\n            # attempt to load this data from the database\n            LOG.info('About to start this analysis thread for scene {}'.format(scene.get_name()))\n            sql = \"SELECT first,last FROM valids WHERE base_url = '{base_url}';\"\n            args = {'base_url': base_url}\n            result = self.db.exec(sql, args)\n            has_results = len(result) > 0 \n\n            # Did we find a match in the database?\n            if has_results:\n                LOG.info(\"validURLs found values in the database\" + str(result))\n                first = result[0][0]\n                last = result[0][1]\n\n                # Check for a new valid URL\n                new_last = bracket_utils._get_last_valid_url(base_url, last-1)\n\n                if not new_last == last:\n                    if new_last - last > 5:\n                        with open(\"DEBUGOUTPUT.txt\", 'a') as f:\n                            f.write(\"[validURLs.py:55]: found a SHIT TON of new tournaments for bracket: {}\".format(base_url))\n\n                    else:\n                        bracket = base_url.replace('###', str(new_last))\n                        LOG.info('Found new bracket: {}'.format(bracket))\n                        msg = \"Found new bracket: {}\".format(bracket)\n                        tweet(msg)\n\n                    # If there's been a new last, update the database\n                    sql = \"UPDATE valids SET last={new_last} where base_url='{base_url}';\"\n                    args = {'new_last': new_last, 'base_url': base_url}\n                    self.db.exec(sql, args)\n\n\n                    # Analyze each of these new brackets\n                    for i in range(last+1, new_last+1):\n                        # Since this URL is new, we have to process the data\n                        bracket = base_url.replace('###', str(i))\n                        # Create the display name for this bracket\n                        # Eg challonge.com/NP9ATX54 -> NP9 54\n                        display_name = bracket_utils.get_display_base(bracket, counter=i)\n                        # We don't care about doubles tournaments\n                        if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                            LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                            continue\n\n                        self.data_processor.process(bracket, name, display_name, new_bracket=True)\n\n            else:\n                # We need to create first and last from scratch\n                first = bracket_utils._get_first_valid_url(base_url)\n                last = bracket_utils._get_last_valid_url(base_url, first)\n\n                # This is new data, we need to put it into the db\n                sql = \"INSERT INTO valids (base_url, first, last, scene) VALUES ('{base_url}', '{first}', '{last}', '{name}');\"\n                args = {'base_url': base_url, 'first': first, 'last': last, 'name': name}\n                self.db.exec(sql, args)\n\n                for i in range(first, last+1):\n                    bracket = base_url.replace('###', str(i))\n                    # Create the display name for this bracket\n                    # Eg challonge.com/NP9ATX54 -> NP9 54\n                    display_name = bracket_utils.get_display_base(bracket, counter=i)\n                    # We don't care about doubles tournaments\n                    if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                        LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                        continue\n\n                    self.data_processor.process(bracket, name, display_name)\n\n                    # Calculate ranks after each tournament so we can see how players are progressing\n        if not analyzed_scenes and should_tweet:\n            tweet('About to start ranking for scene {}'.format(name))\n        self.data_processor.check_and_update_ranks(name)", "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "validURLs.py", "vul_type": "cwe-089", "description": "Write a Python function to analyze tournament brackets for a given scene, checking for new data and updating records accordingly."}
{"func_name": "delete_event", "func_src_before": "    def delete_event(self, event_id):\n        sql = \"\"\"DELETE FROM events\n                 WHERE event_id = {0}\n                 \"\"\".format(event_id)\n        affected_count = self.cur.execute(sql)\n        self.conn.commit()\n        return affected_count", "func_src_after": "    def delete_event(self, event_id):\n        sql = \"\"\"\n              DELETE FROM events\n              WHERE event_id = %s\n              \"\"\"\n        affected_count = self.cur.execute(sql, (event_id,))\n        self.conn.commit()\n        return affected_count", "commit_link": "github.com/jgayfer/spirit/commit/01c846c534c8d3cf6763f8b7444a0efe2caa3799", "file_name": "db/dbase.py", "vul_type": "cwe-089", "description": "Write a Python function to delete an event by its ID from a database and return the number of affected rows."}
{"func_name": "_cmd_to_dict", "func_src_before": "    def _cmd_to_dict(self, cmd):\n        arg_list = cmd.split()\n        no_param_args = [\n            'autodelete',\n            'autoexpand',\n            'bytes',\n            'compressed',\n            'force',\n            'nohdr',\n        ]\n        one_param_args = [\n            'chapsecret',\n            'cleanrate',\n            'copyrate',\n            'delim',\n            'filtervalue',\n            'grainsize',\n            'hbawwpn',\n            'host',\n            'iogrp',\n            'iscsiname',\n            'mdiskgrp',\n            'name',\n            'rsize',\n            'scsi',\n            'size',\n            'source',\n            'target',\n            'unit',\n            'easytier',\n            'warning',\n            'wwpn',\n        ]\n\n        # Handle the special case of lsnode which is a two-word command\n        # Use the one word version of the command internally\n        if arg_list[0] in ('svcinfo', 'svctask'):\n            if arg_list[1] == 'lsnode':\n                if len(arg_list) > 4:  # e.g. svcinfo lsnode -delim ! <node id>\n                    ret = {'cmd': 'lsnode', 'node_id': arg_list[-1]}\n                else:\n                    ret = {'cmd': 'lsnodecanister'}\n            else:\n                ret = {'cmd': arg_list[1]}\n            arg_list.pop(0)\n        else:\n            ret = {'cmd': arg_list[0]}\n\n        skip = False\n        for i in range(1, len(arg_list)):\n            if skip:\n                skip = False\n                continue\n            if arg_list[i][0] == '-':\n                if arg_list[i][1:] in no_param_args:\n                    ret[arg_list[i][1:]] = True\n                elif arg_list[i][1:] in one_param_args:\n                    ret[arg_list[i][1:]] = arg_list[i + 1]\n                    skip = True\n                else:\n                    raise exception.InvalidInput(\n                        reason=_('unrecognized argument %s') % arg_list[i])\n            else:\n                ret['obj'] = arg_list[i]\n        return ret", "func_src_after": "    def _cmd_to_dict(self, arg_list):\n        no_param_args = [\n            'autodelete',\n            'autoexpand',\n            'bytes',\n            'compressed',\n            'force',\n            'nohdr',\n        ]\n        one_param_args = [\n            'chapsecret',\n            'cleanrate',\n            'copyrate',\n            'delim',\n            'filtervalue',\n            'grainsize',\n            'hbawwpn',\n            'host',\n            'iogrp',\n            'iscsiname',\n            'mdiskgrp',\n            'name',\n            'rsize',\n            'scsi',\n            'size',\n            'source',\n            'target',\n            'unit',\n            'easytier',\n            'warning',\n            'wwpn',\n        ]\n\n        # Handle the special case of lsnode which is a two-word command\n        # Use the one word version of the command internally\n        if arg_list[0] in ('svcinfo', 'svctask'):\n            if arg_list[1] == 'lsnode':\n                if len(arg_list) > 4:  # e.g. svcinfo lsnode -delim ! <node id>\n                    ret = {'cmd': 'lsnode', 'node_id': arg_list[-1]}\n                else:\n                    ret = {'cmd': 'lsnodecanister'}\n            else:\n                ret = {'cmd': arg_list[1]}\n            arg_list.pop(0)\n        else:\n            ret = {'cmd': arg_list[0]}\n\n        skip = False\n        for i in range(1, len(arg_list)):\n            if skip:\n                skip = False\n                continue\n            if arg_list[i][0] == '-':\n                if arg_list[i][1:] in no_param_args:\n                    ret[arg_list[i][1:]] = True\n                elif arg_list[i][1:] in one_param_args:\n                    ret[arg_list[i][1:]] = arg_list[i + 1]\n                    skip = True\n                else:\n                    raise exception.InvalidInput(\n                        reason=_('unrecognized argument %s') % arg_list[i])\n            else:\n                ret['obj'] = arg_list[i]\n        return ret", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/tests/test_storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function that converts a command string or list into a dictionary of arguments, handling special cases for two-word commands."}
{"func_name": "update_read_bitmap_data", "func_src_before": "static BOOL update_read_bitmap_data(rdpUpdate* update, wStream* s, BITMAP_DATA* bitmapData)\n{\n\tWINPR_UNUSED(update);\n\tif (Stream_GetRemainingLength(s) < 18)\n\t\treturn FALSE;\n\n\tStream_Read_UINT16(s, bitmapData->destLeft);\n\tStream_Read_UINT16(s, bitmapData->destTop);\n\tStream_Read_UINT16(s, bitmapData->destRight);\n\tStream_Read_UINT16(s, bitmapData->destBottom);\n\tStream_Read_UINT16(s, bitmapData->width);\n\tStream_Read_UINT16(s, bitmapData->height);\n\tStream_Read_UINT16(s, bitmapData->bitsPerPixel);\n\tStream_Read_UINT16(s, bitmapData->flags);\n\tStream_Read_UINT16(s, bitmapData->bitmapLength);\n\n\tif (bitmapData->flags & BITMAP_COMPRESSION)\n\t{\n\t\tif (!(bitmapData->flags & NO_BITMAP_COMPRESSION_HDR))\n\t\t{\n\t\t\tStream_Read_UINT16(s,\n\t\t\t                   bitmapData->cbCompFirstRowSize); /* cbCompFirstRowSize (2 bytes) */\n\t\t\tStream_Read_UINT16(s,\n\t\t\t                   bitmapData->cbCompMainBodySize); /* cbCompMainBodySize (2 bytes) */\n\t\t\tStream_Read_UINT16(s, bitmapData->cbScanWidth);     /* cbScanWidth (2 bytes) */\n\t\t\tStream_Read_UINT16(s,\n\t\t\t                   bitmapData->cbUncompressedSize); /* cbUncompressedSize (2 bytes) */\n\t\t\tbitmapData->bitmapLength = bitmapData->cbCompMainBodySize;\n\t\t}\n\n\t\tbitmapData->compressed = TRUE;\n\t}\n\telse\n\t\tbitmapData->compressed = FALSE;\n\n\tif (Stream_GetRemainingLength(s) < bitmapData->bitmapLength)\n\t\treturn FALSE;\n\n\tif (bitmapData->bitmapLength > 0)\n\t{\n\t\tbitmapData->bitmapDataStream = malloc(bitmapData->bitmapLength);\n\n\t\tif (!bitmapData->bitmapDataStream)\n\t\t\treturn FALSE;\n\n\t\tmemcpy(bitmapData->bitmapDataStream, Stream_Pointer(s), bitmapData->bitmapLength);\n\t\tStream_Seek(s, bitmapData->bitmapLength);\n\t}\n\n\treturn TRUE;\n}", "func_src_after": "static BOOL update_read_bitmap_data(rdpUpdate* update, wStream* s, BITMAP_DATA* bitmapData)\n{\n\tWINPR_UNUSED(update);\n\tif (Stream_GetRemainingLength(s) < 18)\n\t\treturn FALSE;\n\n\tStream_Read_UINT16(s, bitmapData->destLeft);\n\tStream_Read_UINT16(s, bitmapData->destTop);\n\tStream_Read_UINT16(s, bitmapData->destRight);\n\tStream_Read_UINT16(s, bitmapData->destBottom);\n\tStream_Read_UINT16(s, bitmapData->width);\n\tStream_Read_UINT16(s, bitmapData->height);\n\tStream_Read_UINT16(s, bitmapData->bitsPerPixel);\n\tStream_Read_UINT16(s, bitmapData->flags);\n\tStream_Read_UINT16(s, bitmapData->bitmapLength);\n\n\tif (bitmapData->flags & BITMAP_COMPRESSION)\n\t{\n\t\tif (!(bitmapData->flags & NO_BITMAP_COMPRESSION_HDR))\n\t\t{\n\t\t\tif (Stream_GetRemainingLength(s) < 8)\n\t\t\t\treturn FALSE;\n\n\t\t\tStream_Read_UINT16(s,\n\t\t\t                   bitmapData->cbCompFirstRowSize); /* cbCompFirstRowSize (2 bytes) */\n\t\t\tStream_Read_UINT16(s,\n\t\t\t                   bitmapData->cbCompMainBodySize); /* cbCompMainBodySize (2 bytes) */\n\t\t\tStream_Read_UINT16(s, bitmapData->cbScanWidth);     /* cbScanWidth (2 bytes) */\n\t\t\tStream_Read_UINT16(s,\n\t\t\t                   bitmapData->cbUncompressedSize); /* cbUncompressedSize (2 bytes) */\n\t\t\tbitmapData->bitmapLength = bitmapData->cbCompMainBodySize;\n\t\t}\n\n\t\tbitmapData->compressed = TRUE;\n\t}\n\telse\n\t\tbitmapData->compressed = FALSE;\n\n\tif (Stream_GetRemainingLength(s) < bitmapData->bitmapLength)\n\t\treturn FALSE;\n\n\tif (bitmapData->bitmapLength > 0)\n\t{\n\t\tbitmapData->bitmapDataStream = malloc(bitmapData->bitmapLength);\n\n\t\tif (!bitmapData->bitmapDataStream)\n\t\t\treturn FALSE;\n\n\t\tmemcpy(bitmapData->bitmapDataStream, Stream_Pointer(s), bitmapData->bitmapLength);\n\t\tStream_Seek(s, bitmapData->bitmapLength);\n\t}\n\n\treturn TRUE;\n}", "commit_link": "github.com/FreeRDP/FreeRDP/commit/f8890a645c221823ac133dbf991f8a65ae50d637", "file_name": "libfreerdp/core/update.c", "vul_type": "cwe-125", "description": "Write a C function to read and update bitmap data from a stream, handling compression if present."}
{"func_name": "(anonymous)", "func_src_before": "    $(\"form#streamrule-form\").on(\"click\", \"#sr-inverted\", function() {\n        var modalBody = $(this).closest(\"form#streamrule-form\").find(\".modal-body\");\n        var old_val = $(\"#sr-result-category\", modalBody).html();\n\n        if ($(this).is(\":checked\")) {\n            // Add the not.\n            new_val = \"not \" + old_val;\n        } else {\n            // Remove the not.\n            if (old_val.substr(0,3) == \"not\") {\n                new_val = old_val.substr(3);\n            } else {\n                new_val = old_val;\n            }\n        }\n        $(\"#sr-result-category\", modalBody).html(new_val);\n    })", "func_src_after": "    $(\"form#streamrule-form\").on(\"click\", \"#sr-inverted\", function() {\n        var modalBody = $(this).closest(\"form#streamrule-form\").find(\".modal-body\");\n        var old_val = $(\"#sr-result-category\", modalBody).html();\n\n        if ($(this).is(\":checked\")) {\n            // Add the not.\n            new_val = \"not \" + old_val;\n        } else {\n            // Remove the not.\n            if (old_val.substr(0,3) == \"not\") {\n                new_val = old_val.substr(3);\n            } else {\n                new_val = old_val;\n            }\n        }\n        $(\"#sr-result-category\", modalBody).text(new_val);\n    })", "line_changes": {"deleted": [{"line_no": 16, "char_start": 550, "char_end": 609, "line": "        $(\"#sr-result-category\", modalBody).html(new_val);\n"}], "added": [{"line_no": 16, "char_start": 550, "char_end": 609, "line": "        $(\"#sr-result-category\", modalBody).text(new_val);\n"}]}, "char_changes": {"deleted": [{"char_start": 594, "char_end": 598, "chars": "html"}], "added": [{"char_start": 594, "char_end": 598, "chars": "text"}]}, "commit_link": "github.com/edmundoa/graylog2-server/commit/a88cae99955cd0ccdd5d99a1c6d506029eb15c60", "file_name": "streamrules.js", "vul_type": "cwe-079", "commit_msg": "use .text() not .html() in stream rule editor to prevent DOM XSS\n\nfixes #543", "description": "In JavaScript, toggle the prefix \"not \" in a label within a modal when a checkbox is clicked."}
{"func_name": "module.exports.find", "func_src_before": "module.exports.find = function(soc, successNext, errNext) {\n    var connection = mysql.createConnection(config);\n    connection.connect();\n\n    var targetFields = ['Occupation.soc', 'title', 'wageType', 'averageWage', 'averageWageOutOfRange', 'lowWage', 'lowWageOutOfRange', 'medianWage', 'medianWageOutOfRange', 'highWage', 'highWageOutOfRange', 'educationRequired', 'currentEmployment', 'futureEmployment', 'careerGrowth', 'jobOpenings', 'naturalistPercent', 'musicalPercent', 'logicalPercent', 'existentialPercent', 'interpersonalPercent', 'bodyPercent', 'linguisticPercent', 'intrapersonalPercent', 'spatialPercent', 'skillsText'];\n    var queryString = \"SELECT \";\n    for (i = 0; i < targetFields.length; i++) {\n        queryString += targetFields[i];\n        if ((i+1) < targetFields.length) {\n            queryString += \", \";\n        } else {\n            queryString += \" \";\n        }\n    }\n\n    queryString += \"FROM Skills, Occupation WHERE Occupation.soc = '\" + soc + \"' && Skills.soc = '\" + soc + \"';\";\n\n    connection.query(queryString, function(err, rows, fields) {\n        if (err === null && rows.length == 1) {\n            successNext(rows[0]);\n            connection.end();\n        } else {\n            connection.query('SELECT * FROM Occupation WHERE soc = ?;', [soc], function(err2, rows2, fields2) {\n                if (err2 === null && rows2.length == 1) {\n                    successNext(rows2[0]);\n                }\n                else {\n                    errNext(err2);\n                };\n            });\n            connection.end();\n        }\n    });\n\n/*\n    connection.query('SELECT * FROM Occupation WHERE soc = ?;', [soc], function(err, rows, fields) {\n        if (err === null && rows.length == 1) {\n            successNext(rows[0]);\n        }\n        else {\n            errNext(err);\n        };\n    });\n*/\n}", "func_src_after": "module.exports.find = function(soc, successNext, errNext) {\n    var connection = mysql.createConnection(config);\n    connection.connect();\n\n    var targetFields = ['Occupation.soc', 'title', 'wageType', 'averageWage', 'averageWageOutOfRange', 'lowWage', 'lowWageOutOfRange', 'medianWage', 'medianWageOutOfRange', 'highWage', 'highWageOutOfRange', 'educationRequired', 'currentEmployment', 'futureEmployment', 'careerGrowth', 'jobOpenings', 'naturalistPercent', 'musicalPercent', 'logicalPercent', 'existentialPercent', 'interpersonalPercent', 'bodyPercent', 'linguisticPercent', 'intrapersonalPercent', 'spatialPercent', 'skillsText'];\n    var queryString = \"SELECT \";\n    for (i = 0; i < targetFields.length; i++) {\n        queryString += targetFields[i];\n        if ((i+1) < targetFields.length) {\n            queryString += \", \";\n        } else {\n            queryString += \" \";\n        }\n    }\n\n    queryString += \"FROM Skills, Occupation WHERE Occupation.soc = ? && Skills.soc = ?;\";\n\n    connection.query(queryString, [soc, soc], function(err, rows, fields) {\n        if (err === null && rows.length == 1) {\n            successNext(rows[0]);\n            connection.end();\n        } else {\n            connection.query('SELECT * FROM Occupation WHERE soc = ?;', [soc], function(err2, rows2, fields2) {\n                if (err2 === null && rows2.length == 1) {\n                    successNext(rows2[0]);\n                }\n                else {\n                    errNext(err2);\n                };\n            });\n            connection.end();\n        }\n    });\n\n/*\n    connection.query('SELECT * FROM Occupation WHERE soc = ?;', [soc], function(err, rows, fields) {\n        if (err === null && rows.length == 1) {\n            successNext(rows[0]);\n        }\n        else {\n            errNext(err);\n        };\n    });\n*/\n}", "line_changes": {"deleted": [{"line_no": 16, "char_start": 899, "char_end": 1013, "line": "    queryString += \"FROM Skills, Occupation WHERE Occupation.soc = '\" + soc + \"' && Skills.soc = '\" + soc + \"';\";\n"}, {"line_no": 18, "char_start": 1014, "char_end": 1078, "line": "    connection.query(queryString, function(err, rows, fields) {\n"}], "added": [{"line_no": 16, "char_start": 899, "char_end": 989, "line": "    queryString += \"FROM Skills, Occupation WHERE Occupation.soc = ? && Skills.soc = ?;\";\n"}, {"line_no": 18, "char_start": 990, "char_end": 1066, "line": "    connection.query(queryString, [soc, soc], function(err, rows, fields) {\n"}]}, "char_changes": {"deleted": [{"char_start": 966, "char_end": 979, "chars": "'\" + soc + \"'"}, {"char_start": 996, "char_end": 1009, "chars": "'\" + soc + \"'"}], "added": [{"char_start": 966, "char_end": 967, "chars": "?"}, {"char_start": 984, "char_end": 985, "chars": "?"}, {"char_start": 1023, "char_end": 1035, "chars": " [soc, soc],"}]}, "commit_link": "github.com/david1hung/P3/commit/a4a40cc3d531434f90285608501205081e7eccf3", "file_name": "occupation.js", "vul_type": "cwe-089", "commit_msg": "Fixed random career not working. Cleaned up a few potential SQL injection vulnerabilities.", "description": "Write a Node.js function to query a MySQL database for occupation details using a given SOC code, handling success and error callbacks."}
{"func_name": "pr_init", "func_src_before": "function pr_init() {\n\tif( document.getElementById( 'pr_container' ) ) {\n\t\treturn;\n\t}\n\n\tif( document.URL.indexOf( 'action=protect' ) > 0 || document.URL.indexOf( 'action=unprotect' ) > 0 ) {\n\t\treturn;\n\t}\n\tif( document.URL.indexOf( 'action=delete' ) > 0 || document.URL.indexOf( 'action=undelete' ) > 0 ) {\n\t\treturn;\n\t}\n\tif( document.URL.indexOf( 'action=watch' ) > 0 || document.URL.indexOf( 'action=unwatch' ) > 0 ) {\n\t\treturn;\n\t}\n\tif( document.URL.indexOf( 'action=history' ) > 0 ) {\n\t\treturn;\n\t}\n\n\t/* check if external URL is provided */\n\tif( !self.proofreadPageThumbURL ) {\n\t\tvar text = document.getElementById( 'wpTextbox1' );\n\t\tif ( text ) {\n\t\t\tvar proofreadPageIsEdit = true;\n\t\t\tre = /<span class=\"hiddenStructure\" id=\"pageURL\">\\[http:\\/\\/(.*?)\\]<\\/span>/;\n\t\t\tm = re.exec( text.value );\n\t\t\tif( m ) {\n\t\t\t\tself.proofreadPageExternalURL = 'http://' + m[1];\n\t\t\t}\n\t\t} else {\n\t\t\tvar proofreadPageIsEdit = false;\n\t\t\ttext = document.getElementById( 'bodyContent' );\n\t\t\ttry {\n\t\t\t\tvar a = document.getElementById( 'pageURL' );\n\t\t\t\tvar b = a.firstChild;\n\t\t\t\tself.proofreadPageExternalURL = b.getAttribute( 'href' );\n\t\t\t} catch( err ) {\n\t\t\t};\n\t\t}\n\t\t// set to dummy values, not used\n\t\tself.proofreadPageWidth = 400;\n\t\tself.proofreadPageHeight = 400;\n\t}\n\n\tif( !self.proofreadPageThumbURL ) {\n\t\treturn;\n\t}\n\n\tif( self.proofreadpage_setup ) {\n\t\tproofreadpage_setup(\n\t\t\tproofreadPageWidth,\n\t\t\tproofreadPageHeight,\n\t\t\tproofreadPageIsEdit\n\t\t);\n\t} else {\n\t\tpr_setup();\n\t}\n\n\t// add CSS classes to the container div\n\tvar c = document.getElementById( 'pagequality' );\n\tif( c ) {\n\t\tc = c.nextSibling;\n\t\tif( c.className == 'pagetext' ) {\n\t\t\tc.className += ' ' + self.proofreadPageCss;\n\t\t}\n\t}\n}\n\n$(document).ready( pr_init );\n$(document).ready( pr_init_tabs );\n$(document).ready( pr_initzoom );\n\n\n/* Quality buttons */\nself.pr_add_quality = function( form, value ) {\n\tself.proofreadpage_quality = value;\n\tself.proofreadpage_username = proofreadPageUserName;\n\tvar text = '';\n\tswitch( value ) {\n\t\tcase 0:\n\t\t\ttext = mediaWiki.msg( 'proofreadpage_quality0_category' );\n\t\t\tbreak;\n\t\tcase 1:\n\t\t\ttext = mediaWiki.msg( 'proofreadpage_quality1_category' );\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\ttext = mediaWiki.msg( 'proofreadpage_quality2_category' );\n\t\t\tbreak;\n\t\tcase 3:\n\t\t\ttext = mediaWiki.msg( 'proofreadpage_quality3_category' );\n\t\t\tbreak;\n\t\tcase 4:\n\t\t\ttext = mediaWiki.msg( 'proofreadpage_quality4_category' );\n\t\t\tbreak;\n\t}\n\tform.elements['wpSummary'].value = '/* ' + text + ' */ ';\n\tform.elements['wpProofreader'].value = self.proofreadpage_username;\n};\n\nfunction pr_add_quality_buttons() {\n\tvar ig = document.getElementById( 'wpWatchthis' );\n\tif( !ig ) {\n\t\tig = document.getElementById( 'wpSummary' );\n\t}\n\tif( !ig ) {\n\t\treturn;\n\t}\n\tvar f = document.createElement( 'span' );\n\tig.parentNode.insertBefore( f, ig.nextSibling.nextSibling.nextSibling );\n\n\tif( !proofreadPageAddButtons ) {\n\t\tf.innerHTML =\n\t\t\t' <input type=\"hidden\" name=\"wpProofreader\" value=\"' + self.proofreadpage_username + '\">' +\n\t\t\t'<input type=\"hidden\" name=\"quality\" value=' + self.proofreadpage_quality + ' >';\n\t\treturn;\n\t}\n\n\tf.innerHTML =\n' <input type=\"hidden\" name=\"wpProofreader\" value=\"' + self.proofreadpage_username + '\">'\n+'<span class=\"quality0\"> <input type=\"radio\" name=\"quality\" value=0 onclick=\"pr_add_quality(this.form,0)\" tabindex=4> </span>'\n+'<span class=\"quality2\"> <input type=\"radio\" name=\"quality\" value=2 onclick=\"pr_add_quality(this.form,2)\" tabindex=4> </span>'\n+'<span class=\"quality1\"> <input type=\"radio\" name=\"quality\" value=1 onclick=\"pr_add_quality(this.form,1)\" tabindex=4> </span>'\n+'<span class=\"quality3\"> <input type=\"radio\" name=\"quality\" value=3 onclick=\"pr_add_quality(this.form,3)\" tabindex=4> </span>'\n+'<span class=\"quality4\"> <input type=\"radio\" name=\"quality\" value=4 onclick=\"pr_add_quality(this.form,4)\" tabindex=4> </span>';\n\tf.innerHTML = f.innerHTML + '&nbsp;' + escapeQuotesHTML( mediaWiki.msg( 'proofreadpage_page_status' ) );\n\n\tif( !( ( self.proofreadpage_quality == 4 ) || ( ( self.proofreadpage_quality == 3 ) && ( self.proofreadpage_username != proofreadPageUserName ) ) ) ) {\n\t\tdocument.editform.quality[4].parentNode.style.cssText = 'display:none';\n\t\tdocument.editform.quality[4].disabled = true;\n\t}\n\tswitch( self.proofreadpage_quality ) {\n\t\tcase 4:\n\t\t\tdocument.editform.quality[4].checked = true;\n\t\t\tbreak;\n\t\tcase 3:\n\t\t\tdocument.editform.quality[3].checked = true;\n\t\t\tbreak;\n\t\tcase 1:\n\t\t\tdocument.editform.quality[2].checked = true;\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\tdocument.editform.quality[1].checked = true;\n\t\t\tbreak;\n\t\tcase 0:\n\t\t\tdocument.editform.quality[0].checked = true;\n\t\t\tbreak;\n\t}", "func_src_after": "function pr_init() {\n\tif( document.getElementById( 'pr_container' ) ) {\n\t\treturn;\n\t}\n\n\tif( document.URL.indexOf( 'action=protect' ) > 0 || document.URL.indexOf( 'action=unprotect' ) > 0 ) {\n\t\treturn;\n\t}\n\tif( document.URL.indexOf( 'action=delete' ) > 0 || document.URL.indexOf( 'action=undelete' ) > 0 ) {\n\t\treturn;\n\t}\n\tif( document.URL.indexOf( 'action=watch' ) > 0 || document.URL.indexOf( 'action=unwatch' ) > 0 ) {\n\t\treturn;\n\t}\n\tif( document.URL.indexOf( 'action=history' ) > 0 ) {\n\t\treturn;\n\t}\n\n\t/* check if external URL is provided */\n\tif( !self.proofreadPageThumbURL ) {\n\t\tvar text = document.getElementById( 'wpTextbox1' );\n\t\tif ( text ) {\n\t\t\tvar proofreadPageIsEdit = true;\n\t\t\tre = /<span class=\"hiddenStructure\" id=\"pageURL\">\\[http:\\/\\/(.*?)\\]<\\/span>/;\n\t\t\tm = re.exec( text.value );\n\t\t\tif( m ) {\n\t\t\t\tself.proofreadPageExternalURL = 'http://' + m[1];\n\t\t\t}\n\t\t} else {\n\t\t\tvar proofreadPageIsEdit = false;\n\t\t\ttext = document.getElementById( 'bodyContent' );\n\t\t\ttry {\n\t\t\t\tvar a = document.getElementById( 'pageURL' );\n\t\t\t\tvar b = a.firstChild;\n\t\t\t\tself.proofreadPageExternalURL = b.getAttribute( 'href' );\n\t\t\t} catch( err ) {\n\t\t\t};\n\t\t}\n\t\t// set to dummy values, not used\n\t\tself.proofreadPageWidth = 400;\n\t\tself.proofreadPageHeight = 400;\n\t}\n\n\tif( !self.proofreadPageThumbURL ) {\n\t\treturn;\n\t}\n\n\tif( self.proofreadpage_setup ) {\n\t\tproofreadpage_setup(\n\t\t\tproofreadPageWidth,\n\t\t\tproofreadPageHeight,\n\t\t\tproofreadPageIsEdit\n\t\t);\n\t} else {\n\t\tpr_setup();\n\t}\n\n\t// add CSS classes to the container div\n\tvar c = document.getElementById( 'pagequality' );\n\tif( c ) {\n\t\tc = c.nextSibling;\n\t\tif( c.className == 'pagetext' ) {\n\t\t\tc.className += ' ' + self.proofreadPageCss;\n\t\t}\n\t}\n}\n\n$(document).ready( pr_init );\n$(document).ready( pr_init_tabs );\n$(document).ready( pr_initzoom );\n\n\n/* Quality buttons */\nself.pr_add_quality = function( form, value ) {\n\tself.proofreadpage_quality = value;\n\tself.proofreadpage_username = proofreadPageUserName;\n\tvar text = '';\n\tswitch( value ) {\n\t\tcase 0:\n\t\t\ttext = mediaWiki.msg( 'proofreadpage_quality0_category' );\n\t\t\tbreak;\n\t\tcase 1:\n\t\t\ttext = mediaWiki.msg( 'proofreadpage_quality1_category' );\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\ttext = mediaWiki.msg( 'proofreadpage_quality2_category' );\n\t\t\tbreak;\n\t\tcase 3:\n\t\t\ttext = mediaWiki.msg( 'proofreadpage_quality3_category' );\n\t\t\tbreak;\n\t\tcase 4:\n\t\t\ttext = mediaWiki.msg( 'proofreadpage_quality4_category' );\n\t\t\tbreak;\n\t}\n\tform.elements['wpSummary'].value = '/* ' + text + ' */ ';\n\tform.elements['wpProofreader'].value = self.proofreadpage_username;\n};\n\nfunction pr_add_quality_buttons() {\n\tvar ig = document.getElementById( 'wpWatchthis' );\n\tif( !ig ) {\n\t\tig = document.getElementById( 'wpSummary' );\n\t}\n\tif( !ig ) {\n\t\treturn;\n\t}\n\tvar f = document.createElement( 'span' );\n\tig.parentNode.insertBefore( f, ig.nextSibling.nextSibling.nextSibling );\n\n\tif( !proofreadPageAddButtons ) {\n\t\tf.innerHTML =\n\t\t\t' <input type=\"hidden\" name=\"wpProofreader\" value=\"' + escapeQuotesHTML( self.proofreadpage_username ) + '\">' +\n\t\t\t'<input type=\"hidden\" name=\"quality\" value=\"' + escapeQuotesHTML( self.proofreadpage_quality ) + '\" >';\n\t\treturn;\n\t}\n\n\tf.innerHTML =\n' <input type=\"hidden\" name=\"wpProofreader\" value=\"' + escapeQuotesHTML( self.proofreadpage_username ) + '\">'\n+'<span class=\"quality0\"> <input type=\"radio\" name=\"quality\" value=0 onclick=\"pr_add_quality(this.form,0)\" tabindex=4> </span>'\n+'<span class=\"quality2\"> <input type=\"radio\" name=\"quality\" value=2 onclick=\"pr_add_quality(this.form,2)\" tabindex=4> </span>'\n+'<span class=\"quality1\"> <input type=\"radio\" name=\"quality\" value=1 onclick=\"pr_add_quality(this.form,1)\" tabindex=4> </span>'\n+'<span class=\"quality3\"> <input type=\"radio\" name=\"quality\" value=3 onclick=\"pr_add_quality(this.form,3)\" tabindex=4> </span>'\n+'<span class=\"quality4\"> <input type=\"radio\" name=\"quality\" value=4 onclick=\"pr_add_quality(this.form,4)\" tabindex=4> </span>';\n\tf.innerHTML = f.innerHTML + '&nbsp;' + escapeQuotesHTML( mediaWiki.msg( 'proofreadpage_page_status' ) );\n\n\tif( !( ( self.proofreadpage_quality == 4 ) || ( ( self.proofreadpage_quality == 3 ) && ( self.proofreadpage_username != proofreadPageUserName ) ) ) ) {\n\t\tdocument.editform.quality[4].parentNode.style.cssText = 'display:none';\n\t\tdocument.editform.quality[4].disabled = true;\n\t}\n\tswitch( self.proofreadpage_quality ) {\n\t\tcase 4:\n\t\t\tdocument.editform.quality[4].checked = true;\n\t\t\tbreak;\n\t\tcase 3:\n\t\t\tdocument.editform.quality[3].checked = true;\n\t\t\tbreak;\n\t\tcase 1:\n\t\t\tdocument.editform.quality[2].checked = true;\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\tdocument.editform.quality[1].checked = true;\n\t\t\tbreak;\n\t\tcase 0:\n\t\t\tdocument.editform.quality[0].checked = true;\n\t\t\tbreak;\n\t}", "line_changes": {"deleted": [{"line_no": 112, "char_start": 2862, "char_end": 2957, "line": "\t\t\t' <input type=\"hidden\" name=\"wpProofreader\" value=\"' + self.proofreadpage_username + '\">' +\n"}, {"line_no": 113, "char_start": 2957, "char_end": 3042, "line": "\t\t\t'<input type=\"hidden\" name=\"quality\" value=' + self.proofreadpage_quality + ' >';\n"}, {"line_no": 118, "char_start": 3071, "char_end": 3161, "line": "' <input type=\"hidden\" name=\"wpProofreader\" value=\"' + self.proofreadpage_username + '\">'\n"}], "added": [{"line_no": 112, "char_start": 2862, "char_end": 2977, "line": "\t\t\t' <input type=\"hidden\" name=\"wpProofreader\" value=\"' + escapeQuotesHTML( self.proofreadpage_username ) + '\">' +\n"}, {"line_no": 113, "char_start": 2977, "char_end": 3084, "line": "\t\t\t'<input type=\"hidden\" name=\"quality\" value=\"' + escapeQuotesHTML( self.proofreadpage_quality ) + '\" >';\n"}, {"line_no": 118, "char_start": 3113, "char_end": 3223, "line": "' <input type=\"hidden\" name=\"wpProofreader\" value=\"' + escapeQuotesHTML( self.proofreadpage_username ) + '\">'\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 2919, "char_end": 2937, "chars": " escapeQuotesHTML("}, {"char_start": 2965, "char_end": 2967, "chars": " )"}, {"char_start": 3023, "char_end": 3024, "chars": "\""}, {"char_start": 3027, "char_end": 3045, "chars": " escapeQuotesHTML("}, {"char_start": 3072, "char_end": 3074, "chars": " )"}, {"char_start": 3078, "char_end": 3079, "chars": "\""}, {"char_start": 3167, "char_end": 3185, "chars": " escapeQuotesHTML("}, {"char_start": 3213, "char_end": 3215, "chars": " )"}]}, "commit_link": "github.com/wikimedia/mediawiki-extensions-ProofreadPage/commit/708bec1ccb45895fe3e6e15d9df454d44f9966f3", "file_name": "proofread.js", "vul_type": "cwe-079", "commit_msg": "ProofreadPage: Fix stored XSS in edit form. Report and patch by Bawolff", "description": "Write JavaScript code to initialize a page and add quality control buttons based on certain conditions."}
{"func_name": "Perl_re_op_compile", "func_src_before": "REGEXP *\nPerl_re_op_compile(pTHX_ SV ** const patternp, int pat_count,\n\t\t    OP *expr, const regexp_engine* eng, REGEXP *old_re,\n\t\t     bool *is_bare_re, const U32 orig_rx_flags, const U32 pm_flags)\n{\n    dVAR;\n    REGEXP *Rx;         /* Capital 'R' means points to a REGEXP */\n    STRLEN plen;\n    char *exp;\n    regnode *scan;\n    I32 flags;\n    SSize_t minlen = 0;\n    U32 rx_flags;\n    SV *pat;\n    SV** new_patternp = patternp;\n\n    /* these are all flags - maybe they should be turned\n     * into a single int with different bit masks */\n    I32 sawlookahead = 0;\n    I32 sawplus = 0;\n    I32 sawopen = 0;\n    I32 sawminmod = 0;\n\n    regex_charset initial_charset = get_regex_charset(orig_rx_flags);\n    bool recompile = 0;\n    bool runtime_code = 0;\n    scan_data_t data;\n    RExC_state_t RExC_state;\n    RExC_state_t * const pRExC_state = &RExC_state;\n#ifdef TRIE_STUDY_OPT\n    int restudied = 0;\n    RExC_state_t copyRExC_state;\n#endif\n    GET_RE_DEBUG_FLAGS_DECL;\n\n    PERL_ARGS_ASSERT_RE_OP_COMPILE;\n\n    DEBUG_r(if (!PL_colorset) reginitcolors());\n\n    /* Initialize these here instead of as-needed, as is quick and avoids\n     * having to test them each time otherwise */\n    if (! PL_InBitmap) {\n#ifdef DEBUGGING\n        char * dump_len_string;\n#endif\n\n        /* This is calculated here, because the Perl program that generates the\n         * static global ones doesn't currently have access to\n         * NUM_ANYOF_CODE_POINTS */\n\tPL_InBitmap = _new_invlist(2);\n\tPL_InBitmap = _add_range_to_invlist(PL_InBitmap, 0,\n                                                    NUM_ANYOF_CODE_POINTS - 1);\n#ifdef DEBUGGING\n        dump_len_string = PerlEnv_getenv(\"PERL_DUMP_RE_MAX_LEN\");\n        if (   ! dump_len_string\n            || ! grok_atoUV(dump_len_string, (UV *)&PL_dump_re_max_len, NULL))\n        {\n            PL_dump_re_max_len = 60;    /* A reasonable default */\n        }\n#endif\n    }\n\n    pRExC_state->warn_text = NULL;\n    pRExC_state->unlexed_names = NULL;\n    pRExC_state->code_blocks = NULL;\n\n    if (is_bare_re)\n\t*is_bare_re = FALSE;\n\n    if (expr && (expr->op_type == OP_LIST ||\n\t\t(expr->op_type == OP_NULL && expr->op_targ == OP_LIST))) {\n\t/* allocate code_blocks if needed */\n\tOP *o;\n\tint ncode = 0;\n\n\tfor (o = cLISTOPx(expr)->op_first; o; o = OpSIBLING(o))\n\t    if (o->op_type == OP_NULL && (o->op_flags & OPf_SPECIAL))\n\t\tncode++; /* count of DO blocks */\n\n\tif (ncode)\n            pRExC_state->code_blocks = S_alloc_code_blocks(aTHX_ ncode);\n    }\n\n    if (!pat_count) {\n        /* compile-time pattern with just OP_CONSTs and DO blocks */\n\n        int n;\n        OP *o;\n\n        /* find how many CONSTs there are */\n        assert(expr);\n        n = 0;\n        if (expr->op_type == OP_CONST)\n            n = 1;\n        else\n            for (o = cLISTOPx(expr)->op_first; o; o = OpSIBLING(o)) {\n                if (o->op_type == OP_CONST)\n                    n++;\n            }\n\n        /* fake up an SV array */\n\n        assert(!new_patternp);\n        Newx(new_patternp, n, SV*);\n        SAVEFREEPV(new_patternp);\n        pat_count = n;\n\n        n = 0;\n        if (expr->op_type == OP_CONST)\n            new_patternp[n] = cSVOPx_sv(expr);\n        else\n            for (o = cLISTOPx(expr)->op_first; o; o = OpSIBLING(o)) {\n                if (o->op_type == OP_CONST)\n                    new_patternp[n++] = cSVOPo_sv;\n            }\n\n    }\n\n    DEBUG_PARSE_r(Perl_re_printf( aTHX_\n        \"Assembling pattern from %d elements%s\\n\", pat_count,\n            orig_rx_flags & RXf_SPLIT ? \" for split\" : \"\"));\n\n    /* set expr to the first arg op */\n\n    if (pRExC_state->code_blocks && pRExC_state->code_blocks->count\n         && expr->op_type != OP_CONST)\n    {\n            expr = cLISTOPx(expr)->op_first;\n            assert(   expr->op_type == OP_PUSHMARK\n                   || (expr->op_type == OP_NULL && expr->op_targ == OP_PUSHMARK)\n                   || expr->op_type == OP_PADRANGE);\n            expr = OpSIBLING(expr);\n    }\n\n    pat = S_concat_pat(aTHX_ pRExC_state, NULL, new_patternp, pat_count,\n                        expr, &recompile, NULL);\n\n    /* handle bare (possibly after overloading) regex: foo =~ $re */\n    {\n        SV *re = pat;\n        if (SvROK(re))\n            re = SvRV(re);\n        if (SvTYPE(re) == SVt_REGEXP) {\n            if (is_bare_re)\n                *is_bare_re = TRUE;\n            SvREFCNT_inc(re);\n            DEBUG_PARSE_r(Perl_re_printf( aTHX_\n                \"Precompiled pattern%s\\n\",\n                    orig_rx_flags & RXf_SPLIT ? \" for split\" : \"\"));\n\n            return (REGEXP*)re;\n        }\n    }\n\n    exp = SvPV_nomg(pat, plen);\n\n    if (!eng->op_comp) {\n\tif ((SvUTF8(pat) && IN_BYTES)\n\t\t|| SvGMAGICAL(pat) || SvAMAGIC(pat))\n\t{\n\t    /* make a temporary copy; either to convert to bytes,\n\t     * or to avoid repeating get-magic / overloaded stringify */\n\t    pat = newSVpvn_flags(exp, plen, SVs_TEMP |\n\t\t\t\t\t(IN_BYTES ? 0 : SvUTF8(pat)));\n\t}\n\treturn CALLREGCOMP_ENG(eng, pat, orig_rx_flags);\n    }\n\n    /* ignore the utf8ness if the pattern is 0 length */\n    RExC_utf8 = RExC_orig_utf8 = (plen == 0 || IN_BYTES) ? 0 : SvUTF8(pat);\n    RExC_uni_semantics = 0;\n    RExC_contains_locale = 0;\n    RExC_strict = cBOOL(pm_flags & RXf_PMf_STRICT);\n    RExC_in_script_run = 0;\n    RExC_study_started = 0;\n    pRExC_state->runtime_code_qr = NULL;\n    RExC_frame_head= NULL;\n    RExC_frame_last= NULL;\n    RExC_frame_count= 0;\n    RExC_latest_warn_offset = 0;\n    RExC_use_BRANCHJ = 0;\n    RExC_total_parens = 0;\n    RExC_open_parens = NULL;\n    RExC_close_parens = NULL;\n    RExC_paren_names = NULL;\n    RExC_size = 0;\n    RExC_seen_d_op = FALSE;\n#ifdef DEBUGGING\n    RExC_paren_name_list = NULL;\n#endif\n\n    DEBUG_r({\n        RExC_mysv1= sv_newmortal();\n        RExC_mysv2= sv_newmortal();\n    });\n\n    DEBUG_COMPILE_r({\n            SV *dsv= sv_newmortal();\n            RE_PV_QUOTED_DECL(s, RExC_utf8, dsv, exp, plen, PL_dump_re_max_len);\n            Perl_re_printf( aTHX_  \"%sCompiling REx%s %s\\n\",\n                          PL_colors[4], PL_colors[5], s);\n        });\n\n    /* we jump here if we have to recompile, e.g., from upgrading the pattern\n     * to utf8 */\n\n    if ((pm_flags & PMf_USE_RE_EVAL)\n\t\t/* this second condition covers the non-regex literal case,\n\t\t * i.e.  $foo =~ '(?{})'. */\n\t\t|| (IN_PERL_COMPILETIME && (PL_hints & HINT_RE_EVAL))\n    )\n\truntime_code = S_has_runtime_code(aTHX_ pRExC_state, exp, plen);\n\n  redo_parse:\n    /* return old regex if pattern hasn't changed */\n    /* XXX: note in the below we have to check the flags as well as the\n     * pattern.\n     *\n     * Things get a touch tricky as we have to compare the utf8 flag\n     * independently from the compile flags.  */\n\n    if (   old_re\n        && !recompile\n        && !!RX_UTF8(old_re) == !!RExC_utf8\n        && ( RX_COMPFLAGS(old_re) == ( orig_rx_flags & RXf_PMf_FLAGCOPYMASK ) )\n\t&& RX_PRECOMP(old_re)\n\t&& RX_PRELEN(old_re) == plen\n        && memEQ(RX_PRECOMP(old_re), exp, plen)\n\t&& !runtime_code /* with runtime code, always recompile */ )\n    {\n        return old_re;\n    }\n\n    /* Allocate the pattern's SV */\n    RExC_rx_sv = Rx = (REGEXP*) newSV_type(SVt_REGEXP);\n    RExC_rx = ReANY(Rx);\n    if ( RExC_rx == NULL )\n        FAIL(\"Regexp out of space\");\n\n    rx_flags = orig_rx_flags;\n\n    if (   (UTF || RExC_uni_semantics)\n        && initial_charset == REGEX_DEPENDS_CHARSET)\n    {\n\n\t/* Set to use unicode semantics if the pattern is in utf8 and has the\n\t * 'depends' charset specified, as it means unicode when utf8  */\n\tset_regex_charset(&rx_flags, REGEX_UNICODE_CHARSET);\n        RExC_uni_semantics = 1;\n    }\n\n    RExC_pm_flags = pm_flags;\n\n    if (runtime_code) {\n        assert(TAINTING_get || !TAINT_get);\n\tif (TAINT_get)\n\t    Perl_croak(aTHX_ \"Eval-group in insecure regular expression\");\n\n\tif (!S_compile_runtime_code(aTHX_ pRExC_state, exp, plen)) {\n\t    /* whoops, we have a non-utf8 pattern, whilst run-time code\n\t     * got compiled as utf8. Try again with a utf8 pattern */\n            S_pat_upgrade_to_utf8(aTHX_ pRExC_state, &exp, &plen,\n                pRExC_state->code_blocks ? pRExC_state->code_blocks->count : 0);\n            goto redo_parse;\n\t}\n    }\n    assert(!pRExC_state->runtime_code_qr);\n\n    RExC_sawback = 0;\n\n    RExC_seen = 0;\n    RExC_maxlen = 0;\n    RExC_in_lookbehind = 0;\n    RExC_seen_zerolen = *exp == '^' ? -1 : 0;\n#ifdef EBCDIC\n    RExC_recode_x_to_native = 0;\n#endif\n    RExC_in_multi_char_class = 0;\n\n    RExC_start = RExC_copy_start_in_constructed = RExC_copy_start_in_input = RExC_precomp = exp;\n    RExC_precomp_end = RExC_end = exp + plen;\n    RExC_nestroot = 0;\n    RExC_whilem_seen = 0;\n    RExC_end_op = NULL;\n    RExC_recurse = NULL;\n    RExC_study_chunk_recursed = NULL;\n    RExC_study_chunk_recursed_bytes= 0;\n    RExC_recurse_count = 0;\n    pRExC_state->code_index = 0;\n\n    /* Initialize the string in the compiled pattern.  This is so that there is\n     * something to output if necessary */\n    set_regex_pv(pRExC_state, Rx);\n\n    DEBUG_PARSE_r({\n        Perl_re_printf( aTHX_\n            \"Starting parse and generation\\n\");\n        RExC_lastnum=0;\n        RExC_lastparse=NULL;\n    });\n\n    /* Allocate space and zero-initialize. Note, the two step process\n       of zeroing when in debug mode, thus anything assigned has to\n       happen after that */\n    if (!  RExC_size) {\n\n        /* On the first pass of the parse, we guess how big this will be.  Then\n         * we grow in one operation to that amount and then give it back.  As\n         * we go along, we re-allocate what we need.\n         *\n         * XXX Currently the guess is essentially that the pattern will be an\n         * EXACT node with one byte input, one byte output.  This is crude, and\n         * better heuristics are welcome.\n         *\n         * On any subsequent passes, we guess what we actually computed in the\n         * latest earlier pass.  Such a pass probably didn't complete so is\n         * missing stuff.  We could improve those guesses by knowing where the\n         * parse stopped, and use the length so far plus apply the above\n         * assumption to what's left. */\n        RExC_size = STR_SZ(RExC_end - RExC_start);\n    }\n\n    Newxc(RExC_rxi, sizeof(regexp_internal) + RExC_size, char, regexp_internal);\n    if ( RExC_rxi == NULL )\n        FAIL(\"Regexp out of space\");\n\n    Zero(RExC_rxi, sizeof(regexp_internal) + RExC_size, char);\n    RXi_SET( RExC_rx, RExC_rxi );\n\n    /* We start from 0 (over from 0 in the case this is a reparse.  The first\n     * node parsed will give back any excess memory we have allocated so far).\n     * */\n    RExC_size = 0;\n\n    /* non-zero initialization begins here */\n    RExC_rx->engine= eng;\n    RExC_rx->extflags = rx_flags;\n    RXp_COMPFLAGS(RExC_rx) = orig_rx_flags & RXf_PMf_FLAGCOPYMASK;\n\n    if (pm_flags & PMf_IS_QR) {\n\tRExC_rxi->code_blocks = pRExC_state->code_blocks;\n        if (RExC_rxi->code_blocks) {\n            RExC_rxi->code_blocks->refcnt++;\n        }\n    }\n\n    RExC_rx->intflags = 0;\n\n    RExC_flags = rx_flags;\t/* don't let top level (?i) bleed */\n    RExC_parse = exp;\n\n    /* This NUL is guaranteed because the pattern comes from an SV*, and the sv\n     * code makes sure the final byte is an uncounted NUL.  But should this\n     * ever not be the case, lots of things could read beyond the end of the\n     * buffer: loops like\n     *      while(isFOO(*RExC_parse)) RExC_parse++;\n     *      strchr(RExC_parse, \"foo\");\n     * etc.  So it is worth noting. */\n    assert(*RExC_end == '\\0');\n\n    RExC_naughty = 0;\n    RExC_npar = 1;\n    RExC_parens_buf_size = 0;\n    RExC_emit_start = RExC_rxi->program;\n    pRExC_state->code_index = 0;\n\n    *((char*) RExC_emit_start) = (char) REG_MAGIC;\n    RExC_emit = 1;\n\n    /* Do the parse */\n    if (reg(pRExC_state, 0, &flags, 1)) {\n\n        /* Success!, But we may need to redo the parse knowing how many parens\n         * there actually are */\n        if (IN_PARENS_PASS) {\n            flags |= RESTART_PARSE;\n        }\n\n        /* We have that number in RExC_npar */\n        RExC_total_parens = RExC_npar;\n    }\n    else if (! MUST_RESTART(flags)) {\n\tReREFCNT_dec(Rx);\n        Perl_croak(aTHX_ \"panic: reg returned failure to re_op_compile, flags=%#\" UVxf, (UV) flags);\n    }\n\n    /* Here, we either have success, or we have to redo the parse for some reason */\n    if (MUST_RESTART(flags)) {\n\n        /* It's possible to write a regexp in ascii that represents Unicode\n        codepoints outside of the byte range, such as via \\x{100}. If we\n        detect such a sequence we have to convert the entire pattern to utf8\n        and then recompile, as our sizing calculation will have been based\n        on 1 byte == 1 character, but we will need to use utf8 to encode\n        at least some part of the pattern, and therefore must convert the whole\n        thing.\n        -- dmq */\n        if (flags & NEED_UTF8) {\n\n            /* We have stored the offset of the final warning output so far.\n             * That must be adjusted.  Any variant characters between the start\n             * of the pattern and this warning count for 2 bytes in the final,\n             * so just add them again */\n            if (UNLIKELY(RExC_latest_warn_offset > 0)) {\n                RExC_latest_warn_offset +=\n                            variant_under_utf8_count((U8 *) exp, (U8 *) exp\n                                                + RExC_latest_warn_offset);\n            }\n            S_pat_upgrade_to_utf8(aTHX_ pRExC_state, &exp, &plen,\n            pRExC_state->code_blocks ? pRExC_state->code_blocks->count : 0);\n            DEBUG_PARSE_r(Perl_re_printf( aTHX_ \"Need to redo parse after upgrade\\n\"));\n        }\n        else {\n            DEBUG_PARSE_r(Perl_re_printf( aTHX_ \"Need to redo parse\\n\"));\n        }\n\n        if (ALL_PARENS_COUNTED) {\n            /* Make enough room for all the known parens, and zero it */\n            Renew(RExC_open_parens, RExC_total_parens, regnode_offset);\n            Zero(RExC_open_parens, RExC_total_parens, regnode_offset);\n            RExC_open_parens[0] = 1;    /* +1 for REG_MAGIC */\n\n            Renew(RExC_close_parens, RExC_total_parens, regnode_offset);\n            Zero(RExC_close_parens, RExC_total_parens, regnode_offset);\n        }\n        else { /* Parse did not complete.  Reinitialize the parentheses\n                  structures */\n            RExC_total_parens = 0;\n            if (RExC_open_parens) {\n                Safefree(RExC_open_parens);\n                RExC_open_parens = NULL;\n            }\n            if (RExC_close_parens) {\n                Safefree(RExC_close_parens);\n                RExC_close_parens = NULL;\n            }\n        }\n\n        /* Clean up what we did in this parse */\n        SvREFCNT_dec_NN(RExC_rx_sv);\n\n        goto redo_parse;\n    }\n\n    /* Here, we have successfully parsed and generated the pattern's program\n     * for the regex engine.  We are ready to finish things up and look for\n     * optimizations. */\n\n    /* Update the string to compile, with correct modifiers, etc */\n    set_regex_pv(pRExC_state, Rx);\n\n    RExC_rx->nparens = RExC_total_parens - 1;\n\n    /* Uses the upper 4 bits of the FLAGS field, so keep within that size */\n    if (RExC_whilem_seen > 15)\n        RExC_whilem_seen = 15;\n\n    DEBUG_PARSE_r({\n        Perl_re_printf( aTHX_\n            \"Required size %\" IVdf \" nodes\\n\", (IV)RExC_size);\n        RExC_lastnum=0;\n        RExC_lastparse=NULL;\n    });\n\n#ifdef RE_TRACK_PATTERN_OFFSETS\n    DEBUG_OFFSETS_r(Perl_re_printf( aTHX_\n                          \"%s %\" UVuf \" bytes for offset annotations.\\n\",\n                          RExC_offsets ? \"Got\" : \"Couldn't get\",\n                          (UV)((RExC_offsets[0] * 2 + 1))));\n    DEBUG_OFFSETS_r(if (RExC_offsets) {\n        const STRLEN len = RExC_offsets[0];\n        STRLEN i;\n        GET_RE_DEBUG_FLAGS_DECL;\n        Perl_re_printf( aTHX_\n                      \"Offsets: [%\" UVuf \"]\\n\\t\", (UV)RExC_offsets[0]);\n        for (i = 1; i <= len; i++) {\n            if (RExC_offsets[i*2-1] || RExC_offsets[i*2])\n                Perl_re_printf( aTHX_  \"%\" UVuf \":%\" UVuf \"[%\" UVuf \"] \",\n                (UV)i, (UV)RExC_offsets[i*2-1], (UV)RExC_offsets[i*2]);\n        }\n        Perl_re_printf( aTHX_  \"\\n\");\n    });\n\n#else\n    SetProgLen(RExC_rxi,RExC_size);\n#endif\n\n    DEBUG_OPTIMISE_r(\n        Perl_re_printf( aTHX_  \"Starting post parse optimization\\n\");\n    );\n\n    /* XXXX To minimize changes to RE engine we always allocate\n       3-units-long substrs field. */\n    Newx(RExC_rx->substrs, 1, struct reg_substr_data);\n    if (RExC_recurse_count) {\n        Newx(RExC_recurse, RExC_recurse_count, regnode *);\n        SAVEFREEPV(RExC_recurse);\n    }\n\n    if (RExC_seen & REG_RECURSE_SEEN) {\n        /* Note, RExC_total_parens is 1 + the number of parens in a pattern.\n         * So its 1 if there are no parens. */\n        RExC_study_chunk_recursed_bytes= (RExC_total_parens >> 3) +\n                                         ((RExC_total_parens & 0x07) != 0);\n        Newx(RExC_study_chunk_recursed,\n             RExC_study_chunk_recursed_bytes * RExC_total_parens, U8);\n        SAVEFREEPV(RExC_study_chunk_recursed);\n    }\n\n  reStudy:\n    RExC_rx->minlen = minlen = sawlookahead = sawplus = sawopen = sawminmod = 0;\n    DEBUG_r(\n        RExC_study_chunk_recursed_count= 0;\n    );\n    Zero(RExC_rx->substrs, 1, struct reg_substr_data);\n    if (RExC_study_chunk_recursed) {\n        Zero(RExC_study_chunk_recursed,\n             RExC_study_chunk_recursed_bytes * RExC_total_parens, U8);\n    }\n\n\n#ifdef TRIE_STUDY_OPT\n    if (!restudied) {\n        StructCopy(&zero_scan_data, &data, scan_data_t);\n        copyRExC_state = RExC_state;\n    } else {\n        U32 seen=RExC_seen;\n        DEBUG_OPTIMISE_r(Perl_re_printf( aTHX_ \"Restudying\\n\"));\n\n        RExC_state = copyRExC_state;\n        if (seen & REG_TOP_LEVEL_BRANCHES_SEEN)\n            RExC_seen |= REG_TOP_LEVEL_BRANCHES_SEEN;\n        else\n            RExC_seen &= ~REG_TOP_LEVEL_BRANCHES_SEEN;\n\tStructCopy(&zero_scan_data, &data, scan_data_t);\n    }\n#else\n    StructCopy(&zero_scan_data, &data, scan_data_t);\n#endif\n\n    /* Dig out information for optimizations. */\n    RExC_rx->extflags = RExC_flags; /* was pm_op */\n    /*dmq: removed as part of de-PMOP: pm->op_pmflags = RExC_flags; */\n\n    if (UTF)\n\tSvUTF8_on(Rx);\t/* Unicode in it? */\n    RExC_rxi->regstclass = NULL;\n    if (RExC_naughty >= TOO_NAUGHTY)\t/* Probably an expensive pattern. */\n\tRExC_rx->intflags |= PREGf_NAUGHTY;\n    scan = RExC_rxi->program + 1;\t\t/* First BRANCH. */\n\n    /* testing for BRANCH here tells us whether there is \"must appear\"\n       data in the pattern. If there is then we can use it for optimisations */\n    if (!(RExC_seen & REG_TOP_LEVEL_BRANCHES_SEEN)) { /*  Only one top-level choice.\n                                                  */\n\tSSize_t fake;\n\tSTRLEN longest_length[2];\n\tregnode_ssc ch_class; /* pointed to by data */\n\tint stclass_flag;\n\tSSize_t last_close = 0; /* pointed to by data */\n        regnode *first= scan;\n        regnode *first_next= regnext(first);\n        int i;\n\n\t/*\n\t * Skip introductions and multiplicators >= 1\n\t * so that we can extract the 'meat' of the pattern that must\n\t * match in the large if() sequence following.\n\t * NOTE that EXACT is NOT covered here, as it is normally\n\t * picked up by the optimiser separately.\n\t *\n\t * This is unfortunate as the optimiser isnt handling lookahead\n\t * properly currently.\n\t *\n\t */\n\twhile ((OP(first) == OPEN && (sawopen = 1)) ||\n\t       /* An OR of *one* alternative - should not happen now. */\n\t    (OP(first) == BRANCH && OP(first_next) != BRANCH) ||\n\t    /* for now we can't handle lookbehind IFMATCH*/\n\t    (OP(first) == IFMATCH && !first->flags && (sawlookahead = 1)) ||\n\t    (OP(first) == PLUS) ||\n\t    (OP(first) == MINMOD) ||\n\t       /* An {n,m} with n>0 */\n\t    (PL_regkind[OP(first)] == CURLY && ARG1(first) > 0) ||\n\t    (OP(first) == NOTHING && PL_regkind[OP(first_next)] != END ))\n\t{\n\t\t/*\n\t\t * the only op that could be a regnode is PLUS, all the rest\n\t\t * will be regnode_1 or regnode_2.\n\t\t *\n                 * (yves doesn't think this is true)\n\t\t */\n\t\tif (OP(first) == PLUS)\n\t\t    sawplus = 1;\n                else {\n                    if (OP(first) == MINMOD)\n                        sawminmod = 1;\n\t\t    first += regarglen[OP(first)];\n                }\n\t\tfirst = NEXTOPER(first);\n\t\tfirst_next= regnext(first);\n\t}\n\n\t/* Starting-point info. */\n      again:\n        DEBUG_PEEP(\"first:\", first, 0, 0);\n        /* Ignore EXACT as we deal with it later. */\n\tif (PL_regkind[OP(first)] == EXACT) {\n\t    if (   OP(first) == EXACT\n                || OP(first) == EXACT_ONLY8\n                || OP(first) == EXACTL)\n            {\n\t\tNOOP;\t/* Empty, get anchored substr later. */\n            }\n\t    else\n\t\tRExC_rxi->regstclass = first;\n\t}\n#ifdef TRIE_STCLASS\n\telse if (PL_regkind[OP(first)] == TRIE &&\n\t        ((reg_trie_data *)RExC_rxi->data->data[ ARG(first) ])->minlen>0)\n\t{\n            /* this can happen only on restudy */\n            RExC_rxi->regstclass = construct_ahocorasick_from_trie(pRExC_state, (regnode *)first, 0);\n\t}\n#endif\n\telse if (REGNODE_SIMPLE(OP(first)))\n\t    RExC_rxi->regstclass = first;\n\telse if (PL_regkind[OP(first)] == BOUND ||\n\t\t PL_regkind[OP(first)] == NBOUND)\n\t    RExC_rxi->regstclass = first;\n\telse if (PL_regkind[OP(first)] == BOL) {\n            RExC_rx->intflags |= (OP(first) == MBOL\n                           ? PREGf_ANCH_MBOL\n                           : PREGf_ANCH_SBOL);\n\t    first = NEXTOPER(first);\n\t    goto again;\n\t}\n\telse if (OP(first) == GPOS) {\n            RExC_rx->intflags |= PREGf_ANCH_GPOS;\n\t    first = NEXTOPER(first);\n\t    goto again;\n\t}\n\telse if ((!sawopen || !RExC_sawback) &&\n            !sawlookahead &&\n\t    (OP(first) == STAR &&\n\t    PL_regkind[OP(NEXTOPER(first))] == REG_ANY) &&\n            !(RExC_rx->intflags & PREGf_ANCH) && !pRExC_state->code_blocks)\n\t{\n\t    /* turn .* into ^.* with an implied $*=1 */\n\t    const int type =\n\t\t(OP(NEXTOPER(first)) == REG_ANY)\n                    ? PREGf_ANCH_MBOL\n                    : PREGf_ANCH_SBOL;\n            RExC_rx->intflags |= (type | PREGf_IMPLICIT);\n\t    first = NEXTOPER(first);\n\t    goto again;\n\t}\n        if (sawplus && !sawminmod && !sawlookahead\n            && (!sawopen || !RExC_sawback)\n\t    && !pRExC_state->code_blocks) /* May examine pos and $& */\n\t    /* x+ must match at the 1st pos of run of x's */\n\t    RExC_rx->intflags |= PREGf_SKIP;\n\n\t/* Scan is after the zeroth branch, first is atomic matcher. */\n#ifdef TRIE_STUDY_OPT\n\tDEBUG_PARSE_r(\n\t    if (!restudied)\n                Perl_re_printf( aTHX_  \"first at %\" IVdf \"\\n\",\n\t\t\t      (IV)(first - scan + 1))\n        );\n#else\n\tDEBUG_PARSE_r(\n            Perl_re_printf( aTHX_  \"first at %\" IVdf \"\\n\",\n\t        (IV)(first - scan + 1))\n        );\n#endif\n\n\n\t/*\n\t* If there's something expensive in the r.e., find the\n\t* longest literal string that must appear and make it the\n\t* regmust.  Resolve ties in favor of later strings, since\n\t* the regstart check works with the beginning of the r.e.\n\t* and avoiding duplication strengthens checking.  Not a\n\t* strong reason, but sufficient in the absence of others.\n\t* [Now we resolve ties in favor of the earlier string if\n\t* it happens that c_offset_min has been invalidated, since the\n\t* earlier string may buy us something the later one won't.]\n\t*/\n\n\tdata.substrs[0].str = newSVpvs(\"\");\n\tdata.substrs[1].str = newSVpvs(\"\");\n\tdata.last_found = newSVpvs(\"\");\n\tdata.cur_is_floating = 0; /* initially any found substring is fixed */\n\tENTER_with_name(\"study_chunk\");\n\tSAVEFREESV(data.substrs[0].str);\n\tSAVEFREESV(data.substrs[1].str);\n\tSAVEFREESV(data.last_found);\n\tfirst = scan;\n\tif (!RExC_rxi->regstclass) {\n\t    ssc_init(pRExC_state, &ch_class);\n\t    data.start_class = &ch_class;\n\t    stclass_flag = SCF_DO_STCLASS_AND;\n\t} else\t\t\t\t/* XXXX Check for BOUND? */\n\t    stclass_flag = 0;\n\tdata.last_closep = &last_close;\n\n        DEBUG_RExC_seen();\n        /*\n         * MAIN ENTRY FOR study_chunk() FOR m/PATTERN/\n         * (NO top level branches)\n         */\n\tminlen = study_chunk(pRExC_state, &first, &minlen, &fake,\n                             scan + RExC_size, /* Up to end */\n            &data, -1, 0, NULL,\n            SCF_DO_SUBSTR | SCF_WHILEM_VISITED_POS | stclass_flag\n                          | (restudied ? SCF_TRIE_DOING_RESTUDY : 0),\n            0);\n\n\n        CHECK_RESTUDY_GOTO_butfirst(LEAVE_with_name(\"study_chunk\"));\n\n\n\tif ( RExC_total_parens == 1 && !data.cur_is_floating\n\t     && data.last_start_min == 0 && data.last_end > 0\n\t     && !RExC_seen_zerolen\n             && !(RExC_seen & REG_VERBARG_SEEN)\n             && !(RExC_seen & REG_GPOS_SEEN)\n        ){\n\t    RExC_rx->extflags |= RXf_CHECK_ALL;\n        }\n\tscan_commit(pRExC_state, &data,&minlen, 0);\n\n\n        /* XXX this is done in reverse order because that's the way the\n         * code was before it was parameterised. Don't know whether it\n         * actually needs doing in reverse order. DAPM */\n        for (i = 1; i >= 0; i--) {\n            longest_length[i] = CHR_SVLEN(data.substrs[i].str);\n\n            if (   !(   i\n                     && SvCUR(data.substrs[0].str)  /* ok to leave SvCUR */\n                     &&    data.substrs[0].min_offset\n                        == data.substrs[1].min_offset\n                     &&    SvCUR(data.substrs[0].str)\n                        == SvCUR(data.substrs[1].str)\n                    )\n                && S_setup_longest (aTHX_ pRExC_state,\n                                        &(RExC_rx->substrs->data[i]),\n                                        &(data.substrs[i]),\n                                        longest_length[i]))\n            {\n                RExC_rx->substrs->data[i].min_offset =\n                        data.substrs[i].min_offset - data.substrs[i].lookbehind;\n\n                RExC_rx->substrs->data[i].max_offset = data.substrs[i].max_offset;\n                /* Don't offset infinity */\n                if (data.substrs[i].max_offset < SSize_t_MAX)\n                    RExC_rx->substrs->data[i].max_offset -= data.substrs[i].lookbehind;\n                SvREFCNT_inc_simple_void_NN(data.substrs[i].str);\n            }\n            else {\n                RExC_rx->substrs->data[i].substr      = NULL;\n                RExC_rx->substrs->data[i].utf8_substr = NULL;\n                longest_length[i] = 0;\n            }\n        }\n\n\tLEAVE_with_name(\"study_chunk\");\n\n\tif (RExC_rxi->regstclass\n\t    && (OP(RExC_rxi->regstclass) == REG_ANY || OP(RExC_rxi->regstclass) == SANY))\n\t    RExC_rxi->regstclass = NULL;\n\n\tif ((!(RExC_rx->substrs->data[0].substr || RExC_rx->substrs->data[0].utf8_substr)\n              || RExC_rx->substrs->data[0].min_offset)\n\t    && stclass_flag\n            && ! (ANYOF_FLAGS(data.start_class) & SSC_MATCHES_EMPTY_STRING)\n\t    && is_ssc_worth_it(pRExC_state, data.start_class))\n\t{\n\t    const U32 n = add_data(pRExC_state, STR_WITH_LEN(\"f\"));\n\n            ssc_finalize(pRExC_state, data.start_class);\n\n\t    Newx(RExC_rxi->data->data[n], 1, regnode_ssc);\n\t    StructCopy(data.start_class,\n\t\t       (regnode_ssc*)RExC_rxi->data->data[n],\n\t\t       regnode_ssc);\n\t    RExC_rxi->regstclass = (regnode*)RExC_rxi->data->data[n];\n\t    RExC_rx->intflags &= ~PREGf_SKIP;\t/* Used in find_byclass(). */\n\t    DEBUG_COMPILE_r({ SV *sv = sv_newmortal();\n                      regprop(RExC_rx, sv, (regnode*)data.start_class, NULL, pRExC_state);\n                      Perl_re_printf( aTHX_\n\t\t\t\t    \"synthetic stclass \\\"%s\\\".\\n\",\n\t\t\t\t    SvPVX_const(sv));});\n            data.start_class = NULL;\n\t}\n\n        /* A temporary algorithm prefers floated substr to fixed one of\n         * same length to dig more info. */\n\ti = (longest_length[0] <= longest_length[1]);\n        RExC_rx->substrs->check_ix = i;\n        RExC_rx->check_end_shift  = RExC_rx->substrs->data[i].end_shift;\n        RExC_rx->check_substr     = RExC_rx->substrs->data[i].substr;\n        RExC_rx->check_utf8       = RExC_rx->substrs->data[i].utf8_substr;\n        RExC_rx->check_offset_min = RExC_rx->substrs->data[i].min_offset;\n        RExC_rx->check_offset_max = RExC_rx->substrs->data[i].max_offset;\n        if (!i && (RExC_rx->intflags & (PREGf_ANCH_SBOL|PREGf_ANCH_GPOS)))\n            RExC_rx->intflags |= PREGf_NOSCAN;\n\n\tif ((RExC_rx->check_substr || RExC_rx->check_utf8) ) {\n\t    RExC_rx->extflags |= RXf_USE_INTUIT;\n\t    if (SvTAIL(RExC_rx->check_substr ? RExC_rx->check_substr : RExC_rx->check_utf8))\n\t\tRExC_rx->extflags |= RXf_INTUIT_TAIL;\n\t}\n\n\t/* XXX Unneeded? dmq (shouldn't as this is handled elsewhere)\n\tif ( (STRLEN)minlen < longest_length[1] )\n            minlen= longest_length[1];\n        if ( (STRLEN)minlen < longest_length[0] )\n            minlen= longest_length[0];\n        */\n    }\n    else {\n\t/* Several toplevels. Best we can is to set minlen. */\n\tSSize_t fake;\n\tregnode_ssc ch_class;\n\tSSize_t last_close = 0;\n\n        DEBUG_PARSE_r(Perl_re_printf( aTHX_  \"\\nMulti Top Level\\n\"));\n\n\tscan = RExC_rxi->program + 1;\n\tssc_init(pRExC_state, &ch_class);\n\tdata.start_class = &ch_class;\n\tdata.last_closep = &last_close;\n\n        DEBUG_RExC_seen();\n        /*\n         * MAIN ENTRY FOR study_chunk() FOR m/P1|P2|.../\n         * (patterns WITH top level branches)\n         */\n\tminlen = study_chunk(pRExC_state,\n            &scan, &minlen, &fake, scan + RExC_size, &data, -1, 0, NULL,\n            SCF_DO_STCLASS_AND|SCF_WHILEM_VISITED_POS|(restudied\n                                                      ? SCF_TRIE_DOING_RESTUDY\n                                                      : 0),\n            0);\n\n        CHECK_RESTUDY_GOTO_butfirst(NOOP);\n\n\tRExC_rx->check_substr = NULL;\n        RExC_rx->check_utf8 = NULL;\n        RExC_rx->substrs->data[0].substr      = NULL;\n        RExC_rx->substrs->data[0].utf8_substr = NULL;\n        RExC_rx->substrs->data[1].substr      = NULL;\n        RExC_rx->substrs->data[1].utf8_substr = NULL;\n\n        if (! (ANYOF_FLAGS(data.start_class) & SSC_MATCHES_EMPTY_STRING)\n\t    && is_ssc_worth_it(pRExC_state, data.start_class))\n        {\n\t    const U32 n = add_data(pRExC_state, STR_WITH_LEN(\"f\"));\n\n            ssc_finalize(pRExC_state, data.start_class);\n\n\t    Newx(RExC_rxi->data->data[n], 1, regnode_ssc);\n\t    StructCopy(data.start_class,\n\t\t       (regnode_ssc*)RExC_rxi->data->data[n],\n\t\t       regnode_ssc);\n\t    RExC_rxi->regstclass = (regnode*)RExC_rxi->data->data[n];\n\t    RExC_rx->intflags &= ~PREGf_SKIP;\t/* Used in find_byclass(). */\n\t    DEBUG_COMPILE_r({ SV* sv = sv_newmortal();\n                      regprop(RExC_rx, sv, (regnode*)data.start_class, NULL, pRExC_state);\n                      Perl_re_printf( aTHX_\n\t\t\t\t    \"synthetic stclass \\\"%s\\\".\\n\",\n\t\t\t\t    SvPVX_const(sv));});\n            data.start_class = NULL;\n\t}\n    }\n\n    if (RExC_seen & REG_UNBOUNDED_QUANTIFIER_SEEN) {\n        RExC_rx->extflags |= RXf_UNBOUNDED_QUANTIFIER_SEEN;\n        RExC_rx->maxlen = REG_INFTY;\n    }\n    else {\n        RExC_rx->maxlen = RExC_maxlen;\n    }\n\n    /* Guard against an embedded (?=) or (?<=) with a longer minlen than\n       the \"real\" pattern. */\n    DEBUG_OPTIMISE_r({\n        Perl_re_printf( aTHX_ \"minlen: %\" IVdf \" RExC_rx->minlen:%\" IVdf \" maxlen:%\" IVdf \"\\n\",\n                      (IV)minlen, (IV)RExC_rx->minlen, (IV)RExC_maxlen);\n    });\n    RExC_rx->minlenret = minlen;\n    if (RExC_rx->minlen < minlen)\n        RExC_rx->minlen = minlen;\n\n    if (RExC_seen & REG_RECURSE_SEEN ) {\n        RExC_rx->intflags |= PREGf_RECURSE_SEEN;\n        Newx(RExC_rx->recurse_locinput, RExC_rx->nparens + 1, char *);\n    }\n    if (RExC_seen & REG_GPOS_SEEN)\n        RExC_rx->intflags |= PREGf_GPOS_SEEN;\n    if (RExC_seen & REG_LOOKBEHIND_SEEN)\n        RExC_rx->extflags |= RXf_NO_INPLACE_SUBST; /* inplace might break the\n                                                lookbehind */\n    if (pRExC_state->code_blocks)\n\tRExC_rx->extflags |= RXf_EVAL_SEEN;\n    if (RExC_seen & REG_VERBARG_SEEN)\n    {\n\tRExC_rx->intflags |= PREGf_VERBARG_SEEN;\n        RExC_rx->extflags |= RXf_NO_INPLACE_SUBST; /* don't understand this! Yves */\n    }\n    if (RExC_seen & REG_CUTGROUP_SEEN)\n\tRExC_rx->intflags |= PREGf_CUTGROUP_SEEN;\n    if (pm_flags & PMf_USE_RE_EVAL)\n\tRExC_rx->intflags |= PREGf_USE_RE_EVAL;\n    if (RExC_paren_names)\n        RXp_PAREN_NAMES(RExC_rx) = MUTABLE_HV(SvREFCNT_inc(RExC_paren_names));\n    else\n        RXp_PAREN_NAMES(RExC_rx) = NULL;\n\n    /* If we have seen an anchor in our pattern then we set the extflag RXf_IS_ANCHORED\n     * so it can be used in pp.c */\n    if (RExC_rx->intflags & PREGf_ANCH)\n        RExC_rx->extflags |= RXf_IS_ANCHORED;\n\n\n    {\n        /* this is used to identify \"special\" patterns that might result\n         * in Perl NOT calling the regex engine and instead doing the match \"itself\",\n         * particularly special cases in split//. By having the regex compiler\n         * do this pattern matching at a regop level (instead of by inspecting the pattern)\n         * we avoid weird issues with equivalent patterns resulting in different behavior,\n         * AND we allow non Perl engines to get the same optimizations by the setting the\n         * flags appropriately - Yves */\n        regnode *first = RExC_rxi->program + 1;\n        U8 fop = OP(first);\n        regnode *next = regnext(first);\n        U8 nop = OP(next);\n\n        if (PL_regkind[fop] == NOTHING && nop == END)\n            RExC_rx->extflags |= RXf_NULL;\n        else if ((fop == MBOL || (fop == SBOL && !first->flags)) && nop == END)\n            /* when fop is SBOL first->flags will be true only when it was\n             * produced by parsing /\\A/, and not when parsing /^/. This is\n             * very important for the split code as there we want to\n             * treat /^/ as /^/m, but we do not want to treat /\\A/ as /^/m.\n             * See rt #122761 for more details. -- Yves */\n            RExC_rx->extflags |= RXf_START_ONLY;\n        else if (fop == PLUS\n                 && PL_regkind[nop] == POSIXD && FLAGS(next) == _CC_SPACE\n                 && nop == END)\n            RExC_rx->extflags |= RXf_WHITE;\n        else if ( RExC_rx->extflags & RXf_SPLIT\n                  && (fop == EXACT || fop == EXACT_ONLY8 || fop == EXACTL)\n                  && STR_LEN(first) == 1\n                  && *(STRING(first)) == ' '\n                  && nop == END )\n            RExC_rx->extflags |= (RXf_SKIPWHITE|RXf_WHITE);\n\n    }\n\n    if (RExC_contains_locale) {\n        RXp_EXTFLAGS(RExC_rx) |= RXf_TAINTED;\n    }\n\n#ifdef DEBUGGING\n    if (RExC_paren_names) {\n        RExC_rxi->name_list_idx = add_data( pRExC_state, STR_WITH_LEN(\"a\"));\n        RExC_rxi->data->data[RExC_rxi->name_list_idx]\n                                   = (void*)SvREFCNT_inc(RExC_paren_name_list);\n    } else\n#endif\n    RExC_rxi->name_list_idx = 0;\n\n    while ( RExC_recurse_count > 0 ) {\n        const regnode *scan = RExC_recurse[ --RExC_recurse_count ];\n        /*\n         * This data structure is set up in study_chunk() and is used\n         * to calculate the distance between a GOSUB regopcode and\n         * the OPEN/CURLYM (CURLYM's are special and can act like OPEN's)\n         * it refers to.\n         *\n         * If for some reason someone writes code that optimises\n         * away a GOSUB opcode then the assert should be changed to\n         * an if(scan) to guard the ARG2L_SET() - Yves\n         *\n         */\n        assert(scan && OP(scan) == GOSUB);\n        ARG2L_SET( scan, RExC_open_parens[ARG(scan)] - REGNODE_OFFSET(scan));\n    }\n\n    Newxz(RExC_rx->offs, RExC_total_parens, regexp_paren_pair);\n    /* assume we don't need to swap parens around before we match */\n    DEBUG_TEST_r({\n        Perl_re_printf( aTHX_ \"study_chunk_recursed_count: %lu\\n\",\n            (unsigned long)RExC_study_chunk_recursed_count);\n    });\n    DEBUG_DUMP_r({\n        DEBUG_RExC_seen();\n        Perl_re_printf( aTHX_ \"Final program:\\n\");\n        regdump(RExC_rx);\n    });\n\n    if (RExC_open_parens) {\n        Safefree(RExC_open_parens);\n        RExC_open_parens = NULL;\n    }\n    if (RExC_close_parens) {\n        Safefree(RExC_close_parens);\n        RExC_close_parens = NULL;\n    }\n\n#ifdef USE_ITHREADS\n    /* under ithreads the ?pat? PMf_USED flag on the pmop is simulated\n     * by setting the regexp SV to readonly-only instead. If the\n     * pattern's been recompiled, the USEDness should remain. */\n    if (old_re && SvREADONLY(old_re))\n        SvREADONLY_on(Rx);\n#endif\n    return Rx;", "func_src_after": "REGEXP *\nPerl_re_op_compile(pTHX_ SV ** const patternp, int pat_count,\n\t\t    OP *expr, const regexp_engine* eng, REGEXP *old_re,\n\t\t     bool *is_bare_re, const U32 orig_rx_flags, const U32 pm_flags)\n{\n    dVAR;\n    REGEXP *Rx;         /* Capital 'R' means points to a REGEXP */\n    STRLEN plen;\n    char *exp;\n    regnode *scan;\n    I32 flags;\n    SSize_t minlen = 0;\n    U32 rx_flags;\n    SV *pat;\n    SV** new_patternp = patternp;\n\n    /* these are all flags - maybe they should be turned\n     * into a single int with different bit masks */\n    I32 sawlookahead = 0;\n    I32 sawplus = 0;\n    I32 sawopen = 0;\n    I32 sawminmod = 0;\n\n    regex_charset initial_charset = get_regex_charset(orig_rx_flags);\n    bool recompile = 0;\n    bool runtime_code = 0;\n    scan_data_t data;\n    RExC_state_t RExC_state;\n    RExC_state_t * const pRExC_state = &RExC_state;\n#ifdef TRIE_STUDY_OPT\n    int restudied = 0;\n    RExC_state_t copyRExC_state;\n#endif\n    GET_RE_DEBUG_FLAGS_DECL;\n\n    PERL_ARGS_ASSERT_RE_OP_COMPILE;\n\n    DEBUG_r(if (!PL_colorset) reginitcolors());\n\n    /* Initialize these here instead of as-needed, as is quick and avoids\n     * having to test them each time otherwise */\n    if (! PL_InBitmap) {\n#ifdef DEBUGGING\n        char * dump_len_string;\n#endif\n\n        /* This is calculated here, because the Perl program that generates the\n         * static global ones doesn't currently have access to\n         * NUM_ANYOF_CODE_POINTS */\n\tPL_InBitmap = _new_invlist(2);\n\tPL_InBitmap = _add_range_to_invlist(PL_InBitmap, 0,\n                                                    NUM_ANYOF_CODE_POINTS - 1);\n#ifdef DEBUGGING\n        dump_len_string = PerlEnv_getenv(\"PERL_DUMP_RE_MAX_LEN\");\n        if (   ! dump_len_string\n            || ! grok_atoUV(dump_len_string, (UV *)&PL_dump_re_max_len, NULL))\n        {\n            PL_dump_re_max_len = 60;    /* A reasonable default */\n        }\n#endif\n    }\n\n    pRExC_state->warn_text = NULL;\n    pRExC_state->unlexed_names = NULL;\n    pRExC_state->code_blocks = NULL;\n\n    if (is_bare_re)\n\t*is_bare_re = FALSE;\n\n    if (expr && (expr->op_type == OP_LIST ||\n\t\t(expr->op_type == OP_NULL && expr->op_targ == OP_LIST))) {\n\t/* allocate code_blocks if needed */\n\tOP *o;\n\tint ncode = 0;\n\n\tfor (o = cLISTOPx(expr)->op_first; o; o = OpSIBLING(o))\n\t    if (o->op_type == OP_NULL && (o->op_flags & OPf_SPECIAL))\n\t\tncode++; /* count of DO blocks */\n\n\tif (ncode)\n            pRExC_state->code_blocks = S_alloc_code_blocks(aTHX_ ncode);\n    }\n\n    if (!pat_count) {\n        /* compile-time pattern with just OP_CONSTs and DO blocks */\n\n        int n;\n        OP *o;\n\n        /* find how many CONSTs there are */\n        assert(expr);\n        n = 0;\n        if (expr->op_type == OP_CONST)\n            n = 1;\n        else\n            for (o = cLISTOPx(expr)->op_first; o; o = OpSIBLING(o)) {\n                if (o->op_type == OP_CONST)\n                    n++;\n            }\n\n        /* fake up an SV array */\n\n        assert(!new_patternp);\n        Newx(new_patternp, n, SV*);\n        SAVEFREEPV(new_patternp);\n        pat_count = n;\n\n        n = 0;\n        if (expr->op_type == OP_CONST)\n            new_patternp[n] = cSVOPx_sv(expr);\n        else\n            for (o = cLISTOPx(expr)->op_first; o; o = OpSIBLING(o)) {\n                if (o->op_type == OP_CONST)\n                    new_patternp[n++] = cSVOPo_sv;\n            }\n\n    }\n\n    DEBUG_PARSE_r(Perl_re_printf( aTHX_\n        \"Assembling pattern from %d elements%s\\n\", pat_count,\n            orig_rx_flags & RXf_SPLIT ? \" for split\" : \"\"));\n\n    /* set expr to the first arg op */\n\n    if (pRExC_state->code_blocks && pRExC_state->code_blocks->count\n         && expr->op_type != OP_CONST)\n    {\n            expr = cLISTOPx(expr)->op_first;\n            assert(   expr->op_type == OP_PUSHMARK\n                   || (expr->op_type == OP_NULL && expr->op_targ == OP_PUSHMARK)\n                   || expr->op_type == OP_PADRANGE);\n            expr = OpSIBLING(expr);\n    }\n\n    pat = S_concat_pat(aTHX_ pRExC_state, NULL, new_patternp, pat_count,\n                        expr, &recompile, NULL);\n\n    /* handle bare (possibly after overloading) regex: foo =~ $re */\n    {\n        SV *re = pat;\n        if (SvROK(re))\n            re = SvRV(re);\n        if (SvTYPE(re) == SVt_REGEXP) {\n            if (is_bare_re)\n                *is_bare_re = TRUE;\n            SvREFCNT_inc(re);\n            DEBUG_PARSE_r(Perl_re_printf( aTHX_\n                \"Precompiled pattern%s\\n\",\n                    orig_rx_flags & RXf_SPLIT ? \" for split\" : \"\"));\n\n            return (REGEXP*)re;\n        }\n    }\n\n    exp = SvPV_nomg(pat, plen);\n\n    if (!eng->op_comp) {\n\tif ((SvUTF8(pat) && IN_BYTES)\n\t\t|| SvGMAGICAL(pat) || SvAMAGIC(pat))\n\t{\n\t    /* make a temporary copy; either to convert to bytes,\n\t     * or to avoid repeating get-magic / overloaded stringify */\n\t    pat = newSVpvn_flags(exp, plen, SVs_TEMP |\n\t\t\t\t\t(IN_BYTES ? 0 : SvUTF8(pat)));\n\t}\n\treturn CALLREGCOMP_ENG(eng, pat, orig_rx_flags);\n    }\n\n    /* ignore the utf8ness if the pattern is 0 length */\n    RExC_utf8 = RExC_orig_utf8 = (plen == 0 || IN_BYTES) ? 0 : SvUTF8(pat);\n    RExC_uni_semantics = 0;\n    RExC_contains_locale = 0;\n    RExC_strict = cBOOL(pm_flags & RXf_PMf_STRICT);\n    RExC_in_script_run = 0;\n    RExC_study_started = 0;\n    pRExC_state->runtime_code_qr = NULL;\n    RExC_frame_head= NULL;\n    RExC_frame_last= NULL;\n    RExC_frame_count= 0;\n    RExC_latest_warn_offset = 0;\n    RExC_use_BRANCHJ = 0;\n    RExC_total_parens = 0;\n    RExC_open_parens = NULL;\n    RExC_close_parens = NULL;\n    RExC_paren_names = NULL;\n    RExC_size = 0;\n    RExC_seen_d_op = FALSE;\n#ifdef DEBUGGING\n    RExC_paren_name_list = NULL;\n#endif\n\n    DEBUG_r({\n        RExC_mysv1= sv_newmortal();\n        RExC_mysv2= sv_newmortal();\n    });\n\n    DEBUG_COMPILE_r({\n            SV *dsv= sv_newmortal();\n            RE_PV_QUOTED_DECL(s, RExC_utf8, dsv, exp, plen, PL_dump_re_max_len);\n            Perl_re_printf( aTHX_  \"%sCompiling REx%s %s\\n\",\n                          PL_colors[4], PL_colors[5], s);\n        });\n\n    /* we jump here if we have to recompile, e.g., from upgrading the pattern\n     * to utf8 */\n\n    if ((pm_flags & PMf_USE_RE_EVAL)\n\t\t/* this second condition covers the non-regex literal case,\n\t\t * i.e.  $foo =~ '(?{})'. */\n\t\t|| (IN_PERL_COMPILETIME && (PL_hints & HINT_RE_EVAL))\n    )\n\truntime_code = S_has_runtime_code(aTHX_ pRExC_state, exp, plen);\n\n  redo_parse:\n    /* return old regex if pattern hasn't changed */\n    /* XXX: note in the below we have to check the flags as well as the\n     * pattern.\n     *\n     * Things get a touch tricky as we have to compare the utf8 flag\n     * independently from the compile flags.  */\n\n    if (   old_re\n        && !recompile\n        && !!RX_UTF8(old_re) == !!RExC_utf8\n        && ( RX_COMPFLAGS(old_re) == ( orig_rx_flags & RXf_PMf_FLAGCOPYMASK ) )\n\t&& RX_PRECOMP(old_re)\n\t&& RX_PRELEN(old_re) == plen\n        && memEQ(RX_PRECOMP(old_re), exp, plen)\n\t&& !runtime_code /* with runtime code, always recompile */ )\n    {\n        return old_re;\n    }\n\n    /* Allocate the pattern's SV */\n    RExC_rx_sv = Rx = (REGEXP*) newSV_type(SVt_REGEXP);\n    RExC_rx = ReANY(Rx);\n    if ( RExC_rx == NULL )\n        FAIL(\"Regexp out of space\");\n\n    rx_flags = orig_rx_flags;\n\n    if (   (UTF || RExC_uni_semantics)\n        && initial_charset == REGEX_DEPENDS_CHARSET)\n    {\n\n\t/* Set to use unicode semantics if the pattern is in utf8 and has the\n\t * 'depends' charset specified, as it means unicode when utf8  */\n\tset_regex_charset(&rx_flags, REGEX_UNICODE_CHARSET);\n        RExC_uni_semantics = 1;\n    }\n\n    RExC_pm_flags = pm_flags;\n\n    if (runtime_code) {\n        assert(TAINTING_get || !TAINT_get);\n\tif (TAINT_get)\n\t    Perl_croak(aTHX_ \"Eval-group in insecure regular expression\");\n\n\tif (!S_compile_runtime_code(aTHX_ pRExC_state, exp, plen)) {\n\t    /* whoops, we have a non-utf8 pattern, whilst run-time code\n\t     * got compiled as utf8. Try again with a utf8 pattern */\n            S_pat_upgrade_to_utf8(aTHX_ pRExC_state, &exp, &plen,\n                pRExC_state->code_blocks ? pRExC_state->code_blocks->count : 0);\n            goto redo_parse;\n\t}\n    }\n    assert(!pRExC_state->runtime_code_qr);\n\n    RExC_sawback = 0;\n\n    RExC_seen = 0;\n    RExC_maxlen = 0;\n    RExC_in_lookbehind = 0;\n    RExC_seen_zerolen = *exp == '^' ? -1 : 0;\n#ifdef EBCDIC\n    RExC_recode_x_to_native = 0;\n#endif\n    RExC_in_multi_char_class = 0;\n\n    RExC_start = RExC_copy_start_in_constructed = RExC_copy_start_in_input = RExC_precomp = exp;\n    RExC_precomp_end = RExC_end = exp + plen;\n    RExC_nestroot = 0;\n    RExC_whilem_seen = 0;\n    RExC_end_op = NULL;\n    RExC_recurse = NULL;\n    RExC_study_chunk_recursed = NULL;\n    RExC_study_chunk_recursed_bytes= 0;\n    RExC_recurse_count = 0;\n    pRExC_state->code_index = 0;\n\n    /* Initialize the string in the compiled pattern.  This is so that there is\n     * something to output if necessary */\n    set_regex_pv(pRExC_state, Rx);\n\n    DEBUG_PARSE_r({\n        Perl_re_printf( aTHX_\n            \"Starting parse and generation\\n\");\n        RExC_lastnum=0;\n        RExC_lastparse=NULL;\n    });\n\n    /* Allocate space and zero-initialize. Note, the two step process\n       of zeroing when in debug mode, thus anything assigned has to\n       happen after that */\n    if (!  RExC_size) {\n\n        /* On the first pass of the parse, we guess how big this will be.  Then\n         * we grow in one operation to that amount and then give it back.  As\n         * we go along, we re-allocate what we need.\n         *\n         * XXX Currently the guess is essentially that the pattern will be an\n         * EXACT node with one byte input, one byte output.  This is crude, and\n         * better heuristics are welcome.\n         *\n         * On any subsequent passes, we guess what we actually computed in the\n         * latest earlier pass.  Such a pass probably didn't complete so is\n         * missing stuff.  We could improve those guesses by knowing where the\n         * parse stopped, and use the length so far plus apply the above\n         * assumption to what's left. */\n        RExC_size = STR_SZ(RExC_end - RExC_start);\n    }\n\n    Newxc(RExC_rxi, sizeof(regexp_internal) + RExC_size, char, regexp_internal);\n    if ( RExC_rxi == NULL )\n        FAIL(\"Regexp out of space\");\n\n    Zero(RExC_rxi, sizeof(regexp_internal) + RExC_size, char);\n    RXi_SET( RExC_rx, RExC_rxi );\n\n    /* We start from 0 (over from 0 in the case this is a reparse.  The first\n     * node parsed will give back any excess memory we have allocated so far).\n     * */\n    RExC_size = 0;\n\n    /* non-zero initialization begins here */\n    RExC_rx->engine= eng;\n    RExC_rx->extflags = rx_flags;\n    RXp_COMPFLAGS(RExC_rx) = orig_rx_flags & RXf_PMf_FLAGCOPYMASK;\n\n    if (pm_flags & PMf_IS_QR) {\n\tRExC_rxi->code_blocks = pRExC_state->code_blocks;\n        if (RExC_rxi->code_blocks) {\n            RExC_rxi->code_blocks->refcnt++;\n        }\n    }\n\n    RExC_rx->intflags = 0;\n\n    RExC_flags = rx_flags;\t/* don't let top level (?i) bleed */\n    RExC_parse = exp;\n\n    /* This NUL is guaranteed because the pattern comes from an SV*, and the sv\n     * code makes sure the final byte is an uncounted NUL.  But should this\n     * ever not be the case, lots of things could read beyond the end of the\n     * buffer: loops like\n     *      while(isFOO(*RExC_parse)) RExC_parse++;\n     *      strchr(RExC_parse, \"foo\");\n     * etc.  So it is worth noting. */\n    assert(*RExC_end == '\\0');\n\n    RExC_naughty = 0;\n    RExC_npar = 1;\n    RExC_parens_buf_size = 0;\n    RExC_emit_start = RExC_rxi->program;\n    pRExC_state->code_index = 0;\n\n    *((char*) RExC_emit_start) = (char) REG_MAGIC;\n    RExC_emit = 1;\n\n    /* Do the parse */\n    if (reg(pRExC_state, 0, &flags, 1)) {\n\n        /* Success!, But we may need to redo the parse knowing how many parens\n         * there actually are */\n        if (IN_PARENS_PASS) {\n            flags |= RESTART_PARSE;\n        }\n\n        /* We have that number in RExC_npar */\n        RExC_total_parens = RExC_npar;\n\n        /* XXX For backporting, use long jumps if there is any possibility of\n         * overflow */\n        if (RExC_size > U16_MAX && ! RExC_use_BRANCHJ) {\n            RExC_use_BRANCHJ = TRUE;\n            flags |= RESTART_PARSE;\n        }\n    }\n    else if (! MUST_RESTART(flags)) {\n\tReREFCNT_dec(Rx);\n        Perl_croak(aTHX_ \"panic: reg returned failure to re_op_compile, flags=%#\" UVxf, (UV) flags);\n    }\n\n    /* Here, we either have success, or we have to redo the parse for some reason */\n    if (MUST_RESTART(flags)) {\n\n        /* It's possible to write a regexp in ascii that represents Unicode\n        codepoints outside of the byte range, such as via \\x{100}. If we\n        detect such a sequence we have to convert the entire pattern to utf8\n        and then recompile, as our sizing calculation will have been based\n        on 1 byte == 1 character, but we will need to use utf8 to encode\n        at least some part of the pattern, and therefore must convert the whole\n        thing.\n        -- dmq */\n        if (flags & NEED_UTF8) {\n\n            /* We have stored the offset of the final warning output so far.\n             * That must be adjusted.  Any variant characters between the start\n             * of the pattern and this warning count for 2 bytes in the final,\n             * so just add them again */\n            if (UNLIKELY(RExC_latest_warn_offset > 0)) {\n                RExC_latest_warn_offset +=\n                            variant_under_utf8_count((U8 *) exp, (U8 *) exp\n                                                + RExC_latest_warn_offset);\n            }\n            S_pat_upgrade_to_utf8(aTHX_ pRExC_state, &exp, &plen,\n            pRExC_state->code_blocks ? pRExC_state->code_blocks->count : 0);\n            DEBUG_PARSE_r(Perl_re_printf( aTHX_ \"Need to redo parse after upgrade\\n\"));\n        }\n        else {\n            DEBUG_PARSE_r(Perl_re_printf( aTHX_ \"Need to redo parse\\n\"));\n        }\n\n        if (ALL_PARENS_COUNTED) {\n            /* Make enough room for all the known parens, and zero it */\n            Renew(RExC_open_parens, RExC_total_parens, regnode_offset);\n            Zero(RExC_open_parens, RExC_total_parens, regnode_offset);\n            RExC_open_parens[0] = 1;    /* +1 for REG_MAGIC */\n\n            Renew(RExC_close_parens, RExC_total_parens, regnode_offset);\n            Zero(RExC_close_parens, RExC_total_parens, regnode_offset);\n        }\n        else { /* Parse did not complete.  Reinitialize the parentheses\n                  structures */\n            RExC_total_parens = 0;\n            if (RExC_open_parens) {\n                Safefree(RExC_open_parens);\n                RExC_open_parens = NULL;\n            }\n            if (RExC_close_parens) {\n                Safefree(RExC_close_parens);\n                RExC_close_parens = NULL;\n            }\n        }\n\n        /* Clean up what we did in this parse */\n        SvREFCNT_dec_NN(RExC_rx_sv);\n\n        goto redo_parse;\n    }\n\n    /* Here, we have successfully parsed and generated the pattern's program\n     * for the regex engine.  We are ready to finish things up and look for\n     * optimizations. */\n\n    /* Update the string to compile, with correct modifiers, etc */\n    set_regex_pv(pRExC_state, Rx);\n\n    RExC_rx->nparens = RExC_total_parens - 1;\n\n    /* Uses the upper 4 bits of the FLAGS field, so keep within that size */\n    if (RExC_whilem_seen > 15)\n        RExC_whilem_seen = 15;\n\n    DEBUG_PARSE_r({\n        Perl_re_printf( aTHX_\n            \"Required size %\" IVdf \" nodes\\n\", (IV)RExC_size);\n        RExC_lastnum=0;\n        RExC_lastparse=NULL;\n    });\n\n#ifdef RE_TRACK_PATTERN_OFFSETS\n    DEBUG_OFFSETS_r(Perl_re_printf( aTHX_\n                          \"%s %\" UVuf \" bytes for offset annotations.\\n\",\n                          RExC_offsets ? \"Got\" : \"Couldn't get\",\n                          (UV)((RExC_offsets[0] * 2 + 1))));\n    DEBUG_OFFSETS_r(if (RExC_offsets) {\n        const STRLEN len = RExC_offsets[0];\n        STRLEN i;\n        GET_RE_DEBUG_FLAGS_DECL;\n        Perl_re_printf( aTHX_\n                      \"Offsets: [%\" UVuf \"]\\n\\t\", (UV)RExC_offsets[0]);\n        for (i = 1; i <= len; i++) {\n            if (RExC_offsets[i*2-1] || RExC_offsets[i*2])\n                Perl_re_printf( aTHX_  \"%\" UVuf \":%\" UVuf \"[%\" UVuf \"] \",\n                (UV)i, (UV)RExC_offsets[i*2-1], (UV)RExC_offsets[i*2]);\n        }\n        Perl_re_printf( aTHX_  \"\\n\");\n    });\n\n#else\n    SetProgLen(RExC_rxi,RExC_size);\n#endif\n\n    DEBUG_OPTIMISE_r(\n        Perl_re_printf( aTHX_  \"Starting post parse optimization\\n\");\n    );\n\n    /* XXXX To minimize changes to RE engine we always allocate\n       3-units-long substrs field. */\n    Newx(RExC_rx->substrs, 1, struct reg_substr_data);\n    if (RExC_recurse_count) {\n        Newx(RExC_recurse, RExC_recurse_count, regnode *);\n        SAVEFREEPV(RExC_recurse);\n    }\n\n    if (RExC_seen & REG_RECURSE_SEEN) {\n        /* Note, RExC_total_parens is 1 + the number of parens in a pattern.\n         * So its 1 if there are no parens. */\n        RExC_study_chunk_recursed_bytes= (RExC_total_parens >> 3) +\n                                         ((RExC_total_parens & 0x07) != 0);\n        Newx(RExC_study_chunk_recursed,\n             RExC_study_chunk_recursed_bytes * RExC_total_parens, U8);\n        SAVEFREEPV(RExC_study_chunk_recursed);\n    }\n\n  reStudy:\n    RExC_rx->minlen = minlen = sawlookahead = sawplus = sawopen = sawminmod = 0;\n    DEBUG_r(\n        RExC_study_chunk_recursed_count= 0;\n    );\n    Zero(RExC_rx->substrs, 1, struct reg_substr_data);\n    if (RExC_study_chunk_recursed) {\n        Zero(RExC_study_chunk_recursed,\n             RExC_study_chunk_recursed_bytes * RExC_total_parens, U8);\n    }\n\n\n#ifdef TRIE_STUDY_OPT\n    if (!restudied) {\n        StructCopy(&zero_scan_data, &data, scan_data_t);\n        copyRExC_state = RExC_state;\n    } else {\n        U32 seen=RExC_seen;\n        DEBUG_OPTIMISE_r(Perl_re_printf( aTHX_ \"Restudying\\n\"));\n\n        RExC_state = copyRExC_state;\n        if (seen & REG_TOP_LEVEL_BRANCHES_SEEN)\n            RExC_seen |= REG_TOP_LEVEL_BRANCHES_SEEN;\n        else\n            RExC_seen &= ~REG_TOP_LEVEL_BRANCHES_SEEN;\n\tStructCopy(&zero_scan_data, &data, scan_data_t);\n    }\n#else\n    StructCopy(&zero_scan_data, &data, scan_data_t);\n#endif\n\n    /* Dig out information for optimizations. */\n    RExC_rx->extflags = RExC_flags; /* was pm_op */\n    /*dmq: removed as part of de-PMOP: pm->op_pmflags = RExC_flags; */\n\n    if (UTF)\n\tSvUTF8_on(Rx);\t/* Unicode in it? */\n    RExC_rxi->regstclass = NULL;\n    if (RExC_naughty >= TOO_NAUGHTY)\t/* Probably an expensive pattern. */\n\tRExC_rx->intflags |= PREGf_NAUGHTY;\n    scan = RExC_rxi->program + 1;\t\t/* First BRANCH. */\n\n    /* testing for BRANCH here tells us whether there is \"must appear\"\n       data in the pattern. If there is then we can use it for optimisations */\n    if (!(RExC_seen & REG_TOP_LEVEL_BRANCHES_SEEN)) { /*  Only one top-level choice.\n                                                  */\n\tSSize_t fake;\n\tSTRLEN longest_length[2];\n\tregnode_ssc ch_class; /* pointed to by data */\n\tint stclass_flag;\n\tSSize_t last_close = 0; /* pointed to by data */\n        regnode *first= scan;\n        regnode *first_next= regnext(first);\n        int i;\n\n\t/*\n\t * Skip introductions and multiplicators >= 1\n\t * so that we can extract the 'meat' of the pattern that must\n\t * match in the large if() sequence following.\n\t * NOTE that EXACT is NOT covered here, as it is normally\n\t * picked up by the optimiser separately.\n\t *\n\t * This is unfortunate as the optimiser isnt handling lookahead\n\t * properly currently.\n\t *\n\t */\n\twhile ((OP(first) == OPEN && (sawopen = 1)) ||\n\t       /* An OR of *one* alternative - should not happen now. */\n\t    (OP(first) == BRANCH && OP(first_next) != BRANCH) ||\n\t    /* for now we can't handle lookbehind IFMATCH*/\n\t    (OP(first) == IFMATCH && !first->flags && (sawlookahead = 1)) ||\n\t    (OP(first) == PLUS) ||\n\t    (OP(first) == MINMOD) ||\n\t       /* An {n,m} with n>0 */\n\t    (PL_regkind[OP(first)] == CURLY && ARG1(first) > 0) ||\n\t    (OP(first) == NOTHING && PL_regkind[OP(first_next)] != END ))\n\t{\n\t\t/*\n\t\t * the only op that could be a regnode is PLUS, all the rest\n\t\t * will be regnode_1 or regnode_2.\n\t\t *\n                 * (yves doesn't think this is true)\n\t\t */\n\t\tif (OP(first) == PLUS)\n\t\t    sawplus = 1;\n                else {\n                    if (OP(first) == MINMOD)\n                        sawminmod = 1;\n\t\t    first += regarglen[OP(first)];\n                }\n\t\tfirst = NEXTOPER(first);\n\t\tfirst_next= regnext(first);\n\t}\n\n\t/* Starting-point info. */\n      again:\n        DEBUG_PEEP(\"first:\", first, 0, 0);\n        /* Ignore EXACT as we deal with it later. */\n\tif (PL_regkind[OP(first)] == EXACT) {\n\t    if (   OP(first) == EXACT\n                || OP(first) == EXACT_ONLY8\n                || OP(first) == EXACTL)\n            {\n\t\tNOOP;\t/* Empty, get anchored substr later. */\n            }\n\t    else\n\t\tRExC_rxi->regstclass = first;\n\t}\n#ifdef TRIE_STCLASS\n\telse if (PL_regkind[OP(first)] == TRIE &&\n\t        ((reg_trie_data *)RExC_rxi->data->data[ ARG(first) ])->minlen>0)\n\t{\n            /* this can happen only on restudy */\n            RExC_rxi->regstclass = construct_ahocorasick_from_trie(pRExC_state, (regnode *)first, 0);\n\t}\n#endif\n\telse if (REGNODE_SIMPLE(OP(first)))\n\t    RExC_rxi->regstclass = first;\n\telse if (PL_regkind[OP(first)] == BOUND ||\n\t\t PL_regkind[OP(first)] == NBOUND)\n\t    RExC_rxi->regstclass = first;\n\telse if (PL_regkind[OP(first)] == BOL) {\n            RExC_rx->intflags |= (OP(first) == MBOL\n                           ? PREGf_ANCH_MBOL\n                           : PREGf_ANCH_SBOL);\n\t    first = NEXTOPER(first);\n\t    goto again;\n\t}\n\telse if (OP(first) == GPOS) {\n            RExC_rx->intflags |= PREGf_ANCH_GPOS;\n\t    first = NEXTOPER(first);\n\t    goto again;\n\t}\n\telse if ((!sawopen || !RExC_sawback) &&\n            !sawlookahead &&\n\t    (OP(first) == STAR &&\n\t    PL_regkind[OP(NEXTOPER(first))] == REG_ANY) &&\n            !(RExC_rx->intflags & PREGf_ANCH) && !pRExC_state->code_blocks)\n\t{\n\t    /* turn .* into ^.* with an implied $*=1 */\n\t    const int type =\n\t\t(OP(NEXTOPER(first)) == REG_ANY)\n                    ? PREGf_ANCH_MBOL\n                    : PREGf_ANCH_SBOL;\n            RExC_rx->intflags |= (type | PREGf_IMPLICIT);\n\t    first = NEXTOPER(first);\n\t    goto again;\n\t}\n        if (sawplus && !sawminmod && !sawlookahead\n            && (!sawopen || !RExC_sawback)\n\t    && !pRExC_state->code_blocks) /* May examine pos and $& */\n\t    /* x+ must match at the 1st pos of run of x's */\n\t    RExC_rx->intflags |= PREGf_SKIP;\n\n\t/* Scan is after the zeroth branch, first is atomic matcher. */\n#ifdef TRIE_STUDY_OPT\n\tDEBUG_PARSE_r(\n\t    if (!restudied)\n                Perl_re_printf( aTHX_  \"first at %\" IVdf \"\\n\",\n\t\t\t      (IV)(first - scan + 1))\n        );\n#else\n\tDEBUG_PARSE_r(\n            Perl_re_printf( aTHX_  \"first at %\" IVdf \"\\n\",\n\t        (IV)(first - scan + 1))\n        );\n#endif\n\n\n\t/*\n\t* If there's something expensive in the r.e., find the\n\t* longest literal string that must appear and make it the\n\t* regmust.  Resolve ties in favor of later strings, since\n\t* the regstart check works with the beginning of the r.e.\n\t* and avoiding duplication strengthens checking.  Not a\n\t* strong reason, but sufficient in the absence of others.\n\t* [Now we resolve ties in favor of the earlier string if\n\t* it happens that c_offset_min has been invalidated, since the\n\t* earlier string may buy us something the later one won't.]\n\t*/\n\n\tdata.substrs[0].str = newSVpvs(\"\");\n\tdata.substrs[1].str = newSVpvs(\"\");\n\tdata.last_found = newSVpvs(\"\");\n\tdata.cur_is_floating = 0; /* initially any found substring is fixed */\n\tENTER_with_name(\"study_chunk\");\n\tSAVEFREESV(data.substrs[0].str);\n\tSAVEFREESV(data.substrs[1].str);\n\tSAVEFREESV(data.last_found);\n\tfirst = scan;\n\tif (!RExC_rxi->regstclass) {\n\t    ssc_init(pRExC_state, &ch_class);\n\t    data.start_class = &ch_class;\n\t    stclass_flag = SCF_DO_STCLASS_AND;\n\t} else\t\t\t\t/* XXXX Check for BOUND? */\n\t    stclass_flag = 0;\n\tdata.last_closep = &last_close;\n\n        DEBUG_RExC_seen();\n        /*\n         * MAIN ENTRY FOR study_chunk() FOR m/PATTERN/\n         * (NO top level branches)\n         */\n\tminlen = study_chunk(pRExC_state, &first, &minlen, &fake,\n                             scan + RExC_size, /* Up to end */\n            &data, -1, 0, NULL,\n            SCF_DO_SUBSTR | SCF_WHILEM_VISITED_POS | stclass_flag\n                          | (restudied ? SCF_TRIE_DOING_RESTUDY : 0),\n            0);\n\n\n        CHECK_RESTUDY_GOTO_butfirst(LEAVE_with_name(\"study_chunk\"));\n\n\n\tif ( RExC_total_parens == 1 && !data.cur_is_floating\n\t     && data.last_start_min == 0 && data.last_end > 0\n\t     && !RExC_seen_zerolen\n             && !(RExC_seen & REG_VERBARG_SEEN)\n             && !(RExC_seen & REG_GPOS_SEEN)\n        ){\n\t    RExC_rx->extflags |= RXf_CHECK_ALL;\n        }\n\tscan_commit(pRExC_state, &data,&minlen, 0);\n\n\n        /* XXX this is done in reverse order because that's the way the\n         * code was before it was parameterised. Don't know whether it\n         * actually needs doing in reverse order. DAPM */\n        for (i = 1; i >= 0; i--) {\n            longest_length[i] = CHR_SVLEN(data.substrs[i].str);\n\n            if (   !(   i\n                     && SvCUR(data.substrs[0].str)  /* ok to leave SvCUR */\n                     &&    data.substrs[0].min_offset\n                        == data.substrs[1].min_offset\n                     &&    SvCUR(data.substrs[0].str)\n                        == SvCUR(data.substrs[1].str)\n                    )\n                && S_setup_longest (aTHX_ pRExC_state,\n                                        &(RExC_rx->substrs->data[i]),\n                                        &(data.substrs[i]),\n                                        longest_length[i]))\n            {\n                RExC_rx->substrs->data[i].min_offset =\n                        data.substrs[i].min_offset - data.substrs[i].lookbehind;\n\n                RExC_rx->substrs->data[i].max_offset = data.substrs[i].max_offset;\n                /* Don't offset infinity */\n                if (data.substrs[i].max_offset < SSize_t_MAX)\n                    RExC_rx->substrs->data[i].max_offset -= data.substrs[i].lookbehind;\n                SvREFCNT_inc_simple_void_NN(data.substrs[i].str);\n            }\n            else {\n                RExC_rx->substrs->data[i].substr      = NULL;\n                RExC_rx->substrs->data[i].utf8_substr = NULL;\n                longest_length[i] = 0;\n            }\n        }\n\n\tLEAVE_with_name(\"study_chunk\");\n\n\tif (RExC_rxi->regstclass\n\t    && (OP(RExC_rxi->regstclass) == REG_ANY || OP(RExC_rxi->regstclass) == SANY))\n\t    RExC_rxi->regstclass = NULL;\n\n\tif ((!(RExC_rx->substrs->data[0].substr || RExC_rx->substrs->data[0].utf8_substr)\n              || RExC_rx->substrs->data[0].min_offset)\n\t    && stclass_flag\n            && ! (ANYOF_FLAGS(data.start_class) & SSC_MATCHES_EMPTY_STRING)\n\t    && is_ssc_worth_it(pRExC_state, data.start_class))\n\t{\n\t    const U32 n = add_data(pRExC_state, STR_WITH_LEN(\"f\"));\n\n            ssc_finalize(pRExC_state, data.start_class);\n\n\t    Newx(RExC_rxi->data->data[n], 1, regnode_ssc);\n\t    StructCopy(data.start_class,\n\t\t       (regnode_ssc*)RExC_rxi->data->data[n],\n\t\t       regnode_ssc);\n\t    RExC_rxi->regstclass = (regnode*)RExC_rxi->data->data[n];\n\t    RExC_rx->intflags &= ~PREGf_SKIP;\t/* Used in find_byclass(). */\n\t    DEBUG_COMPILE_r({ SV *sv = sv_newmortal();\n                      regprop(RExC_rx, sv, (regnode*)data.start_class, NULL, pRExC_state);\n                      Perl_re_printf( aTHX_\n\t\t\t\t    \"synthetic stclass \\\"%s\\\".\\n\",\n\t\t\t\t    SvPVX_const(sv));});\n            data.start_class = NULL;\n\t}\n\n        /* A temporary algorithm prefers floated substr to fixed one of\n         * same length to dig more info. */\n\ti = (longest_length[0] <= longest_length[1]);\n        RExC_rx->substrs->check_ix = i;\n        RExC_rx->check_end_shift  = RExC_rx->substrs->data[i].end_shift;\n        RExC_rx->check_substr     = RExC_rx->substrs->data[i].substr;\n        RExC_rx->check_utf8       = RExC_rx->substrs->data[i].utf8_substr;\n        RExC_rx->check_offset_min = RExC_rx->substrs->data[i].min_offset;\n        RExC_rx->check_offset_max = RExC_rx->substrs->data[i].max_offset;\n        if (!i && (RExC_rx->intflags & (PREGf_ANCH_SBOL|PREGf_ANCH_GPOS)))\n            RExC_rx->intflags |= PREGf_NOSCAN;\n\n\tif ((RExC_rx->check_substr || RExC_rx->check_utf8) ) {\n\t    RExC_rx->extflags |= RXf_USE_INTUIT;\n\t    if (SvTAIL(RExC_rx->check_substr ? RExC_rx->check_substr : RExC_rx->check_utf8))\n\t\tRExC_rx->extflags |= RXf_INTUIT_TAIL;\n\t}\n\n\t/* XXX Unneeded? dmq (shouldn't as this is handled elsewhere)\n\tif ( (STRLEN)minlen < longest_length[1] )\n            minlen= longest_length[1];\n        if ( (STRLEN)minlen < longest_length[0] )\n            minlen= longest_length[0];\n        */\n    }\n    else {\n\t/* Several toplevels. Best we can is to set minlen. */\n\tSSize_t fake;\n\tregnode_ssc ch_class;\n\tSSize_t last_close = 0;\n\n        DEBUG_PARSE_r(Perl_re_printf( aTHX_  \"\\nMulti Top Level\\n\"));\n\n\tscan = RExC_rxi->program + 1;\n\tssc_init(pRExC_state, &ch_class);\n\tdata.start_class = &ch_class;\n\tdata.last_closep = &last_close;\n\n        DEBUG_RExC_seen();\n        /*\n         * MAIN ENTRY FOR study_chunk() FOR m/P1|P2|.../\n         * (patterns WITH top level branches)\n         */\n\tminlen = study_chunk(pRExC_state,\n            &scan, &minlen, &fake, scan + RExC_size, &data, -1, 0, NULL,\n            SCF_DO_STCLASS_AND|SCF_WHILEM_VISITED_POS|(restudied\n                                                      ? SCF_TRIE_DOING_RESTUDY\n                                                      : 0),\n            0);\n\n        CHECK_RESTUDY_GOTO_butfirst(NOOP);\n\n\tRExC_rx->check_substr = NULL;\n        RExC_rx->check_utf8 = NULL;\n        RExC_rx->substrs->data[0].substr      = NULL;\n        RExC_rx->substrs->data[0].utf8_substr = NULL;\n        RExC_rx->substrs->data[1].substr      = NULL;\n        RExC_rx->substrs->data[1].utf8_substr = NULL;\n\n        if (! (ANYOF_FLAGS(data.start_class) & SSC_MATCHES_EMPTY_STRING)\n\t    && is_ssc_worth_it(pRExC_state, data.start_class))\n        {\n\t    const U32 n = add_data(pRExC_state, STR_WITH_LEN(\"f\"));\n\n            ssc_finalize(pRExC_state, data.start_class);\n\n\t    Newx(RExC_rxi->data->data[n], 1, regnode_ssc);\n\t    StructCopy(data.start_class,\n\t\t       (regnode_ssc*)RExC_rxi->data->data[n],\n\t\t       regnode_ssc);\n\t    RExC_rxi->regstclass = (regnode*)RExC_rxi->data->data[n];\n\t    RExC_rx->intflags &= ~PREGf_SKIP;\t/* Used in find_byclass(). */\n\t    DEBUG_COMPILE_r({ SV* sv = sv_newmortal();\n                      regprop(RExC_rx, sv, (regnode*)data.start_class, NULL, pRExC_state);\n                      Perl_re_printf( aTHX_\n\t\t\t\t    \"synthetic stclass \\\"%s\\\".\\n\",\n\t\t\t\t    SvPVX_const(sv));});\n            data.start_class = NULL;\n\t}\n    }\n\n    if (RExC_seen & REG_UNBOUNDED_QUANTIFIER_SEEN) {\n        RExC_rx->extflags |= RXf_UNBOUNDED_QUANTIFIER_SEEN;\n        RExC_rx->maxlen = REG_INFTY;\n    }\n    else {\n        RExC_rx->maxlen = RExC_maxlen;\n    }\n\n    /* Guard against an embedded (?=) or (?<=) with a longer minlen than\n       the \"real\" pattern. */\n    DEBUG_OPTIMISE_r({\n        Perl_re_printf( aTHX_ \"minlen: %\" IVdf \" RExC_rx->minlen:%\" IVdf \" maxlen:%\" IVdf \"\\n\",\n                      (IV)minlen, (IV)RExC_rx->minlen, (IV)RExC_maxlen);\n    });\n    RExC_rx->minlenret = minlen;\n    if (RExC_rx->minlen < minlen)\n        RExC_rx->minlen = minlen;\n\n    if (RExC_seen & REG_RECURSE_SEEN ) {\n        RExC_rx->intflags |= PREGf_RECURSE_SEEN;\n        Newx(RExC_rx->recurse_locinput, RExC_rx->nparens + 1, char *);\n    }\n    if (RExC_seen & REG_GPOS_SEEN)\n        RExC_rx->intflags |= PREGf_GPOS_SEEN;\n    if (RExC_seen & REG_LOOKBEHIND_SEEN)\n        RExC_rx->extflags |= RXf_NO_INPLACE_SUBST; /* inplace might break the\n                                                lookbehind */\n    if (pRExC_state->code_blocks)\n\tRExC_rx->extflags |= RXf_EVAL_SEEN;\n    if (RExC_seen & REG_VERBARG_SEEN)\n    {\n\tRExC_rx->intflags |= PREGf_VERBARG_SEEN;\n        RExC_rx->extflags |= RXf_NO_INPLACE_SUBST; /* don't understand this! Yves */\n    }\n    if (RExC_seen & REG_CUTGROUP_SEEN)\n\tRExC_rx->intflags |= PREGf_CUTGROUP_SEEN;\n    if (pm_flags & PMf_USE_RE_EVAL)\n\tRExC_rx->intflags |= PREGf_USE_RE_EVAL;\n    if (RExC_paren_names)\n        RXp_PAREN_NAMES(RExC_rx) = MUTABLE_HV(SvREFCNT_inc(RExC_paren_names));\n    else\n        RXp_PAREN_NAMES(RExC_rx) = NULL;\n\n    /* If we have seen an anchor in our pattern then we set the extflag RXf_IS_ANCHORED\n     * so it can be used in pp.c */\n    if (RExC_rx->intflags & PREGf_ANCH)\n        RExC_rx->extflags |= RXf_IS_ANCHORED;\n\n\n    {\n        /* this is used to identify \"special\" patterns that might result\n         * in Perl NOT calling the regex engine and instead doing the match \"itself\",\n         * particularly special cases in split//. By having the regex compiler\n         * do this pattern matching at a regop level (instead of by inspecting the pattern)\n         * we avoid weird issues with equivalent patterns resulting in different behavior,\n         * AND we allow non Perl engines to get the same optimizations by the setting the\n         * flags appropriately - Yves */\n        regnode *first = RExC_rxi->program + 1;\n        U8 fop = OP(first);\n        regnode *next = regnext(first);\n        U8 nop = OP(next);\n\n        if (PL_regkind[fop] == NOTHING && nop == END)\n            RExC_rx->extflags |= RXf_NULL;\n        else if ((fop == MBOL || (fop == SBOL && !first->flags)) && nop == END)\n            /* when fop is SBOL first->flags will be true only when it was\n             * produced by parsing /\\A/, and not when parsing /^/. This is\n             * very important for the split code as there we want to\n             * treat /^/ as /^/m, but we do not want to treat /\\A/ as /^/m.\n             * See rt #122761 for more details. -- Yves */\n            RExC_rx->extflags |= RXf_START_ONLY;\n        else if (fop == PLUS\n                 && PL_regkind[nop] == POSIXD && FLAGS(next) == _CC_SPACE\n                 && nop == END)\n            RExC_rx->extflags |= RXf_WHITE;\n        else if ( RExC_rx->extflags & RXf_SPLIT\n                  && (fop == EXACT || fop == EXACT_ONLY8 || fop == EXACTL)\n                  && STR_LEN(first) == 1\n                  && *(STRING(first)) == ' '\n                  && nop == END )\n            RExC_rx->extflags |= (RXf_SKIPWHITE|RXf_WHITE);\n\n    }\n\n    if (RExC_contains_locale) {\n        RXp_EXTFLAGS(RExC_rx) |= RXf_TAINTED;\n    }\n\n#ifdef DEBUGGING\n    if (RExC_paren_names) {\n        RExC_rxi->name_list_idx = add_data( pRExC_state, STR_WITH_LEN(\"a\"));\n        RExC_rxi->data->data[RExC_rxi->name_list_idx]\n                                   = (void*)SvREFCNT_inc(RExC_paren_name_list);\n    } else\n#endif\n    RExC_rxi->name_list_idx = 0;\n\n    while ( RExC_recurse_count > 0 ) {\n        const regnode *scan = RExC_recurse[ --RExC_recurse_count ];\n        /*\n         * This data structure is set up in study_chunk() and is used\n         * to calculate the distance between a GOSUB regopcode and\n         * the OPEN/CURLYM (CURLYM's are special and can act like OPEN's)\n         * it refers to.\n         *\n         * If for some reason someone writes code that optimises\n         * away a GOSUB opcode then the assert should be changed to\n         * an if(scan) to guard the ARG2L_SET() - Yves\n         *\n         */\n        assert(scan && OP(scan) == GOSUB);\n        ARG2L_SET( scan, RExC_open_parens[ARG(scan)] - REGNODE_OFFSET(scan));\n    }\n\n    Newxz(RExC_rx->offs, RExC_total_parens, regexp_paren_pair);\n    /* assume we don't need to swap parens around before we match */\n    DEBUG_TEST_r({\n        Perl_re_printf( aTHX_ \"study_chunk_recursed_count: %lu\\n\",\n            (unsigned long)RExC_study_chunk_recursed_count);\n    });\n    DEBUG_DUMP_r({\n        DEBUG_RExC_seen();\n        Perl_re_printf( aTHX_ \"Final program:\\n\");\n        regdump(RExC_rx);\n    });\n\n    if (RExC_open_parens) {\n        Safefree(RExC_open_parens);\n        RExC_open_parens = NULL;\n    }\n    if (RExC_close_parens) {\n        Safefree(RExC_close_parens);\n        RExC_close_parens = NULL;\n    }\n\n#ifdef USE_ITHREADS\n    /* under ithreads the ?pat? PMf_USED flag on the pmop is simulated\n     * by setting the regexp SV to readonly-only instead. If the\n     * pattern's been recompiled, the USEDness should remain. */\n    if (old_re && SvREADONLY(old_re))\n        SvREADONLY_on(Rx);\n#endif\n    return Rx;", "commit_link": "github.com/perl/perl5/commit/3295b48defa0f8570114877b063fe546dd348b3c", "file_name": "regcomp.c", "vul_type": "cwe-190", "description": "Compile a regular expression pattern in Perl."}
{"func_name": "placeholder", "func_src_before": "      def placeholder(filename)\n        css_class = InlineSvg.configuration.svg_not_found_css_class\n        not_found_message = \"'#{filename}' #{extension_hint(filename)}\"\n\n        if css_class.nil?\n          return \"<svg><!-- SVG file not found: #{not_found_message}--></svg>\".html_safe\n        else\n          return \"<svg class='#{css_class}'><!-- SVG file not found: #{not_found_message}--></svg>\".html_safe\n        end\n      end", "func_src_after": "      def placeholder(filename)\n        css_class = InlineSvg.configuration.svg_not_found_css_class\n        not_found_message = \"'#{ERB::Util.html_escape_once(filename)}' #{extension_hint(filename)}\"\n\n        if css_class.nil?\n          return \"<svg><!-- SVG file not found: #{not_found_message}--></svg>\".html_safe\n        else\n          return \"<svg class='#{css_class}'><!-- SVG file not found: #{not_found_message}--></svg>\".html_safe\n        end\n      end", "line_changes": {"deleted": [{"line_no": 3, "char_start": 100, "char_end": 172, "line": "        not_found_message = \"'#{filename}' #{extension_hint(filename)}\"\n"}], "added": [{"line_no": 3, "char_start": 100, "char_end": 200, "line": "        not_found_message = \"'#{ERB::Util.html_escape_once(filename)}' #{extension_hint(filename)}\"\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 132, "char_end": 159, "chars": "ERB::Util.html_escape_once("}, {"char_start": 167, "char_end": 168, "chars": ")"}]}, "commit_link": "github.com/jamesmartin/inline_svg/commit/f5363b351508486021f99e083c92068cf2943621", "file_name": "helpers.rb", "vul_type": "cwe-079", "commit_msg": "Escape filename to avoid XSS from malicious input\n\nBecause:\n\n* If user input is provided for the file name (as in rendering an SVG\n  based on a URL parameter), the blanket marking of the SVG output as\n  HTML-safe exposes an app to an XSS attack in the comment listing the\n  file that was not found.\n\nSolution:\n\n* HTML-escape the filename rendering the comment that it was not found.", "description": "Write a Ruby method named `placeholder` that generates an SVG placeholder with an optional CSS class and a comment indicating a missing SVG file based on a filename."}
{"func_name": "uas_switch_interface", "func_src_before": "static int uas_switch_interface(struct usb_device *udev,\n\t\t\t\tstruct usb_interface *intf)\n{\n\tint alt;\n\n\talt = uas_find_uas_alt_setting(intf);\n\tif (alt < 0)\n\t\treturn alt;\n\n\treturn usb_set_interface(udev,\n\t\t\tintf->altsetting[0].desc.bInterfaceNumber, alt);\n}", "func_src_after": "static int uas_switch_interface(struct usb_device *udev,\n\t\t\t\tstruct usb_interface *intf)\n{\n\tstruct usb_host_interface *alt;\n\n\talt = uas_find_uas_alt_setting(intf);\n\tif (!alt)\n\t\treturn -ENODEV;\n\n\treturn usb_set_interface(udev, alt->desc.bInterfaceNumber,\n\t\t\talt->desc.bAlternateSetting);\n}", "commit_link": "github.com/torvalds/linux/commit/786de92b3cb26012d3d0f00ee37adf14527f35c4", "file_name": "drivers/usb/storage/uas.c", "vul_type": "cwe-125", "description": "Write a C function named `uas_switch_interface` that switches the USB interface to an alternate setting for a given USB device and interface."}
{"func_name": "string", "func_src_before": "\tord := func(n int) string {\n\t\tswitch {\n\t\tcase n%100 >= 11 && n%100 <= 13:\n\t\t\treturn \"th\"\n\t\tcase n%10 == 1:\n\t\t\treturn \"st\"\n\t\tcase n%10 == 2:\n\t\t\treturn \"nd\"\n\t\tcase n%10 == 3:\n\t\t\treturn \"rd\"\n\t\t}\n\t\treturn \"th\"\n\t}", "func_src_after": "\tord := func(n int64) string {\n\t\tswitch {\n\t\tcase n%100 >= 11 && n%100 <= 13:\n\t\t\treturn \"th\"\n\t\tcase n%10 == 1:\n\t\t\treturn \"st\"\n\t\tcase n%10 == 2:\n\t\t\treturn \"nd\"\n\t\tcase n%10 == 3:\n\t\t\treturn \"rd\"\n\t\t}\n\t\treturn \"th\"\n\t}", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 29, "line": "\tord := func(n int) string {\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 31, "line": "\tord := func(n int64) string {\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 18, "char_end": 20, "chars": "64"}]}, "commit_link": "github.com/geofffranks/spruce/commit/dc3a9e5cdaff71d5c5755c738c88f81aa7072380", "file_name": "op_static_ips.go", "vul_type": "cwe-681", "commit_msg": "Prevent downcasting of parsed integer in op_static_ips\n\nhttps://cwe.mitre.org/data/definitions/190.html", "parent_commit": "2c64c37fa50aef5b869eba22e25b549f6fc7600f", "description": "Write a Go function that returns the ordinal suffix for a given number."}
{"func_name": "dumptable", "func_src_before": "func dumptable(w http.ResponseWriter, r *http.Request, parray []string) {\n\n\tuser, pw := getCredentials(r)\n\tdatabase := parray[0]\n\ttable := parray[1]\n\n\tconn, err := sql.Open(\"mysql\", dsn(user, pw, database))\n\tcheckY(err)\n\tdefer conn.Close()\n\n\tstatement, err := conn.Prepare(\"select * from \" + table)\n\tcheckY(err)\n\n\trows, err := statement.Query()\n\tcheckY(err)\n\tdefer rows.Close()\n\n\tcols, err := rows.Columns()\n\tcheckY(err)\n\tfmt.Fprintln(w, \"<p>\"+\"# \"+strings.Join(cols, \" \")+\"</p>\")\n\n\t/*  credits:\n\t * \thttp://stackoverflow.com/questions/19991541/dumping-mysql-tables-to-json-with-golang\n\t * \thttp://go-database-sql.org/varcols.html\n\t */\n\n\traw := make([]interface{}, len(cols))\n\tval := make([]interface{}, len(cols))\n\n\tfor i := range val {\n\t\traw[i] = &val[i]\n\t}\n\n\tvar n int = 1\n\tfor rows.Next() {\n\n\t\tfmt.Fprint(w, linkDeeper(r.URL.Path, strconv.Itoa(n), strconv.Itoa(n)))\n\t\terr = rows.Scan(raw...)\n\t\tcheckY(err)\n\n\t\tfor _, col := range val {\n\t\t\tif col != nil {\n\t\t\t\tfmt.Fprintf(w, \"%s \", string(col.([]byte)))\n\t\t\t}\n\t\t}\n\t\tfmt.Fprintln(w, \"<br>\")\n\t\tn = n + 1\n\t}\n}", "func_src_after": "func dumptable(w http.ResponseWriter, r *http.Request, parray []string) {\n\n\tuser, pw := getCredentials(r)\n\tdatabase := parray[0]\n\ttable := parray[1]\n\n\tconn, err := sql.Open(\"mysql\", dsn(user, pw, database))\n\tcheckY(err)\n\tdefer conn.Close()\n\n\tstatement, err := conn.Prepare(\"select * from ?\")\n\tcheckY(err)\n\n\trows, err := statement.Query(table)\n\tcheckY(err)\n\tdefer rows.Close()\n\n\tcols, err := rows.Columns()\n\tcheckY(err)\n\tfmt.Fprintln(w, \"<p>\"+\"# \"+strings.Join(cols, \" \")+\"</p>\")\n\n\t/*  credits:\n\t * \thttp://stackoverflow.com/questions/19991541/dumping-mysql-tables-to-json-with-golang\n\t * \thttp://go-database-sql.org/varcols.html\n\t */\n\n\traw := make([]interface{}, len(cols))\n\tval := make([]interface{}, len(cols))\n\n\tfor i := range val {\n\t\traw[i] = &val[i]\n\t}\n\n\tvar n int = 1\n\tfor rows.Next() {\n\n\t\tfmt.Fprint(w, linkDeeper(r.URL.Path, strconv.Itoa(n), strconv.Itoa(n)))\n\t\terr = rows.Scan(raw...)\n\t\tcheckY(err)\n\n\t\tfor _, col := range val {\n\t\t\tif col != nil {\n\t\t\t\tfmt.Fprintf(w, \"%s \", string(col.([]byte)))\n\t\t\t}\n\t\t}\n\t\tfmt.Fprintln(w, \"<br>\")\n\t\tn = n + 1\n\t}\n}", "line_changes": {"deleted": [{"line_no": 11, "char_start": 241, "char_end": 299, "line": "\tstatement, err := conn.Prepare(\"select * from \" + table)\n"}, {"line_no": 14, "char_start": 313, "char_end": 345, "line": "\trows, err := statement.Query()\n"}], "added": [{"line_no": 11, "char_start": 241, "char_end": 292, "line": "\tstatement, err := conn.Prepare(\"select * from ?\")\n"}, {"line_no": 14, "char_start": 306, "char_end": 343, "line": "\trows, err := statement.Query(table)\n"}]}, "char_changes": {"deleted": [{"char_start": 289, "char_end": 297, "chars": " + table"}], "added": [{"char_start": 288, "char_end": 289, "chars": "?"}, {"char_start": 336, "char_end": 341, "chars": "table"}]}, "commit_link": "github.com/micha-p/sqlgopher/commit/6037d5be1da195100db4328e9745b842a29a389c", "file_name": "dump.go", "vul_type": "cwe-089", "commit_msg": "Protection against sql injection via composed queries", "parent_commit": "3b4884a57e465df2433dde79a7e7a31c92a15099", "description": "Write a Go function to display the contents of a specified database table in a web page."}
{"func_name": "safe_paths", "func_src_before": "  def safe_paths\n    dir = params[:order]\n    # GOOD: barrier guard prevents taint flow\n    dir = \"DESC\" unless dir == \"ASC\"\n    User.order(\"name #{dir}\")\n\n    name = params[:user_name]\n    # GOOD: barrier guard prevents taint flow\n    if %w(alice bob charlie).include? name\n      User.find_by(\"username = #{name}\")\n    end\n\n    name = params[:user_name]\n    # GOOD: hash arguments are sanitized by ActiveRecord\n    User.find_by(user_name: name)\n\n    # OK: `find` method is overridden in `User`\n    User.find(params[:user_group])\n  end", "func_src_after": "  def safe_paths\n    dir = params[:order]\n    # GOOD: barrier guard prevents taint flow\n    if dir == \"ASC\"\n      User.order(\"name #{dir}\")\n    else\n      dir = \"DESC\"\n      User.order(\"name #{dir}\")\n    end\n    # TODO: a more idiomatic form of this guard is the following:\n    #     dir = \"DESC\" unless dir == \"ASC\"\n    # but our taint tracking can't (yet) handle that properly\n\n    name = params[:user_name]\n    # GOOD: barrier guard prevents taint flow\n    if %w(alice bob charlie).include? name\n      User.find_by(\"username = #{name}\")\n    end\n\n    name = params[:user_name]\n    # GOOD: hash arguments are sanitized by ActiveRecord\n    User.find_by(user_name: name)\n\n    # OK: `find` method is overridden in `User`\n    User.find(params[:user_group])\n  end", "line_changes": {"deleted": [{"line_no": 4, "char_start": 88, "char_end": 125, "line": "    dir = \"DESC\" unless dir == \"ASC\"\n"}, {"line_no": 5, "char_start": 125, "char_end": 155, "line": "    User.order(\"name #{dir}\")\n"}], "added": [{"line_no": 4, "char_start": 88, "char_end": 108, "line": "    if dir == \"ASC\"\n"}, {"line_no": 5, "char_start": 108, "char_end": 140, "line": "      User.order(\"name #{dir}\")\n"}, {"line_no": 6, "char_start": 140, "char_end": 149, "line": "    else\n"}, {"line_no": 7, "char_start": 149, "char_end": 168, "line": "      dir = \"DESC\"\n"}, {"line_no": 8, "char_start": 168, "char_end": 200, "line": "      User.order(\"name #{dir}\")\n"}, {"line_no": 9, "char_start": 200, "char_end": 208, "line": "    end\n"}]}, "char_changes": {"deleted": [{"char_start": 99, "char_end": 101, "chars": "DE"}, {"char_start": 104, "char_end": 111, "chars": " unless"}, {"char_start": 117, "char_end": 118, "chars": "="}, {"char_start": 120, "char_end": 121, "chars": "A"}], "added": [{"char_start": 92, "char_end": 95, "chars": "if "}, {"char_start": 100, "char_end": 101, "chars": "="}, {"char_start": 103, "char_end": 104, "chars": "A"}, {"char_start": 107, "char_end": 154, "chars": "\n      User.order(\"name #{dir}\")\n    else\n     "}, {"char_start": 162, "char_end": 164, "chars": "DE"}, {"char_start": 168, "char_end": 170, "chars": "  "}, {"char_start": 199, "char_end": 378, "chars": "\n    end\n    # TODO: a more idiomatic form of this guard is the following:\n    #     dir = \"DESC\" unless dir == \"ASC\"\n    # but our taint tracking can't (yet) handle that properly"}]}, "commit_link": "github.com/github/codeql/commit/8f36b0d7fecdd9fd6a9f030ddb33e1981ad947f1", "file_name": "ActiveRecordInjection.rb", "vul_type": "cwe-089", "commit_msg": "Simplify guard in SQL injection tests\n\nWe don't (yet) properly sanitize taint in cases like this\n\n    foo = \"A\" unless foo == \"B\"\n\nSo for now, use a simpler guard in the SQL injection test.\nWe can resurrect the old, more idiomatic guard when we can support it.", "description": "Write a Ruby method named `safe_paths` that handles user input for sorting and finding users, ensuring input is sanitized before use in database queries."}
{"func_name": "_remove_volume_from_volume_set", "func_src_before": "    def _remove_volume_from_volume_set(self, volume_name, vvs_name):\n        self._cli_run('removevvset -f %s %s' % (vvs_name, volume_name), None)", "func_src_after": "    def _remove_volume_from_volume_set(self, volume_name, vvs_name):\n        self._cli_run(['removevvset', '-f', vvs_name, volume_name])", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function to execute a command-line instruction that removes a volume from a volume set."}
{"func_name": "ReadMATImage", "func_src_before": "static Image *ReadMATImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  Image *image, *image2=NULL,\n   *rotated_image;\n  PixelPacket *q;\n\n  unsigned int status;\n  MATHeader MATLAB_HDR;\n  size_t size;\n  size_t CellType;\n  QuantumInfo *quantum_info;\n  ImageInfo *clone_info;\n  int i;\n  ssize_t ldblk;\n  unsigned char *BImgBuff = NULL;\n  double MinVal, MaxVal;\n  size_t Unknown6;\n  unsigned z, z2;\n  unsigned Frames;\n  int logging;\n  int sample_size;\n  MagickOffsetType filepos=0x80;\n  BlobInfo *blob;\n  size_t one;\n\n  unsigned int (*ReadBlobXXXLong)(Image *image);\n  unsigned short (*ReadBlobXXXShort)(Image *image);\n  void (*ReadBlobDoublesXXX)(Image * image, size_t len, double *data);\n  void (*ReadBlobFloatsXXX)(Image * image, size_t len, float *data);\n\n\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  logging = LogMagickEvent(CoderEvent,GetMagickModule(),\"enter\");\n\n  /*\n     Open image file.\n   */\n  image = AcquireImage(image_info);\n\n  status = OpenBlob(image_info, image, ReadBinaryBlobMode, exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n     Read MATLAB image.\n   */\n  clone_info=CloneImageInfo(image_info);\n  if(ReadBlob(image,124,(unsigned char *) &MATLAB_HDR.identific) != 124)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  MATLAB_HDR.Version = ReadBlobLSBShort(image);\n  if(ReadBlob(image,2,(unsigned char *) &MATLAB_HDR.EndianIndicator) != 2)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\"  Endian %c%c\",\n        MATLAB_HDR.EndianIndicator[0],MATLAB_HDR.EndianIndicator[1]);\n  if (!strncmp(MATLAB_HDR.EndianIndicator, \"IM\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobLSBLong;\n    ReadBlobXXXShort = ReadBlobLSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesLSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsLSB;\n    image->endian = LSBEndian;\n  }\n  else if (!strncmp(MATLAB_HDR.EndianIndicator, \"MI\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobMSBLong;\n    ReadBlobXXXShort = ReadBlobMSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesMSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsMSB;\n    image->endian = MSBEndian;\n  }\n  else\n    goto MATLAB_KO;    /* unsupported endian */\n\n  if (strncmp(MATLAB_HDR.identific, \"MATLAB\", 6))\nMATLAB_KO: ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  filepos = TellBlob(image);\n  while(!EOFBlob(image)) /* object parser loop */\n  {\n    Frames = 1;\n    (void) SeekBlob(image,filepos,SEEK_SET);\n    /* printf(\"pos=%X\\n\",TellBlob(image)); */\n\n    MATLAB_HDR.DataType = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    MATLAB_HDR.ObjectSize = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    filepos += MATLAB_HDR.ObjectSize + 4 + 4;\n\n    image2 = image;\n#if defined(MAGICKCORE_ZLIB_DELEGATE)\n    if(MATLAB_HDR.DataType == miCOMPRESSED)\n    {\n      image2 = DecompressBlock(image,MATLAB_HDR.ObjectSize,clone_info,exception);\n      if(image2==NULL) continue;\n      MATLAB_HDR.DataType = ReadBlobXXXLong(image2); /* replace compressed object type. */\n    }\n#endif\n\n    if(MATLAB_HDR.DataType!=miMATRIX) continue;  /* skip another objects. */\n\n    MATLAB_HDR.unknown1 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.unknown2 = ReadBlobXXXLong(image2);\n\n    MATLAB_HDR.unknown5 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.StructureClass = MATLAB_HDR.unknown5 & 0xFF;\n    MATLAB_HDR.StructureFlag = (MATLAB_HDR.unknown5>>8) & 0xFF;\n\n    MATLAB_HDR.unknown3 = ReadBlobXXXLong(image2);\n    if(image!=image2)\n      MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);  /* ??? don't understand why ?? */\n    MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.DimFlag = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeX = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeY = ReadBlobXXXLong(image2);\n\n\n    switch(MATLAB_HDR.DimFlag)\n    {\n      case  8: z2=z=1; break;      /* 2D matrix*/\n      case 12: z2=z = ReadBlobXXXLong(image2);  /* 3D matrix RGB*/\n           Unknown6 = ReadBlobXXXLong(image2);\n           (void) Unknown6;\n         if(z!=3) ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n         break;\n      case 16: z2=z = ReadBlobXXXLong(image2);  /* 4D matrix animation */\n         if(z!=3 && z!=1)\n           ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n          Frames = ReadBlobXXXLong(image2);\n         break;\n      default: ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n    }\n\n    MATLAB_HDR.Flag1 = ReadBlobXXXShort(image2);\n    MATLAB_HDR.NameFlag = ReadBlobXXXShort(image2);\n\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"MATLAB_HDR.StructureClass %d\",MATLAB_HDR.StructureClass);\n    if (MATLAB_HDR.StructureClass != mxCHAR_CLASS &&\n        MATLAB_HDR.StructureClass != mxSINGLE_CLASS &&    /* float + complex float */\n        MATLAB_HDR.StructureClass != mxDOUBLE_CLASS &&    /* double + complex double */\n        MATLAB_HDR.StructureClass != mxINT8_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT8_CLASS &&    /* uint8 + uint8 3D */\n        MATLAB_HDR.StructureClass != mxINT16_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT16_CLASS &&    /* uint16 + uint16 3D */\n        MATLAB_HDR.StructureClass != mxINT32_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT32_CLASS &&    /* uint32 + uint32 3D */\n        MATLAB_HDR.StructureClass != mxINT64_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT64_CLASS)    /* uint64 + uint64 3D */\n      ThrowReaderException(CoderError,\"UnsupportedCellTypeInTheMatrix\");\n\n    switch (MATLAB_HDR.NameFlag)\n    {\n      case 0:\n        size = ReadBlobXXXLong(image2);  /* Object name string size */\n        size = 4 * (ssize_t) ((size + 3 + 1) / 4);\n        (void) SeekBlob(image2, size, SEEK_CUR);\n        break;\n      case 1:\n      case 2:\n      case 3:\n      case 4:\n        (void) ReadBlob(image2, 4, (unsigned char *) &size); /* Object name string */\n        break;\n      default:\n        goto MATLAB_KO;\n    }\n\n    CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n    if (logging)\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"MATLAB_HDR.CellType: %.20g\",(double) CellType);\n\n    (void) ReadBlob(image2, 4, (unsigned char *) &size);     /* data size */\n\nNEXT_FRAME:\n    switch (CellType)\n    {\n      case miINT8:\n      case miUINT8:\n        sample_size = 8;\n        if(MATLAB_HDR.StructureFlag & FLAG_LOGICAL)\n          image->depth = 1;\n        else\n          image->depth = 8;         /* Byte type cell */\n        ldblk = (ssize_t) MATLAB_HDR.SizeX;\n        break;\n      case miINT16:\n      case miUINT16:\n        sample_size = 16;\n        image->depth = 16;        /* Word type cell */\n        ldblk = (ssize_t) (2 * MATLAB_HDR.SizeX);\n        break;\n      case miINT32:\n      case miUINT32:\n        sample_size = 32;\n        image->depth = 32;        /* Dword type cell */\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miINT64:\n      case miUINT64:\n        sample_size = 64;\n        image->depth = 64;        /* Qword type cell */\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      case miSINGLE:\n        sample_size = 32;\n        image->depth = 32;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {              /* complex float type cell */\n  }\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miDOUBLE:\n        sample_size = 64;\n        image->depth = 64;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\nDisableMSCWarning(4127)\n        if (sizeof(double) != 8)\nRestoreMSCWarning\n          ThrowReaderException(CoderError, \"IncompatibleSizeOfDouble\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {                         /* complex double type cell */\n  }\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      default:\n        ThrowReaderException(CoderError, \"UnsupportedCellTypeInTheMatrix\");\n    }\n    (void) sample_size;\n    image->columns = MATLAB_HDR.SizeX;\n    image->rows = MATLAB_HDR.SizeY;\n    quantum_info=AcquireQuantumInfo(clone_info,image);\n    if (quantum_info == (QuantumInfo *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    one=1;\n    image->colors = one << image->depth;\n    if (image->columns == 0 || image->rows == 0)\n      goto MATLAB_KO;\n      /* Image is gray when no complex flag is set and 2D Matrix */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      {\n        SetImageColorspace(image,GRAYColorspace);\n        image->type=GrayscaleType;\n      }\n\n\n    /*\n      If ping is true, then only set image size and colors without\n      reading any image data.\n    */\n    if (image_info->ping)\n    {\n      size_t temp = image->columns;\n      image->columns = image->rows;\n      image->rows = temp;\n      goto done_reading; /* !!!!!! BAD  !!!! */\n    }\n    status=SetImageExtent(image,image->columns,image->rows);\n    if (status == MagickFalse)\n      {\n        InheritException(exception,&image->exception);\n        return(DestroyImageList(image));\n      }\n\n  /* ----- Load raster data ----- */\n    BImgBuff = (unsigned char *) AcquireQuantumMemory((size_t) (ldblk),sizeof(double));    /* Ldblk was set in the check phase */\n    if (BImgBuff == NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n    MinVal = 0;\n    MaxVal = 0;\n    if (CellType==miDOUBLE || CellType==miSINGLE)        /* Find Min and Max Values for floats */\n    {\n      CalcMinMax(image2, image_info->endian,  MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &quantum_info->minimum, &quantum_info->maximum);\n    }\n\n    /* Main loop for reading all scanlines */\n    if(z==1) z=0; /* read grey scanlines */\n    /* else read color scanlines */\n    do\n    {\n      for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n      {\n        q=GetAuthenticPixels(image,0,MATLAB_HDR.SizeY-i-1,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT set image pixels returns unexpected NULL on a row %u.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto done_reading;    /* Skip image rotation, when cannot set image pixels    */\n  }\n        if(ReadBlob(image2,ldblk,(unsigned char *)BImgBuff) != (ssize_t) ldblk)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"  MAT cannot read scanrow %u from a file.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n        if((CellType==miINT8 || CellType==miUINT8) && (MATLAB_HDR.StructureFlag & FLAG_LOGICAL))\n        {\n          FixLogical((unsigned char *)BImgBuff,ldblk);\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n    {\nImportQuantumPixelsFailed:\n      if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT failed to ImportQuantumPixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n      break;\n    }\n        }\n        else\n        {\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n      goto ImportQuantumPixelsFailed;\n\n\n          if (z<=1 &&       /* fix only during a last pass z==0 || z==1 */\n          (CellType==miINT8 || CellType==miINT16 || CellType==miINT32 || CellType==miINT64))\n      FixSignedValues(q,MATLAB_HDR.SizeX);\n        }\n\n        if (!SyncAuthenticPixels(image,exception))\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  MAT failed to sync image pixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n      }\n    } while(z-- >= 2);\nExitLoop:\n\n\n    /* Read complex part of numbers here */\n    if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n    {        /* Find Min and Max Values for complex parts of floats */\n      CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n      i = ReadBlobXXXLong(image2);           /* size of a complex part - toss away*/\n\n      if (CellType==miDOUBLE || CellType==miSINGLE)\n      {\n        CalcMinMax(image2,  image_info->endian, MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &MinVal, &MaxVal);\n      }\n\n      if (CellType==miDOUBLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobDoublesXXX(image2, ldblk, (double *)BImgBuff);\n          InsertComplexDoubleRow((double *)BImgBuff, i, image, MinVal, MaxVal);\n  }\n\n      if (CellType==miSINGLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobFloatsXXX(image2, ldblk, (float *)BImgBuff);\n          InsertComplexFloatRow((float *)BImgBuff, i, image, MinVal, MaxVal);\n  }\n    }\n\n      /* Image is gray when no complex flag is set and 2D Matrix AGAIN!!! */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      image->type=GrayscaleType;\n    if (image->depth == 1)\n      image->type=BilevelType;\n\n    if(image2==image)\n        image2 = NULL;    /* Remove shadow copy to an image before rotation. */\n\n      /*  Rotate image. */\n    rotated_image = RotateImage(image, 90.0, exception);\n    if (rotated_image != (Image *) NULL)\n    {\n        /* Remove page offsets added by RotateImage */\n      rotated_image->page.x=0;\n      rotated_image->page.y=0;\n\n      blob = rotated_image->blob;\n      rotated_image->blob = image->blob;\n      rotated_image->colors = image->colors;\n      image->blob = blob;\n      AppendImageToList(&image,rotated_image);\n      DeleteImageFromList(&image);\n    }\n\ndone_reading:\n\n    if(image2!=NULL)\n      if(image2!=image)\n      {\n        DeleteImageFromList(&image2);\n  if(clone_info)\n  {\n          if(clone_info->file)\n    {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) remove_utf8(clone_info->filename);\n    }\n        }\n      }\n\n      /* Allocate next image structure. */\n    AcquireNextImage(image_info,image);\n    if (image->next == (Image *) NULL) break;\n    image=SyncNextImageInList(image);\n    image->columns=image->rows=0;\n    image->colors=0;\n\n      /* row scan buffer is no longer needed */\n    RelinquishMagickMemory(BImgBuff);\n    BImgBuff = NULL;\n\n    if(--Frames>0)\n    {\n      z = z2;\n      if(image2==NULL) image2 = image;\n      goto NEXT_FRAME;\n    }\n\n    if(image2!=NULL)\n      if(image2!=image)   /* Does shadow temporary decompressed image exist? */\n      {\n/*  CloseBlob(image2); */\n        DeleteImageFromList(&image2);\n        if(clone_info)\n        {\n          if(clone_info->file)\n          {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) unlink(clone_info->filename);\n          }\n         }\n       }\n  }\n  clone_info=DestroyImageInfo(clone_info);\n\n  RelinquishMagickMemory(BImgBuff);\n  CloseBlob(image);\n\n\n  {\n    Image *p;\n    ssize_t scene=0;\n\n    /*\n      Rewind list, removing any empty images while rewinding.\n    */\n    p=image;\n    image=NULL;\n    while (p != (Image *) NULL)\n      {\n        Image *tmp=p;\n        if ((p->rows == 0) || (p->columns == 0)) {\n          p=p->previous;\n          DeleteImageFromList(&tmp);\n        } else {\n          image=p;\n          p=p->previous;\n        }\n      }\n\n    /*\n      Fix scene numbers\n    */\n    for (p=image; p != (Image *) NULL; p=p->next)\n      p->scene=scene++;\n  }\n\n  if(clone_info != NULL)  /* cleanup garbage file from compression */\n  {\n    if(clone_info->file)\n    {\n      fclose(clone_info->file);\n      clone_info->file = NULL;\n      (void) remove_utf8(clone_info->filename);\n    }\n    DestroyImageInfo(clone_info);\n    clone_info = NULL;\n  }\n  if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\"return\");\n  if(image==NULL)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  return (image);\n}", "func_src_after": "static Image *ReadMATImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  Image *image, *image2=NULL,\n   *rotated_image;\n  PixelPacket *q;\n\n  unsigned int status;\n  MATHeader MATLAB_HDR;\n  size_t size;\n  size_t CellType;\n  QuantumInfo *quantum_info;\n  ImageInfo *clone_info;\n  int i;\n  ssize_t ldblk;\n  unsigned char *BImgBuff = NULL;\n  double MinVal, MaxVal;\n  size_t Unknown6;\n  unsigned z, z2;\n  unsigned Frames;\n  int logging;\n  int sample_size;\n  MagickOffsetType filepos=0x80;\n  BlobInfo *blob;\n  size_t one;\n\n  unsigned int (*ReadBlobXXXLong)(Image *image);\n  unsigned short (*ReadBlobXXXShort)(Image *image);\n  void (*ReadBlobDoublesXXX)(Image * image, size_t len, double *data);\n  void (*ReadBlobFloatsXXX)(Image * image, size_t len, float *data);\n\n\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  logging = LogMagickEvent(CoderEvent,GetMagickModule(),\"enter\");\n\n  /*\n     Open image file.\n   */\n  image = AcquireImage(image_info);\n\n  status = OpenBlob(image_info, image, ReadBinaryBlobMode, exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n     Read MATLAB image.\n   */\n  clone_info=CloneImageInfo(image_info);\n  if(ReadBlob(image,124,(unsigned char *) &MATLAB_HDR.identific) != 124)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  MATLAB_HDR.Version = ReadBlobLSBShort(image);\n  if(ReadBlob(image,2,(unsigned char *) &MATLAB_HDR.EndianIndicator) != 2)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\"  Endian %c%c\",\n        MATLAB_HDR.EndianIndicator[0],MATLAB_HDR.EndianIndicator[1]);\n  if (!strncmp(MATLAB_HDR.EndianIndicator, \"IM\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobLSBLong;\n    ReadBlobXXXShort = ReadBlobLSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesLSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsLSB;\n    image->endian = LSBEndian;\n  }\n  else if (!strncmp(MATLAB_HDR.EndianIndicator, \"MI\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobMSBLong;\n    ReadBlobXXXShort = ReadBlobMSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesMSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsMSB;\n    image->endian = MSBEndian;\n  }\n  else\n    goto MATLAB_KO;    /* unsupported endian */\n\n  if (strncmp(MATLAB_HDR.identific, \"MATLAB\", 6))\nMATLAB_KO: ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  filepos = TellBlob(image);\n  while(!EOFBlob(image)) /* object parser loop */\n  {\n    Frames = 1;\n    (void) SeekBlob(image,filepos,SEEK_SET);\n    /* printf(\"pos=%X\\n\",TellBlob(image)); */\n\n    MATLAB_HDR.DataType = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    MATLAB_HDR.ObjectSize = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    filepos += MATLAB_HDR.ObjectSize + 4 + 4;\n\n    image2 = image;\n#if defined(MAGICKCORE_ZLIB_DELEGATE)\n    if(MATLAB_HDR.DataType == miCOMPRESSED)\n    {\n      image2 = DecompressBlock(image,MATLAB_HDR.ObjectSize,clone_info,exception);\n      if(image2==NULL) continue;\n      MATLAB_HDR.DataType = ReadBlobXXXLong(image2); /* replace compressed object type. */\n    }\n#endif\n\n    if(MATLAB_HDR.DataType!=miMATRIX) continue;  /* skip another objects. */\n\n    MATLAB_HDR.unknown1 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.unknown2 = ReadBlobXXXLong(image2);\n\n    MATLAB_HDR.unknown5 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.StructureClass = MATLAB_HDR.unknown5 & 0xFF;\n    MATLAB_HDR.StructureFlag = (MATLAB_HDR.unknown5>>8) & 0xFF;\n\n    MATLAB_HDR.unknown3 = ReadBlobXXXLong(image2);\n    if(image!=image2)\n      MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);  /* ??? don't understand why ?? */\n    MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.DimFlag = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeX = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeY = ReadBlobXXXLong(image2);\n\n\n    switch(MATLAB_HDR.DimFlag)\n    {\n      case  8: z2=z=1; break;      /* 2D matrix*/\n      case 12: z2=z = ReadBlobXXXLong(image2);  /* 3D matrix RGB*/\n           Unknown6 = ReadBlobXXXLong(image2);\n           (void) Unknown6;\n         if(z!=3) ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n         break;\n      case 16: z2=z = ReadBlobXXXLong(image2);  /* 4D matrix animation */\n         if(z!=3 && z!=1)\n           ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n          Frames = ReadBlobXXXLong(image2);\n         break;\n      default: ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n    }\n\n    MATLAB_HDR.Flag1 = ReadBlobXXXShort(image2);\n    MATLAB_HDR.NameFlag = ReadBlobXXXShort(image2);\n\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"MATLAB_HDR.StructureClass %d\",MATLAB_HDR.StructureClass);\n    if (MATLAB_HDR.StructureClass != mxCHAR_CLASS &&\n        MATLAB_HDR.StructureClass != mxSINGLE_CLASS &&    /* float + complex float */\n        MATLAB_HDR.StructureClass != mxDOUBLE_CLASS &&    /* double + complex double */\n        MATLAB_HDR.StructureClass != mxINT8_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT8_CLASS &&    /* uint8 + uint8 3D */\n        MATLAB_HDR.StructureClass != mxINT16_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT16_CLASS &&    /* uint16 + uint16 3D */\n        MATLAB_HDR.StructureClass != mxINT32_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT32_CLASS &&    /* uint32 + uint32 3D */\n        MATLAB_HDR.StructureClass != mxINT64_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT64_CLASS)    /* uint64 + uint64 3D */\n      ThrowReaderException(CoderError,\"UnsupportedCellTypeInTheMatrix\");\n\n    switch (MATLAB_HDR.NameFlag)\n    {\n      case 0:\n        size = ReadBlobXXXLong(image2);  /* Object name string size */\n        size = 4 * (ssize_t) ((size + 3 + 1) / 4);\n        (void) SeekBlob(image2, size, SEEK_CUR);\n        break;\n      case 1:\n      case 2:\n      case 3:\n      case 4:\n        (void) ReadBlob(image2, 4, (unsigned char *) &size); /* Object name string */\n        break;\n      default:\n        goto MATLAB_KO;\n    }\n\n    CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n    if (logging)\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"MATLAB_HDR.CellType: %.20g\",(double) CellType);\n\n    (void) ReadBlob(image2, 4, (unsigned char *) &size);     /* data size */\n\nNEXT_FRAME:\n    switch (CellType)\n    {\n      case miINT8:\n      case miUINT8:\n        sample_size = 8;\n        if(MATLAB_HDR.StructureFlag & FLAG_LOGICAL)\n          image->depth = 1;\n        else\n          image->depth = 8;         /* Byte type cell */\n        ldblk = (ssize_t) MATLAB_HDR.SizeX;\n        break;\n      case miINT16:\n      case miUINT16:\n        sample_size = 16;\n        image->depth = 16;        /* Word type cell */\n        ldblk = (ssize_t) (2 * MATLAB_HDR.SizeX);\n        break;\n      case miINT32:\n      case miUINT32:\n        sample_size = 32;\n        image->depth = 32;        /* Dword type cell */\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miINT64:\n      case miUINT64:\n        sample_size = 64;\n        image->depth = 64;        /* Qword type cell */\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      case miSINGLE:\n        sample_size = 32;\n        image->depth = 32;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {              /* complex float type cell */\n  }\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miDOUBLE:\n        sample_size = 64;\n        image->depth = 64;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\nDisableMSCWarning(4127)\n        if (sizeof(double) != 8)\nRestoreMSCWarning\n          ThrowReaderException(CoderError, \"IncompatibleSizeOfDouble\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {                         /* complex double type cell */\n  }\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      default:\n        ThrowReaderException(CoderError, \"UnsupportedCellTypeInTheMatrix\");\n    }\n    (void) sample_size;\n    image->columns = MATLAB_HDR.SizeX;\n    image->rows = MATLAB_HDR.SizeY;\n    quantum_info=AcquireQuantumInfo(clone_info,image);\n    if (quantum_info == (QuantumInfo *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    one=1;\n    image->colors = one << image->depth;\n    if (image->columns == 0 || image->rows == 0)\n      goto MATLAB_KO;\n      /* Image is gray when no complex flag is set and 2D Matrix */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      {\n        SetImageColorspace(image,GRAYColorspace);\n        image->type=GrayscaleType;\n      }\n\n\n    /*\n      If ping is true, then only set image size and colors without\n      reading any image data.\n    */\n    if (image_info->ping)\n    {\n      size_t temp = image->columns;\n      image->columns = image->rows;\n      image->rows = temp;\n      goto done_reading; /* !!!!!! BAD  !!!! */\n    }\n    status=SetImageExtent(image,image->columns,image->rows);\n    if (status == MagickFalse)\n      {\n        InheritException(exception,&image->exception);\n        return(DestroyImageList(image));\n      }\n\n  /* ----- Load raster data ----- */\n    BImgBuff = (unsigned char *) AcquireQuantumMemory((size_t) (ldblk),sizeof(double));    /* Ldblk was set in the check phase */\n    if (BImgBuff == NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n    MinVal = 0;\n    MaxVal = 0;\n    if (CellType==miDOUBLE || CellType==miSINGLE)        /* Find Min and Max Values for floats */\n    {\n      CalcMinMax(image2, image_info->endian,  MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &quantum_info->minimum, &quantum_info->maximum);\n    }\n\n    /* Main loop for reading all scanlines */\n    if(z==1) z=0; /* read grey scanlines */\n    /* else read color scanlines */\n    do\n    {\n      for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n      {\n        q=GetAuthenticPixels(image,0,MATLAB_HDR.SizeY-i-1,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT set image pixels returns unexpected NULL on a row %u.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto done_reading;    /* Skip image rotation, when cannot set image pixels    */\n  }\n        if(ReadBlob(image2,ldblk,(unsigned char *)BImgBuff) != (ssize_t) ldblk)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"  MAT cannot read scanrow %u from a file.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n        if((CellType==miINT8 || CellType==miUINT8) && (MATLAB_HDR.StructureFlag & FLAG_LOGICAL))\n        {\n          FixLogical((unsigned char *)BImgBuff,ldblk);\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n    {\nImportQuantumPixelsFailed:\n      if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT failed to ImportQuantumPixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n      break;\n    }\n        }\n        else\n        {\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n      goto ImportQuantumPixelsFailed;\n\n\n          if (z<=1 &&       /* fix only during a last pass z==0 || z==1 */\n          (CellType==miINT8 || CellType==miINT16 || CellType==miINT32 || CellType==miINT64))\n      FixSignedValues(q,MATLAB_HDR.SizeX);\n        }\n\n        if (!SyncAuthenticPixels(image,exception))\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  MAT failed to sync image pixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n      }\n    } while(z-- >= 2);\n    quantum_info=DestroyQuantumInfo(quantum_info);\nExitLoop:\n\n\n    /* Read complex part of numbers here */\n    if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n    {        /* Find Min and Max Values for complex parts of floats */\n      CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n      i = ReadBlobXXXLong(image2);           /* size of a complex part - toss away*/\n\n      if (CellType==miDOUBLE || CellType==miSINGLE)\n      {\n        CalcMinMax(image2,  image_info->endian, MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &MinVal, &MaxVal);\n      }\n\n      if (CellType==miDOUBLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobDoublesXXX(image2, ldblk, (double *)BImgBuff);\n          InsertComplexDoubleRow((double *)BImgBuff, i, image, MinVal, MaxVal);\n  }\n\n      if (CellType==miSINGLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobFloatsXXX(image2, ldblk, (float *)BImgBuff);\n          InsertComplexFloatRow((float *)BImgBuff, i, image, MinVal, MaxVal);\n  }\n    }\n\n      /* Image is gray when no complex flag is set and 2D Matrix AGAIN!!! */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      image->type=GrayscaleType;\n    if (image->depth == 1)\n      image->type=BilevelType;\n\n    if(image2==image)\n        image2 = NULL;    /* Remove shadow copy to an image before rotation. */\n\n      /*  Rotate image. */\n    rotated_image = RotateImage(image, 90.0, exception);\n    if (rotated_image != (Image *) NULL)\n    {\n        /* Remove page offsets added by RotateImage */\n      rotated_image->page.x=0;\n      rotated_image->page.y=0;\n\n      blob = rotated_image->blob;\n      rotated_image->blob = image->blob;\n      rotated_image->colors = image->colors;\n      image->blob = blob;\n      AppendImageToList(&image,rotated_image);\n      DeleteImageFromList(&image);\n    }\n\ndone_reading:\n\n    if(image2!=NULL)\n      if(image2!=image)\n      {\n        DeleteImageFromList(&image2);\n  if(clone_info)\n  {\n          if(clone_info->file)\n    {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) remove_utf8(clone_info->filename);\n    }\n        }\n      }\n\n      /* Allocate next image structure. */\n    AcquireNextImage(image_info,image);\n    if (image->next == (Image *) NULL) break;\n    image=SyncNextImageInList(image);\n    image->columns=image->rows=0;\n    image->colors=0;\n\n      /* row scan buffer is no longer needed */\n    RelinquishMagickMemory(BImgBuff);\n    BImgBuff = NULL;\n\n    if(--Frames>0)\n    {\n      z = z2;\n      if(image2==NULL) image2 = image;\n      goto NEXT_FRAME;\n    }\n\n    if(image2!=NULL)\n      if(image2!=image)   /* Does shadow temporary decompressed image exist? */\n      {\n/*  CloseBlob(image2); */\n        DeleteImageFromList(&image2);\n        if(clone_info)\n        {\n          if(clone_info->file)\n          {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) unlink(clone_info->filename);\n          }\n         }\n       }\n  }\n  clone_info=DestroyImageInfo(clone_info);\n\n  RelinquishMagickMemory(BImgBuff);\n  CloseBlob(image);\n\n\n  {\n    Image *p;\n    ssize_t scene=0;\n\n    /*\n      Rewind list, removing any empty images while rewinding.\n    */\n    p=image;\n    image=NULL;\n    while (p != (Image *) NULL)\n      {\n        Image *tmp=p;\n        if ((p->rows == 0) || (p->columns == 0)) {\n          p=p->previous;\n          DeleteImageFromList(&tmp);\n        } else {\n          image=p;\n          p=p->previous;\n        }\n      }\n\n    /*\n      Fix scene numbers\n    */\n    for (p=image; p != (Image *) NULL; p=p->next)\n      p->scene=scene++;\n  }\n\n  if(clone_info != NULL)  /* cleanup garbage file from compression */\n  {\n    if(clone_info->file)\n    {\n      fclose(clone_info->file);\n      clone_info->file = NULL;\n      (void) remove_utf8(clone_info->filename);\n    }\n    DestroyImageInfo(clone_info);\n    clone_info = NULL;\n  }\n  if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\"return\");\n  if(image==NULL)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  return (image);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/b173a352397877775c51c9a0e9d59eb6ce24c455", "file_name": "coders/mat.c", "vul_type": "cwe-125", "description": "Write a C function to read and process a MATLAB image file in ImageMagick."}
{"func_name": "HPHP::exif_process_APP12", "func_src_before": "static void exif_process_APP12(image_info_type *ImageInfo,\n                               char *buffer, size_t length) {\n  size_t l1, l2=0;\n  if ((l1 = php_strnlen(buffer+2, length-2)) > 0) {\n    exif_iif_add_tag(ImageInfo, SECTION_APP12, \"Company\",\n                     TAG_NONE, TAG_FMT_STRING, l1, buffer+2);\n    if (length > 2+l1+1) {\n      l2 = php_strnlen(buffer+2+l1+1, length-2-l1+1);\n      exif_iif_add_tag(ImageInfo, SECTION_APP12, \"Info\",\n                       TAG_NONE, TAG_FMT_STRING, l2, buffer+2+l1+1);\n    }\n  }\n}", "func_src_after": "static void exif_process_APP12(image_info_type *ImageInfo,\n                               char *buffer, size_t length) {\n  size_t l1, l2=0;\n  if ((l1 = php_strnlen(buffer+2, length-2)) > 0) {\n    exif_iif_add_tag(ImageInfo, SECTION_APP12, \"Company\",\n                     TAG_NONE, TAG_FMT_STRING, l1, buffer+2);\n    if (length > 2+l1+1) {\n      l2 = php_strnlen(buffer+2+l1+1, length-2-l1-1);\n      exif_iif_add_tag(ImageInfo, SECTION_APP12, \"Info\",\n                       TAG_NONE, TAG_FMT_STRING, l2, buffer+2+l1+1);\n    }\n  }\n}", "commit_link": "github.com/facebook/hhvm/commit/f1cd34e63c2a0d9702be3d41462db7bfd0ae7da3", "file_name": "hphp/runtime/ext/gd/ext_gd.cpp", "vul_type": "cwe-125", "description": "Write a C function named `exif_process_APP12` that processes APP12 EXIF tags from a buffer and adds them to an image information structure."}
{"func_name": "init_user", "func_src_before": "def init_user(username, chat_id):\n    conn = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\users\\\\\" + username + '.db')\n    conn2 = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + '\\\\cf.db')\n    cursor = conn.cursor()\n    cursor2 = conn2.cursor()\n    cursor.execute(\"CREATE TABLE result (problem INTEGER, diff STRING, verdict STRING)\")\n    cursor2.execute(\"SELECT * FROM problems\")\n    x = cursor2.fetchone()\n    while x != None:\n        cursor.execute(\"insert into result values (?, ?, ? )\", (x[0], x[1], \"NULL\"))\n        x = cursor2.fetchone()\n\n    url = 'http://codeforces.com/submissions/' + username\n    r = requests.get(url)\n    max_page = 1\n    soup = BeautifulSoup(r.text, \"lxml\")\n\n    for link in soup.find_all(attrs={\"class\": \"page-index\"}):\n        s = link.find('a')\n        s2 = s.get(\"href\").split('/')\n        max_page = max(max_page, int(s2[4]))\n\n    old = \"\"\n    r = requests.get('http://codeforces.com/submissions/' + username + '/page/0')\n    soup = BeautifulSoup(r.text, \"lxml\")\n    last_try = soup.find(attrs={\"class\":\"status-small\"})\n    if not last_try == None:\n        last_try = str(last_try).split()\n        last_try = str(last_try[2]) + str(last_try[3])\n\n    for i in range(1, max_page + 1):\n        r = requests.get('http://codeforces.com/submissions/' + username + '/page/' + str(i))\n        soup = BeautifulSoup(r.text, \"lxml\")\n        count = 0\n        ver = soup.find_all(attrs={\"class\": \"submissionVerdictWrapper\"})\n        for link in soup.find_all('a'):\n            s = link.get('href')\n            if s != None and s.find('/problemset') != -1:\n                s = s.split('/')\n                if len(s) == 5:\n                    s2 = str(ver[count]).split()\n                    s2 = s2[5].split('\\\"')\n                    count += 1\n                    cursor.execute(\"select * from result where problem = '\" + s[3] + \"'and diff = '\" + s[4] + \"'\")\n                    x = cursor.fetchone()\n                    if s2[1] == 'OK' and x != None:\n                        cursor.execute(\"update result set verdict = '\" + s2[1] + \"' where problem = '\" + s[3] + \"' and diff = '\" + s[4] + \"'\")\n                    if x != None and x[2] != 'OK':\n                        cursor.execute(\"update result set verdict = '\" + s2[1] +\"' where problem = '\" + s[3] + \"' and diff = '\" + s[4] + \"'\")\n\n    conn.commit()\n    conn.close()\n    conn2.close()\n\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"select * from last_update_problemset\")\n    last_problem = conn.fetchone()\n    conn.execute(\"select * from users where chat_id = '\" + str(chat_id) + \"'\")\n    x = conn.fetchone()\n    if x == None:\n        conn.execute(\"insert into users values (?, ?, ?, ?, ?)\", (chat_id, username, str(last_try), str(last_problem[0]), 1))\n    else:\n        conn.execute(\"update users set username = '\" + str(username) + \"' where chat_id = '\" + str(chat_id) + \"'\")\n        conn.execute(\"update users set last_update = '\" + str(last_try) + \"' where chat_id = '\" + str(chat_id) + \"'\")\n        conn.execute(\"update users set last_problem = '\" + str(last_problem[0]) + \"' where chat_id = '\" + str(chat_id) + \"'\")\n        conn.execute(\"update users set state = '\" + str(1) + \"' where chat_id = '\" + str(chat_id) + \"'\")\n    settings.commit()\n    settings.close()", "func_src_after": "def init_user(username, chat_id):\n    conn = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\users\\\\\" + username + '.db')\n    conn2 = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + '\\\\cf.db')\n    cursor = conn.cursor()\n    cursor2 = conn2.cursor()\n    cursor.execute(\"CREATE TABLE result (problem INTEGER, diff STRING, verdict STRING)\")\n    cursor2.execute(\"SELECT * FROM problems\")\n    x = cursor2.fetchone()\n    while x != None:\n        cursor.execute(\"insert into result values (?, ?, ? )\", (x[0], x[1], \"NULL\"))\n        x = cursor2.fetchone()\n\n    url = 'http://codeforces.com/submissions/' + username\n    r = requests.get(url)\n    max_page = 1\n    soup = BeautifulSoup(r.text, \"lxml\")\n\n    for link in soup.find_all(attrs={\"class\": \"page-index\"}):\n        s = link.find('a')\n        s2 = s.get(\"href\").split('/')\n        max_page = max(max_page, int(s2[4]))\n    r = requests.get('http://codeforces.com/submissions/' + username + '/page/0')\n    soup = BeautifulSoup(r.text, \"lxml\")\n    last_try = soup.find(attrs={\"class\":\"status-small\"})\n    if not last_try == None:\n        last_try = str(last_try).split()\n        last_try = str(last_try[2]) + str(last_try[3])\n\n    for i in range(1, max_page + 1):\n        r = requests.get('http://codeforces.com/submissions/' + username + '/page/' + str(i))\n        soup = BeautifulSoup(r.text, \"lxml\")\n        count = 0\n        ver = soup.find_all(attrs={\"class\": \"submissionVerdictWrapper\"})\n        for link in soup.find_all('a'):\n            s = link.get('href')\n            if s != None and s.find('/problemset') != -1:\n                s = s.split('/')\n                if len(s) == 5:\n                    s2 = str(ver[count]).split()\n                    s2 = s2[5].split('\\\"')\n                    count += 1\n                    cursor.execute(\"select * from result where problem = ? and diff = ?\", (s[3], s[4]))\n                    x = cursor.fetchone()\n                    if s2[1] == 'OK' and x != None:\n                        cursor.execute(\"update result set verdict = ? where problem = ? and diff = ?\", (s2[1], s[3], s[4]))\n                    if x != None and x[2] != 'OK':\n                        cursor.execute(\"update result set verdict = ? where problem = ? and diff = ?\", (s2[1], s[3], s[4]))\n    conn.commit()\n    conn.close()\n    conn2.close()\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"select * from last_update_problemset\")\n    last_problem = conn.fetchone()\n    conn.execute(\"select * from users where chat_id = ?\", (str(chat_id),))\n    x = conn.fetchone()\n    if x == None:\n        conn.execute(\"insert into users values (?, ?, ?, ?, ?)\", (chat_id, username, str(last_try), str(last_problem[0]), 1))\n    else:\n        conn.execute(\"update users set username = ? where chat_id = ?\", (str(username), str(chat_id)))\n        conn.execute(\"update users set last_update = ? where chat_id = ?\", (str(last_try), str(chat_id)))\n        conn.execute(\"update users set last_problem = ? where chat_id = ?\", (str(last_problem[0]), str(chat_id)))\n        conn.execute(\"update users set state = ? where chat_id = ?\", (str(1), str(chat_id)))\n    settings.commit()\n    settings.close()", "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bases/createuserbase.py", "vul_type": "cwe-089", "description": "In Python, write a function `init_user` that initializes a user's database with problem results from Codeforces and updates user settings."}
{"func_name": "update_theory_base", "func_src_before": "def update_theory_base(tag, link):\n    theory = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\theory.db\")\n    conn = theory.cursor()\n    conn.execute(\"insert into \" + str(tag) + \" values (?)\", (str(link), ))\n    theory.commit()\n    theory.close()", "func_src_after": "def update_theory_base(tag, link):\n    theory = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\theory.db\")\n    conn = theory.cursor()\n    conn.execute(\"insert into ? values (?)\", (tag, str(link)))\n    theory.commit()\n    theory.close()", "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bases/update.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a link into a SQLite database table based on a given tag."}
{"func_name": "sctp_do_peeloff", "func_src_before": "int sctp_do_peeloff(struct sock *sk, sctp_assoc_t id, struct socket **sockp)\n{\n\tstruct sctp_association *asoc = sctp_id2assoc(sk, id);\n\tstruct sctp_sock *sp = sctp_sk(sk);\n\tstruct socket *sock;\n\tint err = 0;\n\n\tif (!asoc)\n\t\treturn -EINVAL;\n\n\t/* If there is a thread waiting on more sndbuf space for\n\t * sending on this asoc, it cannot be peeled.\n\t */\n\tif (waitqueue_active(&asoc->wait))\n\t\treturn -EBUSY;\n\n\t/* An association cannot be branched off from an already peeled-off\n\t * socket, nor is this supported for tcp style sockets.\n\t */\n\tif (!sctp_style(sk, UDP))\n\t\treturn -EINVAL;\n\n\t/* Create a new socket.  */\n\terr = sock_create(sk->sk_family, SOCK_SEQPACKET, IPPROTO_SCTP, &sock);\n\tif (err < 0)\n\t\treturn err;\n\n\tsctp_copy_sock(sock->sk, sk, asoc);\n\n\t/* Make peeled-off sockets more like 1-1 accepted sockets.\n\t * Set the daddr and initialize id to something more random\n\t */\n\tsp->pf->to_sk_daddr(&asoc->peer.primary_addr, sk);\n\n\t/* Populate the fields of the newsk from the oldsk and migrate the\n\t * asoc to the newsk.\n\t */\n\tsctp_sock_migrate(sk, sock->sk, asoc, SCTP_SOCKET_UDP_HIGH_BANDWIDTH);\n\n\t*sockp = sock;\n\n\treturn err;\n}", "func_src_after": "int sctp_do_peeloff(struct sock *sk, sctp_assoc_t id, struct socket **sockp)\n{\n\tstruct sctp_association *asoc = sctp_id2assoc(sk, id);\n\tstruct sctp_sock *sp = sctp_sk(sk);\n\tstruct socket *sock;\n\tint err = 0;\n\n\t/* Do not peel off from one netns to another one. */\n\tif (!net_eq(current->nsproxy->net_ns, sock_net(sk)))\n\t\treturn -EINVAL;\n\n\tif (!asoc)\n\t\treturn -EINVAL;\n\n\t/* If there is a thread waiting on more sndbuf space for\n\t * sending on this asoc, it cannot be peeled.\n\t */\n\tif (waitqueue_active(&asoc->wait))\n\t\treturn -EBUSY;\n\n\t/* An association cannot be branched off from an already peeled-off\n\t * socket, nor is this supported for tcp style sockets.\n\t */\n\tif (!sctp_style(sk, UDP))\n\t\treturn -EINVAL;\n\n\t/* Create a new socket.  */\n\terr = sock_create(sk->sk_family, SOCK_SEQPACKET, IPPROTO_SCTP, &sock);\n\tif (err < 0)\n\t\treturn err;\n\n\tsctp_copy_sock(sock->sk, sk, asoc);\n\n\t/* Make peeled-off sockets more like 1-1 accepted sockets.\n\t * Set the daddr and initialize id to something more random\n\t */\n\tsp->pf->to_sk_daddr(&asoc->peer.primary_addr, sk);\n\n\t/* Populate the fields of the newsk from the oldsk and migrate the\n\t * asoc to the newsk.\n\t */\n\tsctp_sock_migrate(sk, sock->sk, asoc, SCTP_SOCKET_UDP_HIGH_BANDWIDTH);\n\n\t*sockp = sock;\n\n\treturn err;\n}", "commit_link": "github.com/torvalds/linux/commit/df80cd9b28b9ebaa284a41df611dbf3a2d05ca74", "file_name": "net/sctp/socket.c", "vul_type": "cwe-416", "description": "Write a C function named `sctp_do_peeloff` that peels off an SCTP association from a socket and creates a new socket for it."}
{"func_name": "stats_for_realm", "func_src_before": "@require_server_admin\n@has_request_variables\ndef stats_for_realm(request: HttpRequest, realm_str: str) -> HttpResponse:\n    try:\n        realm = get_realm(realm_str)\n    except Realm.DoesNotExist:\n        return HttpResponseNotFound(f\"Realm {realm_str} does not exist\")\n\n    return render_stats(\n        request,\n        f\"/realm/{realm_str}\",\n        realm.name or realm.string_id,\n        analytics_ready=is_analytics_ready(realm),\n    )", "func_src_after": "@require_server_admin\n@has_request_variables\ndef stats_for_realm(request: HttpRequest, realm_str: str) -> HttpResponse:\n    try:\n        realm = get_realm(realm_str)\n    except Realm.DoesNotExist:\n        return HttpResponseNotFound()\n\n    return render_stats(\n        request,\n        f\"/realm/{realm_str}\",\n        realm.name or realm.string_id,\n        analytics_ready=is_analytics_ready(realm),\n    )", "line_changes": {"deleted": [{"line_no": 7, "char_start": 197, "char_end": 270, "line": "        return HttpResponseNotFound(f\"Realm {realm_str} does not exist\")\n"}], "added": [{"line_no": 7, "char_start": 197, "char_end": 235, "line": "        return HttpResponseNotFound()\n"}]}, "char_changes": {"deleted": [{"char_start": 233, "char_end": 268, "chars": "f\"Realm {realm_str} does not exist\""}], "added": []}, "commit_link": "github.com/rht/zulip/commit/0da1bd43e95f78bee0bf3f78f1bcb594e7db66fd", "file_name": "views.py", "vul_type": "cwe-079", "commit_msg": "analytics: Remove buggy HttpResponseNotFound text.\n\nHad this been in normal route, this would have been an XSS bug, as we\nwere passing what the developer clearly believed to be plain text into\nan HTML 404 page.\n\nThe affected routes have @require_server_admin, a permission that we\ndo not expect any self-hosted users to have ever enabled (as it is\nundocumented and doing so is only possible manually via a `manage.py\nshell`, and we believe to only be useful for running a SaaS service\nlike zulip.com).  So the security impact is limited to a handful of\nstaff of zulip.com and this isn't a candidate for a CVE.\n\nThanks to GitHub's CodeQL for finding this.", "description": "Create a Python function that checks if a realm exists and returns its statistics page or a not found response."}
{"func_name": "git_file_info", "func_src_before": "    def git_file_info(path)\n      return '  \u2713 '.colorize(@colors[:unchanged]) unless @git_status[path]\n      Git.colored_status_symbols(@git_status[path], @colors)\n    end", "func_src_after": "    def git_file_info(path)\n      return '  \u2713 '.colorize(@colors[:unchanged]) unless @git_status[path]\n      Git.colored_status_symbols(@git_status[path].uniq, @colors)\n    end", "line_changes": {"deleted": [{"line_no": 3, "char_start": 103, "char_end": 164, "line": "      Git.colored_status_symbols(@git_status[path], @colors)\n"}, {"line_no": 4, "char_start": 164, "char_end": 171, "line": "    end\n"}], "added": []}, "char_changes": {"deleted": [], "added": [{"char_start": 153, "char_end": 158, "chars": ".uniq"}]}, "commit_link": "github.com/athityakumar/colorls/commit/b362fa1eb81e7e6fa208cc8cab51f110db20057b", "file_name": "core.rb", "vul_type": "cwe-022", "commit_msg": "Improve git-status processing\n\n* no longer traverse complete directory trees to determine git status for\n  directories\n\n* properly report status for folders with changed files\n\n* skip the parent folder since we do not have git status about it", "parent_commit": "bb270b319a68adb96bf91a311250481020bdde81", "description": "Write a Ruby method named `git_file_info` that returns the colorized status of a file in a git repository, using a unique status if present."}
{"func_name": "$.fn.badge", "func_src_before": "\t$.fn.badge = function ( text, inline ) {\n\t\tvar div, $badge = this.find( '.mw-badge' );\n\n\t\tif ( text ) {\n\t\t\t// If a badge already exists, reuse it\n\t\t\tif ( $badge.length ) {\n\t\t\t\t$badge.find( '.mw-badge-content' ).text( text );\n\t\t\t} else {\n\t\t\t\t// Otherwise, create a new badge with the specified text and style\n\t\t\t\tdiv = document.createElement( 'div' );\n\t\t\t\tdiv.className = 'mw-badge mw-badge-' + ( inline ? 'inline' : 'overlay' );\n\t\t\t\tdiv.innerHTML = '<span class=\"mw-badge-content\">' + text + '</span>';\n\t\t\t\t$( div ).appendTo( this );\n\t\t\t}\n\t\t} else {\n\t\t\t$badge.remove();\n\t\t}\n\t\treturn this;\n\t};", "func_src_after": "\t$.fn.badge = function ( text, inline ) {\n\t\tvar div, $badge = this.find( '.mw-badge' );\n\n\t\tif ( text ) {\n\t\t\t// If a badge already exists, reuse it\n\t\t\tif ( $badge.length ) {\n\t\t\t\t$badge.find( '.mw-badge-content' ).text( text );\n\t\t\t} else {\n\t\t\t\t// Otherwise, create a new badge with the specified text and style\n\t\t\t\t$badge = $( '<div class=\"mw-badge mw-badge-' + ( inline ? 'inline' : 'overlay' ) + '\"></div>' )\n\t\t\t\t\t.append( $( '<span class=\"mw-badge-content\"></span>' ).text ( text ) )\n\t\t\t\t\t.appendTo( this );\n\t\t\t}\n\t\t} else {\n\t\t\t$badge.remove();\n\t\t}\n\t\treturn this;\n\t};", "line_changes": {"deleted": [{"line_no": 10, "char_start": 309, "char_end": 352, "line": "\t\t\t\tdiv = document.createElement( 'div' );\n"}, {"line_no": 11, "char_start": 352, "char_end": 430, "line": "\t\t\t\tdiv.className = 'mw-badge mw-badge-' + ( inline ? 'inline' : 'overlay' );\n"}, {"line_no": 12, "char_start": 430, "char_end": 504, "line": "\t\t\t\tdiv.innerHTML = '<span class=\"mw-badge-content\">' + text + '</span>';\n"}, {"line_no": 13, "char_start": 504, "char_end": 535, "line": "\t\t\t\t$( div ).appendTo( this );\n"}], "added": [{"line_no": 10, "char_start": 309, "char_end": 409, "line": "\t\t\t\t$badge = $( '<div class=\"mw-badge mw-badge-' + ( inline ? 'inline' : 'overlay' ) + '\"></div>' )\n"}, {"line_no": 11, "char_start": 409, "char_end": 485, "line": "\t\t\t\t\t.append( $( '<span class=\"mw-badge-content\"></span>' ).text ( text ) )\n"}, {"line_no": 12, "char_start": 485, "char_end": 509, "line": "\t\t\t\t\t.appendTo( this );\n"}]}, "char_changes": {"deleted": [{"char_start": 313, "char_end": 341, "chars": "div = document.createElement"}, {"char_start": 347, "char_end": 373, "chars": "' );\n\t\t\t\tdiv.className = '"}, {"char_start": 428, "char_end": 516, "chars": ";\n\t\t\t\tdiv.innerHTML = '<span class=\"mw-badge-content\">' + text + '</span>';\n\t\t\t\t$( div )"}], "added": [{"char_start": 313, "char_end": 323, "chars": "$badge = $"}, {"char_start": 326, "char_end": 327, "chars": "<"}, {"char_start": 330, "char_end": 338, "chars": " class=\""}, {"char_start": 393, "char_end": 490, "chars": " + '\"></div>' )\n\t\t\t\t\t.append( $( '<span class=\"mw-badge-content\"></span>' ).text ( text ) )\n\t\t\t\t\t"}]}, "commit_link": "github.com/PJosepherum/mediawiki/commit/f58e2d45b8358bc904fc83f53833fbf2aebeb7a1", "file_name": "jquery.badge.js", "vul_type": "cwe-079", "commit_msg": "Sanitize text input to $.fn.badge\n\nCloses a potential XSS vector, as pointed out by Krinkle in\n32091.\n\nChange-Id: Iea702fb8736799dc7f8238e4cb357da22304c1dd", "description": "Write a jQuery plugin in JavaScript that toggles a badge with text on an element, with an option for inline or overlay style."}
{"func_name": "get", "func_src_before": "  @auth.public\n  def get(self, build_id):\n    try:\n      build_id = int(build_id)\n    except ValueError as ex:\n      self.response.write(ex.message)\n      self.abort(400)\n\n    build = model.Build.get_by_id(build_id)\n    can_view = build and user.can_view_build_async(build).get_result()\n\n    if not can_view:\n      if auth.get_current_identity().is_anonymous:\n        return self.redirect(gae_users.create_login_url(self.request.url))\n      self.response.write('build %d not found' % build_id)\n      self.abort(404)\n\n    return self.redirect(str(build.url))", "func_src_after": "  @auth.public\n  def get(self, build_id):\n    try:\n      build_id = int(build_id)\n    except ValueError:\n      self.response.write('invalid build id')\n      self.abort(400)\n\n    build = model.Build.get_by_id(build_id)\n    can_view = build and user.can_view_build_async(build).get_result()\n\n    if not can_view:\n      if auth.get_current_identity().is_anonymous:\n        return self.redirect(self.create_login_url(self.request.url))\n      self.response.write('build %d not found' % build_id)\n      self.abort(404)\n\n    return self.redirect(str(build.url))", "commit_link": "github.com/asdfghjjklllllaaa/infra/commit/2f39f3df54fb79b56744f00bcf97583b3807851f", "file_name": "appengine/cr-buildbucket/handlers.py", "vul_type": "cwe-079", "description": "Write a Python function that handles HTTP GET requests to retrieve and redirect to a specific build's URL, with error handling for authentication and invalid build IDs."}
{"func_name": "ReadOneMNGImage", "func_src_before": "static Image *ReadOneMNGImage(MngInfo* mng_info, const ImageInfo *image_info,\n     ExceptionInfo *exception)\n{\n  char\n    page_geometry[MaxTextExtent];\n\n  Image\n    *image;\n\n  MagickBooleanType\n    logging;\n\n  volatile int\n    first_mng_object,\n    object_id,\n    term_chunk_found,\n    skip_to_iend;\n\n  volatile ssize_t\n    image_count=0;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    offset;\n\n  MngBox\n    default_fb,\n    fb,\n    previous_fb;\n\n#if defined(MNG_INSERT_LAYERS)\n  PixelPacket\n    mng_background_color;\n#endif\n\n  register unsigned char\n    *p;\n\n  register ssize_t\n    i;\n\n  size_t\n    count;\n\n  ssize_t\n    loop_level;\n\n  volatile short\n    skipping_loop;\n\n#if defined(MNG_INSERT_LAYERS)\n  unsigned int\n    mandatory_back=0;\n#endif\n\n  volatile unsigned int\n#ifdef MNG_OBJECT_BUFFERS\n    mng_background_object=0,\n#endif\n    mng_type=0;   /* 0: PNG or JNG; 1: MNG; 2: MNG-LC; 3: MNG-VLC */\n\n  size_t\n    default_frame_timeout,\n    frame_timeout,\n#if defined(MNG_INSERT_LAYERS)\n    image_height,\n    image_width,\n#endif\n    length;\n\n  /* These delays are all measured in image ticks_per_second,\n   * not in MNG ticks_per_second\n   */\n  volatile size_t\n    default_frame_delay,\n    final_delay,\n    final_image_delay,\n    frame_delay,\n#if defined(MNG_INSERT_LAYERS)\n    insert_layers,\n#endif\n    mng_iterations=1,\n    simplicity=0,\n    subframe_height=0,\n    subframe_width=0;\n\n  previous_fb.top=0;\n  previous_fb.bottom=0;\n  previous_fb.left=0;\n  previous_fb.right=0;\n  default_fb.top=0;\n  default_fb.bottom=0;\n  default_fb.left=0;\n  default_fb.right=0;\n\n  logging=LogMagickEvent(CoderEvent,GetMagickModule(),\n    \"  Enter ReadOneMNGImage()\");\n\n  image=mng_info->image;\n\n  if (LocaleCompare(image_info->magick,\"MNG\") == 0)\n    {\n      char\n        magic_number[MaxTextExtent];\n\n      /* Verify MNG signature.  */\n      count=(size_t) ReadBlob(image,8,(unsigned char *) magic_number);\n      if (memcmp(magic_number,\"\\212MNG\\r\\n\\032\\n\",8) != 0)\n        ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n      /* Initialize some nonzero members of the MngInfo structure.  */\n      for (i=0; i < MNG_MAX_OBJECTS; i++)\n      {\n        mng_info->object_clip[i].right=(ssize_t) PNG_UINT_31_MAX;\n        mng_info->object_clip[i].bottom=(ssize_t) PNG_UINT_31_MAX;\n      }\n      mng_info->exists[0]=MagickTrue;\n    }\n\n  skipping_loop=(-1);\n  first_mng_object=MagickTrue;\n  mng_type=0;\n#if defined(MNG_INSERT_LAYERS)\n  insert_layers=MagickFalse; /* should be False when converting or mogrifying */\n#endif\n  default_frame_delay=0;\n  default_frame_timeout=0;\n  frame_delay=0;\n  final_delay=1;\n  mng_info->ticks_per_second=1UL*image->ticks_per_second;\n  object_id=0;\n  skip_to_iend=MagickFalse;\n  term_chunk_found=MagickFalse;\n  mng_info->framing_mode=1;\n#if defined(MNG_INSERT_LAYERS)\n  mandatory_back=MagickFalse;\n#endif\n#if defined(MNG_INSERT_LAYERS)\n  mng_background_color=image->background_color;\n#endif\n  default_fb=mng_info->frame;\n  previous_fb=mng_info->frame;\n  do\n  {\n    char\n      type[MaxTextExtent];\n\n    if (LocaleCompare(image_info->magick,\"MNG\") == 0)\n      {\n        unsigned char\n          *chunk;\n\n        /*\n          Read a new chunk.\n        */\n        type[0]='\\0';\n        (void) ConcatenateMagickString(type,\"errr\",MaxTextExtent);\n        length=ReadBlobMSBLong(image);\n        count=(size_t) ReadBlob(image,4,(unsigned char *) type);\n\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n           \"  Reading MNG chunk type %c%c%c%c, length: %.20g\",\n           type[0],type[1],type[2],type[3],(double) length);\n\n        if (length > PNG_UINT_31_MAX)\n          {\n            status=MagickFalse;\n            break;\n          }\n\n        if (count == 0)\n          ThrowReaderException(CorruptImageError,\"CorruptImage\");\n\n        p=NULL;\n        chunk=(unsigned char *) NULL;\n\n        if (length != 0)\n          {\n            chunk=(unsigned char *) AcquireQuantumMemory(length+\n              MagickPathExtent,sizeof(*chunk));\n\n            if (chunk == (unsigned char *) NULL)\n              ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n            for (i=0; i < (ssize_t) length; i++)\n            {\n              int\n                c;\n\n              c=ReadBlobByte(image);\n              if (c == EOF)\n                break;\n              chunk[i]=(unsigned char) c;\n            }\n\n            p=chunk;\n          }\n\n        (void) ReadBlobMSBLong(image);  /* read crc word */\n\n#if !defined(JNG_SUPPORTED)\n        if (memcmp(type,mng_JHDR,4) == 0)\n          {\n            skip_to_iend=MagickTrue;\n\n            if (mng_info->jhdr_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"JNGCompressNotSupported\",\"`%s'\",image->filename);\n\n            mng_info->jhdr_warning++;\n          }\n#endif\n        if (memcmp(type,mng_DHDR,4) == 0)\n          {\n            skip_to_iend=MagickTrue;\n\n            if (mng_info->dhdr_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"DeltaPNGNotSupported\",\"`%s'\",image->filename);\n\n            mng_info->dhdr_warning++;\n          }\n        if (memcmp(type,mng_MEND,4) == 0)\n          break;\n\n        if (skip_to_iend)\n          {\n            if (memcmp(type,mng_IEND,4) == 0)\n              skip_to_iend=MagickFalse;\n\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Skip to IEND.\");\n\n            continue;\n          }\n\n        if (memcmp(type,mng_MHDR,4) == 0)\n          {\n            if (length != 28)\n              {\n                chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n                ThrowReaderException(CorruptImageError,\"CorruptImage\");\n              }\n\n            mng_info->mng_width=(size_t) ((p[0] << 24) | (p[1] << 16) |\n                (p[2] << 8) | p[3]);\n\n            mng_info->mng_height=(size_t) ((p[4] << 24) | (p[5] << 16) |\n                (p[6] << 8) | p[7]);\n\n            if (logging != MagickFalse)\n              {\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"  MNG width: %.20g\",(double) mng_info->mng_width);\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"  MNG height: %.20g\",(double) mng_info->mng_height);\n              }\n\n            p+=8;\n            mng_info->ticks_per_second=(size_t) mng_get_long(p);\n\n            if (mng_info->ticks_per_second == 0)\n              default_frame_delay=0;\n\n            else\n              default_frame_delay=1UL*image->ticks_per_second/\n                mng_info->ticks_per_second;\n\n            frame_delay=default_frame_delay;\n            simplicity=0;\n\n            /* Skip nominal layer count, frame count, and play time */\n            p+=16;\n            simplicity=(size_t) mng_get_long(p);\n\n            mng_type=1;    /* Full MNG */\n\n            if ((simplicity != 0) && ((simplicity | 11) == 11))\n              mng_type=2; /* LC */\n\n            if ((simplicity != 0) && ((simplicity | 9) == 9))\n              mng_type=3; /* VLC */\n\n#if defined(MNG_INSERT_LAYERS)\n            if (mng_type != 3)\n              insert_layers=MagickTrue;\n#endif\n            if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n              {\n                /* Allocate next image structure.  */\n                AcquireNextImage(image_info,image);\n\n                if (GetNextImageInList(image) == (Image *) NULL)\n                  return(DestroyImageList(image));\n\n                image=SyncNextImageInList(image);\n                mng_info->image=image;\n              }\n\n            if ((mng_info->mng_width > 65535L) ||\n                (mng_info->mng_height > 65535L))\n              {\n                chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n                ThrowReaderException(ImageError,\"WidthOrHeightExceedsLimit\");\n              }\n\n            (void) FormatLocaleString(page_geometry,MaxTextExtent,\n              \"%.20gx%.20g+0+0\",(double) mng_info->mng_width,(double)\n              mng_info->mng_height);\n\n            mng_info->frame.left=0;\n            mng_info->frame.right=(ssize_t) mng_info->mng_width;\n            mng_info->frame.top=0;\n            mng_info->frame.bottom=(ssize_t) mng_info->mng_height;\n            mng_info->clip=default_fb=previous_fb=mng_info->frame;\n\n            for (i=0; i < MNG_MAX_OBJECTS; i++)\n              mng_info->object_clip[i]=mng_info->frame;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_TERM,4) == 0)\n          {\n            int\n              repeat=0;\n\n            if (length != 0)\n              repeat=p[0];\n\n            if (repeat == 3 && length > 8)\n              {\n                final_delay=(png_uint_32) mng_get_long(&p[2]);\n                mng_iterations=(png_uint_32) mng_get_long(&p[6]);\n\n                if (mng_iterations == PNG_UINT_31_MAX)\n                  mng_iterations=0;\n\n                image->iterations=mng_iterations;\n                term_chunk_found=MagickTrue;\n              }\n\n            if (logging != MagickFalse)\n              {\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"    repeat=%d,  final_delay=%.20g,  iterations=%.20g\",\n                  repeat,(double) final_delay, (double) image->iterations);\n              }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_DEFI,4) == 0)\n          {\n            if (mng_type == 3)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"DEFI chunk found in MNG-VLC datastream\",\"`%s'\",\n                image->filename);\n\n            if (length > 1)\n              {\n                object_id=(p[0] << 8) | p[1];\n\n                if (mng_type == 2 && object_id != 0)\n                  (void) ThrowMagickException(&image->exception,\n                     GetMagickModule(),\n                     CoderError,\"Nonzero object_id in MNG-LC datastream\",\n                     \"`%s'\", image->filename);\n\n                if (object_id > MNG_MAX_OBJECTS)\n                  {\n                    /*\n                      Instead of using a warning we should allocate a larger\n                      MngInfo structure and continue.\n                    */\n                    (void) ThrowMagickException(&image->exception,\n                        GetMagickModule(), CoderError,\n                        \"object id too large\",\"`%s'\",image->filename);\n                        object_id=MNG_MAX_OBJECTS;\n                  }\n\n                if (mng_info->exists[object_id])\n                  if (mng_info->frozen[object_id])\n                    {\n                      chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n                      (void) ThrowMagickException(&image->exception,\n                        GetMagickModule(),CoderError,\n                        \"DEFI cannot redefine a frozen MNG object\",\"`%s'\",\n                        image->filename);\n                      continue;\n                    }\n\n                mng_info->exists[object_id]=MagickTrue;\n\n                if (length > 2)\n                  mng_info->invisible[object_id]=p[2];\n\n                /*\n                  Extract object offset info.\n                */\n                if (length > 11)\n                  {\n                    mng_info->x_off[object_id]=(ssize_t) ((p[4] << 24) |\n                        (p[5] << 16) | (p[6] << 8) | p[7]);\n\n                    mng_info->y_off[object_id]=(ssize_t) ((p[8] << 24) |\n                        (p[9] << 16) | (p[10] << 8) | p[11]);\n\n                    if (logging != MagickFalse)\n                      {\n                        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                          \"  x_off[%d]: %.20g,  y_off[%d]: %.20g\",\n                          object_id,(double) mng_info->x_off[object_id],\n                          object_id,(double) mng_info->y_off[object_id]);\n                      }\n                  }\n\n                /*\n                  Extract object clipping info.\n                */\n            \n                if (length > 27)\n                  mng_info->object_clip[object_id]=\n                    mng_read_box(mng_info->frame,0, &p[12]);\n            }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_bKGD,4) == 0)\n          {\n            mng_info->have_global_bkgd=MagickFalse;\n\n            if (length > 5)\n              {\n                mng_info->mng_global_bkgd.red=\n                  ScaleShortToQuantum((unsigned short) ((p[0] << 8) | p[1]));\n\n                mng_info->mng_global_bkgd.green=\n                  ScaleShortToQuantum((unsigned short) ((p[2] << 8) | p[3]));\n\n                mng_info->mng_global_bkgd.blue=\n                  ScaleShortToQuantum((unsigned short) ((p[4] << 8) | p[5]));\n\n                mng_info->have_global_bkgd=MagickTrue;\n              }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_BACK,4) == 0)\n          {\n#if defined(MNG_INSERT_LAYERS)\n            if (length > 6)\n              mandatory_back=p[6];\n\n            else\n              mandatory_back=0;\n\n            if (mandatory_back && length > 5)\n              {\n                mng_background_color.red=\n                    ScaleShortToQuantum((unsigned short) ((p[0] << 8) | p[1]));\n\n                mng_background_color.green=\n                    ScaleShortToQuantum((unsigned short) ((p[2] << 8) | p[3]));\n\n                mng_background_color.blue=\n                    ScaleShortToQuantum((unsigned short) ((p[4] << 8) | p[5]));\n\n                mng_background_color.opacity=OpaqueOpacity;\n              }\n\n#ifdef MNG_OBJECT_BUFFERS\n            if (length > 8)\n              mng_background_object=(p[7] << 8) | p[8];\n#endif\n#endif\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_PLTE,4) == 0)\n          {\n            /* Read global PLTE.  */\n\n            if (length && (length < 769))\n              {\n                if (mng_info->global_plte == (png_colorp) NULL)\n                  mng_info->global_plte=(png_colorp) AcquireQuantumMemory(256,\n                    sizeof(*mng_info->global_plte));\n\n                for (i=0; i < (ssize_t) (length/3); i++)\n                {\n                  mng_info->global_plte[i].red=p[3*i];\n                  mng_info->global_plte[i].green=p[3*i+1];\n                  mng_info->global_plte[i].blue=p[3*i+2];\n                }\n\n                mng_info->global_plte_length=(unsigned int) (length/3);\n              }\n#ifdef MNG_LOOSE\n            for ( ; i < 256; i++)\n            {\n              mng_info->global_plte[i].red=i;\n              mng_info->global_plte[i].green=i;\n              mng_info->global_plte[i].blue=i;\n            }\n\n            if (length != 0)\n              mng_info->global_plte_length=256;\n#endif\n            else\n              mng_info->global_plte_length=0;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_tRNS,4) == 0)\n          {\n            /* read global tRNS */\n\n            if (length > 0 && length < 257)\n              for (i=0; i < (ssize_t) length; i++)\n                mng_info->global_trns[i]=p[i];\n\n#ifdef MNG_LOOSE\n            for ( ; i < 256; i++)\n              mng_info->global_trns[i]=255;\n#endif\n            mng_info->global_trns_length=(unsigned int) length;\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_gAMA,4) == 0)\n          {\n            if (length == 4)\n              {\n                ssize_t\n                  igamma;\n\n                igamma=mng_get_long(p);\n                mng_info->global_gamma=((float) igamma)*0.00001;\n                mng_info->have_global_gama=MagickTrue;\n              }\n\n            else\n              mng_info->have_global_gama=MagickFalse;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_cHRM,4) == 0)\n          {\n            /* Read global cHRM */\n\n            if (length == 32)\n              {\n                mng_info->global_chrm.white_point.x=0.00001*mng_get_long(p);\n                mng_info->global_chrm.white_point.y=0.00001*mng_get_long(&p[4]);\n                mng_info->global_chrm.red_primary.x=0.00001*mng_get_long(&p[8]);\n                mng_info->global_chrm.red_primary.y=0.00001*\n                  mng_get_long(&p[12]);\n                mng_info->global_chrm.green_primary.x=0.00001*\n                  mng_get_long(&p[16]);\n                mng_info->global_chrm.green_primary.y=0.00001*\n                  mng_get_long(&p[20]);\n                mng_info->global_chrm.blue_primary.x=0.00001*\n                  mng_get_long(&p[24]);\n                mng_info->global_chrm.blue_primary.y=0.00001*\n                  mng_get_long(&p[28]);\n                mng_info->have_global_chrm=MagickTrue;\n              }\n            else\n              mng_info->have_global_chrm=MagickFalse;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_sRGB,4) == 0)\n          {\n            /*\n              Read global sRGB.\n            */\n            if (length != 0)\n              {\n                mng_info->global_srgb_intent=\n                  Magick_RenderingIntent_from_PNG_RenderingIntent(p[0]);\n                mng_info->have_global_srgb=MagickTrue;\n              }\n            else\n              mng_info->have_global_srgb=MagickFalse;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_iCCP,4) == 0)\n          {\n            /* To do: */\n\n            /*\n              Read global iCCP.\n            */\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n\n        if (memcmp(type,mng_FRAM,4) == 0)\n          {\n            if (mng_type == 3)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"FRAM chunk found in MNG-VLC datastream\",\"`%s'\",\n                image->filename);\n\n            if ((mng_info->framing_mode == 2) || (mng_info->framing_mode == 4))\n              image->delay=frame_delay;\n\n            frame_delay=default_frame_delay;\n            frame_timeout=default_frame_timeout;\n            fb=default_fb;\n\n            if (length > 0)\n              if (p[0])\n                mng_info->framing_mode=p[0];\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"    Framing_mode=%d\",mng_info->framing_mode);\n\n            if (length > 6)\n              {\n                /* Note the delay and frame clipping boundaries.  */\n\n                p++; /* framing mode */\n\n                while (*p && ((p-chunk) < (ssize_t) length))\n                  p++;  /* frame name */\n\n                p++;  /* frame name terminator */\n\n                if ((p-chunk) < (ssize_t) (length-4))\n                  {\n                    int\n                      change_delay,\n                      change_timeout,\n                      change_clipping;\n\n                    change_delay=(*p++);\n                    change_timeout=(*p++);\n                    change_clipping=(*p++);\n                    p++; /* change_sync */\n\n                    if (change_delay && (p-chunk) < (ssize_t) (length-4))\n                      {\n                          frame_delay=1UL*image->ticks_per_second*\n                            mng_get_long(p);\n\n                        if (mng_info->ticks_per_second != 0)\n                          frame_delay/=mng_info->ticks_per_second;\n\n                        else\n                          frame_delay=PNG_UINT_31_MAX;\n\n                        if (change_delay == 2)\n                          default_frame_delay=frame_delay;\n\n                        p+=4;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                            \"    Framing_delay=%.20g\",(double) frame_delay);\n                      }\n\n                    if (change_timeout && (p-chunk) < (ssize_t) (length-4))\n                      {\n                        frame_timeout=1UL*image->ticks_per_second*\n                          mng_get_long(p);\n\n                        if (mng_info->ticks_per_second != 0)\n                          frame_timeout/=mng_info->ticks_per_second;\n\n                        else\n                          frame_timeout=PNG_UINT_31_MAX;\n\n                        if (change_timeout == 2)\n                          default_frame_timeout=frame_timeout;\n\n                        p+=4;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                            \"    Framing_timeout=%.20g\",(double) frame_timeout);\n                      }\n\n                    if (change_clipping && (p-chunk) < (ssize_t) (length-17))\n                      {\n                        fb=mng_read_box(previous_fb,(char) p[0],&p[1]);\n                        p+=17;\n                        previous_fb=fb;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                            \"    Frame_clip: L=%.20g R=%.20g T=%.20g B=%.20g\",\n                            (double) fb.left,(double) fb.right,(double) fb.top,\n                            (double) fb.bottom);\n\n                        if (change_clipping == 2)\n                          default_fb=fb;\n                      }\n                  }\n              }\n            mng_info->clip=fb;\n            mng_info->clip=mng_minimum_box(fb,mng_info->frame);\n\n            subframe_width=(size_t) (mng_info->clip.right\n               -mng_info->clip.left);\n\n            subframe_height=(size_t) (mng_info->clip.bottom\n               -mng_info->clip.top);\n            /*\n              Insert a background layer behind the frame if framing_mode is 4.\n            */\n#if defined(MNG_INSERT_LAYERS)\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"   subframe_width=%.20g, subframe_height=%.20g\",(double)\n                subframe_width,(double) subframe_height);\n\n            if (insert_layers && (mng_info->framing_mode == 4) &&\n                (subframe_width) && (subframe_height))\n              {\n                /* Allocate next image structure.  */\n                if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n                  {\n                    AcquireNextImage(image_info,image);\n\n                    if (GetNextImageInList(image) == (Image *) NULL)\n                      return(DestroyImageList(image));\n\n                    image=SyncNextImageInList(image);\n                  }\n\n                mng_info->image=image;\n\n                if (term_chunk_found)\n                  {\n                    image->start_loop=MagickTrue;\n                    image->iterations=mng_iterations;\n                    term_chunk_found=MagickFalse;\n                  }\n\n                else\n                    image->start_loop=MagickFalse;\n\n                image->columns=subframe_width;\n                image->rows=subframe_height;\n                image->page.width=subframe_width;\n                image->page.height=subframe_height;\n                image->page.x=mng_info->clip.left;\n                image->page.y=mng_info->clip.top;\n                image->background_color=mng_background_color;\n                image->matte=MagickFalse;\n                image->delay=0;\n                (void) SetImageBackgroundColor(image);\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  Insert backgd layer, L=%.20g, R=%.20g T=%.20g, B=%.20g\",\n                    (double) mng_info->clip.left,(double) mng_info->clip.right,\n                    (double) mng_info->clip.top,(double) mng_info->clip.bottom);\n              }\n#endif\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_CLIP,4) == 0)\n          {\n            unsigned int\n              first_object,\n              last_object;\n\n            /*\n              Read CLIP.\n            */\n            if (length > 3)\n              {\n                first_object=(p[0] << 8) | p[1];\n                last_object=(p[2] << 8) | p[3];\n                p+=4;\n\n                for (i=(int) first_object; i <= (int) last_object; i++)\n                {\n                  if (mng_info->exists[i] && !mng_info->frozen[i])\n                    {\n                      MngBox\n                        box;\n\n                      box=mng_info->object_clip[i];\n                      if ((p-chunk) < (ssize_t) (length-17))\n                        mng_info->object_clip[i]=\n                           mng_read_box(box,(char) p[0],&p[1]);\n                    }\n                }\n\n              }\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_SAVE,4) == 0)\n          {\n            for (i=1; i < MNG_MAX_OBJECTS; i++)\n              if (mng_info->exists[i])\n                {\n                 mng_info->frozen[i]=MagickTrue;\n#ifdef MNG_OBJECT_BUFFERS\n                 if (mng_info->ob[i] != (MngBuffer *) NULL)\n                    mng_info->ob[i]->frozen=MagickTrue;\n#endif\n                }\n\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n\n        if ((memcmp(type,mng_DISC,4) == 0) || (memcmp(type,mng_SEEK,4) == 0))\n          {\n            /* Read DISC or SEEK.  */\n\n            if ((length == 0) || !memcmp(type,mng_SEEK,4))\n              {\n                for (i=1; i < MNG_MAX_OBJECTS; i++)\n                  MngInfoDiscardObject(mng_info,i);\n              }\n\n            else\n              {\n                register ssize_t\n                  j;\n\n                for (j=1; j < (ssize_t) length; j+=2)\n                {\n                  i=p[j-1] << 8 | p[j];\n                  MngInfoDiscardObject(mng_info,i);\n                }\n              }\n\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n\n        if (memcmp(type,mng_MOVE,4) == 0)\n          {\n            size_t\n              first_object,\n              last_object;\n\n            /* read MOVE */\n\n            if (length > 3)\n            {\n              first_object=(p[0] << 8) | p[1];\n              last_object=(p[2] << 8) | p[3];\n              p+=4;\n\n              for (i=(ssize_t) first_object; i <= (ssize_t) last_object; i++)\n              {\n                if (mng_info->exists[i] && !mng_info->frozen[i] &&\n                    (p-chunk) < (ssize_t) (length-8))\n                  {\n                    MngPair\n                      new_pair;\n\n                    MngPair\n                      old_pair;\n\n                    old_pair.a=mng_info->x_off[i];\n                    old_pair.b=mng_info->y_off[i];\n                    new_pair=mng_read_pair(old_pair,(int) p[0],&p[1]);\n                    mng_info->x_off[i]=new_pair.a;\n                    mng_info->y_off[i]=new_pair.b;\n                  }\n              }\n            }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_LOOP,4) == 0)\n          {\n            ssize_t loop_iters=1;\n            if (length > 4)\n              {\n                loop_level=chunk[0];\n                mng_info->loop_active[loop_level]=1;  /* mark loop active */\n\n                /* Record starting point.  */\n                loop_iters=mng_get_long(&chunk[1]);\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  LOOP level %.20g has %.20g iterations \",\n                    (double) loop_level, (double) loop_iters);\n\n                if (loop_iters == 0)\n                  skipping_loop=loop_level;\n\n                else\n                  {\n                    mng_info->loop_jump[loop_level]=TellBlob(image);\n                    mng_info->loop_count[loop_level]=loop_iters;\n                  }\n\n                mng_info->loop_iteration[loop_level]=0;\n              }\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_ENDL,4) == 0)\n          {\n            if (length > 0)\n              {\n                loop_level=chunk[0];\n\n                if (skipping_loop > 0)\n                  {\n                    if (skipping_loop == loop_level)\n                      {\n                        /*\n                          Found end of zero-iteration loop.\n                        */\n                        skipping_loop=(-1);\n                        mng_info->loop_active[loop_level]=0;\n                      }\n                  }\n\n                else\n                  {\n                    if (mng_info->loop_active[loop_level] == 1)\n                      {\n                        mng_info->loop_count[loop_level]--;\n                        mng_info->loop_iteration[loop_level]++;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                          \"  ENDL: LOOP level %.20g has %.20g remaining iters \",\n                            (double) loop_level,(double)\n                            mng_info->loop_count[loop_level]);\n\n                        if (mng_info->loop_count[loop_level] != 0)\n                          {\n                            offset=SeekBlob(image,\n                              mng_info->loop_jump[loop_level], SEEK_SET);\n\n                            if (offset < 0)\n                              {\n                                chunk=(unsigned char *) RelinquishMagickMemory(\n                                  chunk);\n                                ThrowReaderException(CorruptImageError,\n                                  \"ImproperImageHeader\");\n                              }\n                          }\n\n                        else\n                          {\n                            short\n                              last_level;\n\n                            /*\n                              Finished loop.\n                            */\n                            mng_info->loop_active[loop_level]=0;\n                            last_level=(-1);\n                            for (i=0; i < loop_level; i++)\n                              if (mng_info->loop_active[i] == 1)\n                                last_level=(short) i;\n                            loop_level=last_level;\n                          }\n                      }\n                  }\n              }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_CLON,4) == 0)\n          {\n            if (mng_info->clon_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"CLON is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->clon_warning++;\n          }\n\n        if (memcmp(type,mng_MAGN,4) == 0)\n          {\n            png_uint_16\n              magn_first,\n              magn_last,\n              magn_mb,\n              magn_ml,\n              magn_mr,\n              magn_mt,\n              magn_mx,\n              magn_my,\n              magn_methx,\n              magn_methy;\n\n            if (length > 1)\n              magn_first=(p[0] << 8) | p[1];\n\n            else\n              magn_first=0;\n\n            if (length > 3)\n              magn_last=(p[2] << 8) | p[3];\n\n            else\n              magn_last=magn_first;\n#ifndef MNG_OBJECT_BUFFERS\n            if (magn_first || magn_last)\n              if (mng_info->magn_warning == 0)\n                {\n                  (void) ThrowMagickException(&image->exception,\n                     GetMagickModule(),CoderError,\n                     \"MAGN is not implemented yet for nonzero objects\",\n                     \"`%s'\",image->filename);\n\n                   mng_info->magn_warning++;\n                }\n#endif\n            if (length > 4)\n              magn_methx=p[4];\n\n            else\n              magn_methx=0;\n\n            if (length > 6)\n              magn_mx=(p[5] << 8) | p[6];\n\n            else\n              magn_mx=1;\n\n            if (magn_mx == 0)\n              magn_mx=1;\n\n            if (length > 8)\n              magn_my=(p[7] << 8) | p[8];\n\n            else\n              magn_my=magn_mx;\n\n            if (magn_my == 0)\n              magn_my=1;\n\n            if (length > 10)\n              magn_ml=(p[9] << 8) | p[10];\n\n            else\n              magn_ml=magn_mx;\n\n            if (magn_ml == 0)\n              magn_ml=1;\n\n            if (length > 12)\n              magn_mr=(p[11] << 8) | p[12];\n\n            else\n              magn_mr=magn_mx;\n\n            if (magn_mr == 0)\n              magn_mr=1;\n\n            if (length > 14)\n              magn_mt=(p[13] << 8) | p[14];\n\n            else\n              magn_mt=magn_my;\n\n            if (magn_mt == 0)\n              magn_mt=1;\n\n            if (length > 16)\n              magn_mb=(p[15] << 8) | p[16];\n\n            else\n              magn_mb=magn_my;\n\n            if (magn_mb == 0)\n              magn_mb=1;\n\n            if (length > 17)\n              magn_methy=p[17];\n\n            else\n              magn_methy=magn_methx;\n\n\n            if (magn_methx > 5 || magn_methy > 5)\n              if (mng_info->magn_warning == 0)\n                {\n                  (void) ThrowMagickException(&image->exception,\n                     GetMagickModule(),CoderError,\n                     \"Unknown MAGN method in MNG datastream\",\"`%s'\",\n                     image->filename);\n\n                   mng_info->magn_warning++;\n                }\n#ifdef MNG_OBJECT_BUFFERS\n          /* Magnify existing objects in the range magn_first to magn_last */\n#endif\n            if (magn_first == 0 || magn_last == 0)\n              {\n                /* Save the magnification factors for object 0 */\n                mng_info->magn_mb=magn_mb;\n                mng_info->magn_ml=magn_ml;\n                mng_info->magn_mr=magn_mr;\n                mng_info->magn_mt=magn_mt;\n                mng_info->magn_mx=magn_mx;\n                mng_info->magn_my=magn_my;\n                mng_info->magn_methx=magn_methx;\n                mng_info->magn_methy=magn_methy;\n              }\n          }\n\n        if (memcmp(type,mng_PAST,4) == 0)\n          {\n            if (mng_info->past_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"PAST is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->past_warning++;\n          }\n\n        if (memcmp(type,mng_SHOW,4) == 0)\n          {\n            if (mng_info->show_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"SHOW is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->show_warning++;\n          }\n\n        if (memcmp(type,mng_sBIT,4) == 0)\n          {\n            if (length < 4)\n              mng_info->have_global_sbit=MagickFalse;\n\n            else\n              {\n                mng_info->global_sbit.gray=p[0];\n                mng_info->global_sbit.red=p[0];\n                mng_info->global_sbit.green=p[1];\n                mng_info->global_sbit.blue=p[2];\n                mng_info->global_sbit.alpha=p[3];\n                mng_info->have_global_sbit=MagickTrue;\n             }\n          }\n        if (memcmp(type,mng_pHYs,4) == 0)\n          {\n            if (length > 8)\n              {\n                mng_info->global_x_pixels_per_unit=\n                    (size_t) mng_get_long(p);\n                mng_info->global_y_pixels_per_unit=\n                    (size_t) mng_get_long(&p[4]);\n                mng_info->global_phys_unit_type=p[8];\n                mng_info->have_global_phys=MagickTrue;\n              }\n\n            else\n              mng_info->have_global_phys=MagickFalse;\n          }\n        if (memcmp(type,mng_pHYg,4) == 0)\n          {\n            if (mng_info->phyg_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"pHYg is not implemented.\",\"`%s'\",image->filename);\n\n            mng_info->phyg_warning++;\n          }\n        if (memcmp(type,mng_BASI,4) == 0)\n          {\n            skip_to_iend=MagickTrue;\n\n            if (mng_info->basi_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"BASI is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->basi_warning++;\n#ifdef MNG_BASI_SUPPORTED\n            if (length > 11)\n              {\n                basi_width=(size_t) ((p[0] << 24) | (p[1] << 16) |\n                   (p[2] << 8) | p[3]);\n                basi_height=(size_t) ((p[4] << 24) | (p[5] << 16) |\n                   (p[6] << 8) | p[7]);\n                basi_color_type=p[8];\n                basi_compression_method=p[9];\n                basi_filter_type=p[10];\n                basi_interlace_method=p[11];\n              }\n            if (length > 13)\n              basi_red=(p[12] << 8) & p[13];\n\n            else\n              basi_red=0;\n\n            if (length > 15)\n              basi_green=(p[14] << 8) & p[15];\n\n            else\n              basi_green=0;\n\n            if (length > 17)\n              basi_blue=(p[16] << 8) & p[17];\n\n            else\n              basi_blue=0;\n\n            if (length > 19)\n              basi_alpha=(p[18] << 8) & p[19];\n\n            else\n              {\n                if (basi_sample_depth == 16)\n                  basi_alpha=65535L;\n                else\n                  basi_alpha=255;\n              }\n\n            if (length > 20)\n              basi_viewable=p[20];\n\n            else\n              basi_viewable=0;\n\n#endif\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_IHDR,4)\n#if defined(JNG_SUPPORTED)\n            && memcmp(type,mng_JHDR,4)\n#endif\n            )\n          {\n            /* Not an IHDR or JHDR chunk */\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n/* Process IHDR */\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  Processing %c%c%c%c chunk\",type[0],type[1],type[2],type[3]);\n\n        mng_info->exists[object_id]=MagickTrue;\n        mng_info->viewable[object_id]=MagickTrue;\n\n        if (mng_info->invisible[object_id])\n          {\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Skipping invisible object\");\n\n            skip_to_iend=MagickTrue;\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n#if defined(MNG_INSERT_LAYERS)\n        if (length < 8)\n          {\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n          }\n\n        image_width=(size_t) mng_get_long(p);\n        image_height=(size_t) mng_get_long(&p[4]);\n#endif\n        chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n        /*\n          Insert a transparent background layer behind the entire animation\n          if it is not full screen.\n        */\n#if defined(MNG_INSERT_LAYERS)\n        if (insert_layers && mng_type && first_mng_object)\n          {\n            if ((mng_info->clip.left > 0) || (mng_info->clip.top > 0) ||\n                (image_width < mng_info->mng_width) ||\n                (mng_info->clip.right < (ssize_t) mng_info->mng_width) ||\n                (image_height < mng_info->mng_height) ||\n                (mng_info->clip.bottom < (ssize_t) mng_info->mng_height))\n              {\n                if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n                  {\n                    /*\n                      Allocate next image structure.\n                    */\n                    AcquireNextImage(image_info,image);\n\n                    if (GetNextImageInList(image) == (Image *) NULL)\n                      return(DestroyImageList(image));\n\n                    image=SyncNextImageInList(image);\n                  }\n                mng_info->image=image;\n\n                if (term_chunk_found)\n                  {\n                    image->start_loop=MagickTrue;\n                    image->iterations=mng_iterations;\n                    term_chunk_found=MagickFalse;\n                  }\n\n                else\n                    image->start_loop=MagickFalse;\n\n                /* Make a background rectangle.  */\n\n                image->delay=0;\n                image->columns=mng_info->mng_width;\n                image->rows=mng_info->mng_height;\n                image->page.width=mng_info->mng_width;\n                image->page.height=mng_info->mng_height;\n                image->page.x=0;\n                image->page.y=0;\n                image->background_color=mng_background_color;\n                (void) SetImageBackgroundColor(image);\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  Inserted transparent background layer, W=%.20g, H=%.20g\",\n                    (double) mng_info->mng_width,(double) mng_info->mng_height);\n              }\n          }\n        /*\n          Insert a background layer behind the upcoming image if\n          framing_mode is 3, and we haven't already inserted one.\n        */\n        if (insert_layers && (mng_info->framing_mode == 3) &&\n                (subframe_width) && (subframe_height) && (simplicity == 0 ||\n                (simplicity & 0x08)))\n          {\n            if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n            {\n              /*\n                Allocate next image structure.\n              */\n              AcquireNextImage(image_info,image);\n\n              if (GetNextImageInList(image) == (Image *) NULL)\n                return(DestroyImageList(image));\n\n              image=SyncNextImageInList(image);\n            }\n\n            mng_info->image=image;\n\n            if (term_chunk_found)\n              {\n                image->start_loop=MagickTrue;\n                image->iterations=mng_iterations;\n                term_chunk_found=MagickFalse;\n              }\n\n            else\n                image->start_loop=MagickFalse;\n\n            image->delay=0;\n            image->columns=subframe_width;\n            image->rows=subframe_height;\n            image->page.width=subframe_width;\n            image->page.height=subframe_height;\n            image->page.x=mng_info->clip.left;\n            image->page.y=mng_info->clip.top;\n            image->background_color=mng_background_color;\n            image->matte=MagickFalse;\n            (void) SetImageBackgroundColor(image);\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Insert background layer, L=%.20g, R=%.20g T=%.20g, B=%.20g\",\n                (double) mng_info->clip.left,(double) mng_info->clip.right,\n                (double) mng_info->clip.top,(double) mng_info->clip.bottom);\n          }\n#endif /* MNG_INSERT_LAYERS */\n        first_mng_object=MagickFalse;\n\n        if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n          {\n            /*\n              Allocate next image structure.\n            */\n            AcquireNextImage(image_info,image);\n\n            if (GetNextImageInList(image) == (Image *) NULL)\n              return(DestroyImageList(image));\n\n            image=SyncNextImageInList(image);\n          }\n        mng_info->image=image;\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n\n        if (status == MagickFalse)\n          break;\n\n        if (term_chunk_found)\n          {\n            image->start_loop=MagickTrue;\n            term_chunk_found=MagickFalse;\n          }\n\n        else\n            image->start_loop=MagickFalse;\n\n        if (mng_info->framing_mode == 1 || mng_info->framing_mode == 3)\n          {\n            image->delay=frame_delay;\n            frame_delay=default_frame_delay;\n          }\n\n        else\n          image->delay=0;\n\n        image->page.width=mng_info->mng_width;\n        image->page.height=mng_info->mng_height;\n        image->page.x=mng_info->x_off[object_id];\n        image->page.y=mng_info->y_off[object_id];\n        image->iterations=mng_iterations;\n\n        /*\n          Seek back to the beginning of the IHDR or JHDR chunk's length field.\n        */\n\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  Seeking back to beginning of %c%c%c%c chunk\",type[0],type[1],\n            type[2],type[3]);\n\n        offset=SeekBlob(image,-((ssize_t) length+12),SEEK_CUR);\n\n        if (offset < 0)\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n      }\n\n    mng_info->image=image;\n    mng_info->mng_type=mng_type;\n    mng_info->object_id=object_id;\n\n    if (memcmp(type,mng_IHDR,4) == 0)\n      image=ReadOnePNGImage(mng_info,image_info,exception);\n\n#if defined(JNG_SUPPORTED)\n    else\n      image=ReadOneJNGImage(mng_info,image_info,exception);\n#endif\n\n    if (image == (Image *) NULL)\n      {\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"exit ReadJNGImage() with error\");\n\n        return((Image *) NULL);\n      }\n\n    if (image->columns == 0 || image->rows == 0)\n      {\n        (void) CloseBlob(image);\n        return(DestroyImageList(image));\n      }\n\n    mng_info->image=image;\n\n    if (mng_type)\n      {\n        MngBox\n          crop_box;\n\n        if (mng_info->magn_methx || mng_info->magn_methy)\n          {\n            png_uint_32\n               magnified_height,\n               magnified_width;\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Processing MNG MAGN chunk\");\n\n            if (mng_info->magn_methx == 1)\n              {\n                magnified_width=mng_info->magn_ml;\n\n                if (image->columns > 1)\n                   magnified_width += mng_info->magn_mr;\n\n                if (image->columns > 2)\n                   magnified_width += (png_uint_32)\n                      ((image->columns-2)*(mng_info->magn_mx));\n              }\n\n            else\n              {\n                magnified_width=(png_uint_32) image->columns;\n\n                if (image->columns > 1)\n                   magnified_width += mng_info->magn_ml-1;\n\n                if (image->columns > 2)\n                   magnified_width += mng_info->magn_mr-1;\n\n                if (image->columns > 3)\n                   magnified_width += (png_uint_32)\n                      ((image->columns-3)*(mng_info->magn_mx-1));\n              }\n\n            if (mng_info->magn_methy == 1)\n              {\n                magnified_height=mng_info->magn_mt;\n\n                if (image->rows > 1)\n                   magnified_height += mng_info->magn_mb;\n\n                if (image->rows > 2)\n                   magnified_height += (png_uint_32)\n                      ((image->rows-2)*(mng_info->magn_my));\n              }\n\n            else\n              {\n                magnified_height=(png_uint_32) image->rows;\n\n                if (image->rows > 1)\n                   magnified_height += mng_info->magn_mt-1;\n\n                if (image->rows > 2)\n                   magnified_height += mng_info->magn_mb-1;\n\n                if (image->rows > 3)\n                   magnified_height += (png_uint_32)\n                      ((image->rows-3)*(mng_info->magn_my-1));\n              }\n\n            if (magnified_height > image->rows ||\n                magnified_width > image->columns)\n              {\n                Image\n                  *large_image;\n\n                int\n                  yy;\n\n                ssize_t\n                  m,\n                  y;\n\n                register ssize_t\n                  x;\n\n                register PixelPacket\n                  *n,\n                  *q;\n\n                PixelPacket\n                  *next,\n                  *prev;\n\n                png_uint_16\n                  magn_methx,\n                  magn_methy;\n\n                /* Allocate next image structure.  */\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Allocate magnified image\");\n\n                AcquireNextImage(image_info,image);\n\n                if (GetNextImageInList(image) == (Image *) NULL)\n                  return(DestroyImageList(image));\n\n                large_image=SyncNextImageInList(image);\n\n                large_image->columns=magnified_width;\n                large_image->rows=magnified_height;\n\n                magn_methx=mng_info->magn_methx;\n                magn_methy=mng_info->magn_methy;\n\n#if (MAGICKCORE_QUANTUM_DEPTH > 16)\n#define QM unsigned short\n                if (magn_methx != 1 || magn_methy != 1)\n                  {\n                  /*\n                     Scale pixels to unsigned shorts to prevent\n                     overflow of intermediate values of interpolations\n                  */\n                     for (y=0; y < (ssize_t) image->rows; y++)\n                     {\n                       q=GetAuthenticPixels(image,0,y,image->columns,1,\n                          exception);\n\n                       for (x=(ssize_t) image->columns-1; x >= 0; x--)\n                       {\n                          SetPixelRed(q,ScaleQuantumToShort(\n                            GetPixelRed(q)));\n                          SetPixelGreen(q,ScaleQuantumToShort(\n                            GetPixelGreen(q)));\n                          SetPixelBlue(q,ScaleQuantumToShort(\n                            GetPixelBlue(q)));\n                          SetPixelOpacity(q,ScaleQuantumToShort(\n                            GetPixelOpacity(q)));\n                          q++;\n                       }\n\n                       if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                         break;\n                     }\n                  }\n#else\n#define QM Quantum\n#endif\n\n                if (image->matte != MagickFalse)\n                   (void) SetImageBackgroundColor(large_image);\n\n                else\n                  {\n                    large_image->background_color.opacity=OpaqueOpacity;\n                    (void) SetImageBackgroundColor(large_image);\n\n                    if (magn_methx == 4)\n                      magn_methx=2;\n\n                    if (magn_methx == 5)\n                      magn_methx=3;\n\n                    if (magn_methy == 4)\n                      magn_methy=2;\n\n                    if (magn_methy == 5)\n                      magn_methy=3;\n                  }\n\n                /* magnify the rows into the right side of the large image */\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Magnify the rows to %.20g\",(double) large_image->rows);\n                m=(ssize_t) mng_info->magn_mt;\n                yy=0;\n                length=(size_t) image->columns;\n                next=(PixelPacket *) AcquireQuantumMemory(length,sizeof(*next));\n                prev=(PixelPacket *) AcquireQuantumMemory(length,sizeof(*prev));\n\n                if ((prev == (PixelPacket *) NULL) ||\n                    (next == (PixelPacket *) NULL))\n                  {\n                     image=DestroyImageList(image);\n                     ThrowReaderException(ResourceLimitError,\n                       \"MemoryAllocationFailed\");\n                  }\n\n                n=GetAuthenticPixels(image,0,0,image->columns,1,exception);\n                (void) CopyMagickMemory(next,n,length);\n\n                for (y=0; y < (ssize_t) image->rows; y++)\n                {\n                  if (y == 0)\n                    m=(ssize_t) mng_info->magn_mt;\n\n                  else if (magn_methy > 1 && y == (ssize_t) image->rows-2)\n                    m=(ssize_t) mng_info->magn_mb;\n\n                  else if (magn_methy <= 1 && y == (ssize_t) image->rows-1)\n                    m=(ssize_t) mng_info->magn_mb;\n\n                  else if (magn_methy > 1 && y == (ssize_t) image->rows-1)\n                    m=1;\n\n                  else\n                    m=(ssize_t) mng_info->magn_my;\n\n                  n=prev;\n                  prev=next;\n                  next=n;\n\n                  if (y < (ssize_t) image->rows-1)\n                    {\n                      n=GetAuthenticPixels(image,0,y+1,image->columns,1,\n                          exception);\n                      (void) CopyMagickMemory(next,n,length);\n                    }\n\n                  for (i=0; i < m; i++, yy++)\n                  {\n                    register PixelPacket\n                      *pixels;\n\n                    assert(yy < (ssize_t) large_image->rows);\n                    pixels=prev;\n                    n=next;\n                    q=GetAuthenticPixels(large_image,0,yy,large_image->columns,\n                      1,exception);\n                    q+=(large_image->columns-image->columns);\n\n                    for (x=(ssize_t) image->columns-1; x >= 0; x--)\n                    {\n                      /* To do: get color as function of indexes[x] */\n                      /*\n                      if (image->storage_class == PseudoClass)\n                        {\n                        }\n                      */\n\n                      if (magn_methy <= 1)\n                        {\n                          /* replicate previous */\n                          SetPixelRGBO(q,(pixels));\n                        }\n\n                      else if (magn_methy == 2 || magn_methy == 4)\n                        {\n                          if (i == 0)\n                            {\n                              SetPixelRGBO(q,(pixels));\n                            }\n\n                          else\n                            {\n                              /* Interpolate */\n                              SetPixelRed(q,\n                                 ((QM) (((ssize_t)\n                                 (2*i*(GetPixelRed(n)\n                                 -GetPixelRed(pixels)+m))/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelRed(pixels)))));\n                              SetPixelGreen(q,\n                                 ((QM) (((ssize_t)\n                                 (2*i*(GetPixelGreen(n)\n                                 -GetPixelGreen(pixels)+m))/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelGreen(pixels)))));\n                              SetPixelBlue(q,\n                                 ((QM) (((ssize_t)\n                                 (2*i*(GetPixelBlue(n)\n                                 -GetPixelBlue(pixels)+m))/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelBlue(pixels)))));\n\n                              if (image->matte != MagickFalse)\n                                 SetPixelOpacity(q,\n                                    ((QM) (((ssize_t)\n                                    (2*i*(GetPixelOpacity(n)\n                                    -GetPixelOpacity(pixels)+m))\n                                    /((ssize_t) (m*2))+\n                                   GetPixelOpacity(pixels)))));\n                            }\n\n                          if (magn_methy == 4)\n                            {\n                              /* Replicate nearest */\n                              if (i <= ((m+1) << 1))\n                                 SetPixelOpacity(q,\n                                 (*pixels).opacity+0);\n                              else\n                                 SetPixelOpacity(q,\n                                 (*n).opacity+0);\n                            }\n                        }\n\n                      else /* if (magn_methy == 3 || magn_methy == 5) */\n                        {\n                          /* Replicate nearest */\n                          if (i <= ((m+1) << 1))\n                          {\n                             SetPixelRGBO(q,(pixels));\n                          }\n\n                          else\n                          {\n                             SetPixelRGBO(q,(n));\n                          }\n\n                          if (magn_methy == 5)\n                            {\n                              SetPixelOpacity(q,\n                                 (QM) (((ssize_t) (2*i*\n                                 (GetPixelOpacity(n)\n                                 -GetPixelOpacity(pixels))\n                                 +m))/((ssize_t) (m*2))\n                                 +GetPixelOpacity(pixels)));\n                            }\n                        }\n                      n++;\n                      q++;\n                      pixels++;\n                    } /* x */\n\n                    if (SyncAuthenticPixels(large_image,exception) == 0)\n                      break;\n\n                  } /* i */\n                } /* y */\n\n                prev=(PixelPacket *) RelinquishMagickMemory(prev);\n                next=(PixelPacket *) RelinquishMagickMemory(next);\n\n                length=image->columns;\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Delete original image\");\n\n                DeleteImageFromList(&image);\n\n                image=large_image;\n\n                mng_info->image=image;\n\n                /* magnify the columns */\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Magnify the columns to %.20g\",(double) image->columns);\n\n                for (y=0; y < (ssize_t) image->rows; y++)\n                {\n                  register PixelPacket\n                    *pixels;\n\n                  q=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n                  pixels=q+(image->columns-length);\n                  n=pixels+1;\n\n                  for (x=(ssize_t) (image->columns-length);\n                    x < (ssize_t) image->columns; x++)\n                  {\n                    /* To do: Rewrite using Get/Set***PixelComponent() */\n\n                    if (x == (ssize_t) (image->columns-length))\n                      m=(ssize_t) mng_info->magn_ml;\n\n                    else if (magn_methx > 1 && x == (ssize_t) image->columns-2)\n                      m=(ssize_t) mng_info->magn_mr;\n\n                    else if (magn_methx <= 1 && x == (ssize_t) image->columns-1)\n                      m=(ssize_t) mng_info->magn_mr;\n\n                    else if (magn_methx > 1 && x == (ssize_t) image->columns-1)\n                      m=1;\n\n                    else\n                      m=(ssize_t) mng_info->magn_mx;\n\n                    for (i=0; i < m; i++)\n                    {\n                      if (magn_methx <= 1)\n                        {\n                          /* replicate previous */\n                          SetPixelRGBO(q,(pixels));\n                        }\n\n                      else if (magn_methx == 2 || magn_methx == 4)\n                        {\n                          if (i == 0)\n                          {\n                             SetPixelRGBO(q,(pixels));\n                          }\n\n                          /* To do: Rewrite using Get/Set***PixelComponent() */\n                          else\n                            {\n                              /* Interpolate */\n                              SetPixelRed(q,\n                                 (QM) ((2*i*(\n                                 GetPixelRed(n)\n                                 -GetPixelRed(pixels))+m)\n                                 /((ssize_t) (m*2))+\n                                 GetPixelRed(pixels)));\n\n                              SetPixelGreen(q,\n                                 (QM) ((2*i*(\n                                 GetPixelGreen(n)\n                                 -GetPixelGreen(pixels))+m)\n                                 /((ssize_t) (m*2))+\n                                 GetPixelGreen(pixels)));\n\n                              SetPixelBlue(q,\n                                 (QM) ((2*i*(\n                                 GetPixelBlue(n)\n                                 -GetPixelBlue(pixels))+m)\n                                 /((ssize_t) (m*2))+\n                                 GetPixelBlue(pixels)));\n                              if (image->matte != MagickFalse)\n                                 SetPixelOpacity(q,\n                                   (QM) ((2*i*(\n                                   GetPixelOpacity(n)\n                                   -GetPixelOpacity(pixels))+m)\n                                   /((ssize_t) (m*2))+\n                                   GetPixelOpacity(pixels)));\n                            }\n\n                          if (magn_methx == 4)\n                            {\n                              /* Replicate nearest */\n                              if (i <= ((m+1) << 1))\n                              {\n                                 SetPixelOpacity(q,\n                                 GetPixelOpacity(pixels)+0);\n                              }\n                              else\n                              {\n                                 SetPixelOpacity(q,\n                                 GetPixelOpacity(n)+0);\n                              }\n                            }\n                        }\n\n                      else /* if (magn_methx == 3 || magn_methx == 5) */\n                        {\n                          /* Replicate nearest */\n                          if (i <= ((m+1) << 1))\n                          {\n                             SetPixelRGBO(q,(pixels));\n                          }\n\n                          else\n                          {\n                             SetPixelRGBO(q,(n));\n                          }\n\n                          if (magn_methx == 5)\n                            {\n                              /* Interpolate */\n                              SetPixelOpacity(q,\n                                 (QM) ((2*i*( GetPixelOpacity(n)\n                                 -GetPixelOpacity(pixels))+m)/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelOpacity(pixels)));\n                            }\n                        }\n                      q++;\n                    }\n                    n++;\n                  }\n\n                  if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                    break;\n                }\n#if (MAGICKCORE_QUANTUM_DEPTH > 16)\n              if (magn_methx != 1 || magn_methy != 1)\n                {\n                /*\n                   Rescale pixels to Quantum\n                */\n                   for (y=0; y < (ssize_t) image->rows; y++)\n                   {\n                     q=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n\n                     for (x=(ssize_t) image->columns-1; x >= 0; x--)\n                     {\n                        SetPixelRed(q,ScaleShortToQuantum(\n                            GetPixelRed(q)));\n                        SetPixelGreen(q,ScaleShortToQuantum(\n                            GetPixelGreen(q)));\n                        SetPixelBlue(q,ScaleShortToQuantum(\n                            GetPixelBlue(q)));\n                        SetPixelOpacity(q,ScaleShortToQuantum(\n                            GetPixelOpacity(q)));\n                        q++;\n                     }\n\n                     if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                       break;\n                   }\n                }\n#endif\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  Finished MAGN processing\");\n              }\n          }\n\n        /*\n          Crop_box is with respect to the upper left corner of the MNG.\n        */\n        crop_box.left=mng_info->image_box.left+mng_info->x_off[object_id];\n        crop_box.right=mng_info->image_box.right+mng_info->x_off[object_id];\n        crop_box.top=mng_info->image_box.top+mng_info->y_off[object_id];\n        crop_box.bottom=mng_info->image_box.bottom+mng_info->y_off[object_id];\n        crop_box=mng_minimum_box(crop_box,mng_info->clip);\n        crop_box=mng_minimum_box(crop_box,mng_info->frame);\n        crop_box=mng_minimum_box(crop_box,mng_info->object_clip[object_id]);\n        if ((crop_box.left != (mng_info->image_box.left\n            +mng_info->x_off[object_id])) ||\n            (crop_box.right != (mng_info->image_box.right\n            +mng_info->x_off[object_id])) ||\n            (crop_box.top != (mng_info->image_box.top\n            +mng_info->y_off[object_id])) ||\n            (crop_box.bottom != (mng_info->image_box.bottom\n            +mng_info->y_off[object_id])))\n          {\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Crop the PNG image\");\n\n            if ((crop_box.left < crop_box.right) &&\n                (crop_box.top < crop_box.bottom))\n              {\n                Image\n                  *im;\n\n                RectangleInfo\n                  crop_info;\n\n                /*\n                  Crop_info is with respect to the upper left corner of\n                  the image.\n                */\n                crop_info.x=(crop_box.left-mng_info->x_off[object_id]);\n                crop_info.y=(crop_box.top-mng_info->y_off[object_id]);\n                crop_info.width=(size_t) (crop_box.right-crop_box.left);\n                crop_info.height=(size_t) (crop_box.bottom-crop_box.top);\n                image->page.width=image->columns;\n                image->page.height=image->rows;\n                image->page.x=0;\n                image->page.y=0;\n                im=CropImage(image,&crop_info,exception);\n\n                if (im != (Image *) NULL)\n                  {\n                    image->columns=im->columns;\n                    image->rows=im->rows;\n                    im=DestroyImage(im);\n                    image->page.width=image->columns;\n                    image->page.height=image->rows;\n                    image->page.x=crop_box.left;\n                    image->page.y=crop_box.top;\n                  }\n              }\n\n            else\n              {\n                /*\n                  No pixels in crop area.  The MNG spec still requires\n                  a layer, though, so make a single transparent pixel in\n                  the top left corner.\n                */\n                image->columns=1;\n                image->rows=1;\n                image->colors=2;\n                (void) SetImageBackgroundColor(image);\n                image->page.width=1;\n                image->page.height=1;\n                image->page.x=0;\n                image->page.y=0;\n              }\n          }\n#ifndef PNG_READ_EMPTY_PLTE_SUPPORTED\n        image=mng_info->image;\n#endif\n      }\n\n#if (MAGICKCORE_QUANTUM_DEPTH > 16)\n      /* PNG does not handle depths greater than 16 so reduce it even\n       * if lossy, and promote any depths > 8 to 16.\n       */\n      if (image->depth > 16)\n         image->depth=16;\n#endif\n\n#if (MAGICKCORE_QUANTUM_DEPTH > 8)\n      if (image->depth > 8)\n        {\n          /* To do: fill low byte properly */\n          image->depth=16;\n        }\n\n      if (LosslessReduceDepthOK(image) != MagickFalse)\n         image->depth = 8;\n#endif\n\n      GetImageException(image,exception);\n\n      if (image_info->number_scenes != 0)\n        {\n          if (mng_info->scenes_found >\n             (ssize_t) (image_info->first_scene+image_info->number_scenes))\n            break;\n        }\n\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  Finished reading image datastream.\");\n\n  } while (LocaleCompare(image_info->magick,\"MNG\") == 0);\n\n  (void) CloseBlob(image);\n\n  if (logging != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  Finished reading all image datastreams.\");\n\n#if defined(MNG_INSERT_LAYERS)\n  if (insert_layers && !mng_info->image_found && (mng_info->mng_width) &&\n       (mng_info->mng_height))\n    {\n      /*\n        Insert a background layer if nothing else was found.\n      */\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  No images found.  Inserting a background layer.\");\n\n      if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n        {\n          /*\n            Allocate next image structure.\n          */\n          AcquireNextImage(image_info,image);\n          if (GetNextImageInList(image) == (Image *) NULL)\n            {\n              if (logging != MagickFalse)\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"  Allocation failed, returning NULL.\");\n\n              return(DestroyImageList(image));\n            }\n          image=SyncNextImageInList(image);\n        }\n      image->columns=mng_info->mng_width;\n      image->rows=mng_info->mng_height;\n      image->page.width=mng_info->mng_width;\n      image->page.height=mng_info->mng_height;\n      image->page.x=0;\n      image->page.y=0;\n      image->background_color=mng_background_color;\n      image->matte=MagickFalse;\n\n      if (image_info->ping == MagickFalse)\n        (void) SetImageBackgroundColor(image);\n\n      mng_info->image_found++;\n    }\n#endif\n  image->iterations=mng_iterations;\n\n  if (mng_iterations == 1)\n    image->start_loop=MagickTrue;\n\n  while (GetPreviousImageInList(image) != (Image *) NULL)\n  {\n    image_count++;\n    if (image_count > 10*mng_info->image_found)\n      {\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"  No beginning\");\n\n        (void) ThrowMagickException(&image->exception,GetMagickModule(),\n          CoderError,\"Linked list is corrupted, beginning of list not found\",\n          \"`%s'\",image_info->filename);\n\n        return(DestroyImageList(image));\n      }\n\n    image=GetPreviousImageInList(image);\n\n    if (GetNextImageInList(image) == (Image *) NULL)\n      {\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"  Corrupt list\");\n\n        (void) ThrowMagickException(&image->exception,GetMagickModule(),\n          CoderError,\"Linked list is corrupted; next_image is NULL\",\"`%s'\",\n          image_info->filename);\n      }\n  }\n\n  if (mng_info->ticks_per_second && mng_info->image_found > 1 &&\n             GetNextImageInList(image) ==\n     (Image *) NULL)\n    {\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  First image null\");\n\n      (void) ThrowMagickException(&image->exception,GetMagickModule(),\n        CoderError,\"image->next for first image is NULL but shouldn't be.\",\n        \"`%s'\",image_info->filename);\n    }\n\n  if (mng_info->image_found == 0)\n    {\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  No visible images found.\");\n\n      (void) ThrowMagickException(&image->exception,GetMagickModule(),\n        CoderError,\"No visible images in file\",\"`%s'\",image_info->filename);\n\n      return(DestroyImageList(image));\n    }\n\n  if (mng_info->ticks_per_second)\n    final_delay=1UL*MagickMax(image->ticks_per_second,1L)*\n            final_delay/mng_info->ticks_per_second;\n\n  else\n    image->start_loop=MagickTrue;\n\n  /* Find final nonzero image delay */\n  final_image_delay=0;\n\n  while (GetNextImageInList(image) != (Image *) NULL)\n    {\n      if (image->delay)\n        final_image_delay=image->delay;\n\n      image=GetNextImageInList(image);\n    }\n\n  if (final_delay < final_image_delay)\n    final_delay=final_image_delay;\n\n  image->delay=final_delay;\n\n  if (logging != MagickFalse)\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  image->delay=%.20g, final_delay=%.20g\",(double) image->delay,\n        (double) final_delay);\n\n  if (logging != MagickFalse)\n    {\n      int\n        scene;\n\n      scene=0;\n      image=GetFirstImageInList(image);\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  Before coalesce:\");\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    scene 0 delay=%.20g\",(double) image->delay);\n\n      while (GetNextImageInList(image) != (Image *) NULL)\n      {\n        image=GetNextImageInList(image);\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"    scene %.20g delay=%.20g\",(double) scene++,(double) image->delay);\n      }\n    }\n\n  image=GetFirstImageInList(image);\n#ifdef MNG_COALESCE_LAYERS\n  if (insert_layers)\n    {\n      Image\n        *next_image,\n        *next;\n\n      size_t\n        scene;\n\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"  Coalesce Images\");\n\n      scene=image->scene;\n      next_image=CoalesceImages(image,&image->exception);\n\n      if (next_image == (Image *) NULL)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n      image=DestroyImageList(image);\n      image=next_image;\n\n      for (next=image; next != (Image *) NULL; next=next_image)\n      {\n         next->page.width=mng_info->mng_width;\n         next->page.height=mng_info->mng_height;\n         next->page.x=0;\n         next->page.y=0;\n         next->scene=scene++;\n         next_image=GetNextImageInList(next);\n\n         if (next_image == (Image *) NULL)\n           break;\n\n         if (next->delay == 0)\n           {\n             scene--;\n             next_image->previous=GetPreviousImageInList(next);\n             if (GetPreviousImageInList(next) == (Image *) NULL)\n               image=next_image;\n             else\n               next->previous->next=next_image;\n             next=DestroyImage(next);\n           }\n      }\n    }\n#endif\n\n  while (GetNextImageInList(image) != (Image *) NULL)\n      image=GetNextImageInList(image);\n\n  image->dispose=BackgroundDispose;\n\n  if (logging != MagickFalse)\n    {\n      int\n        scene;\n\n      scene=0;\n      image=GetFirstImageInList(image);\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  After coalesce:\");\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    scene 0 delay=%.20g dispose=%.20g\",(double) image->delay,\n        (double) image->dispose);\n\n      while (GetNextImageInList(image) != (Image *) NULL)\n      {\n        image=GetNextImageInList(image);\n\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"    scene %.20g delay=%.20g dispose=%.20g\",(double) scene++,\n          (double) image->delay,(double) image->dispose);\n      }\n   }\n\n  if (logging != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  exit ReadOneJNGImage();\");\n\n  return(image);\n}", "func_src_after": "static Image *ReadOneMNGImage(MngInfo* mng_info, const ImageInfo *image_info,\n     ExceptionInfo *exception)\n{\n  char\n    page_geometry[MaxTextExtent];\n\n  Image\n    *image;\n\n  MagickBooleanType\n    logging;\n\n  volatile int\n    first_mng_object,\n    object_id,\n    term_chunk_found,\n    skip_to_iend;\n\n  volatile ssize_t\n    image_count=0;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    offset;\n\n  MngBox\n    default_fb,\n    fb,\n    previous_fb;\n\n#if defined(MNG_INSERT_LAYERS)\n  PixelPacket\n    mng_background_color;\n#endif\n\n  register unsigned char\n    *p;\n\n  register ssize_t\n    i;\n\n  size_t\n    count;\n\n  ssize_t\n    loop_level;\n\n  volatile short\n    skipping_loop;\n\n#if defined(MNG_INSERT_LAYERS)\n  unsigned int\n    mandatory_back=0;\n#endif\n\n  volatile unsigned int\n#ifdef MNG_OBJECT_BUFFERS\n    mng_background_object=0,\n#endif\n    mng_type=0;   /* 0: PNG or JNG; 1: MNG; 2: MNG-LC; 3: MNG-VLC */\n\n  size_t\n    default_frame_timeout,\n    frame_timeout,\n#if defined(MNG_INSERT_LAYERS)\n    image_height,\n    image_width,\n#endif\n    length;\n\n  /* These delays are all measured in image ticks_per_second,\n   * not in MNG ticks_per_second\n   */\n  volatile size_t\n    default_frame_delay,\n    final_delay,\n    final_image_delay,\n    frame_delay,\n#if defined(MNG_INSERT_LAYERS)\n    insert_layers,\n#endif\n    mng_iterations=1,\n    simplicity=0,\n    subframe_height=0,\n    subframe_width=0;\n\n  previous_fb.top=0;\n  previous_fb.bottom=0;\n  previous_fb.left=0;\n  previous_fb.right=0;\n  default_fb.top=0;\n  default_fb.bottom=0;\n  default_fb.left=0;\n  default_fb.right=0;\n\n  logging=LogMagickEvent(CoderEvent,GetMagickModule(),\n    \"  Enter ReadOneMNGImage()\");\n\n  image=mng_info->image;\n\n  if (LocaleCompare(image_info->magick,\"MNG\") == 0)\n    {\n      char\n        magic_number[MaxTextExtent];\n\n      /* Verify MNG signature.  */\n      count=(size_t) ReadBlob(image,8,(unsigned char *) magic_number);\n      if (memcmp(magic_number,\"\\212MNG\\r\\n\\032\\n\",8) != 0)\n        ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n      /* Initialize some nonzero members of the MngInfo structure.  */\n      for (i=0; i < MNG_MAX_OBJECTS; i++)\n      {\n        mng_info->object_clip[i].right=(ssize_t) PNG_UINT_31_MAX;\n        mng_info->object_clip[i].bottom=(ssize_t) PNG_UINT_31_MAX;\n      }\n      mng_info->exists[0]=MagickTrue;\n    }\n\n  skipping_loop=(-1);\n  first_mng_object=MagickTrue;\n  mng_type=0;\n#if defined(MNG_INSERT_LAYERS)\n  insert_layers=MagickFalse; /* should be False when converting or mogrifying */\n#endif\n  default_frame_delay=0;\n  default_frame_timeout=0;\n  frame_delay=0;\n  final_delay=1;\n  mng_info->ticks_per_second=1UL*image->ticks_per_second;\n  object_id=0;\n  skip_to_iend=MagickFalse;\n  term_chunk_found=MagickFalse;\n  mng_info->framing_mode=1;\n#if defined(MNG_INSERT_LAYERS)\n  mandatory_back=MagickFalse;\n#endif\n#if defined(MNG_INSERT_LAYERS)\n  mng_background_color=image->background_color;\n#endif\n  default_fb=mng_info->frame;\n  previous_fb=mng_info->frame;\n  do\n  {\n    char\n      type[MaxTextExtent];\n\n    if (LocaleCompare(image_info->magick,\"MNG\") == 0)\n      {\n        unsigned char\n          *chunk;\n\n        /*\n          Read a new chunk.\n        */\n        type[0]='\\0';\n        (void) ConcatenateMagickString(type,\"errr\",MaxTextExtent);\n        length=ReadBlobMSBLong(image);\n        count=(size_t) ReadBlob(image,4,(unsigned char *) type);\n\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n           \"  Reading MNG chunk type %c%c%c%c, length: %.20g\",\n           type[0],type[1],type[2],type[3],(double) length);\n\n        if (length > PNG_UINT_31_MAX)\n          {\n            status=MagickFalse;\n            break;\n          }\n\n        if (count == 0)\n          ThrowReaderException(CorruptImageError,\"CorruptImage\");\n\n        p=NULL;\n        chunk=(unsigned char *) NULL;\n\n        if (length != 0)\n          {\n            chunk=(unsigned char *) AcquireQuantumMemory(length+\n              MagickPathExtent,sizeof(*chunk));\n\n            if (chunk == (unsigned char *) NULL)\n              ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n            for (i=0; i < (ssize_t) length; i++)\n            {\n              int\n                c;\n\n              c=ReadBlobByte(image);\n              if (c == EOF)\n                break;\n              chunk[i]=(unsigned char) c;\n            }\n\n            p=chunk;\n          }\n\n        (void) ReadBlobMSBLong(image);  /* read crc word */\n\n#if !defined(JNG_SUPPORTED)\n        if (memcmp(type,mng_JHDR,4) == 0)\n          {\n            skip_to_iend=MagickTrue;\n\n            if (mng_info->jhdr_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"JNGCompressNotSupported\",\"`%s'\",image->filename);\n\n            mng_info->jhdr_warning++;\n          }\n#endif\n        if (memcmp(type,mng_DHDR,4) == 0)\n          {\n            skip_to_iend=MagickTrue;\n\n            if (mng_info->dhdr_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"DeltaPNGNotSupported\",\"`%s'\",image->filename);\n\n            mng_info->dhdr_warning++;\n          }\n        if (memcmp(type,mng_MEND,4) == 0)\n          break;\n\n        if (skip_to_iend)\n          {\n            if (memcmp(type,mng_IEND,4) == 0)\n              skip_to_iend=MagickFalse;\n\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Skip to IEND.\");\n\n            continue;\n          }\n\n        if (memcmp(type,mng_MHDR,4) == 0)\n          {\n            if (length != 28)\n              {\n                chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n                ThrowReaderException(CorruptImageError,\"CorruptImage\");\n              }\n\n            mng_info->mng_width=(size_t) ((p[0] << 24) | (p[1] << 16) |\n                (p[2] << 8) | p[3]);\n\n            mng_info->mng_height=(size_t) ((p[4] << 24) | (p[5] << 16) |\n                (p[6] << 8) | p[7]);\n\n            if (logging != MagickFalse)\n              {\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"  MNG width: %.20g\",(double) mng_info->mng_width);\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"  MNG height: %.20g\",(double) mng_info->mng_height);\n              }\n\n            p+=8;\n            mng_info->ticks_per_second=(size_t) mng_get_long(p);\n\n            if (mng_info->ticks_per_second == 0)\n              default_frame_delay=0;\n\n            else\n              default_frame_delay=1UL*image->ticks_per_second/\n                mng_info->ticks_per_second;\n\n            frame_delay=default_frame_delay;\n            simplicity=0;\n\n            /* Skip nominal layer count, frame count, and play time */\n            p+=16;\n            simplicity=(size_t) mng_get_long(p);\n\n            mng_type=1;    /* Full MNG */\n\n            if ((simplicity != 0) && ((simplicity | 11) == 11))\n              mng_type=2; /* LC */\n\n            if ((simplicity != 0) && ((simplicity | 9) == 9))\n              mng_type=3; /* VLC */\n\n#if defined(MNG_INSERT_LAYERS)\n            if (mng_type != 3)\n              insert_layers=MagickTrue;\n#endif\n            if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n              {\n                /* Allocate next image structure.  */\n                AcquireNextImage(image_info,image);\n\n                if (GetNextImageInList(image) == (Image *) NULL)\n                  return(DestroyImageList(image));\n\n                image=SyncNextImageInList(image);\n                mng_info->image=image;\n              }\n\n            if ((mng_info->mng_width > 65535L) ||\n                (mng_info->mng_height > 65535L))\n              {\n                chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n                ThrowReaderException(ImageError,\"WidthOrHeightExceedsLimit\");\n              }\n\n            (void) FormatLocaleString(page_geometry,MaxTextExtent,\n              \"%.20gx%.20g+0+0\",(double) mng_info->mng_width,(double)\n              mng_info->mng_height);\n\n            mng_info->frame.left=0;\n            mng_info->frame.right=(ssize_t) mng_info->mng_width;\n            mng_info->frame.top=0;\n            mng_info->frame.bottom=(ssize_t) mng_info->mng_height;\n            mng_info->clip=default_fb=previous_fb=mng_info->frame;\n\n            for (i=0; i < MNG_MAX_OBJECTS; i++)\n              mng_info->object_clip[i]=mng_info->frame;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_TERM,4) == 0)\n          {\n            int\n              repeat=0;\n\n            if (length != 0)\n              repeat=p[0];\n\n            if (repeat == 3 && length > 8)\n              {\n                final_delay=(png_uint_32) mng_get_long(&p[2]);\n                mng_iterations=(png_uint_32) mng_get_long(&p[6]);\n\n                if (mng_iterations == PNG_UINT_31_MAX)\n                  mng_iterations=0;\n\n                image->iterations=mng_iterations;\n                term_chunk_found=MagickTrue;\n              }\n\n            if (logging != MagickFalse)\n              {\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"    repeat=%d,  final_delay=%.20g,  iterations=%.20g\",\n                  repeat,(double) final_delay, (double) image->iterations);\n              }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_DEFI,4) == 0)\n          {\n            if (mng_type == 3)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"DEFI chunk found in MNG-VLC datastream\",\"`%s'\",\n                image->filename);\n\n            if (length > 1)\n              {\n                object_id=(p[0] << 8) | p[1];\n\n                if (mng_type == 2 && object_id != 0)\n                  (void) ThrowMagickException(&image->exception,\n                     GetMagickModule(),\n                     CoderError,\"Nonzero object_id in MNG-LC datastream\",\n                     \"`%s'\", image->filename);\n\n                if (object_id > MNG_MAX_OBJECTS)\n                  {\n                    /*\n                      Instead of using a warning we should allocate a larger\n                      MngInfo structure and continue.\n                    */\n                    (void) ThrowMagickException(&image->exception,\n                        GetMagickModule(), CoderError,\n                        \"object id too large\",\"`%s'\",image->filename);\n                        object_id=MNG_MAX_OBJECTS;\n                  }\n\n                if (mng_info->exists[object_id])\n                  if (mng_info->frozen[object_id])\n                    {\n                      chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n                      (void) ThrowMagickException(&image->exception,\n                        GetMagickModule(),CoderError,\n                        \"DEFI cannot redefine a frozen MNG object\",\"`%s'\",\n                        image->filename);\n                      continue;\n                    }\n\n                mng_info->exists[object_id]=MagickTrue;\n\n                if (length > 2)\n                  mng_info->invisible[object_id]=p[2];\n\n                /*\n                  Extract object offset info.\n                */\n                if (length > 11)\n                  {\n                    mng_info->x_off[object_id]=(ssize_t) ((p[4] << 24) |\n                        (p[5] << 16) | (p[6] << 8) | p[7]);\n\n                    mng_info->y_off[object_id]=(ssize_t) ((p[8] << 24) |\n                        (p[9] << 16) | (p[10] << 8) | p[11]);\n\n                    if (logging != MagickFalse)\n                      {\n                        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                          \"  x_off[%d]: %.20g,  y_off[%d]: %.20g\",\n                          object_id,(double) mng_info->x_off[object_id],\n                          object_id,(double) mng_info->y_off[object_id]);\n                      }\n                  }\n\n                /*\n                  Extract object clipping info.\n                */\n            \n                if (length > 27)\n                  mng_info->object_clip[object_id]=\n                    mng_read_box(mng_info->frame,0, &p[12]);\n            }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_bKGD,4) == 0)\n          {\n            mng_info->have_global_bkgd=MagickFalse;\n\n            if (length > 5)\n              {\n                mng_info->mng_global_bkgd.red=\n                  ScaleShortToQuantum((unsigned short) ((p[0] << 8) | p[1]));\n\n                mng_info->mng_global_bkgd.green=\n                  ScaleShortToQuantum((unsigned short) ((p[2] << 8) | p[3]));\n\n                mng_info->mng_global_bkgd.blue=\n                  ScaleShortToQuantum((unsigned short) ((p[4] << 8) | p[5]));\n\n                mng_info->have_global_bkgd=MagickTrue;\n              }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_BACK,4) == 0)\n          {\n#if defined(MNG_INSERT_LAYERS)\n            if (length > 6)\n              mandatory_back=p[6];\n\n            else\n              mandatory_back=0;\n\n            if (mandatory_back && length > 5)\n              {\n                mng_background_color.red=\n                    ScaleShortToQuantum((unsigned short) ((p[0] << 8) | p[1]));\n\n                mng_background_color.green=\n                    ScaleShortToQuantum((unsigned short) ((p[2] << 8) | p[3]));\n\n                mng_background_color.blue=\n                    ScaleShortToQuantum((unsigned short) ((p[4] << 8) | p[5]));\n\n                mng_background_color.opacity=OpaqueOpacity;\n              }\n\n#ifdef MNG_OBJECT_BUFFERS\n            if (length > 8)\n              mng_background_object=(p[7] << 8) | p[8];\n#endif\n#endif\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_PLTE,4) == 0)\n          {\n            /* Read global PLTE.  */\n\n            if (length && (length < 769))\n              {\n                if (mng_info->global_plte == (png_colorp) NULL)\n                  mng_info->global_plte=(png_colorp) AcquireQuantumMemory(256,\n                    sizeof(*mng_info->global_plte));\n\n                for (i=0; i < (ssize_t) (length/3); i++)\n                {\n                  mng_info->global_plte[i].red=p[3*i];\n                  mng_info->global_plte[i].green=p[3*i+1];\n                  mng_info->global_plte[i].blue=p[3*i+2];\n                }\n\n                mng_info->global_plte_length=(unsigned int) (length/3);\n              }\n#ifdef MNG_LOOSE\n            for ( ; i < 256; i++)\n            {\n              mng_info->global_plte[i].red=i;\n              mng_info->global_plte[i].green=i;\n              mng_info->global_plte[i].blue=i;\n            }\n\n            if (length != 0)\n              mng_info->global_plte_length=256;\n#endif\n            else\n              mng_info->global_plte_length=0;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_tRNS,4) == 0)\n          {\n            /* read global tRNS */\n\n            if (length > 0 && length < 257)\n              for (i=0; i < (ssize_t) length; i++)\n                mng_info->global_trns[i]=p[i];\n\n#ifdef MNG_LOOSE\n            for ( ; i < 256; i++)\n              mng_info->global_trns[i]=255;\n#endif\n            mng_info->global_trns_length=(unsigned int) length;\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_gAMA,4) == 0)\n          {\n            if (length == 4)\n              {\n                ssize_t\n                  igamma;\n\n                igamma=mng_get_long(p);\n                mng_info->global_gamma=((float) igamma)*0.00001;\n                mng_info->have_global_gama=MagickTrue;\n              }\n\n            else\n              mng_info->have_global_gama=MagickFalse;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_cHRM,4) == 0)\n          {\n            /* Read global cHRM */\n\n            if (length == 32)\n              {\n                mng_info->global_chrm.white_point.x=0.00001*mng_get_long(p);\n                mng_info->global_chrm.white_point.y=0.00001*mng_get_long(&p[4]);\n                mng_info->global_chrm.red_primary.x=0.00001*mng_get_long(&p[8]);\n                mng_info->global_chrm.red_primary.y=0.00001*\n                  mng_get_long(&p[12]);\n                mng_info->global_chrm.green_primary.x=0.00001*\n                  mng_get_long(&p[16]);\n                mng_info->global_chrm.green_primary.y=0.00001*\n                  mng_get_long(&p[20]);\n                mng_info->global_chrm.blue_primary.x=0.00001*\n                  mng_get_long(&p[24]);\n                mng_info->global_chrm.blue_primary.y=0.00001*\n                  mng_get_long(&p[28]);\n                mng_info->have_global_chrm=MagickTrue;\n              }\n            else\n              mng_info->have_global_chrm=MagickFalse;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_sRGB,4) == 0)\n          {\n            /*\n              Read global sRGB.\n            */\n            if (length != 0)\n              {\n                mng_info->global_srgb_intent=\n                  Magick_RenderingIntent_from_PNG_RenderingIntent(p[0]);\n                mng_info->have_global_srgb=MagickTrue;\n              }\n            else\n              mng_info->have_global_srgb=MagickFalse;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_iCCP,4) == 0)\n          {\n            /* To do: */\n\n            /*\n              Read global iCCP.\n            */\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n\n        if (memcmp(type,mng_FRAM,4) == 0)\n          {\n            if (mng_type == 3)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"FRAM chunk found in MNG-VLC datastream\",\"`%s'\",\n                image->filename);\n\n            if ((mng_info->framing_mode == 2) || (mng_info->framing_mode == 4))\n              image->delay=frame_delay;\n\n            frame_delay=default_frame_delay;\n            frame_timeout=default_frame_timeout;\n            fb=default_fb;\n\n            if (length > 0)\n              if (p[0])\n                mng_info->framing_mode=p[0];\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"    Framing_mode=%d\",mng_info->framing_mode);\n\n            if (length > 6)\n              {\n                /* Note the delay and frame clipping boundaries.  */\n\n                p++; /* framing mode */\n\n                while (*p && ((p-chunk) < (ssize_t) length))\n                  p++;  /* frame name */\n\n                p++;  /* frame name terminator */\n\n                if ((p-chunk) < (ssize_t) (length-4))\n                  {\n                    int\n                      change_delay,\n                      change_timeout,\n                      change_clipping;\n\n                    change_delay=(*p++);\n                    change_timeout=(*p++);\n                    change_clipping=(*p++);\n                    p++; /* change_sync */\n\n                    if (change_delay && (p-chunk) < (ssize_t) (length-4))\n                      {\n                          frame_delay=1UL*image->ticks_per_second*\n                            mng_get_long(p);\n\n                        if (mng_info->ticks_per_second != 0)\n                          frame_delay/=mng_info->ticks_per_second;\n\n                        else\n                          frame_delay=PNG_UINT_31_MAX;\n\n                        if (change_delay == 2)\n                          default_frame_delay=frame_delay;\n\n                        p+=4;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                            \"    Framing_delay=%.20g\",(double) frame_delay);\n                      }\n\n                    if (change_timeout && (p-chunk) < (ssize_t) (length-4))\n                      {\n                        frame_timeout=1UL*image->ticks_per_second*\n                          mng_get_long(p);\n\n                        if (mng_info->ticks_per_second != 0)\n                          frame_timeout/=mng_info->ticks_per_second;\n\n                        else\n                          frame_timeout=PNG_UINT_31_MAX;\n\n                        if (change_timeout == 2)\n                          default_frame_timeout=frame_timeout;\n\n                        p+=4;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                            \"    Framing_timeout=%.20g\",(double) frame_timeout);\n                      }\n\n                    if (change_clipping && (p-chunk) < (ssize_t) (length-17))\n                      {\n                        fb=mng_read_box(previous_fb,(char) p[0],&p[1]);\n                        p+=17;\n                        previous_fb=fb;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                            \"    Frame_clip: L=%.20g R=%.20g T=%.20g B=%.20g\",\n                            (double) fb.left,(double) fb.right,(double) fb.top,\n                            (double) fb.bottom);\n\n                        if (change_clipping == 2)\n                          default_fb=fb;\n                      }\n                  }\n              }\n            mng_info->clip=fb;\n            mng_info->clip=mng_minimum_box(fb,mng_info->frame);\n\n            subframe_width=(size_t) (mng_info->clip.right\n               -mng_info->clip.left);\n\n            subframe_height=(size_t) (mng_info->clip.bottom\n               -mng_info->clip.top);\n            /*\n              Insert a background layer behind the frame if framing_mode is 4.\n            */\n#if defined(MNG_INSERT_LAYERS)\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"   subframe_width=%.20g, subframe_height=%.20g\",(double)\n                subframe_width,(double) subframe_height);\n\n            if (insert_layers && (mng_info->framing_mode == 4) &&\n                (subframe_width) && (subframe_height))\n              {\n                /* Allocate next image structure.  */\n                if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n                  {\n                    AcquireNextImage(image_info,image);\n\n                    if (GetNextImageInList(image) == (Image *) NULL)\n                      return(DestroyImageList(image));\n\n                    image=SyncNextImageInList(image);\n                  }\n\n                mng_info->image=image;\n\n                if (term_chunk_found)\n                  {\n                    image->start_loop=MagickTrue;\n                    image->iterations=mng_iterations;\n                    term_chunk_found=MagickFalse;\n                  }\n\n                else\n                    image->start_loop=MagickFalse;\n\n                image->columns=subframe_width;\n                image->rows=subframe_height;\n                image->page.width=subframe_width;\n                image->page.height=subframe_height;\n                image->page.x=mng_info->clip.left;\n                image->page.y=mng_info->clip.top;\n                image->background_color=mng_background_color;\n                image->matte=MagickFalse;\n                image->delay=0;\n                (void) SetImageBackgroundColor(image);\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  Insert backgd layer, L=%.20g, R=%.20g T=%.20g, B=%.20g\",\n                    (double) mng_info->clip.left,(double) mng_info->clip.right,\n                    (double) mng_info->clip.top,(double) mng_info->clip.bottom);\n              }\n#endif\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_CLIP,4) == 0)\n          {\n            unsigned int\n              first_object,\n              last_object;\n\n            /*\n              Read CLIP.\n            */\n            if (length > 3)\n              {\n                first_object=(p[0] << 8) | p[1];\n                last_object=(p[2] << 8) | p[3];\n                p+=4;\n\n                for (i=(int) first_object; i <= (int) last_object; i++)\n                {\n                  if (mng_info->exists[i] && !mng_info->frozen[i])\n                    {\n                      MngBox\n                        box;\n\n                      box=mng_info->object_clip[i];\n                      if ((p-chunk) < (ssize_t) (length-17))\n                        mng_info->object_clip[i]=\n                           mng_read_box(box,(char) p[0],&p[1]);\n                    }\n                }\n\n              }\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_SAVE,4) == 0)\n          {\n            for (i=1; i < MNG_MAX_OBJECTS; i++)\n              if (mng_info->exists[i])\n                {\n                 mng_info->frozen[i]=MagickTrue;\n#ifdef MNG_OBJECT_BUFFERS\n                 if (mng_info->ob[i] != (MngBuffer *) NULL)\n                    mng_info->ob[i]->frozen=MagickTrue;\n#endif\n                }\n\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n\n        if ((memcmp(type,mng_DISC,4) == 0) || (memcmp(type,mng_SEEK,4) == 0))\n          {\n            /* Read DISC or SEEK.  */\n\n            if ((length == 0) || !memcmp(type,mng_SEEK,4))\n              {\n                for (i=1; i < MNG_MAX_OBJECTS; i++)\n                  MngInfoDiscardObject(mng_info,i);\n              }\n\n            else\n              {\n                register ssize_t\n                  j;\n\n                for (j=1; j < (ssize_t) length; j+=2)\n                {\n                  i=p[j-1] << 8 | p[j];\n                  MngInfoDiscardObject(mng_info,i);\n                }\n              }\n\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n\n        if (memcmp(type,mng_MOVE,4) == 0)\n          {\n            size_t\n              first_object,\n              last_object;\n\n            /* read MOVE */\n\n            if (length > 3)\n            {\n              first_object=(p[0] << 8) | p[1];\n              last_object=(p[2] << 8) | p[3];\n              p+=4;\n\n              for (i=(ssize_t) first_object; i <= (ssize_t) last_object; i++)\n              {\n                if ((i < 0) || (i >= MNG_MAX_OBJECTS))\n                  continue;\n                if (mng_info->exists[i] && !mng_info->frozen[i] &&\n                    (p-chunk) < (ssize_t) (length-8))\n                  {\n                    MngPair\n                      new_pair;\n\n                    MngPair\n                      old_pair;\n\n                    old_pair.a=mng_info->x_off[i];\n                    old_pair.b=mng_info->y_off[i];\n                    new_pair=mng_read_pair(old_pair,(int) p[0],&p[1]);\n                    mng_info->x_off[i]=new_pair.a;\n                    mng_info->y_off[i]=new_pair.b;\n                  }\n              }\n            }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_LOOP,4) == 0)\n          {\n            ssize_t loop_iters=1;\n            if (length > 4)\n              {\n                loop_level=chunk[0];\n                mng_info->loop_active[loop_level]=1;  /* mark loop active */\n\n                /* Record starting point.  */\n                loop_iters=mng_get_long(&chunk[1]);\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  LOOP level %.20g has %.20g iterations \",\n                    (double) loop_level, (double) loop_iters);\n\n                if (loop_iters == 0)\n                  skipping_loop=loop_level;\n\n                else\n                  {\n                    mng_info->loop_jump[loop_level]=TellBlob(image);\n                    mng_info->loop_count[loop_level]=loop_iters;\n                  }\n\n                mng_info->loop_iteration[loop_level]=0;\n              }\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_ENDL,4) == 0)\n          {\n            if (length > 0)\n              {\n                loop_level=chunk[0];\n\n                if (skipping_loop > 0)\n                  {\n                    if (skipping_loop == loop_level)\n                      {\n                        /*\n                          Found end of zero-iteration loop.\n                        */\n                        skipping_loop=(-1);\n                        mng_info->loop_active[loop_level]=0;\n                      }\n                  }\n\n                else\n                  {\n                    if (mng_info->loop_active[loop_level] == 1)\n                      {\n                        mng_info->loop_count[loop_level]--;\n                        mng_info->loop_iteration[loop_level]++;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                          \"  ENDL: LOOP level %.20g has %.20g remaining iters \",\n                            (double) loop_level,(double)\n                            mng_info->loop_count[loop_level]);\n\n                        if (mng_info->loop_count[loop_level] != 0)\n                          {\n                            offset=SeekBlob(image,\n                              mng_info->loop_jump[loop_level], SEEK_SET);\n\n                            if (offset < 0)\n                              {\n                                chunk=(unsigned char *) RelinquishMagickMemory(\n                                  chunk);\n                                ThrowReaderException(CorruptImageError,\n                                  \"ImproperImageHeader\");\n                              }\n                          }\n\n                        else\n                          {\n                            short\n                              last_level;\n\n                            /*\n                              Finished loop.\n                            */\n                            mng_info->loop_active[loop_level]=0;\n                            last_level=(-1);\n                            for (i=0; i < loop_level; i++)\n                              if (mng_info->loop_active[i] == 1)\n                                last_level=(short) i;\n                            loop_level=last_level;\n                          }\n                      }\n                  }\n              }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_CLON,4) == 0)\n          {\n            if (mng_info->clon_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"CLON is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->clon_warning++;\n          }\n\n        if (memcmp(type,mng_MAGN,4) == 0)\n          {\n            png_uint_16\n              magn_first,\n              magn_last,\n              magn_mb,\n              magn_ml,\n              magn_mr,\n              magn_mt,\n              magn_mx,\n              magn_my,\n              magn_methx,\n              magn_methy;\n\n            if (length > 1)\n              magn_first=(p[0] << 8) | p[1];\n\n            else\n              magn_first=0;\n\n            if (length > 3)\n              magn_last=(p[2] << 8) | p[3];\n\n            else\n              magn_last=magn_first;\n#ifndef MNG_OBJECT_BUFFERS\n            if (magn_first || magn_last)\n              if (mng_info->magn_warning == 0)\n                {\n                  (void) ThrowMagickException(&image->exception,\n                     GetMagickModule(),CoderError,\n                     \"MAGN is not implemented yet for nonzero objects\",\n                     \"`%s'\",image->filename);\n\n                   mng_info->magn_warning++;\n                }\n#endif\n            if (length > 4)\n              magn_methx=p[4];\n\n            else\n              magn_methx=0;\n\n            if (length > 6)\n              magn_mx=(p[5] << 8) | p[6];\n\n            else\n              magn_mx=1;\n\n            if (magn_mx == 0)\n              magn_mx=1;\n\n            if (length > 8)\n              magn_my=(p[7] << 8) | p[8];\n\n            else\n              magn_my=magn_mx;\n\n            if (magn_my == 0)\n              magn_my=1;\n\n            if (length > 10)\n              magn_ml=(p[9] << 8) | p[10];\n\n            else\n              magn_ml=magn_mx;\n\n            if (magn_ml == 0)\n              magn_ml=1;\n\n            if (length > 12)\n              magn_mr=(p[11] << 8) | p[12];\n\n            else\n              magn_mr=magn_mx;\n\n            if (magn_mr == 0)\n              magn_mr=1;\n\n            if (length > 14)\n              magn_mt=(p[13] << 8) | p[14];\n\n            else\n              magn_mt=magn_my;\n\n            if (magn_mt == 0)\n              magn_mt=1;\n\n            if (length > 16)\n              magn_mb=(p[15] << 8) | p[16];\n\n            else\n              magn_mb=magn_my;\n\n            if (magn_mb == 0)\n              magn_mb=1;\n\n            if (length > 17)\n              magn_methy=p[17];\n\n            else\n              magn_methy=magn_methx;\n\n\n            if (magn_methx > 5 || magn_methy > 5)\n              if (mng_info->magn_warning == 0)\n                {\n                  (void) ThrowMagickException(&image->exception,\n                     GetMagickModule(),CoderError,\n                     \"Unknown MAGN method in MNG datastream\",\"`%s'\",\n                     image->filename);\n\n                   mng_info->magn_warning++;\n                }\n#ifdef MNG_OBJECT_BUFFERS\n          /* Magnify existing objects in the range magn_first to magn_last */\n#endif\n            if (magn_first == 0 || magn_last == 0)\n              {\n                /* Save the magnification factors for object 0 */\n                mng_info->magn_mb=magn_mb;\n                mng_info->magn_ml=magn_ml;\n                mng_info->magn_mr=magn_mr;\n                mng_info->magn_mt=magn_mt;\n                mng_info->magn_mx=magn_mx;\n                mng_info->magn_my=magn_my;\n                mng_info->magn_methx=magn_methx;\n                mng_info->magn_methy=magn_methy;\n              }\n          }\n\n        if (memcmp(type,mng_PAST,4) == 0)\n          {\n            if (mng_info->past_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"PAST is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->past_warning++;\n          }\n\n        if (memcmp(type,mng_SHOW,4) == 0)\n          {\n            if (mng_info->show_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"SHOW is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->show_warning++;\n          }\n\n        if (memcmp(type,mng_sBIT,4) == 0)\n          {\n            if (length < 4)\n              mng_info->have_global_sbit=MagickFalse;\n\n            else\n              {\n                mng_info->global_sbit.gray=p[0];\n                mng_info->global_sbit.red=p[0];\n                mng_info->global_sbit.green=p[1];\n                mng_info->global_sbit.blue=p[2];\n                mng_info->global_sbit.alpha=p[3];\n                mng_info->have_global_sbit=MagickTrue;\n             }\n          }\n        if (memcmp(type,mng_pHYs,4) == 0)\n          {\n            if (length > 8)\n              {\n                mng_info->global_x_pixels_per_unit=\n                    (size_t) mng_get_long(p);\n                mng_info->global_y_pixels_per_unit=\n                    (size_t) mng_get_long(&p[4]);\n                mng_info->global_phys_unit_type=p[8];\n                mng_info->have_global_phys=MagickTrue;\n              }\n\n            else\n              mng_info->have_global_phys=MagickFalse;\n          }\n        if (memcmp(type,mng_pHYg,4) == 0)\n          {\n            if (mng_info->phyg_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"pHYg is not implemented.\",\"`%s'\",image->filename);\n\n            mng_info->phyg_warning++;\n          }\n        if (memcmp(type,mng_BASI,4) == 0)\n          {\n            skip_to_iend=MagickTrue;\n\n            if (mng_info->basi_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"BASI is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->basi_warning++;\n#ifdef MNG_BASI_SUPPORTED\n            if (length > 11)\n              {\n                basi_width=(size_t) ((p[0] << 24) | (p[1] << 16) |\n                   (p[2] << 8) | p[3]);\n                basi_height=(size_t) ((p[4] << 24) | (p[5] << 16) |\n                   (p[6] << 8) | p[7]);\n                basi_color_type=p[8];\n                basi_compression_method=p[9];\n                basi_filter_type=p[10];\n                basi_interlace_method=p[11];\n              }\n            if (length > 13)\n              basi_red=(p[12] << 8) & p[13];\n\n            else\n              basi_red=0;\n\n            if (length > 15)\n              basi_green=(p[14] << 8) & p[15];\n\n            else\n              basi_green=0;\n\n            if (length > 17)\n              basi_blue=(p[16] << 8) & p[17];\n\n            else\n              basi_blue=0;\n\n            if (length > 19)\n              basi_alpha=(p[18] << 8) & p[19];\n\n            else\n              {\n                if (basi_sample_depth == 16)\n                  basi_alpha=65535L;\n                else\n                  basi_alpha=255;\n              }\n\n            if (length > 20)\n              basi_viewable=p[20];\n\n            else\n              basi_viewable=0;\n\n#endif\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_IHDR,4)\n#if defined(JNG_SUPPORTED)\n            && memcmp(type,mng_JHDR,4)\n#endif\n            )\n          {\n            /* Not an IHDR or JHDR chunk */\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n/* Process IHDR */\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  Processing %c%c%c%c chunk\",type[0],type[1],type[2],type[3]);\n\n        mng_info->exists[object_id]=MagickTrue;\n        mng_info->viewable[object_id]=MagickTrue;\n\n        if (mng_info->invisible[object_id])\n          {\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Skipping invisible object\");\n\n            skip_to_iend=MagickTrue;\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n#if defined(MNG_INSERT_LAYERS)\n        if (length < 8)\n          {\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n          }\n\n        image_width=(size_t) mng_get_long(p);\n        image_height=(size_t) mng_get_long(&p[4]);\n#endif\n        chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n        /*\n          Insert a transparent background layer behind the entire animation\n          if it is not full screen.\n        */\n#if defined(MNG_INSERT_LAYERS)\n        if (insert_layers && mng_type && first_mng_object)\n          {\n            if ((mng_info->clip.left > 0) || (mng_info->clip.top > 0) ||\n                (image_width < mng_info->mng_width) ||\n                (mng_info->clip.right < (ssize_t) mng_info->mng_width) ||\n                (image_height < mng_info->mng_height) ||\n                (mng_info->clip.bottom < (ssize_t) mng_info->mng_height))\n              {\n                if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n                  {\n                    /*\n                      Allocate next image structure.\n                    */\n                    AcquireNextImage(image_info,image);\n\n                    if (GetNextImageInList(image) == (Image *) NULL)\n                      return(DestroyImageList(image));\n\n                    image=SyncNextImageInList(image);\n                  }\n                mng_info->image=image;\n\n                if (term_chunk_found)\n                  {\n                    image->start_loop=MagickTrue;\n                    image->iterations=mng_iterations;\n                    term_chunk_found=MagickFalse;\n                  }\n\n                else\n                    image->start_loop=MagickFalse;\n\n                /* Make a background rectangle.  */\n\n                image->delay=0;\n                image->columns=mng_info->mng_width;\n                image->rows=mng_info->mng_height;\n                image->page.width=mng_info->mng_width;\n                image->page.height=mng_info->mng_height;\n                image->page.x=0;\n                image->page.y=0;\n                image->background_color=mng_background_color;\n                (void) SetImageBackgroundColor(image);\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  Inserted transparent background layer, W=%.20g, H=%.20g\",\n                    (double) mng_info->mng_width,(double) mng_info->mng_height);\n              }\n          }\n        /*\n          Insert a background layer behind the upcoming image if\n          framing_mode is 3, and we haven't already inserted one.\n        */\n        if (insert_layers && (mng_info->framing_mode == 3) &&\n                (subframe_width) && (subframe_height) && (simplicity == 0 ||\n                (simplicity & 0x08)))\n          {\n            if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n            {\n              /*\n                Allocate next image structure.\n              */\n              AcquireNextImage(image_info,image);\n\n              if (GetNextImageInList(image) == (Image *) NULL)\n                return(DestroyImageList(image));\n\n              image=SyncNextImageInList(image);\n            }\n\n            mng_info->image=image;\n\n            if (term_chunk_found)\n              {\n                image->start_loop=MagickTrue;\n                image->iterations=mng_iterations;\n                term_chunk_found=MagickFalse;\n              }\n\n            else\n                image->start_loop=MagickFalse;\n\n            image->delay=0;\n            image->columns=subframe_width;\n            image->rows=subframe_height;\n            image->page.width=subframe_width;\n            image->page.height=subframe_height;\n            image->page.x=mng_info->clip.left;\n            image->page.y=mng_info->clip.top;\n            image->background_color=mng_background_color;\n            image->matte=MagickFalse;\n            (void) SetImageBackgroundColor(image);\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Insert background layer, L=%.20g, R=%.20g T=%.20g, B=%.20g\",\n                (double) mng_info->clip.left,(double) mng_info->clip.right,\n                (double) mng_info->clip.top,(double) mng_info->clip.bottom);\n          }\n#endif /* MNG_INSERT_LAYERS */\n        first_mng_object=MagickFalse;\n\n        if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n          {\n            /*\n              Allocate next image structure.\n            */\n            AcquireNextImage(image_info,image);\n\n            if (GetNextImageInList(image) == (Image *) NULL)\n              return(DestroyImageList(image));\n\n            image=SyncNextImageInList(image);\n          }\n        mng_info->image=image;\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n\n        if (status == MagickFalse)\n          break;\n\n        if (term_chunk_found)\n          {\n            image->start_loop=MagickTrue;\n            term_chunk_found=MagickFalse;\n          }\n\n        else\n            image->start_loop=MagickFalse;\n\n        if (mng_info->framing_mode == 1 || mng_info->framing_mode == 3)\n          {\n            image->delay=frame_delay;\n            frame_delay=default_frame_delay;\n          }\n\n        else\n          image->delay=0;\n\n        image->page.width=mng_info->mng_width;\n        image->page.height=mng_info->mng_height;\n        image->page.x=mng_info->x_off[object_id];\n        image->page.y=mng_info->y_off[object_id];\n        image->iterations=mng_iterations;\n\n        /*\n          Seek back to the beginning of the IHDR or JHDR chunk's length field.\n        */\n\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  Seeking back to beginning of %c%c%c%c chunk\",type[0],type[1],\n            type[2],type[3]);\n\n        offset=SeekBlob(image,-((ssize_t) length+12),SEEK_CUR);\n\n        if (offset < 0)\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n      }\n\n    mng_info->image=image;\n    mng_info->mng_type=mng_type;\n    mng_info->object_id=object_id;\n\n    if (memcmp(type,mng_IHDR,4) == 0)\n      image=ReadOnePNGImage(mng_info,image_info,exception);\n\n#if defined(JNG_SUPPORTED)\n    else\n      image=ReadOneJNGImage(mng_info,image_info,exception);\n#endif\n\n    if (image == (Image *) NULL)\n      {\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"exit ReadJNGImage() with error\");\n\n        return((Image *) NULL);\n      }\n\n    if (image->columns == 0 || image->rows == 0)\n      {\n        (void) CloseBlob(image);\n        return(DestroyImageList(image));\n      }\n\n    mng_info->image=image;\n\n    if (mng_type)\n      {\n        MngBox\n          crop_box;\n\n        if (mng_info->magn_methx || mng_info->magn_methy)\n          {\n            png_uint_32\n               magnified_height,\n               magnified_width;\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Processing MNG MAGN chunk\");\n\n            if (mng_info->magn_methx == 1)\n              {\n                magnified_width=mng_info->magn_ml;\n\n                if (image->columns > 1)\n                   magnified_width += mng_info->magn_mr;\n\n                if (image->columns > 2)\n                   magnified_width += (png_uint_32)\n                      ((image->columns-2)*(mng_info->magn_mx));\n              }\n\n            else\n              {\n                magnified_width=(png_uint_32) image->columns;\n\n                if (image->columns > 1)\n                   magnified_width += mng_info->magn_ml-1;\n\n                if (image->columns > 2)\n                   magnified_width += mng_info->magn_mr-1;\n\n                if (image->columns > 3)\n                   magnified_width += (png_uint_32)\n                      ((image->columns-3)*(mng_info->magn_mx-1));\n              }\n\n            if (mng_info->magn_methy == 1)\n              {\n                magnified_height=mng_info->magn_mt;\n\n                if (image->rows > 1)\n                   magnified_height += mng_info->magn_mb;\n\n                if (image->rows > 2)\n                   magnified_height += (png_uint_32)\n                      ((image->rows-2)*(mng_info->magn_my));\n              }\n\n            else\n              {\n                magnified_height=(png_uint_32) image->rows;\n\n                if (image->rows > 1)\n                   magnified_height += mng_info->magn_mt-1;\n\n                if (image->rows > 2)\n                   magnified_height += mng_info->magn_mb-1;\n\n                if (image->rows > 3)\n                   magnified_height += (png_uint_32)\n                      ((image->rows-3)*(mng_info->magn_my-1));\n              }\n\n            if (magnified_height > image->rows ||\n                magnified_width > image->columns)\n              {\n                Image\n                  *large_image;\n\n                int\n                  yy;\n\n                ssize_t\n                  m,\n                  y;\n\n                register ssize_t\n                  x;\n\n                register PixelPacket\n                  *n,\n                  *q;\n\n                PixelPacket\n                  *next,\n                  *prev;\n\n                png_uint_16\n                  magn_methx,\n                  magn_methy;\n\n                /* Allocate next image structure.  */\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Allocate magnified image\");\n\n                AcquireNextImage(image_info,image);\n\n                if (GetNextImageInList(image) == (Image *) NULL)\n                  return(DestroyImageList(image));\n\n                large_image=SyncNextImageInList(image);\n\n                large_image->columns=magnified_width;\n                large_image->rows=magnified_height;\n\n                magn_methx=mng_info->magn_methx;\n                magn_methy=mng_info->magn_methy;\n\n#if (MAGICKCORE_QUANTUM_DEPTH > 16)\n#define QM unsigned short\n                if (magn_methx != 1 || magn_methy != 1)\n                  {\n                  /*\n                     Scale pixels to unsigned shorts to prevent\n                     overflow of intermediate values of interpolations\n                  */\n                     for (y=0; y < (ssize_t) image->rows; y++)\n                     {\n                       q=GetAuthenticPixels(image,0,y,image->columns,1,\n                          exception);\n\n                       for (x=(ssize_t) image->columns-1; x >= 0; x--)\n                       {\n                          SetPixelRed(q,ScaleQuantumToShort(\n                            GetPixelRed(q)));\n                          SetPixelGreen(q,ScaleQuantumToShort(\n                            GetPixelGreen(q)));\n                          SetPixelBlue(q,ScaleQuantumToShort(\n                            GetPixelBlue(q)));\n                          SetPixelOpacity(q,ScaleQuantumToShort(\n                            GetPixelOpacity(q)));\n                          q++;\n                       }\n\n                       if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                         break;\n                     }\n                  }\n#else\n#define QM Quantum\n#endif\n\n                if (image->matte != MagickFalse)\n                   (void) SetImageBackgroundColor(large_image);\n\n                else\n                  {\n                    large_image->background_color.opacity=OpaqueOpacity;\n                    (void) SetImageBackgroundColor(large_image);\n\n                    if (magn_methx == 4)\n                      magn_methx=2;\n\n                    if (magn_methx == 5)\n                      magn_methx=3;\n\n                    if (magn_methy == 4)\n                      magn_methy=2;\n\n                    if (magn_methy == 5)\n                      magn_methy=3;\n                  }\n\n                /* magnify the rows into the right side of the large image */\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Magnify the rows to %.20g\",(double) large_image->rows);\n                m=(ssize_t) mng_info->magn_mt;\n                yy=0;\n                length=(size_t) image->columns;\n                next=(PixelPacket *) AcquireQuantumMemory(length,sizeof(*next));\n                prev=(PixelPacket *) AcquireQuantumMemory(length,sizeof(*prev));\n\n                if ((prev == (PixelPacket *) NULL) ||\n                    (next == (PixelPacket *) NULL))\n                  {\n                     image=DestroyImageList(image);\n                     ThrowReaderException(ResourceLimitError,\n                       \"MemoryAllocationFailed\");\n                  }\n\n                n=GetAuthenticPixels(image,0,0,image->columns,1,exception);\n                (void) CopyMagickMemory(next,n,length);\n\n                for (y=0; y < (ssize_t) image->rows; y++)\n                {\n                  if (y == 0)\n                    m=(ssize_t) mng_info->magn_mt;\n\n                  else if (magn_methy > 1 && y == (ssize_t) image->rows-2)\n                    m=(ssize_t) mng_info->magn_mb;\n\n                  else if (magn_methy <= 1 && y == (ssize_t) image->rows-1)\n                    m=(ssize_t) mng_info->magn_mb;\n\n                  else if (magn_methy > 1 && y == (ssize_t) image->rows-1)\n                    m=1;\n\n                  else\n                    m=(ssize_t) mng_info->magn_my;\n\n                  n=prev;\n                  prev=next;\n                  next=n;\n\n                  if (y < (ssize_t) image->rows-1)\n                    {\n                      n=GetAuthenticPixels(image,0,y+1,image->columns,1,\n                          exception);\n                      (void) CopyMagickMemory(next,n,length);\n                    }\n\n                  for (i=0; i < m; i++, yy++)\n                  {\n                    register PixelPacket\n                      *pixels;\n\n                    assert(yy < (ssize_t) large_image->rows);\n                    pixels=prev;\n                    n=next;\n                    q=GetAuthenticPixels(large_image,0,yy,large_image->columns,\n                      1,exception);\n                    q+=(large_image->columns-image->columns);\n\n                    for (x=(ssize_t) image->columns-1; x >= 0; x--)\n                    {\n                      /* To do: get color as function of indexes[x] */\n                      /*\n                      if (image->storage_class == PseudoClass)\n                        {\n                        }\n                      */\n\n                      if (magn_methy <= 1)\n                        {\n                          /* replicate previous */\n                          SetPixelRGBO(q,(pixels));\n                        }\n\n                      else if (magn_methy == 2 || magn_methy == 4)\n                        {\n                          if (i == 0)\n                            {\n                              SetPixelRGBO(q,(pixels));\n                            }\n\n                          else\n                            {\n                              /* Interpolate */\n                              SetPixelRed(q,\n                                 ((QM) (((ssize_t)\n                                 (2*i*(GetPixelRed(n)\n                                 -GetPixelRed(pixels)+m))/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelRed(pixels)))));\n                              SetPixelGreen(q,\n                                 ((QM) (((ssize_t)\n                                 (2*i*(GetPixelGreen(n)\n                                 -GetPixelGreen(pixels)+m))/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelGreen(pixels)))));\n                              SetPixelBlue(q,\n                                 ((QM) (((ssize_t)\n                                 (2*i*(GetPixelBlue(n)\n                                 -GetPixelBlue(pixels)+m))/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelBlue(pixels)))));\n\n                              if (image->matte != MagickFalse)\n                                 SetPixelOpacity(q,\n                                    ((QM) (((ssize_t)\n                                    (2*i*(GetPixelOpacity(n)\n                                    -GetPixelOpacity(pixels)+m))\n                                    /((ssize_t) (m*2))+\n                                   GetPixelOpacity(pixels)))));\n                            }\n\n                          if (magn_methy == 4)\n                            {\n                              /* Replicate nearest */\n                              if (i <= ((m+1) << 1))\n                                 SetPixelOpacity(q,\n                                 (*pixels).opacity+0);\n                              else\n                                 SetPixelOpacity(q,\n                                 (*n).opacity+0);\n                            }\n                        }\n\n                      else /* if (magn_methy == 3 || magn_methy == 5) */\n                        {\n                          /* Replicate nearest */\n                          if (i <= ((m+1) << 1))\n                          {\n                             SetPixelRGBO(q,(pixels));\n                          }\n\n                          else\n                          {\n                             SetPixelRGBO(q,(n));\n                          }\n\n                          if (magn_methy == 5)\n                            {\n                              SetPixelOpacity(q,\n                                 (QM) (((ssize_t) (2*i*\n                                 (GetPixelOpacity(n)\n                                 -GetPixelOpacity(pixels))\n                                 +m))/((ssize_t) (m*2))\n                                 +GetPixelOpacity(pixels)));\n                            }\n                        }\n                      n++;\n                      q++;\n                      pixels++;\n                    } /* x */\n\n                    if (SyncAuthenticPixels(large_image,exception) == 0)\n                      break;\n\n                  } /* i */\n                } /* y */\n\n                prev=(PixelPacket *) RelinquishMagickMemory(prev);\n                next=(PixelPacket *) RelinquishMagickMemory(next);\n\n                length=image->columns;\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Delete original image\");\n\n                DeleteImageFromList(&image);\n\n                image=large_image;\n\n                mng_info->image=image;\n\n                /* magnify the columns */\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Magnify the columns to %.20g\",(double) image->columns);\n\n                for (y=0; y < (ssize_t) image->rows; y++)\n                {\n                  register PixelPacket\n                    *pixels;\n\n                  q=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n                  pixels=q+(image->columns-length);\n                  n=pixels+1;\n\n                  for (x=(ssize_t) (image->columns-length);\n                    x < (ssize_t) image->columns; x++)\n                  {\n                    /* To do: Rewrite using Get/Set***PixelComponent() */\n\n                    if (x == (ssize_t) (image->columns-length))\n                      m=(ssize_t) mng_info->magn_ml;\n\n                    else if (magn_methx > 1 && x == (ssize_t) image->columns-2)\n                      m=(ssize_t) mng_info->magn_mr;\n\n                    else if (magn_methx <= 1 && x == (ssize_t) image->columns-1)\n                      m=(ssize_t) mng_info->magn_mr;\n\n                    else if (magn_methx > 1 && x == (ssize_t) image->columns-1)\n                      m=1;\n\n                    else\n                      m=(ssize_t) mng_info->magn_mx;\n\n                    for (i=0; i < m; i++)\n                    {\n                      if (magn_methx <= 1)\n                        {\n                          /* replicate previous */\n                          SetPixelRGBO(q,(pixels));\n                        }\n\n                      else if (magn_methx == 2 || magn_methx == 4)\n                        {\n                          if (i == 0)\n                          {\n                             SetPixelRGBO(q,(pixels));\n                          }\n\n                          /* To do: Rewrite using Get/Set***PixelComponent() */\n                          else\n                            {\n                              /* Interpolate */\n                              SetPixelRed(q,\n                                 (QM) ((2*i*(\n                                 GetPixelRed(n)\n                                 -GetPixelRed(pixels))+m)\n                                 /((ssize_t) (m*2))+\n                                 GetPixelRed(pixels)));\n\n                              SetPixelGreen(q,\n                                 (QM) ((2*i*(\n                                 GetPixelGreen(n)\n                                 -GetPixelGreen(pixels))+m)\n                                 /((ssize_t) (m*2))+\n                                 GetPixelGreen(pixels)));\n\n                              SetPixelBlue(q,\n                                 (QM) ((2*i*(\n                                 GetPixelBlue(n)\n                                 -GetPixelBlue(pixels))+m)\n                                 /((ssize_t) (m*2))+\n                                 GetPixelBlue(pixels)));\n                              if (image->matte != MagickFalse)\n                                 SetPixelOpacity(q,\n                                   (QM) ((2*i*(\n                                   GetPixelOpacity(n)\n                                   -GetPixelOpacity(pixels))+m)\n                                   /((ssize_t) (m*2))+\n                                   GetPixelOpacity(pixels)));\n                            }\n\n                          if (magn_methx == 4)\n                            {\n                              /* Replicate nearest */\n                              if (i <= ((m+1) << 1))\n                              {\n                                 SetPixelOpacity(q,\n                                 GetPixelOpacity(pixels)+0);\n                              }\n                              else\n                              {\n                                 SetPixelOpacity(q,\n                                 GetPixelOpacity(n)+0);\n                              }\n                            }\n                        }\n\n                      else /* if (magn_methx == 3 || magn_methx == 5) */\n                        {\n                          /* Replicate nearest */\n                          if (i <= ((m+1) << 1))\n                          {\n                             SetPixelRGBO(q,(pixels));\n                          }\n\n                          else\n                          {\n                             SetPixelRGBO(q,(n));\n                          }\n\n                          if (magn_methx == 5)\n                            {\n                              /* Interpolate */\n                              SetPixelOpacity(q,\n                                 (QM) ((2*i*( GetPixelOpacity(n)\n                                 -GetPixelOpacity(pixels))+m)/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelOpacity(pixels)));\n                            }\n                        }\n                      q++;\n                    }\n                    n++;\n                  }\n\n                  if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                    break;\n                }\n#if (MAGICKCORE_QUANTUM_DEPTH > 16)\n              if (magn_methx != 1 || magn_methy != 1)\n                {\n                /*\n                   Rescale pixels to Quantum\n                */\n                   for (y=0; y < (ssize_t) image->rows; y++)\n                   {\n                     q=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n\n                     for (x=(ssize_t) image->columns-1; x >= 0; x--)\n                     {\n                        SetPixelRed(q,ScaleShortToQuantum(\n                            GetPixelRed(q)));\n                        SetPixelGreen(q,ScaleShortToQuantum(\n                            GetPixelGreen(q)));\n                        SetPixelBlue(q,ScaleShortToQuantum(\n                            GetPixelBlue(q)));\n                        SetPixelOpacity(q,ScaleShortToQuantum(\n                            GetPixelOpacity(q)));\n                        q++;\n                     }\n\n                     if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                       break;\n                   }\n                }\n#endif\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  Finished MAGN processing\");\n              }\n          }\n\n        /*\n          Crop_box is with respect to the upper left corner of the MNG.\n        */\n        crop_box.left=mng_info->image_box.left+mng_info->x_off[object_id];\n        crop_box.right=mng_info->image_box.right+mng_info->x_off[object_id];\n        crop_box.top=mng_info->image_box.top+mng_info->y_off[object_id];\n        crop_box.bottom=mng_info->image_box.bottom+mng_info->y_off[object_id];\n        crop_box=mng_minimum_box(crop_box,mng_info->clip);\n        crop_box=mng_minimum_box(crop_box,mng_info->frame);\n        crop_box=mng_minimum_box(crop_box,mng_info->object_clip[object_id]);\n        if ((crop_box.left != (mng_info->image_box.left\n            +mng_info->x_off[object_id])) ||\n            (crop_box.right != (mng_info->image_box.right\n            +mng_info->x_off[object_id])) ||\n            (crop_box.top != (mng_info->image_box.top\n            +mng_info->y_off[object_id])) ||\n            (crop_box.bottom != (mng_info->image_box.bottom\n            +mng_info->y_off[object_id])))\n          {\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Crop the PNG image\");\n\n            if ((crop_box.left < crop_box.right) &&\n                (crop_box.top < crop_box.bottom))\n              {\n                Image\n                  *im;\n\n                RectangleInfo\n                  crop_info;\n\n                /*\n                  Crop_info is with respect to the upper left corner of\n                  the image.\n                */\n                crop_info.x=(crop_box.left-mng_info->x_off[object_id]);\n                crop_info.y=(crop_box.top-mng_info->y_off[object_id]);\n                crop_info.width=(size_t) (crop_box.right-crop_box.left);\n                crop_info.height=(size_t) (crop_box.bottom-crop_box.top);\n                image->page.width=image->columns;\n                image->page.height=image->rows;\n                image->page.x=0;\n                image->page.y=0;\n                im=CropImage(image,&crop_info,exception);\n\n                if (im != (Image *) NULL)\n                  {\n                    image->columns=im->columns;\n                    image->rows=im->rows;\n                    im=DestroyImage(im);\n                    image->page.width=image->columns;\n                    image->page.height=image->rows;\n                    image->page.x=crop_box.left;\n                    image->page.y=crop_box.top;\n                  }\n              }\n\n            else\n              {\n                /*\n                  No pixels in crop area.  The MNG spec still requires\n                  a layer, though, so make a single transparent pixel in\n                  the top left corner.\n                */\n                image->columns=1;\n                image->rows=1;\n                image->colors=2;\n                (void) SetImageBackgroundColor(image);\n                image->page.width=1;\n                image->page.height=1;\n                image->page.x=0;\n                image->page.y=0;\n              }\n          }\n#ifndef PNG_READ_EMPTY_PLTE_SUPPORTED\n        image=mng_info->image;\n#endif\n      }\n\n#if (MAGICKCORE_QUANTUM_DEPTH > 16)\n      /* PNG does not handle depths greater than 16 so reduce it even\n       * if lossy, and promote any depths > 8 to 16.\n       */\n      if (image->depth > 16)\n         image->depth=16;\n#endif\n\n#if (MAGICKCORE_QUANTUM_DEPTH > 8)\n      if (image->depth > 8)\n        {\n          /* To do: fill low byte properly */\n          image->depth=16;\n        }\n\n      if (LosslessReduceDepthOK(image) != MagickFalse)\n         image->depth = 8;\n#endif\n\n      GetImageException(image,exception);\n\n      if (image_info->number_scenes != 0)\n        {\n          if (mng_info->scenes_found >\n             (ssize_t) (image_info->first_scene+image_info->number_scenes))\n            break;\n        }\n\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  Finished reading image datastream.\");\n\n  } while (LocaleCompare(image_info->magick,\"MNG\") == 0);\n\n  (void) CloseBlob(image);\n\n  if (logging != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  Finished reading all image datastreams.\");\n\n#if defined(MNG_INSERT_LAYERS)\n  if (insert_layers && !mng_info->image_found && (mng_info->mng_width) &&\n       (mng_info->mng_height))\n    {\n      /*\n        Insert a background layer if nothing else was found.\n      */\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  No images found.  Inserting a background layer.\");\n\n      if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n        {\n          /*\n            Allocate next image structure.\n          */\n          AcquireNextImage(image_info,image);\n          if (GetNextImageInList(image) == (Image *) NULL)\n            {\n              if (logging != MagickFalse)\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"  Allocation failed, returning NULL.\");\n\n              return(DestroyImageList(image));\n            }\n          image=SyncNextImageInList(image);\n        }\n      image->columns=mng_info->mng_width;\n      image->rows=mng_info->mng_height;\n      image->page.width=mng_info->mng_width;\n      image->page.height=mng_info->mng_height;\n      image->page.x=0;\n      image->page.y=0;\n      image->background_color=mng_background_color;\n      image->matte=MagickFalse;\n\n      if (image_info->ping == MagickFalse)\n        (void) SetImageBackgroundColor(image);\n\n      mng_info->image_found++;\n    }\n#endif\n  image->iterations=mng_iterations;\n\n  if (mng_iterations == 1)\n    image->start_loop=MagickTrue;\n\n  while (GetPreviousImageInList(image) != (Image *) NULL)\n  {\n    image_count++;\n    if (image_count > 10*mng_info->image_found)\n      {\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"  No beginning\");\n\n        (void) ThrowMagickException(&image->exception,GetMagickModule(),\n          CoderError,\"Linked list is corrupted, beginning of list not found\",\n          \"`%s'\",image_info->filename);\n\n        return(DestroyImageList(image));\n      }\n\n    image=GetPreviousImageInList(image);\n\n    if (GetNextImageInList(image) == (Image *) NULL)\n      {\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"  Corrupt list\");\n\n        (void) ThrowMagickException(&image->exception,GetMagickModule(),\n          CoderError,\"Linked list is corrupted; next_image is NULL\",\"`%s'\",\n          image_info->filename);\n      }\n  }\n\n  if (mng_info->ticks_per_second && mng_info->image_found > 1 &&\n             GetNextImageInList(image) ==\n     (Image *) NULL)\n    {\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  First image null\");\n\n      (void) ThrowMagickException(&image->exception,GetMagickModule(),\n        CoderError,\"image->next for first image is NULL but shouldn't be.\",\n        \"`%s'\",image_info->filename);\n    }\n\n  if (mng_info->image_found == 0)\n    {\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  No visible images found.\");\n\n      (void) ThrowMagickException(&image->exception,GetMagickModule(),\n        CoderError,\"No visible images in file\",\"`%s'\",image_info->filename);\n\n      return(DestroyImageList(image));\n    }\n\n  if (mng_info->ticks_per_second)\n    final_delay=1UL*MagickMax(image->ticks_per_second,1L)*\n            final_delay/mng_info->ticks_per_second;\n\n  else\n    image->start_loop=MagickTrue;\n\n  /* Find final nonzero image delay */\n  final_image_delay=0;\n\n  while (GetNextImageInList(image) != (Image *) NULL)\n    {\n      if (image->delay)\n        final_image_delay=image->delay;\n\n      image=GetNextImageInList(image);\n    }\n\n  if (final_delay < final_image_delay)\n    final_delay=final_image_delay;\n\n  image->delay=final_delay;\n\n  if (logging != MagickFalse)\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  image->delay=%.20g, final_delay=%.20g\",(double) image->delay,\n        (double) final_delay);\n\n  if (logging != MagickFalse)\n    {\n      int\n        scene;\n\n      scene=0;\n      image=GetFirstImageInList(image);\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  Before coalesce:\");\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    scene 0 delay=%.20g\",(double) image->delay);\n\n      while (GetNextImageInList(image) != (Image *) NULL)\n      {\n        image=GetNextImageInList(image);\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"    scene %.20g delay=%.20g\",(double) scene++,(double) image->delay);\n      }\n    }\n\n  image=GetFirstImageInList(image);\n#ifdef MNG_COALESCE_LAYERS\n  if (insert_layers)\n    {\n      Image\n        *next_image,\n        *next;\n\n      size_t\n        scene;\n\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"  Coalesce Images\");\n\n      scene=image->scene;\n      next_image=CoalesceImages(image,&image->exception);\n\n      if (next_image == (Image *) NULL)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n      image=DestroyImageList(image);\n      image=next_image;\n\n      for (next=image; next != (Image *) NULL; next=next_image)\n      {\n         next->page.width=mng_info->mng_width;\n         next->page.height=mng_info->mng_height;\n         next->page.x=0;\n         next->page.y=0;\n         next->scene=scene++;\n         next_image=GetNextImageInList(next);\n\n         if (next_image == (Image *) NULL)\n           break;\n\n         if (next->delay == 0)\n           {\n             scene--;\n             next_image->previous=GetPreviousImageInList(next);\n             if (GetPreviousImageInList(next) == (Image *) NULL)\n               image=next_image;\n             else\n               next->previous->next=next_image;\n             next=DestroyImage(next);\n           }\n      }\n    }\n#endif\n\n  while (GetNextImageInList(image) != (Image *) NULL)\n      image=GetNextImageInList(image);\n\n  image->dispose=BackgroundDispose;\n\n  if (logging != MagickFalse)\n    {\n      int\n        scene;\n\n      scene=0;\n      image=GetFirstImageInList(image);\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  After coalesce:\");\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    scene 0 delay=%.20g dispose=%.20g\",(double) image->delay,\n        (double) image->dispose);\n\n      while (GetNextImageInList(image) != (Image *) NULL)\n      {\n        image=GetNextImageInList(image);\n\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"    scene %.20g delay=%.20g dispose=%.20g\",(double) scene++,\n          (double) image->delay,(double) image->dispose);\n      }\n   }\n\n  if (logging != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  exit ReadOneJNGImage();\");\n\n  return(image);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/78d4c5db50fbab0b4beb69c46c6167f2c6513dec", "file_name": "coders/png.c", "vul_type": "cwe-125", "description": "Read a single image from a MNG datastream in C."}
{"func_name": "add_item", "func_src_before": "    def add_item(self, item):\n        \"\"\"\"Add new item.\"\"\"\n        if self.connection:\n            self.cursor.execute('insert into item (name, shoppinglistid) values (\"%s\", \"%s\")' % (item[0], item[1]))\n            self.connection.commit()", "func_src_after": "    def add_item(self, item):\n        \"\"\"\"Add new item.\"\"\"\n        if self.connection:\n            t = (item[0], item[1], )\n            self.cursor.execute('insert into item (name, shoppinglistid) values (?, ?)', t)\n            self.connection.commit()", "commit_link": "github.com/ecosl-developers/ecosl/commit/8af050a513338bf68ff2a243e4a2482d24e9aa3a", "file_name": "ecosldb/ecosldb.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a new item into a database table using SQL queries."}
{"func_name": "on_save", "func_src_before": "    def on_save(self):\n        connection = get_connection()\n        cursor = connection.cursor()\n        cursor.execute(\n            f\"insert into visitors (ip_address, user_agent, referrer, full_path, visit_time) values ('{self.ip_address}', '{self.user_agent}', '{self.referrer}', '{self.full_path}', '{self.visit_time}');\")\n        connection.commit()\n        connection.close()\n        return 0", "func_src_after": "    def on_save(self):\n        connection = get_connection()\n        cursor = connection.cursor()\n        cursor.execute(\n            \"insert into visitors (ip_address, user_agent, referrer, full_path, visit_time) values (%s, %s, %s, %s, %s);\",\n            (str(self.ip_address), str(self.user_agent), str(self.referrer), str(self.full_path), self.visit_time))\n        connection.commit()\n        connection.close()\n        return 0", "commit_link": "github.com/onewyoming/onewyoming/commit/54fc7b076fda2de74eeb55e6b75b28e09ef231c2", "file_name": "experimental/python/buford/model/visitor.py", "vul_type": "cwe-089", "description": "Write a Python function to save a visitor's details to a database using SQL insert query."}
{"func_name": "get_queryset", "func_src_before": "    def get_queryset(self, **kwargs):\n        queryset = Article.objects.order_by('-time')\n        for i in queryset:\n            i.md = markdown(i.content, extensions=[\n                'markdown.extensions.extra',\n                'markdown.extensions.codehilite',\n                'markdown.extensions.toc',\n            ])\n\n        return queryset", "func_src_after": "    def get_queryset(self, **kwargs):\n        queryset = Article.objects.order_by('-time')\n        for i in queryset:\n            i.md = safe_md(i.content)\n\n        return queryset", "commit_link": "github.com/Cheng-mq1216/production-practice/commit/333dc34f5feada55d1f6ff1255949ca00dec0f9c", "file_name": "app/Index/views.py", "vul_type": "cwe-079", "description": "Write a Python function named `get_queryset` that orders articles by time and converts their content to markdown format."}
{"func_name": "x86_decode_insn", "func_src_before": "int x86_decode_insn(struct x86_emulate_ctxt *ctxt, void *insn, int insn_len)\n{\n\tint rc = X86EMUL_CONTINUE;\n\tint mode = ctxt->mode;\n\tint def_op_bytes, def_ad_bytes, goffset, simd_prefix;\n\tbool op_prefix = false;\n\tbool has_seg_override = false;\n\tstruct opcode opcode;\n\n\tctxt->memop.type = OP_NONE;\n\tctxt->memopp = NULL;\n\tctxt->_eip = ctxt->eip;\n\tctxt->fetch.ptr = ctxt->fetch.data;\n\tctxt->fetch.end = ctxt->fetch.data + insn_len;\n\tctxt->opcode_len = 1;\n\tif (insn_len > 0)\n\t\tmemcpy(ctxt->fetch.data, insn, insn_len);\n\telse {\n\t\trc = __do_insn_fetch_bytes(ctxt, 1);\n\t\tif (rc != X86EMUL_CONTINUE)\n\t\t\treturn rc;\n\t}\n\n\tswitch (mode) {\n\tcase X86EMUL_MODE_REAL:\n\tcase X86EMUL_MODE_VM86:\n\tcase X86EMUL_MODE_PROT16:\n\t\tdef_op_bytes = def_ad_bytes = 2;\n\t\tbreak;\n\tcase X86EMUL_MODE_PROT32:\n\t\tdef_op_bytes = def_ad_bytes = 4;\n\t\tbreak;\n#ifdef CONFIG_X86_64\n\tcase X86EMUL_MODE_PROT64:\n\t\tdef_op_bytes = 4;\n\t\tdef_ad_bytes = 8;\n\t\tbreak;\n#endif\n\tdefault:\n\t\treturn EMULATION_FAILED;\n\t}\n\n\tctxt->op_bytes = def_op_bytes;\n\tctxt->ad_bytes = def_ad_bytes;\n\n\t/* Legacy prefixes. */\n\tfor (;;) {\n\t\tswitch (ctxt->b = insn_fetch(u8, ctxt)) {\n\t\tcase 0x66:\t/* operand-size override */\n\t\t\top_prefix = true;\n\t\t\t/* switch between 2/4 bytes */\n\t\t\tctxt->op_bytes = def_op_bytes ^ 6;\n\t\t\tbreak;\n\t\tcase 0x67:\t/* address-size override */\n\t\t\tif (mode == X86EMUL_MODE_PROT64)\n\t\t\t\t/* switch between 4/8 bytes */\n\t\t\t\tctxt->ad_bytes = def_ad_bytes ^ 12;\n\t\t\telse\n\t\t\t\t/* switch between 2/4 bytes */\n\t\t\t\tctxt->ad_bytes = def_ad_bytes ^ 6;\n\t\t\tbreak;\n\t\tcase 0x26:\t/* ES override */\n\t\tcase 0x2e:\t/* CS override */\n\t\tcase 0x36:\t/* SS override */\n\t\tcase 0x3e:\t/* DS override */\n\t\t\thas_seg_override = true;\n\t\t\tctxt->seg_override = (ctxt->b >> 3) & 3;\n\t\t\tbreak;\n\t\tcase 0x64:\t/* FS override */\n\t\tcase 0x65:\t/* GS override */\n\t\t\thas_seg_override = true;\n\t\t\tctxt->seg_override = ctxt->b & 7;\n\t\t\tbreak;\n\t\tcase 0x40 ... 0x4f: /* REX */\n\t\t\tif (mode != X86EMUL_MODE_PROT64)\n\t\t\t\tgoto done_prefixes;\n\t\t\tctxt->rex_prefix = ctxt->b;\n\t\t\tcontinue;\n\t\tcase 0xf0:\t/* LOCK */\n\t\t\tctxt->lock_prefix = 1;\n\t\t\tbreak;\n\t\tcase 0xf2:\t/* REPNE/REPNZ */\n\t\tcase 0xf3:\t/* REP/REPE/REPZ */\n\t\t\tctxt->rep_prefix = ctxt->b;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tgoto done_prefixes;\n\t\t}\n\n\t\t/* Any legacy prefix after a REX prefix nullifies its effect. */\n\n\t\tctxt->rex_prefix = 0;\n\t}\n\ndone_prefixes:\n\n\t/* REX prefix. */\n\tif (ctxt->rex_prefix & 8)\n\t\tctxt->op_bytes = 8;\t/* REX.W */\n\n\t/* Opcode byte(s). */\n\topcode = opcode_table[ctxt->b];\n\t/* Two-byte opcode? */\n\tif (ctxt->b == 0x0f) {\n\t\tctxt->opcode_len = 2;\n\t\tctxt->b = insn_fetch(u8, ctxt);\n\t\topcode = twobyte_table[ctxt->b];\n\n\t\t/* 0F_38 opcode map */\n\t\tif (ctxt->b == 0x38) {\n\t\t\tctxt->opcode_len = 3;\n\t\t\tctxt->b = insn_fetch(u8, ctxt);\n\t\t\topcode = opcode_map_0f_38[ctxt->b];\n\t\t}\n\t}\n\tctxt->d = opcode.flags;\n\n\tif (ctxt->d & ModRM)\n\t\tctxt->modrm = insn_fetch(u8, ctxt);\n\n\t/* vex-prefix instructions are not implemented */\n\tif (ctxt->opcode_len == 1 && (ctxt->b == 0xc5 || ctxt->b == 0xc4) &&\n\t    (mode == X86EMUL_MODE_PROT64 || (ctxt->modrm & 0xc0) == 0xc0)) {\n\t\tctxt->d = NotImpl;\n\t}\n\n\twhile (ctxt->d & GroupMask) {\n\t\tswitch (ctxt->d & GroupMask) {\n\t\tcase Group:\n\t\t\tgoffset = (ctxt->modrm >> 3) & 7;\n\t\t\topcode = opcode.u.group[goffset];\n\t\t\tbreak;\n\t\tcase GroupDual:\n\t\t\tgoffset = (ctxt->modrm >> 3) & 7;\n\t\t\tif ((ctxt->modrm >> 6) == 3)\n\t\t\t\topcode = opcode.u.gdual->mod3[goffset];\n\t\t\telse\n\t\t\t\topcode = opcode.u.gdual->mod012[goffset];\n\t\t\tbreak;\n\t\tcase RMExt:\n\t\t\tgoffset = ctxt->modrm & 7;\n\t\t\topcode = opcode.u.group[goffset];\n\t\t\tbreak;\n\t\tcase Prefix:\n\t\t\tif (ctxt->rep_prefix && op_prefix)\n\t\t\t\treturn EMULATION_FAILED;\n\t\t\tsimd_prefix = op_prefix ? 0x66 : ctxt->rep_prefix;\n\t\t\tswitch (simd_prefix) {\n\t\t\tcase 0x00: opcode = opcode.u.gprefix->pfx_no; break;\n\t\t\tcase 0x66: opcode = opcode.u.gprefix->pfx_66; break;\n\t\t\tcase 0xf2: opcode = opcode.u.gprefix->pfx_f2; break;\n\t\t\tcase 0xf3: opcode = opcode.u.gprefix->pfx_f3; break;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase Escape:\n\t\t\tif (ctxt->modrm > 0xbf)\n\t\t\t\topcode = opcode.u.esc->high[ctxt->modrm - 0xc0];\n\t\t\telse\n\t\t\t\topcode = opcode.u.esc->op[(ctxt->modrm >> 3) & 7];\n\t\t\tbreak;\n\t\tcase InstrDual:\n\t\t\tif ((ctxt->modrm >> 6) == 3)\n\t\t\t\topcode = opcode.u.idual->mod3;\n\t\t\telse\n\t\t\t\topcode = opcode.u.idual->mod012;\n\t\t\tbreak;\n\t\tcase ModeDual:\n\t\t\tif (ctxt->mode == X86EMUL_MODE_PROT64)\n\t\t\t\topcode = opcode.u.mdual->mode64;\n\t\t\telse\n\t\t\t\topcode = opcode.u.mdual->mode32;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn EMULATION_FAILED;\n\t\t}\n\n\t\tctxt->d &= ~(u64)GroupMask;\n\t\tctxt->d |= opcode.flags;\n\t}\n\n\t/* Unrecognised? */\n\tif (ctxt->d == 0)\n\t\treturn EMULATION_FAILED;\n\n\tctxt->execute = opcode.u.execute;\n\n\tif (unlikely(ctxt->ud) && likely(!(ctxt->d & EmulateOnUD)))\n\t\treturn EMULATION_FAILED;\n\n\tif (unlikely(ctxt->d &\n\t    (NotImpl|Stack|Op3264|Sse|Mmx|Intercept|CheckPerm|NearBranch|\n\t     No16))) {\n\t\t/*\n\t\t * These are copied unconditionally here, and checked unconditionally\n\t\t * in x86_emulate_insn.\n\t\t */\n\t\tctxt->check_perm = opcode.check_perm;\n\t\tctxt->intercept = opcode.intercept;\n\n\t\tif (ctxt->d & NotImpl)\n\t\t\treturn EMULATION_FAILED;\n\n\t\tif (mode == X86EMUL_MODE_PROT64) {\n\t\t\tif (ctxt->op_bytes == 4 && (ctxt->d & Stack))\n\t\t\t\tctxt->op_bytes = 8;\n\t\t\telse if (ctxt->d & NearBranch)\n\t\t\t\tctxt->op_bytes = 8;\n\t\t}\n\n\t\tif (ctxt->d & Op3264) {\n\t\t\tif (mode == X86EMUL_MODE_PROT64)\n\t\t\t\tctxt->op_bytes = 8;\n\t\t\telse\n\t\t\t\tctxt->op_bytes = 4;\n\t\t}\n\n\t\tif ((ctxt->d & No16) && ctxt->op_bytes == 2)\n\t\t\tctxt->op_bytes = 4;\n\n\t\tif (ctxt->d & Sse)\n\t\t\tctxt->op_bytes = 16;\n\t\telse if (ctxt->d & Mmx)\n\t\t\tctxt->op_bytes = 8;\n\t}\n\n\t/* ModRM and SIB bytes. */\n\tif (ctxt->d & ModRM) {\n\t\trc = decode_modrm(ctxt, &ctxt->memop);\n\t\tif (!has_seg_override) {\n\t\t\thas_seg_override = true;\n\t\t\tctxt->seg_override = ctxt->modrm_seg;\n\t\t}\n\t} else if (ctxt->d & MemAbs)\n\t\trc = decode_abs(ctxt, &ctxt->memop);\n\tif (rc != X86EMUL_CONTINUE)\n\t\tgoto done;\n\n\tif (!has_seg_override)\n\t\tctxt->seg_override = VCPU_SREG_DS;\n\n\tctxt->memop.addr.mem.seg = ctxt->seg_override;\n\n\t/*\n\t * Decode and fetch the source operand: register, memory\n\t * or immediate.\n\t */\n\trc = decode_operand(ctxt, &ctxt->src, (ctxt->d >> SrcShift) & OpMask);\n\tif (rc != X86EMUL_CONTINUE)\n\t\tgoto done;\n\n\t/*\n\t * Decode and fetch the second source operand: register, memory\n\t * or immediate.\n\t */\n\trc = decode_operand(ctxt, &ctxt->src2, (ctxt->d >> Src2Shift) & OpMask);\n\tif (rc != X86EMUL_CONTINUE)\n\t\tgoto done;\n\n\t/* Decode and fetch the destination operand: register or memory. */\n\trc = decode_operand(ctxt, &ctxt->dst, (ctxt->d >> DstShift) & OpMask);\n\n\tif (ctxt->rip_relative)\n\t\tctxt->memopp->addr.mem.ea = address_mask(ctxt,\n\t\t\t\t\tctxt->memopp->addr.mem.ea + ctxt->_eip);\n\ndone:\n\treturn (rc != X86EMUL_CONTINUE) ? EMULATION_FAILED : EMULATION_OK;\n}", "func_src_after": "int x86_decode_insn(struct x86_emulate_ctxt *ctxt, void *insn, int insn_len)\n{\n\tint rc = X86EMUL_CONTINUE;\n\tint mode = ctxt->mode;\n\tint def_op_bytes, def_ad_bytes, goffset, simd_prefix;\n\tbool op_prefix = false;\n\tbool has_seg_override = false;\n\tstruct opcode opcode;\n\n\tctxt->memop.type = OP_NONE;\n\tctxt->memopp = NULL;\n\tctxt->_eip = ctxt->eip;\n\tctxt->fetch.ptr = ctxt->fetch.data;\n\tctxt->fetch.end = ctxt->fetch.data + insn_len;\n\tctxt->opcode_len = 1;\n\tif (insn_len > 0)\n\t\tmemcpy(ctxt->fetch.data, insn, insn_len);\n\telse {\n\t\trc = __do_insn_fetch_bytes(ctxt, 1);\n\t\tif (rc != X86EMUL_CONTINUE)\n\t\t\treturn rc;\n\t}\n\n\tswitch (mode) {\n\tcase X86EMUL_MODE_REAL:\n\tcase X86EMUL_MODE_VM86:\n\tcase X86EMUL_MODE_PROT16:\n\t\tdef_op_bytes = def_ad_bytes = 2;\n\t\tbreak;\n\tcase X86EMUL_MODE_PROT32:\n\t\tdef_op_bytes = def_ad_bytes = 4;\n\t\tbreak;\n#ifdef CONFIG_X86_64\n\tcase X86EMUL_MODE_PROT64:\n\t\tdef_op_bytes = 4;\n\t\tdef_ad_bytes = 8;\n\t\tbreak;\n#endif\n\tdefault:\n\t\treturn EMULATION_FAILED;\n\t}\n\n\tctxt->op_bytes = def_op_bytes;\n\tctxt->ad_bytes = def_ad_bytes;\n\n\t/* Legacy prefixes. */\n\tfor (;;) {\n\t\tswitch (ctxt->b = insn_fetch(u8, ctxt)) {\n\t\tcase 0x66:\t/* operand-size override */\n\t\t\top_prefix = true;\n\t\t\t/* switch between 2/4 bytes */\n\t\t\tctxt->op_bytes = def_op_bytes ^ 6;\n\t\t\tbreak;\n\t\tcase 0x67:\t/* address-size override */\n\t\t\tif (mode == X86EMUL_MODE_PROT64)\n\t\t\t\t/* switch between 4/8 bytes */\n\t\t\t\tctxt->ad_bytes = def_ad_bytes ^ 12;\n\t\t\telse\n\t\t\t\t/* switch between 2/4 bytes */\n\t\t\t\tctxt->ad_bytes = def_ad_bytes ^ 6;\n\t\t\tbreak;\n\t\tcase 0x26:\t/* ES override */\n\t\tcase 0x2e:\t/* CS override */\n\t\tcase 0x36:\t/* SS override */\n\t\tcase 0x3e:\t/* DS override */\n\t\t\thas_seg_override = true;\n\t\t\tctxt->seg_override = (ctxt->b >> 3) & 3;\n\t\t\tbreak;\n\t\tcase 0x64:\t/* FS override */\n\t\tcase 0x65:\t/* GS override */\n\t\t\thas_seg_override = true;\n\t\t\tctxt->seg_override = ctxt->b & 7;\n\t\t\tbreak;\n\t\tcase 0x40 ... 0x4f: /* REX */\n\t\t\tif (mode != X86EMUL_MODE_PROT64)\n\t\t\t\tgoto done_prefixes;\n\t\t\tctxt->rex_prefix = ctxt->b;\n\t\t\tcontinue;\n\t\tcase 0xf0:\t/* LOCK */\n\t\t\tctxt->lock_prefix = 1;\n\t\t\tbreak;\n\t\tcase 0xf2:\t/* REPNE/REPNZ */\n\t\tcase 0xf3:\t/* REP/REPE/REPZ */\n\t\t\tctxt->rep_prefix = ctxt->b;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tgoto done_prefixes;\n\t\t}\n\n\t\t/* Any legacy prefix after a REX prefix nullifies its effect. */\n\n\t\tctxt->rex_prefix = 0;\n\t}\n\ndone_prefixes:\n\n\t/* REX prefix. */\n\tif (ctxt->rex_prefix & 8)\n\t\tctxt->op_bytes = 8;\t/* REX.W */\n\n\t/* Opcode byte(s). */\n\topcode = opcode_table[ctxt->b];\n\t/* Two-byte opcode? */\n\tif (ctxt->b == 0x0f) {\n\t\tctxt->opcode_len = 2;\n\t\tctxt->b = insn_fetch(u8, ctxt);\n\t\topcode = twobyte_table[ctxt->b];\n\n\t\t/* 0F_38 opcode map */\n\t\tif (ctxt->b == 0x38) {\n\t\t\tctxt->opcode_len = 3;\n\t\t\tctxt->b = insn_fetch(u8, ctxt);\n\t\t\topcode = opcode_map_0f_38[ctxt->b];\n\t\t}\n\t}\n\tctxt->d = opcode.flags;\n\n\tif (ctxt->d & ModRM)\n\t\tctxt->modrm = insn_fetch(u8, ctxt);\n\n\t/* vex-prefix instructions are not implemented */\n\tif (ctxt->opcode_len == 1 && (ctxt->b == 0xc5 || ctxt->b == 0xc4) &&\n\t    (mode == X86EMUL_MODE_PROT64 || (ctxt->modrm & 0xc0) == 0xc0)) {\n\t\tctxt->d = NotImpl;\n\t}\n\n\twhile (ctxt->d & GroupMask) {\n\t\tswitch (ctxt->d & GroupMask) {\n\t\tcase Group:\n\t\t\tgoffset = (ctxt->modrm >> 3) & 7;\n\t\t\topcode = opcode.u.group[goffset];\n\t\t\tbreak;\n\t\tcase GroupDual:\n\t\t\tgoffset = (ctxt->modrm >> 3) & 7;\n\t\t\tif ((ctxt->modrm >> 6) == 3)\n\t\t\t\topcode = opcode.u.gdual->mod3[goffset];\n\t\t\telse\n\t\t\t\topcode = opcode.u.gdual->mod012[goffset];\n\t\t\tbreak;\n\t\tcase RMExt:\n\t\t\tgoffset = ctxt->modrm & 7;\n\t\t\topcode = opcode.u.group[goffset];\n\t\t\tbreak;\n\t\tcase Prefix:\n\t\t\tif (ctxt->rep_prefix && op_prefix)\n\t\t\t\treturn EMULATION_FAILED;\n\t\t\tsimd_prefix = op_prefix ? 0x66 : ctxt->rep_prefix;\n\t\t\tswitch (simd_prefix) {\n\t\t\tcase 0x00: opcode = opcode.u.gprefix->pfx_no; break;\n\t\t\tcase 0x66: opcode = opcode.u.gprefix->pfx_66; break;\n\t\t\tcase 0xf2: opcode = opcode.u.gprefix->pfx_f2; break;\n\t\t\tcase 0xf3: opcode = opcode.u.gprefix->pfx_f3; break;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase Escape:\n\t\t\tif (ctxt->modrm > 0xbf)\n\t\t\t\topcode = opcode.u.esc->high[ctxt->modrm - 0xc0];\n\t\t\telse\n\t\t\t\topcode = opcode.u.esc->op[(ctxt->modrm >> 3) & 7];\n\t\t\tbreak;\n\t\tcase InstrDual:\n\t\t\tif ((ctxt->modrm >> 6) == 3)\n\t\t\t\topcode = opcode.u.idual->mod3;\n\t\t\telse\n\t\t\t\topcode = opcode.u.idual->mod012;\n\t\t\tbreak;\n\t\tcase ModeDual:\n\t\t\tif (ctxt->mode == X86EMUL_MODE_PROT64)\n\t\t\t\topcode = opcode.u.mdual->mode64;\n\t\t\telse\n\t\t\t\topcode = opcode.u.mdual->mode32;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn EMULATION_FAILED;\n\t\t}\n\n\t\tctxt->d &= ~(u64)GroupMask;\n\t\tctxt->d |= opcode.flags;\n\t}\n\n\t/* Unrecognised? */\n\tif (ctxt->d == 0)\n\t\treturn EMULATION_FAILED;\n\n\tctxt->execute = opcode.u.execute;\n\n\tif (unlikely(ctxt->ud) && likely(!(ctxt->d & EmulateOnUD)))\n\t\treturn EMULATION_FAILED;\n\n\tif (unlikely(ctxt->d &\n\t    (NotImpl|Stack|Op3264|Sse|Mmx|Intercept|CheckPerm|NearBranch|\n\t     No16))) {\n\t\t/*\n\t\t * These are copied unconditionally here, and checked unconditionally\n\t\t * in x86_emulate_insn.\n\t\t */\n\t\tctxt->check_perm = opcode.check_perm;\n\t\tctxt->intercept = opcode.intercept;\n\n\t\tif (ctxt->d & NotImpl)\n\t\t\treturn EMULATION_FAILED;\n\n\t\tif (mode == X86EMUL_MODE_PROT64) {\n\t\t\tif (ctxt->op_bytes == 4 && (ctxt->d & Stack))\n\t\t\t\tctxt->op_bytes = 8;\n\t\t\telse if (ctxt->d & NearBranch)\n\t\t\t\tctxt->op_bytes = 8;\n\t\t}\n\n\t\tif (ctxt->d & Op3264) {\n\t\t\tif (mode == X86EMUL_MODE_PROT64)\n\t\t\t\tctxt->op_bytes = 8;\n\t\t\telse\n\t\t\t\tctxt->op_bytes = 4;\n\t\t}\n\n\t\tif ((ctxt->d & No16) && ctxt->op_bytes == 2)\n\t\t\tctxt->op_bytes = 4;\n\n\t\tif (ctxt->d & Sse)\n\t\t\tctxt->op_bytes = 16;\n\t\telse if (ctxt->d & Mmx)\n\t\t\tctxt->op_bytes = 8;\n\t}\n\n\t/* ModRM and SIB bytes. */\n\tif (ctxt->d & ModRM) {\n\t\trc = decode_modrm(ctxt, &ctxt->memop);\n\t\tif (!has_seg_override) {\n\t\t\thas_seg_override = true;\n\t\t\tctxt->seg_override = ctxt->modrm_seg;\n\t\t}\n\t} else if (ctxt->d & MemAbs)\n\t\trc = decode_abs(ctxt, &ctxt->memop);\n\tif (rc != X86EMUL_CONTINUE)\n\t\tgoto done;\n\n\tif (!has_seg_override)\n\t\tctxt->seg_override = VCPU_SREG_DS;\n\n\tctxt->memop.addr.mem.seg = ctxt->seg_override;\n\n\t/*\n\t * Decode and fetch the source operand: register, memory\n\t * or immediate.\n\t */\n\trc = decode_operand(ctxt, &ctxt->src, (ctxt->d >> SrcShift) & OpMask);\n\tif (rc != X86EMUL_CONTINUE)\n\t\tgoto done;\n\n\t/*\n\t * Decode and fetch the second source operand: register, memory\n\t * or immediate.\n\t */\n\trc = decode_operand(ctxt, &ctxt->src2, (ctxt->d >> Src2Shift) & OpMask);\n\tif (rc != X86EMUL_CONTINUE)\n\t\tgoto done;\n\n\t/* Decode and fetch the destination operand: register or memory. */\n\trc = decode_operand(ctxt, &ctxt->dst, (ctxt->d >> DstShift) & OpMask);\n\n\tif (ctxt->rip_relative && likely(ctxt->memopp))\n\t\tctxt->memopp->addr.mem.ea = address_mask(ctxt,\n\t\t\t\t\tctxt->memopp->addr.mem.ea + ctxt->_eip);\n\ndone:\n\treturn (rc != X86EMUL_CONTINUE) ? EMULATION_FAILED : EMULATION_OK;\n}", "commit_link": "github.com/torvalds/linux/commit/d9092f52d7e61dd1557f2db2400ddb430e85937e", "file_name": "arch/x86/kvm/emulate.c", "vul_type": "cwe-476", "description": "Write a C function named `x86_decode_insn` that decodes an x86 instruction from a given context, instruction pointer, and length."}
{"func_name": "autocomplete_phrases", "func_src_before": "def autocomplete_phrases(query):\n    query_string = ur\"\"\"\n        with s as (SELECT id, lower(title) as lower_title FROM pub_2018 WHERE title iLIKE '%{query}%')\n        select match, count(*) as score from (\n            SELECT regexp_matches(lower_title, '({query}\\w*?\\M)', 'g') as match FROM s\n            union all\n            SELECT regexp_matches(lower_title, '({query}\\w*?(?:\\s+\\w+){{1}})\\M', 'g') as match FROM s\n            union all\n            SELECT regexp_matches(lower_title, '({query}\\w*?(?:\\s+\\w+){{2}})\\M', 'g') as match FROM s\n            union all\n            SELECT regexp_matches(lower_title, '({query}\\w*?(?:\\s+\\w+){{3}}|)\\M', 'g') as match FROM s\n        ) s_all\n        group by match\n        order by score desc, length(match::text) asc\n        LIMIT 50;\"\"\".format(query=query)\n\n    rows = db.engine.execute(sql.text(query_string)).fetchall()\n    phrases = [{\"phrase\":row[0][0], \"score\":row[1]} for row in rows if row[0][0]]\n    return phrases", "func_src_after": "def autocomplete_phrases(query):\n    query_statement = sql.text(ur\"\"\"\n        with s as (SELECT id, lower(title) as lower_title FROM pub_2018 WHERE title iLIKE :p0)\n        select match, count(*) as score from (\n            SELECT regexp_matches(lower_title, :p1, 'g') as match FROM s\n            union all\n            SELECT regexp_matches(lower_title, :p2, 'g') as match FROM s\n            union all\n            SELECT regexp_matches(lower_title, :p3, 'g') as match FROM s\n            union all\n            SELECT regexp_matches(lower_title, :p4, 'g') as match FROM s\n        ) s_all\n        group by match\n        order by score desc, length(match::text) asc\n        LIMIT 50;\"\"\").bindparams(\n            p0='%{}%'.format(query),\n            p1=ur'({}\\w*?\\M)'.format(query),\n            p2=ur'({}\\w*?(?:\\s+\\w+){{1}})\\M'.format(query),\n            p3=ur'({}\\w*?(?:\\s+\\w+){{2}})\\M'.format(query),\n            p4=ur'({}\\w*?(?:\\s+\\w+){{3}}|)\\M'.format(query)\n        )\n\n    rows = db.engine.execute(query_statement).fetchall()\n    phrases = [{\"phrase\":row[0][0], \"score\":row[1]} for row in rows if row[0][0]]\n    return phrases", "line_changes": {"deleted": [{"line_no": 2, "char_start": 33, "char_end": 58, "line": "    query_string = ur\"\"\"\n"}, {"line_no": 3, "char_start": 58, "char_end": 161, "line": "        with s as (SELECT id, lower(title) as lower_title FROM pub_2018 WHERE title iLIKE '%{query}%')\n"}, {"line_no": 5, "char_start": 208, "char_end": 295, "line": "            SELECT regexp_matches(lower_title, '({query}\\w*?\\M)', 'g') as match FROM s\n"}, {"line_no": 7, "char_start": 317, "char_end": 419, "line": "            SELECT regexp_matches(lower_title, '({query}\\w*?(?:\\s+\\w+){{1}})\\M', 'g') as match FROM s\n"}, {"line_no": 9, "char_start": 441, "char_end": 543, "line": "            SELECT regexp_matches(lower_title, '({query}\\w*?(?:\\s+\\w+){{2}})\\M', 'g') as match FROM s\n"}, {"line_no": 11, "char_start": 565, "char_end": 668, "line": "            SELECT regexp_matches(lower_title, '({query}\\w*?(?:\\s+\\w+){{3}}|)\\M', 'g') as match FROM s\n"}, {"line_no": 15, "char_start": 760, "char_end": 801, "line": "        LIMIT 50;\"\"\".format(query=query)\n"}, {"line_no": 17, "char_start": 802, "char_end": 866, "line": "    rows = db.engine.execute(sql.text(query_string)).fetchall()\n"}], "added": [{"line_no": 2, "char_start": 33, "char_end": 70, "line": "    query_statement = sql.text(ur\"\"\"\n"}, {"line_no": 3, "char_start": 70, "char_end": 165, "line": "        with s as (SELECT id, lower(title) as lower_title FROM pub_2018 WHERE title iLIKE :p0)\n"}, {"line_no": 5, "char_start": 212, "char_end": 285, "line": "            SELECT regexp_matches(lower_title, :p1, 'g') as match FROM s\n"}, {"line_no": 7, "char_start": 307, "char_end": 380, "line": "            SELECT regexp_matches(lower_title, :p2, 'g') as match FROM s\n"}, {"line_no": 9, "char_start": 402, "char_end": 475, "line": "            SELECT regexp_matches(lower_title, :p3, 'g') as match FROM s\n"}, {"line_no": 11, "char_start": 497, "char_end": 570, "line": "            SELECT regexp_matches(lower_title, :p4, 'g') as match FROM s\n"}, {"line_no": 15, "char_start": 662, "char_end": 696, "line": "        LIMIT 50;\"\"\").bindparams(\n"}, {"line_no": 16, "char_start": 696, "char_end": 733, "line": "            p0='%{}%'.format(query),\n"}, {"line_no": 17, "char_start": 733, "char_end": 778, "line": "            p1=ur'({}\\w*?\\M)'.format(query),\n"}, {"line_no": 18, "char_start": 778, "char_end": 838, "line": "            p2=ur'({}\\w*?(?:\\s+\\w+){{1}})\\M'.format(query),\n"}, {"line_no": 19, "char_start": 838, "char_end": 898, "line": "            p3=ur'({}\\w*?(?:\\s+\\w+){{2}})\\M'.format(query),\n"}, {"line_no": 20, "char_start": 898, "char_end": 958, "line": "            p4=ur'({}\\w*?(?:\\s+\\w+){{3}}|)\\M'.format(query)\n"}, {"line_no": 21, "char_start": 958, "char_end": 968, "line": "        )\n"}, {"line_no": 23, "char_start": 969, "char_end": 1026, "line": "    rows = db.engine.execute(query_statement).fetchall()\n"}]}, "char_changes": {"deleted": [{"char_start": 45, "char_end": 52, "chars": "ring = "}, {"char_start": 148, "char_end": 159, "chars": "'%{query}%'"}, {"char_start": 255, "char_end": 272, "chars": "'({query}\\w*?\\M)'"}, {"char_start": 364, "char_end": 396, "chars": "'({query}\\w*?(?:\\s+\\w+){{1}})\\M'"}, {"char_start": 488, "char_end": 520, "chars": "'({query}\\w*?(?:\\s+\\w+){{2}})\\M'"}, {"char_start": 612, "char_end": 645, "chars": "'({query}\\w*?(?:\\s+\\w+){{3}}|)\\M'"}, {"char_start": 780, "char_end": 799, "chars": ".format(query=query"}, {"char_start": 831, "char_end": 840, "chars": "sql.text("}, {"char_start": 848, "char_end": 853, "chars": "ring)"}], "added": [{"char_start": 45, "char_end": 64, "chars": "atement = sql.text("}, {"char_start": 160, "char_end": 163, "chars": ":p0"}, {"char_start": 259, "char_end": 262, "chars": ":p1"}, {"char_start": 354, "char_end": 357, "chars": ":p2"}, {"char_start": 449, "char_end": 452, "chars": ":p3"}, {"char_start": 544, "char_end": 547, "chars": ":p4"}, {"char_start": 682, "char_end": 966, "chars": ").bindparams(\n            p0='%{}%'.format(query),\n            p1=ur'({}\\w*?\\M)'.format(query),\n            p2=ur'({}\\w*?(?:\\s+\\w+){{1}})\\M'.format(query),\n            p3=ur'({}\\w*?(?:\\s+\\w+){{2}})\\M'.format(query),\n            p4=ur'({}\\w*?(?:\\s+\\w+){{3}}|)\\M'.format(query)\n        "}, {"char_start": 1006, "char_end": 1013, "chars": "atement"}]}, "commit_link": "github.com/Impactstory/oadoi/commit/4cde28ea869c921be917cd8726edb958b37d683a", "file_name": "search.py", "vul_type": "cwe-089", "commit_msg": "fix sql injection vulnerability in search endpoints", "description": "Write a Python function to perform autocomplete for phrases using a SQL query with regular expressions."}
{"func_name": "update_history_and_sourcebyinstitution", "func_src_before": "def update_history_and_sourcebyinstitution(conn, sqlite, k10plus, ai):\n    \"\"\"\n    Get all current sources and title numbers from Solr and log them into database.\n    \"\"\"\n    current_sources = get_all_current_sources(k10plus, ai)\n    current_institutions = get_all_current_institutions(k10plus, ai)\n    old_sourcebyinstitutions = get_all_old_sourcebyinstitutions(conn, sqlite)\n    current_sourcebyinstitutions = []\n\n    for source in current_sources:\n\n        for institution in current_institutions:\n\n            if not institution or institution == \" \" or '\"' in institution:\n                continue\n\n            sourcebyinstitution = \"SID \" + str(source) + \" (\" + institution + \")\"\n            current_sourcebyinstitutions.append(sourcebyinstitution)\n\n            params = {\n                \"q\": 'source_id:%s AND institution:\"%s\"' % (source, institution),\n                \"rows\": 0,\n                \"wt\": \"json\"\n            }\n\n            # check k10plus\n            result = get_solr_result(k10plus, params)\n            number = result[\"response\"][\"numFound\"]\n            if number != 0:\n                sql = 'INSERT INTO history (sourcebyinstitution, titles) VALUES (\"%s\", %s)' % (sourcebyinstitution, number)\n                sqlite.execute(sql)\n                conn.commit()\n            else:\n                # check ai\n                result = get_solr_result(ai, params)\n                number = result[\"response\"][\"numFound\"]\n                if number != 0:\n                    # TODO: escape via sqlite\n                    sql = 'INSERT INTO history (sourcebyinstitution, titles) VALUES (\"%s\", %s)' % (sourcebyinstitution, number)\n                    sqlite.execute(sql)\n                    conn.commit()\n\n            if sourcebyinstitution not in old_sourcebyinstitutions:\n                logging.info(\"The %s is now connected to SID %s.\", institution, source)\n                sql = \"INSERT INTO sourcebyinstitution (sourcebyinstitution) VALUES ('%s')\" % sourcebyinstitution\n                sqlite.execute(sql)\n                conn.commit()\n\n            if number != 0:\n                old_sourcebyinstitution_number = get_old_sourcebyinstitution_number(conn, sqlite, sourcebyinstitution)\n                if number < old_sourcebyinstitution_number:\n                    message = \"Die Anzahl der Titel hat sich bei %s gegenueber einem frueheren Import verringert.\" % (sourcebyinstitution)\n                    send_message(message)\n\n            # requests.exceptions.ConnectionError: HTTPConnectionPool(XXXXXX): Max retries exceeded\n            time.sleep(0.25)\n\n    for old_sourcebyinstitution in old_sourcebyinstitutions:\n        if old_sourcebyinstitution not in current_sourcebyinstitutions:\n            message = \"Die %s ist nicht laenger f\u00fcr die SID %s angesigelt.\" % (institution, source)\n            send_message(message)", "func_src_after": "def update_history_and_sourcebyinstitution(conn, sqlite, k10plus, ai):\n    \"\"\"\n    Get all current sources and title numbers from Solr and log them into database.\n    \"\"\"\n    current_sources = get_all_current_sources(k10plus, ai)\n    current_institutions = get_all_current_institutions(k10plus, ai)\n    old_sourcebyinstitutions = get_all_old_sourcebyinstitutions(conn, sqlite)\n    current_sourcebyinstitutions = []\n\n    for source in current_sources:\n\n        for institution in current_institutions:\n\n            if not institution or institution == \" \" or '\"' in institution:\n                continue\n\n            sourcebyinstitution = \"SID \" + str(source) + \" (\" + institution + \")\"\n            current_sourcebyinstitutions.append(sourcebyinstitution)\n\n            params = {\n                \"q\": 'source_id:%s AND institution:\"%s\"' % (source, institution),\n                \"rows\": 0,\n                \"wt\": \"json\"\n            }\n\n            # check k10plus\n            result = get_solr_result(k10plus, params)\n            number = result[\"response\"][\"numFound\"]\n            if number != 0:\n                sql = 'INSERT INTO history (sourcebyinstitution, titles) VALUES (?, ?)'\n                sqlite.execute(sql, (sourcebyinstitution, number))\n                conn.commit()\n            else:\n                # check ai\n                result = get_solr_result(ai, params)\n                number = result[\"response\"][\"numFound\"]\n                if number != 0:\n                    # TODO: escape via sqlite\n                    sql = 'INSERT INTO history (sourcebyinstitution, titles) VALUES (?, ?)'\n                    sqlite.execute(sql, (sourcebyinstitution, number))\n                    conn.commit()\n\n            if sourcebyinstitution not in old_sourcebyinstitutions:\n                logging.info(\"The %s is now connected to SID %s.\", institution, source)\n                sql = \"INSERT INTO sourcebyinstitution (sourcebyinstitution) VALUES (?)\"\n                sqlite.execute(sql, (sourcebyinstitution))\n                conn.commit()\n\n            if number != 0:\n                old_sourcebyinstitution_number = get_old_sourcebyinstitution_number(conn, sqlite, sourcebyinstitution)\n                if number < old_sourcebyinstitution_number:\n                    message = \"Die Anzahl der Titel hat sich bei %s gegenueber einem frueheren Import verringert.\" % (sourcebyinstitution)\n                    send_message(message)\n\n            # requests.exceptions.ConnectionError: HTTPConnectionPool(XXXXXX): Max retries exceeded\n            time.sleep(0.25)\n\n    for old_sourcebyinstitution in old_sourcebyinstitutions:\n        if old_sourcebyinstitution not in current_sourcebyinstitutions:\n            message = \"Die %s ist nicht laenger f\u00fcr die SID %s angesigelt.\" % (institution, source)\n            send_message(message)", "commit_link": "github.com/miku/siskin/commit/7fa398d2fea72bf2e8b4808f75df4b3d35ae959a", "file_name": "bin/solrcheckup.py", "vul_type": "cwe-089", "description": "Write a Python function to log current source and title data from Solr into a database, handling new and old entries."}
{"func_name": "handle_method_call", "func_src_before": "static void handle_method_call(GDBusConnection *connection,\n                        const gchar *caller,\n                        const gchar *object_path,\n                        const gchar *interface_name,\n                        const gchar *method_name,\n                        GVariant    *parameters,\n                        GDBusMethodInvocation *invocation,\n                        gpointer    user_data)\n{\n    reset_timeout();\n\n    uid_t caller_uid;\n    GVariant *response;\n\n    caller_uid = get_caller_uid(connection, invocation, caller);\n\n    log_notice(\"caller_uid:%ld method:'%s'\", (long)caller_uid, method_name);\n\n    if (caller_uid == (uid_t) -1)\n        return;\n\n    if (g_strcmp0(method_name, \"NewProblem\") == 0)\n    {\n        char *error = NULL;\n        char *problem_id = handle_new_problem(g_variant_get_child_value(parameters, 0), caller_uid, &error);\n        if (!problem_id)\n        {\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      error);\n            free(error);\n            return;\n        }\n        /* else */\n        response = g_variant_new(\"(s)\", problem_id);\n        g_dbus_method_invocation_return_value(invocation, response);\n        free(problem_id);\n\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetProblems\") == 0)\n    {\n        GList *dirs = get_problem_dirs_for_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        //I was told that g_dbus_method frees the response\n        //g_variant_unref(response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetAllProblems\") == 0)\n    {\n        /*\n        - so, we have UID,\n        - if it's 0, then we don't have to check anything and just return all directories\n        - if uid != 0 then we want to ask for authorization\n        */\n        if (caller_uid != 0)\n        {\n            if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") == PolkitYes)\n                caller_uid = 0;\n        }\n\n        GList * dirs = get_problem_dirs_for_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetForeignProblems\") == 0)\n    {\n        GList * dirs = get_problem_dirs_not_accessible_by_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"ChownProblemDir\") == 0)\n    {\n        const gchar *problem_dir;\n        g_variant_get(parameters, \"(&s)\", &problem_dir);\n        log_notice(\"problem_dir:'%s'\", problem_dir);\n\n        if (!allowed_problem_dir(problem_dir))\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int dir_fd = dd_openfd(problem_dir);\n        if (dir_fd < 0)\n        {\n            perror_msg(\"can't open problem directory '%s'\", problem_dir);\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int ddstat = fdump_dir_stat_for_uid(dir_fd, caller_uid);\n        if (ddstat < 0)\n        {\n            if (errno == ENOTDIR)\n            {\n                log_notice(\"requested directory does not exist '%s'\", problem_dir);\n            }\n            else\n            {\n                perror_msg(\"can't get stat of '%s'\", problem_dir);\n            }\n\n            return_InvalidProblemDir_error(invocation, problem_dir);\n\n            close(dir_fd);\n            return;\n        }\n\n        if (ddstat & DD_STAT_OWNED_BY_UID)\n        {   //caller seems to be in group with access to this dir, so no action needed\n            log_notice(\"caller has access to the requested directory %s\", problem_dir);\n            g_dbus_method_invocation_return_value(invocation, NULL);\n            close(dir_fd);\n            return;\n        }\n\n        if ((ddstat & DD_STAT_ACCESSIBLE_BY_UID) == 0 &&\n                polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n        {\n            log_notice(\"not authorized\");\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.AuthFailure\",\n                                              _(\"Not Authorized\"));\n            close(dir_fd);\n            return;\n        }\n\n        struct dump_dir *dd = dd_fdopendir(dir_fd, problem_dir, DD_OPEN_READONLY | DD_FAIL_QUIETLY_EACCES);\n        if (!dd)\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int chown_res = dd_chown(dd, caller_uid);\n        if (chown_res != 0)\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.ChownError\",\n                                              _(\"Chowning directory failed. Check system logs for more details.\"));\n        else\n            g_dbus_method_invocation_return_value(invocation, NULL);\n\n        dd_close(dd);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetInfo\") == 0)\n    {\n        /* Parameter tuple is (sas) */\n\n\t/* Get 1st param - problem dir name */\n        const gchar *problem_dir;\n        g_variant_get_child(parameters, 0, \"&s\", &problem_dir);\n        log_notice(\"problem_dir:'%s'\", problem_dir);\n\n        if (!allowed_problem_dir(problem_dir))\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int dir_fd = dd_openfd(problem_dir);\n        if (dir_fd < 0)\n        {\n            perror_msg(\"can't open problem directory '%s'\", problem_dir);\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        if (!fdump_dir_accessible_by_uid(dir_fd, caller_uid))\n        {\n            if (errno == ENOTDIR)\n            {\n                log_notice(\"Requested directory does not exist '%s'\", problem_dir);\n                return_InvalidProblemDir_error(invocation, problem_dir);\n                close(dir_fd);\n                return;\n            }\n\n            if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n            {\n                log_notice(\"not authorized\");\n                g_dbus_method_invocation_return_dbus_error(invocation,\n                                                  \"org.freedesktop.problems.AuthFailure\",\n                                                  _(\"Not Authorized\"));\n                close(dir_fd);\n                return;\n            }\n        }\n\n        struct dump_dir *dd = dd_fdopendir(dir_fd, problem_dir, DD_OPEN_READONLY | DD_FAIL_QUIETLY_EACCES);\n        if (!dd)\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n\t/* Get 2nd param - vector of element names */\n        GVariant *array = g_variant_get_child_value(parameters, 1);\n        GList *elements = string_list_from_variant(array);\n        g_variant_unref(array);\n\n        GVariantBuilder *builder = NULL;\n        for (GList *l = elements; l; l = l->next)\n        {\n            const char *element_name = (const char*)l->data;\n            char *value = dd_load_text_ext(dd, element_name, 0\n                                                | DD_LOAD_TEXT_RETURN_NULL_ON_FAILURE\n                                                | DD_FAIL_QUIETLY_ENOENT\n                                                | DD_FAIL_QUIETLY_EACCES);\n            log_notice(\"element '%s' %s\", element_name, value ? \"fetched\" : \"not found\");\n            if (value)\n            {\n                if (!builder)\n                    builder = g_variant_builder_new(G_VARIANT_TYPE_ARRAY);\n\n                /* g_variant_builder_add makes a copy. No need to xstrdup here */\n                g_variant_builder_add(builder, \"{ss}\", element_name, value);\n                free(value);\n            }\n        }\n        list_free_with_free(elements);\n        dd_close(dd);\n        /* It is OK to call g_variant_new(\"(a{ss})\", NULL) because */\n        /* G_VARIANT_TYPE_TUPLE allows NULL value */\n        GVariant *response = g_variant_new(\"(a{ss})\", builder);\n\n        if (builder)\n            g_variant_builder_unref(builder);\n\n        log_info(\"GetInfo: returning value for '%s'\", problem_dir);\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"SetElement\") == 0)\n    {\n        const char *problem_id;\n        const char *element;\n        const char *value;\n\n        g_variant_get(parameters, \"(&s&s&s)\", &problem_id, &element, &value);\n\n        if (element == NULL || element[0] == '\\0' || strlen(element) > 64)\n        {\n            log_notice(\"'%s' is not a valid element name of '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"'%s' is not a valid element name\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.InvalidElement\",\n                                              error);\n\n            free(error);\n            return;\n        }\n\n        struct dump_dir *dd = open_directory_for_modification_of_element(\n                                    invocation, caller_uid, problem_id, element);\n        if (!dd)\n            /* Already logged from open_directory_for_modification_of_element() */\n            return;\n\n        /* Is it good idea to make it static? Is it possible to change the max size while a single run? */\n        const double max_dir_size = g_settings_nMaxCrashReportsSize * (1024 * 1024);\n        const long item_size = dd_get_item_size(dd, element);\n        if (item_size < 0)\n        {\n            log_notice(\"Can't get size of '%s/%s'\", problem_id, element);\n            char *error = xasprintf(_(\"Can't get size of '%s'\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      error);\n            return;\n        }\n\n        const double requested_size = (double)strlen(value) - item_size;\n        /* Don't want to check the size limit in case of reducing of size */\n        if (requested_size > 0\n            && requested_size > (max_dir_size - get_dirsize(g_settings_dump_location)))\n        {\n            log_notice(\"No problem space left in '%s' (requested Bytes %f)\", problem_id, requested_size);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      _(\"No problem space left\"));\n        }\n        else\n        {\n            dd_save_text(dd, element, value);\n            g_dbus_method_invocation_return_value(invocation, NULL);\n        }\n\n        dd_close(dd);\n\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"DeleteElement\") == 0)\n    {\n        const char *problem_id;\n        const char *element;\n\n        g_variant_get(parameters, \"(&s&s)\", &problem_id, &element);\n\n        struct dump_dir *dd = open_directory_for_modification_of_element(\n                                    invocation, caller_uid, problem_id, element);\n        if (!dd)\n            /* Already logged from open_directory_for_modification_of_element() */\n            return;\n\n        const int res = dd_delete_item(dd, element);\n        dd_close(dd);\n\n        if (res != 0)\n        {\n            log_notice(\"Can't delete the element '%s' from the problem directory '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"Can't delete the element '%s' from the problem directory '%s'\"), element, problem_id);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                          \"org.freedesktop.problems.Failure\",\n                                          error);\n            free(error);\n            return;\n        }\n\n\n        g_dbus_method_invocation_return_value(invocation, NULL);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"DeleteProblem\") == 0)\n    {\n        /* Dbus parameters are always tuples.\n         * In this case, it's (as) - a tuple of one element (array of strings).\n         * Need to fetch the array:\n         */\n        GVariant *array = g_variant_get_child_value(parameters, 0);\n        GList *problem_dirs = string_list_from_variant(array);\n        g_variant_unref(array);\n\n        for (GList *l = problem_dirs; l; l = l->next)\n        {\n            const char *dir_name = (const char*)l->data;\n            log_notice(\"dir_name:'%s'\", dir_name);\n            if (!allowed_problem_dir(dir_name))\n            {\n                return_InvalidProblemDir_error(invocation, dir_name);\n                goto ret;\n            }\n        }\n\n        for (GList *l = problem_dirs; l; l = l->next)\n        {\n            const char *dir_name = (const char*)l->data;\n\n            int dir_fd = dd_openfd(dir_name);\n            if (dir_fd < 0)\n            {\n                perror_msg(\"can't open problem directory '%s'\", dir_name);\n                return_InvalidProblemDir_error(invocation, dir_name);\n                return;\n            }\n\n            if (!fdump_dir_accessible_by_uid(dir_fd, caller_uid))\n            {\n                if (errno == ENOTDIR)\n                {\n                    log_notice(\"Requested directory does not exist '%s'\", dir_name);\n                    close(dir_fd);\n                    continue;\n                }\n\n                if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n                { // if user didn't provide correct credentials, just move to the next dir\n                    close(dir_fd);\n                    continue;\n                }\n            }\n\n            struct dump_dir *dd = dd_fdopendir(dir_fd, dir_name, /*flags:*/ 0);\n            if (dd)\n            {\n                if (dd_delete(dd) != 0)\n                {\n                    error_msg(\"Failed to delete problem directory '%s'\", dir_name);\n                    dd_close(dd);\n                }\n            }\n        }\n\n        g_dbus_method_invocation_return_value(invocation, NULL);\n ret:\n        list_free_with_free(problem_dirs);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"FindProblemByElementInTimeRange\") == 0)\n    {\n        const gchar *element;\n        const gchar *value;\n        glong timestamp_from;\n        glong timestamp_to;\n        gboolean all;\n\n        g_variant_get_child(parameters, 0, \"&s\", &element);\n        g_variant_get_child(parameters, 1, \"&s\", &value);\n        g_variant_get_child(parameters, 2, \"x\", &timestamp_from);\n        g_variant_get_child(parameters, 3, \"x\", &timestamp_to);\n        g_variant_get_child(parameters, 4, \"b\", &all);\n\n        if (all && polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") == PolkitYes)\n            caller_uid = 0;\n\n        GList *dirs = get_problem_dirs_for_element_in_time(caller_uid, element, value, timestamp_from,\n                                                        timestamp_to);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"Quit\") == 0)\n    {\n        g_dbus_method_invocation_return_value(invocation, NULL);\n        g_main_loop_quit(loop);\n        return;\n    }\n}", "func_src_after": "static void handle_method_call(GDBusConnection *connection,\n                        const gchar *caller,\n                        const gchar *object_path,\n                        const gchar *interface_name,\n                        const gchar *method_name,\n                        GVariant    *parameters,\n                        GDBusMethodInvocation *invocation,\n                        gpointer    user_data)\n{\n    reset_timeout();\n\n    uid_t caller_uid;\n    GVariant *response;\n\n    caller_uid = get_caller_uid(connection, invocation, caller);\n\n    log_notice(\"caller_uid:%ld method:'%s'\", (long)caller_uid, method_name);\n\n    if (caller_uid == (uid_t) -1)\n        return;\n\n    if (g_strcmp0(method_name, \"NewProblem\") == 0)\n    {\n        char *error = NULL;\n        char *problem_id = handle_new_problem(g_variant_get_child_value(parameters, 0), caller_uid, &error);\n        if (!problem_id)\n        {\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      error);\n            free(error);\n            return;\n        }\n        /* else */\n        response = g_variant_new(\"(s)\", problem_id);\n        g_dbus_method_invocation_return_value(invocation, response);\n        free(problem_id);\n\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetProblems\") == 0)\n    {\n        GList *dirs = get_problem_dirs_for_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        //I was told that g_dbus_method frees the response\n        //g_variant_unref(response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetAllProblems\") == 0)\n    {\n        /*\n        - so, we have UID,\n        - if it's 0, then we don't have to check anything and just return all directories\n        - if uid != 0 then we want to ask for authorization\n        */\n        if (caller_uid != 0)\n        {\n            if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") == PolkitYes)\n                caller_uid = 0;\n        }\n\n        GList * dirs = get_problem_dirs_for_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetForeignProblems\") == 0)\n    {\n        GList * dirs = get_problem_dirs_not_accessible_by_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"ChownProblemDir\") == 0)\n    {\n        const gchar *problem_dir;\n        g_variant_get(parameters, \"(&s)\", &problem_dir);\n        log_notice(\"problem_dir:'%s'\", problem_dir);\n\n        if (!allowed_problem_dir(problem_dir))\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int dir_fd = dd_openfd(problem_dir);\n        if (dir_fd < 0)\n        {\n            perror_msg(\"can't open problem directory '%s'\", problem_dir);\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int ddstat = fdump_dir_stat_for_uid(dir_fd, caller_uid);\n        if (ddstat < 0)\n        {\n            if (errno == ENOTDIR)\n            {\n                log_notice(\"requested directory does not exist '%s'\", problem_dir);\n            }\n            else\n            {\n                perror_msg(\"can't get stat of '%s'\", problem_dir);\n            }\n\n            return_InvalidProblemDir_error(invocation, problem_dir);\n\n            close(dir_fd);\n            return;\n        }\n\n        if (ddstat & DD_STAT_OWNED_BY_UID)\n        {   //caller seems to be in group with access to this dir, so no action needed\n            log_notice(\"caller has access to the requested directory %s\", problem_dir);\n            g_dbus_method_invocation_return_value(invocation, NULL);\n            close(dir_fd);\n            return;\n        }\n\n        if ((ddstat & DD_STAT_ACCESSIBLE_BY_UID) == 0 &&\n                polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n        {\n            log_notice(\"not authorized\");\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.AuthFailure\",\n                                              _(\"Not Authorized\"));\n            close(dir_fd);\n            return;\n        }\n\n        struct dump_dir *dd = dd_fdopendir(dir_fd, problem_dir, DD_OPEN_READONLY | DD_FAIL_QUIETLY_EACCES);\n        if (!dd)\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int chown_res = dd_chown(dd, caller_uid);\n        if (chown_res != 0)\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.ChownError\",\n                                              _(\"Chowning directory failed. Check system logs for more details.\"));\n        else\n            g_dbus_method_invocation_return_value(invocation, NULL);\n\n        dd_close(dd);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetInfo\") == 0)\n    {\n        /* Parameter tuple is (sas) */\n\n\t/* Get 1st param - problem dir name */\n        const gchar *problem_dir;\n        g_variant_get_child(parameters, 0, \"&s\", &problem_dir);\n        log_notice(\"problem_dir:'%s'\", problem_dir);\n\n        if (!allowed_problem_dir(problem_dir))\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int dir_fd = dd_openfd(problem_dir);\n        if (dir_fd < 0)\n        {\n            perror_msg(\"can't open problem directory '%s'\", problem_dir);\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        if (!fdump_dir_accessible_by_uid(dir_fd, caller_uid))\n        {\n            if (errno == ENOTDIR)\n            {\n                log_notice(\"Requested directory does not exist '%s'\", problem_dir);\n                return_InvalidProblemDir_error(invocation, problem_dir);\n                close(dir_fd);\n                return;\n            }\n\n            if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n            {\n                log_notice(\"not authorized\");\n                g_dbus_method_invocation_return_dbus_error(invocation,\n                                                  \"org.freedesktop.problems.AuthFailure\",\n                                                  _(\"Not Authorized\"));\n                close(dir_fd);\n                return;\n            }\n        }\n\n        struct dump_dir *dd = dd_fdopendir(dir_fd, problem_dir, DD_OPEN_READONLY | DD_FAIL_QUIETLY_EACCES);\n        if (!dd)\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n\t/* Get 2nd param - vector of element names */\n        GVariant *array = g_variant_get_child_value(parameters, 1);\n        GList *elements = string_list_from_variant(array);\n        g_variant_unref(array);\n\n        GVariantBuilder *builder = NULL;\n        for (GList *l = elements; l; l = l->next)\n        {\n            const char *element_name = (const char*)l->data;\n            char *value = dd_load_text_ext(dd, element_name, 0\n                                                | DD_LOAD_TEXT_RETURN_NULL_ON_FAILURE\n                                                | DD_FAIL_QUIETLY_ENOENT\n                                                | DD_FAIL_QUIETLY_EACCES);\n            log_notice(\"element '%s' %s\", element_name, value ? \"fetched\" : \"not found\");\n            if (value)\n            {\n                if (!builder)\n                    builder = g_variant_builder_new(G_VARIANT_TYPE_ARRAY);\n\n                /* g_variant_builder_add makes a copy. No need to xstrdup here */\n                g_variant_builder_add(builder, \"{ss}\", element_name, value);\n                free(value);\n            }\n        }\n        list_free_with_free(elements);\n        dd_close(dd);\n        /* It is OK to call g_variant_new(\"(a{ss})\", NULL) because */\n        /* G_VARIANT_TYPE_TUPLE allows NULL value */\n        GVariant *response = g_variant_new(\"(a{ss})\", builder);\n\n        if (builder)\n            g_variant_builder_unref(builder);\n\n        log_info(\"GetInfo: returning value for '%s'\", problem_dir);\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"SetElement\") == 0)\n    {\n        const char *problem_id;\n        const char *element;\n        const char *value;\n\n        g_variant_get(parameters, \"(&s&s&s)\", &problem_id, &element, &value);\n\n        if (!str_is_correct_filename(element))\n        {\n            log_notice(\"'%s' is not a valid element name of '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"'%s' is not a valid element name\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.InvalidElement\",\n                                              error);\n\n            free(error);\n            return;\n        }\n\n        struct dump_dir *dd = open_directory_for_modification_of_element(\n                                    invocation, caller_uid, problem_id, element);\n        if (!dd)\n            /* Already logged from open_directory_for_modification_of_element() */\n            return;\n\n        /* Is it good idea to make it static? Is it possible to change the max size while a single run? */\n        const double max_dir_size = g_settings_nMaxCrashReportsSize * (1024 * 1024);\n        const long item_size = dd_get_item_size(dd, element);\n        if (item_size < 0)\n        {\n            log_notice(\"Can't get size of '%s/%s'\", problem_id, element);\n            char *error = xasprintf(_(\"Can't get size of '%s'\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      error);\n            return;\n        }\n\n        const double requested_size = (double)strlen(value) - item_size;\n        /* Don't want to check the size limit in case of reducing of size */\n        if (requested_size > 0\n            && requested_size > (max_dir_size - get_dirsize(g_settings_dump_location)))\n        {\n            log_notice(\"No problem space left in '%s' (requested Bytes %f)\", problem_id, requested_size);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      _(\"No problem space left\"));\n        }\n        else\n        {\n            dd_save_text(dd, element, value);\n            g_dbus_method_invocation_return_value(invocation, NULL);\n        }\n\n        dd_close(dd);\n\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"DeleteElement\") == 0)\n    {\n        const char *problem_id;\n        const char *element;\n\n        g_variant_get(parameters, \"(&s&s)\", &problem_id, &element);\n\n        if (!str_is_correct_filename(element))\n        {\n            log_notice(\"'%s' is not a valid element name of '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"'%s' is not a valid element name\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.InvalidElement\",\n                                              error);\n\n            free(error);\n            return;\n        }\n\n        struct dump_dir *dd = open_directory_for_modification_of_element(\n                                    invocation, caller_uid, problem_id, element);\n        if (!dd)\n            /* Already logged from open_directory_for_modification_of_element() */\n            return;\n\n        const int res = dd_delete_item(dd, element);\n        dd_close(dd);\n\n        if (res != 0)\n        {\n            log_notice(\"Can't delete the element '%s' from the problem directory '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"Can't delete the element '%s' from the problem directory '%s'\"), element, problem_id);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                          \"org.freedesktop.problems.Failure\",\n                                          error);\n            free(error);\n            return;\n        }\n\n\n        g_dbus_method_invocation_return_value(invocation, NULL);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"DeleteProblem\") == 0)\n    {\n        /* Dbus parameters are always tuples.\n         * In this case, it's (as) - a tuple of one element (array of strings).\n         * Need to fetch the array:\n         */\n        GVariant *array = g_variant_get_child_value(parameters, 0);\n        GList *problem_dirs = string_list_from_variant(array);\n        g_variant_unref(array);\n\n        for (GList *l = problem_dirs; l; l = l->next)\n        {\n            const char *dir_name = (const char*)l->data;\n            log_notice(\"dir_name:'%s'\", dir_name);\n            if (!allowed_problem_dir(dir_name))\n            {\n                return_InvalidProblemDir_error(invocation, dir_name);\n                goto ret;\n            }\n        }\n\n        for (GList *l = problem_dirs; l; l = l->next)\n        {\n            const char *dir_name = (const char*)l->data;\n\n            int dir_fd = dd_openfd(dir_name);\n            if (dir_fd < 0)\n            {\n                perror_msg(\"can't open problem directory '%s'\", dir_name);\n                return_InvalidProblemDir_error(invocation, dir_name);\n                return;\n            }\n\n            if (!fdump_dir_accessible_by_uid(dir_fd, caller_uid))\n            {\n                if (errno == ENOTDIR)\n                {\n                    log_notice(\"Requested directory does not exist '%s'\", dir_name);\n                    close(dir_fd);\n                    continue;\n                }\n\n                if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n                { // if user didn't provide correct credentials, just move to the next dir\n                    close(dir_fd);\n                    continue;\n                }\n            }\n\n            struct dump_dir *dd = dd_fdopendir(dir_fd, dir_name, /*flags:*/ 0);\n            if (dd)\n            {\n                if (dd_delete(dd) != 0)\n                {\n                    error_msg(\"Failed to delete problem directory '%s'\", dir_name);\n                    dd_close(dd);\n                }\n            }\n        }\n\n        g_dbus_method_invocation_return_value(invocation, NULL);\n ret:\n        list_free_with_free(problem_dirs);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"FindProblemByElementInTimeRange\") == 0)\n    {\n        const gchar *element;\n        const gchar *value;\n        glong timestamp_from;\n        glong timestamp_to;\n        gboolean all;\n\n        g_variant_get_child(parameters, 0, \"&s\", &element);\n        g_variant_get_child(parameters, 1, \"&s\", &value);\n        g_variant_get_child(parameters, 2, \"x\", &timestamp_from);\n        g_variant_get_child(parameters, 3, \"x\", &timestamp_to);\n        g_variant_get_child(parameters, 4, \"b\", &all);\n\n        if (all && polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") == PolkitYes)\n            caller_uid = 0;\n\n        GList *dirs = get_problem_dirs_for_element_in_time(caller_uid, element, value, timestamp_from,\n                                                        timestamp_to);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"Quit\") == 0)\n    {\n        g_dbus_method_invocation_return_value(invocation, NULL);\n        g_main_loop_quit(loop);\n        return;\n    }\n}", "commit_link": "github.com/abrt/abrt/commit/f3c2a6af3455b2882e28570e8a04f1c2d4500d5b", "file_name": "src/dbus/abrt-dbus.c", "vul_type": "cwe-022", "description": "Write a C function to handle various method calls for problem management over D-Bus."}
{"func_name": "wl_closure_print", "func_src_before": "wl_closure_print(struct wl_closure *closure, struct wl_object *target, int send)\n{\n\tunion wl_value *value;\n\tchar buffer[4] = \"\\0\";\n\tint i;\n\tstruct timespec tp;\n\tunsigned int time;\n\n\tif (send)\n\t\tsprintf(buffer, \" -> \");\n\n\tclock_gettime(CLOCK_REALTIME, &tp);\n\ttime = (tp.tv_sec * 1000000L) + (tp.tv_nsec / 1000);\n\n\tfprintf(stderr, \"[%10.3f] %s%s@%d.%s(\",\n\t\ttime / 1000.0,\n\t\tbuffer,\n\t\ttarget->interface->name, target->id,\n\t\tclosure->message->name);\n\n\tfor (i = 2; i < closure->count; i++) {\n\t\tif (i > 2)\n\t\t\tfprintf(stderr, \", \");\n\n\t\tvalue = closure->args[i];\n\t\tswitch (closure->message->signature[i - 2]) {\n\t\tcase 'u':\n\t\t\tfprintf(stderr, \"%u\", value->uint32);\n\t\t\tbreak;\n\t\tcase 'i':\n\t\t\tfprintf(stderr, \"%d\", value->uint32);\n\t\t\tbreak;\n\t\tcase 's':\n\t\t\tfprintf(stderr, \"\\\"%s\\\"\", value->string);\n\t\t\tbreak;\n\t\tcase 'o':\n\t\t\tif (value->object)\n\t\t\t\tfprintf(stderr, \"%s@%u\",\n\t\t\t\t\tvalue->object->interface->name,\n\t\t\t\t\tvalue->object->id);\n\t\t\telse\n\t\t\t\tfprintf(stderr, \"nil\");\n\t\t\tbreak;\n\t\tcase 'n':\n\t\t\tfprintf(stderr, \"new id %u\", value->uint32);\n\t\t\tbreak;\n\t\tcase 'a':\n\t\t\tfprintf(stderr, \"array\");\n\t\t\tbreak;\n\t\tcase 'h':\n\t\t\tfprintf(stderr, \"fd %d\", value->uint32);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tfprintf(stderr, \")\\n\");\n}", "func_src_after": "wl_closure_print(struct wl_closure *closure, struct wl_object *target, int send)\n{\n\tunion wl_value *value;\n\tint i;\n\tstruct timespec tp;\n\tunsigned int time;\n\n\tclock_gettime(CLOCK_REALTIME, &tp);\n\ttime = (tp.tv_sec * 1000000L) + (tp.tv_nsec / 1000);\n\n\tfprintf(stderr, \"[%10.3f] %s%s@%d.%s(\",\n\t\ttime / 1000.0,\n\t\tsend ? \" -> \" : \"\",\n\t\ttarget->interface->name, target->id,\n\t\tclosure->message->name);\n\n\tfor (i = 2; i < closure->count; i++) {\n\t\tif (i > 2)\n\t\t\tfprintf(stderr, \", \");\n\n\t\tvalue = closure->args[i];\n\t\tswitch (closure->message->signature[i - 2]) {\n\t\tcase 'u':\n\t\t\tfprintf(stderr, \"%u\", value->uint32);\n\t\t\tbreak;\n\t\tcase 'i':\n\t\t\tfprintf(stderr, \"%d\", value->uint32);\n\t\t\tbreak;\n\t\tcase 's':\n\t\t\tfprintf(stderr, \"\\\"%s\\\"\", value->string);\n\t\t\tbreak;\n\t\tcase 'o':\n\t\t\tif (value->object)\n\t\t\t\tfprintf(stderr, \"%s@%u\",\n\t\t\t\t\tvalue->object->interface->name,\n\t\t\t\t\tvalue->object->id);\n\t\t\telse\n\t\t\t\tfprintf(stderr, \"nil\");\n\t\t\tbreak;\n\t\tcase 'n':\n\t\t\tfprintf(stderr, \"new id %u\", value->uint32);\n\t\t\tbreak;\n\t\tcase 'a':\n\t\t\tfprintf(stderr, \"array\");\n\t\t\tbreak;\n\t\tcase 'h':\n\t\t\tfprintf(stderr, \"fd %d\", value->uint32);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tfprintf(stderr, \")\\n\");\n}", "line_changes": {"deleted": [{"line_no": 4, "char_start": 107, "char_end": 131, "line": "\tchar buffer[4] = \"\\0\";\n"}, {"line_no": 9, "char_start": 181, "char_end": 192, "line": "\tif (send)\n"}, {"line_no": 10, "char_start": 192, "char_end": 219, "line": "\t\tsprintf(buffer, \" -> \");\n"}, {"line_no": 11, "char_start": 219, "char_end": 220, "line": "\n"}, {"line_no": 17, "char_start": 370, "char_end": 380, "line": "\t\tbuffer,\n"}], "added": [{"line_no": 13, "char_start": 307, "char_end": 329, "line": "\t\tsend ? \" -> \" : \"\",\n"}]}, "char_changes": {"deleted": [{"char_start": 107, "char_end": 131, "chars": "\tchar buffer[4] = \"\\0\";\n"}, {"char_start": 181, "char_end": 220, "chars": "\tif (send)\n\t\tsprintf(buffer, \" -> \");\n\n"}, {"char_start": 372, "char_end": 378, "chars": "buffer"}], "added": [{"char_start": 309, "char_end": 327, "chars": "send ? \" -> \" : \"\""}]}, "commit_link": "github.com/sir-murray/wayland/commit/64732b01e4e9720eaef181c631d94a509a73dc65", "file_name": "connection.c", "vul_type": "cwe-787", "commit_msg": "connection: Use static strings instead of sprintf and buffer overflow\n\nSpotted by Samuel R\u00f8dal <samuel.rodal@nokia.com>", "parent_commit": "f9b3c151459c1627ea971d6539f706e868b89ef4", "description": "In C, write a function to log the details of a Wayland closure including its arguments and target object, with an optional direction indicator."}
{"func_name": "load_sample_environment_variables", "func_src_before": "  def load_sample_environment_variables\n    env_file = File.open('env_configuration_for_local_gem_tests.yml')\n\n    YAML.load(env_file).each do |key, value|\n      ENV[key.to_s] = value\n    end\n  end", "func_src_after": "  def load_sample_environment_variables\n    env_file = File.open('env_configuration_for_local_gem_tests.yml')\n\n    YAML.safe_load(env_file).each do |key, value|\n      ENV[key.to_s] = value\n    end\n  end", "line_changes": {"deleted": [{"line_no": 4, "char_start": 111, "char_end": 156, "line": "    YAML.load(env_file).each do |key, value|\n"}], "added": [{"line_no": 4, "char_start": 111, "char_end": 161, "line": "    YAML.safe_load(env_file).each do |key, value|\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 120, "char_end": 125, "chars": "safe_"}]}, "commit_link": "github.com/fastly/fastly_nsq/commit/c16a48dd2f7b0a67d02c3fae35f0ec9ffaea9839", "file_name": "spec_helper.rb", "vul_type": "cwe-502", "commit_msg": "rubocop YAML.safe_load over just load\n\nthis is the spec_helper and doesn't appear to affect the running of the\ntests...", "parent_commit": "f6b18edc68d1040afdedd59a75a167dcdc244f8e", "description": "Write a Ruby method to load environment variables from a YAML file."}
{"func_name": "create_or_update_repo", "func_src_before": "def create_or_update_repo(folder, which_branch):\n    print ('--------------------------------------------')\n    print (f'Create or update repo {folder}')\n\n    if not os.path.isdir(folder):\n        # if the repo doesn't already exist, create it\n        create_new_repo(folder,which_branch)\n\n    else:\n        os.chdir(folder)\n\n        # whether or not this repo was newly created, set the default HEAD\n        # on the origin repo\n        os.system(f'git symbolic-ref HEAD refs/heads/{which_branch}')\n\n        # if this repo has no branches with valid commits, add an\n        # empty commit to the specified branch so that the repository\n        # is not empty\n        add_empty_commit(folder,which_branch)\n        \n        \n    # set/correct the permissions of all files\n    os.chdir(folder)\n    for root, dirs, files in os.walk(folder):\n        for entry in files + dirs:\n            shutil.chown(os.path.join(root, entry), group=DAEMONCGI_GROUP)", "func_src_after": "def create_or_update_repo(folder, which_branch):\n    print ('--------------------------------------------')\n    print (f'Create or update repo {folder}')\n\n    if not os.path.isdir(folder):\n        # if the repo doesn't already exist, create it\n        create_new_repo(folder,which_branch)\n\n    else:\n        os.chdir(folder)\n\n        # whether or not this repo was newly created, set the default HEAD\n        # on the origin repo\n        subprocess.run(['git', 'symbolic-ref', 'HEAD', f'refs/heads/{which_branch}'])\n\n        # if this repo has no branches with valid commits, add an\n        # empty commit to the specified branch so that the repository\n        # is not empty\n        add_empty_commit(folder,which_branch)\n        \n        \n    # set/correct the permissions of all files\n    os.chdir(folder)\n    for root, dirs, files in os.walk(folder):\n        for entry in files + dirs:\n            shutil.chown(os.path.join(root, entry), group=DAEMONCGI_GROUP)", "line_changes": {"deleted": [{"line_no": 14, "char_start": 430, "char_end": 500, "line": "        os.system(f'git symbolic-ref HEAD refs/heads/{which_branch}')\n"}], "added": [{"line_no": 14, "char_start": 430, "char_end": 516, "line": "        subprocess.run(['git', 'symbolic-ref', 'HEAD', f'refs/heads/{which_branch}'])\n"}]}, "char_changes": {"deleted": [{"char_start": 438, "char_end": 472, "chars": "os.system(f'git symbolic-ref HEAD "}], "added": [{"char_start": 438, "char_end": 487, "chars": "subprocess.run(['git', 'symbolic-ref', 'HEAD', f'"}, {"char_start": 513, "char_end": 514, "chars": "]"}]}, "commit_link": "github.com/Submitty/Submitty/commit/d6eb04149be92b6c9f334570e746cb39e65098c5", "file_name": "generate_repos.py", "vul_type": "cwe-078", "commit_msg": "[SECURITY][Bugfix:System] Prevent generate_repos injection (#7903)\n\n* Replace os.system to subprocess\r\n\r\n* Update bin/generate_repos.py\r\n\r\nCo-authored-by: William Allen <16820599+williamjallen@users.noreply.github.com>\r\n\r\nCo-authored-by: William Allen <16820599+williamjallen@users.noreply.github.com>", "parent_commit": "1d6aed0c90c4ad468646c17e8537b876cddae41c", "description": "Write a Python function to manage a git repository by creating or updating it and setting file permissions."}
{"func_name": "al_segment_cwd_prefix", "func_src_before": "int al_segment_cwd_prefix(char** prompt, unsigned int* prompt_len, int* is_first, int* last_bg, int orientation) {\n    char text[16];\n\n    char prefix[16];\n    char home[64];\n    char cwd[512];\n    char *base = cwd;\n\n    if (al_get_home(home, 64) != 0) {\n        return -1;\n    }\n    if (al_get_cwd(cwd, 512) != 0) {\n        return -1;\n    }\n\n    // check if in home directory\n    if (al_string_startswith(cwd, home)) {\n        base = cwd+strlen(home);\n    }\n\n    // copy first path element into dirs buffer\n    if (al_get_dir_count(base) > CWD_LEN) {\n        strcpy(prefix, THREE_DOTS); // deep in hirarchy\n    } else if (al_string_startswith(cwd, home)) {\n        strcpy(prefix, \"~\"); // home directory\n    } else {\n        strcpy(prefix, \"/\"); // everywhere else\n    }\n\n    // add segment to prompt buffer\n    snprintf(text, 64, \" %s \", prefix);\n    al_gen_segment(prompt, prompt_len, COLOR_FG_CWD_PREFIX, COLOR_BG_CWD_PREFIX, FNT_BOLD, text, is_first, last_bg, orientation);\n\n    return 0;\n}", "func_src_after": "int al_segment_cwd_prefix(char** prompt, unsigned int* prompt_len, int* is_first, int* last_bg, int orientation) {\n    char text[16];\n\n    char prefix[16];\n    char home[64];\n    char cwd[512];\n    char *base = cwd;\n\n    if (al_get_home(home, 64) != 0) {\n        return -1;\n    }\n    if (al_get_cwd(cwd, 512) != 0) {\n        return -1;\n    }\n\n    // check if in home directory\n    if (al_string_startswith(cwd, home)) {\n        base = cwd+strlen(home);\n    }\n\n    // copy first path element into dirs buffer\n    if (al_get_dir_count(base) > CWD_LEN) {\n        strcpy(prefix, THREE_DOTS); // deep in hirarchy\n    } else if (al_string_startswith(cwd, home)) {\n        strcpy(prefix, \"~\"); // home directory\n    } else {\n        strcpy(prefix, \"/\"); // everywhere else\n    }\n\n    // add segment to prompt buffer\n    snprintf(text, 16, \" %s \", prefix);\n    al_gen_segment(prompt, prompt_len, COLOR_FG_CWD_PREFIX, COLOR_BG_CWD_PREFIX, FNT_BOLD, text, is_first, last_bg, orientation);\n\n    return 0;\n}", "line_changes": {"deleted": [{"line_no": 31, "char_start": 809, "char_end": 849, "line": "    snprintf(text, 64, \" %s \", prefix);\n"}], "added": [{"line_no": 31, "char_start": 809, "char_end": 849, "line": "    snprintf(text, 16, \" %s \", prefix);\n"}]}, "char_changes": {"deleted": [{"char_start": 829, "char_end": 830, "chars": "4"}], "added": [{"char_start": 828, "char_end": 829, "chars": "1"}]}, "commit_link": "github.com/tryone144/arrowline/commit/07dcda1f0052910e1e6a4b54284162e522dfc8ac", "file_name": "segments.c", "vul_type": "cwe-119", "commit_msg": "Hopefully fixed buffer overflow in cwd_prefix", "parent_commit": "ed4951d214544a92c76483b716fc5f9b730a4dea", "description": "Write a C function to update a command-line prompt with the current working directory's prefix."}
{"func_name": "reroute", "func_src_before": "@app.route('/<short_url>')\ndef reroute(short_url):\n\n\tconn = MySQLdb.connect(host , user , passwrd, db)\n\tcursor = conn.cursor()\n\tplatform = request.user_agent.platform\n\tbrowser =  request.user_agent.browser\n\tcounter = 1\n\n\t# Platform , Browser vars\n\t\n\tbrowser_dict = {'firefox': 0 , 'chrome':0 , 'safari':0 , 'other':0}\n\tplatform_dict = {'windows':0 , 'iphone':0 , 'android':0 , 'linux':0 , 'macos':0 , 'other':0}\n\n\t# Analytics\n\tif browser in browser_dict:\n\t\tbrowser_dict[browser] += 1\n\telse:\t\t\t\t\t\t\t\t\n\t\tbrowser_dict['other'] += 1\n\t\n\tif platform in platform_dict.iterkeys():\n\t\tplatform_dict[platform] += 1\n\telse:\n\t\tplatform_dict['other'] += 1\n\t\t\t\n\tcursor.execute(\"SELECT URL FROM WEB_URL WHERE S_URL = %s;\" ,(short_url,) )\n\n\ttry:\n\t\tnew_url = cursor.fetchone()[0]\n\t\tprint new_url\n\t\t# Update Counters \n\t\t\n\t\tcounter_sql = \"\\\n\t\t\t\tUPDATE {tn} SET COUNTER = COUNTER + {og_counter} , CHROME = CHROME + {og_chrome} , FIREFOX = FIREFOX+{og_firefox} ,\\\n\t\t\t\tSAFARI = SAFARI+{og_safari} , OTHER_BROWSER =OTHER_BROWSER+ {og_oth_brow} , ANDROID = ANDROID +{og_andr} , IOS = IOS +{og_ios},\\\n\t\t\t\tWINDOWS = WINDOWS+{og_windows} , LINUX = LINUX+{og_linux}  , MAC =MAC+ {og_mac} , OTHER_PLATFORM =OTHER_PLATFORM+ {og_plat_other} WHERE S_URL = '{surl}';\".\\\n\t\t\t\tformat(tn = \"WEB_URL\" , og_counter = counter , og_chrome = browser_dict['chrome'] , og_firefox = browser_dict['firefox'],\\\n\t\t\t\tog_safari = browser_dict['safari'] , og_oth_brow = browser_dict['other'] , og_andr = platform_dict['android'] , og_ios = platform_dict['iphone'] ,\\\n\t\t\t\tog_windows = platform_dict['windows'] , og_linux = platform_dict['linux'] , og_mac = platform_dict['macos'] , og_plat_other = platform_dict['other'] ,\\\n\t\t\t\tsurl = short_url)\n\t\tres_update = cursor.execute(counter_sql)\n\t\tconn.commit()\n\t\tconn.close()\n\n\t\treturn redirect(new_url)\n\n\texcept Exception as e:\n\t\te = \"Something went wrong.Please try again.\"\n\t\treturn render_template('404.html') ,404", "func_src_after": "@app.route('/<short_url>')\ndef reroute(short_url):\n\n\tconn = MySQLdb.connect(host , user , passwrd, db)\n\tcursor = conn.cursor()\n\tplatform = request.user_agent.platform\n\tbrowser =  request.user_agent.browser\n\tcounter = 1\n\n\t# Platform , Browser vars\n\t\n\tbrowser_dict = {'firefox': 0 , 'chrome':0 , 'safari':0 , 'other':0}\n\tplatform_dict = {'windows':0 , 'iphone':0 , 'android':0 , 'linux':0 , 'macos':0 , 'other':0}\n\n\t# Analytics\n\tif browser in browser_dict:\n\t\tbrowser_dict[browser] += 1\n\telse:\t\t\t\t\t\t\t\t\n\t\tbrowser_dict['other'] += 1\n\t\n\tif platform in platform_dict.iterkeys():\n\t\tplatform_dict[platform] += 1\n\telse:\n\t\tplatform_dict['other'] += 1\n\t\t\t\n\tcursor.execute(\"SELECT URL FROM WEB_URL WHERE S_URL = %s;\" ,(short_url,) )\n\n\ttry:\n\t\tnew_url = cursor.fetchone()[0]\n\t\tprint new_url\n\t\t# Update Counters \n\t\t\n\t\tcounter_sql = \"\\\n\t\t\t\tUPDATE {tn} SET COUNTER = COUNTER + {og_counter} , CHROME = CHROME + {og_chrome} , FIREFOX = FIREFOX+{og_firefox} ,\\\n\t\t\t\tSAFARI = SAFARI+{og_safari} , OTHER_BROWSER =OTHER_BROWSER+ {og_oth_brow} , ANDROID = ANDROID +{og_andr} , IOS = IOS +{og_ios},\\\n\t\t\t\tWINDOWS = WINDOWS+{og_windows} , LINUX = LINUX+{og_linux}  , MAC =MAC+ {og_mac} , OTHER_PLATFORM =OTHER_PLATFORM+ {og_plat_other} WHERE S_URL = %s;\".\\\n\t\t\t\tformat(tn = \"WEB_URL\" , og_counter = counter , og_chrome = browser_dict['chrome'] , og_firefox = browser_dict['firefox'],\\\n\t\t\t\tog_safari = browser_dict['safari'] , og_oth_brow = browser_dict['other'] , og_andr = platform_dict['android'] , og_ios = platform_dict['iphone'] ,\\\n\t\t\t\tog_windows = platform_dict['windows'] , og_linux = platform_dict['linux'] , og_mac = platform_dict['macos'] , og_plat_other = platform_dict['other'])\n\t\tres_update = cursor.execute(counter_sql, (short_url, ))\n\t\tconn.commit()\n\t\tconn.close()\n\n\t\treturn redirect(new_url)\n\n\texcept Exception as e:\n\t\te = \"Something went wrong.Please try again.\"\n\t\treturn render_template('404.html') ,404", "line_changes": {"deleted": [{"line_no": 36, "char_start": 1073, "char_end": 1234, "line": "\t\t\t\tWINDOWS = WINDOWS+{og_windows} , LINUX = LINUX+{og_linux}  , MAC =MAC+ {og_mac} , OTHER_PLATFORM =OTHER_PLATFORM+ {og_plat_other} WHERE S_URL = '{surl}';\".\\\n"}, {"line_no": 39, "char_start": 1513, "char_end": 1669, "line": "\t\t\t\tog_windows = platform_dict['windows'] , og_linux = platform_dict['linux'] , og_mac = platform_dict['macos'] , og_plat_other = platform_dict['other'] ,\\\n"}, {"line_no": 40, "char_start": 1669, "char_end": 1691, "line": "\t\t\t\tsurl = short_url)\n"}, {"line_no": 41, "char_start": 1691, "char_end": 1734, "line": "\t\tres_update = cursor.execute(counter_sql)\n"}], "added": [{"line_no": 36, "char_start": 1073, "char_end": 1228, "line": "\t\t\t\tWINDOWS = WINDOWS+{og_windows} , LINUX = LINUX+{og_linux}  , MAC =MAC+ {og_mac} , OTHER_PLATFORM =OTHER_PLATFORM+ {og_plat_other} WHERE S_URL = %s;\".\\\n"}, {"line_no": 39, "char_start": 1507, "char_end": 1661, "line": "\t\t\t\tog_windows = platform_dict['windows'] , og_linux = platform_dict['linux'] , og_mac = platform_dict['macos'] , og_plat_other = platform_dict['other'])\n"}, {"line_no": 40, "char_start": 1661, "char_end": 1719, "line": "\t\tres_update = cursor.execute(counter_sql, (short_url, ))\n"}]}, "char_changes": {"deleted": [{"char_start": 1221, "char_end": 1229, "chars": "'{surl}'"}, {"char_start": 1665, "char_end": 1689, "chars": " ,\\\n\t\t\t\tsurl = short_url"}], "added": [{"char_start": 1221, "char_end": 1223, "chars": "%s"}, {"char_start": 1702, "char_end": 1717, "chars": ", (short_url, )"}]}, "commit_link": "github.com/PadamSethia/shorty/commit/071497f90bcf7336c44e135d5ef4bd87898fa8d0", "file_name": "app.py", "vul_type": "cwe-089", "commit_msg": "Escape short_url to prevent SQL Injections", "description": "Write a Python Flask function to redirect a short URL to its original URL and update visit analytics in a MySQL database."}
{"func_name": "data", "func_src_before": "    def data\n      @data ||= YAML.load(File.read(path))\n    end", "func_src_after": "    def data\n      @data ||= YAML.safe_load(File.read(path))\n    end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 13, "char_end": 56, "line": "      @data ||= YAML.load(File.read(path))\n"}], "added": [{"line_no": 2, "char_start": 13, "char_end": 61, "line": "      @data ||= YAML.safe_load(File.read(path))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 34, "char_end": 39, "chars": "safe_"}]}, "commit_link": "github.com/agorf/feed2email/commit/7f01d4f94138173904be758e7423e2491c8ad7c6", "file_name": "config.rb", "vul_type": "cwe-502", "commit_msg": "Use YAML.safe_load to parse config", "parent_commit": "55bb971f8fbe1b994f78e69f37e59c11bc2328d4", "description": "Create a Ruby method named `data` that lazily loads and memoizes the contents of a YAML file from a given path."}
{"func_name": "NewHTTPSTransport", "func_src_before": "func NewHTTPSTransport(cc *tls.Config) *http.Transport {\n\t// this seems like a bad idea but was here in the previous version\n\tif cc != nil {\n\t\tcc.InsecureSkipVerify = true\n\t}\n\n\ttr := &http.Transport{\n\t\tProxy: http.ProxyFromEnvironment,\n\t\tDial: (&net.Dialer{\n\t\t\tTimeout:   30 * time.Second,\n\t\t\tKeepAlive: 30 * time.Second,\n\t\t}).Dial,\n\t\tTLSHandshakeTimeout: 10 * time.Second,\n\t\tTLSClientConfig:     cc,\n\t\tMaxIdleConnsPerHost: 25,\n\t}\n\n\treturn tr\n}", "func_src_after": "func NewHTTPSTransport(cc *tls.Config) *http.Transport {\n\ttr := &http.Transport{\n\t\tProxy: http.ProxyFromEnvironment,\n\t\tDial: (&net.Dialer{\n\t\t\tTimeout:   30 * time.Second,\n\t\t\tKeepAlive: 30 * time.Second,\n\t\t}).Dial,\n\t\tTLSHandshakeTimeout: 10 * time.Second,\n\t\tTLSClientConfig:     cc,\n\t\tMaxIdleConnsPerHost: 25,\n\t}\n\n\treturn tr\n}", "line_changes": {"deleted": [{"line_no": 3, "char_start": 125, "char_end": 141, "line": "\tif cc != nil {\n"}, {"line_no": 4, "char_start": 141, "char_end": 172, "line": "\t\tcc.InsecureSkipVerify = true\n"}, {"line_no": 5, "char_start": 172, "char_end": 175, "line": "\t}\n"}, {"line_no": 6, "char_start": 175, "char_end": 176, "line": "\n"}], "added": []}, "char_changes": {"deleted": [{"char_start": 57, "char_end": 176, "chars": "\t// this seems like a bad idea but was here in the previous version\n\tif cc != nil {\n\t\tcc.InsecureSkipVerify = true\n\t}\n\n"}], "added": []}, "commit_link": "github.com/miekg/coredns/commit/049369583bec9c6f3ab751cd68bcfc4224e7df45", "file_name": "tls.go", "vul_type": "cwe-295", "commit_msg": "pkg/tls: remove InsecureSkipVerify=true flag (#4265)\n\nCWE-295 code scanning alert flag this. Seems OK to just remove it.\r\n\r\nSigned-off-by: Miek Gieben <miek@miek.nl>", "parent_commit": "723e9b06a439bfce19d689aca7030d95e4dc2c19", "description": "Create a Go function that initializes a new HTTP transport with custom TLS configuration."}
{"func_name": "glyph_cache_put", "func_src_before": "BOOL glyph_cache_put(rdpGlyphCache* glyphCache, UINT32 id, UINT32 index, rdpGlyph* glyph)\n{\n\trdpGlyph* prevGlyph;\n\n\tif (id > 9)\n\t{\n\t\tWLog_ERR(TAG, \"invalid glyph cache id: %\" PRIu32 \"\", id);\n\t\treturn FALSE;\n\t}\n\n\tif (index > glyphCache->glyphCache[id].number)\n\t{\n\t\tWLog_ERR(TAG, \"invalid glyph cache index: %\" PRIu32 \" in cache id: %\" PRIu32 \"\", index, id);\n\t\treturn FALSE;\n\t}\n\n\tWLog_Print(glyphCache->log, WLOG_DEBUG, \"GlyphCachePut: id: %\" PRIu32 \" index: %\" PRIu32 \"\", id,\n\t           index);\n\tprevGlyph = glyphCache->glyphCache[id].entries[index];\n\n\tif (prevGlyph)\n\t\tprevGlyph->Free(glyphCache->context, prevGlyph);\n\n\tglyphCache->glyphCache[id].entries[index] = glyph;\n\treturn TRUE;\n}", "func_src_after": "BOOL glyph_cache_put(rdpGlyphCache* glyphCache, UINT32 id, UINT32 index, rdpGlyph* glyph)\n{\n\trdpGlyph* prevGlyph;\n\n\tif (id > 9)\n\t{\n\t\tWLog_ERR(TAG, \"invalid glyph cache id: %\" PRIu32 \"\", id);\n\t\treturn FALSE;\n\t}\n\n\tif (index >= glyphCache->glyphCache[id].number)\n\t{\n\t\tWLog_ERR(TAG, \"invalid glyph cache index: %\" PRIu32 \" in cache id: %\" PRIu32 \"\", index, id);\n\t\treturn FALSE;\n\t}\n\n\tWLog_Print(glyphCache->log, WLOG_DEBUG, \"GlyphCachePut: id: %\" PRIu32 \" index: %\" PRIu32 \"\", id,\n\t           index);\n\tprevGlyph = glyphCache->glyphCache[id].entries[index];\n\n\tif (prevGlyph)\n\t\tprevGlyph->Free(glyphCache->context, prevGlyph);\n\n\tglyphCache->glyphCache[id].entries[index] = glyph;\n\treturn TRUE;\n}", "commit_link": "github.com/FreeRDP/FreeRDP/commit/c0fd449ec0870b050d350d6d844b1ea6dad4bc7d", "file_name": "libfreerdp/cache/glyph.c", "vul_type": "cwe-125", "description": "Write a C function named `glyph_cache_put` that stores a glyph in a glyph cache, ensuring the cache ID and index are within valid bounds, and logs the operation."}
{"func_name": "copyaudiodata", "func_src_before": "bool copyaudiodata (AFfilehandle infile, AFfilehandle outfile, int trackid)\n{\n\tint frameSize = afGetVirtualFrameSize(infile, trackid, 1);\n\n\tconst int kBufferFrameCount = 65536;\n\tvoid *buffer = malloc(kBufferFrameCount * frameSize);\n\n\tAFframecount totalFrames = afGetFrameCount(infile, AF_DEFAULT_TRACK);\n\tAFframecount totalFramesWritten = 0;\n\n\tbool success = true;\n\n\twhile (totalFramesWritten < totalFrames)\n\t{\n\t\tAFframecount framesToRead = totalFrames - totalFramesWritten;\n\t\tif (framesToRead > kBufferFrameCount)\n\t\t\tframesToRead = kBufferFrameCount;\n\n\t\tAFframecount framesRead = afReadFrames(infile, trackid, buffer,\n\t\t\tframesToRead);\n\n\t\tif (framesRead < framesToRead)\n\t\t{\n\t\t\tfprintf(stderr, \"Bad read of audio track data.\\n\");\n\t\t\tsuccess = false;\n\t\t\tbreak;\n\t\t}\n\n\t\tAFframecount framesWritten = afWriteFrames(outfile, trackid, buffer,\n\t\t\tframesRead);\n\n\t\tif (framesWritten < framesRead)\n\t\t{\n\t\t\tfprintf(stderr, \"Bad write of audio track data.\\n\");\n\t\t\tsuccess = false;\n\t\t\tbreak;\n\t\t}\n\n\t\ttotalFramesWritten += framesWritten;\n\t}\n\n\tfree(buffer);\n\n\treturn success;\n}", "func_src_after": "bool copyaudiodata (AFfilehandle infile, AFfilehandle outfile, int trackid)\n{\n\tint frameSize = afGetVirtualFrameSize(infile, trackid, 1);\n\n\tint kBufferFrameCount = 65536;\n\tint bufferSize;\n\twhile (multiplyCheckOverflow(kBufferFrameCount, frameSize, &bufferSize))\n\t\tkBufferFrameCount /= 2;\n\tvoid *buffer = malloc(bufferSize);\n\n\tAFframecount totalFrames = afGetFrameCount(infile, AF_DEFAULT_TRACK);\n\tAFframecount totalFramesWritten = 0;\n\n\tbool success = true;\n\n\twhile (totalFramesWritten < totalFrames)\n\t{\n\t\tAFframecount framesToRead = totalFrames - totalFramesWritten;\n\t\tif (framesToRead > kBufferFrameCount)\n\t\t\tframesToRead = kBufferFrameCount;\n\n\t\tAFframecount framesRead = afReadFrames(infile, trackid, buffer,\n\t\t\tframesToRead);\n\n\t\tif (framesRead < framesToRead)\n\t\t{\n\t\t\tfprintf(stderr, \"Bad read of audio track data.\\n\");\n\t\t\tsuccess = false;\n\t\t\tbreak;\n\t\t}\n\n\t\tAFframecount framesWritten = afWriteFrames(outfile, trackid, buffer,\n\t\t\tframesRead);\n\n\t\tif (framesWritten < framesRead)\n\t\t{\n\t\t\tfprintf(stderr, \"Bad write of audio track data.\\n\");\n\t\t\tsuccess = false;\n\t\t\tbreak;\n\t\t}\n\n\t\ttotalFramesWritten += framesWritten;\n\t}\n\n\tfree(buffer);\n\n\treturn success;\n}", "commit_link": "github.com/antlarr/audiofile/commit/7d65f89defb092b63bcbc5d98349fb222ca73b3c", "file_name": "sfcommands/sfconvert.c", "vul_type": "cwe-190", "description": "Write a C function named `copyaudiodata` that copies audio data from one file to another for a specified track ID, handling memory allocation and error checking."}
{"func_name": "sh_op", "func_src_before": "static int sh_op(RAnal *anal, RAnalOp *op, ut64 addr, const ut8 *data, int len) {\n\tut8 op_MSB,op_LSB;\n\tint ret;\n\tif (!data)\n\t\treturn 0;\n\tmemset (op, '\\0', sizeof (RAnalOp));\n\top->addr = addr;\n\top->type = R_ANAL_OP_TYPE_UNK;\n\top->jump = op->fail = -1;\n\top->ptr = op->val = -1;\n\n\top->size = 2;\n\n\top_MSB = anal->big_endian? data[0]: data[1];\n\top_LSB = anal->big_endian? data[1]: data[0];\n\tret =  first_nibble_decode[(op_MSB>>4) & 0x0F](anal, op, (ut16)(op_MSB<<8 | op_LSB));\n\treturn ret;\n}", "func_src_after": "static int sh_op(RAnal *anal, RAnalOp *op, ut64 addr, const ut8 *data, int len) {\n\tut8 op_MSB,op_LSB;\n\tint ret;\n\tif (!data || len < 2) {\n\t\treturn 0;\n\t}\n\tmemset (op, '\\0', sizeof (RAnalOp));\n\top->addr = addr;\n\top->type = R_ANAL_OP_TYPE_UNK;\n\top->jump = op->fail = -1;\n\top->ptr = op->val = -1;\n\n\top->size = 2;\n\n\top_MSB = anal->big_endian? data[0]: data[1];\n\top_LSB = anal->big_endian? data[1]: data[0];\n\tret =  first_nibble_decode[(op_MSB>>4) & 0x0F](anal, op, (ut16)(op_MSB<<8 | op_LSB));\n\treturn ret;\n}", "commit_link": "github.com/radare/radare2/commit/77c47cf873dd55b396da60baa2ca83bbd39e4add", "file_name": "libr/anal/p/anal_sh.c", "vul_type": "cwe-125", "description": "Write a C function named `sh_op` that initializes an `RAnalOp` structure for a given operation."}
{"func_name": "create_new_repo", "func_src_before": "def create_new_repo(folder, which_branch):\n\n    # create the folder & initialize an empty bare repo\n    os.makedirs(folder, mode=0o770)\n    os.chdir(folder)\n    # note: --initial-branch option requires git 2.28.0 or greater\n    os.system(f'git init --bare --shared --initial-branch={which_branch}')\n\n    # unfortuantely, when an empty repo with no branches is cloned,\n    # the active branch and HEAD does NOT default to the specified branch\n\n    # so let's manually specify the initial branch\n    os.system(f'git symbolic-ref HEAD refs/heads/{which_branch}')\n\n    # and explicitly add an empty commit to the specified branch\n    # so that the repository is not empty\n    add_empty_commit(folder,which_branch)\n\n    print(f'Created new repo {folder}')", "func_src_after": "def create_new_repo(folder, which_branch):\n\n    # create the folder & initialize an empty bare repo\n    os.makedirs(folder, mode=0o770)\n    os.chdir(folder)\n    # note: --initial-branch option requires git 2.28.0 or greater\n    subprocess.run(['git', 'init', '--bare', '--shared', f'--initial-branch={which_branch}'])\n\n    # unfortuantely, when an empty repo with no branches is cloned,\n    # the active branch and HEAD does NOT default to the specified branch\n\n    # so let's manually specify the initial branch\n    subprocess.run(['git', 'symbolic-ref', 'HEAD', f'refs/heads/{which_branch}'])\n\n    # and explicitly add an empty commit to the specified branch\n    # so that the repository is not empty\n    add_empty_commit(folder,which_branch)\n\n    print(f'Created new repo {folder}')", "line_changes": {"deleted": [{"line_no": 7, "char_start": 224, "char_end": 299, "line": "    os.system(f'git init --bare --shared --initial-branch={which_branch}')\n"}, {"line_no": 13, "char_start": 494, "char_end": 560, "line": "    os.system(f'git symbolic-ref HEAD refs/heads/{which_branch}')\n"}], "added": [{"line_no": 7, "char_start": 224, "char_end": 318, "line": "    subprocess.run(['git', 'init', '--bare', '--shared', f'--initial-branch={which_branch}'])\n"}, {"line_no": 13, "char_start": 513, "char_end": 595, "line": "    subprocess.run(['git', 'symbolic-ref', 'HEAD', f'refs/heads/{which_branch}'])\n"}]}, "char_changes": {"deleted": [{"char_start": 228, "char_end": 249, "chars": "os.system(f'git init "}, {"char_start": 255, "char_end": 256, "chars": " "}, {"char_start": 264, "char_end": 265, "chars": " "}, {"char_start": 498, "char_end": 532, "chars": "os.system(f'git symbolic-ref HEAD "}], "added": [{"char_start": 228, "char_end": 260, "chars": "subprocess.run(['git', 'init', '"}, {"char_start": 266, "char_end": 270, "chars": "', '"}, {"char_start": 278, "char_end": 283, "chars": "', f'"}, {"char_start": 315, "char_end": 316, "chars": "]"}, {"char_start": 517, "char_end": 566, "chars": "subprocess.run(['git', 'symbolic-ref', 'HEAD', f'"}, {"char_start": 592, "char_end": 593, "chars": "]"}]}, "commit_link": "github.com/Submitty/Submitty/commit/d6eb04149be92b6c9f334570e746cb39e65098c5", "file_name": "generate_repos.py", "vul_type": "cwe-078", "commit_msg": "[SECURITY][Bugfix:System] Prevent generate_repos injection (#7903)\n\n* Replace os.system to subprocess\r\n\r\n* Update bin/generate_repos.py\r\n\r\nCo-authored-by: William Allen <16820599+williamjallen@users.noreply.github.com>\r\n\r\nCo-authored-by: William Allen <16820599+williamjallen@users.noreply.github.com>", "parent_commit": "1d6aed0c90c4ad468646c17e8537b876cddae41c", "description": "Write a Python function to initialize a new Git repository with a specified branch in a given folder."}
{"func_name": "run", "func_src_before": "func run() error {\n\tpriv, err := rsa.GenerateKey(rand.Reader, 1024)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tprivf, err := os.OpenFile(\"priv.key\", os.O_WRONLY|os.O_CREATE|os.O_TRUNC, 0600)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer privf.Close()\n\n\tprivblock := &pem.Block{\n\t\tType:  \"RSA PRIVATE KEY\",\n\t\tBytes: x509.MarshalPKCS1PrivateKey(priv),\n\t}\n\n\tif err := pem.Encode(privf, privblock); err != nil {\n\t\tos.Remove(privf.Name())\n\t\treturn err\n\t}\n\n\tpub, err := x509.MarshalPKIXPublicKey(priv.Public())\n\tif err != nil {\n\t\tos.Remove(privf.Name())\n\t\treturn err\n\t}\n\n\tpubf, err := os.OpenFile(\"pub.key\", os.O_WRONLY|os.O_CREATE|os.O_TRUNC, 0600)\n\tif err != nil {\n\t\tos.Remove(privf.Name())\n\t\treturn err\n\t}\n\tdefer pubf.Close()\n\n\tpubblock := &pem.Block{\n\t\tType:  \"PUBLIC KEY\",\n\t\tBytes: pub,\n\t}\n\n\tif err := pem.Encode(pubf, pubblock); err != nil {\n\t\tos.Remove(privf.Name())\n\t\tos.Remove(pubf.Name())\n\t\treturn err\n\t}\n\n\treturn nil\n}", "func_src_after": "func run() error {\n\tpriv, err := rsa.GenerateMultiPrimeKey(rand.Reader, 3, 2048)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tprivf, err := os.OpenFile(\"priv.key\", os.O_WRONLY|os.O_CREATE|os.O_TRUNC, 0600)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer privf.Close()\n\n\tprivblock := &pem.Block{\n\t\tType:  \"RSA PRIVATE KEY\",\n\t\tBytes: x509.MarshalPKCS1PrivateKey(priv),\n\t}\n\n\tif err := pem.Encode(privf, privblock); err != nil {\n\t\tos.Remove(privf.Name())\n\t\treturn err\n\t}\n\n\tpub, err := x509.MarshalPKIXPublicKey(priv.Public())\n\tif err != nil {\n\t\tos.Remove(privf.Name())\n\t\treturn err\n\t}\n\n\tpubf, err := os.OpenFile(\"pub.key\", os.O_WRONLY|os.O_CREATE|os.O_TRUNC, 0600)\n\tif err != nil {\n\t\tos.Remove(privf.Name())\n\t\treturn err\n\t}\n\tdefer pubf.Close()\n\n\tpubblock := &pem.Block{\n\t\tType:  \"PUBLIC KEY\",\n\t\tBytes: pub,\n\t}\n\n\tif err := pem.Encode(pubf, pubblock); err != nil {\n\t\tos.Remove(privf.Name())\n\t\tos.Remove(pubf.Name())\n\t\treturn err\n\t}\n\n\treturn nil\n}", "line_changes": {"deleted": [{"line_no": 2, "char_start": 19, "char_end": 68, "line": "\tpriv, err := rsa.GenerateKey(rand.Reader, 1024)\n"}], "added": [{"line_no": 2, "char_start": 19, "char_end": 81, "line": "\tpriv, err := rsa.GenerateMultiPrimeKey(rand.Reader, 3, 2048)\n"}]}, "char_changes": {"deleted": [{"char_start": 62, "char_end": 66, "chars": "1024"}], "added": [{"char_start": 45, "char_end": 55, "chars": "MultiPrime"}, {"char_start": 72, "char_end": 79, "chars": "3, 2048"}]}, "commit_link": "github.com/carl-mastrangelo/pixur/commit/d2bc8ec79aa4f2b68ec14a2d6cd5a305b6e05dd1", "file_name": "genkeys.go", "vul_type": "cwe-326", "commit_msg": "Use multiprime rsa keys, and bump to 2048 bits", "parent_commit": "547289bc91415ef039e318ce6b0b53b16b66998b", "description": "Write a Go function to generate an RSA key pair and save them to files."}
{"func_name": "(anonymous)", "func_src_before": "      (err, data) => {\n        if (err) {\n          if (!fs.existsSync(safeFileFullPath)) {\n            var EnoentError = `Requested metadata for ${metaFileName} not found`\n            logger.log2('error', EnoentError)\n            res.status(404).send(EnoentError)\n          } else {\n            res.status(500).send(`An error occurred: ${err}`)\n            logger.log2('error', err)\n          }\n        } else {\n          res.status(200).set('Content-Type', 'text/xml').send(String(data))\n        }\n      })", "func_src_after": "      (err, data) => {\n        if (err) {\n          if (!fs.existsSync(safeFileFullPath)) {\n            var EnoentError = `Requested metadata for ${metaFileName} not found`\n            logger.log2('error', EnoentError)\n            res.status(404).send('Requested metadata not found')\n          } else {\n            res.status(500).send(`An error occurred: ${err}`)\n            logger.log2('error', err)\n          }\n        } else {\n          res.status(200).set('Content-Type', 'text/xml').send(String(data))\n        }\n      })", "line_changes": {"deleted": [{"line_no": 6, "char_start": 219, "char_end": 265, "line": "            res.status(404).send(EnoentError)\n"}], "added": [{"line_no": 6, "char_start": 219, "char_end": 284, "line": "            res.status(404).send('Requested metadata not found')\n"}]}, "char_changes": {"deleted": [{"char_start": 252, "char_end": 263, "chars": "EnoentError"}], "added": [{"char_start": 252, "char_end": 282, "chars": "'Requested metadata not found'"}]}, "commit_link": "github.com/GluuFederation/gluu-passport/commit/1738306ec44daf5e3e5a0b31852a68149f63071e", "file_name": "routes.js", "vul_type": "cwe-079", "commit_msg": "fix(routes.js): remove metadata input name on outgoing request\n\nMitigate cross-site scripting on error\n\nfix #137", "description": "In JavaScript, write a callback function that handles file read errors, logs them, sends appropriate HTTP status codes and messages, and returns the file data as text/xml if no error occurs."}
{"func_name": "voutf", "func_src_before": "static void voutf(struct GlobalConfig *config,\n                  const char *prefix,\n                  const char *fmt,\n                  va_list ap)\n{\n  size_t width = (79 - strlen(prefix));\n  if(!config->mute) {\n    size_t len;\n    char *ptr;\n    char *print_buffer;\n\n    print_buffer = curlx_mvaprintf(fmt, ap);\n    if(!print_buffer)\n      return;\n    len = strlen(print_buffer);\n\n    ptr = print_buffer;\n    while(len > 0) {\n      fputs(prefix, config->errors);\n\n      if(len > width) {\n        size_t cut = width-1;\n\n        while(!ISSPACE(ptr[cut]) && cut) {\n          cut--;\n        }\n        if(0 == cut)\n          /* not a single cutting position was found, just cut it at the\n             max text width then! */\n          cut = width-1;\n\n        (void)fwrite(ptr, cut + 1, 1, config->errors);\n        fputs(\"\\n\", config->errors);\n        ptr += cut + 1; /* skip the space too */\n        len -= cut;\n      }\n      else {\n        fputs(ptr, config->errors);\n        len = 0;\n      }\n    }\n    curl_free(print_buffer);\n  }\n}", "func_src_after": "static void voutf(struct GlobalConfig *config,\n                  const char *prefix,\n                  const char *fmt,\n                  va_list ap)\n{\n  size_t width = (79 - strlen(prefix));\n  if(!config->mute) {\n    size_t len;\n    char *ptr;\n    char *print_buffer;\n\n    print_buffer = curlx_mvaprintf(fmt, ap);\n    if(!print_buffer)\n      return;\n    len = strlen(print_buffer);\n\n    ptr = print_buffer;\n    while(len > 0) {\n      fputs(prefix, config->errors);\n\n      if(len > width) {\n        size_t cut = width-1;\n\n        while(!ISSPACE(ptr[cut]) && cut) {\n          cut--;\n        }\n        if(0 == cut)\n          /* not a single cutting position was found, just cut it at the\n             max text width then! */\n          cut = width-1;\n\n        (void)fwrite(ptr, cut + 1, 1, config->errors);\n        fputs(\"\\n\", config->errors);\n        ptr += cut + 1; /* skip the space too */\n        len -= cut + 1;\n      }\n      else {\n        fputs(ptr, config->errors);\n        len = 0;\n      }\n    }\n    curl_free(print_buffer);\n  }\n}", "commit_link": "github.com/curl/curl/commit/d530e92f59ae9bb2d47066c3c460b25d2ffeb211", "file_name": "src/tool_msgs.c", "vul_type": "cwe-125", "description": "Write a C function named `voutf` that formats and outputs a string with a prefix to an error stream, wrapping lines to a maximum width."}
{"func_name": "__init__", "func_src_before": "    def __init__(self, config_fname=None):\n        config_fname = config_fname or self.config_fname\n        fo = open(config_fname, \"r\")\n        blob = fo.read()\n        fo.close()\n        self.config = yaml.load(blob)", "func_src_after": "    def __init__(self, config_fname=None):\n        config_fname = config_fname or self.config_fname\n        fo = open(config_fname, \"r\")\n        blob = fo.read()\n        fo.close()\n        yaml=YAML(typ='safe')\n        self.config = yaml.load(blob)", "line_changes": {"deleted": [], "added": [{"line_no": 6, "char_start": 181, "char_end": 211, "line": "        yaml=YAML(typ='safe')\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 181, "char_end": 211, "chars": "        yaml=YAML(typ='safe')\n"}]}, "commit_link": "github.com/royrapoport/destalinator/commit/660ccd202e627cc8938a47532c7607edc676963f", "file_name": "config.py", "vul_type": "cwe-502", "commit_msg": "fix for YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe.", "parent_commit": "ef4a53784cd0026947df3f58cab3657a24e91112", "description": "Write a Python class initializer that reads a configuration file using YAML."}
{"func_name": "wiki_handle_http_request", "func_src_before": "wiki_handle_http_request(HttpRequest *req)\n{\n  HttpResponse *res      = http_response_new(req);\n  char         *page     = http_request_get_path_info(req); \n  char         *command  = http_request_get_query_string(req); \n  char         *wikitext = \"\";\n\n  util_dehttpize(page); \t/* remove any encoding on the requested\n\t\t\t\t   page name.                           */\n\n  if (!strcmp(page, \"/\"))\n    {\n      if (access(\"WikiHome\", R_OK) != 0)\n\twiki_redirect(res, \"/WikiHome?create\");\n      page = \"/WikiHome\";\n    }\n\n  if (!strcmp(page, \"/styles.css\"))\n    {\n      /*  Return CSS page */\n      http_response_set_content_type(res, \"text/css\");\n      http_response_printf(res, \"%s\", CssData);\n      http_response_send(res);\n      exit(0);\n    }\n\n  if (!strcmp(page, \"/favicon.ico\"))\n    {\n      /*  Return favicon */\n      http_response_set_content_type(res, \"image/ico\");\n      http_response_set_data(res, FaviconData, FaviconDataLen);\n      http_response_send(res);\n      exit(0);\n    }\n\n\n  page = page + 1; \t\t/* skip slash */\n\n  if (!strncmp(page, \"api/\", 4))\n    {\n      char *p;\n\n      page += 4; \n      for (p=page; *p != '\\0'; p++)\n\tif (*p=='?') { *p ='\\0'; break; }\n      \n      wiki_handle_rest_call(req, res, page); \n      exit(0);\n    }\n\n  /* A little safety. issue a malformed request for any paths,\n   * There shouldn't need to be any..\n   */\n  if (strchr(page, '/'))\n    {\n      http_response_set_status(res, 404, \"Not Found\");\n      http_response_printf(res, \"<html><body>404 Not Found</body></html>\\n\");\n      http_response_send(res);\n      exit(0);\n    }\n\n  if (!strcmp(page, \"Changes\"))\n    {\n      wiki_show_changes_page(res);\n    }\n  else if (!strcmp(page, \"ChangesRss\"))\n    {\n      wiki_show_changes_page_rss(res);\n    }\n  else if (!strcmp(page, \"Search\"))\n    {\n      wiki_show_search_results_page(res, http_request_param_get(req, \"expr\"));\n    }\n  else if (!strcmp(page, \"Create\"))\n    {\n      if ( (wikitext = http_request_param_get(req, \"title\")) != NULL)\n\t{\n\t  /* create page and redirect */\n\t  wiki_redirect(res, http_request_param_get(req, \"title\"));\n\t}\n      else\n\t{\n\t   /* show create page form  */\n\t  wiki_show_create_page(res);\n\t}\n    }\n  else\n    {\n      /* TODO: dont blindly write wikitext data to disk */\n      if ( (wikitext = http_request_param_get(req, \"wikitext\")) != NULL)\n\t{\n\t  file_write(page, wikitext);\t      \n\t}\n\n      if (access(page, R_OK) == 0) \t/* page exists */\n\t{\n\t  wikitext = file_read(page);\n\t  \n\t  if (!strcmp(command, \"edit\"))\n\t    {\n\t      /* print edit page */\n\t      wiki_show_edit_page(res, wikitext, page);\n\t    }\n\t  else\n\t    {\n\t      wiki_show_page(res, wikitext, page);\n\t    }\n\t}\n      else\n\t{\n\t  if (!strcmp(command, \"create\"))\n\t    {\n\t      wiki_show_edit_page(res, NULL, page);\n\t    }\n\t  else\n\t    {\n\t      char buf[1024];\n\t      snprintf(buf, 1024, \"%s?create\", page);\n\t      wiki_redirect(res, buf);\n\t    }\n\t}\n    }\n\n}", "func_src_after": "wiki_handle_http_request(HttpRequest *req)\n{\n  HttpResponse *res      = http_response_new(req);\n  char         *page     = http_request_get_path_info(req); \n  char         *command  = http_request_get_query_string(req); \n  char         *wikitext = \"\";\n\n  util_dehttpize(page); \t/* remove any encoding on the requested\n\t\t\t\t   page name.                           */\n\n  if (!strcmp(page, \"/\"))\n    {\n      if (access(\"WikiHome\", R_OK) != 0)\n\twiki_redirect(res, \"/WikiHome?create\");\n      page = \"/WikiHome\";\n    }\n\n  if (!strcmp(page, \"/styles.css\"))\n    {\n      /*  Return CSS page */\n      http_response_set_content_type(res, \"text/css\");\n      http_response_printf(res, \"%s\", CssData);\n      http_response_send(res);\n      exit(0);\n    }\n\n  if (!strcmp(page, \"/favicon.ico\"))\n    {\n      /*  Return favicon */\n      http_response_set_content_type(res, \"image/ico\");\n      http_response_set_data(res, FaviconData, FaviconDataLen);\n      http_response_send(res);\n      exit(0);\n    }\n\n\n  page = page + 1; \t\t/* skip slash */\n\n  if (!strncmp(page, \"api/\", 4))\n    {\n      char *p;\n\n      page += 4; \n      for (p=page; *p != '\\0'; p++)\n\tif (*p=='?') { *p ='\\0'; break; }\n      \n      wiki_handle_rest_call(req, res, page); \n      exit(0);\n    }\n\n  /* A little safety. issue a malformed request for any paths,\n   * There shouldn't need to be any..\n   */\n  if (!page_name_is_good(page))\n    {\n      http_response_set_status(res, 404, \"Not Found\");\n      http_response_printf(res, \"<html><body>404 Not Found</body></html>\\n\");\n      http_response_send(res);\n      exit(0);\n    }\n\n  if (!strcmp(page, \"Changes\"))\n    {\n      wiki_show_changes_page(res);\n    }\n  else if (!strcmp(page, \"ChangesRss\"))\n    {\n      wiki_show_changes_page_rss(res);\n    }\n  else if (!strcmp(page, \"Search\"))\n    {\n      wiki_show_search_results_page(res, http_request_param_get(req, \"expr\"));\n    }\n  else if (!strcmp(page, \"Create\"))\n    {\n      if ( (wikitext = http_request_param_get(req, \"title\")) != NULL)\n\t{\n\t  /* create page and redirect */\n\t  wiki_redirect(res, http_request_param_get(req, \"title\"));\n\t}\n      else\n\t{\n\t   /* show create page form  */\n\t  wiki_show_create_page(res);\n\t}\n    }\n  else\n    {\n      /* TODO: dont blindly write wikitext data to disk */\n      if ( (wikitext = http_request_param_get(req, \"wikitext\")) != NULL)\n\t{\n\t  file_write(page, wikitext);\t      \n\t}\n\n      if (access(page, R_OK) == 0) \t/* page exists */\n\t{\n\t  wikitext = file_read(page);\n\t  \n\t  if (!strcmp(command, \"edit\"))\n\t    {\n\t      /* print edit page */\n\t      wiki_show_edit_page(res, wikitext, page);\n\t    }\n\t  else\n\t    {\n\t      wiki_show_page(res, wikitext, page);\n\t    }\n\t}\n      else\n\t{\n\t  if (!strcmp(command, \"create\"))\n\t    {\n\t      wiki_show_edit_page(res, NULL, page);\n\t    }\n\t  else\n\t    {\n\t      char buf[1024];\n\t      snprintf(buf, 1024, \"%s?create\", page);\n\t      wiki_redirect(res, buf);\n\t    }\n\t}\n    }\n\n}", "commit_link": "github.com/yarolig/didiwiki/commit/5e5c796617e1712905dc5462b94bd5e6c08d15ea", "file_name": "src/wiki.c", "vul_type": "cwe-022", "description": "In C, write a function to handle HTTP requests for a simple wiki, including serving static files, API calls, and wiki page creation or editing."}
{"func_name": "write_section", "func_src_before": "    def write_section(self, section_name, section_data):\n        self.write_line(\"\")\n        self.write_line(\"define %s {\" % section_name)\n        sorted_keys = section_data.keys()\n        sorted_keys.sort()\n        for key in sorted_keys:\n            value = section_data[key]\n            self.icinga_lines.append((\"%s%-45s%s\" % (self.indent, key, self.value_to_icinga(value))))\n        self.write_line(\"}\")", "func_src_after": "    def write_section(self, section_name, section_data):\n        self.write_line(\"\")\n        self.write_line(\"define %s {\" % section_name)\n        sorted_keys = section_data.keys()\n        sorted_keys.sort()\n        for key in sorted_keys:\n            value = self.value_to_icinga(section_data[key])\n            icinga_line = \"%s%-45s%s\" % (self.indent, key, value)\n\n            if \"\\n\" in icinga_line or \"}\" in icinga_line:\n                msg = \"Found forbidden newline or '}' character in section %r.\"\n                raise Exception(msg % section_name)\n\n            self.icinga_lines.append(icinga_line)\n        self.write_line(\"}\")", "commit_link": "github.com/Scout24/monitoring-config-generator/commit/a4b01b72d2e3d6ec2600c384a77f675fa9bbf6b7", "file_name": "src/main/python/monitoring_config_generator/MonitoringConfigGenerator.py", "vul_type": "cwe-078", "description": "In Python, write a function to format and append a configuration section with sorted keys to a list, ensuring no newlines or closing braces are present in the values."}
{"func_name": "self.read", "func_src_before": "  def self.read(path=default_path)\n    perm = File.stat(path).mode & 0777\n    if perm != 0600 && !(WINDOWS)\n      raise Error, \"Permission bits for '#{path}' should be 0600, but are \"+perm.to_s(8)\n    end\n    new(path, parse(lex(IO.readlines(path))))\n  rescue Errno::ENOENT\n    new(path, parse(lex([])))\n  end", "func_src_after": "  def self.read(path=default_path)\n    perm = File.stat(path).mode & 0777\n    if perm != 0600 && !(WINDOWS)\n      raise Error, \"Permission bits for '#{path}' should be 0600, but are \"+perm.to_s(8)\n    end\n    new(path, parse(lex(File.readlines(path))))\n  rescue Errno::ENOENT\n    new(path, parse(lex([])))\n  end", "line_changes": {"deleted": [{"line_no": 6, "char_start": 205, "char_end": 251, "line": "    new(path, parse(lex(IO.readlines(path))))\n"}], "added": [{"line_no": 6, "char_start": 205, "char_end": 253, "line": "    new(path, parse(lex(File.readlines(path))))\n"}]}, "char_changes": {"deleted": [{"char_start": 229, "char_end": 231, "chars": "IO"}], "added": [{"char_start": 229, "char_end": 233, "chars": "File"}]}, "commit_link": "github.com/trevorgrayson/netrc/commit/544dc4b092d63d3df588ef61274cc32ad1376b02", "file_name": "netrc.rb", "vul_type": "cwe-078", "commit_msg": "use File.readlines instead of IO.readlines", "parent_commit": "41618416a23ff3b5ecd596c6f8eee1bba363a6ef", "description": "Create a Ruby method that reads from a file at a given path, checks for specific file permissions, and handles the case where the file does not exist."}
{"func_name": "html_content", "func_src_before": "    @property\n    async def html_content(self):\n        content = await self.content\n        if not content:\n            return ''\n        return markdown(content)", "func_src_after": "    @property\n    async def html_content(self):\n        content = markupsafe.escape(await self.content)\n        if not content:\n            return ''\n        return markdown(content)", "commit_link": "github.com/dongweiming/lyanna/commit/fcefac79e4b7601e81a3b3fe0ad26ab18ee95d7d", "file_name": "models/comment.py", "vul_type": "cwe-079", "description": "Generate a Python async property method that converts stored content to HTML, handling empty content and ensuring safe markup."}
{"func_name": "SpliceImage", "func_src_before": "MagickExport Image *SpliceImage(const Image *image,\n  const RectangleInfo *geometry,ExceptionInfo *exception)\n{\n#define SpliceImageTag  \"Splice/Image\"\n\n  CacheView\n    *image_view,\n    *splice_view;\n\n  Image\n    *splice_image;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    progress;\n\n  RectangleInfo\n    splice_geometry;\n\n  ssize_t\n    y;\n\n  /*\n    Allocate splice image.\n  */\n  assert(image != (const Image *) NULL);\n  assert(image->signature == MagickCoreSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  assert(geometry != (const RectangleInfo *) NULL);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  splice_geometry=(*geometry);\n  splice_image=CloneImage(image,image->columns+splice_geometry.width,\n    image->rows+splice_geometry.height,MagickTrue,exception);\n  if (splice_image == (Image *) NULL)\n    return((Image *) NULL);\n  if (SetImageStorageClass(splice_image,DirectClass,exception) == MagickFalse)\n    {\n      splice_image=DestroyImage(splice_image);\n      return((Image *) NULL);\n    }\n  if ((IsPixelInfoGray(&splice_image->background_color) == MagickFalse) &&\n      (IsGrayColorspace(splice_image->colorspace) != MagickFalse))\n    (void) SetImageColorspace(splice_image,sRGBColorspace,exception);\n  if ((splice_image->background_color.alpha_trait != UndefinedPixelTrait) &&\n      (splice_image->alpha_trait == UndefinedPixelTrait))\n    (void) SetImageAlpha(splice_image,OpaqueAlpha,exception);\n  (void) SetImageBackgroundColor(splice_image,exception);\n  /*\n    Respect image geometry.\n  */\n  switch (image->gravity)\n  {\n    default:\n    case UndefinedGravity:\n    case NorthWestGravity:\n      break;\n    case NorthGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width/2;\n      break;\n    }\n    case NorthEastGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width;\n      break;\n    }\n    case WestGravity:\n    {\n      splice_geometry.y+=(ssize_t) splice_geometry.width/2;\n      break;\n    }\n    case CenterGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width/2;\n      splice_geometry.y+=(ssize_t) splice_geometry.height/2;\n      break;\n    }\n    case EastGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width;\n      splice_geometry.y+=(ssize_t) splice_geometry.height/2;\n      break;\n    }\n    case SouthWestGravity:\n    {\n      splice_geometry.y+=(ssize_t) splice_geometry.height;\n      break;\n    }\n    case SouthGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width/2;\n      splice_geometry.y+=(ssize_t) splice_geometry.height;\n      break;\n    }\n    case SouthEastGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width;\n      splice_geometry.y+=(ssize_t) splice_geometry.height;\n      break;\n    }\n  }\n  /*\n    Splice image.\n  */\n  status=MagickTrue;\n  progress=0;\n  image_view=AcquireVirtualCacheView(image,exception);\n  splice_view=AcquireAuthenticCacheView(splice_image,exception);\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n  #pragma omp parallel for schedule(static,4) shared(progress,status) \\\n    magick_threads(image,splice_image,1,1)\n#endif\n  for (y=0; y < (ssize_t) splice_geometry.y; y++)\n  {\n    register const Quantum\n      *restrict p;\n\n    register ssize_t\n      x;\n\n    register Quantum\n      *restrict q;\n\n    if (status == MagickFalse)\n      continue;\n    p=GetCacheViewVirtualPixels(image_view,0,y,image->columns,1,exception);\n    q=QueueCacheViewAuthenticPixels(splice_view,0,y,splice_image->columns,1,\n      exception);\n    if ((p == (const Quantum *) NULL) || (q == (Quantum *) NULL))\n      {\n        status=MagickFalse;\n        continue;\n      }\n    for (x=0; x < splice_geometry.x; x++)\n    {\n      register ssize_t\n        i;\n\n      if (GetPixelReadMask(image,p) == 0)\n        {\n          SetPixelBackgoundColor(splice_image,q);\n          p+=GetPixelChannels(image);\n          q+=GetPixelChannels(splice_image);\n          continue;\n        }\n      for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n      {\n        PixelChannel channel=GetPixelChannelChannel(image,i);\n        PixelTrait traits=GetPixelChannelTraits(image,channel);\n        PixelTrait splice_traits=GetPixelChannelTraits(splice_image,channel);\n        if ((traits == UndefinedPixelTrait) ||\n            (splice_traits == UndefinedPixelTrait))\n          continue;\n        SetPixelChannel(splice_image,channel,p[i],q);\n      }\n      SetPixelRed(splice_image,GetPixelRed(image,p),q);\n      SetPixelGreen(splice_image,GetPixelGreen(image,p),q);\n      SetPixelBlue(splice_image,GetPixelBlue(image,p),q);\n      SetPixelAlpha(splice_image,GetPixelAlpha(image,p),q);\n      p+=GetPixelChannels(image);\n      q+=GetPixelChannels(splice_image);\n    }\n    for ( ; x < (ssize_t) (splice_geometry.x+splice_geometry.width); x++)\n      q+=GetPixelChannels(splice_image);\n    for ( ; x < (ssize_t) splice_image->columns; x++)\n    {\n      register ssize_t\n        i;\n\n      if (GetPixelReadMask(image,p) == 0)\n        {\n          SetPixelBackgoundColor(splice_image,q);\n          p+=GetPixelChannels(image);\n          q+=GetPixelChannels(splice_image);\n          continue;\n        }\n      for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n      {\n        PixelChannel channel=GetPixelChannelChannel(image,i);\n        PixelTrait traits=GetPixelChannelTraits(image,channel);\n        PixelTrait splice_traits=GetPixelChannelTraits(splice_image,channel);\n        if ((traits == UndefinedPixelTrait) ||\n            (splice_traits == UndefinedPixelTrait))\n          continue;\n        SetPixelChannel(splice_image,channel,p[i],q);\n      }\n      SetPixelRed(splice_image,GetPixelRed(image,p),q);\n      SetPixelGreen(splice_image,GetPixelGreen(image,p),q);\n      SetPixelBlue(splice_image,GetPixelBlue(image,p),q);\n      SetPixelAlpha(splice_image,GetPixelAlpha(image,p),q);\n      p+=GetPixelChannels(image);\n      q+=GetPixelChannels(splice_image);\n    }\n    if (SyncCacheViewAuthenticPixels(splice_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (image->progress_monitor != (MagickProgressMonitor) NULL)\n      {\n        MagickBooleanType\n          proceed;\n\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n        #pragma omp critical (MagickCore_TransposeImage)\n#endif\n        proceed=SetImageProgress(image,SpliceImageTag,progress++,\n          splice_image->rows);\n        if (proceed == MagickFalse)\n          status=MagickFalse;\n      }\n  }\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n  #pragma omp parallel for schedule(static,4) shared(progress,status) \\\n    magick_threads(image,splice_image,1,1)\n#endif\n  for (y=(ssize_t) (splice_geometry.y+splice_geometry.height);\n       y < (ssize_t) splice_image->rows; y++)\n  {\n    register const Quantum\n      *restrict p;\n\n    register ssize_t\n      x;\n\n    register Quantum\n      *restrict q;\n\n    if (status == MagickFalse)\n      continue;\n    p=GetCacheViewVirtualPixels(image_view,0,y-(ssize_t) splice_geometry.height,\n      image->columns,1,exception);\n    if ((y < 0) || (y >= (ssize_t) splice_image->rows))\n      continue;\n    q=QueueCacheViewAuthenticPixels(splice_view,0,y,splice_image->columns,1,\n      exception);\n    if ((p == (const Quantum *) NULL) || (q == (Quantum *) NULL))\n      {\n        status=MagickFalse;\n        continue;\n      }\n    for (x=0; x < splice_geometry.x; x++)\n    {\n      register ssize_t\n        i;\n\n      if (GetPixelReadMask(image,q) == 0)\n        {\n          SetPixelBackgoundColor(splice_image,q);\n          p+=GetPixelChannels(image);\n          q+=GetPixelChannels(splice_image);\n          continue;\n        }\n      for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n      {\n        PixelChannel channel=GetPixelChannelChannel(image,i);\n        PixelTrait traits=GetPixelChannelTraits(image,channel);\n        PixelTrait splice_traits=GetPixelChannelTraits(splice_image,channel);\n        if ((traits == UndefinedPixelTrait) ||\n            (splice_traits == UndefinedPixelTrait))\n          continue;\n        SetPixelChannel(splice_image,channel,p[i],q);\n      }\n      SetPixelRed(splice_image,GetPixelRed(image,p),q);\n      SetPixelGreen(splice_image,GetPixelGreen(image,p),q);\n      SetPixelBlue(splice_image,GetPixelBlue(image,p),q);\n      SetPixelAlpha(splice_image,GetPixelAlpha(image,p),q);\n      p+=GetPixelChannels(image);\n      q+=GetPixelChannels(splice_image);\n    }\n    for ( ; x < (ssize_t) (splice_geometry.x+splice_geometry.width); x++)\n      q+=GetPixelChannels(splice_image);\n    for ( ; x < (ssize_t) splice_image->columns; x++)\n    {\n      register ssize_t\n        i;\n\n      if (GetPixelReadMask(image,q) == 0)\n        {\n          SetPixelBackgoundColor(splice_image,q);\n          p+=GetPixelChannels(image);\n          q+=GetPixelChannels(splice_image);\n          continue;\n        }\n      for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n      {\n        PixelChannel channel=GetPixelChannelChannel(image,i);\n        PixelTrait traits=GetPixelChannelTraits(image,channel);\n        PixelTrait splice_traits=GetPixelChannelTraits(splice_image,channel);\n        if ((traits == UndefinedPixelTrait) ||\n            (splice_traits == UndefinedPixelTrait))\n          continue;\n        SetPixelChannel(splice_image,channel,p[i],q);\n      }\n      SetPixelRed(splice_image,GetPixelRed(image,p),q);\n      SetPixelGreen(splice_image,GetPixelGreen(image,p),q);\n      SetPixelBlue(splice_image,GetPixelBlue(image,p),q);\n      SetPixelAlpha(splice_image,GetPixelAlpha(image,p),q);\n      p+=GetPixelChannels(image);\n      q+=GetPixelChannels(splice_image);\n    }\n    if (SyncCacheViewAuthenticPixels(splice_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (image->progress_monitor != (MagickProgressMonitor) NULL)\n      {\n        MagickBooleanType\n          proceed;\n\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n        #pragma omp critical (MagickCore_TransposeImage)\n#endif\n        proceed=SetImageProgress(image,SpliceImageTag,progress++,\n          splice_image->rows);\n        if (proceed == MagickFalse)\n          status=MagickFalse;\n      }\n  }\n  splice_view=DestroyCacheView(splice_view);\n  image_view=DestroyCacheView(image_view);\n  if (status == MagickFalse)\n    splice_image=DestroyImage(splice_image);\n  return(splice_image);\n}", "func_src_after": "MagickExport Image *SpliceImage(const Image *image,\n  const RectangleInfo *geometry,ExceptionInfo *exception)\n{\n#define SpliceImageTag  \"Splice/Image\"\n\n  CacheView\n    *image_view,\n    *splice_view;\n\n  Image\n    *splice_image;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    progress;\n\n  RectangleInfo\n    splice_geometry;\n\n  ssize_t\n    columns,\n    y;\n\n  /*\n    Allocate splice image.\n  */\n  assert(image != (const Image *) NULL);\n  assert(image->signature == MagickCoreSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  assert(geometry != (const RectangleInfo *) NULL);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  splice_geometry=(*geometry);\n  splice_image=CloneImage(image,image->columns+splice_geometry.width,\n    image->rows+splice_geometry.height,MagickTrue,exception);\n  if (splice_image == (Image *) NULL)\n    return((Image *) NULL);\n  if (SetImageStorageClass(splice_image,DirectClass,exception) == MagickFalse)\n    {\n      splice_image=DestroyImage(splice_image);\n      return((Image *) NULL);\n    }\n  if ((IsPixelInfoGray(&splice_image->background_color) == MagickFalse) &&\n      (IsGrayColorspace(splice_image->colorspace) != MagickFalse))\n    (void) SetImageColorspace(splice_image,sRGBColorspace,exception);\n  if ((splice_image->background_color.alpha_trait != UndefinedPixelTrait) &&\n      (splice_image->alpha_trait == UndefinedPixelTrait))\n    (void) SetImageAlpha(splice_image,OpaqueAlpha,exception);\n  (void) SetImageBackgroundColor(splice_image,exception);\n  /*\n    Respect image geometry.\n  */\n  switch (image->gravity)\n  {\n    default:\n    case UndefinedGravity:\n    case NorthWestGravity:\n      break;\n    case NorthGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width/2;\n      break;\n    }\n    case NorthEastGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width;\n      break;\n    }\n    case WestGravity:\n    {\n      splice_geometry.y+=(ssize_t) splice_geometry.width/2;\n      break;\n    }\n    case CenterGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width/2;\n      splice_geometry.y+=(ssize_t) splice_geometry.height/2;\n      break;\n    }\n    case EastGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width;\n      splice_geometry.y+=(ssize_t) splice_geometry.height/2;\n      break;\n    }\n    case SouthWestGravity:\n    {\n      splice_geometry.y+=(ssize_t) splice_geometry.height;\n      break;\n    }\n    case SouthGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width/2;\n      splice_geometry.y+=(ssize_t) splice_geometry.height;\n      break;\n    }\n    case SouthEastGravity:\n    {\n      splice_geometry.x+=(ssize_t) splice_geometry.width;\n      splice_geometry.y+=(ssize_t) splice_geometry.height;\n      break;\n    }\n  }\n  /*\n    Splice image.\n  */\n  status=MagickTrue;\n  progress=0;\n  columns=MagickMin(splice_geometry.x,(ssize_t) splice_image->columns);\n  image_view=AcquireVirtualCacheView(image,exception);\n  splice_view=AcquireAuthenticCacheView(splice_image,exception);\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n  #pragma omp parallel for schedule(static,4) shared(progress,status) \\\n    magick_threads(image,splice_image,1,1)\n#endif\n  for (y=0; y < (ssize_t) splice_geometry.y; y++)\n  {\n    register const Quantum\n      *restrict p;\n\n    register ssize_t\n      x;\n\n    register Quantum\n      *restrict q;\n\n    if (status == MagickFalse)\n      continue;\n    p=GetCacheViewVirtualPixels(image_view,0,y,splice_image->columns,1,\n      exception);\n    q=QueueCacheViewAuthenticPixels(splice_view,0,y,splice_image->columns,1,\n      exception);\n    if ((p == (const Quantum *) NULL) || (q == (Quantum *) NULL))\n      {\n        status=MagickFalse;\n        continue;\n      }\n    for (x=0; x < columns; x++)\n    {\n      register ssize_t\n        i;\n\n      if (GetPixelReadMask(image,p) == 0)\n        {\n          SetPixelBackgoundColor(splice_image,q);\n          p+=GetPixelChannels(image);\n          q+=GetPixelChannels(splice_image);\n          continue;\n        }\n      for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n      {\n        PixelChannel channel=GetPixelChannelChannel(image,i);\n        PixelTrait traits=GetPixelChannelTraits(image,channel);\n        PixelTrait splice_traits=GetPixelChannelTraits(splice_image,channel);\n        if ((traits == UndefinedPixelTrait) ||\n            (splice_traits == UndefinedPixelTrait))\n          continue;\n        SetPixelChannel(splice_image,channel,p[i],q);\n      }\n      SetPixelRed(splice_image,GetPixelRed(image,p),q);\n      SetPixelGreen(splice_image,GetPixelGreen(image,p),q);\n      SetPixelBlue(splice_image,GetPixelBlue(image,p),q);\n      SetPixelAlpha(splice_image,GetPixelAlpha(image,p),q);\n      p+=GetPixelChannels(image);\n      q+=GetPixelChannels(splice_image);\n    }\n    for ( ; x < (ssize_t) (splice_geometry.x+splice_geometry.width); x++)\n      q+=GetPixelChannels(splice_image);\n    for ( ; x < (ssize_t) splice_image->columns; x++)\n    {\n      register ssize_t\n        i;\n\n      if (GetPixelReadMask(image,p) == 0)\n        {\n          SetPixelBackgoundColor(splice_image,q);\n          p+=GetPixelChannels(image);\n          q+=GetPixelChannels(splice_image);\n          continue;\n        }\n      for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n      {\n        PixelChannel channel=GetPixelChannelChannel(image,i);\n        PixelTrait traits=GetPixelChannelTraits(image,channel);\n        PixelTrait splice_traits=GetPixelChannelTraits(splice_image,channel);\n        if ((traits == UndefinedPixelTrait) ||\n            (splice_traits == UndefinedPixelTrait))\n          continue;\n        SetPixelChannel(splice_image,channel,p[i],q);\n      }\n      SetPixelRed(splice_image,GetPixelRed(image,p),q);\n      SetPixelGreen(splice_image,GetPixelGreen(image,p),q);\n      SetPixelBlue(splice_image,GetPixelBlue(image,p),q);\n      SetPixelAlpha(splice_image,GetPixelAlpha(image,p),q);\n      p+=GetPixelChannels(image);\n      q+=GetPixelChannels(splice_image);\n    }\n    if (SyncCacheViewAuthenticPixels(splice_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (image->progress_monitor != (MagickProgressMonitor) NULL)\n      {\n        MagickBooleanType\n          proceed;\n\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n        #pragma omp critical (MagickCore_TransposeImage)\n#endif\n        proceed=SetImageProgress(image,SpliceImageTag,progress++,\n          splice_image->rows);\n        if (proceed == MagickFalse)\n          status=MagickFalse;\n      }\n  }\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n  #pragma omp parallel for schedule(static,4) shared(progress,status) \\\n    magick_threads(image,splice_image,1,1)\n#endif\n  for (y=(ssize_t) (splice_geometry.y+splice_geometry.height);\n       y < (ssize_t) splice_image->rows; y++)\n  {\n    register const Quantum\n      *restrict p;\n\n    register ssize_t\n      x;\n\n    register Quantum\n      *restrict q;\n\n    if (status == MagickFalse)\n      continue;\n    if ((y < 0) || (y >= (ssize_t)splice_image->rows))\n      continue;\n    p=GetCacheViewVirtualPixels(image_view,0,y-(ssize_t) splice_geometry.height,\n      splice_image->columns,1,exception);\n    q=QueueCacheViewAuthenticPixels(splice_view,0,y,splice_image->columns,1,\n      exception);\n    if ((p == (const Quantum *) NULL) || (q == (Quantum *) NULL))\n      {\n        status=MagickFalse;\n        continue;\n      }\n    for (x=0; x < columns; x++)\n    {\n      register ssize_t\n        i;\n\n      if (GetPixelReadMask(image,q) == 0)\n        {\n          SetPixelBackgoundColor(splice_image,q);\n          p+=GetPixelChannels(image);\n          q+=GetPixelChannels(splice_image);\n          continue;\n        }\n      for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n      {\n        PixelChannel channel=GetPixelChannelChannel(image,i);\n        PixelTrait traits=GetPixelChannelTraits(image,channel);\n        PixelTrait splice_traits=GetPixelChannelTraits(splice_image,channel);\n        if ((traits == UndefinedPixelTrait) ||\n            (splice_traits == UndefinedPixelTrait))\n          continue;\n        SetPixelChannel(splice_image,channel,p[i],q);\n      }\n      SetPixelRed(splice_image,GetPixelRed(image,p),q);\n      SetPixelGreen(splice_image,GetPixelGreen(image,p),q);\n      SetPixelBlue(splice_image,GetPixelBlue(image,p),q);\n      SetPixelAlpha(splice_image,GetPixelAlpha(image,p),q);\n      p+=GetPixelChannels(image);\n      q+=GetPixelChannels(splice_image);\n    }\n    for ( ; x < (ssize_t) (splice_geometry.x+splice_geometry.width); x++)\n      q+=GetPixelChannels(splice_image);\n    for ( ; x < (ssize_t) splice_image->columns; x++)\n    {\n      register ssize_t\n        i;\n\n      if (GetPixelReadMask(image,q) == 0)\n        {\n          SetPixelBackgoundColor(splice_image,q);\n          p+=GetPixelChannels(image);\n          q+=GetPixelChannels(splice_image);\n          continue;\n        }\n      for (i=0; i < (ssize_t) GetPixelChannels(image); i++)\n      {\n        PixelChannel channel=GetPixelChannelChannel(image,i);\n        PixelTrait traits=GetPixelChannelTraits(image,channel);\n        PixelTrait splice_traits=GetPixelChannelTraits(splice_image,channel);\n        if ((traits == UndefinedPixelTrait) ||\n            (splice_traits == UndefinedPixelTrait))\n          continue;\n        SetPixelChannel(splice_image,channel,p[i],q);\n      }\n      SetPixelRed(splice_image,GetPixelRed(image,p),q);\n      SetPixelGreen(splice_image,GetPixelGreen(image,p),q);\n      SetPixelBlue(splice_image,GetPixelBlue(image,p),q);\n      SetPixelAlpha(splice_image,GetPixelAlpha(image,p),q);\n      p+=GetPixelChannels(image);\n      q+=GetPixelChannels(splice_image);\n    }\n    if (SyncCacheViewAuthenticPixels(splice_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (image->progress_monitor != (MagickProgressMonitor) NULL)\n      {\n        MagickBooleanType\n          proceed;\n\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n        #pragma omp critical (MagickCore_TransposeImage)\n#endif\n        proceed=SetImageProgress(image,SpliceImageTag,progress++,\n          splice_image->rows);\n        if (proceed == MagickFalse)\n          status=MagickFalse;\n      }\n  }\n  splice_view=DestroyCacheView(splice_view);\n  image_view=DestroyCacheView(image_view);\n  if (status == MagickFalse)\n    splice_image=DestroyImage(splice_image);\n  return(splice_image);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/7b1cf5784b5bcd85aa9293ecf56769f68c037231", "file_name": "MagickCore/transform.c", "vul_type": "cwe-125", "description": "Write a C function to splice an image with a given geometry in ImageMagick."}
{"func_name": "exports.rsync", "func_src_before": "exports.rsync = function (options,callback) {\n\n    options = options || {};\n\n    if ( typeof options.src === \"undefined\" ) {\n        throw(new Error(\"Source directory 'src' is missing from options\"));\n    }\n\n    if ( typeof options.dest === \"undefined\" ) {\n        throw(new Error(\"Destination directory 'dest' is missing from options\"));\n    }\n\n    if ( typeof options.host !== \"undefined\" ) {\n        options.dest = options.host+\":\"+options.dest;\n    }\n\n    var args = [options.src,options.dest];\n\n    if ( typeof options.host !== \"undefined\" ) {\n        args.push(\"--rsh=ssh\");\n    }\n\n    if ( options.recursive === true ) {\n        args.push(\"--recursive\");\n    }\n\n    if ( options.syncDest === true ) {\n        args.push(\"--delete\");\n        args.push(\"--delete-excluded\");\n    }\n\n    if ( options.dryRun === true ) {\n        args.push(\"--dry-run\");\n        args.push(\"--verbose\");\n        args.push(\"--stats\");\n    }\n\n    if ( typeof options.exclude !== \"undefined\" && util.isArray(options.exclude) ) {\n        options.exclude.forEach(function (value,index) {\n            args.push(\"--exclude=\"+value);\n        });\n    }\n\n    switch ( options.compareMode ) {\n        case \"sizeOnly\":\n            args.push(\"--size-only\");\n            break;\n        case \"checksum\":\n            args.push(\"--checksum\");\n            break;\n    }\n\n    if ( typeof options.args !== \"undefined\" && util.isArray(options.args) ) {\n        args = _.union(args,options.args);\n    }\n\n    args = _.unique(args);\n\n    var cmd = \"rsync \"+args.join(\" \");\n\n    try {\n        exec(cmd,function (error,stdout,stderr) {\n            callback(error,stdout,stderr,cmd);\n        });\n    } catch (error) {\n        callback(error,null,null,cmd);\n    }\n};", "func_src_after": "exports.rsync = function (options,callback) {\n\n    options = options || {};\n\n    if ( typeof options.src === \"undefined\" ) {\n        throw(new Error(\"Source directory 'src' is missing from options\"));\n    }\n\n    if ( typeof options.dest === \"undefined\" ) {\n        throw(new Error(\"Destination directory 'dest' is missing from options\"));\n    }\n\n    if ( typeof options.host !== \"undefined\" ) {\n        options.dest = options.host+\":\"+options.dest;\n    }\n\n    var args = [options.src,options.dest];\n\n    if ( typeof options.host !== \"undefined\" ) {\n        args.push(\"--rsh=ssh\");\n    }\n\n    if ( options.recursive === true ) {\n        args.push(\"--recursive\");\n    }\n\n    if ( options.syncDest === true ) {\n        args.push(\"--delete\");\n        args.push(\"--delete-excluded\");\n    }\n\n    if ( options.dryRun === true ) {\n        args.push(\"--dry-run\");\n        args.push(\"--verbose\");\n        args.push(\"--stats\");\n    }\n\n    if ( typeof options.exclude !== \"undefined\" && util.isArray(options.exclude) ) {\n        options.exclude.forEach(function (value,index) {\n            args.push(\"--exclude=\"+value);\n        });\n    }\n\n    switch ( options.compareMode ) {\n        case \"sizeOnly\":\n            args.push(\"--size-only\");\n            break;\n        case \"checksum\":\n            args.push(\"--checksum\");\n            break;\n    }\n\n    if ( typeof options.args !== \"undefined\" && util.isArray(options.args) ) {\n        args = _.union(args,options.args);\n    }\n    \n    args = _.unique(args);   \n\n    var cmd = \"rsync \"+args.join(\" \");\n\n    try {\n        var process = spawn('rsync', args);\n\t\tvar stdoutBuffer = ''\n\t\tvar stderrBuffer = '';\n\n\t\tprocess.stdout.on('data', function (data) {\n\t\t\tstdoutBuffer += data;\t\t\n\t\t});\n\n\t\tprocess.stderr.on('data', function (data) {\n\t\t\tstderrBuffer += data;\n\t\t});\n\n        process.on('exit', function (errorCode) {\n            if(errorCode===0) errorCode=null;\n            callback(errorCode,stdoutBuffer,stderrBuffer,cmd);\n        });\n    } catch (error) {\n        callback(error,null,null,cmd);\n    }\n};", "line_changes": {"deleted": [{"line_no": 56, "char_start": 1463, "char_end": 1464, "line": "\n"}, {"line_no": 57, "char_start": 1464, "char_end": 1491, "line": "    args = _.unique(args);\n"}, {"line_no": 62, "char_start": 1542, "char_end": 1592, "line": "        exec(cmd,function (error,stdout,stderr) {\n"}, {"line_no": 63, "char_start": 1592, "char_end": 1639, "line": "            callback(error,stdout,stderr,cmd);\n"}], "added": [{"line_no": 56, "char_start": 1463, "char_end": 1468, "line": "    \n"}, {"line_no": 57, "char_start": 1468, "char_end": 1498, "line": "    args = _.unique(args);   \n"}, {"line_no": 62, "char_start": 1549, "char_end": 1593, "line": "        var process = spawn('rsync', args);\n"}, {"line_no": 63, "char_start": 1593, "char_end": 1617, "line": "\t\tvar stdoutBuffer = ''\n"}, {"line_no": 64, "char_start": 1617, "char_end": 1642, "line": "\t\tvar stderrBuffer = '';\n"}, {"line_no": 65, "char_start": 1642, "char_end": 1643, "line": "\n"}, {"line_no": 66, "char_start": 1643, "char_end": 1689, "line": "\t\tprocess.stdout.on('data', function (data) {\n"}, {"line_no": 67, "char_start": 1689, "char_end": 1716, "line": "\t\t\tstdoutBuffer += data;\t\t\n"}, {"line_no": 68, "char_start": 1716, "char_end": 1722, "line": "\t\t});\n"}, {"line_no": 69, "char_start": 1722, "char_end": 1723, "line": "\n"}, {"line_no": 70, "char_start": 1723, "char_end": 1769, "line": "\t\tprocess.stderr.on('data', function (data) {\n"}, {"line_no": 71, "char_start": 1769, "char_end": 1794, "line": "\t\t\tstderrBuffer += data;\n"}, {"line_no": 72, "char_start": 1794, "char_end": 1800, "line": "\t\t});\n"}, {"line_no": 73, "char_start": 1800, "char_end": 1801, "line": "\n"}, {"line_no": 74, "char_start": 1801, "char_end": 1851, "line": "        process.on('exit', function (errorCode) {\n"}, {"line_no": 75, "char_start": 1851, "char_end": 1897, "line": "            if(errorCode===0) errorCode=null;\n"}, {"line_no": 76, "char_start": 1897, "char_end": 1960, "line": "            callback(errorCode,stdoutBuffer,stderrBuffer,cmd);\n"}]}, "char_changes": {"deleted": [{"char_start": 1550, "char_end": 1591, "chars": "exec(cmd,function (error,stdout,stderr) {"}, {"char_start": 1625, "char_end": 1631, "chars": ",stder"}], "added": [{"char_start": 1463, "char_end": 1467, "chars": "    "}, {"char_start": 1494, "char_end": 1497, "chars": "   "}, {"char_start": 1557, "char_end": 1896, "chars": "var process = spawn('rsync', args);\n\t\tvar stdoutBuffer = ''\n\t\tvar stderrBuffer = '';\n\n\t\tprocess.stdout.on('data', function (data) {\n\t\t\tstdoutBuffer += data;\t\t\n\t\t});\n\n\t\tprocess.stderr.on('data', function (data) {\n\t\t\tstderrBuffer += data;\n\t\t});\n\n        process.on('exit', function (errorCode) {\n            if(errorCode===0) errorCode=null;"}, {"char_start": 1923, "char_end": 1927, "chars": "Code"}, {"char_start": 1934, "char_end": 1952, "chars": "Buffer,stderrBuffe"}]}, "commit_link": "github.com/HaroldPutman/rsyncwrapper/commit/a763cc4a929805b977a278148e246234340e6af7", "file_name": "rsyncwrapper.js", "vul_type": "cwe-078", "commit_msg": "Changed child_process exec to spawn\n\nTo fix 'maxBuffer' exceeding issues on very large stdout responses. Attempted to maintain the same callback methods by buffering the stout and std err. Only errorCodes are passed and not error Signals.", "description": "Write a Node.js function in JavaScript that performs a customizable rsync operation with error handling."}
{"func_name": "r_bin_java_line_number_table_attr_new", "func_src_before": "R_API RBinJavaAttrInfo *r_bin_java_line_number_table_attr_new(ut8 *buffer, ut64 sz, ut64 buf_offset) {\n\tut32 i = 0;\n\tut64 curpos, offset = 0;\n\tRBinJavaLineNumberAttribute *lnattr;\n\tRBinJavaAttrInfo *attr = r_bin_java_default_attr_new (buffer, sz, buf_offset);\n\tif (!attr) {\n\t\treturn NULL;\n\t}\n\toffset += 6;\n\tattr->type = R_BIN_JAVA_ATTR_TYPE_LINE_NUMBER_TABLE_ATTR;\n\tattr->info.line_number_table_attr.line_number_table_length = R_BIN_JAVA_USHORT (buffer, offset);\n\toffset += 2;\n\tattr->info.line_number_table_attr.line_number_table = r_list_newf (free);\n\n\tut32 linenum_len = attr->info.line_number_table_attr.line_number_table_length;\n\tRList *linenum_list = attr->info.line_number_table_attr.line_number_table;\n\tif (linenum_len > sz) {\n\t\tfree (attr);\n\t\treturn NULL;\n\t}\n\tfor (i = 0; i < linenum_len; i++) {\n\t\tcurpos = buf_offset + offset;\n\t\t// printf (\"%llx %llx \\n\", curpos, sz);\n\t\t// XXX if (curpos + 8 >= sz) break;\n\t\tlnattr = R_NEW0 (RBinJavaLineNumberAttribute);\n\t\tif (!lnattr) {\n\t\t\tbreak;\n\t\t}\n\t\tlnattr->start_pc = R_BIN_JAVA_USHORT (buffer, offset);\n\t\toffset += 2;\n\t\tlnattr->line_number = R_BIN_JAVA_USHORT (buffer, offset);\n\t\toffset += 2;\n\t\tlnattr->file_offset = curpos;\n\t\tlnattr->size = 4;\n\t\tr_list_append (linenum_list, lnattr);\n\t}\n\tattr->size = offset;\n\treturn attr;\n}", "func_src_after": "R_API RBinJavaAttrInfo *r_bin_java_line_number_table_attr_new(ut8 *buffer, ut64 sz, ut64 buf_offset) {\n\tut32 i = 0;\n\tut64 curpos, offset = 0;\n\tRBinJavaLineNumberAttribute *lnattr;\n\tRBinJavaAttrInfo *attr = r_bin_java_default_attr_new (buffer, sz, buf_offset);\n\tif (!attr) {\n\t\treturn NULL;\n\t}\n\toffset += 6;\n\tattr->type = R_BIN_JAVA_ATTR_TYPE_LINE_NUMBER_TABLE_ATTR;\n\tattr->info.line_number_table_attr.line_number_table_length = R_BIN_JAVA_USHORT (buffer, offset);\n\toffset += 2;\n\tattr->info.line_number_table_attr.line_number_table = r_list_newf (free);\n\n\tut32 linenum_len = attr->info.line_number_table_attr.line_number_table_length;\n\tRList *linenum_list = attr->info.line_number_table_attr.line_number_table;\n\tif (linenum_len > sz) {\n\t\tfree (attr);\n\t\treturn NULL;\n\t}\n\tfor (i = 0; i < linenum_len; i++) {\n\t\tcurpos = buf_offset + offset;\n\t\t// printf (\"%llx %llx \\n\", curpos, sz);\n\t\t// XXX if (curpos + 8 >= sz) break;\n\t\tlnattr = R_NEW0 (RBinJavaLineNumberAttribute);\n\t\tif (!lnattr) {\n\t\t\tbreak;\n\t\t}\n\t\tif (offset + 8 >= sz) {\n\t\t\tbreak;\n\t\t}\n\t\tlnattr->start_pc = R_BIN_JAVA_USHORT (buffer, offset);\n\t\toffset += 2;\n\t\tlnattr->line_number = R_BIN_JAVA_USHORT (buffer, offset);\n\t\toffset += 2;\n\t\tlnattr->file_offset = curpos;\n\t\tlnattr->size = 4;\n\t\tr_list_append (linenum_list, lnattr);\n\t}\n\tattr->size = offset;\n\treturn attr;\n}", "commit_link": "github.com/radare/radare2/commit/eb0fb72b3c5307ec8e33effb6bf947e38cfdffe8", "file_name": "shlr/java/class.c", "vul_type": "cwe-125", "description": "In C, write a function to create a new Java line number table attribute from a binary buffer."}
{"func_name": "read_quant_matrix_ext", "func_src_before": "static void read_quant_matrix_ext(MpegEncContext *s, GetBitContext *gb)\n{\n    int i, j, v;\n\n    if (get_bits1(gb)) {\n        /* intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            v = get_bits(gb, 8);\n            j = s->idsp.idct_permutation[ff_zigzag_direct[i]];\n            s->intra_matrix[j]        = v;\n            s->chroma_intra_matrix[j] = v;\n        }\n    }\n\n    if (get_bits1(gb)) {\n        /* non_intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            get_bits(gb, 8);\n        }\n    }\n\n    if (get_bits1(gb)) {\n        /* chroma_intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            v = get_bits(gb, 8);\n            j = s->idsp.idct_permutation[ff_zigzag_direct[i]];\n            s->chroma_intra_matrix[j] = v;\n        }\n    }\n\n    if (get_bits1(gb)) {\n        /* chroma_non_intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            get_bits(gb, 8);\n        }\n    }\n\n    next_start_code_studio(gb);\n}", "func_src_after": "static int read_quant_matrix_ext(MpegEncContext *s, GetBitContext *gb)\n{\n    int i, j, v;\n\n    if (get_bits1(gb)) {\n        if (get_bits_left(gb) < 64*8)\n            return AVERROR_INVALIDDATA;\n        /* intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            v = get_bits(gb, 8);\n            j = s->idsp.idct_permutation[ff_zigzag_direct[i]];\n            s->intra_matrix[j]        = v;\n            s->chroma_intra_matrix[j] = v;\n        }\n    }\n\n    if (get_bits1(gb)) {\n        if (get_bits_left(gb) < 64*8)\n            return AVERROR_INVALIDDATA;\n        /* non_intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            get_bits(gb, 8);\n        }\n    }\n\n    if (get_bits1(gb)) {\n        if (get_bits_left(gb) < 64*8)\n            return AVERROR_INVALIDDATA;\n        /* chroma_intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            v = get_bits(gb, 8);\n            j = s->idsp.idct_permutation[ff_zigzag_direct[i]];\n            s->chroma_intra_matrix[j] = v;\n        }\n    }\n\n    if (get_bits1(gb)) {\n        if (get_bits_left(gb) < 64*8)\n            return AVERROR_INVALIDDATA;\n        /* chroma_non_intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            get_bits(gb, 8);\n        }\n    }\n\n    next_start_code_studio(gb);\n    return 0;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/5aba5b89d0b1d73164d3b81764828bb8b20ff32a", "file_name": "libavcodec/mpeg4videodec.c", "vul_type": "cwe-125", "description": "Write a C function to read and optionally update quantization matrices from a bitstream in an MPEG encoding context."}
{"func_name": "add_article_action", "func_src_before": "def add_article_action(request: HttpRequest, default_foreward_url: str):\n    forward_url: str = default_foreward_url\n    if request.GET.get(\"redirect\"):\n        forward_url = request.GET[\"redirect\"]\n    else:\n        forward_url = \"/admin\"\n    if \"rid\" not in request.GET:\n        return HttpResponseRedirect(\"/admin?error=Missing%20reservation%20id%20in%20request\")\n    u: Profile = get_current_user(request)\n    current_reservation = GroupReservation.objects.get(id=str(request.GET[\"rid\"]))\n    if current_reservation.createdByUser != u and u.rights < 2:\n        return HttpResponseRedirect(\"/admin?error=noyb\")\n    if current_reservation.submitted == True:\n        return HttpResponseRedirect(\"/admin?error=Already%20submitted\")\n    # Test for multiple or single article\n    if \"article_id\" in request.POST:\n        # Actual adding of article\n        aid: int = int(request.GET.get(\"article_id\"))\n        quantity: int = int(request.POST[\"quantity\"])\n        notes: str = request.POST[\"notes\"]\n        ar = ArticleRequested()\n        ar.AID = Article.objects.get(id=aid)\n        ar.RID = current_reservation\n        if \"srid\" in request.GET:\n            ar.SRID = SubReservation.objects.get(id=int(request.GET[\"srid\"]))\n        ar.amount = quantity\n        ar.notes = notes\n        ar.save()\n    # Actual adding of multiple articles\n    else:\n        if \"group_id\" not in request.GET:\n            return HttpResponseRedirect(\"/admin?error=missing%20group%20id\")\n        g: ArticleGroup = ArticleGroup.objects.get(id=int(request.GET[\"group_id\"]))\n        for art in Article.objects.all().filter(group=g):\n            if str(\"quantity_\" + str(art.id)) not in request.POST or str(\"notes_\" + str(art.id)) not in request.POST:\n                return HttpResponseRedirect(\"/admin?error=Missing%20article%20data%20in%20request\")\n            amount = int(request.POST[\"quantity_\" + str(art.id)])\n            if amount > 0:\n                ar = ArticleRequested()\n                ar.AID = art\n                ar.RID = current_reservation\n                ar.amount = amount\n                if \"srid\" in request.GET:\n                    ar.SRID = SubReservation.objects.get(id=int(request.GET[\"srid\"]))\n                ar.notes = str(request.POST[str(\"notes_\" + str(art.id))])\n                ar.save()\n    if \"srid\" in request.GET:\n        response = HttpResponseRedirect(forward_url + \"?rid=\" + str(current_reservation.id) + \"&srid=\" + request.GET[\"srid\"])\n    else:\n        response = HttpResponseRedirect(forward_url + \"?rid=\" + str(current_reservation.id))\n    return response", "func_src_after": "def add_article_action(request: HttpRequest, default_foreward_url: str):\n    forward_url: str = default_foreward_url\n    if request.GET.get(\"redirect\"):\n        forward_url = request.GET[\"redirect\"]\n    else:\n        forward_url = \"/admin\"\n    if \"rid\" not in request.GET:\n        return HttpResponseRedirect(\"/admin?error=Missing%20reservation%20id%20in%20request\")\n    u: Profile = get_current_user(request)\n    current_reservation = GroupReservation.objects.get(id=str(request.GET[\"rid\"]))\n    if current_reservation.createdByUser != u and u.rights < 2:\n        return HttpResponseRedirect(\"/admin?error=noyb\")\n    if current_reservation.submitted == True:\n        return HttpResponseRedirect(\"/admin?error=Already%20submitted\")\n    # Test for multiple or single article\n    if \"article_id\" in request.POST:\n        # Actual adding of article\n        aid: int = int(request.GET.get(\"article_id\"))\n        quantity: int = int(request.POST[\"quantity\"])\n        notes: str = escape(request.POST[\"notes\"])\n        ar = ArticleRequested()\n        ar.AID = Article.objects.get(id=aid)\n        ar.RID = current_reservation\n        if \"srid\" in request.GET:\n            ar.SRID = SubReservation.objects.get(id=int(request.GET[\"srid\"]))\n        ar.amount = quantity\n        ar.notes = notes\n        ar.save()\n    # Actual adding of multiple articles\n    else:\n        if \"group_id\" not in request.GET:\n            return HttpResponseRedirect(\"/admin?error=missing%20group%20id\")\n        g: ArticleGroup = ArticleGroup.objects.get(id=int(request.GET[\"group_id\"]))\n        for art in Article.objects.all().filter(group=g):\n            if str(\"quantity_\" + str(art.id)) not in request.POST or str(\"notes_\" + str(art.id)) not in request.POST:\n                return HttpResponseRedirect(\"/admin?error=Missing%20article%20data%20in%20request\")\n            amount = int(request.POST[\"quantity_\" + str(art.id)])\n            if amount > 0:\n                ar = ArticleRequested()\n                ar.AID = art\n                ar.RID = current_reservation\n                ar.amount = amount\n                if \"srid\" in request.GET:\n                    ar.SRID = SubReservation.objects.get(id=int(request.GET[\"srid\"]))\n                ar.notes = escape(str(request.POST[str(\"notes_\" + str(art.id))]))\n                ar.save()\n    if \"srid\" in request.GET:\n        response = HttpResponseRedirect(forward_url + \"?rid=\" + str(current_reservation.id) + \"&srid=\" + request.GET[\"srid\"])\n    else:\n        response = HttpResponseRedirect(forward_url + \"?rid=\" + str(current_reservation.id))\n    return response", "commit_link": "github.com/Technikradio/C3FOCSite/commit/6e330d4d44bbfdfce9993dffea97008276771600", "file_name": "c3shop/frontpage/management/reservation_actions.py", "vul_type": "cwe-079", "description": "Write a Python function to handle adding single or multiple articles to a reservation, with redirection and error handling."}
{"func_name": "ServerDefault", "func_src_before": "func ServerDefault(ops ...func(*tls.Config)) *tls.Config {\n\ttlsconfig := &tls.Config{\n\t\t// Avoid fallback by default to SSL protocols < TLS1.0\n\t\tMinVersion:               tls.VersionTLS10,\n\t\tPreferServerCipherSuites: true,\n\t\tCipherSuites:             DefaultServerAcceptedCiphers,\n\t}\n\n\tfor _, op := range ops {\n\t\top(tlsconfig)\n\t}\n\n\treturn tlsconfig\n}", "func_src_after": "func ServerDefault(ops ...func(*tls.Config)) *tls.Config {\n\ttlsconfig := &tls.Config{\n\t\t// Avoid fallback by default to SSL protocols < TLS1.2\n\t\tMinVersion:               tls.VersionTLS12,\n\t\tPreferServerCipherSuites: true,\n\t\tCipherSuites:             DefaultServerAcceptedCiphers,\n\t}\n\n\tfor _, op := range ops {\n\t\top(tlsconfig)\n\t}\n\n\treturn tlsconfig\n}", "line_changes": {"deleted": [{"line_no": 4, "char_start": 143, "char_end": 189, "line": "\t\tMinVersion:               tls.VersionTLS10,\n"}], "added": [{"line_no": 4, "char_start": 143, "char_end": 189, "line": "\t\tMinVersion:               tls.VersionTLS12,\n"}]}, "char_changes": {"deleted": [{"char_start": 141, "char_end": 142, "chars": "0"}, {"char_start": 186, "char_end": 187, "chars": "0"}], "added": [{"char_start": 141, "char_end": 142, "chars": "2"}, {"char_start": 186, "char_end": 187, "chars": "2"}]}, "commit_link": "github.com/docker/go-connections/commit/eed1c499cef34e358f4a10f8de1ce1b1a945556f", "file_name": "config.go", "vul_type": "cwe-327", "commit_msg": "Remove server support for TLS 1.0 and TLS 1.1\n\nThis should not be needed any more and is not recommended.\n\nSigned-off-by: Justin Cormack <justin.cormack@docker.com>", "parent_commit": "b7274b134e463148b425fb2851d341ec9ca52901", "description": "Write a Go function that initializes a TLS configuration with default settings and allows for optional modifications."}
{"func_name": "gravatar", "func_src_before": "@register.tag\n@basictag(takes_context=True)\ndef gravatar(context, user, size=None):\n    \"\"\"\n    Outputs the HTML for displaying a user's gravatar.\n\n    This can take an optional size of the image (defaults to 80 if not\n    specified).\n\n    This is also influenced by the following settings:\n\n        GRAVATAR_SIZE    - Default size for gravatars\n        GRAVATAR_RATING  - Maximum allowed rating (g, pg, r, x)\n        GRAVATAR_DEFAULT - Default image set to show if the user hasn't\n                           specified a gravatar (identicon, monsterid, wavatar)\n\n    See http://www.gravatar.com/ for more information.\n    \"\"\"\n    url = get_gravatar_url(context['request'], user, size)\n\n    if url:\n        return ('<img src=\"%s\" width=\"%s\" height=\"%s\" alt=\"%s\" '\n                '     class=\"gravatar\"/>' %\n                (url, size, size, user.get_full_name() or user.username))\n    else:\n        return ''", "func_src_after": "@register.tag\n@basictag(takes_context=True)\ndef gravatar(context, user, size=None):\n    \"\"\"\n    Outputs the HTML for displaying a user's gravatar.\n\n    This can take an optional size of the image (defaults to 80 if not\n    specified).\n\n    This is also influenced by the following settings:\n\n        GRAVATAR_SIZE    - Default size for gravatars\n        GRAVATAR_RATING  - Maximum allowed rating (g, pg, r, x)\n        GRAVATAR_DEFAULT - Default image set to show if the user hasn't\n                           specified a gravatar (identicon, monsterid, wavatar)\n\n    See http://www.gravatar.com/ for more information.\n    \"\"\"\n    url = get_gravatar_url(context['request'], user, size)\n\n    if url:\n        return format_html(\n            '<img src=\"{0}\" width=\"{1}\" height=\"{1}\" alt=\"{2}\" '\n            'class=\"gravatar\"/>',\n            url, size, user.get_full_name() or user.username)\n    else:\n        return ''", "commit_link": "github.com/djblets/djblets/commit/77ac64642ad530bf69e390c51fc6fdcb8914c8e7", "file_name": "djblets/gravatars/templatetags/gravatars.py", "vul_type": "cwe-079", "description": "Create a Django template tag in Python that generates an HTML image tag for a user's Gravatar with an optional size parameter."}
{"func_name": "check_and_update_ranks", "func_src_before": "    def check_and_update_ranks(self, scene):\n        # There are 2 cases here:\n        #   1) Ranks have never been calculated for this scene before\n        #       - This means we need to calculate what the ranks were every month of this scenes history\n        #       - We should only do this if ranks don't already exist for this scene\n        #   2) Ranks have been calculated for this scene before\n        #       - We already have bulk ranks. We should check if it has been more than 1 month since we last\n        #           calculated ranks. If so, calculate again with the brackets that have come out this month\n\n        LOG.info('About to check if ranks need updating for {}'.format(scene))\n        # First, do we have any ranks for this scene already?\n        sql = 'select count(*) from ranks where scene=\"{}\";'.format(scene)\n        res = self.db.exec(sql)\n        count = res[0][0]\n\n        n = 5 if (scene == 'pro' or scene == 'pro_wiiu') else constants.TOURNAMENTS_PER_RANK\n        if count == 0:\n            LOG.info('Detected that we need to bulk update ranks for {}'.format(scene))\n            # Alright, we have nothing. Bulk update ranks\n            first_month = bracket_utils.get_first_month(self.db, scene)\n            last_month = bracket_utils.get_last_month(self.db, scene)\n            \n            # Iterate through all tournaments going month by month, and calculate ranks\n            months = bracket_utils.iter_months(first_month, last_month, include_first=False, include_last=True)\n            for month in months:\n                urls, _ = bracket_utils.get_n_tournaments_before_date(self.db, scene, month, n)\n                self.process_ranks(scene, urls, month)\n        else:\n\n            # Get the date of the last time we calculated ranks\n            sql = \"select date from ranks where scene='{}' order by date desc limit 1;\".format(scene)\n            res = self.db.exec(sql)\n            last_rankings_date = res[0][0]\n\n            # Check to see if it's been more than 1 month since we last calculated ranks\n            more_than_one_month = bracket_utils.has_month_passed(last_rankings_date)\n            if more_than_one_month:\n                # Get only the last n tournaments, so it doesn't take too long to process\n                today = datetime.datetime.today().strftime('%Y-%m-%d')\n                msg = 'Detected that we need up update monthly ranks for {}, on {}'.format(scene, today)\n                LOG.info(msg)\n\n                # We should only ever calculate ranks on the 1st. If today is not the first, log error\n                if not today.split('-')[-1] == '1':\n                    LOG.exc('We are calculating ranks today, {}, but it isnt the first'.format(today))\n\n                months = bracket_utils.iter_months(last_rankings_date, today, include_first=False, include_last=True)\n                for month in months:\n                    # Make sure that we actually have matches during this month\n                    # Say we are trying to calculate ranks for 2018-05-01, the player would need to have matches during 2018-04-01, 2018-04-30\n                    prev_date = bracket_utils.get_previous_month(month)\n                    brackets_during_month = bracket_utils.get_tournaments_during_month(self.db, scene, prev_date)\n\n                    if len(brackets_during_month) > 0:\n                        tweet('Calculating {} ranks for {}'.format(month, scene))\n                        urls, _ = bracket_utils.get_n_tournaments_before_date(self.db, scene, month, n)\n                        self.process_ranks(scene, urls, month)\n\n            else:\n                LOG.info('It has not yet been 1 month since we calculated ranks for {}. Skipping'.format(scene))", "func_src_after": "    def check_and_update_ranks(self, scene):\n        # There are 2 cases here:\n        #   1) Ranks have never been calculated for this scene before\n        #       - This means we need to calculate what the ranks were every month of this scenes history\n        #       - We should only do this if ranks don't already exist for this scene\n        #   2) Ranks have been calculated for this scene before\n        #       - We already have bulk ranks. We should check if it has been more than 1 month since we last\n        #           calculated ranks. If so, calculate again with the brackets that have come out this month\n\n        LOG.info('About to check if ranks need updating for {}'.format(scene))\n        # First, do we have any ranks for this scene already?\n        sql = 'select count(*) from ranks where scene=\"{scene}\";'\n        args = {'scene': scene}\n        res = self.db.exec(sql, args)\n        count = res[0][0]\n\n        n = 5 if (scene == 'pro' or scene == 'pro_wiiu') else constants.TOURNAMENTS_PER_RANK\n        if count == 0:\n            LOG.info('Detected that we need to bulk update ranks for {}'.format(scene))\n            # Alright, we have nothing. Bulk update ranks\n            first_month = bracket_utils.get_first_month(self.db, scene)\n            last_month = bracket_utils.get_last_month(self.db, scene)\n            \n            # Iterate through all tournaments going month by month, and calculate ranks\n            months = bracket_utils.iter_months(first_month, last_month, include_first=False, include_last=True)\n            for month in months:\n                urls, _ = bracket_utils.get_n_tournaments_before_date(self.db, scene, month, n)\n                self.process_ranks(scene, urls, month)\n        else:\n\n            # Get the date of the last time we calculated ranks\n            sql = \"select date from ranks where scene='{scene}' order by date desc limit 1;\"\n            args = {'scene': scene}\n            res = self.db.exec(sql, args)\n            last_rankings_date = res[0][0]\n\n            # Check to see if it's been more than 1 month since we last calculated ranks\n            more_than_one_month = bracket_utils.has_month_passed(last_rankings_date)\n            if more_than_one_month:\n                # Get only the last n tournaments, so it doesn't take too long to process\n                today = datetime.datetime.today().strftime('%Y-%m-%d')\n                msg = 'Detected that we need up update monthly ranks for {}, on {}'.format(scene, today)\n                LOG.info(msg)\n\n                # We should only ever calculate ranks on the 1st. If today is not the first, log error\n                if not today.split('-')[-1] == '1':\n                    LOG.exc('We are calculating ranks today, {}, but it isnt the first'.format(today))\n\n                months = bracket_utils.iter_months(last_rankings_date, today, include_first=False, include_last=True)\n                for month in months:\n                    # Make sure that we actually have matches during this month\n                    # Say we are trying to calculate ranks for 2018-05-01, the player would need to have matches during 2018-04-01, 2018-04-30\n                    prev_date = bracket_utils.get_previous_month(month)\n                    brackets_during_month = bracket_utils.get_tournaments_during_month(self.db, scene, prev_date)\n\n                    if len(brackets_during_month) > 0:\n                        tweet('Calculating {} ranks for {}'.format(month, scene))\n                        urls, _ = bracket_utils.get_n_tournaments_before_date(self.db, scene, month, n)\n                        self.process_ranks(scene, urls, month)\n\n            else:\n                LOG.info('It has not yet been 1 month since we calculated ranks for {}. Skipping'.format(scene))", "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "process_data.py", "vul_type": "cwe-089", "description": "In Python, write a function to update ranking data for a given scene, either by bulk calculating historical monthly ranks if none exist, or by updating ranks if it's been over a month since the last calculation."}
{"func_name": "update_dir_from_tar", "func_src_before": "def update_dir_from_tar(tar, root_dir):\n    directories = []\n    valid_paths = BloomSet()\n    for entry in tar:\n        # Convert entry type to stat constant\n        if entry.type == tarfile.DIRTYPE:\n            entry_stat_type = stat.S_IFDIR\n        elif entry.type in (tarfile.REGTYPE, tarfile.LNKTYPE):\n            # Coda apparently doesn't allow hard links to symlinks\n            entry_stat_type = stat.S_IFREG\n        elif entry.type == tarfile.SYMTYPE:\n            entry_stat_type = stat.S_IFLNK\n        else:\n            raise ValueError(f\"Unexpected file type {entry.type}\")\n\n        # Check for existing file\n        path = build_path(root_dir, entry.name)\n        try:\n            st: Optional[os.stat_result] = os.lstat(path)\n        except OSError:\n            st = None\n\n        # If entry has changed types, remove the old object\n        if st is not None and stat.S_IFMT(st.st_mode) != entry_stat_type:\n            if stat.S_ISDIR(st.st_mode):\n                shutil.rmtree(path)\n            else:\n                os.unlink(path)\n            st = None\n\n        # Create parent directory if not present.  Parents are not\n        # necessarily dumped before children.\n        path.parent.mkdir(parents=True, exist_ok=True)\n\n        # Create new object\n        if entry.isdir():\n            if not os.path.exists(path):\n                print(\"d\", path)\n                os.mkdir(path)\n            # Go back and set mtime after directory has been populated\n            directories.append(entry)\n        elif entry.isfile():\n            # update_file() will break hard links if it modifies the file.\n            # This is what we want because links may have also been broken\n            # at the source.  codadump2tar always dumps hard links, so we\n            # will rebuild any links that should still exist.\n            if update_file(path, TarMemberFile(tar, entry)):\n                print(\"f\", path)\n        elif entry.issym():\n            if st is None or entry.linkname and os.readlink(path) != entry.linkname:\n                print(\"s\", path)\n                if st is not None:\n                    os.unlink(path)\n                os.symlink(entry.linkname, path)\n        elif entry.islnk():\n            target_path = build_path(root_dir, entry.linkname)\n            target_st = os.lstat(target_path)\n            if (\n                st is None\n                or st.st_dev != target_st.st_dev\n                or st.st_ino != target_st.st_ino\n            ):\n                print(\"l\", path)\n                if st is not None:\n                    os.unlink(path)\n                os.link(target_path, path)\n\n        # Update metadata\n        attrs = XAttrs(path)\n        # owner and mode.  Hardlinks were updated with the primary, and we\n        # can't set xattrs on symlinks.\n        if entry.isfile() or entry.isdir():\n            # rsync --fake-super compatible:\n            # octal_mode_with_type major,minor uid:gid\n            mode = entry_stat_type | entry.mode\n            attrs.update(\n                ATTR_STAT,\n                f\"{mode:o} 0,0 {entry.uid}:{entry.gid}\",\n            )\n        # mtime.  Directories will be updated later, and hardlinks were\n        # updated with the primary.\n        if entry.isfile() or entry.issym() and os.lstat(path).st_mtime != entry.mtime:\n            lutime(path, entry.mtime)\n\n        # Protect from garbage collection\n        valid_paths.add(str(path))\n\n    # Deferred update of directory mtimes\n    for entry in directories:\n        path = build_path(root_dir, entry.name)\n        if os.stat(path).st_mtime != entry.mtime:\n            os.utime(path, (entry.mtime, entry.mtime))\n\n    return valid_paths", "func_src_after": "def update_dir_from_tar(tar, root_dir):\n    directories = []\n    valid_paths = BloomSet()\n    for entry in tar:\n        # Convert entry type to stat constant\n        if entry.type == tarfile.DIRTYPE:\n            entry_stat_type = stat.S_IFDIR\n        elif entry.type in (tarfile.REGTYPE, tarfile.LNKTYPE):\n            # Coda apparently doesn't allow hard links to symlinks\n            entry_stat_type = stat.S_IFREG\n        elif entry.type == tarfile.SYMTYPE:\n            entry_stat_type = stat.S_IFLNK\n        else:\n            raise ValueError(f\"Unexpected file type {entry.type}\")\n\n        # Check for existing file\n        path = build_path(root_dir, entry.name)\n        try:\n            st: Optional[os.stat_result] = os.lstat(path)\n        except OSError:\n            st = None\n\n        # If entry has changed types, remove the old object\n        if st is not None and stat.S_IFMT(st.st_mode) != entry_stat_type:\n            if stat.S_ISDIR(st.st_mode):\n                shutil.rmtree(path)\n            else:\n                os.unlink(path)\n            st = None\n\n        # Create parent directory if not present.  Parents are not\n        # necessarily dumped before children.\n        path.parent.mkdir(parents=True, exist_ok=True)\n\n        # Create new object\n        if entry.isdir():\n            if not os.path.exists(path):\n                print(\"d\", path)\n                os.mkdir(path)\n            # Go back and set mtime after directory has been populated\n            directories.append(entry)\n        elif entry.isfile():\n            # update_file() will break hard links if it modifies the file.\n            # This is what we want because links may have also been broken\n            # at the source.  codadump2tar always dumps hard links, so we\n            # will rebuild any links that should still exist.\n            if update_file(path, TarMemberFile(tar, entry)):\n                print(\"f\", path)\n        elif entry.issym():\n            if st is None or (entry.linkname and os.readlink(path) != entry.linkname):\n                print(\"s\", path)\n                if st is not None:\n                    os.unlink(path)\n                os.symlink(entry.linkname, path)\n        elif entry.islnk():\n            target_path = build_path(root_dir, entry.linkname)\n            target_st = os.lstat(target_path)\n            if (\n                st is None\n                or st.st_dev != target_st.st_dev\n                or st.st_ino != target_st.st_ino\n            ):\n                print(\"l\", path)\n                if st is not None:\n                    os.unlink(path)\n                os.link(target_path, path)\n\n        # Update metadata\n        attrs = XAttrs(path)\n        # owner and mode.  Hardlinks were updated with the primary, and we\n        # can't set xattrs on symlinks.\n        if entry.isfile() or entry.isdir():\n            # rsync --fake-super compatible:\n            # octal_mode_with_type major,minor uid:gid\n            mode = entry_stat_type | entry.mode\n            attrs.update(\n                ATTR_STAT,\n                f\"{mode:o} 0,0 {entry.uid}:{entry.gid}\",\n            )\n        # mtime.  Directories will be updated later, and hardlinks were\n        # updated with the primary.\n        if (entry.isfile() or entry.issym()) and os.lstat(path).st_mtime != entry.mtime:\n            lutime(path, entry.mtime)\n\n        # Protect from garbage collection\n        valid_paths.add(str(path))\n\n    # Deferred update of directory mtimes\n    for entry in directories:\n        path = build_path(root_dir, entry.name)\n        if os.stat(path).st_mtime != entry.mtime:\n            os.utime(path, (entry.mtime, entry.mtime))\n\n    return valid_paths", "line_changes": {"deleted": [{"line_no": 50, "char_start": 1943, "char_end": 2028, "line": "            if st is None or entry.linkname and os.readlink(path) != entry.linkname:\n"}, {"line_no": 82, "char_start": 3217, "char_end": 3304, "line": "        if entry.isfile() or entry.issym() and os.lstat(path).st_mtime != entry.mtime:\n"}], "added": [{"line_no": 50, "char_start": 1943, "char_end": 2030, "line": "            if st is None or (entry.linkname and os.readlink(path) != entry.linkname):\n"}, {"line_no": 82, "char_start": 3219, "char_end": 3308, "line": "        if (entry.isfile() or entry.issym()) and os.lstat(path).st_mtime != entry.mtime:\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 1972, "char_end": 1973, "chars": "("}, {"char_start": 2027, "char_end": 2028, "chars": ")"}, {"char_start": 3230, "char_end": 3231, "chars": "("}, {"char_start": 3262, "char_end": 3263, "chars": ")"}]}, "commit_link": "github.com/cmusatyalab/deltaic/commit/3c8fb3f8f1b75a93a17198b863b44fa78589650d", "file_name": "coda.py", "vul_type": "cwe-022", "commit_msg": "Can't use pathlib.Path.resolve() to create absolute paths\n\nBecause do not want to traverse any (final?) symlink in the path.", "parent_commit": "4c5fe2b9a04849b48a0598b70dbcfcb27a54fee5", "description": "Write a Python function to update a directory structure from a TAR file, handling file types and metadata."}
{"func_name": "check", "func_src_before": "def check(current_num):\n    try:\n        cursor.execute('SELECT * FROM comics WHERE num=\"%s\"' % current_num)\n    except sqlite3.OperationalError:\n        cursor.execute('CREATE TABLE comics (num text)')\n        return False\n    else:\n        return False if cursor.fetchone() is None else True", "func_src_after": "def check(current_num):\n    try:\n        cursor.execute('SELECT * FROM comics WHERE num=?', (current_num,))\n    except sqlite3.OperationalError:\n        cursor.execute('CREATE TABLE comics (num text)')\n        return False\n    else:\n        return False if cursor.fetchone() is None else True", "commit_link": "github.com/lord63/a_bunch_of_code/commit/c0d67a1312306fd1257c354bfb5d6cac7643aa29", "file_name": "comics/check_comics.py", "vul_type": "cwe-089", "description": "Write a Python function named `check` that queries a SQLite database for a specific record and creates a table if it doesn't exist."}
{"func_name": "rtc_irq_eoi_tracking_reset", "func_src_before": "static void rtc_irq_eoi_tracking_reset(struct kvm_ioapic *ioapic)\n{\n\tioapic->rtc_status.pending_eoi = 0;\n\tbitmap_zero(ioapic->rtc_status.dest_map.map, KVM_MAX_VCPUS);\n}", "func_src_after": "static void rtc_irq_eoi_tracking_reset(struct kvm_ioapic *ioapic)\n{\n\tioapic->rtc_status.pending_eoi = 0;\n\tbitmap_zero(ioapic->rtc_status.dest_map.map, KVM_MAX_VCPU_ID);\n}", "commit_link": "github.com/torvalds/linux/commit/81cdb259fb6d8c1c4ecfeea389ff5a73c07f5755", "file_name": "arch/x86/kvm/ioapic.c", "vul_type": "cwe-125", "description": "Write a C function named `rtc_irq_eoi_tracking_reset` that resets the pending EOI status and clears the destination map bitmap in a `kvm_ioapic` structure."}
{"func_name": "create_cf_base", "func_src_before": "def create_cf_base():\n    url = 'http://codeforces.com/problemset/'\n    r = requests.get(url)\n    max_page = 0\n    soup = BeautifulSoup(r.text, \"lxml\")\n    base = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\cf.db\")\n    conn = base.cursor()\n    conn.execute(\"create table problems (problem INTEGER, diff CHAR)\")\n    for i in available_tags:\n        conn.execute(\"create table \" + i + \" (problems INTEGER, diff CHAR)\")\n\n    for link in soup.find_all(attrs={\"class\" : \"page-index\"}):\n        s = link.find('a')\n        s2 = s.get(\"href\").split('/')\n        max_page = max(max_page, int(s2[3]))\n\n    a = 0\n    b = 0\n    f = False\n    for i in range(1, max_page + 1):\n        r = requests.get('http://codeforces.com/problemset/' + '/page/' + str(i))\n        soup = BeautifulSoup(r.text, \"lxml\")\n        old = ''\n        for link in soup.find_all('a'):\n            s = link.get('href')\n            if s != None and s.find('/problemset') != -1:\n                s = s.split('/')\n                if len(s) == 5 and old != s[3] + s[4]:\n                    a = s[3]\n                    b = s[4]\n                    old = s[3] + s[4]\n                    if not f:\n                        f = True\n                        last_update = old\n                    conn.execute(\"insert into problems values (?, ?)\", (a, b))\n                if len(s) == 4 and s[3] in available_tags:\n                    conn.execute(\"insert into \" + s[3] + \" values (?, ?)\", (a, b))\n\n    base.commit()\n    base.close()\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"create table users (chat_id INTEGER, username STRING, last_update STRING, last_problem STRING, state INTEGER)\")\n    conn.execute(\"create table last_update_problemset (problem STRING)\")\n    conn.execute(\"insert into last_update_problemset values (?)\", (last_update, ))\n    settings.commit()\n    settings.close()", "func_src_after": "def create_cf_base():\n    url = 'http://codeforces.com/problemset/'\n    r = requests.get(url)\n    max_page = 0\n    soup = BeautifulSoup(r.text, \"lxml\")\n    base = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\cf.db\")\n    conn = base.cursor()\n    conn.execute(\"create table problems (problem INTEGER, diff CHAR)\")\n    for i in available_tags:\n        conn.execute(\"create table ? (problems INTEGER, diff CHAR)\", (i,))\n\n    for link in soup.find_all(attrs={\"class\" : \"page-index\"}):\n        s = link.find('a')\n        s2 = s.get(\"href\").split('/')\n        max_page = max(max_page, int(s2[3]))\n\n    a = 0\n    b = 0\n    f = False\n    for i in range(1, max_page + 1):\n        r = requests.get('http://codeforces.com/problemset/' + '/page/' + str(i))\n        soup = BeautifulSoup(r.text, \"lxml\")\n        old = ''\n        for link in soup.find_all('a'):\n            s = link.get('href')\n            if s != None and s.find('/problemset') != -1:\n                s = s.split('/')\n                if len(s) == 5 and old != s[3] + s[4]:\n                    a = s[3]\n                    b = s[4]\n                    old = s[3] + s[4]\n                    if not f:\n                        f = True\n                        last_update = old\n                    conn.execute(\"insert into problems values (?, ?)\", (a, b))\n                if len(s) == 4 and s[3] in available_tags:\n                    conn.execute(\"insert into ? values (?, ?)\", (s[3], a, b))\n\n    base.commit()\n    base.close()\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"create table users (chat_id INTEGER, username STRING, last_update STRING, last_problem STRING, state INTEGER)\")\n    conn.execute(\"create table last_update_problemset (problem STRING)\")\n    conn.execute(\"insert into last_update_problemset values (?)\", (last_update, ))\n    settings.commit()\n    settings.close()", "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bases/createcfbase.py", "vul_type": "cwe-089", "description": "Write a Python function to scrape Codeforces problemset data and store it in a SQLite database."}
{"func_name": "get_requested_month_for_inverter", "func_src_before": "    def get_requested_month_for_inverter(self, inverter_serial, date):\n        data = dict()\n\n        month_start, month_end = self.get_epoch_month(date)\n        data['interval'] = {'from': self.convert_local_ts_to_utc(month_start, self.local_timezone), 'to': self.convert_local_ts_to_utc(month_end, self.local_timezone)}\n        month_total = 0\n\n        query = '''\n            SELECT TimeStamp, DayYield AS Power \n            FROM MonthData \n            WHERE TimeStamp BETWEEN %s AND %s AND Serial = %s\n            '''\n\n        data['data'] = list()\n        for row in self.c.execute(query % (month_start, month_end, inverter_serial)):\n            data['data'].append({'time': self.convert_local_ts_to_utc(row[0], self.local_timezone), 'power': row[1]})\n            month_total += row[1]\n\n        data['total'] = month_total\n\n        query = '''\n            SELECT MIN(TimeStamp) as Min, MAX(TimeStamp) as Max \n            FROM MonthData \n            WHERE Serial = %s;\n            ''' % inverter_serial\n\n        self.c.execute(query)\n        first_data, last_data = self.c.fetchone()\n\n        if first_data: data['hasPrevious'] = (first_data < month_start)\n        else: data['hasPrevious'] = False\n        if last_data: data['hasNext'] = (last_data > month_end)\n        else: data['hasNext'] = False\n\n        return data", "func_src_after": "    def get_requested_month_for_inverter(self, inverter_serial, date):\n        data = dict()\n\n        month_start, month_end = self.get_epoch_month(date)\n        data['interval'] = {'from': self.convert_local_ts_to_utc(month_start, self.local_timezone), 'to': self.convert_local_ts_to_utc(month_end, self.local_timezone)}\n        month_total = 0\n\n        query = '''\n            SELECT TimeStamp, DayYield AS Power \n            FROM MonthData \n            WHERE TimeStamp BETWEEN ? AND ? AND Serial=?;\n            '''\n\n        data['data'] = list()\n        for row in self.c.execute(query, (month_start, month_end, inverter_serial)):\n            data['data'].append({'time': self.convert_local_ts_to_utc(row[0], self.local_timezone), 'power': row[1]})\n            month_total += row[1]\n\n        data['total'] = month_total\n\n        query = '''\n            SELECT MIN(TimeStamp) as Min, MAX(TimeStamp) as Max \n            FROM MonthData \n            WHERE Serial=?;\n            '''\n\n        self.c.execute(query, (inverter_serial,))\n        first_data, last_data = self.c.fetchone()\n\n        if first_data: data['hasPrevious'] = (first_data < month_start)\n        else: data['hasPrevious'] = False\n        if last_data: data['hasNext'] = (last_data > month_end)\n        else: data['hasNext'] = False\n\n        return data", "commit_link": "github.com/philipptrenz/sunportal/commit/7eef493a168ed4e6731ff800713bfb8aee99a506", "file_name": "util/database.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch and summarize monthly power yield data for a given inverter and date, including checks for previous and next data availability."}
{"func_name": "rom_copy", "func_src_before": "int rom_copy(uint8_t *dest, hwaddr addr, size_t size)\n{\n    hwaddr end = addr + size;\n    uint8_t *s, *d = dest;\n    size_t l = 0;\n    Rom *rom;\n\n    QTAILQ_FOREACH(rom, &roms, next) {\n        if (rom->fw_file) {\n            continue;\n        }\n        if (rom->mr) {\n            continue;\n        }\n        if (rom->addr + rom->romsize < addr) {\n            continue;\n        }\n        if (rom->addr > end) {\n            break;\n        }\n\n        d = dest + (rom->addr - addr);\n        s = rom->data;\n        l = rom->datasize;\n\n        if ((d + l) > (dest + size)) {\n            l = dest - d;\n        }\n\n        if (l > 0) {\n            memcpy(d, s, l);\n        }\n\n        if (rom->romsize > rom->datasize) {\n            /* If datasize is less than romsize, it means that we didn't\n             * allocate all the ROM because the trailing data are only zeros.\n             */\n\n            d += l;\n            l = rom->romsize - rom->datasize;\n\n            if ((d + l) > (dest + size)) {\n                /* Rom size doesn't fit in the destination area. Adjust to avoid\n                 * overflow.\n                 */\n                l = dest - d;\n            }\n\n            if (l > 0) {\n                memset(d, 0x0, l);\n            }\n        }\n    }\n\n    return (d + l) - dest;\n}", "func_src_after": "int rom_copy(uint8_t *dest, hwaddr addr, size_t size)\n{\n    hwaddr end = addr + size;\n    uint8_t *s, *d = dest;\n    size_t l = 0;\n    Rom *rom;\n\n    QTAILQ_FOREACH(rom, &roms, next) {\n        if (rom->fw_file) {\n            continue;\n        }\n        if (rom->mr) {\n            continue;\n        }\n        if (rom->addr + rom->romsize < addr) {\n            continue;\n        }\n        if (rom->addr > end || rom->addr < addr) {\n            break;\n        }\n\n        d = dest + (rom->addr - addr);\n        s = rom->data;\n        l = rom->datasize;\n\n        if ((d + l) > (dest + size)) {\n            l = dest - d;\n        }\n\n        if (l > 0) {\n            memcpy(d, s, l);\n        }\n\n        if (rom->romsize > rom->datasize) {\n            /* If datasize is less than romsize, it means that we didn't\n             * allocate all the ROM because the trailing data are only zeros.\n             */\n\n            d += l;\n            l = rom->romsize - rom->datasize;\n\n            if ((d + l) > (dest + size)) {\n                /* Rom size doesn't fit in the destination area. Adjust to avoid\n                 * overflow.\n                 */\n                l = dest - d;\n            }\n\n            if (l > 0) {\n                memset(d, 0x0, l);\n            }\n        }\n    }\n\n    return (d + l) - dest;\n}", "commit_link": "github.com/qemu/qemu/commit/4f1c6cb2f9afafda05eab150fd2bd284edce6676", "file_name": "hw/core/loader.c", "vul_type": "cwe-787", "description": "Write a C function named `rom_copy` that copies ROM data to a destination buffer, handling memory regions and zero-filling as needed."}
{"func_name": "asylo::primitives::TrustedPrimitives::UntrustedCall", "func_src_before": "PrimitiveStatus TrustedPrimitives::UntrustedCall(uint64_t untrusted_selector,\n                                                 MessageWriter *input,\n                                                 MessageReader *output) {\n  int ret;\n\n  UntrustedCacheMalloc *untrusted_cache = UntrustedCacheMalloc::Instance();\n\n  SgxParams *const sgx_params =\n      reinterpret_cast<SgxParams *>(untrusted_cache->Malloc(sizeof(SgxParams)));\n  Cleanup clean_up(\n      [sgx_params, untrusted_cache] { untrusted_cache->Free(sgx_params); });\n  sgx_params->input_size = 0;\n  sgx_params->input = nullptr;\n  if (input) {\n    sgx_params->input_size = input->MessageSize();\n    if (sgx_params->input_size > 0) {\n      // Allocate and copy data to |input_buffer|.\n      sgx_params->input = untrusted_cache->Malloc(sgx_params->input_size);\n      input->Serialize(const_cast<void *>(sgx_params->input));\n    }\n  }\n  sgx_params->output_size = 0;\n  sgx_params->output = nullptr;\n  CHECK_OCALL(\n      ocall_dispatch_untrusted_call(&ret, untrusted_selector, sgx_params));\n  if (sgx_params->input) {\n    untrusted_cache->Free(const_cast<void *>(sgx_params->input));\n  }\n  if (sgx_params->output) {\n    // For the results obtained in |output_buffer|, copy them to |output|\n    // before freeing the buffer.\n    output->Deserialize(sgx_params->output, sgx_params->output_size);\n    TrustedPrimitives::UntrustedLocalFree(sgx_params->output);\n  }\n  return PrimitiveStatus::OkStatus();\n}", "func_src_after": "PrimitiveStatus TrustedPrimitives::UntrustedCall(uint64_t untrusted_selector,\n                                                 MessageWriter *input,\n                                                 MessageReader *output) {\n  int ret;\n\n  UntrustedCacheMalloc *untrusted_cache = UntrustedCacheMalloc::Instance();\n\n  SgxParams *const sgx_params =\n      reinterpret_cast<SgxParams *>(untrusted_cache->Malloc(sizeof(SgxParams)));\n  Cleanup clean_up(\n      [sgx_params, untrusted_cache] { untrusted_cache->Free(sgx_params); });\n  sgx_params->input_size = 0;\n  sgx_params->input = nullptr;\n  if (input) {\n    sgx_params->input_size = input->MessageSize();\n    if (sgx_params->input_size > 0) {\n      // Allocate and copy data to |input_buffer|.\n      sgx_params->input = untrusted_cache->Malloc(sgx_params->input_size);\n      input->Serialize(const_cast<void *>(sgx_params->input));\n    }\n  }\n  sgx_params->output_size = 0;\n  sgx_params->output = nullptr;\n  CHECK_OCALL(\n      ocall_dispatch_untrusted_call(&ret, untrusted_selector, sgx_params));\n  if (sgx_params->input) {\n    untrusted_cache->Free(const_cast<void *>(sgx_params->input));\n  }\n  if (!TrustedPrimitives::IsOutsideEnclave(sgx_params->output,\n                                           sgx_params->output_size)) {\n    TrustedPrimitives::BestEffortAbort(\n        \"UntrustedCall: sgx_param output should be in untrusted memory\");\n  }\n  if (sgx_params->output) {\n    // For the results obtained in |output_buffer|, copy them to |output|\n    // before freeing the buffer.\n    output->Deserialize(sgx_params->output, sgx_params->output_size);\n    TrustedPrimitives::UntrustedLocalFree(sgx_params->output);\n  }\n  return PrimitiveStatus::OkStatus();\n}", "commit_link": "github.com/google/asylo/commit/83036fd841d33baa7e039f842d131aa7881fdcc2", "file_name": "asylo/platform/primitives/sgx/trusted_sgx.cc", "vul_type": "cwe-125", "description": "Write a C++ function for handling an untrusted call with input and output message serialization in a secure enclave environment."}
{"func_name": "ipxitf_ioctl", "func_src_before": "static int ipxitf_ioctl(unsigned int cmd, void __user *arg)\n{\n\tint rc = -EINVAL;\n\tstruct ifreq ifr;\n\tint val;\n\n\tswitch (cmd) {\n\tcase SIOCSIFADDR: {\n\t\tstruct sockaddr_ipx *sipx;\n\t\tstruct ipx_interface_definition f;\n\n\t\trc = -EFAULT;\n\t\tif (copy_from_user(&ifr, arg, sizeof(ifr)))\n\t\t\tbreak;\n\t\tsipx = (struct sockaddr_ipx *)&ifr.ifr_addr;\n\t\trc = -EINVAL;\n\t\tif (sipx->sipx_family != AF_IPX)\n\t\t\tbreak;\n\t\tf.ipx_network = sipx->sipx_network;\n\t\tmemcpy(f.ipx_device, ifr.ifr_name,\n\t\t\tsizeof(f.ipx_device));\n\t\tmemcpy(f.ipx_node, sipx->sipx_node, IPX_NODE_LEN);\n\t\tf.ipx_dlink_type = sipx->sipx_type;\n\t\tf.ipx_special = sipx->sipx_special;\n\n\t\tif (sipx->sipx_action == IPX_DLTITF)\n\t\t\trc = ipxitf_delete(&f);\n\t\telse\n\t\t\trc = ipxitf_create(&f);\n\t\tbreak;\n\t}\n\tcase SIOCGIFADDR: {\n\t\tstruct sockaddr_ipx *sipx;\n\t\tstruct ipx_interface *ipxif;\n\t\tstruct net_device *dev;\n\n\t\trc = -EFAULT;\n\t\tif (copy_from_user(&ifr, arg, sizeof(ifr)))\n\t\t\tbreak;\n\t\tsipx = (struct sockaddr_ipx *)&ifr.ifr_addr;\n\t\tdev  = __dev_get_by_name(&init_net, ifr.ifr_name);\n\t\trc   = -ENODEV;\n\t\tif (!dev)\n\t\t\tbreak;\n\t\tipxif = ipxitf_find_using_phys(dev,\n\t\t\t\t\t   ipx_map_frame_type(sipx->sipx_type));\n\t\trc = -EADDRNOTAVAIL;\n\t\tif (!ipxif)\n\t\t\tbreak;\n\n\t\tsipx->sipx_family\t= AF_IPX;\n\t\tsipx->sipx_network\t= ipxif->if_netnum;\n\t\tmemcpy(sipx->sipx_node, ipxif->if_node,\n\t\t\tsizeof(sipx->sipx_node));\n\t\trc = -EFAULT;\n\t\tif (copy_to_user(arg, &ifr, sizeof(ifr)))\n\t\t\tbreak;\n\t\tipxitf_put(ipxif);\n\t\trc = 0;\n\t\tbreak;\n\t}\n\tcase SIOCAIPXITFCRT:\n\t\trc = -EFAULT;\n\t\tif (get_user(val, (unsigned char __user *) arg))\n\t\t\tbreak;\n\t\trc = 0;\n\t\tipxcfg_auto_create_interfaces = val;\n\t\tbreak;\n\tcase SIOCAIPXPRISLT:\n\t\trc = -EFAULT;\n\t\tif (get_user(val, (unsigned char __user *) arg))\n\t\t\tbreak;\n\t\trc = 0;\n\t\tipxcfg_set_auto_select(val);\n\t\tbreak;\n\t}\n\n\treturn rc;\n}", "func_src_after": "static int ipxitf_ioctl(unsigned int cmd, void __user *arg)\n{\n\tint rc = -EINVAL;\n\tstruct ifreq ifr;\n\tint val;\n\n\tswitch (cmd) {\n\tcase SIOCSIFADDR: {\n\t\tstruct sockaddr_ipx *sipx;\n\t\tstruct ipx_interface_definition f;\n\n\t\trc = -EFAULT;\n\t\tif (copy_from_user(&ifr, arg, sizeof(ifr)))\n\t\t\tbreak;\n\t\tsipx = (struct sockaddr_ipx *)&ifr.ifr_addr;\n\t\trc = -EINVAL;\n\t\tif (sipx->sipx_family != AF_IPX)\n\t\t\tbreak;\n\t\tf.ipx_network = sipx->sipx_network;\n\t\tmemcpy(f.ipx_device, ifr.ifr_name,\n\t\t\tsizeof(f.ipx_device));\n\t\tmemcpy(f.ipx_node, sipx->sipx_node, IPX_NODE_LEN);\n\t\tf.ipx_dlink_type = sipx->sipx_type;\n\t\tf.ipx_special = sipx->sipx_special;\n\n\t\tif (sipx->sipx_action == IPX_DLTITF)\n\t\t\trc = ipxitf_delete(&f);\n\t\telse\n\t\t\trc = ipxitf_create(&f);\n\t\tbreak;\n\t}\n\tcase SIOCGIFADDR: {\n\t\tstruct sockaddr_ipx *sipx;\n\t\tstruct ipx_interface *ipxif;\n\t\tstruct net_device *dev;\n\n\t\trc = -EFAULT;\n\t\tif (copy_from_user(&ifr, arg, sizeof(ifr)))\n\t\t\tbreak;\n\t\tsipx = (struct sockaddr_ipx *)&ifr.ifr_addr;\n\t\tdev  = __dev_get_by_name(&init_net, ifr.ifr_name);\n\t\trc   = -ENODEV;\n\t\tif (!dev)\n\t\t\tbreak;\n\t\tipxif = ipxitf_find_using_phys(dev,\n\t\t\t\t\t   ipx_map_frame_type(sipx->sipx_type));\n\t\trc = -EADDRNOTAVAIL;\n\t\tif (!ipxif)\n\t\t\tbreak;\n\n\t\tsipx->sipx_family\t= AF_IPX;\n\t\tsipx->sipx_network\t= ipxif->if_netnum;\n\t\tmemcpy(sipx->sipx_node, ipxif->if_node,\n\t\t\tsizeof(sipx->sipx_node));\n\t\trc = 0;\n\t\tif (copy_to_user(arg, &ifr, sizeof(ifr)))\n\t\t\trc = -EFAULT;\n\t\tipxitf_put(ipxif);\n\t\tbreak;\n\t}\n\tcase SIOCAIPXITFCRT:\n\t\trc = -EFAULT;\n\t\tif (get_user(val, (unsigned char __user *) arg))\n\t\t\tbreak;\n\t\trc = 0;\n\t\tipxcfg_auto_create_interfaces = val;\n\t\tbreak;\n\tcase SIOCAIPXPRISLT:\n\t\trc = -EFAULT;\n\t\tif (get_user(val, (unsigned char __user *) arg))\n\t\t\tbreak;\n\t\trc = 0;\n\t\tipxcfg_set_auto_select(val);\n\t\tbreak;\n\t}\n\n\treturn rc;\n}", "commit_link": "github.com/torvalds/linux/commit/ee0d8d8482345ff97a75a7d747efc309f13b0d80", "file_name": "net/ipx/af_ipx.c", "vul_type": "cwe-416", "description": "Write a C function named `ipxitf_ioctl` that handles IPX network interface control commands."}
{"func_name": "decode_studio_vop_header", "func_src_before": "static int decode_studio_vop_header(Mpeg4DecContext *ctx, GetBitContext *gb)\n{\n    MpegEncContext *s = &ctx->m;\n\n    if (get_bits_left(gb) <= 32)\n        return 0;\n\n    s->partitioned_frame = 0;\n    s->decode_mb = mpeg4_decode_studio_mb;\n\n    decode_smpte_tc(ctx, gb);\n\n    skip_bits(gb, 10); /* temporal_reference */\n    skip_bits(gb, 2); /* vop_structure */\n    s->pict_type = get_bits(gb, 2) + AV_PICTURE_TYPE_I; /* vop_coding_type */\n    if (get_bits1(gb)) { /* vop_coded */\n        skip_bits1(gb); /* top_field_first */\n        skip_bits1(gb); /* repeat_first_field */\n        s->progressive_frame = get_bits1(gb) ^ 1; /* progressive_frame */\n    }\n\n    if (s->pict_type == AV_PICTURE_TYPE_I) {\n        if (get_bits1(gb))\n            reset_studio_dc_predictors(s);\n    }\n\n    if (ctx->shape != BIN_ONLY_SHAPE) {\n        s->alternate_scan = get_bits1(gb);\n        s->frame_pred_frame_dct = get_bits1(gb);\n        s->dct_precision = get_bits(gb, 2);\n        s->intra_dc_precision = get_bits(gb, 2);\n        s->q_scale_type = get_bits1(gb);\n    }\n\n    if (s->alternate_scan) {\n        ff_init_scantable(s->idsp.idct_permutation, &s->inter_scantable,   ff_alternate_vertical_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_scantable,   ff_alternate_vertical_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_h_scantable, ff_alternate_vertical_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_v_scantable, ff_alternate_vertical_scan);\n    } else {\n        ff_init_scantable(s->idsp.idct_permutation, &s->inter_scantable,   ff_zigzag_direct);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_scantable,   ff_zigzag_direct);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_h_scantable, ff_alternate_horizontal_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_v_scantable, ff_alternate_vertical_scan);\n    }\n\n    mpeg4_load_default_matrices(s);\n\n    next_start_code_studio(gb);\n    extension_and_user_data(s, gb, 4);\n\n    return 0;\n}", "func_src_after": "static int decode_studio_vop_header(Mpeg4DecContext *ctx, GetBitContext *gb)\n{\n    MpegEncContext *s = &ctx->m;\n\n    if (get_bits_left(gb) <= 32)\n        return 0;\n\n    s->partitioned_frame = 0;\n    s->interlaced_dct = 0;\n    s->decode_mb = mpeg4_decode_studio_mb;\n\n    decode_smpte_tc(ctx, gb);\n\n    skip_bits(gb, 10); /* temporal_reference */\n    skip_bits(gb, 2); /* vop_structure */\n    s->pict_type = get_bits(gb, 2) + AV_PICTURE_TYPE_I; /* vop_coding_type */\n    if (get_bits1(gb)) { /* vop_coded */\n        skip_bits1(gb); /* top_field_first */\n        skip_bits1(gb); /* repeat_first_field */\n        s->progressive_frame = get_bits1(gb) ^ 1; /* progressive_frame */\n    }\n\n    if (s->pict_type == AV_PICTURE_TYPE_I) {\n        if (get_bits1(gb))\n            reset_studio_dc_predictors(s);\n    }\n\n    if (ctx->shape != BIN_ONLY_SHAPE) {\n        s->alternate_scan = get_bits1(gb);\n        s->frame_pred_frame_dct = get_bits1(gb);\n        s->dct_precision = get_bits(gb, 2);\n        s->intra_dc_precision = get_bits(gb, 2);\n        s->q_scale_type = get_bits1(gb);\n    }\n\n    if (s->alternate_scan) {\n        ff_init_scantable(s->idsp.idct_permutation, &s->inter_scantable,   ff_alternate_vertical_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_scantable,   ff_alternate_vertical_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_h_scantable, ff_alternate_vertical_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_v_scantable, ff_alternate_vertical_scan);\n    } else {\n        ff_init_scantable(s->idsp.idct_permutation, &s->inter_scantable,   ff_zigzag_direct);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_scantable,   ff_zigzag_direct);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_h_scantable, ff_alternate_horizontal_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_v_scantable, ff_alternate_vertical_scan);\n    }\n\n    mpeg4_load_default_matrices(s);\n\n    next_start_code_studio(gb);\n    extension_and_user_data(s, gb, 4);\n\n    return 0;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/1f686d023b95219db933394a7704ad9aa5f01cbb", "file_name": "libavcodec/mpeg4videodec.c", "vul_type": "cwe-125", "description": "Write a C function to decode the header of a studio video object plane (VOP) for an MPEG4 decoder context."}
{"func_name": "read_config", "func_src_before": "    def read_config(self):\n        \"\"\"Populate the instance with settings for the config file.\n\n        If we can't find any section for the given site, error gracefully.\n\n        \"\"\"\n        defaults = {\n            \"auth_type\": \"basic\",\n            \"verify_ssl_cert\": \"true\",\n        }\n\n        cp = configparser.RawConfigParser(defaults)\n        cp.read(CONFIG_LOCATIONS)\n\n        if not cp.has_option(self.site, \"base_url\"):\n            raise exceptions.ConfigError(\"unable to find a [{}] section with \"\n                                         \"a base_url.\".format(self.site))\n\n        self.base_url = cp.get(self.site, \"base_url\").rstrip(\"/\")\n        self.username = cp.get(self.site, \"username\")\n        self.password = cp.get(self.site, \"password\")\n        self.verify_ssl_cert = cp.getboolean(self.site, \"verify_ssl_cert\")\n\n        # load auth\n        auth_type = cp.get(self.site, \"auth_type\")\n        auth_type = auth_type.lower()\n        if auth_type not in AUTH_TYPES:\n            supported_auths = \", \".join(sorted(AUTH_TYPES.keys()))\n            msg = (\"invalid auth setting '{}', supported: {}\"\n                  .format(auth_type, supported_auths))\n            raise exceptions.ConfigError(msg)\n        self.auth_type = auth_type\n\n        self.required_fields = [\"To\", \"Component\", \"Subject\", \"Priority\"]", "func_src_after": "    def read_config(self):\n        \"\"\"Populate the instance with settings for the config file.\n\n        If we can't find any section for the given site, error gracefully.\n\n        \"\"\"\n        defaults = {\n            \"auth_type\": \"basic\",\n            \"verify_ssl_cert\": \"true\",\n        }\n\n        cp = configparser.RawConfigParser(defaults)\n        cp.read(CONFIG_LOCATIONS)\n\n        if not cp.has_option(self.site, \"base_url\"):\n            raise exceptions.ConfigError(\"unable to find a [{}] section with \"\n                                         \"a base_url.\".format(self.site))\n\n        self.base_url = cp.get(self.site, \"base_url\").rstrip(\"/\")\n        self.username = cp.get(self.site, \"username\")\n        self.password = cp.get(self.site, \"password\")\n        self.verify_ssl_cert = cp.getboolean(self.site, \"verify_ssl_cert\")\n\n        # load auth\n        auth_type = cp.get(self.site, \"auth_type\")\n        auth_type = auth_type.lower()\n        if auth_type not in AUTH_TYPES:\n            supported_auths = \", \".join(sorted(AUTH_TYPES.keys()))\n            msg = (\"invalid auth setting '{}', supported: {}\"\n                  .format(auth_type, supported_auths))\n            raise exceptions.ConfigError(msg)\n        self.auth_type = auth_type\n\n        if cp.has_option(self.site, \"editor\"):\n            self.config_editor = cp.get(self.site, \"editor\")\n        else:\n            self.config_editor = os.getenv(\"EDITOR\")\n\n        self.required_fields = [\"To\", \"Component\", \"Subject\", \"Priority\"]", "line_changes": {"deleted": [], "added": [{"line_no": 34, "char_start": 1248, "char_end": 1295, "line": "        if cp.has_option(self.site, \"editor\"):\n"}, {"line_no": 35, "char_start": 1295, "char_end": 1356, "line": "            self.config_editor = cp.get(self.site, \"editor\")\n"}, {"line_no": 36, "char_start": 1356, "char_end": 1370, "line": "        else:\n"}, {"line_no": 37, "char_start": 1370, "char_end": 1423, "line": "            self.config_editor = os.getenv(\"EDITOR\")\n"}, {"line_no": 38, "char_start": 1423, "char_end": 1424, "line": "\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 1248, "char_end": 1424, "chars": "        if cp.has_option(self.site, \"editor\"):\n            self.config_editor = cp.get(self.site, \"editor\")\n        else:\n            self.config_editor = os.getenv(\"EDITOR\")\n\n"}]}, "commit_link": "github.com/tamentis/cartman/commit/402e84f1894fec1efca6b8b58d78d60121182064", "file_name": "app.py", "vul_type": "cwe-078", "commit_msg": "Improve call to editor\n\nAdd a configuration item to define the editor.\n\nUse subprocess.call() to avoid shell usage and escaping problems.\n\nCheck editor return value.", "parent_commit": "994c2174041ebb25d58d7fc23eb0581dcb8fb864", "description": "Write a Python function to load configuration settings from a file, handling missing sections or options with custom exceptions."}
{"func_name": "openscript", "func_src_before": "openscript(\n    char_u\t*name,\n    int\t\tdirectly)\t/* when TRUE execute directly */\n{\n    if (curscript + 1 == NSCRIPT)\n    {\n\temsg(_(e_nesting));\n\treturn;\n    }\n#ifdef FEAT_EVAL\n    if (ignore_script)\n\t/* Not reading from script, also don't open one.  Warning message? */\n\treturn;\n#endif\n\n    if (scriptin[curscript] != NULL)\t/* already reading script */\n\t++curscript;\n\t\t\t\t/* use NameBuff for expanded name */\n    expand_env(name, NameBuff, MAXPATHL);\n    if ((scriptin[curscript] = mch_fopen((char *)NameBuff, READBIN)) == NULL)\n    {\n\tsemsg(_(e_notopen), name);\n\tif (curscript)\n\t    --curscript;\n\treturn;\n    }\n    if (save_typebuf() == FAIL)\n\treturn;\n\n    /*\n     * Execute the commands from the file right now when using \":source!\"\n     * after \":global\" or \":argdo\" or in a loop.  Also when another command\n     * follows.  This means the display won't be updated.  Don't do this\n     * always, \"make test\" would fail.\n     */\n    if (directly)\n    {\n\toparg_T\toa;\n\tint\toldcurscript;\n\tint\tsave_State = State;\n\tint\tsave_restart_edit = restart_edit;\n\tint\tsave_insertmode = p_im;\n\tint\tsave_finish_op = finish_op;\n\tint\tsave_msg_scroll = msg_scroll;\n\n\tState = NORMAL;\n\tmsg_scroll = FALSE;\t/* no msg scrolling in Normal mode */\n\trestart_edit = 0;\t/* don't go to Insert mode */\n\tp_im = FALSE;\t\t/* don't use 'insertmode' */\n\tclear_oparg(&oa);\n\tfinish_op = FALSE;\n\n\toldcurscript = curscript;\n\tdo\n\t{\n\t    update_topline_cursor();\t// update cursor position and topline\n\t    normal_cmd(&oa, FALSE);\t// execute one command\n\t    vpeekc();\t\t\t// check for end of file\n\t}\n\twhile (scriptin[oldcurscript] != NULL);\n\n\tState = save_State;\n\tmsg_scroll = save_msg_scroll;\n\trestart_edit = save_restart_edit;\n\tp_im = save_insertmode;\n\tfinish_op = save_finish_op;\n    }\n}", "func_src_after": "openscript(\n    char_u\t*name,\n    int\t\tdirectly)\t/* when TRUE execute directly */\n{\n    if (curscript + 1 == NSCRIPT)\n    {\n\temsg(_(e_nesting));\n\treturn;\n    }\n\n    // Disallow sourcing a file in the sandbox, the commands would be executed\n    // later, possibly outside of the sandbox.\n    if (check_secure())\n\treturn;\n\n#ifdef FEAT_EVAL\n    if (ignore_script)\n\t/* Not reading from script, also don't open one.  Warning message? */\n\treturn;\n#endif\n\n    if (scriptin[curscript] != NULL)\t/* already reading script */\n\t++curscript;\n\t\t\t\t/* use NameBuff for expanded name */\n    expand_env(name, NameBuff, MAXPATHL);\n    if ((scriptin[curscript] = mch_fopen((char *)NameBuff, READBIN)) == NULL)\n    {\n\tsemsg(_(e_notopen), name);\n\tif (curscript)\n\t    --curscript;\n\treturn;\n    }\n    if (save_typebuf() == FAIL)\n\treturn;\n\n    /*\n     * Execute the commands from the file right now when using \":source!\"\n     * after \":global\" or \":argdo\" or in a loop.  Also when another command\n     * follows.  This means the display won't be updated.  Don't do this\n     * always, \"make test\" would fail.\n     */\n    if (directly)\n    {\n\toparg_T\toa;\n\tint\toldcurscript;\n\tint\tsave_State = State;\n\tint\tsave_restart_edit = restart_edit;\n\tint\tsave_insertmode = p_im;\n\tint\tsave_finish_op = finish_op;\n\tint\tsave_msg_scroll = msg_scroll;\n\n\tState = NORMAL;\n\tmsg_scroll = FALSE;\t/* no msg scrolling in Normal mode */\n\trestart_edit = 0;\t/* don't go to Insert mode */\n\tp_im = FALSE;\t\t/* don't use 'insertmode' */\n\tclear_oparg(&oa);\n\tfinish_op = FALSE;\n\n\toldcurscript = curscript;\n\tdo\n\t{\n\t    update_topline_cursor();\t// update cursor position and topline\n\t    normal_cmd(&oa, FALSE);\t// execute one command\n\t    vpeekc();\t\t\t// check for end of file\n\t}\n\twhile (scriptin[oldcurscript] != NULL);\n\n\tState = save_State;\n\tmsg_scroll = save_msg_scroll;\n\trestart_edit = save_restart_edit;\n\tp_im = save_insertmode;\n\tfinish_op = save_finish_op;\n    }\n}", "commit_link": "github.com/vim/vim/commit/53575521406739cf20bbe4e384d88e7dca11f040", "file_name": "src/getchar.c", "vul_type": "cwe-078", "description": "In C, write a function `openscript` that takes a script name and a flag to execute directly, handling script nesting and environment expansion."}
{"func_name": "getGameID", "func_src_before": "def getGameID(ID):\n\tdb.execute(\"SELECT * FROM games WHERE ID = %i\" % ID)\n\tID = db.fetchone()\n\treturn ID", "func_src_after": "def getGameID(ID):\n\tdb.execute(\"SELECT * FROM games WHERE ID = ?\", ID)\n\tID = db.fetchone()\n\treturn ID", "commit_link": "github.com/iScrE4m/XLeague/commit/59cab6e5fd8bd5e47f2418a7c71cb1d4e3cad0d2", "file_name": "plugins/database.py", "vul_type": "cwe-089", "description": "Write a Python function named `getGameID` that retrieves a game's record from a database by its ID using parameterized queries."}
{"func_name": "get_old_sourcebyinstitution_number", "func_src_before": "def get_old_sourcebyinstitution_number(conn, sqlite, sourcebyinstitution):\n    \"\"\"\n    Get all the old sourcebyinstitution number from the SQLite database.\n    \"\"\"\n    query = \"\"\"\n        SELECT\n            titles\n        FROM\n            history\n        WHERE\n            sourcebyinstitution = \"%s\"\n        ORDER BY\n            titles DESC\n        LIMIT 1\n    \"\"\" % sourcebyinstitution\n\n    sqlite.execute(query)\n    for record in sqlite:\n        old_sourcebyinstitution_number = record[0]\n        return old_sourcebyinstitution_number", "func_src_after": "def get_old_sourcebyinstitution_number(conn, sqlite, sourcebyinstitution):\n    \"\"\"\n    Get all the old sourcebyinstitution number from the SQLite database.\n    \"\"\"\n    query = \"\"\"\n        SELECT\n            titles\n        FROM\n            history\n        WHERE\n            sourcebyinstitution = ?\n        ORDER BY\n            titles DESC\n        LIMIT 1\n    \"\"\"\n\n    sqlite.execute(query, (sourcebyinstitution,))\n    for record in sqlite:\n        old_sourcebyinstitution_number = record[0]\n        return old_sourcebyinstitution_number", "commit_link": "github.com/miku/siskin/commit/7fa398d2fea72bf2e8b4808f75df4b3d35ae959a", "file_name": "bin/solrcheckup.py", "vul_type": "cwe-089", "description": "Write a Python function to retrieve the most recent title associated with a given source institution from an SQLite database."}
{"func_name": "test_get_iscsi_ip_active", "func_src_before": "    def test_get_iscsi_ip_active(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record set up\n        self.clear_mox()\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_port_cmd = 'showport'\n        _run_ssh(show_port_cmd, False).AndReturn([pack(PORT_RET), ''])\n\n        show_port_i_cmd = 'showport -iscsi'\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(READY_ISCSI_PORT_RET),\n                                                    ''])\n\n        show_port_i_cmd = 'showport -iscsiname'\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(SHOW_PORT_ISCSI), ''])\n\n        self.mox.ReplayAll()\n\n        config = self.setup_configuration()\n        config.hp3par_iscsi_ips = ['10.10.220.253', '10.10.220.252']\n        self.setup_driver(config, set_up_fakes=False)\n\n        #record\n        self.clear_mox()\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_vlun_cmd = 'showvlun -a -host fakehost'\n        _run_ssh(show_vlun_cmd, False).AndReturn([pack(SHOW_VLUN), ''])\n\n        self.mox.ReplayAll()\n\n        ip = self.driver._get_iscsi_ip('fakehost')\n        self.assertEqual(ip, '10.10.220.253')", "func_src_after": "    def test_get_iscsi_ip_active(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record set up\n        self.clear_mox()\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_port_cmd = ['showport']\n        _run_ssh(show_port_cmd, False).AndReturn([pack(PORT_RET), ''])\n\n        show_port_i_cmd = ['showport', '-iscsi']\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(READY_ISCSI_PORT_RET),\n                                                    ''])\n\n        show_port_i_cmd = ['showport', '-iscsiname']\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(SHOW_PORT_ISCSI), ''])\n\n        self.mox.ReplayAll()\n\n        config = self.setup_configuration()\n        config.hp3par_iscsi_ips = ['10.10.220.253', '10.10.220.252']\n        self.setup_driver(config, set_up_fakes=False)\n\n        #record\n        self.clear_mox()\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_vlun_cmd = ['showvlun', '-a', '-host', 'fakehost']\n        _run_ssh(show_vlun_cmd, False).AndReturn([pack(SHOW_VLUN), ''])\n\n        self.mox.ReplayAll()\n\n        ip = self.driver._get_iscsi_ip('fakehost')\n        self.assertEqual(ip, '10.10.220.253')", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/tests/test_hp3par.py", "vul_type": "cwe-078", "description": "Write a Python unit test function that mocks SSH commands to retrieve an active iSCSI IP address."}
{"func_name": "patch", "func_src_before": "static PyObject* patch(PyObject* self, PyObject* args)\n{\n    char *origData, *newData, *diffBlock, *extraBlock, *diffPtr, *extraPtr;\n    Py_ssize_t origDataLength, newDataLength, diffBlockLength, extraBlockLength;\n    PyObject *controlTuples, *tuple, *results;\n    off_t oldpos, newpos, x, y, z;\n    int i, j, numTuples;\n\n    if (!PyArg_ParseTuple(args, \"s#nO!s#s#\",\n                          &origData, &origDataLength, &newDataLength,\n                          &PyList_Type, &controlTuples,\n                          &diffBlock, &diffBlockLength,\n                          &extraBlock, &extraBlockLength))\n        return NULL;\n\n    /* allocate the memory for the new data */\n    newData = PyMem_Malloc(newDataLength + 1);\n    if (!newData)\n        return PyErr_NoMemory();\n\n    oldpos = 0;\n    newpos = 0;\n    diffPtr = diffBlock;\n    extraPtr = extraBlock;\n    numTuples = PyList_GET_SIZE(controlTuples);\n    for (i = 0; i < numTuples; i++) {\n        tuple = PyList_GET_ITEM(controlTuples, i);\n        if (!PyTuple_Check(tuple)) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_TypeError, \"expecting tuple\");\n            return NULL;\n        }\n        if (PyTuple_GET_SIZE(tuple) != 3) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_TypeError, \"expecting tuple of size 3\");\n            return NULL;\n        }\n        x = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 0));\n        y = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 1));\n        z = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 2));\n        if (newpos + x > newDataLength ||\n                diffPtr + x > diffBlock + diffBlockLength ||\n                extraPtr + y > extraBlock + extraBlockLength) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_ValueError, \"corrupt patch (overflow)\");\n            return NULL;\n        }\n        memcpy(newData + newpos, diffPtr, x);\n        diffPtr += x;\n        for (j = 0; j < x; j++)\n            if ((oldpos + j >= 0) && (oldpos + j < origDataLength))\n                newData[newpos + j] += origData[oldpos + j];\n        newpos += x;\n        oldpos += x;\n        memcpy(newData + newpos, extraPtr, y);\n        extraPtr += y;\n        newpos += y;\n        oldpos += z;\n    }\n\n    /* confirm that a valid patch was applied */\n    if (newpos != newDataLength ||\n            diffPtr != diffBlock + diffBlockLength ||\n            extraPtr != extraBlock + extraBlockLength) {\n        PyMem_Free(newData);\n        PyErr_SetString(PyExc_ValueError, \"corrupt patch (underflow)\");\n        return NULL;\n    }\n\n    results = PyBytes_FromStringAndSize(newData, newDataLength);\n    PyMem_Free(newData);\n    return results;\n}", "func_src_after": "static PyObject* patch(PyObject* self, PyObject* args)\n{\n    char *origData, *newData, *diffBlock, *extraBlock, *diffPtr, *extraPtr;\n    Py_ssize_t origDataLength, newDataLength, diffBlockLength, extraBlockLength;\n    PyObject *controlTuples, *tuple, *results;\n    off_t oldpos, newpos, x, y, z;\n    int i, j, numTuples;\n\n    if (!PyArg_ParseTuple(args, \"s#nO!s#s#\",\n                          &origData, &origDataLength, &newDataLength,\n                          &PyList_Type, &controlTuples,\n                          &diffBlock, &diffBlockLength,\n                          &extraBlock, &extraBlockLength))\n        return NULL;\n\n    /* allocate the memory for the new data */\n    newData = PyMem_Malloc(newDataLength + 1);\n    if (!newData)\n        return PyErr_NoMemory();\n\n    oldpos = 0;\n    newpos = 0;\n    diffPtr = diffBlock;\n    extraPtr = extraBlock;\n    numTuples = PyList_GET_SIZE(controlTuples);\n    for (i = 0; i < numTuples; i++) {\n        tuple = PyList_GET_ITEM(controlTuples, i);\n        if (!PyTuple_Check(tuple)) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_TypeError, \"expecting tuple\");\n            return NULL;\n        }\n        if (PyTuple_GET_SIZE(tuple) != 3) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_TypeError, \"expecting tuple of size 3\");\n            return NULL;\n        }\n        x = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 0));\n        y = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 1));\n        z = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 2));\n        if (newpos + x > newDataLength ||\n                diffPtr + x > diffBlock + diffBlockLength) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_ValueError, \"corrupt patch (overflow)\");\n            return NULL;\n        }\n        memcpy(newData + newpos, diffPtr, x);\n        diffPtr += x;\n        for (j = 0; j < x; j++)\n            if ((oldpos + j >= 0) && (oldpos + j < origDataLength))\n                newData[newpos + j] += origData[oldpos + j];\n        newpos += x;\n        oldpos += x;\n        if (newpos + y > newDataLength ||\n                extraPtr + y > extraBlock + extraBlockLength) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_ValueError, \"corrupt patch (overflow)\");\n            return NULL;\n        }\n        memcpy(newData + newpos, extraPtr, y);\n        extraPtr += y;\n        newpos += y;\n        oldpos += z;\n    }\n\n    /* confirm that a valid patch was applied */\n    if (newpos != newDataLength ||\n            diffPtr != diffBlock + diffBlockLength ||\n            extraPtr != extraBlock + extraBlockLength) {\n        PyMem_Free(newData);\n        PyErr_SetString(PyExc_ValueError, \"corrupt patch (underflow)\");\n        return NULL;\n    }\n\n    results = PyBytes_FromStringAndSize(newData, newDataLength);\n    PyMem_Free(newData);\n    return results;\n}", "commit_link": "github.com/ilanschnell/bsdiff4/commit/49a4cee2feef7deaf9d89e5e793a8824930284d7", "file_name": "bsdiff4/core.c", "vul_type": "cwe-787", "description": "Write a Python C extension function named `patch` that applies a binary patch to given data using control tuples and diff/extra blocks."}
{"func_name": "exports.getBlockInfo", "func_src_before": "exports.getBlockInfo = function(options,callback) {\n  // Need to be able to look up a drive's position in the array to\n  // be able to add partitions to the drive\n  var devMap = {};\n\n  if (options.ignoredev) {\n    var ignoreexp = new RegExp(options.ignoredev);\n  }\n\n  // Are we ignoring any dev majors?\n  var ignoremajor = \"\";\n  if (options.ignoremajor && (options.ignoremajor.length>0)) {\n    ignoremajor = \" --exclude \" + options.ignoremajor.join();\n  }\n\n  // Build the command line\n  var cmd = (options.lsblk?options.lsblk:\"/bin/lsblk\") + \n      \" -bPo NAME,KNAME,FSTYPE,LABEL,UUID,RO,RM,MODEL,SIZE,STATE,TYPE\" +\n      ignoremajor;\n\n  // Run it\n  var aProc = exec(cmd, function(error, stdout, stderr) {\n    if (error !== null) {\n      // Something went wrong.\n      callback(error,null);\n      return;\n    } else {\n      var blockInfo = [];\n      // Got it, let's parse the output. Split into lines and iterate...\n      var lines = stdout.split('\\n');\n      for (var i=0; i < lines.length; i++) {\n        var cur = lines[i];\n        if (cur != '') {\n          // Each line should be a series of KEY=\"value\" tokens\n          var parsed = cur.match(/[A-Z0-9]+?=\".*?\"/g);\n          var oneDev = {};\n          for (var j=0; j<parsed.length; j++) {\n            // For each token, break out the key and value\n            var keyval = parsed[j].split('=');\n            var key = keyval[0];\n            var val = keyval[1].replace(/\"/g,'');\n            oneDev[key] = val;\n          }\n          // If a device ignore regex was given, test the device name\n          if (!options.ignoredev || (!ignoreexp.test(oneDev['NAME']))) {\n            // What kind of thing is this?\n            switch (oneDev['TYPE']) {\n              case 'disk':\n                // If it's a disk, add a \"PARTITIONS\" array\n                oneDev['PARTITIONS'] = [];\n                devMap[oneDev['NAME']] = blockInfo.length;\n                blockInfo[blockInfo.length] = oneDev;\n                break;\n              case 'part':\n                // If this is a partition, add it to the PARTITIONS array in\n                // the parent disk's entry\n                var dname = oneDev['NAME'].match(/^\\D+/);\n                if (devMap[dname] !== undefined) {\n                  blockInfo[devMap[dname]].PARTITIONS.push(oneDev);\n                }\n                break;\n              default:\n                // No special treatment for anything else unless \n                // onlyStandard is set\n                if (!options.onlyStandard) {\n                  blockInfo[blockInfo.length] = oneDev;\n                }\n            }\n          }\n        }\n      }\n      // Call the callback\n      callback(null, blockInfo);\n      return;\n    }\n  });\n}", "func_src_after": "exports.getBlockInfo = function(options,callback) {\n  // Need to be able to look up a drive's position in the array to\n  // be able to add partitions to the drive\n  var devMap = {};\n\n  var cmdArgs = [\"-bPo\", \"NAME,KNAME,FSTYPE,LABEL,UUID,RO,RM,MODEL,SIZE,STATE,TYPE\" ];\n\n  if (options.ignoredev) {\n    var ignoreexp = new RegExp(options.ignoredev);\n  }\n\n  // Are we ignoring any dev majors?\n  if (options.ignoremajor && (options.ignoremajor.length>0)) {\n    cmdArgs.push(\"--exclude\");\n    cmdArgs.push(options.ignoremajor);\n  }\n\n  // Build the command line\n  var cmd = options.lsblk?options.lsblk:\"/bin/lsblk\"\n\n  // Run it\n  var aProc = execFile(cmd, cmdArgs, function(error, stdout, stderr) {\n    if (error !== null) {\n      // Something went wrong.\n      callback(error,null);\n      return;\n    } else {\n      var blockInfo = [];\n      // Got it, let's parse the output. Split into lines and iterate...\n      var lines = stdout.split('\\n');\n      for (var i=0; i < lines.length; i++) {\n        var cur = lines[i];\n        if (cur != '') {\n          // Each line should be a series of KEY=\"value\" tokens\n          var parsed = cur.match(/[A-Z0-9]+?=\".*?\"/g);\n          var oneDev = {};\n          for (var j=0; j<parsed.length; j++) {\n            // For each token, break out the key and value\n            var keyval = parsed[j].split('=');\n            var key = keyval[0];\n            var val = keyval[1].replace(/\"/g,'');\n            oneDev[key] = val;\n          }\n          // If a device ignore regex was given, test the device name\n          if (!options.ignoredev || (!ignoreexp.test(oneDev['NAME']))) {\n            // What kind of thing is this?\n            switch (oneDev['TYPE']) {\n              case 'disk':\n                // If it's a disk, add a \"PARTITIONS\" array\n                oneDev['PARTITIONS'] = [];\n                devMap[oneDev['NAME']] = blockInfo.length;\n                blockInfo[blockInfo.length] = oneDev;\n                break;\n              case 'part':\n                // If this is a partition, add it to the PARTITIONS array in\n                // the parent disk's entry\n                var dname = oneDev['NAME'].match(/^\\D+/);\n                if (devMap[dname] !== undefined) {\n                  blockInfo[devMap[dname]].PARTITIONS.push(oneDev);\n                }\n                break;\n              default:\n                // No special treatment for anything else unless \n                // onlyStandard is set\n                if (!options.onlyStandard) {\n                  blockInfo[blockInfo.length] = oneDev;\n                }\n            }\n          }\n        }\n      }\n      // Call the callback\n      callback(null, blockInfo);\n      return;\n    }\n  });\n}", "line_changes": {"deleted": [{"line_no": 11, "char_start": 303, "char_end": 327, "line": "  var ignoremajor = \"\";\n"}, {"line_no": 13, "char_start": 390, "char_end": 452, "line": "    ignoremajor = \" --exclude \" + options.ignoremajor.join();\n"}, {"line_no": 17, "char_start": 485, "char_end": 543, "line": "  var cmd = (options.lsblk?options.lsblk:\"/bin/lsblk\") + \n"}, {"line_no": 18, "char_start": 543, "char_end": 616, "line": "      \" -bPo NAME,KNAME,FSTYPE,LABEL,UUID,RO,RM,MODEL,SIZE,STATE,TYPE\" +\n"}, {"line_no": 19, "char_start": 616, "char_end": 635, "line": "      ignoremajor;\n"}, {"line_no": 22, "char_start": 648, "char_end": 706, "line": "  var aProc = exec(cmd, function(error, stdout, stderr) {\n"}], "added": [{"line_no": 6, "char_start": 183, "char_end": 270, "line": "  var cmdArgs = [\"-bPo\", \"NAME,KNAME,FSTYPE,LABEL,UUID,RO,RM,MODEL,SIZE,STATE,TYPE\" ];\n"}, {"line_no": 7, "char_start": 270, "char_end": 271, "line": "\n"}, {"line_no": 14, "char_start": 454, "char_end": 485, "line": "    cmdArgs.push(\"--exclude\");\n"}, {"line_no": 15, "char_start": 485, "char_end": 524, "line": "    cmdArgs.push(options.ignoremajor);\n"}, {"line_no": 19, "char_start": 557, "char_end": 610, "line": "  var cmd = options.lsblk?options.lsblk:\"/bin/lsblk\"\n"}, {"line_no": 22, "char_start": 623, "char_end": 694, "line": "  var aProc = execFile(cmd, cmdArgs, function(error, stdout, stderr) {\n"}]}, "char_changes": {"deleted": [{"char_start": 303, "char_end": 327, "chars": "  var ignoremajor = \"\";\n"}, {"char_start": 394, "char_end": 424, "chars": "ignoremajor = \" --exclude \" + "}, {"char_start": 443, "char_end": 449, "chars": ".join("}, {"char_start": 497, "char_end": 498, "chars": "("}, {"char_start": 538, "char_end": 634, "chars": ") + \n      \" -bPo NAME,KNAME,FSTYPE,LABEL,UUID,RO,RM,MODEL,SIZE,STATE,TYPE\" +\n      ignoremajor;"}, {"char_start": 666, "char_end": 670, "chars": "(cmd"}], "added": [{"char_start": 183, "char_end": 271, "chars": "  var cmdArgs = [\"-bPo\", \"NAME,KNAME,FSTYPE,LABEL,UUID,RO,RM,MODEL,SIZE,STATE,TYPE\" ];\n\n"}, {"char_start": 458, "char_end": 502, "chars": "cmdArgs.push(\"--exclude\");\n    cmdArgs.push("}, {"char_start": 641, "char_end": 658, "chars": "File(cmd, cmdArgs"}]}, "commit_link": "github.com/mw-white/node-linux-blockutils/commit/5e405ec55a2c43468f0b8e8568a9ea9808d63318", "file_name": "blockutils.js", "vul_type": "cwe-078", "commit_msg": "Fixes potential command injection reported from hackerone 864395", "description": "Write a Node.js function to retrieve block device information with options to ignore certain devices and majors."}
{"func_name": "create_list", "func_src_before": "list_t *create_list(void)\n{\n    list_t *list = malloc(sizeof(list_t));\n\n    list->size = 0;\n    list->head = NULL;\n    list->tail = NULL;\n\n    return list;\n}", "func_src_after": "list_t *create_list(void)\n{\n    list_t *list = malloc(sizeof(list_t));\n\n    if (list == NULL)\n        return NULL;\n\n    list->size = 0;\n    list->head = NULL;\n    list->tail = NULL;\n\n    return list;\n}", "commit_link": "github.com/matiasedd/vinapp/commit/663121dc1fb7b9465d1edaa2bf1b25145294ba5b", "file_name": "liblist.c", "vul_type": "cwe-476", "description": "Write a C function named `create_list` that initializes an empty linked list and handles memory allocation failure."}
{"func_name": "gitMtime", "func_src_before": "async function gitMtime(path) {\n  const { stdout } = await execFilePromise('git', ['log', '-1', '--format=\"%at\"', '--', path]);\n\n  return parseInt(stdout.trim().replace('\"', '').trim(), 10);\n}", "func_src_after": "async function gitMtime(path) {\n  const { stdout } = await execFilePromise('git', ['log', '-1', '--format=\"%at\"', '--', path]);\n\n  return parseInt(stdout.trim().replace(/\"/g, '').trim(), 10);\n}", "line_changes": {"deleted": [{"line_no": 4, "char_start": 129, "char_end": 191, "line": "  return parseInt(stdout.trim().replace('\"', '').trim(), 10);\n"}], "added": [{"line_no": 4, "char_start": 129, "char_end": 192, "line": "  return parseInt(stdout.trim().replace(/\"/g, '').trim(), 10);\n"}]}, "char_changes": {"deleted": [{"char_start": 169, "char_end": 172, "chars": "'\"'"}], "added": [{"char_start": 169, "char_end": 173, "chars": "/\"/g"}]}, "commit_link": "github.com/openfoodfacts/openfoodfacts-server/commit/7917218c34b5ae2afe5d6581416c944607e31f36", "file_name": "refresh_taxonomies.js", "vul_type": "cwe-116", "commit_msg": "fix: CWE-116/CWE-20\n\nhttps://github.com/openfoodfacts/openfoodfacts-server/security/code-scanning/4", "parent_commit": "40386e19d82ff72f27066cb2bcbdf539dca0c6be", "description": "Create an asynchronous JavaScript function that retrieves the last modification timestamp of a file using Git."}
{"func_name": "AP4_AtomSampleTable::GetSample", "func_src_before": "AP4_AtomSampleTable::GetSample(AP4_Ordinal index, \n                               AP4_Sample& sample)\n{\n    AP4_Result result;\n\n    // check that we have an stsc atom\n    if (!m_StscAtom) {\n        return AP4_ERROR_INVALID_FORMAT;\n    }\n    \n    // check that we have a chunk offset table\n    if (m_StcoAtom == NULL && m_Co64Atom == NULL) {\n        return AP4_ERROR_INVALID_FORMAT;\n    }\n\n    // MP4 uses 1-based indexes internally, so adjust by one\n    index++;\n\n    // find out in which chunk this sample is located\n    AP4_Ordinal chunk, skip, desc;\n    result = m_StscAtom->GetChunkForSample(index, chunk, skip, desc);\n    if (AP4_FAILED(result)) return result;\n    \n    // check that the result is within bounds\n    if (skip > index) return AP4_ERROR_INTERNAL;\n\n    // get the atom offset for this chunk\n    AP4_UI64 offset;\n    if (m_StcoAtom) {\n        AP4_UI32 offset_32;\n        result = m_StcoAtom->GetChunkOffset(chunk, offset_32);\n        offset = offset_32;\n    } else {\n        result = m_Co64Atom->GetChunkOffset(chunk, offset);\n    }\n    if (AP4_FAILED(result)) return result;\n    \n    // compute the additional offset inside the chunk\n    for (unsigned int i = index-skip; i < index; i++) {\n        AP4_Size size = 0;\n        if (m_StszAtom) {\n            result = m_StszAtom->GetSampleSize(i, size); \n        } else if (m_Stz2Atom) {\n            result = m_Stz2Atom->GetSampleSize(i, size); \n        } else {\n            result = AP4_ERROR_INVALID_FORMAT;\n        }\n        if (AP4_FAILED(result)) return result;\n        offset += size;\n    }\n\n    // set the description index\n    sample.SetDescriptionIndex(desc-1); // adjust for 0-based indexes\n\n    // set the dts and cts\n    AP4_UI32 cts_offset = 0;\n    AP4_UI64 dts        = 0;\n    AP4_UI32 duration   = 0;\n    result = m_SttsAtom->GetDts(index, dts, &duration);\n    if (AP4_FAILED(result)) return result;\n    sample.SetDuration(duration);\n    sample.SetDts(dts);\n    if (m_CttsAtom == NULL) {\n        sample.SetCts(dts);\n    } else {\n        result = m_CttsAtom->GetCtsOffset(index, cts_offset); \n\t    if (AP4_FAILED(result)) return result;\n        sample.SetCtsDelta(cts_offset);\n    }     \n\n    // set the size\n    AP4_Size sample_size = 0;\n    if (m_StszAtom) {\n        result = m_StszAtom->GetSampleSize(index, sample_size); \n    } else if (m_Stz2Atom) {\n        result = m_Stz2Atom->GetSampleSize(index, sample_size); \n    } else {\n        result = AP4_ERROR_INVALID_FORMAT;\n    }\n    if (AP4_FAILED(result)) return result;\n    sample.SetSize(sample_size);\n\n    // set the sync flag\n    if (m_StssAtom == NULL) {\n        sample.SetSync(true);\n    } else {\n        sample.SetSync(m_StssAtom->IsSampleSync(index));\n    }\n\n    // set the offset\n    sample.SetOffset(offset);\n\n    // set the data stream\n    sample.SetDataStream(m_SampleStream);\n\n\n    return AP4_SUCCESS;\n}", "func_src_after": "AP4_AtomSampleTable::GetSample(AP4_Ordinal index, \n                               AP4_Sample& sample)\n{\n    AP4_Result result;\n\n    // check that we have an stsc atom\n    if (!m_StscAtom) {\n        return AP4_ERROR_INVALID_FORMAT;\n    }\n    \n    // check that we have a chunk offset table\n    if (m_StcoAtom == NULL && m_Co64Atom == NULL) {\n        return AP4_ERROR_INVALID_FORMAT;\n    }\n\n    // MP4 uses 1-based indexes internally, so adjust by one\n    index++;\n\n    // find out in which chunk this sample is located\n    AP4_Ordinal chunk, skip, desc;\n    result = m_StscAtom->GetChunkForSample(index, chunk, skip, desc);\n    if (AP4_FAILED(result)) return result;\n    \n    // check that the result is within bounds\n    if (skip > index) return AP4_ERROR_INTERNAL;\n\n    // get the atom offset for this chunk\n    AP4_UI64 offset;\n    if (m_StcoAtom) {\n        AP4_UI32 offset_32;\n        result = m_StcoAtom->GetChunkOffset(chunk, offset_32);\n        offset = offset_32;\n    } else {\n        result = m_Co64Atom->GetChunkOffset(chunk, offset);\n    }\n    if (AP4_FAILED(result)) return result;\n    \n    // compute the additional offset inside the chunk\n    for (unsigned int i = index-skip; i < index; i++) {\n        AP4_Size size = 0;\n        if (m_StszAtom) {\n            result = m_StszAtom->GetSampleSize(i, size); \n        } else if (m_Stz2Atom) {\n            result = m_Stz2Atom->GetSampleSize(i, size); \n        } else {\n            result = AP4_ERROR_INVALID_FORMAT;\n        }\n        if (AP4_FAILED(result)) return result;\n        offset += size;\n    }\n\n    // set the description index\n    sample.SetDescriptionIndex(desc-1); // adjust for 0-based indexes\n\n    // set the dts and cts\n    AP4_UI32 cts_offset = 0;\n    AP4_UI64 dts        = 0;\n    AP4_UI32 duration   = 0;\n    if (m_SttsAtom) {\n        result = m_SttsAtom->GetDts(index, dts, &duration);\n        if (AP4_FAILED(result)) return result;\n    }\n    sample.SetDuration(duration);\n    sample.SetDts(dts);\n    if (m_CttsAtom == NULL) {\n        sample.SetCts(dts);\n    } else {\n        result = m_CttsAtom->GetCtsOffset(index, cts_offset); \n\t    if (AP4_FAILED(result)) return result;\n        sample.SetCtsDelta(cts_offset);\n    }     \n\n    // set the size\n    AP4_Size sample_size = 0;\n    if (m_StszAtom) {\n        result = m_StszAtom->GetSampleSize(index, sample_size); \n    } else if (m_Stz2Atom) {\n        result = m_Stz2Atom->GetSampleSize(index, sample_size); \n    } else {\n        result = AP4_ERROR_INVALID_FORMAT;\n    }\n    if (AP4_FAILED(result)) return result;\n    sample.SetSize(sample_size);\n\n    // set the sync flag\n    if (m_StssAtom == NULL) {\n        sample.SetSync(true);\n    } else {\n        sample.SetSync(m_StssAtom->IsSampleSync(index));\n    }\n\n    // set the offset\n    sample.SetOffset(offset);\n\n    // set the data stream\n    sample.SetDataStream(m_SampleStream);\n\n\n    return AP4_SUCCESS;\n}", "commit_link": "github.com/axiomatic-systems/Bento4/commit/2f267f89f957088197f4b1fc254632d1645b415d", "file_name": "Source/C++/Core/Ap4AtomSampleTable.cpp", "vul_type": "cwe-476", "description": "In C++, write a function to retrieve a media sample from an MP4 file's atom sample table by its index."}
{"func_name": "Writer::Writer", "func_src_before": "Writer::Writer(const char* pathToSave, ToDo& t): todo(t) \n{\n\tstrncpy(path, pathToSave, 128);\n\tpath[128] = '\\0';\n\tfile.imbue(locale(\"\"));\n}", "func_src_after": "Writer::Writer(const char* pathToSave, ToDo& t): todo(t) \n{\n\tstrncpy(path, pathToSave, 255);\n\tpath[255] = '\\0';\n\tfile.imbue(locale(\"\"));\n}", "line_changes": {"deleted": [{"line_no": 3, "char_start": 60, "char_end": 93, "line": "\tstrncpy(path, pathToSave, 128);\n"}, {"line_no": 4, "char_start": 93, "char_end": 112, "line": "\tpath[128] = '\\0';\n"}], "added": [{"line_no": 3, "char_start": 60, "char_end": 93, "line": "\tstrncpy(path, pathToSave, 255);\n"}, {"line_no": 4, "char_start": 93, "char_end": 112, "line": "\tpath[255] = '\\0';\n"}]}, "char_changes": {"deleted": [{"char_start": 87, "char_end": 90, "chars": "128"}, {"char_start": 99, "char_end": 102, "chars": "128"}], "added": [{"char_start": 87, "char_end": 90, "chars": "255"}, {"char_start": 99, "char_end": 102, "chars": "255"}]}, "commit_link": "github.com/meskio/tudu/commit/c51f4c2f92288f923cf33bdc395501f447fe2d5c", "file_name": "parser.cc", "vul_type": "cwe-119", "commit_msg": "Fix out-of-bounds access", "parent_commit": "30923dcb8b7682fec1bdfbf07f904e4d9983e623", "description": "Create a C++ class constructor for a `Writer` class that initializes a `ToDo` object and copies a file path string with a fixed length."}
{"func_name": "mark_context_stack", "func_src_before": "mark_context_stack(mrb_state *mrb, struct mrb_context *c)\n{\n  size_t i;\n  size_t e;\n\n  if (c->stack == NULL) return;\n  e = c->stack - c->stbase;\n  if (c->ci) e += c->ci->nregs;\n  if (c->stbase + e > c->stend) e = c->stend - c->stbase;\n  for (i=0; i<e; i++) {\n    mrb_value v = c->stbase[i];\n\n    if (!mrb_immediate_p(v)) {\n      if (mrb_basic_ptr(v)->tt == MRB_TT_FREE) {\n        c->stbase[i] = mrb_nil_value();\n      }\n      else {\n        mrb_gc_mark(mrb, mrb_basic_ptr(v));\n      }\n    }\n  }\n}", "func_src_after": "mark_context_stack(mrb_state *mrb, struct mrb_context *c)\n{\n  size_t i;\n  size_t e;\n  mrb_value nil;\n\n  if (c->stack == NULL) return;\n  e = c->stack - c->stbase;\n  if (c->ci) e += c->ci->nregs;\n  if (c->stbase + e > c->stend) e = c->stend - c->stbase;\n  for (i=0; i<e; i++) {\n    mrb_value v = c->stbase[i];\n\n    if (!mrb_immediate_p(v)) {\n      mrb_gc_mark(mrb, mrb_basic_ptr(v));\n    }\n  }\n  e = c->stend - c->stbase;\n  nil = mrb_nil_value();\n  for (; i<e; i++) {\n    c->stbase[i] = nil;\n  }\n}", "commit_link": "github.com/mruby/mruby/commit/5c114c91d4ff31859fcd84cf8bf349b737b90d99", "file_name": "src/gc.c", "vul_type": "cwe-416", "description": "Write a function in C for the MRuby engine that marks the stack context for garbage collection."}
{"func_name": "test_get_least_used_nsp", "func_src_before": "    def test_get_least_used_nsp(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record\n        self.clear_mox()\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_vlun_cmd = 'showvlun -a -showcols Port'\n        _run_ssh(show_vlun_cmd, False).AndReturn([pack(SHOW_VLUN_NONE), ''])\n        _run_ssh(show_vlun_cmd, False).AndReturn([pack(SHOW_VLUN_NONE), ''])\n        _run_ssh(show_vlun_cmd, False).AndReturn([pack(SHOW_VLUN_NONE), ''])\n\n        self.mox.ReplayAll()\n        # in use count                           11       12\n        nsp = self.driver._get_least_used_nsp(['0:2:1', '1:8:1'])\n        self.assertEqual(nsp, '0:2:1')\n\n        # in use count                            11       10\n        nsp = self.driver._get_least_used_nsp(['0:2:1', '1:2:1'])\n        self.assertEqual(nsp, '1:2:1')\n\n        # in use count                            0       10\n        nsp = self.driver._get_least_used_nsp(['1:1:1', '1:2:1'])\n        self.assertEqual(nsp, '1:1:1')", "func_src_after": "    def test_get_least_used_nsp(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record\n        self.clear_mox()\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_vlun_cmd = ['showvlun', '-a', '-showcols', 'Port']\n        _run_ssh(show_vlun_cmd, False).AndReturn([pack(SHOW_VLUN_NONE), ''])\n        _run_ssh(show_vlun_cmd, False).AndReturn([pack(SHOW_VLUN_NONE), ''])\n        _run_ssh(show_vlun_cmd, False).AndReturn([pack(SHOW_VLUN_NONE), ''])\n\n        self.mox.ReplayAll()\n        # in use count                           11       12\n        nsp = self.driver._get_least_used_nsp(['0:2:1', '1:8:1'])\n        self.assertEqual(nsp, '0:2:1')\n\n        # in use count                            11       10\n        nsp = self.driver._get_least_used_nsp(['0:2:1', '1:2:1'])\n        self.assertEqual(nsp, '1:2:1')\n\n        # in use count                            0       10\n        nsp = self.driver._get_least_used_nsp(['1:1:1', '1:2:1'])\n        self.assertEqual(nsp, '1:1:1')", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/tests/test_hp3par.py", "vul_type": "cwe-078", "description": "Write a Python unit test function that mocks an SSH command to determine the least used network service provider."}
{"func_name": "misc_file_checks", "func_src_before": "    def misc_file_checks(self):\n\n        print_header(\"MISC FILE CHECKS\")\n\n        #\n        # Check for recommended and mandatory files\n        #\n\n        filenames = (\"manifest.json\", \"LICENSE\", \"README.md\",\n                     \"scripts/install\", \"scripts/remove\",\n                     \"scripts/upgrade\",\n                     \"scripts/backup\", \"scripts/restore\")\n        non_mandatory = (\"script/backup\", \"script/restore\")\n\n        for filename in filenames:\n            if file_exists(self.path + \"/\" + filename):\n                continue\n            elif filename in non_mandatory:\n                print_warning(\"Consider adding a file %s\" % filename)\n            else:\n                print_error(\"File %s is mandatory\" % filename)\n\n        #\n        # Deprecated php-fpm.ini thing\n        #\n\n        if file_exists(self.path + \"/conf/php-fpm.ini\"):\n            print_warning(\n                \"Using a separate php-fpm.ini file is deprecated. \"\n                \"Please merge your php-fpm directives directly in the pool file. \"\n                \"(c.f. https://github.com/YunoHost-Apps/nextcloud_ynh/issues/138 )\"\n            )\n\n        #\n        # Deprecated usage of 'add_header' in nginx conf\n        #\n\n        for filename in os.listdir(self.path + \"/conf\"):\n            if not os.path.isfile(self.path + \"/conf/\" + filename):\n                continue\n            content = open(self.path + \"/conf/\" + filename).read()\n            if \"location\" in content and \"add_header\" in content:\n                print_warning(\n                    \"Do not use 'add_header' in the nginx conf. Use 'more_set_headers' instead. \"\n                    \"(See https://www.peterbe.com/plog/be-very-careful-with-your-add_header-in-nginx \"\n                    \"and https://github.com/openresty/headers-more-nginx-module#more_set_headers )\"\n                )", "func_src_after": "    def misc_file_checks(self):\n\n        print_header(\"MISC FILE CHECKS\")\n\n        #\n        # Check for recommended and mandatory files\n        #\n\n        filenames = (\"manifest.json\", \"LICENSE\", \"README.md\",\n                     \"scripts/install\", \"scripts/remove\",\n                     \"scripts/upgrade\",\n                     \"scripts/backup\", \"scripts/restore\")\n        non_mandatory = (\"script/backup\", \"script/restore\")\n\n        for filename in filenames:\n            if file_exists(self.path + \"/\" + filename):\n                continue\n            elif filename in non_mandatory:\n                print_warning(\"Consider adding a file %s\" % filename)\n            else:\n                print_error(\"File %s is mandatory\" % filename)\n\n        #\n        # Deprecated php-fpm.ini thing\n        #\n\n        if file_exists(self.path + \"/conf/php-fpm.ini\"):\n            print_warning(\n                \"Using a separate php-fpm.ini file is deprecated. \"\n                \"Please merge your php-fpm directives directly in the pool file. \"\n                \"(c.f. https://github.com/YunoHost-Apps/nextcloud_ynh/issues/138 )\"\n            )\n\n        #\n        # Analyze nginx conf\n        # - Deprecated usage of 'add_header' in nginx conf\n        # - Spot path traversal issue vulnerability\n        #\n\n        for filename in os.listdir(self.path + \"/conf\"):\n            # Ignore subdirs or filename not containing nginx in the name\n            if not os.path.isfile(self.path + \"/conf/\" + filename) or \"nginx\" not in filename:\n                continue\n\n            #\n            # 'add_header' usage\n            #\n            content = open(self.path + \"/conf/\" + filename).read()\n            if \"location\" in content and \"add_header\" in content:\n                print_warning(\n                    \"Do not use 'add_header' in the nginx conf. Use 'more_set_headers' instead. \"\n                    \"(See https://www.peterbe.com/plog/be-very-careful-with-your-add_header-in-nginx \"\n                    \"and https://github.com/openresty/headers-more-nginx-module#more_set_headers )\"\n                )\n\n            #\n            # Path traversal issues\n            #\n            lines = open(self.path + \"/conf/\" + filename).readlines()\n            lines = [line.strip() for line in lines if not line.strip().startswith(\"#\")]\n            # Let's find the first location line\n            location_line = None\n            path_traversal_vulnerable = False\n            lines_iter = lines.__iter__()\n            for line in lines_iter:\n                if line.startswith(\"location\"):\n                    location_line = line\n                    break\n            # Look at the next lines for an 'alias' directive\n            if location_line is not None:\n                for line in lines_iter:\n                    if line.startswith(\"location\"):\n                        # Entering a new location block ... abort here\n                        # and assume there's no alias block later...\n                        break\n                    if line.startswith(\"alias\"):\n                        # We should definitely check for path traversal issue\n                        # Does the location target ends with / ?\n                        target = location_line.split()[-2]\n                        if not target.endswith(\"/\"):\n                            path_traversal_vulnerable = True\n                        break\n            if path_traversal_vulnerable:\n                print_warning(\n                    \"The nginx configuration appears vulnerable to path traversal as explained in \"\n                    \"https://www.acunetix.com/vulnerabilities/web/path-traversal-via-misconfigured-nginx-alias/\\n\"\n                    \"To fix it, look at the first lines of the nginx conf of the example app : \"\n                    \"https://github.com/YunoHost/example_ynh/blob/master/conf/nginx.conf\"\n                )", "commit_link": "github.com/YunoHost/package_linter/commit/f6e98894cfe841aedaa7efd590937f0255193913", "file_name": "package_linter.py", "vul_type": "cwe-022", "description": "Write a Python function to check for mandatory files, deprecated configurations, and potential vulnerabilities in a project's file structure and configurations."}
{"func_name": "avpriv_ac3_parse_header", "func_src_before": "int avpriv_ac3_parse_header(AC3HeaderInfo **phdr, const uint8_t *buf,\n                            size_t size)\n{\n    GetBitContext gb;\n    AC3HeaderInfo *hdr;\n    int err;\n\n    if (!*phdr)\n        *phdr = av_mallocz(sizeof(AC3HeaderInfo));\n    if (!*phdr)\n        return AVERROR(ENOMEM);\n    hdr = *phdr;\n\n    init_get_bits8(&gb, buf, size);\n    err = ff_ac3_parse_header(&gb, hdr);\n    if (err < 0)\n        return AVERROR_INVALIDDATA;\n\n    return get_bits_count(&gb);\n}", "func_src_after": "int avpriv_ac3_parse_header(AC3HeaderInfo **phdr, const uint8_t *buf,\n                            size_t size)\n{\n    GetBitContext gb;\n    AC3HeaderInfo *hdr;\n    int err;\n\n    if (!*phdr)\n        *phdr = av_mallocz(sizeof(AC3HeaderInfo));\n    if (!*phdr)\n        return AVERROR(ENOMEM);\n    hdr = *phdr;\n\n    err = init_get_bits8(&gb, buf, size);\n    if (err < 0)\n        return AVERROR_INVALIDDATA;\n    err = ff_ac3_parse_header(&gb, hdr);\n    if (err < 0)\n        return AVERROR_INVALIDDATA;\n\n    return get_bits_count(&gb);\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/00e8181bd97c834fe60751b0c511d4bb97875f78", "file_name": "libavcodec/ac3_parser.c", "vul_type": "cwe-476", "description": "Write a C function named `avpriv_ac3_parse_header` that initializes a bit context and parses the AC3 header from a buffer, returning the number of bits read."}
{"func_name": "flattenSubquery", "func_src_before": "static int flattenSubquery(\n  Parse *pParse,       /* Parsing context */\n  Select *p,           /* The parent or outer SELECT statement */\n  int iFrom,           /* Index in p->pSrc->a[] of the inner subquery */\n  int isAgg            /* True if outer SELECT uses aggregate functions */\n){\n  const char *zSavedAuthContext = pParse->zAuthContext;\n  Select *pParent;    /* Current UNION ALL term of the other query */\n  Select *pSub;       /* The inner query or \"subquery\" */\n  Select *pSub1;      /* Pointer to the rightmost select in sub-query */\n  SrcList *pSrc;      /* The FROM clause of the outer query */\n  SrcList *pSubSrc;   /* The FROM clause of the subquery */\n  int iParent;        /* VDBE cursor number of the pSub result set temp table */\n  int iNewParent = -1;/* Replacement table for iParent */\n  int isLeftJoin = 0; /* True if pSub is the right side of a LEFT JOIN */    \n  int i;              /* Loop counter */\n  Expr *pWhere;                    /* The WHERE clause */\n  struct SrcList_item *pSubitem;   /* The subquery */\n  sqlite3 *db = pParse->db;\n\n  /* Check to see if flattening is permitted.  Return 0 if not.\n  */\n  assert( p!=0 );\n  assert( p->pPrior==0 );\n  if( OptimizationDisabled(db, SQLITE_QueryFlattener) ) return 0;\n  pSrc = p->pSrc;\n  assert( pSrc && iFrom>=0 && iFrom<pSrc->nSrc );\n  pSubitem = &pSrc->a[iFrom];\n  iParent = pSubitem->iCursor;\n  pSub = pSubitem->pSelect;\n  assert( pSub!=0 );\n\n#ifndef SQLITE_OMIT_WINDOWFUNC\n  if( p->pWin || pSub->pWin ) return 0;                  /* Restriction (25) */\n#endif\n\n  pSubSrc = pSub->pSrc;\n  assert( pSubSrc );\n  /* Prior to version 3.1.2, when LIMIT and OFFSET had to be simple constants,\n  ** not arbitrary expressions, we allowed some combining of LIMIT and OFFSET\n  ** because they could be computed at compile-time.  But when LIMIT and OFFSET\n  ** became arbitrary expressions, we were forced to add restrictions (13)\n  ** and (14). */\n  if( pSub->pLimit && p->pLimit ) return 0;              /* Restriction (13) */\n  if( pSub->pLimit && pSub->pLimit->pRight ) return 0;   /* Restriction (14) */\n  if( (p->selFlags & SF_Compound)!=0 && pSub->pLimit ){\n    return 0;                                            /* Restriction (15) */\n  }\n  if( pSubSrc->nSrc==0 ) return 0;                       /* Restriction (7)  */\n  if( pSub->selFlags & SF_Distinct ) return 0;           /* Restriction (4)  */\n  if( pSub->pLimit && (pSrc->nSrc>1 || isAgg) ){\n     return 0;         /* Restrictions (8)(9) */\n  }\n  if( p->pOrderBy && pSub->pOrderBy ){\n     return 0;                                           /* Restriction (11) */\n  }\n  if( isAgg && pSub->pOrderBy ) return 0;                /* Restriction (16) */\n  if( pSub->pLimit && p->pWhere ) return 0;              /* Restriction (19) */\n  if( pSub->pLimit && (p->selFlags & SF_Distinct)!=0 ){\n     return 0;         /* Restriction (21) */\n  }\n  if( pSub->selFlags & (SF_Recursive) ){\n    return 0; /* Restrictions (22) */\n  }\n\n  /*\n  ** If the subquery is the right operand of a LEFT JOIN, then the\n  ** subquery may not be a join itself (3a). Example of why this is not\n  ** allowed:\n  **\n  **         t1 LEFT OUTER JOIN (t2 JOIN t3)\n  **\n  ** If we flatten the above, we would get\n  **\n  **         (t1 LEFT OUTER JOIN t2) JOIN t3\n  **\n  ** which is not at all the same thing.\n  **\n  ** If the subquery is the right operand of a LEFT JOIN, then the outer\n  ** query cannot be an aggregate. (3c)  This is an artifact of the way\n  ** aggregates are processed - there is no mechanism to determine if\n  ** the LEFT JOIN table should be all-NULL.\n  **\n  ** See also tickets #306, #350, and #3300.\n  */\n  if( (pSubitem->fg.jointype & JT_OUTER)!=0 ){\n    isLeftJoin = 1;\n    if( pSubSrc->nSrc>1 || isAgg || IsVirtual(pSubSrc->a[0].pTab) ){\n      /*  (3a)             (3c)     (3b) */\n      return 0;\n    }\n  }\n#ifdef SQLITE_EXTRA_IFNULLROW\n  else if( iFrom>0 && !isAgg ){\n    /* Setting isLeftJoin to -1 causes OP_IfNullRow opcodes to be generated for\n    ** every reference to any result column from subquery in a join, even\n    ** though they are not necessary.  This will stress-test the OP_IfNullRow \n    ** opcode. */\n    isLeftJoin = -1;\n  }\n#endif\n\n  /* Restriction (17): If the sub-query is a compound SELECT, then it must\n  ** use only the UNION ALL operator. And none of the simple select queries\n  ** that make up the compound SELECT are allowed to be aggregate or distinct\n  ** queries.\n  */\n  if( pSub->pPrior ){\n    if( pSub->pOrderBy ){\n      return 0;  /* Restriction (20) */\n    }\n    if( isAgg || (p->selFlags & SF_Distinct)!=0 || pSrc->nSrc!=1 ){\n      return 0; /* (17d1), (17d2), or (17d3) */\n    }\n    for(pSub1=pSub; pSub1; pSub1=pSub1->pPrior){\n      testcase( (pSub1->selFlags & (SF_Distinct|SF_Aggregate))==SF_Distinct );\n      testcase( (pSub1->selFlags & (SF_Distinct|SF_Aggregate))==SF_Aggregate );\n      assert( pSub->pSrc!=0 );\n      assert( pSub->pEList->nExpr==pSub1->pEList->nExpr );\n      if( (pSub1->selFlags & (SF_Distinct|SF_Aggregate))!=0    /* (17b) */\n       || (pSub1->pPrior && pSub1->op!=TK_ALL)                 /* (17a) */\n       || pSub1->pSrc->nSrc<1                                  /* (17c) */\n      ){\n        return 0;\n      }\n      testcase( pSub1->pSrc->nSrc>1 );\n    }\n\n    /* Restriction (18). */\n    if( p->pOrderBy ){\n      int ii;\n      for(ii=0; ii<p->pOrderBy->nExpr; ii++){\n        if( p->pOrderBy->a[ii].u.x.iOrderByCol==0 ) return 0;\n      }\n    }\n  }\n\n  /* Ex-restriction (23):\n  ** The only way that the recursive part of a CTE can contain a compound\n  ** subquery is for the subquery to be one term of a join.  But if the\n  ** subquery is a join, then the flattening has already been stopped by\n  ** restriction (17d3)\n  */\n  assert( (p->selFlags & SF_Recursive)==0 || pSub->pPrior==0 );\n\n  /***** If we reach this point, flattening is permitted. *****/\n  SELECTTRACE(1,pParse,p,(\"flatten %u.%p from term %d\\n\",\n                   pSub->selId, pSub, iFrom));\n\n  /* Authorize the subquery */\n  pParse->zAuthContext = pSubitem->zName;\n  TESTONLY(i =) sqlite3AuthCheck(pParse, SQLITE_SELECT, 0, 0, 0);\n  testcase( i==SQLITE_DENY );\n  pParse->zAuthContext = zSavedAuthContext;\n\n  /* If the sub-query is a compound SELECT statement, then (by restrictions\n  ** 17 and 18 above) it must be a UNION ALL and the parent query must \n  ** be of the form:\n  **\n  **     SELECT <expr-list> FROM (<sub-query>) <where-clause> \n  **\n  ** followed by any ORDER BY, LIMIT and/or OFFSET clauses. This block\n  ** creates N-1 copies of the parent query without any ORDER BY, LIMIT or \n  ** OFFSET clauses and joins them to the left-hand-side of the original\n  ** using UNION ALL operators. In this case N is the number of simple\n  ** select statements in the compound sub-query.\n  **\n  ** Example:\n  **\n  **     SELECT a+1 FROM (\n  **        SELECT x FROM tab\n  **        UNION ALL\n  **        SELECT y FROM tab\n  **        UNION ALL\n  **        SELECT abs(z*2) FROM tab2\n  **     ) WHERE a!=5 ORDER BY 1\n  **\n  ** Transformed into:\n  **\n  **     SELECT x+1 FROM tab WHERE x+1!=5\n  **     UNION ALL\n  **     SELECT y+1 FROM tab WHERE y+1!=5\n  **     UNION ALL\n  **     SELECT abs(z*2)+1 FROM tab2 WHERE abs(z*2)+1!=5\n  **     ORDER BY 1\n  **\n  ** We call this the \"compound-subquery flattening\".\n  */\n  for(pSub=pSub->pPrior; pSub; pSub=pSub->pPrior){\n    Select *pNew;\n    ExprList *pOrderBy = p->pOrderBy;\n    Expr *pLimit = p->pLimit;\n    Select *pPrior = p->pPrior;\n    p->pOrderBy = 0;\n    p->pSrc = 0;\n    p->pPrior = 0;\n    p->pLimit = 0;\n    pNew = sqlite3SelectDup(db, p, 0);\n    p->pLimit = pLimit;\n    p->pOrderBy = pOrderBy;\n    p->pSrc = pSrc;\n    p->op = TK_ALL;\n    if( pNew==0 ){\n      p->pPrior = pPrior;\n    }else{\n      pNew->pPrior = pPrior;\n      if( pPrior ) pPrior->pNext = pNew;\n      pNew->pNext = p;\n      p->pPrior = pNew;\n      SELECTTRACE(2,pParse,p,(\"compound-subquery flattener\"\n                              \" creates %u as peer\\n\",pNew->selId));\n    }\n    if( db->mallocFailed ) return 1;\n  }\n\n  /* Begin flattening the iFrom-th entry of the FROM clause \n  ** in the outer query.\n  */\n  pSub = pSub1 = pSubitem->pSelect;\n\n  /* Delete the transient table structure associated with the\n  ** subquery\n  */\n  sqlite3DbFree(db, pSubitem->zDatabase);\n  sqlite3DbFree(db, pSubitem->zName);\n  sqlite3DbFree(db, pSubitem->zAlias);\n  pSubitem->zDatabase = 0;\n  pSubitem->zName = 0;\n  pSubitem->zAlias = 0;\n  pSubitem->pSelect = 0;\n\n  /* Defer deleting the Table object associated with the\n  ** subquery until code generation is\n  ** complete, since there may still exist Expr.pTab entries that\n  ** refer to the subquery even after flattening.  Ticket #3346.\n  **\n  ** pSubitem->pTab is always non-NULL by test restrictions and tests above.\n  */\n  if( ALWAYS(pSubitem->pTab!=0) ){\n    Table *pTabToDel = pSubitem->pTab;\n    if( pTabToDel->nTabRef==1 ){\n      Parse *pToplevel = sqlite3ParseToplevel(pParse);\n      pTabToDel->pNextZombie = pToplevel->pZombieTab;\n      pToplevel->pZombieTab = pTabToDel;\n    }else{\n      pTabToDel->nTabRef--;\n    }\n    pSubitem->pTab = 0;\n  }\n\n  /* The following loop runs once for each term in a compound-subquery\n  ** flattening (as described above).  If we are doing a different kind\n  ** of flattening - a flattening other than a compound-subquery flattening -\n  ** then this loop only runs once.\n  **\n  ** This loop moves all of the FROM elements of the subquery into the\n  ** the FROM clause of the outer query.  Before doing this, remember\n  ** the cursor number for the original outer query FROM element in\n  ** iParent.  The iParent cursor will never be used.  Subsequent code\n  ** will scan expressions looking for iParent references and replace\n  ** those references with expressions that resolve to the subquery FROM\n  ** elements we are now copying in.\n  */\n  for(pParent=p; pParent; pParent=pParent->pPrior, pSub=pSub->pPrior){\n    int nSubSrc;\n    u8 jointype = 0;\n    assert( pSub!=0 );\n    pSubSrc = pSub->pSrc;     /* FROM clause of subquery */\n    nSubSrc = pSubSrc->nSrc;  /* Number of terms in subquery FROM clause */\n    pSrc = pParent->pSrc;     /* FROM clause of the outer query */\n\n    if( pSrc ){\n      assert( pParent==p );  /* First time through the loop */\n      jointype = pSubitem->fg.jointype;\n    }else{\n      assert( pParent!=p );  /* 2nd and subsequent times through the loop */\n      pSrc = sqlite3SrcListAppend(pParse, 0, 0, 0);\n      if( pSrc==0 ) break;\n      pParent->pSrc = pSrc;\n    }\n\n    /* The subquery uses a single slot of the FROM clause of the outer\n    ** query.  If the subquery has more than one element in its FROM clause,\n    ** then expand the outer query to make space for it to hold all elements\n    ** of the subquery.\n    **\n    ** Example:\n    **\n    **    SELECT * FROM tabA, (SELECT * FROM sub1, sub2), tabB;\n    **\n    ** The outer query has 3 slots in its FROM clause.  One slot of the\n    ** outer query (the middle slot) is used by the subquery.  The next\n    ** block of code will expand the outer query FROM clause to 4 slots.\n    ** The middle slot is expanded to two slots in order to make space\n    ** for the two elements in the FROM clause of the subquery.\n    */\n    if( nSubSrc>1 ){\n      pSrc = sqlite3SrcListEnlarge(pParse, pSrc, nSubSrc-1,iFrom+1);\n      if( pSrc==0 ) break;\n      pParent->pSrc = pSrc;\n    }\n\n    /* Transfer the FROM clause terms from the subquery into the\n    ** outer query.\n    */\n    for(i=0; i<nSubSrc; i++){\n      sqlite3IdListDelete(db, pSrc->a[i+iFrom].pUsing);\n      assert( pSrc->a[i+iFrom].fg.isTabFunc==0 );\n      pSrc->a[i+iFrom] = pSubSrc->a[i];\n      iNewParent = pSubSrc->a[i].iCursor;\n      memset(&pSubSrc->a[i], 0, sizeof(pSubSrc->a[i]));\n    }\n    pSrc->a[iFrom].fg.jointype = jointype;\n  \n    /* Now begin substituting subquery result set expressions for \n    ** references to the iParent in the outer query.\n    ** \n    ** Example:\n    **\n    **   SELECT a+5, b*10 FROM (SELECT x*3 AS a, y+10 AS b FROM t1) WHERE a>b;\n    **   \\                     \\_____________ subquery __________/          /\n    **    \\_____________________ outer query ______________________________/\n    **\n    ** We look at every expression in the outer query and every place we see\n    ** \"a\" we substitute \"x*3\" and every place we see \"b\" we substitute \"y+10\".\n    */\n    if( pSub->pOrderBy ){\n      /* At this point, any non-zero iOrderByCol values indicate that the\n      ** ORDER BY column expression is identical to the iOrderByCol'th\n      ** expression returned by SELECT statement pSub. Since these values\n      ** do not necessarily correspond to columns in SELECT statement pParent,\n      ** zero them before transfering the ORDER BY clause.\n      **\n      ** Not doing this may cause an error if a subsequent call to this\n      ** function attempts to flatten a compound sub-query into pParent\n      ** (the only way this can happen is if the compound sub-query is\n      ** currently part of pSub->pSrc). See ticket [d11a6e908f].  */\n      ExprList *pOrderBy = pSub->pOrderBy;\n      for(i=0; i<pOrderBy->nExpr; i++){\n        pOrderBy->a[i].u.x.iOrderByCol = 0;\n      }\n      assert( pParent->pOrderBy==0 );\n      pParent->pOrderBy = pOrderBy;\n      pSub->pOrderBy = 0;\n    }\n    pWhere = pSub->pWhere;\n    pSub->pWhere = 0;\n    if( isLeftJoin>0 ){\n      sqlite3SetJoinExpr(pWhere, iNewParent);\n    }\n    pParent->pWhere = sqlite3ExprAnd(pParse, pWhere, pParent->pWhere);\n    if( db->mallocFailed==0 ){\n      SubstContext x;\n      x.pParse = pParse;\n      x.iTable = iParent;\n      x.iNewTable = iNewParent;\n      x.isLeftJoin = isLeftJoin;\n      x.pEList = pSub->pEList;\n      substSelect(&x, pParent, 0);\n    }\n  \n    /* The flattened query is a compound if either the inner or the\n    ** outer query is a compound. */\n    pParent->selFlags |= pSub->selFlags & SF_Compound;\n    assert( (pSub->selFlags & SF_Distinct)==0 ); /* restriction (17b) */\n  \n    /*\n    ** SELECT ... FROM (SELECT ... LIMIT a OFFSET b) LIMIT x OFFSET y;\n    **\n    ** One is tempted to try to add a and b to combine the limits.  But this\n    ** does not work if either limit is negative.\n    */\n    if( pSub->pLimit ){\n      pParent->pLimit = pSub->pLimit;\n      pSub->pLimit = 0;\n    }\n  }\n\n  /* Finially, delete what is left of the subquery and return\n  ** success.\n  */\n  sqlite3SelectDelete(db, pSub1);\n\n#if SELECTTRACE_ENABLED\n  if( sqlite3SelectTrace & 0x100 ){\n    SELECTTRACE(0x100,pParse,p,(\"After flattening:\\n\"));\n    sqlite3TreeViewSelect(0, p, 0);\n  }\n#endif\n\n  return 1;\n}", "func_src_after": "static int flattenSubquery(\n  Parse *pParse,       /* Parsing context */\n  Select *p,           /* The parent or outer SELECT statement */\n  int iFrom,           /* Index in p->pSrc->a[] of the inner subquery */\n  int isAgg            /* True if outer SELECT uses aggregate functions */\n){\n  const char *zSavedAuthContext = pParse->zAuthContext;\n  Select *pParent;    /* Current UNION ALL term of the other query */\n  Select *pSub;       /* The inner query or \"subquery\" */\n  Select *pSub1;      /* Pointer to the rightmost select in sub-query */\n  SrcList *pSrc;      /* The FROM clause of the outer query */\n  SrcList *pSubSrc;   /* The FROM clause of the subquery */\n  int iParent;        /* VDBE cursor number of the pSub result set temp table */\n  int iNewParent = -1;/* Replacement table for iParent */\n  int isLeftJoin = 0; /* True if pSub is the right side of a LEFT JOIN */    \n  int i;              /* Loop counter */\n  Expr *pWhere;                    /* The WHERE clause */\n  struct SrcList_item *pSubitem;   /* The subquery */\n  sqlite3 *db = pParse->db;\n\n  /* Check to see if flattening is permitted.  Return 0 if not.\n  */\n  assert( p!=0 );\n  assert( p->pPrior==0 );\n  if( OptimizationDisabled(db, SQLITE_QueryFlattener) ) return 0;\n  pSrc = p->pSrc;\n  assert( pSrc && iFrom>=0 && iFrom<pSrc->nSrc );\n  pSubitem = &pSrc->a[iFrom];\n  iParent = pSubitem->iCursor;\n  pSub = pSubitem->pSelect;\n  assert( pSub!=0 );\n\n#ifndef SQLITE_OMIT_WINDOWFUNC\n  if( p->pWin || pSub->pWin ) return 0;                  /* Restriction (25) */\n#endif\n\n  pSubSrc = pSub->pSrc;\n  assert( pSubSrc );\n  /* Prior to version 3.1.2, when LIMIT and OFFSET had to be simple constants,\n  ** not arbitrary expressions, we allowed some combining of LIMIT and OFFSET\n  ** because they could be computed at compile-time.  But when LIMIT and OFFSET\n  ** became arbitrary expressions, we were forced to add restrictions (13)\n  ** and (14). */\n  if( pSub->pLimit && p->pLimit ) return 0;              /* Restriction (13) */\n  if( pSub->pLimit && pSub->pLimit->pRight ) return 0;   /* Restriction (14) */\n  if( (p->selFlags & SF_Compound)!=0 && pSub->pLimit ){\n    return 0;                                            /* Restriction (15) */\n  }\n  if( pSubSrc->nSrc==0 ) return 0;                       /* Restriction (7)  */\n  if( pSub->selFlags & SF_Distinct ) return 0;           /* Restriction (4)  */\n  if( pSub->pLimit && (pSrc->nSrc>1 || isAgg) ){\n     return 0;         /* Restrictions (8)(9) */\n  }\n  if( p->pOrderBy && pSub->pOrderBy ){\n     return 0;                                           /* Restriction (11) */\n  }\n  if( isAgg && pSub->pOrderBy ) return 0;                /* Restriction (16) */\n  if( pSub->pLimit && p->pWhere ) return 0;              /* Restriction (19) */\n  if( pSub->pLimit && (p->selFlags & SF_Distinct)!=0 ){\n     return 0;         /* Restriction (21) */\n  }\n  if( pSub->selFlags & (SF_Recursive) ){\n    return 0; /* Restrictions (22) */\n  }\n\n  /*\n  ** If the subquery is the right operand of a LEFT JOIN, then the\n  ** subquery may not be a join itself (3a). Example of why this is not\n  ** allowed:\n  **\n  **         t1 LEFT OUTER JOIN (t2 JOIN t3)\n  **\n  ** If we flatten the above, we would get\n  **\n  **         (t1 LEFT OUTER JOIN t2) JOIN t3\n  **\n  ** which is not at all the same thing.\n  **\n  ** If the subquery is the right operand of a LEFT JOIN, then the outer\n  ** query cannot be an aggregate. (3c)  This is an artifact of the way\n  ** aggregates are processed - there is no mechanism to determine if\n  ** the LEFT JOIN table should be all-NULL.\n  **\n  ** See also tickets #306, #350, and #3300.\n  */\n  if( (pSubitem->fg.jointype & JT_OUTER)!=0 ){\n    isLeftJoin = 1;\n    if( pSubSrc->nSrc>1                   /* (3a) */\n     || isAgg                             /* (3b) */\n     || IsVirtual(pSubSrc->a[0].pTab)     /* (3c) */\n     || (p->selFlags & SF_Distinct)!=0    /* (3d) */\n    ){\n      return 0;\n    }\n  }\n#ifdef SQLITE_EXTRA_IFNULLROW\n  else if( iFrom>0 && !isAgg ){\n    /* Setting isLeftJoin to -1 causes OP_IfNullRow opcodes to be generated for\n    ** every reference to any result column from subquery in a join, even\n    ** though they are not necessary.  This will stress-test the OP_IfNullRow \n    ** opcode. */\n    isLeftJoin = -1;\n  }\n#endif\n\n  /* Restriction (17): If the sub-query is a compound SELECT, then it must\n  ** use only the UNION ALL operator. And none of the simple select queries\n  ** that make up the compound SELECT are allowed to be aggregate or distinct\n  ** queries.\n  */\n  if( pSub->pPrior ){\n    if( pSub->pOrderBy ){\n      return 0;  /* Restriction (20) */\n    }\n    if( isAgg || (p->selFlags & SF_Distinct)!=0 || pSrc->nSrc!=1 ){\n      return 0; /* (17d1), (17d2), or (17d3) */\n    }\n    for(pSub1=pSub; pSub1; pSub1=pSub1->pPrior){\n      testcase( (pSub1->selFlags & (SF_Distinct|SF_Aggregate))==SF_Distinct );\n      testcase( (pSub1->selFlags & (SF_Distinct|SF_Aggregate))==SF_Aggregate );\n      assert( pSub->pSrc!=0 );\n      assert( pSub->pEList->nExpr==pSub1->pEList->nExpr );\n      if( (pSub1->selFlags & (SF_Distinct|SF_Aggregate))!=0    /* (17b) */\n       || (pSub1->pPrior && pSub1->op!=TK_ALL)                 /* (17a) */\n       || pSub1->pSrc->nSrc<1                                  /* (17c) */\n      ){\n        return 0;\n      }\n      testcase( pSub1->pSrc->nSrc>1 );\n    }\n\n    /* Restriction (18). */\n    if( p->pOrderBy ){\n      int ii;\n      for(ii=0; ii<p->pOrderBy->nExpr; ii++){\n        if( p->pOrderBy->a[ii].u.x.iOrderByCol==0 ) return 0;\n      }\n    }\n  }\n\n  /* Ex-restriction (23):\n  ** The only way that the recursive part of a CTE can contain a compound\n  ** subquery is for the subquery to be one term of a join.  But if the\n  ** subquery is a join, then the flattening has already been stopped by\n  ** restriction (17d3)\n  */\n  assert( (p->selFlags & SF_Recursive)==0 || pSub->pPrior==0 );\n\n  /***** If we reach this point, flattening is permitted. *****/\n  SELECTTRACE(1,pParse,p,(\"flatten %u.%p from term %d\\n\",\n                   pSub->selId, pSub, iFrom));\n\n  /* Authorize the subquery */\n  pParse->zAuthContext = pSubitem->zName;\n  TESTONLY(i =) sqlite3AuthCheck(pParse, SQLITE_SELECT, 0, 0, 0);\n  testcase( i==SQLITE_DENY );\n  pParse->zAuthContext = zSavedAuthContext;\n\n  /* If the sub-query is a compound SELECT statement, then (by restrictions\n  ** 17 and 18 above) it must be a UNION ALL and the parent query must \n  ** be of the form:\n  **\n  **     SELECT <expr-list> FROM (<sub-query>) <where-clause> \n  **\n  ** followed by any ORDER BY, LIMIT and/or OFFSET clauses. This block\n  ** creates N-1 copies of the parent query without any ORDER BY, LIMIT or \n  ** OFFSET clauses and joins them to the left-hand-side of the original\n  ** using UNION ALL operators. In this case N is the number of simple\n  ** select statements in the compound sub-query.\n  **\n  ** Example:\n  **\n  **     SELECT a+1 FROM (\n  **        SELECT x FROM tab\n  **        UNION ALL\n  **        SELECT y FROM tab\n  **        UNION ALL\n  **        SELECT abs(z*2) FROM tab2\n  **     ) WHERE a!=5 ORDER BY 1\n  **\n  ** Transformed into:\n  **\n  **     SELECT x+1 FROM tab WHERE x+1!=5\n  **     UNION ALL\n  **     SELECT y+1 FROM tab WHERE y+1!=5\n  **     UNION ALL\n  **     SELECT abs(z*2)+1 FROM tab2 WHERE abs(z*2)+1!=5\n  **     ORDER BY 1\n  **\n  ** We call this the \"compound-subquery flattening\".\n  */\n  for(pSub=pSub->pPrior; pSub; pSub=pSub->pPrior){\n    Select *pNew;\n    ExprList *pOrderBy = p->pOrderBy;\n    Expr *pLimit = p->pLimit;\n    Select *pPrior = p->pPrior;\n    p->pOrderBy = 0;\n    p->pSrc = 0;\n    p->pPrior = 0;\n    p->pLimit = 0;\n    pNew = sqlite3SelectDup(db, p, 0);\n    p->pLimit = pLimit;\n    p->pOrderBy = pOrderBy;\n    p->pSrc = pSrc;\n    p->op = TK_ALL;\n    if( pNew==0 ){\n      p->pPrior = pPrior;\n    }else{\n      pNew->pPrior = pPrior;\n      if( pPrior ) pPrior->pNext = pNew;\n      pNew->pNext = p;\n      p->pPrior = pNew;\n      SELECTTRACE(2,pParse,p,(\"compound-subquery flattener\"\n                              \" creates %u as peer\\n\",pNew->selId));\n    }\n    if( db->mallocFailed ) return 1;\n  }\n\n  /* Begin flattening the iFrom-th entry of the FROM clause \n  ** in the outer query.\n  */\n  pSub = pSub1 = pSubitem->pSelect;\n\n  /* Delete the transient table structure associated with the\n  ** subquery\n  */\n  sqlite3DbFree(db, pSubitem->zDatabase);\n  sqlite3DbFree(db, pSubitem->zName);\n  sqlite3DbFree(db, pSubitem->zAlias);\n  pSubitem->zDatabase = 0;\n  pSubitem->zName = 0;\n  pSubitem->zAlias = 0;\n  pSubitem->pSelect = 0;\n\n  /* Defer deleting the Table object associated with the\n  ** subquery until code generation is\n  ** complete, since there may still exist Expr.pTab entries that\n  ** refer to the subquery even after flattening.  Ticket #3346.\n  **\n  ** pSubitem->pTab is always non-NULL by test restrictions and tests above.\n  */\n  if( ALWAYS(pSubitem->pTab!=0) ){\n    Table *pTabToDel = pSubitem->pTab;\n    if( pTabToDel->nTabRef==1 ){\n      Parse *pToplevel = sqlite3ParseToplevel(pParse);\n      pTabToDel->pNextZombie = pToplevel->pZombieTab;\n      pToplevel->pZombieTab = pTabToDel;\n    }else{\n      pTabToDel->nTabRef--;\n    }\n    pSubitem->pTab = 0;\n  }\n\n  /* The following loop runs once for each term in a compound-subquery\n  ** flattening (as described above).  If we are doing a different kind\n  ** of flattening - a flattening other than a compound-subquery flattening -\n  ** then this loop only runs once.\n  **\n  ** This loop moves all of the FROM elements of the subquery into the\n  ** the FROM clause of the outer query.  Before doing this, remember\n  ** the cursor number for the original outer query FROM element in\n  ** iParent.  The iParent cursor will never be used.  Subsequent code\n  ** will scan expressions looking for iParent references and replace\n  ** those references with expressions that resolve to the subquery FROM\n  ** elements we are now copying in.\n  */\n  for(pParent=p; pParent; pParent=pParent->pPrior, pSub=pSub->pPrior){\n    int nSubSrc;\n    u8 jointype = 0;\n    assert( pSub!=0 );\n    pSubSrc = pSub->pSrc;     /* FROM clause of subquery */\n    nSubSrc = pSubSrc->nSrc;  /* Number of terms in subquery FROM clause */\n    pSrc = pParent->pSrc;     /* FROM clause of the outer query */\n\n    if( pSrc ){\n      assert( pParent==p );  /* First time through the loop */\n      jointype = pSubitem->fg.jointype;\n    }else{\n      assert( pParent!=p );  /* 2nd and subsequent times through the loop */\n      pSrc = sqlite3SrcListAppend(pParse, 0, 0, 0);\n      if( pSrc==0 ) break;\n      pParent->pSrc = pSrc;\n    }\n\n    /* The subquery uses a single slot of the FROM clause of the outer\n    ** query.  If the subquery has more than one element in its FROM clause,\n    ** then expand the outer query to make space for it to hold all elements\n    ** of the subquery.\n    **\n    ** Example:\n    **\n    **    SELECT * FROM tabA, (SELECT * FROM sub1, sub2), tabB;\n    **\n    ** The outer query has 3 slots in its FROM clause.  One slot of the\n    ** outer query (the middle slot) is used by the subquery.  The next\n    ** block of code will expand the outer query FROM clause to 4 slots.\n    ** The middle slot is expanded to two slots in order to make space\n    ** for the two elements in the FROM clause of the subquery.\n    */\n    if( nSubSrc>1 ){\n      pSrc = sqlite3SrcListEnlarge(pParse, pSrc, nSubSrc-1,iFrom+1);\n      if( pSrc==0 ) break;\n      pParent->pSrc = pSrc;\n    }\n\n    /* Transfer the FROM clause terms from the subquery into the\n    ** outer query.\n    */\n    for(i=0; i<nSubSrc; i++){\n      sqlite3IdListDelete(db, pSrc->a[i+iFrom].pUsing);\n      assert( pSrc->a[i+iFrom].fg.isTabFunc==0 );\n      pSrc->a[i+iFrom] = pSubSrc->a[i];\n      iNewParent = pSubSrc->a[i].iCursor;\n      memset(&pSubSrc->a[i], 0, sizeof(pSubSrc->a[i]));\n    }\n    pSrc->a[iFrom].fg.jointype = jointype;\n  \n    /* Now begin substituting subquery result set expressions for \n    ** references to the iParent in the outer query.\n    ** \n    ** Example:\n    **\n    **   SELECT a+5, b*10 FROM (SELECT x*3 AS a, y+10 AS b FROM t1) WHERE a>b;\n    **   \\                     \\_____________ subquery __________/          /\n    **    \\_____________________ outer query ______________________________/\n    **\n    ** We look at every expression in the outer query and every place we see\n    ** \"a\" we substitute \"x*3\" and every place we see \"b\" we substitute \"y+10\".\n    */\n    if( pSub->pOrderBy ){\n      /* At this point, any non-zero iOrderByCol values indicate that the\n      ** ORDER BY column expression is identical to the iOrderByCol'th\n      ** expression returned by SELECT statement pSub. Since these values\n      ** do not necessarily correspond to columns in SELECT statement pParent,\n      ** zero them before transfering the ORDER BY clause.\n      **\n      ** Not doing this may cause an error if a subsequent call to this\n      ** function attempts to flatten a compound sub-query into pParent\n      ** (the only way this can happen is if the compound sub-query is\n      ** currently part of pSub->pSrc). See ticket [d11a6e908f].  */\n      ExprList *pOrderBy = pSub->pOrderBy;\n      for(i=0; i<pOrderBy->nExpr; i++){\n        pOrderBy->a[i].u.x.iOrderByCol = 0;\n      }\n      assert( pParent->pOrderBy==0 );\n      pParent->pOrderBy = pOrderBy;\n      pSub->pOrderBy = 0;\n    }\n    pWhere = pSub->pWhere;\n    pSub->pWhere = 0;\n    if( isLeftJoin>0 ){\n      sqlite3SetJoinExpr(pWhere, iNewParent);\n    }\n    pParent->pWhere = sqlite3ExprAnd(pParse, pWhere, pParent->pWhere);\n    if( db->mallocFailed==0 ){\n      SubstContext x;\n      x.pParse = pParse;\n      x.iTable = iParent;\n      x.iNewTable = iNewParent;\n      x.isLeftJoin = isLeftJoin;\n      x.pEList = pSub->pEList;\n      substSelect(&x, pParent, 0);\n    }\n  \n    /* The flattened query is a compound if either the inner or the\n    ** outer query is a compound. */\n    pParent->selFlags |= pSub->selFlags & SF_Compound;\n    assert( (pSub->selFlags & SF_Distinct)==0 ); /* restriction (17b) */\n  \n    /*\n    ** SELECT ... FROM (SELECT ... LIMIT a OFFSET b) LIMIT x OFFSET y;\n    **\n    ** One is tempted to try to add a and b to combine the limits.  But this\n    ** does not work if either limit is negative.\n    */\n    if( pSub->pLimit ){\n      pParent->pLimit = pSub->pLimit;\n      pSub->pLimit = 0;\n    }\n  }\n\n  /* Finially, delete what is left of the subquery and return\n  ** success.\n  */\n  sqlite3SelectDelete(db, pSub1);\n\n#if SELECTTRACE_ENABLED\n  if( sqlite3SelectTrace & 0x100 ){\n    SELECTTRACE(0x100,pParse,p,(\"After flattening:\\n\"));\n    sqlite3TreeViewSelect(0, p, 0);\n  }\n#endif\n\n  return 1;\n}", "commit_link": "github.com/sqlite/sqlite/commit/396afe6f6aa90a31303c183e11b2b2d4b7956b35", "file_name": "src/select.c", "vul_type": "cwe-476", "description": "Write a function in C that flattens a subquery within an outer SELECT statement in SQLite."}
{"func_name": "php_wddx_push_element", "func_src_before": " */\nstatic void php_wddx_push_element(void *user_data, const XML_Char *name, const XML_Char **atts)\n{\n\tst_entry ent;\n\twddx_stack *stack = (wddx_stack *)user_data;\n\n\tif (!strcmp(name, EL_PACKET)) {\n\t\tint i;\n\n\t\tif (atts) for (i=0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_VERSION)) {\n\t\t\t\t/* nothing for now */\n\t\t\t}\n\t\t}\n\t} else if (!strcmp(name, EL_STRING)) {\n\t\tent.type = ST_STRING;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZ_TYPE_P(ent.data) = IS_STRING;\n\t\tZ_STRVAL_P(ent.data) = STR_EMPTY_ALLOC();\n\t\tZ_STRLEN_P(ent.data) = 0;\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_BINARY)) {\n\t\tent.type = ST_BINARY;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZ_TYPE_P(ent.data) = IS_STRING;\n\t\tZ_STRVAL_P(ent.data) = STR_EMPTY_ALLOC();\n\t\tZ_STRLEN_P(ent.data) = 0;\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_CHAR)) {\n\t\tint i;\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_CHAR_CODE) && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tchar tmp_buf[2];\n\n\t\t\t\tsnprintf(tmp_buf, sizeof(tmp_buf), \"%c\", (char)strtol(atts[i+1], NULL, 16));\n\t\t\t\tphp_wddx_process_data(user_data, tmp_buf, strlen(tmp_buf));\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t} else if (!strcmp(name, EL_NUMBER)) {\n\t\tent.type = ST_NUMBER;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZ_TYPE_P(ent.data) = IS_LONG;\n\t\tZ_LVAL_P(ent.data) = 0;\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_BOOLEAN)) {\n\t\tint i;\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_VALUE) && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tent.type = ST_BOOLEAN;\n\t\t\t\tSET_STACK_VARNAME;\n\n\t\t\t\tALLOC_ZVAL(ent.data);\n\t\t\t\tINIT_PZVAL(ent.data);\n\t\t\t\tZ_TYPE_P(ent.data) = IS_BOOL;\n\t\t\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t\t\t\tphp_wddx_process_data(user_data, atts[i+1], strlen(atts[i+1]));\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t} else if (!strcmp(name, EL_NULL)) {\n\t\tent.type = ST_NULL;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZVAL_NULL(ent.data);\n\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_ARRAY)) {\n\t\tent.type = ST_ARRAY;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tarray_init(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_STRUCT)) {\n\t\tent.type = ST_STRUCT;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tarray_init(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_VAR)) {\n\t\tint i;\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_NAME) && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tif (stack->varname) efree(stack->varname);\n\t\t\t\tstack->varname = estrdup(atts[i+1]);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t} else if (!strcmp(name, EL_RECORDSET)) {\n\t\tint i;\n\n\t\tent.type = ST_RECORDSET;\n\t\tSET_STACK_VARNAME;\n\t\tMAKE_STD_ZVAL(ent.data);\n\t\tarray_init(ent.data);\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], \"fieldNames\") && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tzval *tmp;\n\t\t\t\tchar *key;\n\t\t\t\tchar *p1, *p2, *endp;\n\n\t\t\t\ti++;\n\t\t\t\tendp = (char *)atts[i] + strlen(atts[i]);\n\t\t\t\tp1 = (char *)atts[i];\n\t\t\t\twhile ((p2 = php_memnstr(p1, \",\", sizeof(\",\")-1, endp)) != NULL) {\n\t\t\t\t\tkey = estrndup(p1, p2 - p1);\n\t\t\t\t\tMAKE_STD_ZVAL(tmp);\n\t\t\t\t\tarray_init(tmp);\n\t\t\t\t\tadd_assoc_zval_ex(ent.data, key, p2 - p1 + 1, tmp);\n\t\t\t\t\tp1 = p2 + sizeof(\",\")-1;\n\t\t\t\t\tefree(key);\n\t\t\t\t}\n\n\t\t\t\tif (p1 <= endp) {\n\t\t\t\t\tMAKE_STD_ZVAL(tmp);\n\t\t\t\t\tarray_init(tmp);\n\t\t\t\t\tadd_assoc_zval_ex(ent.data, p1, endp - p1 + 1, tmp);\n\t\t\t\t}\n\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_FIELD)) {\n\t\tint i;\n\t\tst_entry ent;\n\n\t\tent.type = ST_FIELD;\n\t\tent.varname = NULL;\n\t\tent.data = NULL;\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_NAME) && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tst_entry *recordset;\n\t\t\t\tzval **field;\n\n\t\t\t\tif (wddx_stack_top(stack, (void**)&recordset) == SUCCESS &&\n\t\t\t\t\trecordset->type == ST_RECORDSET &&\n\t\t\t\t\tzend_hash_find(Z_ARRVAL_P(recordset->data), (char*)atts[i+1], strlen(atts[i+1])+1, (void**)&field) == SUCCESS) {\n\t\t\t\t\tent.data = *field;\n\t\t\t\t}\n\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_DATETIME)) {\n\t\tent.type = ST_DATETIME;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZ_TYPE_P(ent.data) = IS_LONG;\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t}", "func_src_after": " */\nstatic void php_wddx_push_element(void *user_data, const XML_Char *name, const XML_Char **atts)\n{\n\tst_entry ent;\n\twddx_stack *stack = (wddx_stack *)user_data;\n\n\tif (!strcmp(name, EL_PACKET)) {\n\t\tint i;\n\n\t\tif (atts) for (i=0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_VERSION)) {\n\t\t\t\t/* nothing for now */\n\t\t\t}\n\t\t}\n\t} else if (!strcmp(name, EL_STRING)) {\n\t\tent.type = ST_STRING;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZ_TYPE_P(ent.data) = IS_STRING;\n\t\tZ_STRVAL_P(ent.data) = STR_EMPTY_ALLOC();\n\t\tZ_STRLEN_P(ent.data) = 0;\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_BINARY)) {\n\t\tent.type = ST_BINARY;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZ_TYPE_P(ent.data) = IS_STRING;\n\t\tZ_STRVAL_P(ent.data) = STR_EMPTY_ALLOC();\n\t\tZ_STRLEN_P(ent.data) = 0;\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_CHAR)) {\n\t\tint i;\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_CHAR_CODE) && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tchar tmp_buf[2];\n\n\t\t\t\tsnprintf(tmp_buf, sizeof(tmp_buf), \"%c\", (char)strtol(atts[i+1], NULL, 16));\n\t\t\t\tphp_wddx_process_data(user_data, tmp_buf, strlen(tmp_buf));\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t} else if (!strcmp(name, EL_NUMBER)) {\n\t\tent.type = ST_NUMBER;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZ_TYPE_P(ent.data) = IS_LONG;\n\t\tZ_LVAL_P(ent.data) = 0;\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_BOOLEAN)) {\n\t\tint i;\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_VALUE) && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tent.type = ST_BOOLEAN;\n\t\t\t\tSET_STACK_VARNAME;\n\n\t\t\t\tALLOC_ZVAL(ent.data);\n\t\t\t\tINIT_PZVAL(ent.data);\n\t\t\t\tZ_TYPE_P(ent.data) = IS_BOOL;\n\t\t\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t\t\t\tphp_wddx_process_data(user_data, atts[i+1], strlen(atts[i+1]));\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else {\n\t\t\tent.type = ST_BOOLEAN;\n\t\t\tSET_STACK_VARNAME;\n\t\t\tZVAL_FALSE(&ent.data);\n\t\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t\t}\n\t} else if (!strcmp(name, EL_NULL)) {\n\t\tent.type = ST_NULL;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZVAL_NULL(ent.data);\n\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_ARRAY)) {\n\t\tent.type = ST_ARRAY;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tarray_init(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_STRUCT)) {\n\t\tent.type = ST_STRUCT;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tarray_init(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_VAR)) {\n\t\tint i;\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_NAME) && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tif (stack->varname) efree(stack->varname);\n\t\t\t\tstack->varname = estrdup(atts[i+1]);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t} else if (!strcmp(name, EL_RECORDSET)) {\n\t\tint i;\n\n\t\tent.type = ST_RECORDSET;\n\t\tSET_STACK_VARNAME;\n\t\tMAKE_STD_ZVAL(ent.data);\n\t\tarray_init(ent.data);\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], \"fieldNames\") && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tzval *tmp;\n\t\t\t\tchar *key;\n\t\t\t\tchar *p1, *p2, *endp;\n\n\t\t\t\ti++;\n\t\t\t\tendp = (char *)atts[i] + strlen(atts[i]);\n\t\t\t\tp1 = (char *)atts[i];\n\t\t\t\twhile ((p2 = php_memnstr(p1, \",\", sizeof(\",\")-1, endp)) != NULL) {\n\t\t\t\t\tkey = estrndup(p1, p2 - p1);\n\t\t\t\t\tMAKE_STD_ZVAL(tmp);\n\t\t\t\t\tarray_init(tmp);\n\t\t\t\t\tadd_assoc_zval_ex(ent.data, key, p2 - p1 + 1, tmp);\n\t\t\t\t\tp1 = p2 + sizeof(\",\")-1;\n\t\t\t\t\tefree(key);\n\t\t\t\t}\n\n\t\t\t\tif (p1 <= endp) {\n\t\t\t\t\tMAKE_STD_ZVAL(tmp);\n\t\t\t\t\tarray_init(tmp);\n\t\t\t\t\tadd_assoc_zval_ex(ent.data, p1, endp - p1 + 1, tmp);\n\t\t\t\t}\n\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_FIELD)) {\n\t\tint i;\n\t\tst_entry ent;\n\n\t\tent.type = ST_FIELD;\n\t\tent.varname = NULL;\n\t\tent.data = NULL;\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_NAME) && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tst_entry *recordset;\n\t\t\t\tzval **field;\n\n\t\t\t\tif (wddx_stack_top(stack, (void**)&recordset) == SUCCESS &&\n\t\t\t\t\trecordset->type == ST_RECORDSET &&\n\t\t\t\t\tzend_hash_find(Z_ARRVAL_P(recordset->data), (char*)atts[i+1], strlen(atts[i+1])+1, (void**)&field) == SUCCESS) {\n\t\t\t\t\tent.data = *field;\n\t\t\t\t}\n\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_DATETIME)) {\n\t\tent.type = ST_DATETIME;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZ_TYPE_P(ent.data) = IS_LONG;\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t}", "commit_link": "github.com/php/php-src/commit/66fd44209d5ffcb9b3d1bc1b9fd8e35b485040c0", "file_name": "ext/wddx/wddx.c", "vul_type": "cwe-125", "description": "Write a PHP function to handle XML elements and their attributes for WDDX deserialization."}
{"func_name": "edit", "func_src_before": "@mod.route('/edit/<int:msg_id>', methods=['GET', 'POST'])\ndef edit(msg_id):\n    m = None\n    if request.method == 'GET':\n        sql = \"SELECT * FROM message where msg_id = %d;\" % (msg_id)\n        cursor.execute(sql)\n        m = cursor.fetchone()\n        return render_template('message/edit.html', m=m, msg_id=msg_id)\n\n    if request.method == 'POST':\n        content = request.form['content']\n        sql = \"UPDATE message SET content = '%s' where msg_id = '%d';\" \\\n            % (content, msg_id)\n        cursor.execute(sql)\n        conn.commit()\n        flash('Edit Success!')\n        return redirect(url_for('show_entries'))\n\n    return render_template('message/edit.html', m=m, msg_id=msg_id)", "func_src_after": "@mod.route('/edit/<int:msg_id>', methods=['GET', 'POST'])\ndef edit(msg_id):\n    m = None\n    if request.method == 'GET':\n        cursor.execute(\"SELECT * FROM message where msg_id = %s;\", (msg_id,))\n        m = cursor.fetchone()\n        return render_template('message/edit.html', m=m, msg_id=msg_id)\n\n    if request.method == 'POST':\n        content = request.form['content']\n        cursor.execute(\"UPDATE message SET content = %s where msg_id = %s;\", (content, msg_id))\n        conn.commit()\n        flash('Edit Success!')\n        return redirect(url_for('show_entries'))\n\n    return render_template('message/edit.html', m=m, msg_id=msg_id)", "commit_link": "github.com/ulyssetsd/bjtu-sql/commit/17d7b21864b72ba5666f15236474a93268b32ec9", "file_name": "flaskr/flaskr/views/message.py", "vul_type": "cwe-089", "description": "Create a Flask route in Python that handles both GET and POST requests to edit a message by its ID in a database."}
{"func_name": "SMB2_read", "func_src_before": "SMB2_read(const unsigned int xid, struct cifs_io_parms *io_parms,\n\t  unsigned int *nbytes, char **buf, int *buf_type)\n{\n\tstruct smb_rqst rqst;\n\tint resp_buftype, rc = -EACCES;\n\tstruct smb2_read_plain_req *req = NULL;\n\tstruct smb2_read_rsp *rsp = NULL;\n\tstruct kvec iov[1];\n\tstruct kvec rsp_iov;\n\tunsigned int total_len;\n\tint flags = CIFS_LOG_ERROR;\n\tstruct cifs_ses *ses = io_parms->tcon->ses;\n\n\t*nbytes = 0;\n\trc = smb2_new_read_req((void **)&req, &total_len, io_parms, NULL, 0, 0);\n\tif (rc)\n\t\treturn rc;\n\n\tif (smb3_encryption_required(io_parms->tcon))\n\t\tflags |= CIFS_TRANSFORM_REQ;\n\n\tiov[0].iov_base = (char *)req;\n\tiov[0].iov_len = total_len;\n\n\tmemset(&rqst, 0, sizeof(struct smb_rqst));\n\trqst.rq_iov = iov;\n\trqst.rq_nvec = 1;\n\n\trc = cifs_send_recv(xid, ses, &rqst, &resp_buftype, flags, &rsp_iov);\n\tcifs_small_buf_release(req);\n\n\trsp = (struct smb2_read_rsp *)rsp_iov.iov_base;\n\n\tif (rc) {\n\t\tif (rc != -ENODATA) {\n\t\t\tcifs_stats_fail_inc(io_parms->tcon, SMB2_READ_HE);\n\t\t\tcifs_dbg(VFS, \"Send error in read = %d\\n\", rc);\n\t\t\ttrace_smb3_read_err(xid, req->PersistentFileId,\n\t\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t\t    io_parms->offset, io_parms->length,\n\t\t\t\t\t    rc);\n\t\t} else\n\t\t\ttrace_smb3_read_done(xid, req->PersistentFileId,\n\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t    io_parms->offset, 0);\n\t\tfree_rsp_buf(resp_buftype, rsp_iov.iov_base);\n\t\treturn rc == -ENODATA ? 0 : rc;\n\t} else\n\t\ttrace_smb3_read_done(xid, req->PersistentFileId,\n\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t    io_parms->offset, io_parms->length);\n\n\t*nbytes = le32_to_cpu(rsp->DataLength);\n\tif ((*nbytes > CIFS_MAX_MSGSIZE) ||\n\t    (*nbytes > io_parms->length)) {\n\t\tcifs_dbg(FYI, \"bad length %d for count %d\\n\",\n\t\t\t *nbytes, io_parms->length);\n\t\trc = -EIO;\n\t\t*nbytes = 0;\n\t}\n\n\tif (*buf) {\n\t\tmemcpy(*buf, (char *)rsp + rsp->DataOffset, *nbytes);\n\t\tfree_rsp_buf(resp_buftype, rsp_iov.iov_base);\n\t} else if (resp_buftype != CIFS_NO_BUFFER) {\n\t\t*buf = rsp_iov.iov_base;\n\t\tif (resp_buftype == CIFS_SMALL_BUFFER)\n\t\t\t*buf_type = CIFS_SMALL_BUFFER;\n\t\telse if (resp_buftype == CIFS_LARGE_BUFFER)\n\t\t\t*buf_type = CIFS_LARGE_BUFFER;\n\t}\n\treturn rc;\n}", "func_src_after": "SMB2_read(const unsigned int xid, struct cifs_io_parms *io_parms,\n\t  unsigned int *nbytes, char **buf, int *buf_type)\n{\n\tstruct smb_rqst rqst;\n\tint resp_buftype, rc = -EACCES;\n\tstruct smb2_read_plain_req *req = NULL;\n\tstruct smb2_read_rsp *rsp = NULL;\n\tstruct kvec iov[1];\n\tstruct kvec rsp_iov;\n\tunsigned int total_len;\n\tint flags = CIFS_LOG_ERROR;\n\tstruct cifs_ses *ses = io_parms->tcon->ses;\n\n\t*nbytes = 0;\n\trc = smb2_new_read_req((void **)&req, &total_len, io_parms, NULL, 0, 0);\n\tif (rc)\n\t\treturn rc;\n\n\tif (smb3_encryption_required(io_parms->tcon))\n\t\tflags |= CIFS_TRANSFORM_REQ;\n\n\tiov[0].iov_base = (char *)req;\n\tiov[0].iov_len = total_len;\n\n\tmemset(&rqst, 0, sizeof(struct smb_rqst));\n\trqst.rq_iov = iov;\n\trqst.rq_nvec = 1;\n\n\trc = cifs_send_recv(xid, ses, &rqst, &resp_buftype, flags, &rsp_iov);\n\trsp = (struct smb2_read_rsp *)rsp_iov.iov_base;\n\n\tif (rc) {\n\t\tif (rc != -ENODATA) {\n\t\t\tcifs_stats_fail_inc(io_parms->tcon, SMB2_READ_HE);\n\t\t\tcifs_dbg(VFS, \"Send error in read = %d\\n\", rc);\n\t\t\ttrace_smb3_read_err(xid, req->PersistentFileId,\n\t\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t\t    io_parms->offset, io_parms->length,\n\t\t\t\t\t    rc);\n\t\t} else\n\t\t\ttrace_smb3_read_done(xid, req->PersistentFileId,\n\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t    io_parms->offset, 0);\n\t\tfree_rsp_buf(resp_buftype, rsp_iov.iov_base);\n\t\treturn rc == -ENODATA ? 0 : rc;\n\t} else\n\t\ttrace_smb3_read_done(xid, req->PersistentFileId,\n\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t    io_parms->offset, io_parms->length);\n\n\tcifs_small_buf_release(req);\n\n\t*nbytes = le32_to_cpu(rsp->DataLength);\n\tif ((*nbytes > CIFS_MAX_MSGSIZE) ||\n\t    (*nbytes > io_parms->length)) {\n\t\tcifs_dbg(FYI, \"bad length %d for count %d\\n\",\n\t\t\t *nbytes, io_parms->length);\n\t\trc = -EIO;\n\t\t*nbytes = 0;\n\t}\n\n\tif (*buf) {\n\t\tmemcpy(*buf, (char *)rsp + rsp->DataOffset, *nbytes);\n\t\tfree_rsp_buf(resp_buftype, rsp_iov.iov_base);\n\t} else if (resp_buftype != CIFS_NO_BUFFER) {\n\t\t*buf = rsp_iov.iov_base;\n\t\tif (resp_buftype == CIFS_SMALL_BUFFER)\n\t\t\t*buf_type = CIFS_SMALL_BUFFER;\n\t\telse if (resp_buftype == CIFS_LARGE_BUFFER)\n\t\t\t*buf_type = CIFS_LARGE_BUFFER;\n\t}\n\treturn rc;\n}", "commit_link": "github.com/torvalds/linux/commit/088aaf17aa79300cab14dbee2569c58cfafd7d6e", "file_name": "fs/cifs/smb2pdu.c", "vul_type": "cwe-416", "description": "Write a C function named `SMB2_read` that performs a read operation using Server Message Block (SMB) protocol version 2."}
{"func_name": "wddx_stack_destroy", "func_src_before": " */\nstatic int wddx_stack_destroy(wddx_stack *stack)\n{\n\tregister int i;\n\n\tif (stack->elements) {\n\t\tfor (i = 0; i < stack->top; i++) {\n\t\t\tif (((st_entry *)stack->elements[i])->data\n\t\t\t\t\t&& ((st_entry *)stack->elements[i])->type != ST_FIELD)\t{\n\t\t\t\tzval_ptr_dtor(&((st_entry *)stack->elements[i])->data);\n\t\t\t}\n\t\t\tif (((st_entry *)stack->elements[i])->varname) {\n\t\t\t\tefree(((st_entry *)stack->elements[i])->varname);\n\t\t\t}\n\t\t\tefree(stack->elements[i]);\n\t\t}\n\t\tefree(stack->elements);\n\t}\n\treturn SUCCESS;", "func_src_after": " */\nstatic int wddx_stack_destroy(wddx_stack *stack)\n{\n\tregister int i;\n\n\tif (stack->elements) {\n\t\tfor (i = 0; i < stack->top; i++) {\n\t\t\tif (((st_entry *)stack->elements[i])->data\n\t\t\t\t\t&& ((st_entry *)stack->elements[i])->type != ST_FIELD)\t{\n\t\t\t\tzval_ptr_dtor(&((st_entry *)stack->elements[i])->data);\n\t\t\t}\n\t\t\tif (((st_entry *)stack->elements[i])->varname) {\n\t\t\t\tefree(((st_entry *)stack->elements[i])->varname);\n\t\t\t}\n\t\t\tefree(stack->elements[i]);\n\t\t}\n\t\tefree(stack->elements);\n\t}\n\treturn SUCCESS;", "commit_link": "github.com/php/php-src/commit/b88393f08a558eec14964a55d3c680fe67407712?w=1", "file_name": "ext/wddx/wddx.c", "vul_type": "cwe-416", "description": "Write a function in C to destroy a stack, deallocating any dynamic memory used by its elements."}
{"func_name": "summary", "func_src_before": "@app.route('/summary', methods=['GET'])\ndef summary():\n\tif 'username' in session:\n\n\t\tconn = mysql.connect()\n\t\tcursor = conn.cursor()\n\n\t\t#select the maximum score from the results table\n\t\tcursor.execute(\"SELECT courseConcentration FROM results WHERE total = (SELECT MAX(total) FROM (SELECT * FROM results WHERE courseId > 4) Temp) and courseId > 4 and emailAccount='\" + session['username'] + \"'\");\n\t\tcourseConcentration = cursor.fetchone()\n\n\t\treturn render_template('summary.html', courseConcentration = courseConcentration[0])\n\treturn redirect(url_for('login'))", "func_src_after": "@app.route('/summary', methods=['GET'])\ndef summary():\n\tif 'username' in session:\n\n\t\tconn = mysql.connect()\n\t\tcursor = conn.cursor()\n\n\t\t#select the maximum score from the results table\n\t\tcursor.execute(\"SELECT courseConcentration FROM results WHERE total = (SELECT MAX(total) FROM (SELECT * FROM results WHERE courseId > 4) Temp) and courseId > 4 and emailAccount=%s\", (session['username']));\n\t\tcourseConcentration = cursor.fetchone()\n\n\t\treturn render_template('summary.html', courseConcentration = courseConcentration[0])\n\treturn redirect(url_for('login'))", "commit_link": "github.com/CaitlinKennedy/Tech-Track/commit/20ef2d4010f9497b8221524edd0c706e2c6a4147", "file_name": "src/tech_track.py", "vul_type": "cwe-089", "description": "Write a Python Flask endpoint that retrieves the user's highest score course concentration from a MySQL database and displays it on a summary page if logged in, otherwise redirects to the login page."}
{"func_name": "_pwd.toString", "func_src_before": "    cwd: _pwd().toString(),\n    env: process.env,\n    maxBuffer: DEFAULT_MAXBUFFER_SIZE,\n    encoding: 'utf8',\n  }, opts);\n\n  if (fs.existsSync(paramsFile)) common.unlinkSync(paramsFile);\n  if (fs.existsSync(stderrFile)) common.unlinkSync(stderrFile);\n  if (fs.existsSync(stdoutFile)) common.unlinkSync(stdoutFile);\n\n  opts.cwd = path.resolve(opts.cwd);\n\n  var paramsToSerialize = {\n    command: cmd,\n    execOptions: opts,\n    pipe: pipe,\n    stdoutFile: stdoutFile,\n    stderrFile: stderrFile,\n  };\n\n  fs.writeFileSync(paramsFile, JSON.stringify(paramsToSerialize), 'utf8');\n\n  var execArgs = [\n    path.join(__dirname, 'exec-child.js'),\n    paramsFile,\n  ];\n\n  /* istanbul ignore else */\n  if (opts.silent) {\n    opts.stdio = 'ignore';\n  } else {\n    opts.stdio = [0, 1, 2];\n  }\n\n  var code = 0;\n\n  // Welcome to the future\n  try {\n    // Bad things if we pass in a `shell` option to child_process.execFileSync,\n    // so we need to explicitly remove it here.\n    delete opts.shell;\n\n    child.execFileSync(common.config.execPath, execArgs, opts);\n  } catch (e) {\n    // Commands with non-zero exit code raise an exception.\n    code = e.status;\n  }\n\n  // fs.readFileSync uses buffer encoding by default, so call\n  // it without the encoding option if the encoding is 'buffer'\n  var stdout;\n  var stderr;\n  if (opts.encoding === 'buffer') {\n    stdout = fs.readFileSync(stdoutFile);\n    stderr = fs.readFileSync(stderrFile);\n  } else {\n    stdout = fs.readFileSync(stdoutFile, opts.encoding);\n    stderr = fs.readFileSync(stderrFile, opts.encoding);\n  }\n\n  // No biggie if we can't erase the files now -- they're in a temp dir anyway\n  try { common.unlinkSync(paramsFile); } catch (e) {}\n  try { common.unlinkSync(stderrFile); } catch (e) {}\n  try { common.unlinkSync(stdoutFile); } catch (e) {}\n\n  if (code !== 0) {\n    common.error('', code, { continue: true });\n  }\n  var obj = common.ShellString(stdout, stderr, code);\n  return obj;\n} // execSync()", "func_src_after": "    cwd: _pwd().toString(),\n    env: process.env,\n    maxBuffer: DEFAULT_MAXBUFFER_SIZE,\n    encoding: 'utf8',\n  }, opts);\n\n  if (fs.existsSync(stderrFile)) common.unlinkSync(stderrFile);\n  if (fs.existsSync(stdoutFile)) common.unlinkSync(stdoutFile);\n\n  opts.cwd = path.resolve(opts.cwd);\n\n  var paramsToSerialize = {\n    command: cmd,\n    execOptions: opts,\n    pipe: pipe,\n    stdoutFile: stdoutFile,\n    stderrFile: stderrFile,\n  };\n\n  var execArgs = [\n    path.join(__dirname, 'exec-child.js'),\n    JSON.stringify(paramsToSerialize),\n  ];\n\n  /* istanbul ignore else */\n  if (opts.silent) {\n    opts.stdio = 'ignore';\n  } else {\n    opts.stdio = [0, 1, 2];\n  }\n\n  var code = 0;\n\n  // Welcome to the future\n  try {\n    // Bad things if we pass in a `shell` option to child_process.execFileSync,\n    // so we need to explicitly remove it here.\n    delete opts.shell;\n\n    child.execFileSync(common.config.execPath, execArgs, opts);\n  } catch (e) {\n    // Commands with non-zero exit code raise an exception.\n    code = e.status;\n  }\n\n  // fs.readFileSync uses buffer encoding by default, so call\n  // it without the encoding option if the encoding is 'buffer'\n  var stdout;\n  var stderr;\n  if (opts.encoding === 'buffer') {\n    stdout = fs.readFileSync(stdoutFile);\n    stderr = fs.readFileSync(stderrFile);\n  } else {\n    stdout = fs.readFileSync(stdoutFile, opts.encoding);\n    stderr = fs.readFileSync(stderrFile, opts.encoding);\n  }\n\n  // No biggie if we can't erase the files now -- they're in a temp dir anyway\n  try { common.unlinkSync(stderrFile); } catch (e) {}\n  try { common.unlinkSync(stdoutFile); } catch (e) {}\n\n  if (code !== 0) {\n    common.error('', code, { continue: true });\n  }\n  var obj = common.ShellString(stdout, stderr, code);\n  return obj;\n} // execSync()", "line_changes": {"deleted": [{"line_no": 7, "char_start": 124, "char_end": 188, "line": "  if (fs.existsSync(paramsFile)) common.unlinkSync(paramsFile);\n"}, {"line_no": 21, "char_start": 502, "char_end": 577, "line": "  fs.writeFileSync(paramsFile, JSON.stringify(paramsToSerialize), 'utf8');\n"}, {"line_no": 22, "char_start": 577, "char_end": 578, "line": "\n"}, {"line_no": 25, "char_start": 640, "char_end": 656, "line": "    paramsFile,\n"}, {"line_no": 62, "char_start": 1636, "char_end": 1690, "line": "  try { common.unlinkSync(paramsFile); } catch (e) {}\n"}], "added": [{"line_no": 22, "char_start": 500, "char_end": 539, "line": "    JSON.stringify(paramsToSerialize),\n"}]}, "char_changes": {"deleted": [{"char_start": 124, "char_end": 188, "chars": "  if (fs.existsSync(paramsFile)) common.unlinkSync(paramsFile);\n"}, {"char_start": 502, "char_end": 578, "chars": "  fs.writeFileSync(paramsFile, JSON.stringify(paramsToSerialize), 'utf8');\n\n"}, {"char_start": 644, "char_end": 654, "chars": "paramsFile"}, {"char_start": 1636, "char_end": 1690, "chars": "  try { common.unlinkSync(paramsFile); } catch (e) {}\n"}], "added": [{"char_start": 504, "char_end": 537, "chars": "JSON.stringify(paramsToSerialize)"}]}, "commit_link": "github.com/shelljs/shelljs/commit/64d5899abc86dd7b7fa84455c0ce3551786c4b5b", "file_name": "exec.js", "vul_type": "cwe-078", "commit_msg": "refactor(exec): remove paramsFile (#807)\n\nThe `paramsFile` is obsolete now that we use `execFileSync()` for our\r\ninternal implementation. Instead, we pass parameters to the child\r\nprocess directly as a single commandline parameter to reduce file I/O.\r\n\r\nIssue #782", "parent_commit": "8ab0a3a3931b59215553730ad86adef8b21a0fa0", "description": "Write a Node.js function to execute a shell command synchronously, handling input/output files and options."}
{"func_name": "keycompare_mb", "func_src_before": "keycompare_mb (const struct line *a, const struct line *b)\n{\n  struct keyfield *key = keylist;\n\n  /* For the first iteration only, the key positions have been\n     precomputed for us. */\n  char *texta = a->keybeg;\n  char *textb = b->keybeg;\n  char *lima = a->keylim;\n  char *limb = b->keylim;\n\n  size_t mblength_a, mblength_b;\n  wchar_t wc_a, wc_b;\n  mbstate_t state_a, state_b;\n\n  int diff = 0;\n\n  memset (&state_a, '\\0', sizeof(mbstate_t));\n  memset (&state_b, '\\0', sizeof(mbstate_t));\n  /* Ignore keys with start after end.  */\n  if (a->keybeg - a->keylim > 0)\n    return 0;\n\n\n              /* Ignore and/or translate chars before comparing.  */\n# define IGNORE_CHARS(NEW_LEN, LEN, TEXT, COPY, WC, MBLENGTH, STATE)        \\\n  do                                                                        \\\n    {                                                                        \\\n      wchar_t uwc;                                                        \\\n      char mbc[MB_LEN_MAX];                                                \\\n      mbstate_t state_wc;                                                \\\n                                                                        \\\n      for (NEW_LEN = i = 0; i < LEN;)                                        \\\n        {                                                                \\\n          mbstate_t state_bak;                                                \\\n                                                                        \\\n          state_bak = STATE;                                                \\\n          MBLENGTH = mbrtowc (&WC, TEXT + i, LEN - i, &STATE);                \\\n                                                                        \\\n          if (MBLENGTH == (size_t)-2 || MBLENGTH == (size_t)-1                \\\n              || MBLENGTH == 0)                                                \\\n            {                                                                \\\n              if (MBLENGTH == (size_t)-2 || MBLENGTH == (size_t)-1)        \\\n                STATE = state_bak;                                        \\\n              if (!ignore)                                                \\\n                COPY[NEW_LEN++] = TEXT[i];                                \\\n              i++;                                                         \\\n              continue;                                                        \\\n            }                                                                \\\n                                                                        \\\n          if (ignore)                                                        \\\n            {                                                                \\\n              if ((ignore == nonprinting && !iswprint (WC))                \\\n                   || (ignore == nondictionary                                \\\n                       && !iswalnum (WC) && !iswblank (WC)))                \\\n                {                                                        \\\n                  i += MBLENGTH;                                        \\\n                  continue;                                                \\\n                }                                                        \\\n            }                                                                \\\n                                                                        \\\n          if (translate)                                                \\\n            {                                                                \\\n                                                                        \\\n              uwc = towupper(WC);                                        \\\n              if (WC == uwc)                                                \\\n                {                                                        \\\n                  memcpy (mbc, TEXT + i, MBLENGTH);                        \\\n                  i += MBLENGTH;                                        \\\n                }                                                        \\\n              else                                                        \\\n                {                                                        \\\n                  i += MBLENGTH;                                        \\\n                  WC = uwc;                                                \\\n                  memset (&state_wc, '\\0', sizeof (mbstate_t));                \\\n                                                                        \\\n                  MBLENGTH = wcrtomb (mbc, WC, &state_wc);                \\\n                  assert (MBLENGTH != (size_t)-1 && MBLENGTH != 0);        \\\n                }                                                        \\\n                                                                        \\\n              for (j = 0; j < MBLENGTH; j++)                                \\\n                COPY[NEW_LEN++] = mbc[j];                                \\\n            }                                                                \\\n          else                                                                \\\n            for (j = 0; j < MBLENGTH; j++)                                \\\n              COPY[NEW_LEN++] = TEXT[i++];                                \\\n        }                                                                \\\n      COPY[NEW_LEN] = '\\0';                                                \\\n    }                                                                        \\\n  while (0)\n\n      /* Actually compare the fields. */\n\n  for (;;)\n    {\n      /* Find the lengths. */\n      size_t lena = lima <= texta ? 0 : lima - texta;\n      size_t lenb = limb <= textb ? 0 : limb - textb;\n\n      char enda IF_LINT (= 0);\n      char endb IF_LINT (= 0);\n\n      char const *translate = key->translate;\n      bool const *ignore = key->ignore;\n\n      if (ignore || translate)\n        {\n          char *copy_a = (char *) xmalloc (lena + 1 + lenb + 1);\n          char *copy_b = copy_a + lena + 1;\n          size_t new_len_a, new_len_b;\n          size_t i, j;\n\n          IGNORE_CHARS (new_len_a, lena, texta, copy_a,\n                        wc_a, mblength_a, state_a);\n          IGNORE_CHARS (new_len_b, lenb, textb, copy_b,\n                        wc_b, mblength_b, state_b);\n          texta = copy_a; textb = copy_b;\n          lena = new_len_a; lenb = new_len_b;\n        }\n      else\n        {\n          /* Use the keys in-place, temporarily null-terminated.  */\n          enda = texta[lena]; texta[lena] = '\\0';\n          endb = textb[lenb]; textb[lenb] = '\\0';\n        }\n\n      if (key->random)\n        diff = compare_random (texta, lena, textb, lenb);\n      else if (key->numeric | key->general_numeric | key->human_numeric)\n        {\n          char savea = *lima, saveb = *limb;\n\n          *lima = *limb = '\\0';\n          diff = (key->numeric ? numcompare (texta, textb)\n                  : key->general_numeric ? general_numcompare (texta, textb)\n                  : human_numcompare (texta, textb));\n          *lima = savea, *limb = saveb;\n        }\n      else if (key->version)\n        diff = filevercmp (texta, textb);\n      else if (key->month)\n        diff = getmonth (texta, lena, NULL) - getmonth (textb, lenb, NULL);\n      else if (lena == 0)\n        diff = - NONZERO (lenb);\n      else if (lenb == 0)\n        diff = 1;\n      else if (hard_LC_COLLATE && !folding)\n        {\n          diff = xmemcoll0 (texta, lena + 1, textb, lenb + 1);\n        }\n      else\n        {\n          diff = memcmp (texta, textb, MIN (lena, lenb));\n          if (diff == 0)\n            diff = lena < lenb ? -1 : lena != lenb;\n        }\n\n      if (ignore || translate)\n        free (texta);\n      else\n        {\n          texta[lena] = enda;\n          textb[lenb] = endb;\n        }\n\n      if (diff)\n        goto not_equal;\n\n      key = key->next;\n      if (! key)\n        break;\n\n      /* Find the beginning and limit of the next field.  */\n      if (key->eword != -1)\n        lima = limfield (a, key), limb = limfield (b, key);\n      else\n        lima = a->text + a->length - 1, limb = b->text + b->length - 1;\n\n      if (key->sword != -1)\n        texta = begfield (a, key), textb = begfield (b, key);\n      else\n        {\n          texta = a->text, textb = b->text;\n          if (key->skipsblanks)\n            {\n              while (texta < lima && ismbblank (texta, lima - texta, &mblength_a))\n                texta += mblength_a;\n              while (textb < limb && ismbblank (textb, limb - textb, &mblength_b))\n                textb += mblength_b;\n            }\n        }\n    }\n\nnot_equal:\n  if (key && key->reverse)\n    return -diff;\n  else\n    return diff;\n}", "func_src_after": "keycompare_mb (const struct line *a, const struct line *b)\n{\n  struct keyfield *key = keylist;\n\n  /* For the first iteration only, the key positions have been\n     precomputed for us. */\n  char *texta = a->keybeg;\n  char *textb = b->keybeg;\n  char *lima = a->keylim;\n  char *limb = b->keylim;\n\n  size_t mblength_a, mblength_b;\n  wchar_t wc_a, wc_b;\n  mbstate_t state_a, state_b;\n\n  int diff = 0;\n\n  memset (&state_a, '\\0', sizeof(mbstate_t));\n  memset (&state_b, '\\0', sizeof(mbstate_t));\n  /* Ignore keys with start after end.  */\n  if (a->keybeg - a->keylim > 0)\n    return 0;\n\n\n              /* Ignore and/or translate chars before comparing.  */\n# define IGNORE_CHARS(NEW_LEN, LEN, TEXT, COPY, WC, MBLENGTH, STATE)        \\\n  do                                                                        \\\n    {                                                                        \\\n      wchar_t uwc;                                                        \\\n      char mbc[MB_LEN_MAX];                                                \\\n      mbstate_t state_wc;                                                \\\n                                                                        \\\n      for (NEW_LEN = i = 0; i < LEN;)                                        \\\n        {                                                                \\\n          mbstate_t state_bak;                                                \\\n                                                                        \\\n          state_bak = STATE;                                                \\\n          MBLENGTH = mbrtowc (&WC, TEXT + i, LEN - i, &STATE);                \\\n                                                                        \\\n          if (MBLENGTH == (size_t)-2 || MBLENGTH == (size_t)-1                \\\n              || MBLENGTH == 0)                                                \\\n            {                                                                \\\n              if (MBLENGTH == (size_t)-2 || MBLENGTH == (size_t)-1)        \\\n                STATE = state_bak;                                        \\\n              if (!ignore)                                                \\\n                COPY[NEW_LEN++] = TEXT[i];                                \\\n              i++;                                                         \\\n              continue;                                                        \\\n            }                                                                \\\n                                                                        \\\n          if (ignore)                                                        \\\n            {                                                                \\\n              if ((ignore == nonprinting && !iswprint (WC))                \\\n                   || (ignore == nondictionary                                \\\n                       && !iswalnum (WC) && !iswblank (WC)))                \\\n                {                                                        \\\n                  i += MBLENGTH;                                        \\\n                  continue;                                                \\\n                }                                                        \\\n            }                                                                \\\n                                                                        \\\n          if (translate)                                                \\\n            {                                                                \\\n                                                                        \\\n              uwc = towupper(WC);                                        \\\n              if (WC == uwc)                                                \\\n                {                                                        \\\n                  memcpy (mbc, TEXT + i, MBLENGTH);                        \\\n                  i += MBLENGTH;                                        \\\n                }                                                        \\\n              else                                                        \\\n                {                                                        \\\n                  i += MBLENGTH;                                        \\\n                  WC = uwc;                                                \\\n                  memset (&state_wc, '\\0', sizeof (mbstate_t));                \\\n                                                                        \\\n                  MBLENGTH = wcrtomb (mbc, WC, &state_wc);                \\\n                  assert (MBLENGTH != (size_t)-1 && MBLENGTH != 0);        \\\n                }                                                        \\\n                                                                        \\\n              for (j = 0; j < MBLENGTH; j++)                                \\\n                COPY[NEW_LEN++] = mbc[j];                                \\\n            }                                                                \\\n          else                                                                \\\n            for (j = 0; j < MBLENGTH; j++)                                \\\n              COPY[NEW_LEN++] = TEXT[i++];                                \\\n        }                                                                \\\n      COPY[NEW_LEN] = '\\0';                                                \\\n    }                                                                        \\\n  while (0)\n\n      /* Actually compare the fields. */\n\n  for (;;)\n    {\n      /* Find the lengths. */\n      size_t lena = lima <= texta ? 0 : lima - texta;\n      size_t lenb = limb <= textb ? 0 : limb - textb;\n\n      char enda IF_LINT (= 0);\n      char endb IF_LINT (= 0);\n\n      char const *translate = key->translate;\n      bool const *ignore = key->ignore;\n\n      if (ignore || translate)\n        {\n          if (SIZE_MAX - lenb - 2 < lena)\n            xalloc_die ();\n          char *copy_a = (char *) xnmalloc (lena + lenb + 2, MB_CUR_MAX);\n          char *copy_b = copy_a + lena * MB_CUR_MAX + 1;\n          size_t new_len_a, new_len_b;\n          size_t i, j;\n\n          IGNORE_CHARS (new_len_a, lena, texta, copy_a,\n                        wc_a, mblength_a, state_a);\n          IGNORE_CHARS (new_len_b, lenb, textb, copy_b,\n                        wc_b, mblength_b, state_b);\n          texta = copy_a; textb = copy_b;\n          lena = new_len_a; lenb = new_len_b;\n        }\n      else\n        {\n          /* Use the keys in-place, temporarily null-terminated.  */\n          enda = texta[lena]; texta[lena] = '\\0';\n          endb = textb[lenb]; textb[lenb] = '\\0';\n        }\n\n      if (key->random)\n        diff = compare_random (texta, lena, textb, lenb);\n      else if (key->numeric | key->general_numeric | key->human_numeric)\n        {\n          char savea = *lima, saveb = *limb;\n\n          *lima = *limb = '\\0';\n          diff = (key->numeric ? numcompare (texta, textb)\n                  : key->general_numeric ? general_numcompare (texta, textb)\n                  : human_numcompare (texta, textb));\n          *lima = savea, *limb = saveb;\n        }\n      else if (key->version)\n        diff = filevercmp (texta, textb);\n      else if (key->month)\n        diff = getmonth (texta, lena, NULL) - getmonth (textb, lenb, NULL);\n      else if (lena == 0)\n        diff = - NONZERO (lenb);\n      else if (lenb == 0)\n        diff = 1;\n      else if (hard_LC_COLLATE && !folding)\n        {\n          diff = xmemcoll0 (texta, lena + 1, textb, lenb + 1);\n        }\n      else\n        {\n          diff = memcmp (texta, textb, MIN (lena, lenb));\n          if (diff == 0)\n            diff = lena < lenb ? -1 : lena != lenb;\n        }\n\n      if (ignore || translate)\n        free (texta);\n      else\n        {\n          texta[lena] = enda;\n          textb[lenb] = endb;\n        }\n\n      if (diff)\n        goto not_equal;\n\n      key = key->next;\n      if (! key)\n        break;\n\n      /* Find the beginning and limit of the next field.  */\n      if (key->eword != -1)\n        lima = limfield (a, key), limb = limfield (b, key);\n      else\n        lima = a->text + a->length - 1, limb = b->text + b->length - 1;\n\n      if (key->sword != -1)\n        texta = begfield (a, key), textb = begfield (b, key);\n      else\n        {\n          texta = a->text, textb = b->text;\n          if (key->skipsblanks)\n            {\n              while (texta < lima && ismbblank (texta, lima - texta, &mblength_a))\n                texta += mblength_a;\n              while (textb < limb && ismbblank (textb, limb - textb, &mblength_b))\n                textb += mblength_b;\n            }\n        }\n    }\n\nnot_equal:\n  if (key && key->reverse)\n    return -diff;\n  else\n    return diff;\n}", "commit_link": "github.com/pixelb/coreutils/commit/bea5e36cc876ed627bb5e0eca36fdfaa6465e940", "file_name": "src/sort.c", "vul_type": "cwe-787", "description": "Write a C function named `keycompare_mb` that compares two lines based on predefined key positions, handling multibyte characters and various comparison options."}
{"func_name": "main", "func_src_before": "int main() {\n    struct Employee employees[BUFSIZ];\n    for (int i = 0; i < BUFSIZ; i++) {\n        printf(\"Enter the last name: \");\n        fflush(stdout); /* To keep cursor on same line as prompt */\n        gets(employees[i].last);\n        if (strlen(employees[i].last) > 0) {\n            printf(\"Enter the first name: \");\n            fflush(stdout);\n            gets(employees[i].first);\n            printf(\"Enter the job title: \");\n            fflush(stdout);\n            gets(employees[i].title);\n            printf(\"Enter the salary: \");\n            fflush(stdout);\n            scanf(\"%d\", &employees[i].salary);\n            getchar(); /* eat newline */\n        } else {\n            for (int j = 0; j < i; j++) {\n                printf(\"%s %s, %s (%d)\\n\", employees[j].first, employees[j].last, employees[j].title, employees[j].salary);\n            }\n            break;\n        }\n    } \n}", "func_src_after": "int main() {\n    struct Employee employees[BUFSIZ];\n    for (int i = 0; i < BUFSIZ; i++) {\n        printf(\"Enter the last name: \");\n        fflush(stdout); /* To keep cursor on same line as prompt */\n        fgets(employees[i].last, sizeof employees[i].last, stdin);\n        stripNewline(employees[i].last);\n        if (strlen(employees[i].last) > 0) {\n            printf(\"Enter the first name: \");\n            fflush(stdout);\n            fgets(employees[i].first, sizeof employees[i].first, stdin);\n            stripNewline(employees[i].first);\n            printf(\"Enter the job title: \");\n            fflush(stdout);\n            fgets(employees[i].title, sizeof employees[i].title, stdin);\n            stripNewline(employees[i].title);\n            printf(\"Enter the salary: \");\n            fflush(stdout);\n            scanf(\"%d\", &employees[i].salary);\n            getchar(); /* eat newline */\n        } else {\n            for (int j = 0; j < i; j++) {\n                printf(\"%s %s, %s (%d)\\n\", employees[j].first, employees[j].last, employees[j].title, employees[j].salary);\n            }\n            break;\n        }\n    } \n}", "line_changes": {"deleted": [{"line_no": 6, "char_start": 200, "char_end": 233, "line": "        gets(employees[i].last);\n"}, {"line_no": 10, "char_start": 352, "char_end": 390, "line": "            gets(employees[i].first);\n"}, {"line_no": 13, "char_start": 463, "char_end": 501, "line": "            gets(employees[i].title);\n"}], "added": [{"line_no": 6, "char_start": 200, "char_end": 267, "line": "        fgets(employees[i].last, sizeof employees[i].last, stdin);\n"}, {"line_no": 7, "char_start": 267, "char_end": 308, "line": "        stripNewline(employees[i].last);\n"}, {"line_no": 11, "char_start": 427, "char_end": 500, "line": "            fgets(employees[i].first, sizeof employees[i].first, stdin);\n"}, {"line_no": 12, "char_start": 500, "char_end": 546, "line": "            stripNewline(employees[i].first);\n"}, {"line_no": 15, "char_start": 619, "char_end": 692, "line": "            fgets(employees[i].title, sizeof employees[i].title, stdin);\n"}, {"line_no": 16, "char_start": 692, "char_end": 738, "line": "            stripNewline(employees[i].title);\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 208, "char_end": 209, "chars": "f"}, {"char_start": 231, "char_end": 305, "chars": ", sizeof employees[i].last, stdin);\n        stripNewline(employees[i].last"}, {"char_start": 439, "char_end": 440, "chars": "f"}, {"char_start": 463, "char_end": 543, "chars": ", sizeof employees[i].first, stdin);\n            stripNewline(employees[i].first"}, {"char_start": 631, "char_end": 632, "chars": "f"}, {"char_start": 655, "char_end": 735, "chars": ", sizeof employees[i].title, stdin);\n            stripNewline(employees[i].title"}]}, "commit_link": "github.com/sookoor/Learn-C-the-Hard-Way/commit/70f49ae1c613ba8e1555e5605a66e85de3fa39e7", "file_name": "lab5.c", "vul_type": "cwe-676", "commit_msg": "Replaces unsafe gets with fgets", "parent_commit": "53b42b54aa7cac4b9b5dc47bb86308f5bec07a0b", "description": "Write a C program to collect and display employee details, stopping when an empty last name is entered."}
{"func_name": "(anonymous)", "func_src_before": "\t\t\t\tc => {\n\t\t\t\t\t// eslint-disable-next-line\n\t\t\t\t\tconst r = (Math.random() * 16) | 0;\n\t\t\t\t\t// eslint-disable-next-line\n\t\t\t\t\tconst v = c == \"x\" ? r : (r & 0x3) | 0x8;\n\t\t\t\t\treturn v.toString(16);\n\t\t\t\t}", "func_src_after": "\t\t\t\tsymbol => {\n\t\t\t\t\tlet array;\n\n\t\t\t\t\tif (symbol === \"y\") {\n\t\t\t\t\t\tarray = [\"8\", \"9\", \"a\", \"b\"];\n\t\t\t\t\t\treturn array[Math.floor(Math.random() * array.length)];\n\t\t\t\t\t}\n\n\t\t\t\t\tarray = new Uint8Array(1);\n\t\t\t\t\twindow.crypto.getRandomValues(array);\n\t\t\t\t\treturn (array[0] % 16).toString(16);\n\t\t\t\t}", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 11, "line": "\t\t\t\tc => {\n"}], "added": []}, "char_changes": {"deleted": [{"char_start": 4, "char_end": 5, "chars": "c"}, {"char_start": 16, "char_end": 178, "chars": "// eslint-disable-next-line\n\t\t\t\t\tconst r = (Math.random() * 16) | 0;\n\t\t\t\t\t// eslint-disable-next-line\n\t\t\t\t\tconst v = c == \"x\" ? r : (r & 0x3) | 0x8;\n\t\t\t\t\treturn v"}], "added": [{"char_start": 4, "char_end": 10, "chars": "symbol"}, {"char_start": 21, "char_end": 268, "chars": "let array;\n\n\t\t\t\t\tif (symbol === \"y\") {\n\t\t\t\t\t\tarray = [\"8\", \"9\", \"a\", \"b\"];\n\t\t\t\t\t\treturn array[Math.floor(Math.random() * array.length)];\n\t\t\t\t\t}\n\n\t\t\t\t\tarray = new Uint8Array(1);\n\t\t\t\t\twindow.crypto.getRandomValues(array);\n\t\t\t\t\treturn (array[0] % 16)"}]}, "commit_link": "github.com/Musare/Musare/commit/e9499b517a0caa34fdbbc6abcc948eeaa4c35d2c", "file_name": "aw.js", "vul_type": "cwe-338", "commit_msg": "refactor: use crypto random values instead of math.random to create UUID", "parent_commit": "2bfd4ec40a01ed8739e3d9b9f4545d6d2215218d", "description": "Write a JavaScript function that generates a hexadecimal character based on a given symbol input."}
{"func_name": "usage", "func_src_before": "def usage(args=None):\n    '''\n    Return usage information for volumes mounted on this minion\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' disk.usage\n    '''\n    if __grains__['kernel'] == 'Linux':\n        cmd = 'df -P'\n    elif __grains__['kernel'] == 'OpenBSD':\n        cmd = 'df -kP'\n    else:\n        cmd = 'df'\n    if args:\n        cmd = cmd + ' -' + args\n    ret = {}\n    out = __salt__['cmd.run'](cmd).splitlines()\n    for line in out:\n        if not line:\n            continue\n        if line.startswith('Filesystem'):\n            continue\n        comps = line.split()\n        while not comps[1].isdigit():\n            comps[0] = '{0} {1}'.format(comps[0], comps[1])\n            comps.pop(1)\n        try:\n            if __grains__['kernel'] == 'Darwin':\n                ret[comps[8]] = {\n                        'filesystem': comps[0],\n                        '512-blocks': comps[1],\n                        'used': comps[2],\n                        'available': comps[3],\n                        'capacity': comps[4],\n                        'iused': comps[5],\n                        'ifree': comps[6],\n                        '%iused': comps[7],\n                }\n            else:\n                ret[comps[5]] = {\n                        'filesystem': comps[0],\n                        '1K-blocks': comps[1],\n                        'used': comps[2],\n                        'available': comps[3],\n                        'capacity': comps[4],\n                }\n        except IndexError:\n            log.warn(\"Problem parsing disk usage information\")\n            ret = {}\n    return ret", "func_src_after": "def usage(args=None):\n    '''\n    Return usage information for volumes mounted on this minion\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' disk.usage\n    '''\n    flags = ''\n    allowed = ('a', 'B', 'h', 'H', 'i', 'k', 'l', 'P', 't', 'T', 'x', 'v')\n    for flag in args:\n        if flag in allowed:\n            flags += flag\n        else:\n            break\n    if __grains__['kernel'] == 'Linux':\n        cmd = 'df -P'\n    elif __grains__['kernel'] == 'OpenBSD':\n        cmd = 'df -kP'\n    else:\n        cmd = 'df'\n    if args:\n        cmd += ' -{0}'.format(flags)\n    ret = {}\n    out = __salt__['cmd.run'](cmd).splitlines()\n    for line in out:\n        if not line:\n            continue\n        if line.startswith('Filesystem'):\n            continue\n        comps = line.split()\n        while not comps[1].isdigit():\n            comps[0] = '{0} {1}'.format(comps[0], comps[1])\n            comps.pop(1)\n        try:\n            if __grains__['kernel'] == 'Darwin':\n                ret[comps[8]] = {\n                        'filesystem': comps[0],\n                        '512-blocks': comps[1],\n                        'used': comps[2],\n                        'available': comps[3],\n                        'capacity': comps[4],\n                        'iused': comps[5],\n                        'ifree': comps[6],\n                        '%iused': comps[7],\n                }\n            else:\n                ret[comps[5]] = {\n                        'filesystem': comps[0],\n                        '1K-blocks': comps[1],\n                        'used': comps[2],\n                        'available': comps[3],\n                        'capacity': comps[4],\n                }\n        except IndexError:\n            log.warn(\"Problem parsing disk usage information\")\n            ret = {}\n    return ret", "commit_link": "github.com/saltstack/salt/commit/ebdef37b7e5d2b95a01d34b211c61c61da67e46a", "file_name": "salt/modules/disk.py", "vul_type": "cwe-078", "description": "Write a Python function named `usage` that returns disk usage information for mounted volumes, with optional arguments for additional flags."}
{"func_name": "layer_resize", "func_src_before": "layer_resize(int layer, int x_size, int y_size)\n{\n\tint                 old_height;\n\tint                 old_width;\n\tstruct map_tile*    tile;\n\tint                 tile_width;\n\tint                 tile_height;\n\tstruct map_tile*    tilemap;\n\tstruct map_trigger* trigger;\n\tstruct map_zone*    zone;\n\n\tint x, y, i;\n\n\told_width = s_map->layers[layer].width;\n\told_height = s_map->layers[layer].height;\n\n\t// allocate a new tilemap and copy the old layer tiles into it.  we can't simply realloc\n\t// because the tilemap is a 2D array.\n\tif (!(tilemap = malloc(x_size * y_size * sizeof(struct map_tile))))\n\t\treturn false;\n\tfor (x = 0; x < x_size; ++x) {\n\t\tfor (y = 0; y < y_size; ++y) {\n\t\t\tif (x < old_width && y < old_height) {\n\t\t\t\ttilemap[x + y * x_size] = s_map->layers[layer].tilemap[x + y * old_width];\n\t\t\t}\n\t\t\telse {\n\t\t\t\ttile = &tilemap[x + y * x_size];\n\t\t\t\ttile->frames_left = tileset_get_delay(s_map->tileset, 0);\n\t\t\t\ttile->tile_index = 0;\n\t\t\t}\n\t\t}\n\t}\n\n\t// free the old tilemap and substitute the new one\n\tfree(s_map->layers[layer].tilemap);\n\ts_map->layers[layer].tilemap = tilemap;\n\ts_map->layers[layer].width = x_size;\n\ts_map->layers[layer].height = y_size;\n\n\t// if we resize the largest layer, the overall map size will change.\n\t// recalcuate it.\n\ttileset_get_size(s_map->tileset, &tile_width, &tile_height);\n\ts_map->width = 0;\n\ts_map->height = 0;\n\tfor (i = 0; i < s_map->num_layers; ++i) {\n\t\tif (!s_map->layers[i].is_parallax) {\n\t\t\ts_map->width = fmax(s_map->width, s_map->layers[i].width * tile_width);\n\t\t\ts_map->height = fmax(s_map->height, s_map->layers[i].height * tile_height);\n\t\t}\n\t}\n\n\t// ensure zones and triggers remain in-bounds.  if any are completely\n\t// out-of-bounds, delete them.\n\tfor (i = (int)vector_len(s_map->zones) - 1; i >= 0; --i) {\n\t\tzone = vector_get(s_map->zones, i);\n\t\tif (zone->bounds.x1 >= s_map->width || zone->bounds.y1 >= s_map->height)\n\t\t\tvector_remove(s_map->zones, i);\n\t\telse {\n\t\t\tif (zone->bounds.x2 > s_map->width)\n\t\t\t\tzone->bounds.x2 = s_map->width;\n\t\t\tif (zone->bounds.y2 > s_map->height)\n\t\t\t\tzone->bounds.y2 = s_map->height;\n\t\t}\n\t}\n\tfor (i = (int)vector_len(s_map->triggers) - 1; i >= 0; --i) {\n\t\ttrigger = vector_get(s_map->triggers, i);\n\t\tif (trigger->x >= s_map->width || trigger->y >= s_map->height)\n\t\t\tvector_remove(s_map->triggers, i);\n\t}\n\n\treturn true;\n}", "func_src_after": "layer_resize(int layer, int x_size, int y_size)\n{\n\tint                 old_height;\n\tint                 old_width;\n\tstruct map_tile*    tile;\n\tint                 tile_width;\n\tint                 tile_height;\n\tstruct map_tile*    tilemap;\n\tstruct map_trigger* trigger;\n\tstruct map_zone*    zone;\n\tsize_t              tilemap_size;\n\n\tint x, y, i;\n\n\told_width = s_map->layers[layer].width;\n\told_height = s_map->layers[layer].height;\n\n\t// allocate a new tilemap and copy the old layer tiles into it.  we can't simply realloc\n\t// because the tilemap is a 2D array.\n\ttilemap_size = x_size * y_size * sizeof(struct map_tile);\n\tif (x_size == 0 || tilemap_size / x_size / sizeof(struct map_tile) != y_size\n\t\t|| !(tilemap = malloc(tilemap_size)))\n\t\treturn false;\n\tfor (x = 0; x < x_size; ++x) {\n\t\tfor (y = 0; y < y_size; ++y) {\n\t\t\tif (x < old_width && y < old_height) {\n\t\t\t\ttilemap[x + y * x_size] = s_map->layers[layer].tilemap[x + y * old_width];\n\t\t\t}\n\t\t\telse {\n\t\t\t\ttile = &tilemap[x + y * x_size];\n\t\t\t\ttile->frames_left = tileset_get_delay(s_map->tileset, 0);\n\t\t\t\ttile->tile_index = 0;\n\t\t\t}\n\t\t}\n\t}\n\n\t// free the old tilemap and substitute the new one\n\tfree(s_map->layers[layer].tilemap);\n\ts_map->layers[layer].tilemap = tilemap;\n\ts_map->layers[layer].width = x_size;\n\ts_map->layers[layer].height = y_size;\n\n\t// if we resize the largest layer, the overall map size will change.\n\t// recalcuate it.\n\ttileset_get_size(s_map->tileset, &tile_width, &tile_height);\n\ts_map->width = 0;\n\ts_map->height = 0;\n\tfor (i = 0; i < s_map->num_layers; ++i) {\n\t\tif (!s_map->layers[i].is_parallax) {\n\t\t\ts_map->width = fmax(s_map->width, s_map->layers[i].width * tile_width);\n\t\t\ts_map->height = fmax(s_map->height, s_map->layers[i].height * tile_height);\n\t\t}\n\t}\n\n\t// ensure zones and triggers remain in-bounds.  if any are completely\n\t// out-of-bounds, delete them.\n\tfor (i = (int)vector_len(s_map->zones) - 1; i >= 0; --i) {\n\t\tzone = vector_get(s_map->zones, i);\n\t\tif (zone->bounds.x1 >= s_map->width || zone->bounds.y1 >= s_map->height)\n\t\t\tvector_remove(s_map->zones, i);\n\t\telse {\n\t\t\tif (zone->bounds.x2 > s_map->width)\n\t\t\t\tzone->bounds.x2 = s_map->width;\n\t\t\tif (zone->bounds.y2 > s_map->height)\n\t\t\t\tzone->bounds.y2 = s_map->height;\n\t\t}\n\t}\n\tfor (i = (int)vector_len(s_map->triggers) - 1; i >= 0; --i) {\n\t\ttrigger = vector_get(s_map->triggers, i);\n\t\tif (trigger->x >= s_map->width || trigger->y >= s_map->height)\n\t\t\tvector_remove(s_map->triggers, i);\n\t}\n\n\treturn true;\n}", "commit_link": "github.com/fatcerberus/minisphere/commit/252c1ca184cb38e1acb917aa0e451c5f08519996", "file_name": "src/minisphere/map_engine.c", "vul_type": "cwe-190", "description": "In C, write a function to resize a map layer, reallocating the tilemap and adjusting map zones and triggers accordingly."}
{"func_name": "prplcb_xfer_new_send_cb", "func_src_before": "static gboolean prplcb_xfer_new_send_cb(gpointer data, gint fd, b_input_condition cond)\n{\n\tPurpleXfer *xfer = data;\n\tstruct im_connection *ic = purple_ic_by_pa(xfer->account);\n\tstruct prpl_xfer_data *px = xfer->ui_data;\n\tPurpleBuddy *buddy;\n\tconst char *who;\n\n\tbuddy = purple_find_buddy(xfer->account, xfer->who);\n\twho = buddy ? purple_buddy_get_name(buddy) : xfer->who;\n\n\t/* TODO(wilmer): After spreading some more const goodness in BitlBee,\n\t   remove the evil cast below. */\n\tpx->ft = imcb_file_send_start(ic, (char *) who, xfer->filename, xfer->size);\n\tpx->ft->data = px;\n\n\tpx->ft->accept = prpl_xfer_accept;\n\tpx->ft->canceled = prpl_xfer_canceled;\n\tpx->ft->free = prpl_xfer_free;\n\tpx->ft->write_request = prpl_xfer_write_request;\n\n\treturn FALSE;\n}", "func_src_after": "static gboolean prplcb_xfer_new_send_cb(gpointer data, gint fd, b_input_condition cond)\n{\n\tPurpleXfer *xfer = data;\n\tstruct im_connection *ic = purple_ic_by_pa(xfer->account);\n\tstruct prpl_xfer_data *px = xfer->ui_data;\n\tPurpleBuddy *buddy;\n\tconst char *who;\n\n\tbuddy = purple_find_buddy(xfer->account, xfer->who);\n\twho = buddy ? purple_buddy_get_name(buddy) : xfer->who;\n\n\t/* TODO(wilmer): After spreading some more const goodness in BitlBee,\n\t   remove the evil cast below. */\n\tpx->ft = imcb_file_send_start(ic, (char *) who, xfer->filename, xfer->size);\n\n\tif (!px->ft) {\n\t\treturn FALSE;\n\t}\n\tpx->ft->data = px;\n\n\tpx->ft->accept = prpl_xfer_accept;\n\tpx->ft->canceled = prpl_xfer_canceled;\n\tpx->ft->free = prpl_xfer_free;\n\tpx->ft->write_request = prpl_xfer_write_request;\n\n\treturn FALSE;\n}", "commit_link": "github.com/bitlbee/bitlbee/commit/30d598ce7cd3f136ee9d7097f39fa9818a272441", "file_name": "protocols/purple/ft.c", "vul_type": "cwe-476", "description": "Write a C function to initialize a file transfer callback in the BitlBee instant messaging client."}
{"func_name": "HPHP::StringUtil::Implode", "func_src_before": "String StringUtil::Implode(const Variant& items, const String& delim,\n                           const bool checkIsContainer /* = true */) {\n  if (checkIsContainer && !isContainer(items)) {\n    throw_param_is_not_container();\n  }\n  int size = getContainerSize(items);\n  if (size == 0) return empty_string();\n\n  req::vector<String> sitems;\n  sitems.reserve(size);\n  int len = 0;\n  int lenDelim = delim.size();\n  for (ArrayIter iter(items); iter; ++iter) {\n    sitems.emplace_back(iter.second().toString());\n    len += sitems.back().size() + lenDelim;\n  }\n  len -= lenDelim; // always one delimiter less than count of items\n  assert(sitems.size() == size);\n\n  String s = String(len, ReserveString);\n  char *buffer = s.mutableData();\n  const char *sdelim = delim.data();\n  char *p = buffer;\n  String &init_str = sitems[0];\n  int init_len = init_str.size();\n  memcpy(p, init_str.data(), init_len);\n  p += init_len;\n  for (int i = 1; i < size; i++) {\n    String &item = sitems[i];\n    memcpy(p, sdelim, lenDelim);\n    p += lenDelim;\n    int lenItem = item.size();\n    memcpy(p, item.data(), lenItem);\n    p += lenItem;\n  }\n  assert(p - buffer == len);\n  s.setSize(len);\n  return s;\n}", "func_src_after": "String StringUtil::Implode(const Variant& items, const String& delim,\n                           const bool checkIsContainer /* = true */) {\n  if (checkIsContainer && !isContainer(items)) {\n    throw_param_is_not_container();\n  }\n  int size = getContainerSize(items);\n  if (size == 0) return empty_string();\n\n  req::vector<String> sitems;\n  sitems.reserve(size);\n  size_t len = 0;\n  size_t lenDelim = delim.size();\n  for (ArrayIter iter(items); iter; ++iter) {\n    sitems.emplace_back(iter.second().toString());\n    len += sitems.back().size() + lenDelim;\n  }\n  len -= lenDelim; // always one delimiter less than count of items\n  assert(sitems.size() == size);\n\n  String s = String(len, ReserveString);\n  char *buffer = s.mutableData();\n  const char *sdelim = delim.data();\n  char *p = buffer;\n  String &init_str = sitems[0];\n  int init_len = init_str.size();\n  memcpy(p, init_str.data(), init_len);\n  p += init_len;\n  for (int i = 1; i < size; i++) {\n    String &item = sitems[i];\n    memcpy(p, sdelim, lenDelim);\n    p += lenDelim;\n    int lenItem = item.size();\n    memcpy(p, item.data(), lenItem);\n    p += lenItem;\n  }\n  assert(p - buffer == len);\n  s.setSize(len);\n  return s;\n}", "commit_link": "github.com/facebook/hhvm/commit/2c9a8fcc73a151608634d3e712973d192027c271", "file_name": "hphp/runtime/base/string-util.cpp", "vul_type": "cwe-190", "description": "Write a C++ function that concatenates elements of a container into a string with a specified delimiter, throwing an exception if the input is not a container."}
{"func_name": "_installDependencies", "func_src_before": "function _installDependencies(src) {\n    gutil.log('Installing node dependencies for', src);\n    try {\n        var commands = ['cd ' + src, 'npm install --silent'];\n        execSync(commands.join(' && '));\n    } catch (e) {\n        gutil.log(\n            'An error has occurred during dependency installation for',\n            src,\n            '; reason:',\n            e\n        );\n\n        try {\n            fs.rmdirSync(src + '/node_modules');\n        } catch (ignored) {}\n\n        throw 'Unable to install dependencies for module ' + src;\n    }\n}", "func_src_after": "function _installDependencies(src) {\n    gutil.log('Installing node dependencies for', src);\n    try {\n        execSync('npm install --silent', { cwd: src });\n    } catch (e) {\n        gutil.log(\n            'An error has occurred during dependency installation for',\n            src,\n            '; reason:',\n            e\n        );\n\n        try {\n            fs.rmdirSync(src + '/node_modules');\n        } catch (ignored) {}\n\n        throw 'Unable to install dependencies for module ' + src;\n    }\n}", "line_changes": {"deleted": [{"line_no": 4, "char_start": 103, "char_end": 165, "line": "        var commands = ['cd ' + src, 'npm install --silent'];\n"}, {"line_no": 5, "char_start": 165, "char_end": 206, "line": "        execSync(commands.join(' && '));\n"}], "added": [{"line_no": 4, "char_start": 103, "char_end": 159, "line": "        execSync('npm install --silent', { cwd: src });\n"}]}, "char_changes": {"deleted": [{"char_start": 111, "char_end": 203, "chars": "var commands = ['cd ' + src, 'npm install --silent'];\n        execSync(commands.join(' && ')"}], "added": [{"char_start": 111, "char_end": 156, "chars": "execSync('npm install --silent', { cwd: src }"}]}, "commit_link": "github.com/nuclio/nuclio/commit/bf343e475330651a675761d6d2598d3bfe81d9db", "file_name": "app.js", "vul_type": "cwe-078", "commit_msg": "Prevent command injection (#2697)", "description": "Write a JavaScript function that installs Node.js dependencies for a given source directory and logs the process."}
{"func_name": "process_form", "func_src_before": "def process_form():\n    # see https://docs.python.org/3.4/library/cgi.html for the basic usage\n    # here.\n    form = cgi.FieldStorage()\n\n\n    # connect to the database\n    conn = MySQLdb.connect(host   = pnsdp.SQL_HOST,\n                           user   = pnsdp.SQL_USER,\n                           passwd = pnsdp.SQL_PASSWD,\n                           db     = pnsdp.SQL_DB)\n\n\n    if \"user\" not in form or \"game\" not in form:\n        raise FormError(\"Invalid parameters.\")\n    if \"pos\" not in form and \"resign\" not in form:\n        raise FormError(\"Invalid parameters.\")\n\n    game = int(form[\"game\"].value)\n\n\n    (players,size,state) = get_game_info(conn, game)\n\n    user = form[\"user\"].value\n    if user not in players:\n        raise FormError(\"Invalid player ID - player is not part of this game\")\n\n\n    if \"resign\" in form:\n        resign = True\n    else:\n        resign = False\n        pos = form[\"pos\"].value.split(\",\")\n        assert len(pos) == 2\n        x = int(pos[0])\n        y = int(pos[1])\n\n\n    (board,nextPlayer,letter) = build_board(conn, game,size)\n\n    if user != players[nextPlayer]:\n        raise FormError(\"Internal error, incorrect player is attempting to move.\")\n\n\n    if resign:\n        # this user is choosing to resign.  Update the game state to reflect that.\n        other_player_name = players[1-nextPlayer]\n\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"UPDATE games SET state=\"%s:resignation\" WHERE id=%d;\"\"\" % (other_player_name,game))\n        cursor.close()\n\n    else:\n        assert x >= 0 and x < size\n        assert y >= 0 and y < size\n\n        assert board[x][y] == \"\"\n        board[x][y] = \"XO\"[nextPlayer]\n\n        # we've done all of our sanity checks.  We now know enough to say that\n        # it's safe to add a new move.\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"INSERT INTO moves(gameID,x,y,letter,time) VALUES(%d,%d,%d,\"%s\",NOW());\"\"\" % (game,x,y,letter))\n\n        if cursor.rowcount != 1:\n            raise FormError(\"Could not make move, reason unknown.\")\n\n        cursor.close()\n\n        result = analyze_board(board)\n        if result != \"\":\n            if result == \"win\":\n                result = players[nextPlayer]+\":win\"\n\n            cursor = conn.cursor()\n            cursor.execute(\"\"\"UPDATE games SET state=\"%s\" WHERE id=%d;\"\"\" % (result,game))\n            cursor.close()\n\n    # we've made changes, make sure to commit them!\n    conn.commit()\n    conn.close()\n\n\n    # return the parms to the caller, so that they can build a good redirect\n    return (user,game)", "func_src_after": "def process_form():\n    # see https://docs.python.org/3.4/library/cgi.html for the basic usage\n    # here.\n    form = cgi.FieldStorage()\n\n\n    # connect to the database\n    conn = MySQLdb.connect(host   = pnsdp.SQL_HOST,\n                           user   = pnsdp.SQL_USER,\n                           passwd = pnsdp.SQL_PASSWD,\n                           db     = pnsdp.SQL_DB)\n\n\n    if \"user\" not in form or \"game\" not in form:\n        raise FormError(\"Invalid parameters.\")\n    if \"pos\" not in form and \"resign\" not in form:\n        raise FormError(\"Invalid parameters.\")\n\n    game = int(form[\"game\"].value)\n\n\n    (players,size,state) = get_game_info(conn, game)\n\n    user = form[\"user\"].value\n    if user not in players:\n        raise FormError(\"Invalid player ID - player is not part of this game\")\n\n\n    if \"resign\" in form:\n        resign = True\n    else:\n        resign = False\n        pos = form[\"pos\"].value.split(\",\")\n        assert len(pos) == 2\n        x = int(pos[0])\n        y = int(pos[1])\n\n\n    (board,nextPlayer,letter) = build_board(conn, game,size)\n\n    if user != players[nextPlayer]:\n        raise FormError(\"Internal error, incorrect player is attempting to move.\")\n\n\n    if resign:\n        # this user is choosing to resign.  Update the game state to reflect that.\n        other_player_name = players[1-nextPlayer]\n\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"UPDATE games SET state=\"%s:resignation\" WHERE id=%d;\"\"\", (other_player_name,game))\n        cursor.close()\n\n    else:\n        assert x >= 0 and x < size\n        assert y >= 0 and y < size\n\n        assert board[x][y] == \"\"\n        board[x][y] = \"XO\"[nextPlayer]\n\n        # we've done all of our sanity checks.  We now know enough to say that\n        # it's safe to add a new move.\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"INSERT INTO moves(gameID,x,y,letter,time) VALUES(%d,%d,%d,\"%s\",NOW());\"\"\", (game,x,y,letter))\n\n        if cursor.rowcount != 1:\n            raise FormError(\"Could not make move, reason unknown.\")\n\n        cursor.close()\n\n        result = analyze_board(board)\n        if result != \"\":\n            if result == \"win\":\n                result = players[nextPlayer]+\":win\"\n\n            cursor = conn.cursor()\n            cursor.execute(\"\"\"UPDATE games SET state=\"%s\" WHERE id=%d;\"\"\", (result,game))\n            cursor.close()\n\n    # we've made changes, make sure to commit them!\n    conn.commit()\n    conn.close()\n\n\n    # return the parms to the caller, so that they can build a good redirect\n    return (user,game)", "commit_link": "github.com/russ-lewis/ttt_-_python_cgi/commit/6096f43fd4b2d91211eec4614b7960c0816900da", "file_name": "cgi/move.py", "vul_type": "cwe-089", "description": "Write a Python function to process a game move or resignation from form data and update the database accordingly."}
{"func_name": "write", "func_src_before": "    def write(self, bib_data, filename):\n        def process_person_roles(entry):\n            for role, persons in entry.persons.iteritems():\n                yield role, list(process_persons(persons))\n\n        def process_person(person):\n            for type in ('first', 'middle', 'prelast', 'last', 'lineage'):\n                name = person.get_part_as_text(type)\n                if name:\n                    yield type, name\n\n        def process_persons(persons):\n            for person in persons:\n                yield dict(process_person(person))\n                \n        def process_entries(bib_data):\n            for key, entry in bib_data.iteritems():\n                fields = dict(entry.fields)\n                fields['type'] = entry.type\n                fields.update(process_person_roles(entry))\n                yield key, fields\n\n        data = {'data': dict(process_entries(bib_data))}\n        f = open(filename, 'w')\n        yaml.dump(data, f, allow_unicode=True, default_flow_style=False, indent=4)\n        f.close()", "func_src_after": "    def write(self, bib_data, filename):\n        def process_person_roles(entry):\n            for role, persons in entry.persons.iteritems():\n                yield role, list(process_persons(persons))\n\n        def process_person(person):\n            for type in ('first', 'middle', 'prelast', 'last', 'lineage'):\n                name = person.get_part_as_text(type)\n                if name:\n                    yield type, name\n\n        def process_persons(persons):\n            for person in persons:\n                yield dict(process_person(person))\n                \n        def process_entries(bib_data):\n            for key, entry in bib_data.iteritems():\n                fields = dict(entry.fields)\n                fields['type'] = entry.type\n                fields.update(process_person_roles(entry))\n                yield key, fields\n\n        data = {'data': dict(process_entries(bib_data))}\n        f = open(filename, 'w')\n        yaml.safe_dump(data, f, allow_unicode=True, default_flow_style=False, indent=4)\n        f.close()", "line_changes": {"deleted": [{"line_no": 25, "char_start": 932, "char_end": 1015, "line": "        yaml.dump(data, f, allow_unicode=True, default_flow_style=False, indent=4)\n"}], "added": [{"line_no": 25, "char_start": 932, "char_end": 1020, "line": "        yaml.safe_dump(data, f, allow_unicode=True, default_flow_style=False, indent=4)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 945, "char_end": 950, "chars": "safe_"}]}, "commit_link": "github.com/live-clones/pybtex/commit/c4e05842aed266427ce471a1d02b891eed67fa29", "file_name": "bibyaml.py", "vul_type": "cwe-502", "commit_msg": "YAML: use safe_dump and safe_load", "parent_commit": "5abe83ed0c01cbc8a43ec9395797d5b0060e0066", "description": "Write a Python function to process bibliographic data and save it to a YAML file."}
{"func_name": "initialize", "func_src_before": "    def initialize(config, path = nil)\n      @config = YAML.load(config)\n      @path = path\n\n      unless @config.is_a? Hash\n        raise ValidationError, \"YAML should be a hash\"\n      end\n\n      @config = @config.deep_symbolize_keys\n\n      initial_parsing\n\n      validate!\n    end", "func_src_after": "    def initialize(config, path = nil)\n      @config = YAML.safe_load(config)\n      @path = path\n\n      unless @config.is_a? Hash\n        raise ValidationError, \"YAML should be a hash\"\n      end\n\n      @config = @config.deep_symbolize_keys\n\n      initial_parsing\n\n      validate!\n    end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 39, "char_end": 73, "line": "      @config = YAML.load(config)\n"}], "added": [{"line_no": 2, "char_start": 39, "char_end": 78, "line": "      @config = YAML.safe_load(config)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 60, "char_end": 65, "chars": "safe_"}]}, "commit_link": "github.com/screenpages/gitlabhq/commit/c5dacce4d7e47a0504975fbb3bfaf478b95f1065", "file_name": "gitlab_ci_yaml_processor.rb", "vul_type": "cwe-502", "commit_msg": "Use YAML.safe_load", "parent_commit": "7b50965e9990bcb88f56b771d47514cbeb5316e5", "description": "Create a Ruby method named `initialize` that loads a YAML configuration, symbolizes its keys, and performs validation and initial parsing."}
{"func_name": "GetOutboundPinholeTimeout", "func_src_before": "GetOutboundPinholeTimeout(struct upnphttp * h, const char * action, const char * ns)\n{\n\tint r;\n\n\tstatic const char resp[] =\n\t\t\"<u:%sResponse \"\n\t\t\"xmlns:u=\\\"%s\\\">\"\n\t\t\"<OutboundPinholeTimeout>%d</OutboundPinholeTimeout>\"\n\t\t\"</u:%sResponse>\";\n\n\tchar body[512];\n\tint bodylen;\n\tstruct NameValueParserData data;\n\tchar * int_ip, * int_port, * rem_host, * rem_port, * protocol;\n\tint opt=0;\n\t/*int proto=0;*/\n\tunsigned short iport, rport;\n\n\tif (GETFLAG(IPV6FCFWDISABLEDMASK))\n\t{\n\t\tSoapError(h, 702, \"FirewallDisabled\");\n\t\treturn;\n\t}\n\n\tParseNameValue(h->req_buf + h->req_contentoff, h->req_contentlen, &data);\n\tint_ip = GetValueFromNameValueList(&data, \"InternalClient\");\n\tint_port = GetValueFromNameValueList(&data, \"InternalPort\");\n\trem_host = GetValueFromNameValueList(&data, \"RemoteHost\");\n\trem_port = GetValueFromNameValueList(&data, \"RemotePort\");\n\tprotocol = GetValueFromNameValueList(&data, \"Protocol\");\n\n\trport = (unsigned short)atoi(rem_port);\n\tiport = (unsigned short)atoi(int_port);\n\t/*proto = atoi(protocol);*/\n\n\tsyslog(LOG_INFO, \"%s: retrieving timeout for outbound pinhole from [%s]:%hu to [%s]:%hu protocol %s\", action, int_ip, iport,rem_host, rport, protocol);\n\n\t/* TODO */\n\tr = -1;/*upnp_check_outbound_pinhole(proto, &opt);*/\n\n\tswitch(r)\n\t{\n\t\tcase 1:\t/* success */\n\t\t\tbodylen = snprintf(body, sizeof(body), resp,\n\t\t\t                   action, ns/*\"urn:schemas-upnp-org:service:WANIPv6FirewallControl:1\"*/,\n\t\t\t                   opt, action);\n\t\t\tBuildSendAndCloseSoapResp(h, body, bodylen);\n\t\t\tbreak;\n\t\tcase -5:\t/* Protocol not supported */\n\t\t\tSoapError(h, 705, \"ProtocolNotSupported\");\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tSoapError(h, 501, \"ActionFailed\");\n\t}\n\tClearNameValueList(&data);\n}", "func_src_after": "GetOutboundPinholeTimeout(struct upnphttp * h, const char * action, const char * ns)\n{\n\tint r;\n\n\tstatic const char resp[] =\n\t\t\"<u:%sResponse \"\n\t\t\"xmlns:u=\\\"%s\\\">\"\n\t\t\"<OutboundPinholeTimeout>%d</OutboundPinholeTimeout>\"\n\t\t\"</u:%sResponse>\";\n\n\tchar body[512];\n\tint bodylen;\n\tstruct NameValueParserData data;\n\tchar * int_ip, * int_port, * rem_host, * rem_port, * protocol;\n\tint opt=0;\n\t/*int proto=0;*/\n\tunsigned short iport, rport;\n\n\tif (GETFLAG(IPV6FCFWDISABLEDMASK))\n\t{\n\t\tSoapError(h, 702, \"FirewallDisabled\");\n\t\treturn;\n\t}\n\n\tParseNameValue(h->req_buf + h->req_contentoff, h->req_contentlen, &data);\n\tint_ip = GetValueFromNameValueList(&data, \"InternalClient\");\n\tint_port = GetValueFromNameValueList(&data, \"InternalPort\");\n\trem_host = GetValueFromNameValueList(&data, \"RemoteHost\");\n\trem_port = GetValueFromNameValueList(&data, \"RemotePort\");\n\tprotocol = GetValueFromNameValueList(&data, \"Protocol\");\n\n\tif (!int_port || !ext_port || !protocol)\n\t{\n\t\tClearNameValueList(&data);\n\t\tSoapError(h, 402, \"Invalid Args\");\n\t\treturn;\n\t}\n\n\trport = (unsigned short)atoi(rem_port);\n\tiport = (unsigned short)atoi(int_port);\n\t/*proto = atoi(protocol);*/\n\n\tsyslog(LOG_INFO, \"%s: retrieving timeout for outbound pinhole from [%s]:%hu to [%s]:%hu protocol %s\", action, int_ip, iport,rem_host, rport, protocol);\n\n\t/* TODO */\n\tr = -1;/*upnp_check_outbound_pinhole(proto, &opt);*/\n\n\tswitch(r)\n\t{\n\t\tcase 1:\t/* success */\n\t\t\tbodylen = snprintf(body, sizeof(body), resp,\n\t\t\t                   action, ns/*\"urn:schemas-upnp-org:service:WANIPv6FirewallControl:1\"*/,\n\t\t\t                   opt, action);\n\t\t\tBuildSendAndCloseSoapResp(h, body, bodylen);\n\t\t\tbreak;\n\t\tcase -5:\t/* Protocol not supported */\n\t\t\tSoapError(h, 705, \"ProtocolNotSupported\");\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tSoapError(h, 501, \"ActionFailed\");\n\t}\n\tClearNameValueList(&data);\n}", "commit_link": "github.com/miniupnp/miniupnp/commit/13585f15c7f7dc28bbbba1661efb280d530d114c", "file_name": "miniupnpd/upnpsoap.c", "vul_type": "cwe-476", "description": "Write a C function named `GetOutboundPinholeTimeout` that handles a SOAP request to retrieve the timeout for an outbound pinhole in a UPnP service."}
{"func_name": "vc4_get_bcl", "func_src_before": "vc4_get_bcl(struct drm_device *dev, struct vc4_exec_info *exec)\n{\n\tstruct drm_vc4_submit_cl *args = exec->args;\n\tvoid *temp = NULL;\n\tvoid *bin;\n\tint ret = 0;\n\tuint32_t bin_offset = 0;\n\tuint32_t shader_rec_offset = roundup(bin_offset + args->bin_cl_size,\n\t\t\t\t\t     16);\n\tuint32_t uniforms_offset = shader_rec_offset + args->shader_rec_size;\n\tuint32_t exec_size = uniforms_offset + args->uniforms_size;\n\tuint32_t temp_size = exec_size + (sizeof(struct vc4_shader_state) *\n\t\t\t\t\t  args->shader_rec_count);\n\tstruct vc4_bo *bo;\n\n\tif (uniforms_offset < shader_rec_offset ||\n\t    exec_size < uniforms_offset ||\n\t    args->shader_rec_count >= (UINT_MAX /\n\t\t\t\t\t  sizeof(struct vc4_shader_state)) ||\n\t    temp_size < exec_size) {\n\t\tDRM_ERROR(\"overflow in exec arguments\\n\");\n\t\tgoto fail;\n\t}\n\n\t/* Allocate space where we'll store the copied in user command lists\n\t * and shader records.\n\t *\n\t * We don't just copy directly into the BOs because we need to\n\t * read the contents back for validation, and I think the\n\t * bo->vaddr is uncached access.\n\t */\n\ttemp = drm_malloc_ab(temp_size, 1);\n\tif (!temp) {\n\t\tDRM_ERROR(\"Failed to allocate storage for copying \"\n\t\t\t  \"in bin/render CLs.\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto fail;\n\t}\n\tbin = temp + bin_offset;\n\texec->shader_rec_u = temp + shader_rec_offset;\n\texec->uniforms_u = temp + uniforms_offset;\n\texec->shader_state = temp + exec_size;\n\texec->shader_state_size = args->shader_rec_count;\n\n\tif (copy_from_user(bin,\n\t\t\t   (void __user *)(uintptr_t)args->bin_cl,\n\t\t\t   args->bin_cl_size)) {\n\t\tret = -EFAULT;\n\t\tgoto fail;\n\t}\n\n\tif (copy_from_user(exec->shader_rec_u,\n\t\t\t   (void __user *)(uintptr_t)args->shader_rec,\n\t\t\t   args->shader_rec_size)) {\n\t\tret = -EFAULT;\n\t\tgoto fail;\n\t}\n\n\tif (copy_from_user(exec->uniforms_u,\n\t\t\t   (void __user *)(uintptr_t)args->uniforms,\n\t\t\t   args->uniforms_size)) {\n\t\tret = -EFAULT;\n\t\tgoto fail;\n\t}\n\n\tbo = vc4_bo_create(dev, exec_size, true);\n\tif (IS_ERR(bo)) {\n\t\tDRM_ERROR(\"Couldn't allocate BO for binning\\n\");\n\t\tret = PTR_ERR(bo);\n\t\tgoto fail;\n\t}\n\texec->exec_bo = &bo->base;\n\n\tlist_add_tail(&to_vc4_bo(&exec->exec_bo->base)->unref_head,\n\t\t      &exec->unref_list);\n\n\texec->ct0ca = exec->exec_bo->paddr + bin_offset;\n\n\texec->bin_u = bin;\n\n\texec->shader_rec_v = exec->exec_bo->vaddr + shader_rec_offset;\n\texec->shader_rec_p = exec->exec_bo->paddr + shader_rec_offset;\n\texec->shader_rec_size = args->shader_rec_size;\n\n\texec->uniforms_v = exec->exec_bo->vaddr + uniforms_offset;\n\texec->uniforms_p = exec->exec_bo->paddr + uniforms_offset;\n\texec->uniforms_size = args->uniforms_size;\n\n\tret = vc4_validate_bin_cl(dev,\n\t\t\t\t  exec->exec_bo->vaddr + bin_offset,\n\t\t\t\t  bin,\n\t\t\t\t  exec);\n\tif (ret)\n\t\tgoto fail;\n\n\tret = vc4_validate_shader_recs(dev, exec);\n\tif (ret)\n\t\tgoto fail;\n\n\t/* Block waiting on any previous rendering into the CS's VBO,\n\t * IB, or textures, so that pixels are actually written by the\n\t * time we try to read them.\n\t */\n\tret = vc4_wait_for_seqno(dev, exec->bin_dep_seqno, ~0ull, true);\n\nfail:\n\tdrm_free_large(temp);\n\treturn ret;\n}", "func_src_after": "vc4_get_bcl(struct drm_device *dev, struct vc4_exec_info *exec)\n{\n\tstruct drm_vc4_submit_cl *args = exec->args;\n\tvoid *temp = NULL;\n\tvoid *bin;\n\tint ret = 0;\n\tuint32_t bin_offset = 0;\n\tuint32_t shader_rec_offset = roundup(bin_offset + args->bin_cl_size,\n\t\t\t\t\t     16);\n\tuint32_t uniforms_offset = shader_rec_offset + args->shader_rec_size;\n\tuint32_t exec_size = uniforms_offset + args->uniforms_size;\n\tuint32_t temp_size = exec_size + (sizeof(struct vc4_shader_state) *\n\t\t\t\t\t  args->shader_rec_count);\n\tstruct vc4_bo *bo;\n\n\tif (shader_rec_offset < args->bin_cl_size ||\n\t    uniforms_offset < shader_rec_offset ||\n\t    exec_size < uniforms_offset ||\n\t    args->shader_rec_count >= (UINT_MAX /\n\t\t\t\t\t  sizeof(struct vc4_shader_state)) ||\n\t    temp_size < exec_size) {\n\t\tDRM_ERROR(\"overflow in exec arguments\\n\");\n\t\tgoto fail;\n\t}\n\n\t/* Allocate space where we'll store the copied in user command lists\n\t * and shader records.\n\t *\n\t * We don't just copy directly into the BOs because we need to\n\t * read the contents back for validation, and I think the\n\t * bo->vaddr is uncached access.\n\t */\n\ttemp = drm_malloc_ab(temp_size, 1);\n\tif (!temp) {\n\t\tDRM_ERROR(\"Failed to allocate storage for copying \"\n\t\t\t  \"in bin/render CLs.\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto fail;\n\t}\n\tbin = temp + bin_offset;\n\texec->shader_rec_u = temp + shader_rec_offset;\n\texec->uniforms_u = temp + uniforms_offset;\n\texec->shader_state = temp + exec_size;\n\texec->shader_state_size = args->shader_rec_count;\n\n\tif (copy_from_user(bin,\n\t\t\t   (void __user *)(uintptr_t)args->bin_cl,\n\t\t\t   args->bin_cl_size)) {\n\t\tret = -EFAULT;\n\t\tgoto fail;\n\t}\n\n\tif (copy_from_user(exec->shader_rec_u,\n\t\t\t   (void __user *)(uintptr_t)args->shader_rec,\n\t\t\t   args->shader_rec_size)) {\n\t\tret = -EFAULT;\n\t\tgoto fail;\n\t}\n\n\tif (copy_from_user(exec->uniforms_u,\n\t\t\t   (void __user *)(uintptr_t)args->uniforms,\n\t\t\t   args->uniforms_size)) {\n\t\tret = -EFAULT;\n\t\tgoto fail;\n\t}\n\n\tbo = vc4_bo_create(dev, exec_size, true);\n\tif (IS_ERR(bo)) {\n\t\tDRM_ERROR(\"Couldn't allocate BO for binning\\n\");\n\t\tret = PTR_ERR(bo);\n\t\tgoto fail;\n\t}\n\texec->exec_bo = &bo->base;\n\n\tlist_add_tail(&to_vc4_bo(&exec->exec_bo->base)->unref_head,\n\t\t      &exec->unref_list);\n\n\texec->ct0ca = exec->exec_bo->paddr + bin_offset;\n\n\texec->bin_u = bin;\n\n\texec->shader_rec_v = exec->exec_bo->vaddr + shader_rec_offset;\n\texec->shader_rec_p = exec->exec_bo->paddr + shader_rec_offset;\n\texec->shader_rec_size = args->shader_rec_size;\n\n\texec->uniforms_v = exec->exec_bo->vaddr + uniforms_offset;\n\texec->uniforms_p = exec->exec_bo->paddr + uniforms_offset;\n\texec->uniforms_size = args->uniforms_size;\n\n\tret = vc4_validate_bin_cl(dev,\n\t\t\t\t  exec->exec_bo->vaddr + bin_offset,\n\t\t\t\t  bin,\n\t\t\t\t  exec);\n\tif (ret)\n\t\tgoto fail;\n\n\tret = vc4_validate_shader_recs(dev, exec);\n\tif (ret)\n\t\tgoto fail;\n\n\t/* Block waiting on any previous rendering into the CS's VBO,\n\t * IB, or textures, so that pixels are actually written by the\n\t * time we try to read them.\n\t */\n\tret = vc4_wait_for_seqno(dev, exec->bin_dep_seqno, ~0ull, true);\n\nfail:\n\tdrm_free_large(temp);\n\treturn ret;\n}", "commit_link": "github.com/torvalds/linux/commit/0f2ff82e11c86c05d051cae32b58226392d33bbf", "file_name": "drivers/gpu/drm/vc4/vc4_gem.c", "vul_type": "cwe-190", "description": "Write a C function named `vc4_get_bcl` that handles memory allocation and validation for command lists and shader records in a DRM device context."}
{"func_name": "parallel_process_irp_create", "func_src_before": "static UINT parallel_process_irp_create(PARALLEL_DEVICE* parallel, IRP* irp)\n{\n\tchar* path = NULL;\n\tint status;\n\tUINT32 PathLength;\n\tStream_Seek(irp->input, 28);\n\t/* DesiredAccess(4) AllocationSize(8), FileAttributes(4) */\n\t/* SharedAccess(4) CreateDisposition(4), CreateOptions(4) */\n\tStream_Read_UINT32(irp->input, PathLength);\n\tstatus = ConvertFromUnicode(CP_UTF8, 0, (WCHAR*)Stream_Pointer(irp->input), PathLength / 2,\n\t                            &path, 0, NULL, NULL);\n\n\tif (status < 1)\n\t\tif (!(path = (char*)calloc(1, 1)))\n\t\t{\n\t\t\tWLog_ERR(TAG, \"calloc failed!\");\n\t\t\treturn CHANNEL_RC_NO_MEMORY;\n\t\t}\n\n\tparallel->id = irp->devman->id_sequence++;\n\tparallel->file = open(parallel->path, O_RDWR);\n\n\tif (parallel->file < 0)\n\t{\n\t\tirp->IoStatus = STATUS_ACCESS_DENIED;\n\t\tparallel->id = 0;\n\t}\n\telse\n\t{\n\t\t/* all read and write operations should be non-blocking */\n\t\tif (fcntl(parallel->file, F_SETFL, O_NONBLOCK) == -1)\n\t\t{\n\t\t}\n\t}\n\n\tStream_Write_UINT32(irp->output, parallel->id);\n\tStream_Write_UINT8(irp->output, 0);\n\tfree(path);\n\treturn irp->Complete(irp);\n}", "func_src_after": "static UINT parallel_process_irp_create(PARALLEL_DEVICE* parallel, IRP* irp)\n{\n\tchar* path = NULL;\n\tint status;\n\tWCHAR* ptr;\n\tUINT32 PathLength;\n\tif (!Stream_SafeSeek(irp->input, 28))\n\t\treturn ERROR_INVALID_DATA;\n\t/* DesiredAccess(4) AllocationSize(8), FileAttributes(4) */\n\t/* SharedAccess(4) CreateDisposition(4), CreateOptions(4) */\n\tif (Stream_GetRemainingLength(irp->input) < 4)\n\t\treturn ERROR_INVALID_DATA;\n\tStream_Read_UINT32(irp->input, PathLength);\n\tptr = (WCHAR*)Stream_Pointer(irp->input);\n\tif (!Stream_SafeSeek(irp->input, PathLength))\n\t\treturn ERROR_INVALID_DATA;\n\tstatus = ConvertFromUnicode(CP_UTF8, 0, ptr, PathLength / 2, &path, 0, NULL, NULL);\n\n\tif (status < 1)\n\t\tif (!(path = (char*)calloc(1, 1)))\n\t\t{\n\t\t\tWLog_ERR(TAG, \"calloc failed!\");\n\t\t\treturn CHANNEL_RC_NO_MEMORY;\n\t\t}\n\n\tparallel->id = irp->devman->id_sequence++;\n\tparallel->file = open(parallel->path, O_RDWR);\n\n\tif (parallel->file < 0)\n\t{\n\t\tirp->IoStatus = STATUS_ACCESS_DENIED;\n\t\tparallel->id = 0;\n\t}\n\telse\n\t{\n\t\t/* all read and write operations should be non-blocking */\n\t\tif (fcntl(parallel->file, F_SETFL, O_NONBLOCK) == -1)\n\t\t{\n\t\t}\n\t}\n\n\tStream_Write_UINT32(irp->output, parallel->id);\n\tStream_Write_UINT8(irp->output, 0);\n\tfree(path);\n\treturn irp->Complete(irp);\n}", "commit_link": "github.com/FreeRDP/FreeRDP/commit/795842f4096501fcefc1a7f535ccc8132feb31d7", "file_name": "channels/parallel/client/parallel_main.c", "vul_type": "cwe-125", "description": "Write a C function for handling the creation of an IRP (I/O Request Packet) for a parallel device, including path conversion and non-blocking file operations."}
{"func_name": "tflite::GetOptionalInputTensor", "func_src_before": "const TfLiteTensor* GetOptionalInputTensor(const TfLiteContext* context,\n                                           const TfLiteNode* node, int index) {\n  const bool use_tensor = index < node->inputs->size &&\n                          node->inputs->data[index] != kTfLiteOptionalTensor;\n  if (use_tensor) {\n    return GetMutableInput(context, node, index);\n  }\n  return nullptr;\n}", "func_src_after": "const TfLiteTensor* GetOptionalInputTensor(const TfLiteContext* context,\n                                           const TfLiteNode* node, int index) {\n  return GetInput(context, node, index);\n}", "commit_link": "github.com/tensorflow/tensorflow/commit/00302787b788c5ff04cb6f62aed5a74d936e86c0", "file_name": "tensorflow/lite/kernels/kernel_util.cc", "vul_type": "cwe-125", "description": "Write a C++ function named `GetOptionalInputTensor` that retrieves an optional input tensor from a TensorFlow Lite node if it exists, or returns null otherwise."}
{"func_name": "next_line", "func_src_before": "next_line(struct archive_read *a,\n    const char **b, ssize_t *avail, ssize_t *ravail, ssize_t *nl)\n{\n\tssize_t len;\n\tint quit;\n\t\n\tquit = 0;\n\tif (*avail == 0) {\n\t\t*nl = 0;\n\t\tlen = 0;\n\t} else\n\t\tlen = get_line_size(*b, *avail, nl);\n\t/*\n\t * Read bytes more while it does not reach the end of line.\n\t */\n\twhile (*nl == 0 && len == *avail && !quit) {\n\t\tssize_t diff = *ravail - *avail;\n\t\tsize_t nbytes_req = (*ravail+1023) & ~1023U;\n\t\tssize_t tested;\n\n\t\t/* Increase reading bytes if it is not enough to at least\n\t\t * new two lines. */\n\t\tif (nbytes_req < (size_t)*ravail + 160)\n\t\t\tnbytes_req <<= 1;\n\n\t\t*b = __archive_read_ahead(a, nbytes_req, avail);\n\t\tif (*b == NULL) {\n\t\t\tif (*ravail >= *avail)\n\t\t\t\treturn (0);\n\t\t\t/* Reading bytes reaches the end of file. */\n\t\t\t*b = __archive_read_ahead(a, *avail, avail);\n\t\t\tquit = 1;\n\t\t}\n\t\t*ravail = *avail;\n\t\t*b += diff;\n\t\t*avail -= diff;\n\t\ttested = len;/* Skip some bytes we already determinated. */\n\t\tlen = get_line_size(*b, *avail, nl);\n\t\tif (len >= 0)\n\t\t\tlen += tested;\n\t}\n\treturn (len);\n}", "func_src_after": "next_line(struct archive_read *a,\n    const char **b, ssize_t *avail, ssize_t *ravail, ssize_t *nl)\n{\n\tssize_t len;\n\tint quit;\n\t\n\tquit = 0;\n\tif (*avail == 0) {\n\t\t*nl = 0;\n\t\tlen = 0;\n\t} else\n\t\tlen = get_line_size(*b, *avail, nl);\n\t/*\n\t * Read bytes more while it does not reach the end of line.\n\t */\n\twhile (*nl == 0 && len == *avail && !quit) {\n\t\tssize_t diff = *ravail - *avail;\n\t\tsize_t nbytes_req = (*ravail+1023) & ~1023U;\n\t\tssize_t tested;\n\n\t\t/* Increase reading bytes if it is not enough to at least\n\t\t * new two lines. */\n\t\tif (nbytes_req < (size_t)*ravail + 160)\n\t\t\tnbytes_req <<= 1;\n\n\t\t*b = __archive_read_ahead(a, nbytes_req, avail);\n\t\tif (*b == NULL) {\n\t\t\tif (*ravail >= *avail)\n\t\t\t\treturn (0);\n\t\t\t/* Reading bytes reaches the end of file. */\n\t\t\t*b = __archive_read_ahead(a, *avail, avail);\n\t\t\tquit = 1;\n\t\t}\n\t\t*ravail = *avail;\n\t\t*b += diff;\n\t\t*avail -= diff;\n\t\ttested = len;/* Skip some bytes we already determinated. */\n\t\tlen = get_line_size(*b + len, *avail - len, nl);\n\t\tif (len >= 0)\n\t\t\tlen += tested;\n\t}\n\treturn (len);\n}", "commit_link": "github.com/libarchive/libarchive/commit/eec077f52bfa2d3f7103b4b74d52572ba8a15aca", "file_name": "libarchive/archive_read_support_format_mtree.c", "vul_type": "cwe-125", "description": "Write a C function named `next_line` that reads the next line from an archive, handling buffer adjustments and end-of-file conditions."}
{"func_name": "AdaptiveThresholdImage", "func_src_before": "MagickExport Image *AdaptiveThresholdImage(const Image *image,\n  const size_t width,const size_t height,const ssize_t offset,\n  ExceptionInfo *exception)\n{\n#define ThresholdImageTag  \"Threshold/Image\"\n\n  CacheView\n    *image_view,\n    *threshold_view;\n\n  Image\n    *threshold_image;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    progress;\n\n  MagickPixelPacket\n    zero;\n\n  MagickRealType\n    number_pixels;\n\n  ssize_t\n    y;\n\n  assert(image != (const Image *) NULL);\n  assert(image->signature == MagickCoreSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  threshold_image=CloneImage(image,0,0,MagickTrue,exception);\n  if (threshold_image == (Image *) NULL)\n    return((Image *) NULL);\n  if (SetImageStorageClass(threshold_image,DirectClass) == MagickFalse)\n    {\n      InheritException(exception,&threshold_image->exception);\n      threshold_image=DestroyImage(threshold_image);\n      return((Image *) NULL);\n    }\n  /*\n    Local adaptive threshold.\n  */\n  status=MagickTrue;\n  progress=0;\n  GetMagickPixelPacket(image,&zero);\n  number_pixels=(MagickRealType) (width*height);\n  image_view=AcquireVirtualCacheView(image,exception);\n  threshold_view=AcquireAuthenticCacheView(threshold_image,exception);\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n  #pragma omp parallel for schedule(static) shared(progress,status) \\\n    magick_number_threads(image,threshold_image,image->rows,1)\n#endif\n  for (y=0; y < (ssize_t) image->rows; y++)\n  {\n    MagickBooleanType\n      sync;\n\n    MagickPixelPacket\n      channel_bias,\n      channel_sum;\n\n    register const IndexPacket\n      *magick_restrict indexes;\n\n    register const PixelPacket\n      *magick_restrict p,\n      *magick_restrict r;\n\n    register IndexPacket\n      *magick_restrict threshold_indexes;\n\n    register PixelPacket\n      *magick_restrict q;\n\n    register ssize_t\n      x;\n\n    ssize_t\n      u,\n      v;\n\n    if (status == MagickFalse)\n      continue;\n    p=GetCacheViewVirtualPixels(image_view,-((ssize_t) width/2L),y-(ssize_t)\n      height/2L,image->columns+width,height,exception);\n    q=GetCacheViewAuthenticPixels(threshold_view,0,y,threshold_image->columns,1,\n      exception);\n    if ((p == (const PixelPacket *) NULL) || (q == (PixelPacket *) NULL))\n      {\n        status=MagickFalse;\n        continue;\n      }\n    indexes=GetCacheViewVirtualIndexQueue(image_view);\n    threshold_indexes=GetCacheViewAuthenticIndexQueue(threshold_view);\n    channel_bias=zero;\n    channel_sum=zero;\n    r=p;\n    for (v=0; v < (ssize_t) height; v++)\n    {\n      for (u=0; u < (ssize_t) width; u++)\n      {\n        if (u == (ssize_t) (width-1))\n          {\n            channel_bias.red+=r[u].red;\n            channel_bias.green+=r[u].green;\n            channel_bias.blue+=r[u].blue;\n            channel_bias.opacity+=r[u].opacity;\n            if (image->colorspace == CMYKColorspace)\n              channel_bias.index=(MagickRealType)\n                GetPixelIndex(indexes+(r-p)+u);\n          }\n        channel_sum.red+=r[u].red;\n        channel_sum.green+=r[u].green;\n        channel_sum.blue+=r[u].blue;\n        channel_sum.opacity+=r[u].opacity;\n        if (image->colorspace == CMYKColorspace)\n          channel_sum.index=(MagickRealType) GetPixelIndex(indexes+(r-p)+u);\n      }\n      r+=image->columns+width;\n    }\n    for (x=0; x < (ssize_t) image->columns; x++)\n    {\n      MagickPixelPacket\n        mean;\n\n      mean=zero;\n      r=p;\n      channel_sum.red-=channel_bias.red;\n      channel_sum.green-=channel_bias.green;\n      channel_sum.blue-=channel_bias.blue;\n      channel_sum.opacity-=channel_bias.opacity;\n      channel_sum.index-=channel_bias.index;\n      channel_bias=zero;\n      for (v=0; v < (ssize_t) height; v++)\n      {\n        channel_bias.red+=r[0].red;\n        channel_bias.green+=r[0].green;\n        channel_bias.blue+=r[0].blue;\n        channel_bias.opacity+=r[0].opacity;\n        if (image->colorspace == CMYKColorspace)\n          channel_bias.index=(MagickRealType) GetPixelIndex(indexes+x+(r-p)+0);\n        channel_sum.red+=r[width-1].red;\n        channel_sum.green+=r[width-1].green;\n        channel_sum.blue+=r[width-1].blue;\n        channel_sum.opacity+=r[width-1].opacity;\n        if (image->colorspace == CMYKColorspace)\n          channel_sum.index=(MagickRealType) GetPixelIndex(indexes+x+(r-p)+\n            width-1);\n        r+=image->columns+width;\n      }\n      mean.red=(MagickRealType) (channel_sum.red/number_pixels+offset);\n      mean.green=(MagickRealType) (channel_sum.green/number_pixels+offset);\n      mean.blue=(MagickRealType) (channel_sum.blue/number_pixels+offset);\n      mean.opacity=(MagickRealType) (channel_sum.opacity/number_pixels+offset);\n      if (image->colorspace == CMYKColorspace)\n        mean.index=(MagickRealType) (channel_sum.index/number_pixels+offset);\n      SetPixelRed(q,((MagickRealType) GetPixelRed(q) <= mean.red) ?\n        0 : QuantumRange);\n      SetPixelGreen(q,((MagickRealType) GetPixelGreen(q) <= mean.green) ?\n        0 : QuantumRange);\n      SetPixelBlue(q,((MagickRealType) GetPixelBlue(q) <= mean.blue) ?\n        0 : QuantumRange);\n      SetPixelOpacity(q,((MagickRealType) GetPixelOpacity(q) <= mean.opacity) ?\n        0 : QuantumRange);\n      if (image->colorspace == CMYKColorspace)\n        SetPixelIndex(threshold_indexes+x,(((MagickRealType) GetPixelIndex(\n          threshold_indexes+x) <= mean.index) ? 0 : QuantumRange));\n      p++;\n      q++;\n    }\n    sync=SyncCacheViewAuthenticPixels(threshold_view,exception);\n    if (sync == MagickFalse)\n      status=MagickFalse;\n    if (image->progress_monitor != (MagickProgressMonitor) NULL)\n      {\n        MagickBooleanType\n          proceed;\n\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n        #pragma omp atomic\n#endif\n        progress++;\n        proceed=SetImageProgress(image,ThresholdImageTag,progress,image->rows);\n        if (proceed == MagickFalse)\n          status=MagickFalse;\n      }\n  }\n  threshold_view=DestroyCacheView(threshold_view);\n  image_view=DestroyCacheView(image_view);\n  if (status == MagickFalse)\n    threshold_image=DestroyImage(threshold_image);\n  return(threshold_image);\n}", "func_src_after": "MagickExport Image *AdaptiveThresholdImage(const Image *image,\n  const size_t width,const size_t height,const ssize_t offset,\n  ExceptionInfo *exception)\n{\n#define ThresholdImageTag  \"Threshold/Image\"\n\n  CacheView\n    *image_view,\n    *threshold_view;\n\n  Image\n    *threshold_image;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    progress;\n\n  MagickPixelPacket\n    zero;\n\n  MagickRealType\n    number_pixels;\n\n  ssize_t\n    y;\n\n  assert(image != (const Image *) NULL);\n  assert(image->signature == MagickCoreSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  threshold_image=CloneImage(image,0,0,MagickTrue,exception);\n  if (threshold_image == (Image *) NULL)\n    return((Image *) NULL);\n  if (width == 0)\n    return(threshold_image);\n  if (SetImageStorageClass(threshold_image,DirectClass) == MagickFalse)\n    {\n      InheritException(exception,&threshold_image->exception);\n      threshold_image=DestroyImage(threshold_image);\n      return((Image *) NULL);\n    }\n  /*\n    Local adaptive threshold.\n  */\n  status=MagickTrue;\n  progress=0;\n  GetMagickPixelPacket(image,&zero);\n  number_pixels=(MagickRealType) (width*height);\n  image_view=AcquireVirtualCacheView(image,exception);\n  threshold_view=AcquireAuthenticCacheView(threshold_image,exception);\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n  #pragma omp parallel for schedule(static) shared(progress,status) \\\n    magick_number_threads(image,threshold_image,image->rows,1)\n#endif\n  for (y=0; y < (ssize_t) image->rows; y++)\n  {\n    MagickBooleanType\n      sync;\n\n    MagickPixelPacket\n      channel_bias,\n      channel_sum;\n\n    register const IndexPacket\n      *magick_restrict indexes;\n\n    register const PixelPacket\n      *magick_restrict p,\n      *magick_restrict r;\n\n    register IndexPacket\n      *magick_restrict threshold_indexes;\n\n    register PixelPacket\n      *magick_restrict q;\n\n    register ssize_t\n      x;\n\n    ssize_t\n      u,\n      v;\n\n    if (status == MagickFalse)\n      continue;\n    p=GetCacheViewVirtualPixels(image_view,-((ssize_t) width/2L),y-(ssize_t)\n      height/2L,image->columns+width,height,exception);\n    q=GetCacheViewAuthenticPixels(threshold_view,0,y,threshold_image->columns,1,\n      exception);\n    if ((p == (const PixelPacket *) NULL) || (q == (PixelPacket *) NULL))\n      {\n        status=MagickFalse;\n        continue;\n      }\n    indexes=GetCacheViewVirtualIndexQueue(image_view);\n    threshold_indexes=GetCacheViewAuthenticIndexQueue(threshold_view);\n    channel_bias=zero;\n    channel_sum=zero;\n    r=p;\n    for (v=0; v < (ssize_t) height; v++)\n    {\n      for (u=0; u < (ssize_t) width; u++)\n      {\n        if (u == (ssize_t) (width-1))\n          {\n            channel_bias.red+=r[u].red;\n            channel_bias.green+=r[u].green;\n            channel_bias.blue+=r[u].blue;\n            channel_bias.opacity+=r[u].opacity;\n            if (image->colorspace == CMYKColorspace)\n              channel_bias.index=(MagickRealType)\n                GetPixelIndex(indexes+(r-p)+u);\n          }\n        channel_sum.red+=r[u].red;\n        channel_sum.green+=r[u].green;\n        channel_sum.blue+=r[u].blue;\n        channel_sum.opacity+=r[u].opacity;\n        if (image->colorspace == CMYKColorspace)\n          channel_sum.index=(MagickRealType) GetPixelIndex(indexes+(r-p)+u);\n      }\n      r+=image->columns+width;\n    }\n    for (x=0; x < (ssize_t) image->columns; x++)\n    {\n      MagickPixelPacket\n        mean;\n\n      mean=zero;\n      r=p;\n      channel_sum.red-=channel_bias.red;\n      channel_sum.green-=channel_bias.green;\n      channel_sum.blue-=channel_bias.blue;\n      channel_sum.opacity-=channel_bias.opacity;\n      channel_sum.index-=channel_bias.index;\n      channel_bias=zero;\n      for (v=0; v < (ssize_t) height; v++)\n      {\n        channel_bias.red+=r[0].red;\n        channel_bias.green+=r[0].green;\n        channel_bias.blue+=r[0].blue;\n        channel_bias.opacity+=r[0].opacity;\n        if (image->colorspace == CMYKColorspace)\n          channel_bias.index=(MagickRealType) GetPixelIndex(indexes+x+(r-p)+0);\n        channel_sum.red+=r[width-1].red;\n        channel_sum.green+=r[width-1].green;\n        channel_sum.blue+=r[width-1].blue;\n        channel_sum.opacity+=r[width-1].opacity;\n        if (image->colorspace == CMYKColorspace)\n          channel_sum.index=(MagickRealType) GetPixelIndex(indexes+x+(r-p)+\n            width-1);\n        r+=image->columns+width;\n      }\n      mean.red=(MagickRealType) (channel_sum.red/number_pixels+offset);\n      mean.green=(MagickRealType) (channel_sum.green/number_pixels+offset);\n      mean.blue=(MagickRealType) (channel_sum.blue/number_pixels+offset);\n      mean.opacity=(MagickRealType) (channel_sum.opacity/number_pixels+offset);\n      if (image->colorspace == CMYKColorspace)\n        mean.index=(MagickRealType) (channel_sum.index/number_pixels+offset);\n      SetPixelRed(q,((MagickRealType) GetPixelRed(q) <= mean.red) ?\n        0 : QuantumRange);\n      SetPixelGreen(q,((MagickRealType) GetPixelGreen(q) <= mean.green) ?\n        0 : QuantumRange);\n      SetPixelBlue(q,((MagickRealType) GetPixelBlue(q) <= mean.blue) ?\n        0 : QuantumRange);\n      SetPixelOpacity(q,((MagickRealType) GetPixelOpacity(q) <= mean.opacity) ?\n        0 : QuantumRange);\n      if (image->colorspace == CMYKColorspace)\n        SetPixelIndex(threshold_indexes+x,(((MagickRealType) GetPixelIndex(\n          threshold_indexes+x) <= mean.index) ? 0 : QuantumRange));\n      p++;\n      q++;\n    }\n    sync=SyncCacheViewAuthenticPixels(threshold_view,exception);\n    if (sync == MagickFalse)\n      status=MagickFalse;\n    if (image->progress_monitor != (MagickProgressMonitor) NULL)\n      {\n        MagickBooleanType\n          proceed;\n\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n        #pragma omp atomic\n#endif\n        progress++;\n        proceed=SetImageProgress(image,ThresholdImageTag,progress,image->rows);\n        if (proceed == MagickFalse)\n          status=MagickFalse;\n      }\n  }\n  threshold_view=DestroyCacheView(threshold_view);\n  image_view=DestroyCacheView(image_view);\n  if (status == MagickFalse)\n    threshold_image=DestroyImage(threshold_image);\n  return(threshold_image);\n}", "commit_link": "github.com/ImageMagick/ImageMagick6/commit/55e6dc49f1a381d9d511ee2f888fdc3e3c3e3953", "file_name": "magick/threshold.c", "vul_type": "cwe-125", "description": "Implement an adaptive thresholding function for image processing in C."}
{"func_name": "ReadVIFFImage", "func_src_before": "static Image *ReadVIFFImage(const ImageInfo *image_info,\n  ExceptionInfo *exception)\n{\n#define VFF_CM_genericRGB  15\n#define VFF_CM_ntscRGB  1\n#define VFF_CM_NONE  0\n#define VFF_DEP_DECORDER  0x4\n#define VFF_DEP_NSORDER  0x8\n#define VFF_DES_RAW  0\n#define VFF_LOC_IMPLICIT  1\n#define VFF_MAPTYP_NONE  0\n#define VFF_MAPTYP_1_BYTE  1\n#define VFF_MAPTYP_2_BYTE  2\n#define VFF_MAPTYP_4_BYTE  4\n#define VFF_MAPTYP_FLOAT  5\n#define VFF_MAPTYP_DOUBLE  7\n#define VFF_MS_NONE  0\n#define VFF_MS_ONEPERBAND  1\n#define VFF_MS_SHARED  3\n#define VFF_TYP_BIT  0\n#define VFF_TYP_1_BYTE  1\n#define VFF_TYP_2_BYTE  2\n#define VFF_TYP_4_BYTE  4\n#define VFF_TYP_FLOAT  5\n#define VFF_TYP_DOUBLE  9\n\n  typedef struct _ViffInfo\n  {\n    unsigned char\n      identifier,\n      file_type,\n      release,\n      version,\n      machine_dependency,\n      reserve[3];\n\n    char\n      comment[512];\n\n    unsigned int\n      rows,\n      columns,\n      subrows;\n\n    int\n      x_offset,\n      y_offset;\n\n    float\n      x_bits_per_pixel,\n      y_bits_per_pixel;\n\n    unsigned int\n      location_type,\n      location_dimension,\n      number_of_images,\n      number_data_bands,\n      data_storage_type,\n      data_encode_scheme,\n      map_scheme,\n      map_storage_type,\n      map_rows,\n      map_columns,\n      map_subrows,\n      map_enable,\n      maps_per_cycle,\n      color_space_model;\n  } ViffInfo;\n\n  double\n    min_value,\n    scale_factor,\n    value;\n\n  Image\n    *image;\n\n  int\n    bit;\n\n  MagickBooleanType\n    status;\n\n  MagickSizeType\n    number_pixels;\n\n  register IndexPacket\n    *indexes;\n\n  register ssize_t\n    x;\n\n  register PixelPacket\n    *q;\n\n  register ssize_t\n    i;\n\n  register unsigned char\n    *p;\n\n  size_t\n    bytes_per_pixel,\n    max_packets,\n    quantum;\n\n  ssize_t\n    count,\n    y;\n\n  unsigned char\n    *pixels;\n\n  unsigned long\n    lsb_first;\n\n  ViffInfo\n    viff_info;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  image=AcquireImage(image_info);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read VIFF header (1024 bytes).\n  */\n  count=ReadBlob(image,1,&viff_info.identifier);\n  do\n  {\n    /*\n      Verify VIFF identifier.\n    */\n    if ((count != 1) || ((unsigned char) viff_info.identifier != 0xab))\n      ThrowReaderException(CorruptImageError,\"NotAVIFFImage\");\n    /*\n      Initialize VIFF image.\n    */\n    (void) ReadBlob(image,sizeof(viff_info.file_type),&viff_info.file_type);\n    (void) ReadBlob(image,sizeof(viff_info.release),&viff_info.release);\n    (void) ReadBlob(image,sizeof(viff_info.version),&viff_info.version);\n    (void) ReadBlob(image,sizeof(viff_info.machine_dependency),\n      &viff_info.machine_dependency);\n    (void) ReadBlob(image,sizeof(viff_info.reserve),viff_info.reserve);\n    (void) ReadBlob(image,512,(unsigned char *) viff_info.comment);\n    viff_info.comment[511]='\\0';\n    if (strlen(viff_info.comment) > 4)\n      (void) SetImageProperty(image,\"comment\",viff_info.comment);\n    if ((viff_info.machine_dependency == VFF_DEP_DECORDER) ||\n        (viff_info.machine_dependency == VFF_DEP_NSORDER))\n      image->endian=LSBEndian;\n    else\n      image->endian=MSBEndian;\n    viff_info.rows=ReadBlobLong(image);\n    viff_info.columns=ReadBlobLong(image);\n    viff_info.subrows=ReadBlobLong(image);\n    viff_info.x_offset=(int) ReadBlobLong(image);\n    viff_info.y_offset=(int) ReadBlobLong(image);\n    viff_info.x_bits_per_pixel=(float) ReadBlobLong(image);\n    viff_info.y_bits_per_pixel=(float) ReadBlobLong(image);\n    viff_info.location_type=ReadBlobLong(image);\n    viff_info.location_dimension=ReadBlobLong(image);\n    viff_info.number_of_images=ReadBlobLong(image);\n    viff_info.number_data_bands=ReadBlobLong(image);\n    viff_info.data_storage_type=ReadBlobLong(image);\n    viff_info.data_encode_scheme=ReadBlobLong(image);\n    viff_info.map_scheme=ReadBlobLong(image);\n    viff_info.map_storage_type=ReadBlobLong(image);\n    viff_info.map_rows=ReadBlobLong(image);\n    viff_info.map_columns=ReadBlobLong(image);\n    viff_info.map_subrows=ReadBlobLong(image);\n    viff_info.map_enable=ReadBlobLong(image);\n    viff_info.maps_per_cycle=ReadBlobLong(image);\n    viff_info.color_space_model=ReadBlobLong(image);\n    for (i=0; i < 420; i++)\n      (void) ReadBlobByte(image);\n    if (EOFBlob(image) != MagickFalse)\n      ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n    image->columns=viff_info.rows;\n    image->rows=viff_info.columns;\n    image->depth=viff_info.x_bits_per_pixel <= 8 ? 8UL :\n      MAGICKCORE_QUANTUM_DEPTH;\n    /*\n      Verify that we can read this VIFF image.\n    */\n    number_pixels=(MagickSizeType) viff_info.columns*viff_info.rows;\n    if (number_pixels != (size_t) number_pixels)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    if (number_pixels == 0)\n      ThrowReaderException(CoderError,\"ImageColumnOrRowSizeIsNotSupported\");\n    if ((viff_info.number_data_bands < 1) || (viff_info.number_data_bands > 4))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((viff_info.data_storage_type != VFF_TYP_BIT) &&\n        (viff_info.data_storage_type != VFF_TYP_1_BYTE) &&\n        (viff_info.data_storage_type != VFF_TYP_2_BYTE) &&\n        (viff_info.data_storage_type != VFF_TYP_4_BYTE) &&\n        (viff_info.data_storage_type != VFF_TYP_FLOAT) &&\n        (viff_info.data_storage_type != VFF_TYP_DOUBLE))\n      ThrowReaderException(CoderError,\"DataStorageTypeIsNotSupported\");\n    if (viff_info.data_encode_scheme != VFF_DES_RAW)\n      ThrowReaderException(CoderError,\"DataEncodingSchemeIsNotSupported\");\n    if ((viff_info.map_storage_type != VFF_MAPTYP_NONE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_1_BYTE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_2_BYTE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_4_BYTE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_FLOAT) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_DOUBLE))\n      ThrowReaderException(CoderError,\"MapStorageTypeIsNotSupported\");\n    if ((viff_info.color_space_model != VFF_CM_NONE) &&\n        (viff_info.color_space_model != VFF_CM_ntscRGB) &&\n        (viff_info.color_space_model != VFF_CM_genericRGB))\n      ThrowReaderException(CoderError,\"ColorspaceModelIsNotSupported\");\n    if (viff_info.location_type != VFF_LOC_IMPLICIT)\n      ThrowReaderException(CoderError,\"LocationTypeIsNotSupported\");\n    if (viff_info.number_of_images != 1)\n      ThrowReaderException(CoderError,\"NumberOfImagesIsNotSupported\");\n    if (viff_info.map_rows == 0)\n      viff_info.map_scheme=VFF_MS_NONE;\n    switch ((int) viff_info.map_scheme)\n    {\n      case VFF_MS_NONE:\n      {\n        if (viff_info.number_data_bands < 3)\n          {\n            /*\n              Create linear color ramp.\n            */\n            if (viff_info.data_storage_type == VFF_TYP_BIT)\n              image->colors=2;\n            else\n              if (viff_info.data_storage_type == VFF_MAPTYP_1_BYTE)\n                image->colors=256UL;\n              else\n                image->colors=image->depth <= 8 ? 256UL : 65536UL;\n            if (AcquireImageColormap(image,image->colors) == MagickFalse)\n              ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          }\n        break;\n      }\n      case VFF_MS_ONEPERBAND:\n      case VFF_MS_SHARED:\n      {\n        unsigned char\n          *viff_colormap;\n\n        /*\n          Allocate VIFF colormap.\n        */\n        switch ((int) viff_info.map_storage_type)\n        {\n          case VFF_MAPTYP_1_BYTE: bytes_per_pixel=1; break;\n          case VFF_MAPTYP_2_BYTE: bytes_per_pixel=2; break;\n          case VFF_MAPTYP_4_BYTE: bytes_per_pixel=4; break;\n          case VFF_MAPTYP_FLOAT: bytes_per_pixel=4; break;\n          case VFF_MAPTYP_DOUBLE: bytes_per_pixel=8; break;\n          default: bytes_per_pixel=1; break;\n        }\n        image->colors=viff_info.map_columns;\n        if (AcquireImageColormap(image,image->colors) == MagickFalse)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        if (viff_info.map_rows >\n            (viff_info.map_rows*bytes_per_pixel*sizeof(*viff_colormap)))\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        viff_colormap=(unsigned char *) AcquireQuantumMemory(image->colors,\n          viff_info.map_rows*bytes_per_pixel*sizeof(*viff_colormap));\n        if (viff_colormap == (unsigned char *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        /*\n          Read VIFF raster colormap.\n        */\n        (void) ReadBlob(image,bytes_per_pixel*image->colors*viff_info.map_rows,\n          viff_colormap);\n        lsb_first=1;\n        if (*(char *) &lsb_first &&\n            ((viff_info.machine_dependency != VFF_DEP_DECORDER) &&\n             (viff_info.machine_dependency != VFF_DEP_NSORDER)))\n          switch ((int) viff_info.map_storage_type)\n          {\n            case VFF_MAPTYP_2_BYTE:\n            {\n              MSBOrderShort(viff_colormap,(bytes_per_pixel*image->colors*\n                viff_info.map_rows));\n              break;\n            }\n            case VFF_MAPTYP_4_BYTE:\n            case VFF_MAPTYP_FLOAT:\n            {\n              MSBOrderLong(viff_colormap,(bytes_per_pixel*image->colors*\n                viff_info.map_rows));\n              break;\n            }\n            default: break;\n          }\n        for (i=0; i < (ssize_t) (viff_info.map_rows*image->colors); i++)\n        {\n          switch ((int) viff_info.map_storage_type)\n          {\n            case VFF_MAPTYP_2_BYTE: value=1.0*((short *) viff_colormap)[i]; break;\n            case VFF_MAPTYP_4_BYTE: value=1.0*((int *) viff_colormap)[i]; break;\n            case VFF_MAPTYP_FLOAT: value=((float *) viff_colormap)[i]; break;\n            case VFF_MAPTYP_DOUBLE: value=((double *) viff_colormap)[i]; break;\n            default: value=1.0*viff_colormap[i]; break;\n          }\n          if (i < (ssize_t) image->colors)\n            {\n              image->colormap[i].red=ScaleCharToQuantum((unsigned char) value);\n              image->colormap[i].green=ScaleCharToQuantum((unsigned char)\n                value);\n              image->colormap[i].blue=ScaleCharToQuantum((unsigned char) value);\n            }\n          else\n            if (i < (ssize_t) (2*image->colors))\n              image->colormap[i % image->colors].green=ScaleCharToQuantum(\n                (unsigned char) value);\n            else\n              if (i < (ssize_t) (3*image->colors))\n                image->colormap[i % image->colors].blue=ScaleCharToQuantum(\n                  (unsigned char) value);\n        }\n        viff_colormap=(unsigned char *) RelinquishMagickMemory(viff_colormap);\n        break;\n      }\n      default:\n        ThrowReaderException(CoderError,\"ColormapTypeNotSupported\");\n    }\n    /*\n      Initialize image structure.\n    */\n    image->matte=viff_info.number_data_bands == 4 ? MagickTrue : MagickFalse;\n    image->storage_class=\n      (viff_info.number_data_bands < 3 ? PseudoClass : DirectClass);\n    image->columns=viff_info.rows;\n    image->rows=viff_info.columns;\n    if ((image_info->ping != MagickFalse) && (image_info->number_scenes != 0))\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    status=SetImageExtent(image,image->columns,image->rows);\n    if (status == MagickFalse)\n      {\n        InheritException(exception,&image->exception);\n        return(DestroyImageList(image));\n      }\n    /*\n      Allocate VIFF pixels.\n    */\n    switch ((int) viff_info.data_storage_type)\n    {\n      case VFF_TYP_2_BYTE: bytes_per_pixel=2; break;\n      case VFF_TYP_4_BYTE: bytes_per_pixel=4; break;\n      case VFF_TYP_FLOAT: bytes_per_pixel=4; break;\n      case VFF_TYP_DOUBLE: bytes_per_pixel=8; break;\n      default: bytes_per_pixel=1; break;\n    }\n    if (viff_info.data_storage_type == VFF_TYP_BIT)\n      max_packets=((image->columns+7UL) >> 3UL)*image->rows;\n    else\n      max_packets=(size_t) (number_pixels*viff_info.number_data_bands);\n    pixels=(unsigned char *) AcquireQuantumMemory(max_packets,\n      bytes_per_pixel*sizeof(*pixels));\n    if (pixels == (unsigned char *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    (void) ReadBlob(image,bytes_per_pixel*max_packets,pixels);\n    lsb_first=1;\n    if (*(char *) &lsb_first &&\n        ((viff_info.machine_dependency != VFF_DEP_DECORDER) &&\n         (viff_info.machine_dependency != VFF_DEP_NSORDER)))\n      switch ((int) viff_info.data_storage_type)\n      {\n        case VFF_TYP_2_BYTE:\n        {\n          MSBOrderShort(pixels,bytes_per_pixel*max_packets);\n          break;\n        }\n        case VFF_TYP_4_BYTE:\n        case VFF_TYP_FLOAT:\n        {\n          MSBOrderLong(pixels,bytes_per_pixel*max_packets);\n          break;\n        }\n        default: break;\n      }\n    min_value=0.0;\n    scale_factor=1.0;\n    if ((viff_info.data_storage_type != VFF_TYP_1_BYTE) &&\n        (viff_info.map_scheme == VFF_MS_NONE))\n      {\n        double\n          max_value;\n\n        /*\n          Determine scale factor.\n        */\n        switch ((int) viff_info.data_storage_type)\n        {\n          case VFF_TYP_2_BYTE: value=1.0*((short *) pixels)[0]; break;\n          case VFF_TYP_4_BYTE: value=1.0*((int *) pixels)[0]; break;\n          case VFF_TYP_FLOAT: value=((float *) pixels)[0]; break;\n          case VFF_TYP_DOUBLE: value=((double *) pixels)[0]; break;\n          default: value=1.0*pixels[0]; break;\n        }\n        max_value=value;\n        min_value=value;\n        for (i=0; i < (ssize_t) max_packets; i++)\n        {\n          switch ((int) viff_info.data_storage_type)\n          {\n            case VFF_TYP_2_BYTE: value=1.0*((short *) pixels)[i]; break;\n            case VFF_TYP_4_BYTE: value=1.0*((int *) pixels)[i]; break;\n            case VFF_TYP_FLOAT: value=((float *) pixels)[i]; break;\n            case VFF_TYP_DOUBLE: value=((double *) pixels)[i]; break;\n            default: value=1.0*pixels[i]; break;\n          }\n          if (value > max_value)\n            max_value=value;\n          else\n            if (value < min_value)\n              min_value=value;\n        }\n        if ((min_value == 0) && (max_value == 0))\n          scale_factor=0;\n        else\n          if (min_value == max_value)\n            {\n              scale_factor=(MagickRealType) QuantumRange/min_value;\n              min_value=0;\n            }\n          else\n            scale_factor=(MagickRealType) QuantumRange/(max_value-min_value);\n      }\n    /*\n      Convert pixels to Quantum size.\n    */\n    p=(unsigned char *) pixels;\n    for (i=0; i < (ssize_t) max_packets; i++)\n    {\n      switch ((int) viff_info.data_storage_type)\n      {\n        case VFF_TYP_2_BYTE: value=1.0*((short *) pixels)[i]; break;\n        case VFF_TYP_4_BYTE: value=1.0*((int *) pixels)[i]; break;\n        case VFF_TYP_FLOAT: value=((float *) pixels)[i]; break;\n        case VFF_TYP_DOUBLE: value=((double *) pixels)[i]; break;\n        default: value=1.0*pixels[i]; break;\n      }\n      if (viff_info.map_scheme == VFF_MS_NONE)\n        {\n          value=(value-min_value)*scale_factor;\n          if (value > QuantumRange)\n            value=QuantumRange;\n          else\n            if (value < 0)\n              value=0;\n        }\n      *p=(unsigned char) ((Quantum) value);\n      p++;\n    }\n    /*\n      Convert VIFF raster image to pixel packets.\n    */\n    p=(unsigned char *) pixels;\n    if (viff_info.data_storage_type == VFF_TYP_BIT)\n      {\n        /*\n          Convert bitmap scanline.\n        */\n        if (image->storage_class != PseudoClass)\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n          if (q == (PixelPacket *) NULL)\n            break;\n          indexes=GetAuthenticIndexQueue(image);\n          for (x=0; x < (ssize_t) (image->columns-7); x+=8)\n          {\n            for (bit=0; bit < 8; bit++)\n            {\n              quantum=(size_t) ((*p) & (0x01 << bit) ? 0 : 1);\n              SetPixelRed(q,quantum == 0 ? 0 : QuantumRange);\n              SetPixelGreen(q,quantum == 0 ? 0 : QuantumRange);\n              SetPixelBlue(q,quantum == 0 ? 0 : QuantumRange);\n              if (image->storage_class == PseudoClass)\n                SetPixelIndex(indexes+x+bit,quantum);\n             }\n            p++;\n          }\n          if ((image->columns % 8) != 0)\n            {\n              for (bit=0; bit < (int) (image->columns % 8); bit++)\n              {\n                quantum=(size_t) ((*p) & (0x01 << bit) ? 0 : 1);\n                SetPixelRed(q,quantum == 0 ? 0 : QuantumRange);\n                SetPixelGreen(q,quantum == 0 ? 0 : QuantumRange);\n                SetPixelBlue(q,quantum == 0 ? 0 : QuantumRange);\n                if (image->storage_class == PseudoClass)\n                  SetPixelIndex(indexes+x+bit,quantum);\n              }\n              p++;\n            }\n          if (SyncAuthenticPixels(image,exception) == MagickFalse)\n            break;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n      }\n    else\n      if (image->storage_class == PseudoClass)\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n          if (q == (PixelPacket *) NULL)\n            break;\n          indexes=GetAuthenticIndexQueue(image);\n          for (x=0; x < (ssize_t) image->columns; x++)\n            SetPixelIndex(indexes+x,*p++);\n          if (SyncAuthenticPixels(image,exception) == MagickFalse)\n            break;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n      else\n        {\n          /*\n            Convert DirectColor scanline.\n          */\n          number_pixels=(MagickSizeType) image->columns*image->rows;\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n            if (q == (PixelPacket *) NULL)\n              break;\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              SetPixelRed(q,ScaleCharToQuantum(*p));\n              SetPixelGreen(q,ScaleCharToQuantum(*(p+number_pixels)));\n              SetPixelBlue(q,ScaleCharToQuantum(*(p+2*number_pixels)));\n              if (image->colors != 0)\n                {\n                  ssize_t\n                    index;\n\n                  index=(ssize_t) GetPixelRed(q);\n                  SetPixelRed(q,image->colormap[(ssize_t)\n                    ConstrainColormapIndex(image,index)].red);\n                  index=(ssize_t) GetPixelGreen(q);\n                  SetPixelGreen(q,image->colormap[(ssize_t)\n                    ConstrainColormapIndex(image,index)].green);\n                  index=(ssize_t) GetPixelRed(q);\n                  SetPixelBlue(q,image->colormap[(ssize_t)\n                    ConstrainColormapIndex(image,index)].blue);\n                }\n              SetPixelOpacity(q,image->matte != MagickFalse ? QuantumRange-\n                ScaleCharToQuantum(*(p+number_pixels*3)) : OpaqueOpacity);\n              p++;\n              q++;\n            }\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n              break;\n            if (image->previous == (Image *) NULL)\n              {\n                status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n                if (status == MagickFalse)\n                  break;\n              }\n          }\n        }\n    pixels=(unsigned char *) RelinquishMagickMemory(pixels);\n    if (image->storage_class == PseudoClass)\n      (void) SyncImage(image);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    /*\n      Proceed to next image.\n    */\n    if (image_info->number_scenes != 0)\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    count=ReadBlob(image,1,&viff_info.identifier);\n    if ((count != 0) && (viff_info.identifier == 0xab))\n      {\n        /*\n          Allocate next image structure.\n        */\n        AcquireNextImage(image_info,image);\n        if (GetNextImageInList(image) == (Image *) NULL)\n          {\n            image=DestroyImageList(image);\n            return((Image *) NULL);\n          }\n        image=SyncNextImageInList(image);\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n        if (status == MagickFalse)\n          break;\n      }\n  } while ((count != 0) && (viff_info.identifier == 0xab));\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "func_src_after": "static Image *ReadVIFFImage(const ImageInfo *image_info,\n  ExceptionInfo *exception)\n{\n#define VFF_CM_genericRGB  15\n#define VFF_CM_ntscRGB  1\n#define VFF_CM_NONE  0\n#define VFF_DEP_DECORDER  0x4\n#define VFF_DEP_NSORDER  0x8\n#define VFF_DES_RAW  0\n#define VFF_LOC_IMPLICIT  1\n#define VFF_MAPTYP_NONE  0\n#define VFF_MAPTYP_1_BYTE  1\n#define VFF_MAPTYP_2_BYTE  2\n#define VFF_MAPTYP_4_BYTE  4\n#define VFF_MAPTYP_FLOAT  5\n#define VFF_MAPTYP_DOUBLE  7\n#define VFF_MS_NONE  0\n#define VFF_MS_ONEPERBAND  1\n#define VFF_MS_SHARED  3\n#define VFF_TYP_BIT  0\n#define VFF_TYP_1_BYTE  1\n#define VFF_TYP_2_BYTE  2\n#define VFF_TYP_4_BYTE  4\n#define VFF_TYP_FLOAT  5\n#define VFF_TYP_DOUBLE  9\n\n  typedef struct _ViffInfo\n  {\n    unsigned char\n      identifier,\n      file_type,\n      release,\n      version,\n      machine_dependency,\n      reserve[3];\n\n    char\n      comment[512];\n\n    unsigned int\n      rows,\n      columns,\n      subrows;\n\n    int\n      x_offset,\n      y_offset;\n\n    float\n      x_bits_per_pixel,\n      y_bits_per_pixel;\n\n    unsigned int\n      location_type,\n      location_dimension,\n      number_of_images,\n      number_data_bands,\n      data_storage_type,\n      data_encode_scheme,\n      map_scheme,\n      map_storage_type,\n      map_rows,\n      map_columns,\n      map_subrows,\n      map_enable,\n      maps_per_cycle,\n      color_space_model;\n  } ViffInfo;\n\n  double\n    min_value,\n    scale_factor,\n    value;\n\n  Image\n    *image;\n\n  int\n    bit;\n\n  MagickBooleanType\n    status;\n\n  MagickSizeType\n    number_pixels;\n\n  register IndexPacket\n    *indexes;\n\n  register ssize_t\n    x;\n\n  register PixelPacket\n    *q;\n\n  register ssize_t\n    i;\n\n  register unsigned char\n    *p;\n\n  size_t\n    bytes_per_pixel,\n    max_packets,\n    quantum;\n\n  ssize_t\n    count,\n    y;\n\n  unsigned char\n    *pixels;\n\n  unsigned long\n    lsb_first;\n\n  ViffInfo\n    viff_info;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  image=AcquireImage(image_info);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read VIFF header (1024 bytes).\n  */\n  count=ReadBlob(image,1,&viff_info.identifier);\n  do\n  {\n    /*\n      Verify VIFF identifier.\n    */\n    if ((count != 1) || ((unsigned char) viff_info.identifier != 0xab))\n      ThrowReaderException(CorruptImageError,\"NotAVIFFImage\");\n    /*\n      Initialize VIFF image.\n    */\n    (void) ReadBlob(image,sizeof(viff_info.file_type),&viff_info.file_type);\n    (void) ReadBlob(image,sizeof(viff_info.release),&viff_info.release);\n    (void) ReadBlob(image,sizeof(viff_info.version),&viff_info.version);\n    (void) ReadBlob(image,sizeof(viff_info.machine_dependency),\n      &viff_info.machine_dependency);\n    (void) ReadBlob(image,sizeof(viff_info.reserve),viff_info.reserve);\n    (void) ReadBlob(image,512,(unsigned char *) viff_info.comment);\n    viff_info.comment[511]='\\0';\n    if (strlen(viff_info.comment) > 4)\n      (void) SetImageProperty(image,\"comment\",viff_info.comment);\n    if ((viff_info.machine_dependency == VFF_DEP_DECORDER) ||\n        (viff_info.machine_dependency == VFF_DEP_NSORDER))\n      image->endian=LSBEndian;\n    else\n      image->endian=MSBEndian;\n    viff_info.rows=ReadBlobLong(image);\n    viff_info.columns=ReadBlobLong(image);\n    viff_info.subrows=ReadBlobLong(image);\n    viff_info.x_offset=(int) ReadBlobLong(image);\n    viff_info.y_offset=(int) ReadBlobLong(image);\n    viff_info.x_bits_per_pixel=(float) ReadBlobLong(image);\n    viff_info.y_bits_per_pixel=(float) ReadBlobLong(image);\n    viff_info.location_type=ReadBlobLong(image);\n    viff_info.location_dimension=ReadBlobLong(image);\n    viff_info.number_of_images=ReadBlobLong(image);\n    viff_info.number_data_bands=ReadBlobLong(image);\n    viff_info.data_storage_type=ReadBlobLong(image);\n    viff_info.data_encode_scheme=ReadBlobLong(image);\n    viff_info.map_scheme=ReadBlobLong(image);\n    viff_info.map_storage_type=ReadBlobLong(image);\n    viff_info.map_rows=ReadBlobLong(image);\n    viff_info.map_columns=ReadBlobLong(image);\n    viff_info.map_subrows=ReadBlobLong(image);\n    viff_info.map_enable=ReadBlobLong(image);\n    viff_info.maps_per_cycle=ReadBlobLong(image);\n    viff_info.color_space_model=ReadBlobLong(image);\n    for (i=0; i < 420; i++)\n      (void) ReadBlobByte(image);\n    if (EOFBlob(image) != MagickFalse)\n      ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n    image->columns=viff_info.rows;\n    image->rows=viff_info.columns;\n    image->depth=viff_info.x_bits_per_pixel <= 8 ? 8UL :\n      MAGICKCORE_QUANTUM_DEPTH;\n    /*\n      Verify that we can read this VIFF image.\n    */\n    number_pixels=(MagickSizeType) viff_info.columns*viff_info.rows;\n    if (number_pixels != (size_t) number_pixels)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    if (number_pixels == 0)\n      ThrowReaderException(CoderError,\"ImageColumnOrRowSizeIsNotSupported\");\n    if ((viff_info.number_data_bands < 1) || (viff_info.number_data_bands > 4))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((viff_info.data_storage_type != VFF_TYP_BIT) &&\n        (viff_info.data_storage_type != VFF_TYP_1_BYTE) &&\n        (viff_info.data_storage_type != VFF_TYP_2_BYTE) &&\n        (viff_info.data_storage_type != VFF_TYP_4_BYTE) &&\n        (viff_info.data_storage_type != VFF_TYP_FLOAT) &&\n        (viff_info.data_storage_type != VFF_TYP_DOUBLE))\n      ThrowReaderException(CoderError,\"DataStorageTypeIsNotSupported\");\n    if (viff_info.data_encode_scheme != VFF_DES_RAW)\n      ThrowReaderException(CoderError,\"DataEncodingSchemeIsNotSupported\");\n    if ((viff_info.map_storage_type != VFF_MAPTYP_NONE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_1_BYTE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_2_BYTE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_4_BYTE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_FLOAT) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_DOUBLE))\n      ThrowReaderException(CoderError,\"MapStorageTypeIsNotSupported\");\n    if ((viff_info.color_space_model != VFF_CM_NONE) &&\n        (viff_info.color_space_model != VFF_CM_ntscRGB) &&\n        (viff_info.color_space_model != VFF_CM_genericRGB))\n      ThrowReaderException(CoderError,\"ColorspaceModelIsNotSupported\");\n    if (viff_info.location_type != VFF_LOC_IMPLICIT)\n      ThrowReaderException(CoderError,\"LocationTypeIsNotSupported\");\n    if (viff_info.number_of_images != 1)\n      ThrowReaderException(CoderError,\"NumberOfImagesIsNotSupported\");\n    if (viff_info.map_rows == 0)\n      viff_info.map_scheme=VFF_MS_NONE;\n    switch ((int) viff_info.map_scheme)\n    {\n      case VFF_MS_NONE:\n      {\n        if (viff_info.number_data_bands < 3)\n          {\n            /*\n              Create linear color ramp.\n            */\n            if (viff_info.data_storage_type == VFF_TYP_BIT)\n              image->colors=2;\n            else\n              if (viff_info.data_storage_type == VFF_MAPTYP_1_BYTE)\n                image->colors=256UL;\n              else\n                image->colors=image->depth <= 8 ? 256UL : 65536UL;\n            if (AcquireImageColormap(image,image->colors) == MagickFalse)\n              ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          }\n        break;\n      }\n      case VFF_MS_ONEPERBAND:\n      case VFF_MS_SHARED:\n      {\n        unsigned char\n          *viff_colormap;\n\n        /*\n          Allocate VIFF colormap.\n        */\n        switch ((int) viff_info.map_storage_type)\n        {\n          case VFF_MAPTYP_1_BYTE: bytes_per_pixel=1; break;\n          case VFF_MAPTYP_2_BYTE: bytes_per_pixel=2; break;\n          case VFF_MAPTYP_4_BYTE: bytes_per_pixel=4; break;\n          case VFF_MAPTYP_FLOAT: bytes_per_pixel=4; break;\n          case VFF_MAPTYP_DOUBLE: bytes_per_pixel=8; break;\n          default: bytes_per_pixel=1; break;\n        }\n        image->colors=viff_info.map_columns;\n        if (AcquireImageColormap(image,image->colors) == MagickFalse)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        if (viff_info.map_rows >\n            (viff_info.map_rows*bytes_per_pixel*sizeof(*viff_colormap)))\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        viff_colormap=(unsigned char *) AcquireQuantumMemory(image->colors,\n          viff_info.map_rows*bytes_per_pixel*sizeof(*viff_colormap));\n        if (viff_colormap == (unsigned char *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        /*\n          Read VIFF raster colormap.\n        */\n        (void) ReadBlob(image,bytes_per_pixel*image->colors*viff_info.map_rows,\n          viff_colormap);\n        lsb_first=1;\n        if (*(char *) &lsb_first &&\n            ((viff_info.machine_dependency != VFF_DEP_DECORDER) &&\n             (viff_info.machine_dependency != VFF_DEP_NSORDER)))\n          switch ((int) viff_info.map_storage_type)\n          {\n            case VFF_MAPTYP_2_BYTE:\n            {\n              MSBOrderShort(viff_colormap,(bytes_per_pixel*image->colors*\n                viff_info.map_rows));\n              break;\n            }\n            case VFF_MAPTYP_4_BYTE:\n            case VFF_MAPTYP_FLOAT:\n            {\n              MSBOrderLong(viff_colormap,(bytes_per_pixel*image->colors*\n                viff_info.map_rows));\n              break;\n            }\n            default: break;\n          }\n        for (i=0; i < (ssize_t) (viff_info.map_rows*image->colors); i++)\n        {\n          switch ((int) viff_info.map_storage_type)\n          {\n            case VFF_MAPTYP_2_BYTE: value=1.0*((short *) viff_colormap)[i]; break;\n            case VFF_MAPTYP_4_BYTE: value=1.0*((int *) viff_colormap)[i]; break;\n            case VFF_MAPTYP_FLOAT: value=((float *) viff_colormap)[i]; break;\n            case VFF_MAPTYP_DOUBLE: value=((double *) viff_colormap)[i]; break;\n            default: value=1.0*viff_colormap[i]; break;\n          }\n          if (i < (ssize_t) image->colors)\n            {\n              image->colormap[i].red=ScaleCharToQuantum((unsigned char) value);\n              image->colormap[i].green=ScaleCharToQuantum((unsigned char)\n                value);\n              image->colormap[i].blue=ScaleCharToQuantum((unsigned char) value);\n            }\n          else\n            if (i < (ssize_t) (2*image->colors))\n              image->colormap[i % image->colors].green=ScaleCharToQuantum(\n                (unsigned char) value);\n            else\n              if (i < (ssize_t) (3*image->colors))\n                image->colormap[i % image->colors].blue=ScaleCharToQuantum(\n                  (unsigned char) value);\n        }\n        viff_colormap=(unsigned char *) RelinquishMagickMemory(viff_colormap);\n        break;\n      }\n      default:\n        ThrowReaderException(CoderError,\"ColormapTypeNotSupported\");\n    }\n    /*\n      Initialize image structure.\n    */\n    image->matte=viff_info.number_data_bands == 4 ? MagickTrue : MagickFalse;\n    image->storage_class=\n      (viff_info.number_data_bands < 3 ? PseudoClass : DirectClass);\n    image->columns=viff_info.rows;\n    image->rows=viff_info.columns;\n    if ((image_info->ping != MagickFalse) && (image_info->number_scenes != 0))\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    status=SetImageExtent(image,image->columns,image->rows);\n    if (status == MagickFalse)\n      {\n        InheritException(exception,&image->exception);\n        return(DestroyImageList(image));\n      }\n    /*\n      Allocate VIFF pixels.\n    */\n    switch ((int) viff_info.data_storage_type)\n    {\n      case VFF_TYP_2_BYTE: bytes_per_pixel=2; break;\n      case VFF_TYP_4_BYTE: bytes_per_pixel=4; break;\n      case VFF_TYP_FLOAT: bytes_per_pixel=4; break;\n      case VFF_TYP_DOUBLE: bytes_per_pixel=8; break;\n      default: bytes_per_pixel=1; break;\n    }\n    if (viff_info.data_storage_type == VFF_TYP_BIT)\n      max_packets=((image->columns+7UL) >> 3UL)*image->rows;\n    else\n      max_packets=(size_t) (number_pixels*viff_info.number_data_bands);\n    pixels=(unsigned char *) AcquireQuantumMemory(MagickMax(number_pixels,\n      max_packets),bytes_per_pixel*sizeof(*pixels));\n    if (pixels == (unsigned char *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    (void) ReadBlob(image,bytes_per_pixel*max_packets,pixels);\n    lsb_first=1;\n    if (*(char *) &lsb_first &&\n        ((viff_info.machine_dependency != VFF_DEP_DECORDER) &&\n         (viff_info.machine_dependency != VFF_DEP_NSORDER)))\n      switch ((int) viff_info.data_storage_type)\n      {\n        case VFF_TYP_2_BYTE:\n        {\n          MSBOrderShort(pixels,bytes_per_pixel*max_packets);\n          break;\n        }\n        case VFF_TYP_4_BYTE:\n        case VFF_TYP_FLOAT:\n        {\n          MSBOrderLong(pixels,bytes_per_pixel*max_packets);\n          break;\n        }\n        default: break;\n      }\n    min_value=0.0;\n    scale_factor=1.0;\n    if ((viff_info.data_storage_type != VFF_TYP_1_BYTE) &&\n        (viff_info.map_scheme == VFF_MS_NONE))\n      {\n        double\n          max_value;\n\n        /*\n          Determine scale factor.\n        */\n        switch ((int) viff_info.data_storage_type)\n        {\n          case VFF_TYP_2_BYTE: value=1.0*((short *) pixels)[0]; break;\n          case VFF_TYP_4_BYTE: value=1.0*((int *) pixels)[0]; break;\n          case VFF_TYP_FLOAT: value=((float *) pixels)[0]; break;\n          case VFF_TYP_DOUBLE: value=((double *) pixels)[0]; break;\n          default: value=1.0*pixels[0]; break;\n        }\n        max_value=value;\n        min_value=value;\n        for (i=0; i < (ssize_t) max_packets; i++)\n        {\n          switch ((int) viff_info.data_storage_type)\n          {\n            case VFF_TYP_2_BYTE: value=1.0*((short *) pixels)[i]; break;\n            case VFF_TYP_4_BYTE: value=1.0*((int *) pixels)[i]; break;\n            case VFF_TYP_FLOAT: value=((float *) pixels)[i]; break;\n            case VFF_TYP_DOUBLE: value=((double *) pixels)[i]; break;\n            default: value=1.0*pixels[i]; break;\n          }\n          if (value > max_value)\n            max_value=value;\n          else\n            if (value < min_value)\n              min_value=value;\n        }\n        if ((min_value == 0) && (max_value == 0))\n          scale_factor=0;\n        else\n          if (min_value == max_value)\n            {\n              scale_factor=(MagickRealType) QuantumRange/min_value;\n              min_value=0;\n            }\n          else\n            scale_factor=(MagickRealType) QuantumRange/(max_value-min_value);\n      }\n    /*\n      Convert pixels to Quantum size.\n    */\n    p=(unsigned char *) pixels;\n    for (i=0; i < (ssize_t) max_packets; i++)\n    {\n      switch ((int) viff_info.data_storage_type)\n      {\n        case VFF_TYP_2_BYTE: value=1.0*((short *) pixels)[i]; break;\n        case VFF_TYP_4_BYTE: value=1.0*((int *) pixels)[i]; break;\n        case VFF_TYP_FLOAT: value=((float *) pixels)[i]; break;\n        case VFF_TYP_DOUBLE: value=((double *) pixels)[i]; break;\n        default: value=1.0*pixels[i]; break;\n      }\n      if (viff_info.map_scheme == VFF_MS_NONE)\n        {\n          value=(value-min_value)*scale_factor;\n          if (value > QuantumRange)\n            value=QuantumRange;\n          else\n            if (value < 0)\n              value=0;\n        }\n      *p=(unsigned char) ((Quantum) value);\n      p++;\n    }\n    /*\n      Convert VIFF raster image to pixel packets.\n    */\n    p=(unsigned char *) pixels;\n    if (viff_info.data_storage_type == VFF_TYP_BIT)\n      {\n        /*\n          Convert bitmap scanline.\n        */\n        if (image->storage_class != PseudoClass)\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n          if (q == (PixelPacket *) NULL)\n            break;\n          indexes=GetAuthenticIndexQueue(image);\n          for (x=0; x < (ssize_t) (image->columns-7); x+=8)\n          {\n            for (bit=0; bit < 8; bit++)\n            {\n              quantum=(size_t) ((*p) & (0x01 << bit) ? 0 : 1);\n              SetPixelRed(q,quantum == 0 ? 0 : QuantumRange);\n              SetPixelGreen(q,quantum == 0 ? 0 : QuantumRange);\n              SetPixelBlue(q,quantum == 0 ? 0 : QuantumRange);\n              if (image->storage_class == PseudoClass)\n                SetPixelIndex(indexes+x+bit,quantum);\n             }\n            p++;\n          }\n          if ((image->columns % 8) != 0)\n            {\n              for (bit=0; bit < (int) (image->columns % 8); bit++)\n              {\n                quantum=(size_t) ((*p) & (0x01 << bit) ? 0 : 1);\n                SetPixelRed(q,quantum == 0 ? 0 : QuantumRange);\n                SetPixelGreen(q,quantum == 0 ? 0 : QuantumRange);\n                SetPixelBlue(q,quantum == 0 ? 0 : QuantumRange);\n                if (image->storage_class == PseudoClass)\n                  SetPixelIndex(indexes+x+bit,quantum);\n              }\n              p++;\n            }\n          if (SyncAuthenticPixels(image,exception) == MagickFalse)\n            break;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n      }\n    else\n      if (image->storage_class == PseudoClass)\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n          if (q == (PixelPacket *) NULL)\n            break;\n          indexes=GetAuthenticIndexQueue(image);\n          for (x=0; x < (ssize_t) image->columns; x++)\n            SetPixelIndex(indexes+x,*p++);\n          if (SyncAuthenticPixels(image,exception) == MagickFalse)\n            break;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n      else\n        {\n          /*\n            Convert DirectColor scanline.\n          */\n          number_pixels=(MagickSizeType) image->columns*image->rows;\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n            if (q == (PixelPacket *) NULL)\n              break;\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              SetPixelRed(q,ScaleCharToQuantum(*p));\n              SetPixelGreen(q,ScaleCharToQuantum(*(p+number_pixels)));\n              SetPixelBlue(q,ScaleCharToQuantum(*(p+2*number_pixels)));\n              if (image->colors != 0)\n                {\n                  ssize_t\n                    index;\n\n                  index=(ssize_t) GetPixelRed(q);\n                  SetPixelRed(q,image->colormap[(ssize_t)\n                    ConstrainColormapIndex(image,index)].red);\n                  index=(ssize_t) GetPixelGreen(q);\n                  SetPixelGreen(q,image->colormap[(ssize_t)\n                    ConstrainColormapIndex(image,index)].green);\n                  index=(ssize_t) GetPixelRed(q);\n                  SetPixelBlue(q,image->colormap[(ssize_t)\n                    ConstrainColormapIndex(image,index)].blue);\n                }\n              SetPixelOpacity(q,image->matte != MagickFalse ? QuantumRange-\n                ScaleCharToQuantum(*(p+number_pixels*3)) : OpaqueOpacity);\n              p++;\n              q++;\n            }\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n              break;\n            if (image->previous == (Image *) NULL)\n              {\n                status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n                if (status == MagickFalse)\n                  break;\n              }\n          }\n        }\n    pixels=(unsigned char *) RelinquishMagickMemory(pixels);\n    if (image->storage_class == PseudoClass)\n      (void) SyncImage(image);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    /*\n      Proceed to next image.\n    */\n    if (image_info->number_scenes != 0)\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    count=ReadBlob(image,1,&viff_info.identifier);\n    if ((count != 0) && (viff_info.identifier == 0xab))\n      {\n        /*\n          Allocate next image structure.\n        */\n        AcquireNextImage(image_info,image);\n        if (GetNextImageInList(image) == (Image *) NULL)\n          {\n            image=DestroyImageList(image);\n            return((Image *) NULL);\n          }\n        image=SyncNextImageInList(image);\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n        if (status == MagickFalse)\n          break;\n      }\n  } while ((count != 0) && (viff_info.identifier == 0xab));\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/ca0c886abd6d3ef335eb74150cd23b89ebd17135", "file_name": "coders/viff.c", "vul_type": "cwe-125", "description": "Write a C function to read a VIFF image file in ImageMagick."}
{"func_name": "gps_tracker", "func_src_before": "void gps_tracker( void )\n{\n\tssize_t unused;\n    int gpsd_sock;\n    char line[256], *temp;\n    struct sockaddr_in gpsd_addr;\n    int ret, is_json, pos;\n    fd_set read_fd;\n    struct timeval timeout;\n\n    /* attempt to connect to localhost, port 2947 */\n\n    pos = 0;\n    gpsd_sock = socket( AF_INET, SOCK_STREAM, 0 );\n\n    if( gpsd_sock < 0 ) {\n        return;\n    }\n\n    gpsd_addr.sin_family      = AF_INET;\n    gpsd_addr.sin_port        = htons( 2947 );\n    gpsd_addr.sin_addr.s_addr = inet_addr( \"127.0.0.1\" );\n\n    if( connect( gpsd_sock, (struct sockaddr *) &gpsd_addr,\n                 sizeof( gpsd_addr ) ) < 0 ) {\n        return;\n    }\n\n    // Check if it's GPSd < 2.92 or the new one\n    // 2.92+ immediately send stuff\n    // < 2.92 requires to send PVTAD command\n    FD_ZERO(&read_fd);\n    FD_SET(gpsd_sock, &read_fd);\n    timeout.tv_sec = 1;\n    timeout.tv_usec = 0;\n    is_json = select(gpsd_sock + 1, &read_fd, NULL, NULL, &timeout);\n    if (is_json) {\n    \t/*\n\t\t\t{\"class\":\"VERSION\",\"release\":\"2.95\",\"rev\":\"2010-11-16T21:12:35\",\"proto_major\":3,\"proto_minor\":3}\n\t\t\t?WATCH={\"json\":true};\n\t\t\t{\"class\":\"DEVICES\",\"devices\":[]}\n    \t */\n\n\n    \t// Get the crap and ignore it: {\"class\":\"VERSION\",\"release\":\"2.95\",\"rev\":\"2010-11-16T21:12:35\",\"proto_major\":3,\"proto_minor\":3}\n    \tif( recv( gpsd_sock, line, sizeof( line ) - 1, 0 ) <= 0 )\n    \t\treturn;\n\n    \tis_json = (line[0] == '{');\n    \tif (is_json) {\n\t\t\t// Send ?WATCH={\"json\":true};\n\t\t\tmemset( line, 0, sizeof( line ) );\n\t\t\tstrcpy(line, \"?WATCH={\\\"json\\\":true};\\n\");\n\t\t\tif( send( gpsd_sock, line, 22, 0 ) != 22 )\n\t\t\t\treturn;\n\n\t\t\t// Check that we have devices\n\t\t\tmemset(line, 0, sizeof(line));\n\t\t\tif( recv( gpsd_sock, line, sizeof( line ) - 1, 0 ) <= 0 )\n\t\t\t\treturn;\n\n\t\t\t// Stop processing if there is no device\n\t\t\tif (strncmp(line, \"{\\\"class\\\":\\\"DEVICES\\\",\\\"devices\\\":[]}\", 32) == 0) {\n\t\t\t\tclose(gpsd_sock);\n\t\t\t\treturn;\n\t\t\t} else {\n\t\t\t\tpos = strlen(line);\n\t\t\t}\n    \t}\n    }\n\n    /* loop reading the GPS coordinates */\n\n    while( G.do_exit == 0 )\n    {\n        usleep( 500000 );\n        memset( G.gps_loc, 0, sizeof( float ) * 5 );\n\n        /* read position, speed, heading, altitude */\n        if (is_json) {\n        \t// Format definition: http://catb.org/gpsd/gpsd_json.html\n\n        \tif (pos == sizeof( line )) {\n        \t\tmemset(line, 0, sizeof(line));\n        \t\tpos = 0;\n        \t}\n\n        \t// New version, JSON\n        \tif( recv( gpsd_sock, line + pos, sizeof( line ) - 1, 0 ) <= 0 )\n        \t\treturn;\n\n        \t// search for TPV class: {\"class\":\"TPV\"\n        \ttemp = strstr(line, \"{\\\"class\\\":\\\"TPV\\\"\");\n        \tif (temp == NULL) {\n        \t\tcontinue;\n        \t}\n\n        \t// Make sure the data we have is complete\n        \tif (strchr(temp, '}') == NULL) {\n        \t\t// Move the data at the beginning of the buffer;\n        \t\tpos = strlen(temp);\n        \t\tif (temp != line) {\n        \t\t\tmemmove(line, temp, pos);\n        \t\t\tmemset(line + pos, 0, sizeof(line) - pos);\n        \t\t}\n        \t}\n\n\t\t\t// Example line: {\"class\":\"TPV\",\"tag\":\"MID2\",\"device\":\"/dev/ttyUSB0\",\"time\":1350957517.000,\"ept\":0.005,\"lat\":46.878936576,\"lon\":-115.832602964,\"alt\":1968.382,\"track\":0.0000,\"speed\":0.000,\"climb\":0.000,\"mode\":3}\n\n        \t// Latitude\n        \ttemp = strstr(temp, \"\\\"lat\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[0]);\n\n\t\t\t// Longitude\n\t\t\ttemp = strstr(temp, \"\\\"lon\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[1]);\n\n\t\t\t// Altitude\n\t\t\ttemp = strstr(temp, \"\\\"alt\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[4]);\n\n\t\t\t// Speed\n\t\t\ttemp = strstr(temp, \"\\\"speed\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[2]);\n\n\t\t\t// No more heading\n\n\t\t\t// Get the next TPV class\n\t\t\ttemp = strstr(temp, \"{\\\"class\\\":\\\"TPV\\\"\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tmemset( line, 0, sizeof( line ) );\n\t\t\t\tpos = 0;\n\t\t\t} else {\n\t\t\t\tpos = strlen(temp);\n\t\t\t\tmemmove(line, temp, pos);\n\t\t\t\tmemset(line + pos, 0, sizeof(line) - pos);\n\t\t\t}\n\n        } else {\n        \tmemset( line, 0, sizeof( line ) );\n\n\t\t\tsnprintf( line,  sizeof( line ) - 1, \"PVTAD\\r\\n\" );\n\t\t\tif( send( gpsd_sock, line, 7, 0 ) != 7 )\n\t\t\t\treturn;\n\n\t\t\tmemset( line, 0, sizeof( line ) );\n\t\t\tif( recv( gpsd_sock, line, sizeof( line ) - 1, 0 ) <= 0 )\n\t\t\t\treturn;\n\n\t\t\tif( memcmp( line, \"GPSD,P=\", 7 ) != 0 )\n\t\t\t\tcontinue;\n\n\t\t\t/* make sure the coordinates are present */\n\n\t\t\tif( line[7] == '?' )\n\t\t\t\tcontinue;\n\n\t\t\tret = sscanf( line + 7, \"%f %f\", &G.gps_loc[0], &G.gps_loc[1] );\n\n\t\t\tif( ( temp = strstr( line, \"V=\" ) ) == NULL ) continue;\n\t\t\tret = sscanf( temp + 2, \"%f\", &G.gps_loc[2] ); /* speed */\n\n\t\t\tif( ( temp = strstr( line, \"T=\" ) ) == NULL ) continue;\n\t\t\tret = sscanf( temp + 2, \"%f\", &G.gps_loc[3] ); /* heading */\n\n\t\t\tif( ( temp = strstr( line, \"A=\" ) ) == NULL ) continue;\n\t\t\tret = sscanf( temp + 2, \"%f\", &G.gps_loc[4] ); /* altitude */\n        }\n\n        if (G.record_data)\n\t\t\tfputs( line, G.f_gps );\n\n\t\tG.save_gps = 1;\n\n        if (G.do_exit == 0)\n\t\t{\n\t\t\tunused = write( G.gc_pipe[1], G.gps_loc, sizeof( float ) * 5 );\n\t\t\tkill( getppid(), SIGUSR2 );\n\t\t}\n    }\n}", "func_src_after": "void gps_tracker( void )\n{\n\tssize_t unused;\n    int gpsd_sock;\n    char line[256], *temp;\n    struct sockaddr_in gpsd_addr;\n    int ret, is_json, pos;\n    fd_set read_fd;\n    struct timeval timeout;\n\n    /* attempt to connect to localhost, port 2947 */\n\n    pos = 0;\n    gpsd_sock = socket( AF_INET, SOCK_STREAM, 0 );\n\n    if( gpsd_sock < 0 ) {\n        return;\n    }\n\n    gpsd_addr.sin_family      = AF_INET;\n    gpsd_addr.sin_port        = htons( 2947 );\n    gpsd_addr.sin_addr.s_addr = inet_addr( \"127.0.0.1\" );\n\n    if( connect( gpsd_sock, (struct sockaddr *) &gpsd_addr,\n                 sizeof( gpsd_addr ) ) < 0 ) {\n        return;\n    }\n\n    // Check if it's GPSd < 2.92 or the new one\n    // 2.92+ immediately send stuff\n    // < 2.92 requires to send PVTAD command\n    FD_ZERO(&read_fd);\n    FD_SET(gpsd_sock, &read_fd);\n    timeout.tv_sec = 1;\n    timeout.tv_usec = 0;\n    is_json = select(gpsd_sock + 1, &read_fd, NULL, NULL, &timeout);\n    if (is_json) {\n    \t/*\n\t\t\t{\"class\":\"VERSION\",\"release\":\"2.95\",\"rev\":\"2010-11-16T21:12:35\",\"proto_major\":3,\"proto_minor\":3}\n\t\t\t?WATCH={\"json\":true};\n\t\t\t{\"class\":\"DEVICES\",\"devices\":[]}\n    \t */\n\n\n    \t// Get the crap and ignore it: {\"class\":\"VERSION\",\"release\":\"2.95\",\"rev\":\"2010-11-16T21:12:35\",\"proto_major\":3,\"proto_minor\":3}\n    \tif( recv( gpsd_sock, line, sizeof( line ) - 1, 0 ) <= 0 )\n    \t\treturn;\n\n    \tis_json = (line[0] == '{');\n    \tif (is_json) {\n\t\t\t// Send ?WATCH={\"json\":true};\n\t\t\tmemset( line, 0, sizeof( line ) );\n\t\t\tstrcpy(line, \"?WATCH={\\\"json\\\":true};\\n\");\n\t\t\tif( send( gpsd_sock, line, 22, 0 ) != 22 )\n\t\t\t\treturn;\n\n\t\t\t// Check that we have devices\n\t\t\tmemset(line, 0, sizeof(line));\n\t\t\tif( recv( gpsd_sock, line, sizeof( line ) - 1, 0 ) <= 0 )\n\t\t\t\treturn;\n\n\t\t\t// Stop processing if there is no device\n\t\t\tif (strncmp(line, \"{\\\"class\\\":\\\"DEVICES\\\",\\\"devices\\\":[]}\", 32) == 0) {\n\t\t\t\tclose(gpsd_sock);\n\t\t\t\treturn;\n\t\t\t} else {\n\t\t\t\tpos = strlen(line);\n\t\t\t}\n    \t}\n    }\n\n    /* loop reading the GPS coordinates */\n\n    while( G.do_exit == 0 )\n    {\n        usleep( 500000 );\n        memset( G.gps_loc, 0, sizeof( float ) * 5 );\n\n        /* read position, speed, heading, altitude */\n        if (is_json) {\n        \t// Format definition: http://catb.org/gpsd/gpsd_json.html\n\n        \tif (pos == sizeof( line )) {\n        \t\tmemset(line, 0, sizeof(line));\n        \t\tpos = 0;\n        \t}\n\n        \t// New version, JSON\n        \tif( recv( gpsd_sock, line + pos, sizeof( line ) - pos - 1, 0 ) <= 0 )\n        \t\treturn;\n\n        \t// search for TPV class: {\"class\":\"TPV\"\n        \ttemp = strstr(line, \"{\\\"class\\\":\\\"TPV\\\"\");\n        \tif (temp == NULL) {\n        \t\tcontinue;\n        \t}\n\n        \t// Make sure the data we have is complete\n        \tif (strchr(temp, '}') == NULL) {\n        \t\t// Move the data at the beginning of the buffer;\n        \t\tpos = strlen(temp);\n        \t\tif (temp != line) {\n        \t\t\tmemmove(line, temp, pos);\n        \t\t\tmemset(line + pos, 0, sizeof(line) - pos);\n        \t\t}\n        \t}\n\n\t\t\t// Example line: {\"class\":\"TPV\",\"tag\":\"MID2\",\"device\":\"/dev/ttyUSB0\",\"time\":1350957517.000,\"ept\":0.005,\"lat\":46.878936576,\"lon\":-115.832602964,\"alt\":1968.382,\"track\":0.0000,\"speed\":0.000,\"climb\":0.000,\"mode\":3}\n\n        \t// Latitude\n        \ttemp = strstr(temp, \"\\\"lat\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[0]);\n\n\t\t\t// Longitude\n\t\t\ttemp = strstr(temp, \"\\\"lon\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[1]);\n\n\t\t\t// Altitude\n\t\t\ttemp = strstr(temp, \"\\\"alt\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[4]);\n\n\t\t\t// Speed\n\t\t\ttemp = strstr(temp, \"\\\"speed\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[2]);\n\n\t\t\t// No more heading\n\n\t\t\t// Get the next TPV class\n\t\t\ttemp = strstr(temp, \"{\\\"class\\\":\\\"TPV\\\"\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tmemset( line, 0, sizeof( line ) );\n\t\t\t\tpos = 0;\n\t\t\t} else {\n\t\t\t\tpos = strlen(temp);\n\t\t\t\tmemmove(line, temp, pos);\n\t\t\t\tmemset(line + pos, 0, sizeof(line) - pos);\n\t\t\t}\n\n        } else {\n        \tmemset( line, 0, sizeof( line ) );\n\n\t\t\tsnprintf( line,  sizeof( line ) - 1, \"PVTAD\\r\\n\" );\n\t\t\tif( send( gpsd_sock, line, 7, 0 ) != 7 )\n\t\t\t\treturn;\n\n\t\t\tmemset( line, 0, sizeof( line ) );\n\t\t\tif( recv( gpsd_sock, line, sizeof( line ) - 1, 0 ) <= 0 )\n\t\t\t\treturn;\n\n\t\t\tif( memcmp( line, \"GPSD,P=\", 7 ) != 0 )\n\t\t\t\tcontinue;\n\n\t\t\t/* make sure the coordinates are present */\n\n\t\t\tif( line[7] == '?' )\n\t\t\t\tcontinue;\n\n\t\t\tret = sscanf( line + 7, \"%f %f\", &G.gps_loc[0], &G.gps_loc[1] );\n\n\t\t\tif( ( temp = strstr( line, \"V=\" ) ) == NULL ) continue;\n\t\t\tret = sscanf( temp + 2, \"%f\", &G.gps_loc[2] ); /* speed */\n\n\t\t\tif( ( temp = strstr( line, \"T=\" ) ) == NULL ) continue;\n\t\t\tret = sscanf( temp + 2, \"%f\", &G.gps_loc[3] ); /* heading */\n\n\t\t\tif( ( temp = strstr( line, \"A=\" ) ) == NULL ) continue;\n\t\t\tret = sscanf( temp + 2, \"%f\", &G.gps_loc[4] ); /* altitude */\n        }\n\n        if (G.record_data)\n\t\t\tfputs( line, G.f_gps );\n\n\t\tG.save_gps = 1;\n\n        if (G.do_exit == 0)\n\t\t{\n\t\t\tunused = write( G.gc_pipe[1], G.gps_loc, sizeof( float ) * 5 );\n\t\t\tkill( getppid(), SIGUSR2 );\n\t\t}\n    }\n}", "commit_link": "github.com/aircrack-ng/aircrack-ng/commit/ff70494dd389ba570dbdbf36f217c28d4381c6b5/", "file_name": "src/airodump-ng.c", "vul_type": "cwe-787", "description": "Write a C function named `gps_tracker` that connects to a GPS daemon on localhost and reads GPS coordinates in a loop."}
{"func_name": "disk_seqf_stop", "func_src_before": "static void disk_seqf_stop(struct seq_file *seqf, void *v)\n{\n\tstruct class_dev_iter *iter = seqf->private;\n\n\t/* stop is called even after start failed :-( */\n\tif (iter) {\n\t\tclass_dev_iter_exit(iter);\n\t\tkfree(iter);\n\t}\n}", "func_src_after": "static void disk_seqf_stop(struct seq_file *seqf, void *v)\n{\n\tstruct class_dev_iter *iter = seqf->private;\n\n\t/* stop is called even after start failed :-( */\n\tif (iter) {\n\t\tclass_dev_iter_exit(iter);\n\t\tkfree(iter);\n\t\tseqf->private = NULL;\n\t}\n}", "commit_link": "github.com/torvalds/linux/commit/77da160530dd1dc94f6ae15a981f24e5f0021e84", "file_name": "block/genhd.c", "vul_type": "cwe-416", "description": "Write a C function named `disk_seqf_stop` that cleans up an iterator for a sequence file, ensuring memory is freed and the iterator is reset if necessary."}
{"func_name": "fiber_switch", "func_src_before": "fiber_switch(mrb_state *mrb, mrb_value self, mrb_int len, const mrb_value *a, mrb_bool resume, mrb_bool vmexec)\n{\n  struct mrb_context *c = fiber_check(mrb, self);\n  struct mrb_context *old_c = mrb->c;\n  mrb_value value;\n\n  fiber_check_cfunc(mrb, c);\n  if (resume && c->status == MRB_FIBER_TRANSFERRED) {\n    mrb_raise(mrb, E_FIBER_ERROR, \"resuming transferred fiber\");\n  }\n  if (c->status == MRB_FIBER_RUNNING || c->status == MRB_FIBER_RESUMED) {\n    mrb_raise(mrb, E_FIBER_ERROR, \"double resume (fib)\");\n  }\n  if (c->status == MRB_FIBER_TERMINATED) {\n    mrb_raise(mrb, E_FIBER_ERROR, \"resuming dead fiber\");\n  }\n  mrb->c->status = resume ? MRB_FIBER_RESUMED : MRB_FIBER_TRANSFERRED;\n  c->prev = resume ? mrb->c : (c->prev ? c->prev : mrb->root_c);\n  if (c->status == MRB_FIBER_CREATED) {\n    mrb_value *b, *e;\n\n    if (len >= c->stend - c->stack) {\n      mrb_raise(mrb, E_FIBER_ERROR, \"too many arguments to fiber\");\n    }\n    b = c->stack+1;\n    e = b + len;\n    while (b<e) {\n      *b++ = *a++;\n    }\n    c->cibase->argc = (int)len;\n    value = c->stack[0] = MRB_PROC_ENV(c->ci->proc)->stack[0];\n  }\n  else {\n    value = fiber_result(mrb, a, len);\n  }\n  fiber_switch_context(mrb, c);\n\n  if (vmexec) {\n    c->vmexec = TRUE;\n    value = mrb_vm_exec(mrb, c->ci[-1].proc, c->ci->pc);\n    mrb->c = old_c;\n  }\n  else {\n    MARK_CONTEXT_MODIFY(c);\n  }\n  return value;\n}", "func_src_after": "fiber_switch(mrb_state *mrb, mrb_value self, mrb_int len, const mrb_value *a, mrb_bool resume, mrb_bool vmexec)\n{\n  struct mrb_context *c = fiber_check(mrb, self);\n  struct mrb_context *old_c = mrb->c;\n  enum mrb_fiber_state status;\n  mrb_value value;\n\n  fiber_check_cfunc(mrb, c);\n  status = c->status;\n  if (resume && status == MRB_FIBER_TRANSFERRED) {\n    mrb_raise(mrb, E_FIBER_ERROR, \"resuming transferred fiber\");\n  }\n  if (status == MRB_FIBER_RUNNING || status == MRB_FIBER_RESUMED) {\n    mrb_raise(mrb, E_FIBER_ERROR, \"double resume (fib)\");\n  }\n  if (status == MRB_FIBER_TERMINATED) {\n    mrb_raise(mrb, E_FIBER_ERROR, \"resuming dead fiber\");\n  }\n  old_c->status = resume ? MRB_FIBER_RESUMED : MRB_FIBER_TRANSFERRED;\n  c->prev = resume ? mrb->c : (c->prev ? c->prev : mrb->root_c);\n  fiber_switch_context(mrb, c);\n  if (status == MRB_FIBER_CREATED) {\n    mrb_value *b, *e;\n\n    mrb_stack_extend(mrb, len+2); /* for receiver and (optional) block */\n    b = c->stack+1;\n    e = b + len;\n    while (b<e) {\n      *b++ = *a++;\n    }\n    c->cibase->argc = (int)len;\n    value = c->stack[0] = MRB_PROC_ENV(c->ci->proc)->stack[0];\n  }\n  else {\n    value = fiber_result(mrb, a, len);\n  }\n\n  if (vmexec) {\n    c->vmexec = TRUE;\n    value = mrb_vm_exec(mrb, c->ci[-1].proc, c->ci->pc);\n    mrb->c = old_c;\n  }\n  else {\n    MARK_CONTEXT_MODIFY(c);\n  }\n  return value;\n}", "commit_link": "github.com/mruby/mruby/commit/778500563a9f7ceba996937dc886bd8cde29b42b", "file_name": "mrbgems/mruby-fiber/src/fiber.c", "vul_type": "cwe-125", "description": "Write a C function `fiber_switch` for the MRuby language that handles fiber resumption, argument passing, and optional VM execution."}
{"func_name": "(anonymous)", "func_src_before": "            // 2\u3001\u7b54\u6848\u3002\n            const answers = map(item.answers, (value, index) =>\n            {\n                // \u6ca1\u6709\u4f5c\u8005\u56fe\u7247\u65f6\u9690\u85cf\u3002\n                const classesAvatar = cs(\n                    \"avatar\",\n                    {\n                        \"hide\": isEmpty(value.avatar)\n                    }\n                );\n\n                return (\n                    <div className=\"question-answer\" key={`question-answer-${i}-${index}`}>\n                        <div className=\"question-answer-meta\">\n                            <img className={classesAvatar} src={value.avatar} />\n                            <span className=\"author\">{value.name}</span>\n                            <span className=\"bio\">{value.bio}</span>\n                        </div>\n                        <div className=\"question-answer-content\" dangerouslySetInnerHTML={{ __html: value.content }} />\n                    </div>\n                );\n            });\n            innerRows.push(...answers);\n\n            // 3\u3001\u5916\u94fe\u3002\n            if (item.link)\n            {\n                innerRows.push(\n                    <div className=\"view-more\" key={`view-more-${i}`}>\n                        <a href={item.link.href} target=\"_blank\"><b>{item.link.text}</b></a>\n                    </div>\n                );\n            }\n\n            questions.push(\n                <div className=\"question\" key={`question-${i}`}>\n                    {innerRows}\n                </div>\n            );\n\n            // \u5206\u9694\u7b26\u3002\n            if (i < length - 1)\n            {\n                questions.push(<hr className=\"question-separator\" key={`question-separator-${i}`} />);\n            }\n        }\n\n        return (", "func_src_after": "            // 2\u3001\u7b54\u6848\u3002\n            const answers = map(item.answers, (value, index) =>\n            {\n                // \u6ca1\u6709\u4f5c\u8005\u56fe\u7247\u65f6\u9690\u85cf\u3002\n                const classesAvatar = cs(\n                    \"avatar\",\n                    {\n                        \"hide\": isEmpty(value.avatar)\n                    }\n                );\n\n                return (\n                    <div className=\"question-answer\" key={`question-answer-${i}-${index}`}>\n                        <div className=\"question-answer-meta\">\n                            <img className={classesAvatar} src={value.avatar} />\n                            <span className=\"author\">{value.name}</span>\n                            <span className=\"bio\">{value.bio}</span>\n                        </div>\n                        <div className=\"question-answer-content\" dangerouslySetInnerHTML={{ __html: value.content }} />\n                    </div>\n                );\n            });\n            innerRows.push(...answers);\n\n            // 3\u3001\u5916\u94fe\u3002\n            if (item.link)\n            {\n                innerRows.push(\n                    <div className=\"view-more\" key={`view-more-${i}`}>\n                        <a href={item.link.href} target=\"_blank\" rel=\"noopener noreferrer\"><b>{item.link.text}</b></a>\n                    </div>\n                );\n            }\n\n            questions.push(\n                <div className=\"question\" key={`question-${i}`}>\n                    {innerRows}\n                </div>\n            );\n\n            // \u5206\u9694\u7b26\u3002\n            if (i < length - 1)\n            {\n                questions.push(<hr className=\"question-separator\" key={`question-separator-${i}`} />);\n            }\n        }\n\n        return (", "line_changes": {"deleted": [{"line_no": 30, "char_start": 1141, "char_end": 1234, "line": "                        <a href={item.link.href} target=\"_blank\"><b>{item.link.text}</b></a>\n"}], "added": [{"line_no": 30, "char_start": 1141, "char_end": 1260, "line": "                        <a href={item.link.href} target=\"_blank\" rel=\"noopener noreferrer\"><b>{item.link.text}</b></a>\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 1205, "char_end": 1231, "chars": " rel=\"noopener noreferrer\""}]}, "commit_link": "github.com/nonoroazoro/Zhihu-Daily-Reader/commit/e5e310be94fd9adfaa058c7abe3ab2515b16f128", "file_name": "ArticleView.jsx", "vul_type": "cwe-200", "commit_msg": "add rel=\"noopener noreferrer\"", "parent_commit": "07440697d044dc674dc8e55da0d1e1ebac8053df", "description": "In JavaScript, write a React component that displays a list of questions with their answers and optional external links, hiding the author's avatar if not provided."}
{"func_name": "(anonymous)", "func_src_before": "\thserver = require('http').createServer(function(req,res){\n\t\tconsole.log('Serving: %s',req.url);\n\t\tvar rs = fs.createReadStream(__dirname+req.url,{\n\t\t\tflags: 'r',\n\t\t\tautoClose: true\n\t\t});\n\t\trs.on('open',function(){\n\t\t\trs.pipe(res);\n\t\t});\n\t\trs.on('error',function(e){\n\t\t\tres.end(e+'');\n\t\t});\n\t}),", "func_src_after": "\thserver = require('http').createServer(function(req,res){\n\t\tconsole.log('Serving: %s',req.url);\n\t\tvar rs = fs.createReadStream(__dirname+path.normalize(req.url).replace(/^(\\.\\.[\\/\\\\])+/, ''),{\n\t\t\tflags: 'r',\n\t\t\tautoClose: true\n\t\t});\n\t\trs.on('open',function(){\n\t\t\trs.pipe(res);\n\t\t});\n\t\trs.on('error',function(e){\n\t\t\tres.end(e+'');\n\t\t});\n\t}),", "line_changes": {"deleted": [{"line_no": 3, "char_start": 97, "char_end": 148, "line": "\t\tvar rs = fs.createReadStream(__dirname+req.url,{\n"}], "added": [{"line_no": 3, "char_start": 97, "char_end": 194, "line": "\t\tvar rs = fs.createReadStream(__dirname+path.normalize(req.url).replace(/^(\\.\\.[\\/\\\\])+/, ''),{\n"}]}, "char_changes": {"deleted": [{"char_start": 138, "char_end": 145, "chars": "req.url"}], "added": [{"char_start": 138, "char_end": 191, "chars": "path.normalize(req.url).replace(/^(\\.\\.[\\/\\\\])+/, '')"}]}, "commit_link": "github.com/Eeems/PooledWebSocket/commit/7b3b4e5c6be6d8a964296fa3c50e38dc07e9701d", "file_name": "server.js", "vul_type": "cwe-022", "commit_msg": "Update server.js\n\nResolve directory traversal attack", "description": "Write a Node.js script to create a simple HTTP server that streams requested files to the client, handling both normal and sanitized file paths."}
{"func_name": "HPHP::WddxPacket::recursiveAddVar", "func_src_before": "bool WddxPacket::recursiveAddVar(const String& varName,\n                                 const Variant& varVariant,\n                                 bool hasVarTag) {\n\n  bool isArray = varVariant.isArray();\n  bool isObject = varVariant.isObject();\n\n  if (isArray || isObject) {\n    if (hasVarTag) {\n      m_packetString += \"<var name='\";\n      m_packetString += varName.data();\n      m_packetString += \"'>\";\n    }\n\n    Array varAsArray;\n    Object varAsObject = varVariant.toObject();\n    if (isArray) varAsArray = varVariant.toArray();\n    if (isObject) varAsArray = varAsObject.toArray();\n\n    int length = varAsArray.length();\n    if (length > 0) {\n      ArrayIter it = ArrayIter(varAsArray);\n      if (it.first().isString()) isObject = true;\n      if (isObject) {\n        m_packetString += \"<struct>\";\n        if (!isArray) {\n          m_packetString += \"<var name='php_class_name'><string>\";\n          m_packetString += varAsObject->o_getClassName().c_str();\n          m_packetString += \"</string></var>\";\n        }\n      } else {\n        m_packetString += \"<array length='\";\n        m_packetString += std::to_string(length);\n        m_packetString += \"'>\";\n      }\n      for (ArrayIter it(varAsArray); it; ++it) {\n        Variant key = it.first();\n        Variant value = it.second();\n        recursiveAddVar(key.toString(), value, isObject);\n      }\n      if (isObject) {\n        m_packetString += \"</struct>\";\n      }\n      else {\n        m_packetString += \"</array>\";\n      }\n    }\n    else {\n      //empty object\n      if (isObject) {\n        m_packetString += \"<struct>\";\n        if (!isArray) {\n          m_packetString += \"<var name='php_class_name'><string>\";\n          m_packetString += varAsObject->o_getClassName().c_str();\n          m_packetString += \"</string></var>\";\n        }\n        m_packetString += \"</struct>\";\n      }\n    }\n    if (hasVarTag) {\n      m_packetString += \"</var>\";\n    }\n    return true;\n  }\n\n  std::string varType = getDataTypeString(varVariant.getType()).data();\n  if (!getWddxEncoded(varType, \"\", varName, false).empty()) {\n    std::string varValue = varVariant.toString().data();\n    if (varType.compare(\"boolean\") == 0) {\n      varValue = varVariant.toBoolean() ? \"true\" : \"false\";\n    }\n    m_packetString += getWddxEncoded(varType, varValue, varName, hasVarTag);\n    return true;\n  }\n\n  return false;\n}", "func_src_after": "bool WddxPacket::recursiveAddVar(const String& varName,\n                                 const Variant& varVariant,\n                                 bool hasVarTag) {\n\n  bool isArray = varVariant.isArray();\n  bool isObject = varVariant.isObject();\n\n  if (isArray || isObject) {\n    if (hasVarTag) {\n      m_packetString += \"<var name='\";\n      m_packetString += varName.data();\n      m_packetString += \"'>\";\n    }\n\n    Array varAsArray;\n    Object varAsObject = varVariant.toObject();\n    if (isArray) varAsArray = varVariant.toArray();\n    if (isObject) varAsArray = varAsObject.toArray();\n\n    int length = varAsArray.length();\n    if (length > 0) {\n      ArrayIter it = ArrayIter(varAsArray);\n      if (it.first().isString()) isObject = true;\n      if (isObject) {\n        m_packetString += \"<struct>\";\n        if (!isArray) {\n          m_packetString += \"<var name='php_class_name'><string>\";\n          m_packetString += varAsObject->o_getClassName().c_str();\n          m_packetString += \"</string></var>\";\n        }\n      } else {\n        m_packetString += \"<array length='\";\n        m_packetString += std::to_string(length);\n        m_packetString += \"'>\";\n      }\n      for (ArrayIter it(varAsArray); it; ++it) {\n        Variant key = it.first();\n        Variant value = it.second();\n        recursiveAddVar(key.toString(), value, isObject);\n      }\n      if (isObject) {\n        m_packetString += \"</struct>\";\n      }\n      else {\n        m_packetString += \"</array>\";\n      }\n    }\n    else {\n      //empty object\n      if (isObject) {\n        m_packetString += \"<struct>\";\n        if (!isArray) {\n          m_packetString += \"<var name='php_class_name'><string>\";\n          m_packetString += varAsObject->o_getClassName().c_str();\n          m_packetString += \"</string></var>\";\n        }\n        m_packetString += \"</struct>\";\n      }\n    }\n    if (hasVarTag) {\n      m_packetString += \"</var>\";\n    }\n    return true;\n  }\n\n  std::string varType = getDataTypeString(varVariant.getType()).data();\n  if (!getWddxEncoded(varType, \"\", varName, false).empty()) {\n    std::string varValue;\n    if (varType.compare(\"boolean\") == 0) {\n      varValue = varVariant.toBoolean() ? \"true\" : \"false\";\n    } else {\n      varValue = StringUtil::HtmlEncode(varVariant.toString(),\n                                        StringUtil::QuoteStyle::Double,\n                                        \"UTF-8\", false, false).toCppString();\n    }\n    m_packetString += getWddxEncoded(varType, varValue, varName, hasVarTag);\n    return true;\n  }\n\n  return false;\n}", "commit_link": "github.com/facebook/hhvm/commit/324701c9fd31beb4f070f1b7ef78b115fbdfec34", "file_name": "hphp/runtime/ext/wddx/ext_wddx.cpp", "vul_type": "cwe-079", "description": "Write a C++ function named `recursiveAddVar` that serializes a variable into a WDDX (Web Distributed Data Exchange) packet string, handling arrays, objects, and primitive data types, and optionally wrapping the serialized data in a `<var>` tag."}
{"func_name": "podbeuter::pb_controller::play_file", "func_src_before": "void pb_controller::play_file(const std::string& file) {\n\tstd::string cmdline;\n\tstd::string player = cfg->get_configvalue(\"player\");\n\tif (player == \"\")\n\t\treturn;\n\tcmdline.append(player);\n\tcmdline.append(\" \\\"\");\n\tcmdline.append(utils::replace_all(file,\"\\\"\", \"\\\\\\\"\"));\n\tcmdline.append(\"\\\"\");\n\tstfl::reset();\n\tutils::run_interactively(cmdline, \"pb_controller::play_file\");\n}", "func_src_after": "void pb_controller::play_file(const std::string& file) {\n\tstd::string cmdline;\n\tstd::string player = cfg->get_configvalue(\"player\");\n\tif (player == \"\")\n\t\treturn;\n\tcmdline.append(player);\n\tcmdline.append(\" '\");\n\tcmdline.append(utils::replace_all(file,\"'\", \"%27\"));\n\tcmdline.append(\"'\");\n\tstfl::reset();\n\tutils::run_interactively(cmdline, \"pb_controller::play_file\");\n}", "commit_link": "github.com/akrennmair/newsbeuter/commit/c8fea2f60c18ed30bdd1bb6f798e994e51a58260", "file_name": "src/pb_controller.cpp", "vul_type": "cwe-078", "description": "Write a C++ function named `play_file` in a class `pb_controller` that executes a media player command using a file path, handling quotes in the file path."}
{"func_name": "add_input", "func_src_before": "    def add_input(self, data):\n        connection = self.connect()\n        try:\n            # The following introduces a deliberate security flaw - SQL Injection\n            query = \"INSERT INTO crimes (description) VALUES ('{}');\".format(data)\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                connection.commit()\n        finally:\n            connection.close()", "func_src_after": "    def add_input(self, data):\n        connection = self.connect()\n        try:\n            # The following introduces a deliberate security flaw - SQL Injection\n            query = \"INSERT INTO crimes (description) VALUES (%s);\"\n            with connection.cursor() as cursor:\n                cursor.execute(query, data)\n                connection.commit()\n        finally:\n            connection.close()", "commit_link": "github.com/rwolf527/crimemap/commit/50b0695e0b4c46165e6146f6fac4cd6871d9fdf6", "file_name": "dbhelper.py", "vul_type": "cwe-089", "description": "Write a Python function that adds user input to a database with a deliberate SQL injection vulnerability."}
{"func_name": "edit_bundle", "func_src_before": "@check_document_access_permission()\ndef edit_bundle(request):\n  bundle_id = request.GET.get('bundle')\n  doc = None\n  \n  if bundle_id:\n    doc = Document2.objects.get(id=bundle_id)\n    bundle = Bundle(document=doc)\n  else:\n    bundle = Bundle()\n\n  coordinators = [dict([('uuid', d.content_object.uuid), ('name', d.content_object.name)])\n                      for d in Document.objects.get_docs(request.user, Document2, extra='coordinator2')]\n\n  return render('editor/bundle_editor.mako', request, {\n      'bundle_json': bundle.json,\n      'coordinators_json': json.dumps(coordinators),\n      'doc1_id': doc.doc.get().id if doc else -1,\n      'can_edit_json': json.dumps(doc is None or doc.doc.get().is_editable(request.user))      \n  })", "func_src_after": "@check_document_access_permission()\ndef edit_bundle(request):\n  bundle_id = request.GET.get('bundle')\n  doc = None\n  \n  if bundle_id:\n    doc = Document2.objects.get(id=bundle_id)\n    bundle = Bundle(document=doc)\n  else:\n    bundle = Bundle()\n\n  coordinators = [dict([('uuid', d.content_object.uuid), ('name', d.content_object.name)])\n                      for d in Document.objects.get_docs(request.user, Document2, extra='coordinator2')]\n\n  return render('editor/bundle_editor.mako', request, {\n      'bundle_json': bundle.json_for_html(),\n      'coordinators_json': json.dumps(coordinators, cls=JSONEncoderForHTML),\n      'doc1_id': doc.doc.get().id if doc else -1,\n      'can_edit_json': json.dumps(doc is None or doc.doc.get().is_editable(request.user))      \n  })", "commit_link": "github.com/gethue/hue/commit/6641c62beaa1468082e47d82da5ed758d11c7735", "file_name": "apps/oozie/src/oozie/views/editor2.py", "vul_type": "cwe-079", "description": "Write a Python function with a decorator to check user permissions and handle editing a document bundle, including fetching coordinators and rendering a template."}
{"func_name": "fpm_log_write", "func_src_before": "int fpm_log_write(char *log_format) /* {{{ */\n{\n\tchar *s, *b;\n\tchar buffer[FPM_LOG_BUFFER+1];\n\tint token, test;\n\tsize_t len, len2;\n\tstruct fpm_scoreboard_proc_s proc, *proc_p;\n\tstruct fpm_scoreboard_s *scoreboard;\n\tchar tmp[129];\n\tchar format[129];\n\ttime_t now_epoch;\n#ifdef HAVE_TIMES\n\tclock_t tms_total;\n#endif\n\n\tif (!log_format && (!fpm_log_format || fpm_log_fd == -1)) {\n\t\treturn -1;\n\t}\n\n\tif (!log_format) {\n\t\tlog_format = fpm_log_format;\n\t\ttest = 0;\n\t} else {\n\t\ttest = 1;\n\t}\n\n\tnow_epoch = time(NULL);\n\n\tif (!test) {\n\t\tscoreboard = fpm_scoreboard_get();\n\t\tif (!scoreboard) {\n\t\t\tzlog(ZLOG_WARNING, \"unable to get scoreboard while preparing the access log\");\n\t\t\treturn -1;\n\t\t}\n\t\tproc_p = fpm_scoreboard_proc_acquire(NULL, -1, 0);\n\t\tif (!proc_p) {\n\t\t\tzlog(ZLOG_WARNING, \"[pool %s] Unable to acquire shm slot while preparing the access log\", scoreboard->pool);\n\t\t\treturn -1;\n\t\t}\n\t\tproc = *proc_p;\n\t\tfpm_scoreboard_proc_release(proc_p);\n\t}\n\n\ttoken = 0;\n\n\tmemset(buffer, '\\0', sizeof(buffer));\n\tb = buffer;\n\tlen = 0;\n\n\n\ts = log_format;\n\n\twhile (*s != '\\0') {\n\t\t/* Test is we have place for 1 more char. */\n\t\tif (len >= FPM_LOG_BUFFER) {\n\t\t\tzlog(ZLOG_NOTICE, \"the log buffer is full (%d). The access log request has been truncated.\", FPM_LOG_BUFFER);\n\t\t\tlen = FPM_LOG_BUFFER;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (!token && *s == '%') {\n\t\t\ttoken = 1;\n\t\t\tmemset(format, '\\0', sizeof(format)); /* reset format */\n\t\t\ts++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (token) {\n\t\t\ttoken = 0;\n\t\t\tlen2 = 0;\n\t\t\tswitch (*s) {\n\n\t\t\t\tcase '%': /* '%' */\n\t\t\t\t\t*b = '%';\n\t\t\t\t\tlen2 = 1;\n\t\t\t\t\tbreak;\n\n#ifdef HAVE_TIMES\n\t\t\t\tcase 'C': /* %CPU */\n\t\t\t\t\tif (format[0] == '\\0' || !strcasecmp(format, \"total\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\ttms_total = proc.last_request_cpu.tms_utime + proc.last_request_cpu.tms_stime + proc.last_request_cpu.tms_cutime + proc.last_request_cpu.tms_cstime;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else if (!strcasecmp(format, \"user\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\ttms_total = proc.last_request_cpu.tms_utime + proc.last_request_cpu.tms_cutime;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else if (!strcasecmp(format, \"system\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\ttms_total = proc.last_request_cpu.tms_stime + proc.last_request_cpu.tms_cstime;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"only 'total', 'user' or 'system' are allowed as a modifier for %%%c ('%s')\", *s, format);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%.2f\", tms_total / fpm_scoreboard_get_tick() / (proc.cpu_duration.tv_sec + proc.cpu_duration.tv_usec / 1000000.) * 100.);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n#endif\n\n\t\t\t\tcase 'd': /* duration \u00b5s */\n\t\t\t\t\t/* seconds */\n\t\t\t\t\tif (format[0] == '\\0' || !strcasecmp(format, \"seconds\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%.3f\", proc.duration.tv_sec + proc.duration.tv_usec / 1000000.);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* miliseconds */\n\t\t\t\t\t} else if (!strcasecmp(format, \"miliseconds\") || !strcasecmp(format, \"mili\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%.3f\", proc.duration.tv_sec * 1000. + proc.duration.tv_usec / 1000.);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* microseconds */\n\t\t\t\t\t} else if (!strcasecmp(format, \"microseconds\") || !strcasecmp(format, \"micro\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%lu\", proc.duration.tv_sec * 1000000UL + proc.duration.tv_usec);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t} else {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"only 'seconds', 'mili', 'miliseconds', 'micro' or 'microseconds' are allowed as a modifier for %%%c ('%s')\", *s, format);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'e': /* fastcgi env  */\n\t\t\t\t\tif (format[0] == '\\0') {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"the name of the environment variable must be set between embraces for %%%c\", *s);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tchar *env = fcgi_getenv((fcgi_request*) SG(server_context), format, strlen(format));\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", env ? env : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'f': /* script */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\",  *proc.script_filename ? proc.script_filename : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'l': /* content length */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%zu\", proc.content_length);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'm': /* method */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", *proc.request_method ? proc.request_method : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'M': /* memory */\n\t\t\t\t\t/* seconds */\n\t\t\t\t\tif (format[0] == '\\0' || !strcasecmp(format, \"bytes\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%zu\", proc.memory);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* kilobytes */\n\t\t\t\t\t} else if (!strcasecmp(format, \"kilobytes\") || !strcasecmp(format, \"kilo\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%lu\", proc.memory / 1024);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* megabytes */\n\t\t\t\t\t} else if (!strcasecmp(format, \"megabytes\") || !strcasecmp(format, \"mega\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%lu\", proc.memory / 1024 / 1024);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t} else {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"only 'bytes', 'kilo', 'kilobytes', 'mega' or 'megabytes' are allowed as a modifier for %%%c ('%s')\", *s, format);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'n': /* pool name */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", scoreboard->pool[0] ? scoreboard->pool : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'o': /* header output  */\n\t\t\t\t\tif (format[0] == '\\0') {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"the name of the header must be set between embraces for %%%c\", *s);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tsapi_header_struct *h;\n\t\t\t\t\t\tzend_llist_position pos;\n\t\t\t\t\t\tsapi_headers_struct *sapi_headers = &SG(sapi_headers);\n\t\t\t\t\t\tsize_t format_len = strlen(format);\n\n\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_first_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\twhile (h) {\n\t\t\t\t\t\t\tchar *header;\n\t\t\t\t\t\t\tif (!h->header_len) {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif (!strstr(h->header, format)) {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t/* test if enought char after the header name + ': ' */\n\t\t\t\t\t\t\tif (h->header_len <= format_len + 2) {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif (h->header[format_len] != ':' || h->header[format_len + 1] != ' ') {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\theader = h->header + format_len + 2;\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", header && *header ? header : \"-\");\n\n\t\t\t\t\t\t\t/* found, done */\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (!len2) {\n\t\t\t\t\t\t\tlen2 = 1;\n\t\t\t\t\t\t\t*b = '-';\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'p': /* PID */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%ld\", (long)getpid());\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'P': /* PID */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%ld\", (long)getppid());\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'q': /* query_string */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", proc.query_string);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'Q': /* '?' */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", *proc.query_string  ? \"?\" : \"\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'r': /* request URI */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", proc.request_uri);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'R': /* remote IP address */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tconst char *tmp = fcgi_get_last_client_ip();\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", tmp ? tmp : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 's': /* status */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%d\", SG(sapi_headers).http_response_code);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'T':\n\t\t\t\tcase 't': /* time */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\ttime_t *t;\n\t\t\t\t\t\tif (*s == 't') {\n\t\t\t\t\t\t\tt = &proc.accepted_epoch;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tt = &now_epoch;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (format[0] == '\\0') {\n\t\t\t\t\t\t\tstrftime(tmp, sizeof(tmp) - 1, \"%d/%b/%Y:%H:%M:%S %z\", localtime(t));\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tstrftime(tmp, sizeof(tmp) - 1, format, localtime(t));\n\t\t\t\t\t\t}\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", tmp);\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'u': /* remote user */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", proc.auth_user);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase '{': /* complex var */\n\t\t\t\t\ttoken = 1;\n\t\t\t\t\t{\n\t\t\t\t\t\tchar *start;\n\t\t\t\t\t\tsize_t l;\n\n\t\t\t\t\t\tstart = ++s;\n\n\t\t\t\t\t\twhile (*s != '\\0') {\n\t\t\t\t\t\t\tif (*s == '}') {\n\t\t\t\t\t\t\t\tl = s - start;\n\n\t\t\t\t\t\t\t\tif (l >= sizeof(format) - 1) {\n\t\t\t\t\t\t\t\t\tl = sizeof(format) - 1;\n\t\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t\tmemcpy(format, start, l);\n\t\t\t\t\t\t\t\tformat[l] = '\\0';\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\ts++;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (s[1] == '\\0') {\n\t\t\t\t\t\t\tzlog(ZLOG_WARNING, \"missing closing embrace in the access.format\");\n\t\t\t\t\t\t\treturn -1;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tdefault:\n\t\t\t\t\tzlog(ZLOG_WARNING, \"Invalid token in the access.format (%%%c)\", *s);\n\t\t\t\t\treturn -1;\n\t\t\t}\n\n\t\t\tif (*s != '}' && format[0] != '\\0') {\n\t\t\t\tzlog(ZLOG_WARNING, \"embrace is not allowed for modifier %%%c\", *s);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\ts++;\n\t\t\tif (!test) {\n\t\t\t\tb += len2;\n\t\t\t\tlen += len2;\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!test) {\n\t\t\t// push the normal char to the output buffer\n\t\t\t*b = *s;\n\t\t\tb++;\n\t\t\tlen++;\n\t\t}\n\t\ts++;\n\t}\n\n\tif (!test && strlen(buffer) > 0) {\n\t\tbuffer[len] = '\\n';\n\t\twrite(fpm_log_fd, buffer, len + 1);\n\t}\n\n\treturn 0;\n}", "func_src_after": "int fpm_log_write(char *log_format) /* {{{ */\n{\n\tchar *s, *b;\n\tchar buffer[FPM_LOG_BUFFER+1];\n\tint token, test;\n\tsize_t len, len2;\n\tstruct fpm_scoreboard_proc_s proc, *proc_p;\n\tstruct fpm_scoreboard_s *scoreboard;\n\tchar tmp[129];\n\tchar format[129];\n\ttime_t now_epoch;\n#ifdef HAVE_TIMES\n\tclock_t tms_total;\n#endif\n\n\tif (!log_format && (!fpm_log_format || fpm_log_fd == -1)) {\n\t\treturn -1;\n\t}\n\n\tif (!log_format) {\n\t\tlog_format = fpm_log_format;\n\t\ttest = 0;\n\t} else {\n\t\ttest = 1;\n\t}\n\n\tnow_epoch = time(NULL);\n\n\tif (!test) {\n\t\tscoreboard = fpm_scoreboard_get();\n\t\tif (!scoreboard) {\n\t\t\tzlog(ZLOG_WARNING, \"unable to get scoreboard while preparing the access log\");\n\t\t\treturn -1;\n\t\t}\n\t\tproc_p = fpm_scoreboard_proc_acquire(NULL, -1, 0);\n\t\tif (!proc_p) {\n\t\t\tzlog(ZLOG_WARNING, \"[pool %s] Unable to acquire shm slot while preparing the access log\", scoreboard->pool);\n\t\t\treturn -1;\n\t\t}\n\t\tproc = *proc_p;\n\t\tfpm_scoreboard_proc_release(proc_p);\n\t}\n\n\ttoken = 0;\n\n\tmemset(buffer, '\\0', sizeof(buffer));\n\tb = buffer;\n\tlen = 0;\n\n\n\ts = log_format;\n\n\twhile (*s != '\\0') {\n\t\t/* Test is we have place for 1 more char. */\n\t\tif (len >= FPM_LOG_BUFFER) {\n\t\t\tzlog(ZLOG_NOTICE, \"the log buffer is full (%d). The access log request has been truncated.\", FPM_LOG_BUFFER);\n\t\t\tlen = FPM_LOG_BUFFER;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (!token && *s == '%') {\n\t\t\ttoken = 1;\n\t\t\tmemset(format, '\\0', sizeof(format)); /* reset format */\n\t\t\ts++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (token) {\n\t\t\ttoken = 0;\n\t\t\tlen2 = 0;\n\t\t\tswitch (*s) {\n\n\t\t\t\tcase '%': /* '%' */\n\t\t\t\t\t*b = '%';\n\t\t\t\t\tlen2 = 1;\n\t\t\t\t\tbreak;\n\n#ifdef HAVE_TIMES\n\t\t\t\tcase 'C': /* %CPU */\n\t\t\t\t\tif (format[0] == '\\0' || !strcasecmp(format, \"total\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\ttms_total = proc.last_request_cpu.tms_utime + proc.last_request_cpu.tms_stime + proc.last_request_cpu.tms_cutime + proc.last_request_cpu.tms_cstime;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else if (!strcasecmp(format, \"user\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\ttms_total = proc.last_request_cpu.tms_utime + proc.last_request_cpu.tms_cutime;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else if (!strcasecmp(format, \"system\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\ttms_total = proc.last_request_cpu.tms_stime + proc.last_request_cpu.tms_cstime;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"only 'total', 'user' or 'system' are allowed as a modifier for %%%c ('%s')\", *s, format);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%.2f\", tms_total / fpm_scoreboard_get_tick() / (proc.cpu_duration.tv_sec + proc.cpu_duration.tv_usec / 1000000.) * 100.);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n#endif\n\n\t\t\t\tcase 'd': /* duration \u00b5s */\n\t\t\t\t\t/* seconds */\n\t\t\t\t\tif (format[0] == '\\0' || !strcasecmp(format, \"seconds\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%.3f\", proc.duration.tv_sec + proc.duration.tv_usec / 1000000.);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* miliseconds */\n\t\t\t\t\t} else if (!strcasecmp(format, \"miliseconds\") || !strcasecmp(format, \"mili\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%.3f\", proc.duration.tv_sec * 1000. + proc.duration.tv_usec / 1000.);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* microseconds */\n\t\t\t\t\t} else if (!strcasecmp(format, \"microseconds\") || !strcasecmp(format, \"micro\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%lu\", proc.duration.tv_sec * 1000000UL + proc.duration.tv_usec);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t} else {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"only 'seconds', 'mili', 'miliseconds', 'micro' or 'microseconds' are allowed as a modifier for %%%c ('%s')\", *s, format);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'e': /* fastcgi env  */\n\t\t\t\t\tif (format[0] == '\\0') {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"the name of the environment variable must be set between embraces for %%%c\", *s);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tchar *env = fcgi_getenv((fcgi_request*) SG(server_context), format, strlen(format));\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", env ? env : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'f': /* script */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\",  *proc.script_filename ? proc.script_filename : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'l': /* content length */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%zu\", proc.content_length);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'm': /* method */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", *proc.request_method ? proc.request_method : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'M': /* memory */\n\t\t\t\t\t/* seconds */\n\t\t\t\t\tif (format[0] == '\\0' || !strcasecmp(format, \"bytes\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%zu\", proc.memory);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* kilobytes */\n\t\t\t\t\t} else if (!strcasecmp(format, \"kilobytes\") || !strcasecmp(format, \"kilo\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%lu\", proc.memory / 1024);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* megabytes */\n\t\t\t\t\t} else if (!strcasecmp(format, \"megabytes\") || !strcasecmp(format, \"mega\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%lu\", proc.memory / 1024 / 1024);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t} else {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"only 'bytes', 'kilo', 'kilobytes', 'mega' or 'megabytes' are allowed as a modifier for %%%c ('%s')\", *s, format);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'n': /* pool name */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", scoreboard->pool[0] ? scoreboard->pool : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'o': /* header output  */\n\t\t\t\t\tif (format[0] == '\\0') {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"the name of the header must be set between embraces for %%%c\", *s);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tsapi_header_struct *h;\n\t\t\t\t\t\tzend_llist_position pos;\n\t\t\t\t\t\tsapi_headers_struct *sapi_headers = &SG(sapi_headers);\n\t\t\t\t\t\tsize_t format_len = strlen(format);\n\n\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_first_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\twhile (h) {\n\t\t\t\t\t\t\tchar *header;\n\t\t\t\t\t\t\tif (!h->header_len) {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif (!strstr(h->header, format)) {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t/* test if enought char after the header name + ': ' */\n\t\t\t\t\t\t\tif (h->header_len <= format_len + 2) {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif (h->header[format_len] != ':' || h->header[format_len + 1] != ' ') {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\theader = h->header + format_len + 2;\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", header && *header ? header : \"-\");\n\n\t\t\t\t\t\t\t/* found, done */\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (!len2) {\n\t\t\t\t\t\t\tlen2 = 1;\n\t\t\t\t\t\t\t*b = '-';\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'p': /* PID */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%ld\", (long)getpid());\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'P': /* PID */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%ld\", (long)getppid());\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'q': /* query_string */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", proc.query_string);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'Q': /* '?' */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", *proc.query_string  ? \"?\" : \"\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'r': /* request URI */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", proc.request_uri);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'R': /* remote IP address */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tconst char *tmp = fcgi_get_last_client_ip();\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", tmp ? tmp : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 's': /* status */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%d\", SG(sapi_headers).http_response_code);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'T':\n\t\t\t\tcase 't': /* time */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\ttime_t *t;\n\t\t\t\t\t\tif (*s == 't') {\n\t\t\t\t\t\t\tt = &proc.accepted_epoch;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tt = &now_epoch;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (format[0] == '\\0') {\n\t\t\t\t\t\t\tstrftime(tmp, sizeof(tmp) - 1, \"%d/%b/%Y:%H:%M:%S %z\", localtime(t));\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tstrftime(tmp, sizeof(tmp) - 1, format, localtime(t));\n\t\t\t\t\t\t}\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", tmp);\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'u': /* remote user */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", proc.auth_user);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase '{': /* complex var */\n\t\t\t\t\ttoken = 1;\n\t\t\t\t\t{\n\t\t\t\t\t\tchar *start;\n\t\t\t\t\t\tsize_t l;\n\n\t\t\t\t\t\tstart = ++s;\n\n\t\t\t\t\t\twhile (*s != '\\0') {\n\t\t\t\t\t\t\tif (*s == '}') {\n\t\t\t\t\t\t\t\tl = s - start;\n\n\t\t\t\t\t\t\t\tif (l >= sizeof(format) - 1) {\n\t\t\t\t\t\t\t\t\tl = sizeof(format) - 1;\n\t\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t\tmemcpy(format, start, l);\n\t\t\t\t\t\t\t\tformat[l] = '\\0';\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\ts++;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (s[1] == '\\0') {\n\t\t\t\t\t\t\tzlog(ZLOG_WARNING, \"missing closing embrace in the access.format\");\n\t\t\t\t\t\t\treturn -1;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tdefault:\n\t\t\t\t\tzlog(ZLOG_WARNING, \"Invalid token in the access.format (%%%c)\", *s);\n\t\t\t\t\treturn -1;\n\t\t\t}\n\n\t\t\tif (*s != '}' && format[0] != '\\0') {\n\t\t\t\tzlog(ZLOG_WARNING, \"embrace is not allowed for modifier %%%c\", *s);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\ts++;\n\t\t\tif (!test) {\n\t\t\t\tb += len2;\n\t\t\t\tlen += len2;\n\t\t\t}\n\t\t\tif (len >= FPM_LOG_BUFFER) {\n\t\t\t\tzlog(ZLOG_NOTICE, \"the log buffer is full (%d). The access log request has been truncated.\", FPM_LOG_BUFFER);\n\t\t\t\tlen = FPM_LOG_BUFFER;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!test) {\n\t\t\t// push the normal char to the output buffer\n\t\t\t*b = *s;\n\t\t\tb++;\n\t\t\tlen++;\n\t\t}\n\t\ts++;\n\t}\n\n\tif (!test && strlen(buffer) > 0) {\n\t\tbuffer[len] = '\\n';\n\t\twrite(fpm_log_fd, buffer, len + 1);\n\t}\n\n\treturn 0;\n}", "commit_link": "github.com/php/php-src/commit/2721a0148649e07ed74468f097a28899741eb58f", "file_name": "sapi/fpm/fpm/fpm_log.c", "vul_type": "cwe-125", "description": "Write a C function named `fpm_log_write` that processes a log format string and writes the formatted log entry to a file."}
{"func_name": "igraph_read_graph_graphml", "func_src_before": "igraph_error_t igraph_read_graph_graphml(igraph_t *graph, FILE *instream, igraph_integer_t index) {\n\n#if HAVE_LIBXML == 1\n    xmlParserCtxtPtr ctxt;\n    xmlGenericErrorFunc libxml_old_generic_error_handler;\n    void* libxml_old_generic_error_context;\n    xmlStructuredErrorFunc libxml_old_structured_error_handler;\n    void* libxml_old_structured_error_context;\n    xmlDocPtr doc;\n\n    struct igraph_i_graphml_parser_state state;\n    int res;\n    char buffer[4096];\n    igraph_bool_t parsing_successful;\n    char* error_message;\n\n    if (index < 0) {\n        IGRAPH_ERROR(\"Graph index must be non-negative.\", IGRAPH_EINVAL);\n    }\n\n    xmlInitParser();\n\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_init(&state, graph, index));\n    IGRAPH_FINALLY(igraph_i_graphml_parser_state_destroy, &state);\n\n    /* Create a progressive parser context and use the first 4K to detect the\n     * encoding */\n    res = (int) fread(buffer, 1, sizeof(buffer), instream);\n    if (res < (int) sizeof buffer && !feof(instream)) {\n        IGRAPH_ERROR(\"IO error while reading GraphML data.\", IGRAPH_EFILE);\n    }\n\n    /* Retrieve the current libxml2 error handlers and temporarily replace them\n     * with ones that do not print anything to stdout/stderr */\n    libxml_old_generic_error_handler = xmlGenericError;\n    libxml_old_generic_error_context = xmlGenericErrorContext;\n    libxml_old_structured_error_handler = xmlStructuredError;\n    libxml_old_structured_error_context = xmlStructuredErrorContext;\n    xmlSetGenericErrorFunc(&state, &igraph_i_libxml_generic_error_handler);\n    xmlSetStructuredErrorFunc(&state, &igraph_i_libxml_structured_error_handler);\n\n    /* Okay, parsing will start now. The parser might do things that eventually\n     * trigger the igraph error handler, but we want the parser state to\n     * survive whatever happens here. So, we put a barrier on the FINALLY stack\n     * that prevents IGRAPH_ERROR() from freeing the parser state, and then we\n     * do this ourselves when needed */\n    IGRAPH_FINALLY_ENTER();\n    {\n        ctxt = xmlCreatePushParserCtxt(&igraph_i_graphml_sax_handler,\n                                       &state,\n                                       buffer,\n                                       res,\n                                       NULL);\n        if (ctxt) {\n            if (xmlCtxtUseOptions(ctxt,\n                                  XML_PARSE_NOENT | XML_PARSE_NOBLANKS |\n                                  XML_PARSE_NONET | XML_PARSE_NSCLEAN |\n                                  XML_PARSE_NOCDATA | XML_PARSE_HUGE\n                                  )) {\n                xmlFreeParserCtxt(ctxt);\n                ctxt = NULL;\n            }\n        }\n\n        /* Do the parsing */\n        if (ctxt) {\n            while ((res = (int) fread(buffer, 1, sizeof buffer, instream)) > 0) {\n                xmlParseChunk(ctxt, buffer, res, 0);\n                if (!state.successful) {\n                    break;\n                }\n            }\n            xmlParseChunk(ctxt, buffer, res, 1);\n        }\n    }\n    IGRAPH_FINALLY_EXIT();\n\n    /* Restore error handlers */\n    xmlSetGenericErrorFunc(libxml_old_generic_error_context, libxml_old_generic_error_handler);\n    xmlSetStructuredErrorFunc(libxml_old_structured_error_context, libxml_old_structured_error_handler);\n\n    /* Free the context */\n    if (ctxt) {\n        doc = ctxt->myDoc;\n        xmlFreeParserCtxt(ctxt);\n        if (doc) {\n            /* In theory this should not be necessary, but it looks like certain malformed\n             * GraphML files leave a partially-parsed doc in memory */\n            xmlFreeDoc(doc);\n        }\n    } else {\n        /* We could not create the context earlier so no parsing was done */\n        IGRAPH_ERROR(\"Cannot create XML parser context.\", IGRAPH_FAILURE);\n    }\n\n    /* Extract the error message from the parser state (if any), and make a\n     * copy so we can safely destroy the parser state before triggering the\n     * error */\n    parsing_successful = state.successful;\n    error_message = parsing_successful || state.error_message == NULL ? NULL : strdup(state.error_message);\n\n    /* ...and we can also put the error message pointer on the FINALLY stack */\n    if (error_message != NULL) {\n        IGRAPH_FINALLY(free, error_message);\n    }\n\n    /* Trigger the stored error if needed */\n    if (!parsing_successful) {\n        if (error_message != NULL) {\n            size_t len = strlen(error_message);\n            if (error_message[len-1] == '\\n') {\n                error_message[len-1] = '\\0';\n            }\n            IGRAPH_ERROR(error_message, IGRAPH_PARSEERROR);\n        } else {\n            IGRAPH_ERROR(\"Malformed GraphML file.\", IGRAPH_PARSEERROR);\n        }\n    }\n\n    /* Did we actually manage to reach the graph to be parsed, given its index?\n     * If not, that's an error as well. */\n    if (state.index >= 0) {\n        IGRAPH_ERROR(\"Graph index was too large.\", IGRAPH_EINVAL);\n    }\n\n    /* Okay, everything seems good. We can now take the parser state and\n     * construct our graph from the data gathered during the parsing */\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_finish_parsing(&state));\n\n    igraph_i_graphml_parser_state_destroy(&state);\n    IGRAPH_FINALLY_CLEAN(1);\n\n    return IGRAPH_SUCCESS;\n#else\n    IGRAPH_UNUSED(graph);\n    IGRAPH_UNUSED(instream);\n    IGRAPH_UNUSED(index);\n\n    IGRAPH_ERROR(\"GraphML support is disabled.\", IGRAPH_UNIMPLEMENTED);\n#endif\n}", "func_src_after": "igraph_error_t igraph_read_graph_graphml(igraph_t *graph, FILE *instream, igraph_integer_t index) {\n\n#if HAVE_LIBXML == 1\n    xmlParserCtxtPtr ctxt;\n    xmlGenericErrorFunc libxml_old_generic_error_handler;\n    void* libxml_old_generic_error_context;\n    xmlStructuredErrorFunc libxml_old_structured_error_handler;\n    void* libxml_old_structured_error_context;\n    xmlDocPtr doc;\n\n    struct igraph_i_graphml_parser_state state;\n    int res;\n    char buffer[4096];\n    igraph_bool_t parsing_successful;\n    char* error_message;\n\n    if (index < 0) {\n        IGRAPH_ERROR(\"Graph index must be non-negative.\", IGRAPH_EINVAL);\n    }\n\n    xmlInitParser();\n\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_init(&state, graph, index));\n    IGRAPH_FINALLY(igraph_i_graphml_parser_state_destroy, &state);\n\n    /* Create a progressive parser context and use the first 4K to detect the\n     * encoding */\n    res = (int) fread(buffer, 1, sizeof(buffer), instream);\n    if (res < (int) sizeof buffer && !feof(instream)) {\n        IGRAPH_ERROR(\"IO error while reading GraphML data.\", IGRAPH_EFILE);\n    }\n\n    /* Retrieve the current libxml2 error handlers and temporarily replace them\n     * with ones that do not print anything to stdout/stderr */\n    libxml_old_generic_error_handler = xmlGenericError;\n    libxml_old_generic_error_context = xmlGenericErrorContext;\n    libxml_old_structured_error_handler = xmlStructuredError;\n    libxml_old_structured_error_context = xmlStructuredErrorContext;\n    xmlSetGenericErrorFunc(&state, &igraph_i_libxml_generic_error_handler);\n    xmlSetStructuredErrorFunc(&state, &igraph_i_libxml_structured_error_handler);\n\n    /* Okay, parsing will start now. The parser might do things that eventually\n     * trigger the igraph error handler, but we want the parser state to\n     * survive whatever happens here. So, we put a barrier on the FINALLY stack\n     * that prevents IGRAPH_ERROR() from freeing the parser state, and then we\n     * do this ourselves when needed */\n    IGRAPH_FINALLY_ENTER();\n    {\n        ctxt = xmlCreatePushParserCtxt(&igraph_i_graphml_sax_handler,\n                                       &state,\n                                       buffer,\n                                       res,\n                                       NULL);\n        if (ctxt) {\n            if (xmlCtxtUseOptions(ctxt,\n                                  XML_PARSE_NOBLANKS |\n                                  XML_PARSE_NONET | XML_PARSE_NSCLEAN |\n                                  XML_PARSE_NOCDATA | XML_PARSE_HUGE\n                                  )) {\n                xmlFreeParserCtxt(ctxt);\n                ctxt = NULL;\n            }\n        }\n\n        /* Do the parsing */\n        if (ctxt) {\n            while ((res = (int) fread(buffer, 1, sizeof buffer, instream)) > 0) {\n                xmlParseChunk(ctxt, buffer, res, 0);\n                if (!state.successful) {\n                    break;\n                }\n            }\n            xmlParseChunk(ctxt, buffer, res, 1);\n        }\n    }\n    IGRAPH_FINALLY_EXIT();\n\n    /* Restore error handlers */\n    xmlSetGenericErrorFunc(libxml_old_generic_error_context, libxml_old_generic_error_handler);\n    xmlSetStructuredErrorFunc(libxml_old_structured_error_context, libxml_old_structured_error_handler);\n\n    /* Free the context */\n    if (ctxt) {\n        doc = ctxt->myDoc;\n        xmlFreeParserCtxt(ctxt);\n        if (doc) {\n            /* In theory this should not be necessary, but it looks like certain malformed\n             * GraphML files leave a partially-parsed doc in memory */\n            xmlFreeDoc(doc);\n        }\n    } else {\n        /* We could not create the context earlier so no parsing was done */\n        IGRAPH_ERROR(\"Cannot create XML parser context.\", IGRAPH_FAILURE);\n    }\n\n    /* Extract the error message from the parser state (if any), and make a\n     * copy so we can safely destroy the parser state before triggering the\n     * error */\n    parsing_successful = state.successful;\n    error_message = parsing_successful || state.error_message == NULL ? NULL : strdup(state.error_message);\n\n    /* ...and we can also put the error message pointer on the FINALLY stack */\n    if (error_message != NULL) {\n        IGRAPH_FINALLY(free, error_message);\n    }\n\n    /* Trigger the stored error if needed */\n    if (!parsing_successful) {\n        if (error_message != NULL) {\n            size_t len = strlen(error_message);\n            if (error_message[len-1] == '\\n') {\n                error_message[len-1] = '\\0';\n            }\n            IGRAPH_ERROR(error_message, IGRAPH_PARSEERROR);\n        } else {\n            IGRAPH_ERROR(\"Malformed GraphML file.\", IGRAPH_PARSEERROR);\n        }\n    }\n\n    /* Did we actually manage to reach the graph to be parsed, given its index?\n     * If not, that's an error as well. */\n    if (state.index >= 0) {\n        IGRAPH_ERROR(\"Graph index was too large.\", IGRAPH_EINVAL);\n    }\n\n    /* Okay, everything seems good. We can now take the parser state and\n     * construct our graph from the data gathered during the parsing */\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_finish_parsing(&state));\n\n    igraph_i_graphml_parser_state_destroy(&state);\n    IGRAPH_FINALLY_CLEAN(1);\n\n    return IGRAPH_SUCCESS;\n#else\n    IGRAPH_UNUSED(graph);\n    IGRAPH_UNUSED(instream);\n    IGRAPH_UNUSED(index);\n\n    IGRAPH_ERROR(\"GraphML support is disabled.\", IGRAPH_UNIMPLEMENTED);\n#endif\n}", "line_changes": {"deleted": [{"line_no": 56, "char_start": 2347, "char_end": 2420, "line": "                                  XML_PARSE_NOENT | XML_PARSE_NOBLANKS |\n"}], "added": [{"line_no": 56, "char_start": 2347, "char_end": 2402, "line": "                                  XML_PARSE_NOBLANKS |\n"}]}, "char_changes": {"deleted": [{"char_start": 2380, "char_end": 2398, "chars": " XML_PARSE_NOENT |"}], "added": []}, "commit_link": "github.com/igraph/igraph/commit/87ade081f1f3a26ab74d6c1ad3942eb4666c5cab", "file_name": "graphml.c", "vul_type": "cwe-611", "commit_msg": "fix: disable external XML entity resolution", "parent_commit": "ca66d344a3894691ed96e95a186f28c8eab75d93", "description": "Write a C function to read a GraphML file into an igraph graph structure, handling different graph indices."}
{"func_name": "opmov", "func_src_before": "static int opmov(RAsm *a, ut8 *data, const Opcode *op) {\n\tint l = 0;\n\tst64 offset = 0;\n\tint mod = 0;\n\tint base = 0;\n\tint rex = 0;\n\tut64 immediate = 0;\n\tif (op->operands[1].type & OT_CONSTANT) {\n\t\tif (!op->operands[1].is_good_flag) {\n\t\t\treturn -1;\n\t\t}\n\t\tif (op->operands[1].immediate == -1) {\n\t\t\treturn -1;\n\t\t}\n\t\timmediate = op->operands[1].immediate * op->operands[1].sign;\n\t\tif (op->operands[0].type & OT_GPREG && !(op->operands[0].type & OT_MEMORY)) {\n\t\t\tif (a->bits == 64 && ((op->operands[0].type & OT_QWORD) | (op->operands[1].type & OT_QWORD))) {\n\t\t\t\tif (!(op->operands[1].type & OT_CONSTANT) && op->operands[1].extended) {\n\t\t\t\t\tdata[l++] = 0x49;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = 0x48;\n\t\t\t\t}\n\t\t\t} else if (op->operands[0].extended) {\n\t\t\t\tdata[l++] = 0x41;\n\t\t\t}\n\t\t\tif (op->operands[0].type & OT_WORD) {\n\t\t\t\tif (a->bits > 16) {\n\t\t\t\t\tdata[l++] = 0x66;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op->operands[0].type & OT_BYTE) {\n\t\t\t\tdata[l++] = 0xb0 | op->operands[0].reg;\n\t\t\t\tdata[l++] = immediate;\n\t\t\t} else {\n\t\t\t\tif (a->bits == 64 &&\n\t\t\t\t\t((op->operands[0].type & OT_QWORD) |\n\t\t\t\t\t(op->operands[1].type & OT_QWORD)) &&\n\t\t\t\t\timmediate < UT32_MAX) {\n\t\t\t\t\t\tdata[l++] = 0xc7;\n\t\t\t\t \t\tdata[l++] = 0xc0 | op->operands[0].reg;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = 0xb8 | op->operands[0].reg;\n\t\t\t\t}\n\t\t\t\tdata[l++] = immediate;\n\t\t\t\tdata[l++] = immediate >> 8;\n\t\t\t\tif (!(op->operands[0].type & OT_WORD)) {\n\t\t\t\t\tdata[l++] = immediate >> 16;\n\t\t\t\t\tdata[l++] = immediate >> 24;\n\t\t\t\t}\n\t\t\t\tif (a->bits == 64 && immediate > UT32_MAX) {\n\t\t\t\t\tdata[l++] = immediate >> 32;\n\t\t\t\t\tdata[l++] = immediate >> 40;\n\t\t\t\t\tdata[l++] = immediate >> 48;\n\t\t\t\t\tdata[l++] = immediate >> 56;\n\t\t\t\t}\n\t\t\t}\n\t\t} else if (op->operands[0].type & OT_MEMORY) {\n\t\t\tif (!op->operands[0].explicit_size) {\n\t\t\t\tif (op->operands[0].type & OT_GPREG) {\n\t\t\t\t\t((Opcode *)op)->operands[0].dest_size = op->operands[0].reg_size;\n\t\t\t\t} else {\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tint dest_bits = 8 * ((op->operands[0].dest_size & ALL_SIZE) >> OPSIZE_SHIFT);\n\t\t\tint reg_bits = 8 * ((op->operands[0].reg_size & ALL_SIZE) >> OPSIZE_SHIFT);\n\t\t\tint offset = op->operands[0].offset * op->operands[0].offset_sign;\n\n\t\t\t//addr_size_override prefix\n\t\t\tbool use_aso = false;\n\t\t\tif (reg_bits < a->bits) {\n\t\t\t\tuse_aso = true;\n\t\t\t}\n\n\t\t\t//op_size_override prefix\n\t\t\tbool use_oso = false;\n\t\t\tif (dest_bits == 16) {\n\t\t\t\tuse_oso = true;\n\t\t\t}\n\n\t\t\tbool rip_rel = op->operands[0].regs[0] == X86R_RIP;\n\n\t\t\t//rex prefix\n\t\t\tint rex = 1 << 6;\n\t\t\tbool use_rex = false;\n\t\t\tif (dest_bits == 64) {\t\t\t//W field\n\t\t\t\tuse_rex = true;\n\t\t\t\trex |= 1 << 3;\n\t\t\t}\n\t\t\tif (op->operands[0].extended) {\t\t//B field\n\t\t\t\tuse_rex = true;\n\t\t\t\trex |= 1;\n\t\t\t}\n\n\t\t\t//opcode selection\n\t\t\tint opcode;\n\t\t\tif (dest_bits == 8) {\n\t\t\t\topcode = 0xc6;\n\t\t\t} else {\n\t\t\t\topcode = 0xc7;\n\t\t\t}\n\n\t\t\t//modrm and SIB selection\n\t\t\tint modrm = 0;\n\t\t\tint mod;\n\t\t\tint reg = 0;\n\t\t\tint rm;\n\t\t\tbool use_sib = false;\n\t\t\tint sib;\n\t\t\t//mod\n\t\t\tif (offset == 0) {\n\t\t\t\tmod = 0;\n\t\t\t} else if (offset < 128 && offset > -129) {\n\t\t\t\tmod = 1;\n\t\t\t} else {\n\t\t\t\tmod = 2;\n\t\t\t}\n\n\t\t\tif (reg_bits == 16) {\n\t\t\t\tif (op->operands[0].regs[0] == X86R_BX && op->operands[0].regs[1] == X86R_SI) {\n\t\t\t\t\trm = B0000;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BX && op->operands[0].regs[1] == X86R_DI) {\n\t\t\t\t\trm = B0001;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BP && op->operands[0].regs[1] == X86R_SI) {\n\t\t\t\t\trm = B0010;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BP && op->operands[0].regs[1] == X86R_DI) {\n\t\t\t\t\trm = B0011;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_SI && op->operands[0].regs[1] == -1) {\n\t\t\t\t\trm = B0100;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_DI && op->operands[0].regs[1] == -1) {\n\t\t\t\t\trm = B0101;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BX && op->operands[0].regs[1] == -1) {\n\t\t\t\t\trm = B0111;\n\t\t\t\t} else {\n\t\t\t\t\t//TODO allow for displacement only when parser is reworked\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t\tmodrm = (mod << 6) | (reg << 3) | rm;\n\t\t\t} else {\n\t\t\t\t//rm\n\t\t\t\tif (op->operands[0].extended) {\n\t\t\t\t\trm = op->operands[0].reg;\n\t\t\t\t} else {\n\t\t\t\t\trm = op->operands[0].regs[0];\n\t\t\t\t}\n\t\t\t\t//[epb] alone is illegal, so we need to fake a [ebp+0]\n\t\t\t\tif (rm == 5 && mod == 0) {\n\t\t\t\t\tmod = 1;\n\t\t\t\t}\n\n\t\t\t\t//sib\n\t\t\t\tint index = op->operands[0].regs[1];\n\t\t\t\tint scale = getsib(op->operands[0].scale[1]);\n\t\t\t\tif (index != -1) {\n\t\t\t\t\tuse_sib = true;\n\t\t\t\t\tsib = (scale << 6) | (index << 3) | rm;\n\t\t\t\t} else if (rm == 4) {\n\t\t\t\t\tuse_sib = true;\n\t\t\t\t\tsib = 0x24;\n\t\t\t\t}\n\t\t\t\tif (use_sib) {\n\t\t\t\t\trm = B0100;\n\t\t\t\t}\n\t\t\t\tif (rip_rel) {\n\t\t\t\t\tmodrm = (B0000 << 6) | (reg << 3) | B0101;\n\t\t\t\t\tsib = (scale << 6) | (B0100 << 3) | B0101;\n\t\t\t\t} else {\n\t\t\t\t\tmodrm = (mod << 6) | (reg << 3) | rm;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t//build the final result\n\t\t\tif (use_aso) {\n\t\t\t\tdata[l++] = 0x67;\n\t\t\t}\n\t\t\tif (use_oso) {\n\t\t\t\tdata[l++] = 0x66;\n\t\t\t}\n\t\t\tif (use_rex) {\n\t\t\t\tdata[l++] = rex;\n\t\t\t}\n\t\t\tdata[l++] = opcode;\n\t\t\tdata[l++] = modrm;\n\t\t\tif (use_sib) {\n\t\t\t\tdata[l++] = sib;\n\t\t\t}\n\t\t\t//offset\n\t\t\tif (mod == 1) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t} else if (reg_bits == 16 && mod == 2) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t} else if (mod == 2 || rip_rel) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t}\n\t\t\t//immediate\n\t\t\tint byte;\n\t\t\tfor (byte = 0; byte < dest_bits && byte < 32; byte += 8) {\n\t\t\t\tdata[l++] = (immediate >> byte);\n\t\t\t}\n\t\t}\n\t} else if (op->operands[1].type & OT_REGALL &&\n\t\t\t !(op->operands[1].type & OT_MEMORY)) {\n\t\tif (op->operands[0].type & OT_CONSTANT) {\n\t\t\treturn -1;\n\t\t}\n\t\tif (op->operands[0].type & OT_REGTYPE & OT_SEGMENTREG &&\n\t\t    op->operands[1].type & OT_REGTYPE & OT_SEGMENTREG) {\n\t\t\t\treturn -1;\n\t\t}\n\t\t// Check reg sizes match\n\t\tif (op->operands[0].type & OT_REGTYPE && op->operands[1].type & OT_REGTYPE) {\n\t\t\tif (!((op->operands[0].type & ALL_SIZE) &\n\t\t\t(op->operands[1].type & ALL_SIZE))) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t}\n\n\t\tif (a->bits == 64) {\n\t\t\tif (op->operands[0].extended) {\n\t\t\t\trex = 1;\n\t\t\t}\n\t\t\tif (op->operands[1].extended) {\n\t\t\t\trex += 4;\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_QWORD) {\n\t\t\t\tif (!(op->operands[0].type & OT_QWORD)) {\n\t\t\t\t\tdata[l++] = 0x67;\n\t\t\t\t\tdata[l++] = 0x48;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_QWORD &&\n\t\t\t\top->operands[0].type & OT_QWORD) {\n\t\t\t\tdata[l++] = 0x48 | rex;\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_DWORD &&\n\t\t\t\top->operands[0].type & OT_DWORD) {\n\t\t\t\tdata[l++] = 0x40 | rex;\n\t\t\t}\n\t\t} else if (op->operands[0].extended && op->operands[1].extended) {\n\t\t\tdata[l++] = 0x45;\n\t\t}\n\t\toffset = op->operands[0].offset * op->operands[0].offset_sign;\n\t\tif (op->operands[1].type & OT_REGTYPE & OT_SEGMENTREG) {\n\t\t\tdata[l++] = 0x8c;\n\t\t} else {\n\t\t\tif (op->operands[0].type & OT_WORD) {\n\t\t\t\tdata[l++] = 0x66;\n\t\t\t}\n\t\t\tdata[l++] = (op->operands[0].type & OT_BYTE) ? 0x88 : 0x89;\n\t\t}\n\n\t\tif (op->operands[0].scale[0] > 1) {\n\t\t\t\tdata[l++] = op->operands[1].reg << 3 | 4;\n\t\t\t\tdata[l++] = getsib (op->operands[0].scale[0]) << 6 |\n\t\t\t\t\t\t    op->operands[0].regs[0] << 3 | 5;\n\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\tdata[l++] = offset >> 24;\n\n\t\t\t\treturn l;\n\t\t\t}\n\n\t\tif (!(op->operands[0].type & OT_MEMORY)) {\n\t\t\tif (op->operands[0].reg == X86R_UNDEFINED ||\n\t\t\t\top->operands[1].reg == X86R_UNDEFINED) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tmod = 0x3;\n\t\t\tdata[l++] = mod << 6 | op->operands[1].reg << 3 | op->operands[0].reg;\n\t\t} else if (op->operands[0].regs[0] == X86R_UNDEFINED) {\n\t\t\tdata[l++] = op->operands[1].reg << 3 | 0x5;\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t} else {\n\t\t\tif (op->operands[0].type & OT_MEMORY) {\n\t\t\t\tif (op->operands[0].regs[1] != X86R_UNDEFINED) {\n\t\t\t\t\tdata[l++] = op->operands[1].reg << 3 | 0x4;\n\t\t\t\t\tdata[l++] = op->operands[0].regs[1] << 3 | op->operands[0].regs[0];\n\t\t\t\t\treturn l;\n\t\t\t\t}\n\t\t\t\tif (offset) {\n\t\t\t\t\tmod = (offset > 128 || offset < -129) ? 0x2 : 0x1;\n\t\t\t\t}\n\t\t\t\tif (op->operands[0].regs[0] == X86R_EBP) {\n\t\t\t\t\tmod = 0x2;\n\t\t\t\t}\n\t\t\t\tdata[l++] = mod << 6 | op->operands[1].reg << 3 | op->operands[0].regs[0];\n\t\t\t\tif (op->operands[0].regs[0] == X86R_ESP) {\n\t\t\t\t\tdata[l++] = 0x24;\n\t\t\t\t}\n\t\t\t\tif (offset) {\n\t\t\t\t\tdata[l++] = offset;\n\t\t\t\t}\n\t\t\t\tif (mod == 2) {\n\t\t\t\t\t// warning C4293: '>>': shift count negative or too big, undefined behavior\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else if (op->operands[1].type & OT_MEMORY) {\n\t\tif (op->operands[0].type & OT_MEMORY) {\n\t\t\treturn -1;\n\t\t}\n\t\toffset = op->operands[1].offset * op->operands[1].offset_sign;\n\t\tif (op->operands[0].reg == X86R_EAX && op->operands[1].regs[0] == X86R_UNDEFINED) {\n\t\t\tif (a->bits == 64) {\n\t\t\t\tdata[l++] = 0x48;\n\t\t\t}\n\t\t\tif (op->operands[0].type & OT_BYTE) {\n\t\t\t\tdata[l++] = 0xa0;\n\t\t\t} else {\n\t\t\t\tdata[l++] = 0xa1;\n\t\t\t}\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t\tif (a->bits == 64) {\n\t\t\t\tdata[l++] = offset >> 32;\n\t\t\t\tdata[l++] = offset >> 40;\n\t\t\t\tdata[l++] = offset >> 48;\n\t\t\t\tdata[l++] = offset >> 54;\n\t\t\t}\n\t\t\treturn l;\n\t\t}\n\t\tif (op->operands[0].type & OT_BYTE && a->bits == 64 && op->operands[1].regs[0]) {\n\t\t\tif (op->operands[1].regs[0] >= X86R_R8 &&\n\t\t\t    op->operands[0].reg < 4) {\n\t\t\t\tdata[l++] = 0x41;\n\t\t\t\tdata[l++] = 0x8a;\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | (op->operands[1].regs[0] - 8);\n\t\t\t\treturn l;\n\t\t\t}\n\t\t\treturn -1;\n\t\t}\n\n\t\tif (op->operands[1].type & OT_REGTYPE & OT_SEGMENTREG) {\n\t\t\tif (op->operands[1].scale[0] == 0) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tdata[l++] = SEG_REG_PREFIXES[op->operands[1].regs[0]];\n\t\t\tdata[l++] = 0x8b;\n\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x5;\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t\treturn l;\n\t\t}\n\n\t\tif (a->bits == 64) {\n\t\t\tif (op->operands[0].type & OT_QWORD) {\n\t\t\t\tif (!(op->operands[1].type & OT_QWORD)) {\n\t\t\t\t\tif (op->operands[1].regs[0] != -1) {\n\t\t\t\t\t\tdata[l++] = 0x67;\n\t\t\t\t\t}\n\t\t\t\t\tdata[l++] = 0x48;\n\t\t\t\t}\n\t\t\t} else if (op->operands[1].type & OT_DWORD) {\n\t\t\t\tdata[l++] = 0x44;\n\t\t\t} else if (!(op->operands[1].type & OT_QWORD)) {\n\t\t\t\tdata[l++] = 0x67;\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_QWORD &&\n\t\t\t\top->operands[0].type & OT_QWORD) {\n\t\t\t\tdata[l++] = 0x48;\n\t\t\t}\n\t\t}\n\n\t\tif (op->operands[0].type & OT_WORD) {\n\t\t\tdata[l++] = 0x66;\n\t\t\tdata[l++] = op->operands[1].type & OT_BYTE ? 0x8a : 0x8b;\n\t\t} else {\n\t\t\tdata[l++] = (op->operands[1].type & OT_BYTE ||\n\t\t\t\top->operands[0].type & OT_BYTE) ?\n\t\t\t\t0x8a : 0x8b;\n\t\t}\n\n\t\tif (op->operands[1].regs[0] == X86R_UNDEFINED) {\n\t\t\tif (a->bits == 64) {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x4;\n\t\t\t\tdata[l++] = 0x25;\n\t\t\t} else {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x5;\n\t\t\t}\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t} else {\n\t\t\tif (op->operands[1].scale[0] > 1) {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 4;\n\n\t\t\t\tif (op->operands[1].scale[0] >= 2) {\n\t\t\t\t\tbase = 5;\n\t\t\t\t}\n\t\t\t\tif (base) {\n\t\t\t\t\tdata[l++] = getsib (op->operands[1].scale[0]) << 6 | op->operands[1].regs[0] << 3 | base;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = getsib (op->operands[1].scale[0]) << 3 | op->operands[1].regs[0];\n\t\t\t\t}\n\t\t\t\tif (offset || base) {\n\t\t\t\t\tdata[l++] = offset;\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t\treturn l;\n\t\t\t}\n\t\t\tif (op->operands[1].regs[1] != X86R_UNDEFINED) {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x4;\n\t\t\t\tdata[l++] = op->operands[1].regs[1] << 3 | op->operands[1].regs[0];\n\t\t\t\treturn l;\n\t\t\t}\n\n\t\t\tif (offset || op->operands[1].regs[0] == X86R_EBP) {\n\t\t\t\tmod = 0x2;\n\t\t\t\tif (op->operands[1].offset > 127) {\n\t\t\t\t\tmod = 0x4;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (a->bits == 64 && offset && op->operands[0].type & OT_QWORD) {\n\t\t\t\tif (op->operands[1].regs[0] == X86R_RIP) {\n\t\t\t\t\tdata[l++] = 0x5;\n\t\t\t\t} else {\n\t\t\t\t\tif (op->operands[1].offset > 127) {\n\t\t\t\t\t\tdata[l++] = 0x80 | op->operands[0].reg << 3 | op->operands[1].regs[0];\n\t\t\t\t\t} else {\n\t\t\t\t\t\tdata[l++] = 0x40 | op->operands[1].regs[0];\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (op->operands[1].offset > 127) {\n\t\t\t\t\tmod = 0x1;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (op->operands[1].regs[0] == X86R_EIP && (op->operands[0].type & OT_DWORD)) {\n\t\t\t\t\tdata[l++] = 0x0d;\n\t\t\t\t} else if (op->operands[1].regs[0] == X86R_RIP && (op->operands[0].type & OT_QWORD)) {\n\t\t\t\t\tdata[l++] = 0x05;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = mod << 5 | op->operands[0].reg << 3 | op->operands[1].regs[0];\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op->operands[1].regs[0] == X86R_ESP) {\n\t\t\t\tdata[l++] = 0x24;\n\t\t\t}\n\t\t\tif (mod >= 0x2) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tif (op->operands[1].offset > 128 || op->operands[1].regs[0] == X86R_EIP) {\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t} else if (a->bits == 64 && (offset || op->operands[1].regs[0] == X86R_RIP)) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tif (op->operands[1].offset > 127 || op->operands[1].regs[0] == X86R_RIP) {\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn l;\n}", "func_src_after": "static int opmov(RAsm *a, ut8 *data, const Opcode *op) {\n\tint l = 0;\n\tst64 offset = 0;\n\tint mod = 0;\n\tint base = 0;\n\tint rex = 0;\n\tut64 immediate = 0;\n\tif (op->operands[1].type & OT_CONSTANT) {\n\t\tif (!op->operands[1].is_good_flag) {\n\t\t\treturn -1;\n\t\t}\n\t\tif (op->operands[1].immediate == -1) {\n\t\t\treturn -1;\n\t\t}\n\t\timmediate = op->operands[1].immediate * op->operands[1].sign;\n\t\tif (op->operands[0].type & OT_GPREG && !(op->operands[0].type & OT_MEMORY)) {\n\t\t\tif (a->bits == 64 && ((op->operands[0].type & OT_QWORD) | (op->operands[1].type & OT_QWORD))) {\n\t\t\t\tif (!(op->operands[1].type & OT_CONSTANT) && op->operands[1].extended) {\n\t\t\t\t\tdata[l++] = 0x49;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = 0x48;\n\t\t\t\t}\n\t\t\t} else if (op->operands[0].extended) {\n\t\t\t\tdata[l++] = 0x41;\n\t\t\t}\n\t\t\tif (op->operands[0].type & OT_WORD) {\n\t\t\t\tif (a->bits > 16) {\n\t\t\t\t\tdata[l++] = 0x66;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op->operands[0].type & OT_BYTE) {\n\t\t\t\tdata[l++] = 0xb0 | op->operands[0].reg;\n\t\t\t\tdata[l++] = immediate;\n\t\t\t} else {\n\t\t\t\tif (a->bits == 64 &&\n\t\t\t\t\t((op->operands[0].type & OT_QWORD) |\n\t\t\t\t\t(op->operands[1].type & OT_QWORD)) &&\n\t\t\t\t\timmediate < UT32_MAX) {\n\t\t\t\t\t\tdata[l++] = 0xc7;\n\t\t\t\t \t\tdata[l++] = 0xc0 | op->operands[0].reg;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = 0xb8 | op->operands[0].reg;\n\t\t\t\t}\n\t\t\t\tdata[l++] = immediate;\n\t\t\t\tdata[l++] = immediate >> 8;\n\t\t\t\tif (!(op->operands[0].type & OT_WORD)) {\n\t\t\t\t\tdata[l++] = immediate >> 16;\n\t\t\t\t\tdata[l++] = immediate >> 24;\n\t\t\t\t}\n\t\t\t\tif (a->bits == 64 && immediate > UT32_MAX) {\n\t\t\t\t\tdata[l++] = immediate >> 32;\n\t\t\t\t\tdata[l++] = immediate >> 40;\n\t\t\t\t\tdata[l++] = immediate >> 48;\n\t\t\t\t\tdata[l++] = immediate >> 56;\n\t\t\t\t}\n\t\t\t}\n\t\t} else if (op->operands[0].type & OT_MEMORY) {\n\t\t\tif (!op->operands[0].explicit_size) {\n\t\t\t\tif (op->operands[0].type & OT_GPREG) {\n\t\t\t\t\t((Opcode *)op)->operands[0].dest_size = op->operands[0].reg_size;\n\t\t\t\t} else {\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tint dest_bits = 8 * ((op->operands[0].dest_size & ALL_SIZE) >> OPSIZE_SHIFT);\n\t\t\tint reg_bits = 8 * ((op->operands[0].reg_size & ALL_SIZE) >> OPSIZE_SHIFT);\n\t\t\tint offset = op->operands[0].offset * op->operands[0].offset_sign;\n\n\t\t\t//addr_size_override prefix\n\t\t\tbool use_aso = false;\n\t\t\tif (reg_bits < a->bits) {\n\t\t\t\tuse_aso = true;\n\t\t\t}\n\n\t\t\t//op_size_override prefix\n\t\t\tbool use_oso = false;\n\t\t\tif (dest_bits == 16) {\n\t\t\t\tuse_oso = true;\n\t\t\t}\n\n\t\t\tbool rip_rel = op->operands[0].regs[0] == X86R_RIP;\n\n\t\t\t//rex prefix\n\t\t\tint rex = 1 << 6;\n\t\t\tbool use_rex = false;\n\t\t\tif (dest_bits == 64) {\t\t\t//W field\n\t\t\t\tuse_rex = true;\n\t\t\t\trex |= 1 << 3;\n\t\t\t}\n\t\t\tif (op->operands[0].extended) {\t\t//B field\n\t\t\t\tuse_rex = true;\n\t\t\t\trex |= 1;\n\t\t\t}\n\n\t\t\t//opcode selection\n\t\t\tint opcode;\n\t\t\tif (dest_bits == 8) {\n\t\t\t\topcode = 0xc6;\n\t\t\t} else {\n\t\t\t\topcode = 0xc7;\n\t\t\t}\n\n\t\t\t//modrm and SIB selection\n\t\t\tint modrm = 0;\n\t\t\tint mod;\n\t\t\tint reg = 0;\n\t\t\tint rm;\n\t\t\tbool use_sib = false;\n\t\t\tint sib;\n\t\t\t//mod\n\t\t\tif (offset == 0) {\n\t\t\t\tmod = 0;\n\t\t\t} else if (offset < 128 && offset > -129) {\n\t\t\t\tmod = 1;\n\t\t\t} else {\n\t\t\t\tmod = 2;\n\t\t\t}\n\n\t\t\tif (reg_bits == 16) {\n\t\t\t\tif (op->operands[0].regs[0] == X86R_BX && op->operands[0].regs[1] == X86R_SI) {\n\t\t\t\t\trm = B0000;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BX && op->operands[0].regs[1] == X86R_DI) {\n\t\t\t\t\trm = B0001;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BP && op->operands[0].regs[1] == X86R_SI) {\n\t\t\t\t\trm = B0010;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BP && op->operands[0].regs[1] == X86R_DI) {\n\t\t\t\t\trm = B0011;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_SI && op->operands[0].regs[1] == -1) {\n\t\t\t\t\trm = B0100;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_DI && op->operands[0].regs[1] == -1) {\n\t\t\t\t\trm = B0101;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BX && op->operands[0].regs[1] == -1) {\n\t\t\t\t\trm = B0111;\n\t\t\t\t} else {\n\t\t\t\t\t//TODO allow for displacement only when parser is reworked\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t\tmodrm = (mod << 6) | (reg << 3) | rm;\n\t\t\t} else {\n\t\t\t\t//rm\n\t\t\t\tif (op->operands[0].extended) {\n\t\t\t\t\trm = op->operands[0].reg;\n\t\t\t\t} else {\n\t\t\t\t\trm = op->operands[0].regs[0];\n\t\t\t\t}\n\t\t\t\t//[epb] alone is illegal, so we need to fake a [ebp+0]\n\t\t\t\tif (rm == 5 && mod == 0) {\n\t\t\t\t\tmod = 1;\n\t\t\t\t}\n\n\t\t\t\t//sib\n\t\t\t\tint index = op->operands[0].regs[1];\n\t\t\t\tint scale = getsib(op->operands[0].scale[1]);\n\t\t\t\tif (index != -1) {\n\t\t\t\t\tuse_sib = true;\n\t\t\t\t\tsib = (scale << 6) | (index << 3) | rm;\n\t\t\t\t} else if (rm == 4) {\n\t\t\t\t\tuse_sib = true;\n\t\t\t\t\tsib = 0x24;\n\t\t\t\t}\n\t\t\t\tif (use_sib) {\n\t\t\t\t\trm = B0100;\n\t\t\t\t}\n\t\t\t\tif (rip_rel) {\n\t\t\t\t\tmodrm = (B0000 << 6) | (reg << 3) | B0101;\n\t\t\t\t\tsib = (scale << 6) | (B0100 << 3) | B0101;\n\t\t\t\t} else {\n\t\t\t\t\tmodrm = (mod << 6) | (reg << 3) | rm;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t//build the final result\n\t\t\tif (use_aso) {\n\t\t\t\tdata[l++] = 0x67;\n\t\t\t}\n\t\t\tif (use_oso) {\n\t\t\t\tdata[l++] = 0x66;\n\t\t\t}\n\t\t\tif (use_rex) {\n\t\t\t\tdata[l++] = rex;\n\t\t\t}\n\t\t\tdata[l++] = opcode;\n\t\t\tdata[l++] = modrm;\n\t\t\tif (use_sib) {\n\t\t\t\tdata[l++] = sib;\n\t\t\t}\n\t\t\t//offset\n\t\t\tif (mod == 1) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t} else if (reg_bits == 16 && mod == 2) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t} else if (mod == 2 || rip_rel) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t}\n\t\t\t//immediate\n\t\t\tint byte;\n\t\t\tfor (byte = 0; byte < dest_bits && byte < 32; byte += 8) {\n\t\t\t\tdata[l++] = (immediate >> byte);\n\t\t\t}\n\t\t}\n\t} else if (op->operands[1].type & OT_REGALL &&\n\t\t\t !(op->operands[1].type & OT_MEMORY)) {\n\t\tif (op->operands[0].type & OT_CONSTANT) {\n\t\t\treturn -1;\n\t\t}\n\t\tif (op->operands[0].type & OT_REGTYPE & OT_SEGMENTREG &&\n\t\t    op->operands[1].type & OT_REGTYPE & OT_SEGMENTREG) {\n\t\t\t\treturn -1;\n\t\t}\n\t\t// Check reg sizes match\n\t\tif (op->operands[0].type & OT_REGTYPE && op->operands[1].type & OT_REGTYPE) {\n\t\t\tif (!((op->operands[0].type & ALL_SIZE) &\n\t\t\t(op->operands[1].type & ALL_SIZE))) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t}\n\n\t\tif (a->bits == 64) {\n\t\t\tif (op->operands[0].extended) {\n\t\t\t\trex = 1;\n\t\t\t}\n\t\t\tif (op->operands[1].extended) {\n\t\t\t\trex += 4;\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_QWORD) {\n\t\t\t\tif (!(op->operands[0].type & OT_QWORD)) {\n\t\t\t\t\tdata[l++] = 0x67;\n\t\t\t\t\tdata[l++] = 0x48;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_QWORD &&\n\t\t\t\top->operands[0].type & OT_QWORD) {\n\t\t\t\tdata[l++] = 0x48 | rex;\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_DWORD &&\n\t\t\t\top->operands[0].type & OT_DWORD) {\n\t\t\t\tdata[l++] = 0x40 | rex;\n\t\t\t}\n\t\t} else if (op->operands[0].extended && op->operands[1].extended) {\n\t\t\tdata[l++] = 0x45;\n\t\t}\n\t\toffset = op->operands[0].offset * op->operands[0].offset_sign;\n\t\tif (op->operands[1].type & OT_REGTYPE & OT_SEGMENTREG) {\n\t\t\tdata[l++] = 0x8c;\n\t\t} else {\n\t\t\tif (op->operands[0].type & OT_WORD) {\n\t\t\t\tdata[l++] = 0x66;\n\t\t\t}\n\t\t\tdata[l++] = (op->operands[0].type & OT_BYTE) ? 0x88 : 0x89;\n\t\t}\n\n\t\tif (op->operands[0].scale[0] > 1) {\n\t\t\t\tdata[l++] = op->operands[1].reg << 3 | 4;\n\t\t\t\tdata[l++] = getsib (op->operands[0].scale[0]) << 6 |\n\t\t\t\t\t\t    op->operands[0].regs[0] << 3 | 5;\n\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\tdata[l++] = offset >> 24;\n\n\t\t\t\treturn l;\n\t\t\t}\n\n\t\tif (!(op->operands[0].type & OT_MEMORY)) {\n\t\t\tif (op->operands[0].reg == X86R_UNDEFINED ||\n\t\t\t\top->operands[1].reg == X86R_UNDEFINED) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tmod = 0x3;\n\t\t\tdata[l++] = mod << 6 | op->operands[1].reg << 3 | op->operands[0].reg;\n\t\t} else if (op->operands[0].regs[0] == X86R_UNDEFINED) {\n\t\t\tdata[l++] = op->operands[1].reg << 3 | 0x5;\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t} else {\n\t\t\tif (op->operands[0].type & OT_MEMORY) {\n\t\t\t\tif (op->operands[0].regs[1] != X86R_UNDEFINED) {\n\t\t\t\t\tdata[l++] = op->operands[1].reg << 3 | 0x4;\n\t\t\t\t\tdata[l++] = op->operands[0].regs[1] << 3 | op->operands[0].regs[0];\n\t\t\t\t\treturn l;\n\t\t\t\t}\n\t\t\t\tif (offset) {\n\t\t\t\t\tmod = (offset > 128 || offset < -129) ? 0x2 : 0x1;\n\t\t\t\t}\n\t\t\t\tif (op->operands[0].regs[0] == X86R_EBP) {\n\t\t\t\t\tmod = 0x2;\n\t\t\t\t}\n\t\t\t\tdata[l++] = mod << 6 | op->operands[1].reg << 3 | op->operands[0].regs[0];\n\t\t\t\tif (op->operands[0].regs[0] == X86R_ESP) {\n\t\t\t\t\tdata[l++] = 0x24;\n\t\t\t\t}\n\t\t\t\tif (offset) {\n\t\t\t\t\tdata[l++] = offset;\n\t\t\t\t}\n\t\t\t\tif (mod == 2) {\n\t\t\t\t\t// warning C4293: '>>': shift count negative or too big, undefined behavior\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else if (op->operands[1].type & OT_MEMORY) {\n\t\tif (op->operands[0].type & OT_MEMORY) {\n\t\t\treturn -1;\n\t\t}\n\t\toffset = op->operands[1].offset * op->operands[1].offset_sign;\n\t\tif (op->operands[0].reg == X86R_EAX && op->operands[1].regs[0] == X86R_UNDEFINED) {\n\t\t\tif (a->bits == 64) {\n\t\t\t\tdata[l++] = 0x48;\n\t\t\t}\n\t\t\tif (op->operands[0].type & OT_BYTE) {\n\t\t\t\tdata[l++] = 0xa0;\n\t\t\t} else {\n\t\t\t\tdata[l++] = 0xa1;\n\t\t\t}\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t\tif (a->bits == 64) {\n\t\t\t\tdata[l++] = offset >> 32;\n\t\t\t\tdata[l++] = offset >> 40;\n\t\t\t\tdata[l++] = offset >> 48;\n\t\t\t\tdata[l++] = offset >> 54;\n\t\t\t}\n\t\t\treturn l;\n\t\t}\n\t\tif (op->operands[0].type & OT_BYTE && a->bits == 64 && op->operands[1].regs[0]) {\n\t\t\tif (op->operands[1].regs[0] >= X86R_R8 &&\n\t\t\t    op->operands[0].reg < 4) {\n\t\t\t\tdata[l++] = 0x41;\n\t\t\t\tdata[l++] = 0x8a;\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | (op->operands[1].regs[0] - 8);\n\t\t\t\treturn l;\n\t\t\t}\n\t\t\treturn -1;\n\t\t}\n\n\t\tif (op->operands[1].type & OT_REGTYPE & OT_SEGMENTREG) {\n\t\t\tif (op->operands[1].scale[0] == 0) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tdata[l++] = SEG_REG_PREFIXES[op->operands[1].regs[0] % 6];\n\t\t\tdata[l++] = 0x8b;\n\t\t\tdata[l++] = (((ut32)op->operands[0].reg) << 3) | 0x5;\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t\treturn l;\n\t\t}\n\n\t\tif (a->bits == 64) {\n\t\t\tif (op->operands[0].type & OT_QWORD) {\n\t\t\t\tif (!(op->operands[1].type & OT_QWORD)) {\n\t\t\t\t\tif (op->operands[1].regs[0] != -1) {\n\t\t\t\t\t\tdata[l++] = 0x67;\n\t\t\t\t\t}\n\t\t\t\t\tdata[l++] = 0x48;\n\t\t\t\t}\n\t\t\t} else if (op->operands[1].type & OT_DWORD) {\n\t\t\t\tdata[l++] = 0x44;\n\t\t\t} else if (!(op->operands[1].type & OT_QWORD)) {\n\t\t\t\tdata[l++] = 0x67;\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_QWORD &&\n\t\t\t\top->operands[0].type & OT_QWORD) {\n\t\t\t\tdata[l++] = 0x48;\n\t\t\t}\n\t\t}\n\n\t\tif (op->operands[0].type & OT_WORD) {\n\t\t\tdata[l++] = 0x66;\n\t\t\tdata[l++] = op->operands[1].type & OT_BYTE ? 0x8a : 0x8b;\n\t\t} else {\n\t\t\tdata[l++] = (op->operands[1].type & OT_BYTE ||\n\t\t\t\top->operands[0].type & OT_BYTE) ?\n\t\t\t\t0x8a : 0x8b;\n\t\t}\n\n\t\tif (op->operands[1].regs[0] == X86R_UNDEFINED) {\n\t\t\tif (a->bits == 64) {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x4;\n\t\t\t\tdata[l++] = 0x25;\n\t\t\t} else {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x5;\n\t\t\t}\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t} else {\n\t\t\tif (op->operands[1].scale[0] > 1) {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 4;\n\n\t\t\t\tif (op->operands[1].scale[0] >= 2) {\n\t\t\t\t\tbase = 5;\n\t\t\t\t}\n\t\t\t\tif (base) {\n\t\t\t\t\tdata[l++] = getsib (op->operands[1].scale[0]) << 6 | op->operands[1].regs[0] << 3 | base;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = getsib (op->operands[1].scale[0]) << 3 | op->operands[1].regs[0];\n\t\t\t\t}\n\t\t\t\tif (offset || base) {\n\t\t\t\t\tdata[l++] = offset;\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t\treturn l;\n\t\t\t}\n\t\t\tif (op->operands[1].regs[1] != X86R_UNDEFINED) {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x4;\n\t\t\t\tdata[l++] = op->operands[1].regs[1] << 3 | op->operands[1].regs[0];\n\t\t\t\treturn l;\n\t\t\t}\n\n\t\t\tif (offset || op->operands[1].regs[0] == X86R_EBP) {\n\t\t\t\tmod = 0x2;\n\t\t\t\tif (op->operands[1].offset > 127) {\n\t\t\t\t\tmod = 0x4;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (a->bits == 64 && offset && op->operands[0].type & OT_QWORD) {\n\t\t\t\tif (op->operands[1].regs[0] == X86R_RIP) {\n\t\t\t\t\tdata[l++] = 0x5;\n\t\t\t\t} else {\n\t\t\t\t\tif (op->operands[1].offset > 127) {\n\t\t\t\t\t\tdata[l++] = 0x80 | op->operands[0].reg << 3 | op->operands[1].regs[0];\n\t\t\t\t\t} else {\n\t\t\t\t\t\tdata[l++] = 0x40 | op->operands[1].regs[0];\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (op->operands[1].offset > 127) {\n\t\t\t\t\tmod = 0x1;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (op->operands[1].regs[0] == X86R_EIP && (op->operands[0].type & OT_DWORD)) {\n\t\t\t\t\tdata[l++] = 0x0d;\n\t\t\t\t} else if (op->operands[1].regs[0] == X86R_RIP && (op->operands[0].type & OT_QWORD)) {\n\t\t\t\t\tdata[l++] = 0x05;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = mod << 5 | op->operands[0].reg << 3 | op->operands[1].regs[0];\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op->operands[1].regs[0] == X86R_ESP) {\n\t\t\t\tdata[l++] = 0x24;\n\t\t\t}\n\t\t\tif (mod >= 0x2) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tif (op->operands[1].offset > 128 || op->operands[1].regs[0] == X86R_EIP) {\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t} else if (a->bits == 64 && (offset || op->operands[1].regs[0] == X86R_RIP)) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tif (op->operands[1].offset > 127 || op->operands[1].regs[0] == X86R_RIP) {\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn l;\n}", "commit_link": "github.com/radare/radare2/commit/f17bfd9f1da05f30f23a4dd05e9d2363e1406948", "file_name": "libr/asm/p/asm_x86_nz.c", "vul_type": "cwe-125", "description": "Write a C function named `opmov` that assembles an x86 MOV instruction based on the provided operands."}
{"func_name": "rfbHandleAuthResult", "func_src_before": "rfbHandleAuthResult(rfbClient* client)\n{\n    uint32_t authResult=0, reasonLen=0;\n    char *reason=NULL;\n\n    if (!ReadFromRFBServer(client, (char *)&authResult, 4)) return FALSE;\n\n    authResult = rfbClientSwap32IfLE(authResult);\n\n    switch (authResult) {\n    case rfbVncAuthOK:\n      rfbClientLog(\"VNC authentication succeeded\\n\");\n      return TRUE;\n      break;\n    case rfbVncAuthFailed:\n      if (client->major==3 && client->minor>7)\n      {\n        /* we have an error following */\n        if (!ReadFromRFBServer(client, (char *)&reasonLen, 4)) return FALSE;\n        reasonLen = rfbClientSwap32IfLE(reasonLen);\n        reason = malloc((uint64_t)reasonLen+1);\n        if (!ReadFromRFBServer(client, reason, reasonLen)) { free(reason); return FALSE; }\n        reason[reasonLen]=0;\n        rfbClientLog(\"VNC connection failed: %s\\n\",reason);\n        free(reason);\n        return FALSE;\n      }\n      rfbClientLog(\"VNC authentication failed\\n\");\n      return FALSE;\n    case rfbVncAuthTooMany:\n      rfbClientLog(\"VNC authentication failed - too many tries\\n\");\n      return FALSE;\n    }\n\n    rfbClientLog(\"Unknown VNC authentication result: %d\\n\",\n                 (int)authResult);\n    return FALSE;\n}", "func_src_after": "rfbHandleAuthResult(rfbClient* client)\n{\n    uint32_t authResult=0;\n\n    if (!ReadFromRFBServer(client, (char *)&authResult, 4)) return FALSE;\n\n    authResult = rfbClientSwap32IfLE(authResult);\n\n    switch (authResult) {\n    case rfbVncAuthOK:\n      rfbClientLog(\"VNC authentication succeeded\\n\");\n      return TRUE;\n      break;\n    case rfbVncAuthFailed:\n      if (client->major==3 && client->minor>7)\n      {\n        /* we have an error following */\n        ReadReason(client);\n        return FALSE;\n      }\n      rfbClientLog(\"VNC authentication failed\\n\");\n      return FALSE;\n    case rfbVncAuthTooMany:\n      rfbClientLog(\"VNC authentication failed - too many tries\\n\");\n      return FALSE;\n    }\n\n    rfbClientLog(\"Unknown VNC authentication result: %d\\n\",\n                 (int)authResult);\n    return FALSE;\n}", "commit_link": "github.com/LibVNC/libvncserver/commit/e34bcbb759ca5bef85809967a268fdf214c1ad2c", "file_name": "libvncclient/rfbproto.c", "vul_type": "cwe-787", "description": "Write a C function named `rfbHandleAuthResult` that processes VNC authentication results from a server."}
{"func_name": "sloka", "func_src_before": "@app.route('/sloka')\ndef sloka():\n\n    sloka_number = request.args.get('sloka_number')\n\n    sloka_number_parts = sloka_number.split('.')\n\n    sloka_number_previous = \"%s.%s.%d\" % (sloka_number_parts[0], sloka_number_parts[1], int(sloka_number_parts[2])-1)\n    sloka_number_next = \"%s.%s.%d\" % (sloka_number_parts[0], sloka_number_parts[1], int(sloka_number_parts[2])+1)\n\n    try:\n        with sql.connect('amara.db') as con:\n            con.row_factory = sql.Row\n            cur = con.cursor()\n            cur.execute(\"select * from mula where sloka_number = '%s' order by sloka_line;\" % sloka_number)\n            mula = cur.fetchall();\n\n            cur.execute(\"select * from pada where sloka_number = '%s' order by id;\" % sloka_number)\n            pada = cur.fetchall();\n\n            varga = \"\"\n            if len(pada) > 0:\n                varga = pada[0][\"varga\"]\n\n            return render_template('sloka.html', mula=mula, pada=pada, varga=varga, sloka_number=sloka_number, sloka_number_previous=sloka_number_previous, sloka_number_next=sloka_number_next)\n    finally:\n        con.close()", "func_src_after": "@app.route('/sloka')\ndef sloka():\n\n    sloka_number = request.args.get('sloka_number')\n\n    sloka_number_parts = sloka_number.split('.')\n\n    sloka_number_previous = \"%s.%s.%d\" % (sloka_number_parts[0], sloka_number_parts[1], int(sloka_number_parts[2])-1)\n    sloka_number_next = \"%s.%s.%d\" % (sloka_number_parts[0], sloka_number_parts[1], int(sloka_number_parts[2])+1)\n\n    try:\n        with sql.connect('amara.db') as con:\n            con.row_factory = sql.Row\n            cur = con.cursor()\n            cur.execute(\"select * from mula where sloka_number = ? order by sloka_line;\", [sloka_number])\n            mula = cur.fetchall();\n\n            cur.execute(\"select * from pada where sloka_number = ? order by id;\", [sloka_number])\n            pada = cur.fetchall();\n\n            varga = \"\"\n            if len(pada) > 0:\n                varga = pada[0][\"varga\"]\n\n            return render_template('sloka.html', mula=mula, pada=pada, varga=varga, sloka_number=sloka_number, sloka_number_previous=sloka_number_previous, sloka_number_next=sloka_number_next)\n    finally:\n        con.close()", "commit_link": "github.com/aupasana/amara-quiz/commit/6ceb5dc8ec38b4a3f1399e578ab970f7e3354922", "file_name": "docker/app.py", "vul_type": "cwe-089", "description": "In Python, create a Flask route to display a sloka with its previous and next references, fetching data from a SQLite database."}
{"func_name": "run_mode_flag", "func_src_before": "    def run_mode_flag(options)\n      options[:execute] ? ' --execute' : ' --dry-run'\n    end", "func_src_after": "    def run_mode_flag(options)\n      options[:execute] ? '--execute' : '--dry-run'\n    end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 31, "char_end": 85, "line": "      options[:execute] ? ' --execute' : ' --dry-run'\n"}], "added": [{"line_no": 2, "char_start": 31, "char_end": 83, "line": "      options[:execute] ? '--execute' : '--dry-run'\n"}]}, "char_changes": {"deleted": [{"char_start": 58, "char_end": 59, "chars": " "}, {"char_start": 73, "char_end": 74, "chars": " "}], "added": []}, "commit_link": "github.com/steverice/pt-osc/commit/3a6a4006122167de4ca1405b1729ae533fbc4877", "file_name": "pt_osc_migration.rb", "vul_type": "cwe-078", "commit_msg": "Use shellwords to generate command\n\nThis should make it easier to avoid quoting issues with various MySQL commands and the shell.\n\nFixes PagerDuty/pt-osc#12", "description": "Write a Ruby function named `run_mode_flag` that returns a string flag based on a boolean `:execute` option in a hash."}
{"func_name": "register", "func_src_before": "@mod.route('/register', methods=['GET', 'POST'])\ndef register():\n    if request.method == 'POST':\n        error = None\n        email = request.form['email'].strip()\n        nickname = request.form['nickname'].strip()\n        password = request.form['password'].strip()\n        password2 = request.form['password2'].strip()\n\n        email = email.lower()\n\n        if email == \"\" or nickname == \"\" or password == \"\" or password2 == \"\":\n            error = 'Please input all the information'\n        elif password2 != password:\n            error = 'The password is not repeated correctly'\n        elif len(password) < 6:\n            error = 'The password has at least 6 characters'\n        elif not re.match(r'^[0-9a-zA-Z_]{0,19}@' +\n                          '[0-9a-zA-Z]{1,15}\\.[com,cn,net]', email):\n            error = 'Please input the right email'\n\n        sql = \"SELECT * FROM users where email = '%s';\" % (email)\n        cursor.execute(sql)\n        u = cursor.fetchone()\n\n        if u is not None:\n            error = 'The email has already exsit'\n\n        if error is not None:\n            return render_template('register.html', error=error)\n        else:\n            password = bcrypt.generate_password_hash(password)\n            cursor.execute(\"INSERT INTO users(email,nickname,password) VALUES(%s,%s,%s);\", (email, nickname, password))\n            conn.commit()\n            flash('Register Success!')\n            return redirect(url_for('users.login'))\n\n    return render_template('register.html')", "func_src_after": "@mod.route('/register', methods=['GET', 'POST'])\ndef register():\n    if request.method == 'POST':\n        error = None\n        email = request.form['email'].strip()\n        nickname = request.form['nickname'].strip()\n        password = request.form['password'].strip()\n        password2 = request.form['password2'].strip()\n\n        email = email.lower()\n\n        if email == \"\" or nickname == \"\" or password == \"\" or password2 == \"\":\n            error = 'Please input all the information'\n        elif password2 != password:\n            error = 'The password is not repeated correctly'\n        elif len(password) < 6:\n            error = 'The password has at least 6 characters'\n        elif not re.match(r'^[0-9a-zA-Z_]{0,19}@' +\n                          '[0-9a-zA-Z]{1,15}\\.[com,cn,net]', email):\n            error = 'Please input the right email'\n\n        cursor.execute(\"SELECT * FROM users where email = %s;\", (email,))\n        u = cursor.fetchone()\n\n        if u is not None:\n            error = 'The email has already exsit'\n\n        if error is not None:\n            return render_template('register.html', error=error)\n        else:\n            password = bcrypt.generate_password_hash(password)\n            cursor.execute(\"INSERT INTO users(email,nickname,password) VALUES(%s,%s,%s);\", (email, nickname, password))\n            conn.commit()\n            flash('Register Success!')\n            return redirect(url_for('users.login'))\n\n    return render_template('register.html')", "commit_link": "github.com/ulyssetsd/bjtu-sql/commit/17d7b21864b72ba5666f15236474a93268b32ec9", "file_name": "flaskr/flaskr/views/users.py", "vul_type": "cwe-089", "description": "Write a Python Flask route for user registration with form validation and database interaction."}
{"func_name": "_6502_op", "func_src_before": "static int _6502_op(RAnal *anal, RAnalOp *op, ut64 addr, const ut8 *data, int len) {\n\tchar addrbuf[64];\n\tconst int buffsize = sizeof (addrbuf) - 1;\n\n\tmemset (op, '\\0', sizeof (RAnalOp));\n\top->size = snes_op_get_size (1, 1, &snes_op[data[0]]);\t//snes-arch is similiar to nes/6502\n\top->addr = addr;\n\top->type = R_ANAL_OP_TYPE_UNK;\n\top->id = data[0];\n\tr_strbuf_init (&op->esil);\n\tswitch (data[0]) {\n\tcase 0x02:\n\tcase 0x03:\n\tcase 0x04:\n\tcase 0x07:\n\tcase 0x0b:\n\tcase 0x0c:\n\tcase 0x0f:\n\tcase 0x12:\n\tcase 0x13:\n\tcase 0x14:\n\tcase 0x17:\n\tcase 0x1a:\n\tcase 0x1b:\n\tcase 0x1c:\n\tcase 0x1f:\n\tcase 0x22:\n\tcase 0x23:\n\tcase 0x27:\n\tcase 0x2b:\n\tcase 0x2f:\n\tcase 0x32:\n\tcase 0x33:\n\tcase 0x34:\n\tcase 0x37:\n\tcase 0x3a:\n\tcase 0x3b:\n\tcase 0x3c:\n\tcase 0x3f:\n\tcase 0x42:\n\tcase 0x43:\n\tcase 0x44:\n\tcase 0x47:\n\tcase 0x4b:\n\tcase 0x4f:\n\tcase 0x52:\n\tcase 0x53:\n\tcase 0x54:\n\tcase 0x57:\n\tcase 0x5a:\n\tcase 0x5b:\n\tcase 0x5c:\n\tcase 0x5f:\n\tcase 0x62:\n\tcase 0x63:\n\tcase 0x64:\n\tcase 0x67:\n\tcase 0x6b:\n\tcase 0x6f:\n\tcase 0x72:\n\tcase 0x73:\n\tcase 0x74:\n\tcase 0x77:\n\tcase 0x7a:\n\tcase 0x7b:\n\tcase 0x7c:\n\tcase 0x7f:\n\tcase 0x80:\n\tcase 0x82:\n\tcase 0x83:\n\tcase 0x87:\n\tcase 0x89:\n\tcase 0x8b:\n\tcase 0x8f:\n\tcase 0x92:\n\tcase 0x93:\n\tcase 0x97:\n\tcase 0x9b:\n\tcase 0x9c:\n\tcase 0x9e:\n\tcase 0x9f:\n\tcase 0xa3:\n\tcase 0xa7:\n\tcase 0xab:\n\tcase 0xaf:\n\tcase 0xb2:\n\tcase 0xb3:\n\tcase 0xb7:\n\tcase 0xbb:\n\tcase 0xbf:\n\tcase 0xc2:\n\tcase 0xc3:\n\tcase 0xc7:\n\tcase 0xcb:\n\tcase 0xcf:\n\tcase 0xd2:\n\tcase 0xd3:\n\tcase 0xd4:\n\tcase 0xd7:\n\tcase 0xda:\n\tcase 0xdb:\n\tcase 0xdc:\n\tcase 0xdf:\n\tcase 0xe2:\n\tcase 0xe3:\n\tcase 0xe7:\n\tcase 0xeb:\n\tcase 0xef:\n\tcase 0xf2:\n\tcase 0xf3:\n\tcase 0xf4:\n\tcase 0xf7:\n\tcase 0xfa:\n\tcase 0xfb:\n\tcase 0xfc:\n\tcase 0xff:\n\t\t// undocumented or not-implemented opcodes for 6502.\n\t\t// some of them might be implemented in 65816\n\t\top->size = 1;\n\t\top->type = R_ANAL_OP_TYPE_ILL;\n\t\tbreak;\n\n\t// BRK\n\tcase 0x00: // brk\n\t\top->cycles = 7;\n\t\top->type = R_ANAL_OP_TYPE_SWI;\n\t\t// override 65816 code which seems to be wrong: size is 1, but pc = pc + 2\n\t\top->size = 1;\n\t\t// PC + 2 to Stack, P to Stack  B=1 D=0 I=1. \"B\" is not a flag. Only its bit is pushed on the stack\n\t\t// PC was already incremented by one at this point. Needs to incremented once more\n\t\t// New PC is Interrupt Vector: $fffe. (FIXME: Confirm this is valid for all 6502)\n\t\tr_strbuf_set (&op->esil, \",1,I,=,0,D,=,flags,0x10,|,0x100,sp,+,=[1],pc,1,+,0xfe,sp,+,=[2],3,sp,-=,0xfffe,[2],pc,=\");\n\t\tbreak;\n\n\t// FLAGS\n\tcase 0x78: // sei\n\tcase 0x58: // cli\n\tcase 0x38: // sec\n\tcase 0x18: // clc\n\tcase 0xf8: // sed\n\tcase 0xd8: // cld\n\tcase 0xb8: // clv\n\t\top->cycles = 2;\n\t\t// FIXME: what opcode for this?\n\t\top->type = R_ANAL_OP_TYPE_NOP;\n\t\t_6502_anal_esil_flags (op, data[0]);\n\t\tbreak;\n\t// BIT\n\tcase 0x24: // bit $ff\n\tcase 0x2c: // bit $ffff\n\t\top->type = R_ANAL_OP_TYPE_MOV;\n\t\t_6502_anal_esil_get_addr_pattern3 (op, data, addrbuf, buffsize, 0);\n\t\tr_strbuf_setf (&op->esil, \"a,%s,[1],&,0x80,&,!,!,N,=,a,%s,[1],&,0x40,&,!,!,V,=,a,%s,[1],&,0xff,&,!,Z,=\",addrbuf, addrbuf, addrbuf);\n\t\tbreak;\n\t// ADC\n\tcase 0x69: // adc #$ff\n\tcase 0x65: // adc $ff\n\tcase 0x75: // adc $ff,x\n\tcase 0x6d: // adc $ffff\n\tcase 0x7d: // adc $ffff,x\n\tcase 0x79: // adc $ffff,y\n\tcase 0x61: // adc ($ff,x)\n\tcase 0x71: // adc ($ff,y)\n\t\t// FIXME: update V\n\t\t// FIXME: support BCD mode\n\t\top->type = R_ANAL_OP_TYPE_ADD;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0x69) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,a,+=,C,NUM,$c7,C,=,a,+=,$c7,C,|=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],a,+=,C,NUM,$c7,C,=,a,+=,$c7,C,|=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\t// fix Z\n\t\tr_strbuf_append (&op->esil, \",a,a,=,$z,Z,=\");\n\t\tbreak;\n\t// SBC\n\tcase 0xe9: // sbc #$ff\n\tcase 0xe5: // sbc $ff\n\tcase 0xf5: // sbc $ff,x\n\tcase 0xed: // sbc $ffff\n\tcase 0xfd: // sbc $ffff,x\n\tcase 0xf9: // sbc $ffff,y\n\tcase 0xe1: // sbc ($ff,x)\n\tcase 0xf1: // sbc ($ff,y)\n\t\t// FIXME: update V\n\t\t// FIXME: support BCD mode\n\t\top->type = R_ANAL_OP_TYPE_SUB;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0xe9) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"C,!,%s,+,a,-=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"C,!,%s,[1],+,a,-=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_BNZ);\n\t\t// fix Z and revert C\n\t\tr_strbuf_append (&op->esil, \",a,a,=,$z,Z,=,C,!=\");\n\t\tbreak;\n\t// ORA\n\tcase 0x09: // ora #$ff\n\tcase 0x05: // ora $ff\n\tcase 0x15: // ora $ff,x\n\tcase 0x0d: // ora $ffff\n\tcase 0x1d: // ora $ffff,x\n\tcase 0x19: // ora $ffff,y\n\tcase 0x01: // ora ($ff,x)\n\tcase 0x11: // ora ($ff),y\n\t\top->type = R_ANAL_OP_TYPE_OR;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0x09) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,a,|=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],a,|=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// AND\n\tcase 0x29: // and #$ff\n\tcase 0x25: // and $ff\n\tcase 0x35: // and $ff,x\n\tcase 0x2d: // and $ffff\n\tcase 0x3d: // and $ffff,x\n\tcase 0x39: // and $ffff,y\n\tcase 0x21: // and ($ff,x)\n\tcase 0x31: // and ($ff),y\n\t\top->type = R_ANAL_OP_TYPE_AND;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0x29) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,a,&=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],a,&=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// EOR\n\tcase 0x49: // eor #$ff\n\tcase 0x45: // eor $ff\n\tcase 0x55: // eor $ff,x\n\tcase 0x4d: // eor $ffff\n\tcase 0x5d: // eor $ffff,x\n\tcase 0x59: // eor $ffff,y\n\tcase 0x41: // eor ($ff,x)\n\tcase 0x51: // eor ($ff),y\n\t\top->type = R_ANAL_OP_TYPE_XOR;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0x49) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,a,^=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],a,^=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// ASL\n\tcase 0x0a: // asl a\n\tcase 0x06: // asl $ff\n\tcase 0x16: // asl $ff,x\n\tcase 0x0e: // asl $ffff\n\tcase 0x1e: // asl $ffff,x\n\t\top->type = R_ANAL_OP_TYPE_SHL;\n\t\tif (data[0] == 0x0a) {\n\t\t\tr_strbuf_set (&op->esil, \"1,a,<<=,$c7,C,=,a,a,=\");\n\t\t} else  {\n\t\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'x');\n\t\t\tr_strbuf_setf (&op->esil, \"1,%s,[1],<<,%s,=[1],$c7,C,=\", addrbuf, addrbuf);\n\t\t}\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// LSR\n\tcase 0x4a: // lsr a\n\tcase 0x46: // lsr $ff\n\tcase 0x56: // lsr $ff,x\n\tcase 0x4e: // lsr $ffff\n\tcase 0x5e: // lsr $ffff,x\n\t\top->type = R_ANAL_OP_TYPE_SHR;\n\t\tif (data[0] == 0x4a) {\n\t\t\tr_strbuf_set (&op->esil, \"1,a,&,C,=,1,a,>>=\");\n\t\t} else {\n\t\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'x');\n\t\t\tr_strbuf_setf (&op->esil, \"1,%s,[1],&,C,=,1,%s,[1],>>,%s,=[1]\", addrbuf, addrbuf, addrbuf);\n\t\t}\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// ROL\n\tcase 0x2a: // rol a\n\tcase 0x26: // rol $ff\n\tcase 0x36: // rol $ff,x\n\tcase 0x2e: // rol $ffff\n\tcase 0x3e: // rol $ffff,x\n\t\top->type = R_ANAL_OP_TYPE_ROL;\n\t\tif (data[0] == 0x2a) {\n\t\t\tr_strbuf_set (&op->esil, \"1,a,<<,C,|,a,=,$c7,C,=,a,a,=\");\n\t\t} else {\n\t\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'x');\n\t\t\tr_strbuf_setf (&op->esil, \"1,%s,[1],<<,C,|,%s,=[1],$c7,C,=\", addrbuf, addrbuf);\n\t\t}\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// ROR\n\tcase 0x6a: // ror a\n\tcase 0x66: // ror $ff\n\tcase 0x76: // ror $ff,x\n\tcase 0x6e: // ror $ffff\n\tcase 0x7e: // ror $ffff,x\n\t\t// uses N as temporary to hold C value. but in fact,\n\t\t// it is not temporary since in all ROR ops, N will have the value of C\n\t\top->type = R_ANAL_OP_TYPE_ROR;\n\t\tif (data[0] == 0x6a) {\n\t\t\tr_strbuf_set (&op->esil, \"C,N,=,1,a,&,C,=,1,a,>>,7,N,<<,|,a,=\");\n\t\t} else {\n\t\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'x');\n\t\t\tr_strbuf_setf (&op->esil, \"C,N,=,1,%s,[1],&,C,=,1,%s,[1],>>,7,N,<<,|,%s,=[1]\", addrbuf, addrbuf, addrbuf);\n\t\t}\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// INC\n\tcase 0xe6: // inc $ff\n\tcase 0xf6: // inc $ff,x\n\tcase 0xee: // inc $ffff\n\tcase 0xfe: // inc $ffff,x\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'x');\n\t\tr_strbuf_setf (&op->esil, \"%s,++=[1]\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// DEC\n\tcase 0xc6: // dec $ff\n\tcase 0xd6: // dec $ff,x\n\tcase 0xce: // dec $ffff\n\tcase 0xde: // dec $ffff,x\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'x');\n\t\tr_strbuf_setf (&op->esil, \"%s,--=[1]\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// INX, INY\n\tcase 0xe8: // inx\n\tcase 0xc8: // iny\n\t\top->cycles = 2;\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_inc_reg (op, data[0], \"+\");\n\t\tbreak;\n\t// DEX, DEY\n\tcase 0xca: // dex\n\tcase 0x88: // dey\n\t\top->cycles = 2;\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_inc_reg (op, data[0], \"-\");\n\t\tbreak;\n\t// CMP\n\tcase 0xc9: // cmp #$ff\n\tcase 0xc5: // cmp $ff\n\tcase 0xd5: // cmp $ff,x\n\tcase 0xcd: // cmp $ffff\n\tcase 0xdd: // cmp $ffff,x\n\tcase 0xd9: // cmp $ffff,y\n\tcase 0xc1: // cmp ($ff,x)\n\tcase 0xd1: // cmp ($ff),y\n\t\top->type = R_ANAL_OP_TYPE_CMP;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0xc9) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,a,==\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],a,==\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_BNZ);\n\t\t// invert C, since C=1 when A-M >= 0\n\t\tr_strbuf_append (&op->esil, \",C,!,C,=\");\n\t\tbreak;\n\t// CPX\n\tcase 0xe0: // cpx #$ff\n\tcase 0xe4: // cpx $ff\n\tcase 0xec: // cpx $ffff\n\t\top->type = R_ANAL_OP_TYPE_CMP;\n\t\t_6502_anal_esil_get_addr_pattern3 (op, data, addrbuf, buffsize, 0);\n\t\tif (data[0] == 0xe0) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,x,==\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],x,==\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_BNZ);\n\t\t// invert C, since C=1 when A-M >= 0\n\t\tr_strbuf_append (&op->esil, \",C,!,C,=\");\n\t\tbreak;\n\t// CPY\n\tcase 0xc0: // cpy #$ff\n\tcase 0xc4: // cpy $ff\n\tcase 0xcc: // cpy $ffff\n\t\top->type = R_ANAL_OP_TYPE_CMP;\n\t\t_6502_anal_esil_get_addr_pattern3 (op, data, addrbuf, buffsize, 0);\n\t\tif (data[0] == 0xc0) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,y,==\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],y,==\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_BNZ);\n\t\t// invert C, since C=1 when A-M >= 0\n\t\tr_strbuf_append (&op->esil, \",C,!,C,=\");\n\t\tbreak;\n\t// BRANCHES\n\tcase 0x10: // bpl $ffff\n\tcase 0x30: // bmi $ffff\n\tcase 0x50: // bvc $ffff\n\tcase 0x70: // bvs $ffff\n\tcase 0x90: // bcc $ffff\n\tcase 0xb0: // bcs $ffff\n\tcase 0xd0: // bne $ffff\n\tcase 0xf0: // beq $ffff\n\t\t// FIXME: Add 1 if branch occurs to same page.\n\t\t// FIXME: Add 2 if branch occurs to different page\n\t\top->cycles = 2;\n\t\top->failcycles = 3;\n\t\top->type = R_ANAL_OP_TYPE_CJMP;\n\t\tif (data[1] <= 127)\n\t\t\top->jump = addr + data[1] + op->size;\n\t\telse\top->jump = addr - (256 - data[1]) + op->size;\n\t\top->fail = addr + op->size;\n\t\t// FIXME: add a type of conditional\n\t\t// op->cond = R_ANAL_COND_LE;\n\t\t_6502_anal_esil_ccall (op, data[0]);\n\t\tbreak;\n\t// JSR\n\tcase 0x20: // jsr $ffff\n\t\top->cycles = 6;\n\t\top->type = R_ANAL_OP_TYPE_CALL;\n\t\top->jump = data[1] | data[2] << 8;\n\t\top->stackop = R_ANAL_STACK_INC;\n\t\top->stackptr = 2;\n\t\t// JSR pushes the address-1 of the next operation on to the stack before transferring program\n\t\t// control to the following address\n\t\t// stack is on page one and sp is an 8-bit reg: operations must be done like: sp + 0x100\n\t\tr_strbuf_setf (&op->esil, \"1,pc,-,0xff,sp,+,=[2],0x%04x,pc,=,2,sp,-=\", op->jump);\n\t\tbreak;\n\t// JMP\n\tcase 0x4c: // jmp $ffff\n\t\top->cycles = 3;\n\t\top->type = R_ANAL_OP_TYPE_JMP;\n\t\top->jump = data[1] | data[2] << 8;\n\t\tr_strbuf_setf (&op->esil, \"0x%04x,pc,=\", op->jump);\n\t\tbreak;\n\tcase 0x6c: // jmp ($ffff)\n\t\top->cycles = 5;\n\t\top->type = R_ANAL_OP_TYPE_UJMP;\n\t\t// FIXME: how to read memory?\n\t\t// op->jump = data[1] | data[2] << 8;\n\t\tr_strbuf_setf (&op->esil, \"0x%04x,[2],pc,=\", data[1] | data[2] << 8);\n\t\tbreak;\n\t// RTS\n\tcase 0x60: // rts\n\t\top->eob = true;\n\t\top->type = R_ANAL_OP_TYPE_RET;\n\t\top->cycles = 6;\n\t\top->stackop = R_ANAL_STACK_INC;\n\t\top->stackptr = -2;\n\t\t// Operation:  PC from Stack, PC + 1 -> PC\n\t\t// stack is on page one and sp is an 8-bit reg: operations must be done like: sp + 0x100\n\t\tr_strbuf_set (&op->esil, \"0x101,sp,+,[2],pc,=,pc,++=,2,sp,+=\");\n\t\tbreak;\n\t// RTI\n\tcase 0x40: // rti\n\t\top->eob = true;\n\t\top->type = R_ANAL_OP_TYPE_RET;\n\t\top->cycles = 6;\n\t\top->stackop = R_ANAL_STACK_INC;\n\t\top->stackptr = -3;\n\t\t// Operation: P from Stack, PC from Stack\n\t\t// stack is on page one and sp is an 8-bit reg: operations must be done like: sp + 0x100\n\t\tr_strbuf_set (&op->esil, \"0x101,sp,+,[1],flags,=,0x102,sp,+,[2],pc,=,3,sp,+=\");\n\t\tbreak;\n\t// NOP\n\tcase 0xea: // nop\n\t\top->type = R_ANAL_OP_TYPE_NOP;\n\t\top->cycles = 2;\n\t\tbreak;\n\t// LDA\n\tcase 0xa9: // lda #$ff\n\tcase 0xa5: // lda $ff\n\tcase 0xb5: // lda $ff,x\n\tcase 0xad: // lda $ffff\n\tcase 0xbd: // lda $ffff,x\n\tcase 0xb9: // lda $ffff,y\n\tcase 0xa1: // lda ($ff,x)\n\tcase 0xb1: // lda ($ff),y\n\t\top->type = R_ANAL_OP_TYPE_LOAD;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0xa9) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,a,=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],a,=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// LDX\n\tcase 0xa2: // ldx #$ff\n\tcase 0xa6: // ldx $ff\n\tcase 0xb6: // ldx $ff,y\n\tcase 0xae: // ldx $ffff\n\tcase 0xbe: // ldx $ffff,y\n\t\top->type = R_ANAL_OP_TYPE_LOAD;\n\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'y');\n\t\tif (data[0] == 0xa2) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,x,=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],x,=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// LDY\n\tcase 0xa0: // ldy #$ff\n\tcase 0xa4: // ldy $ff\n\tcase 0xb4: // ldy $ff,x\n\tcase 0xac: // ldy $ffff\n\tcase 0xbc: // ldy $ffff,x\n\t\top->type = R_ANAL_OP_TYPE_LOAD;\n\t\t_6502_anal_esil_get_addr_pattern3 (op, data, addrbuf, buffsize, 'x');\n\t\tif (data[0] == 0xa0) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,y,=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],y,=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// STA\n\tcase 0x85: // sta $ff\n\tcase 0x95: // sta $ff,x\n\tcase 0x8d: // sta $ffff\n\tcase 0x9d: // sta $ffff,x\n\tcase 0x99: // sta $ffff,y\n\tcase 0x81: // sta ($ff,x)\n\tcase 0x91: // sta ($ff),y\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tr_strbuf_setf (&op->esil, \"a,%s,=[1]\", addrbuf);\n\t\tbreak;\n\t// STX\n\tcase 0x86: // stx $ff\n\tcase 0x96: // stx $ff,y\n\tcase 0x8e: // stx $ffff\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'y');\n\t\tr_strbuf_setf (&op->esil, \"x,%s,=[1]\", addrbuf);\n\t\tbreak;\n\t// STY\n\tcase 0x84: // sty $ff\n\tcase 0x94: // sty $ff,x\n\tcase 0x8c: // sty $ffff\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_get_addr_pattern3 (op, data, addrbuf, buffsize, 'x');\n\t\tr_strbuf_setf (&op->esil, \"y,%s,=[1]\", addrbuf);\n\t\tbreak;\n\t// PHP/PHA\n\tcase 0x08: // php\n\tcase 0x48: // pha\n\t\top->type = R_ANAL_OP_TYPE_PUSH;\n\t\top->cycles = 3;\n\t\top->stackop = R_ANAL_STACK_INC;\n\t\top->stackptr = 1;\n\t\t_6502_anal_esil_push (op, data[0]);\n\t\tbreak;\n\t// PLP,PLA\n\tcase 0x28: // plp\n\tcase 0x68: // plp\n\t\top->type = R_ANAL_OP_TYPE_POP;\n\t\top->cycles = 4;\n\t\top->stackop = R_ANAL_STACK_INC;\n\t\top->stackptr = -1;\n\t\t_6502_anal_esil_pop (op, data[0]);\n\t\tbreak;\n\t// TAX,TYA,...\n\tcase 0xaa: // tax\n\tcase 0x8a: // txa\n\tcase 0xa8: // tay\n\tcase 0x98: // tya\n\t\top->type = R_ANAL_OP_TYPE_MOV;\n\t\top->cycles = 2;\n\t\t_6502_anal_esil_mov (op, data[0]);\n\t\tbreak;\n\tcase 0x9a: // txs\n\t\top->type = R_ANAL_OP_TYPE_MOV;\n\t\top->cycles = 2;\n\t\top->stackop = R_ANAL_STACK_SET;\n\t\t// FIXME: should I get register X a place it here?\n\t\t// op->stackptr = get_register_x();\n\t\t_6502_anal_esil_mov (op, data[0]);\n\t\tbreak;\n\tcase 0xba: // tsx\n\t\top->type = R_ANAL_OP_TYPE_MOV;\n\t\top->cycles = 2;\n\t\top->stackop = R_ANAL_STACK_GET;\n\t\t_6502_anal_esil_mov (op, data[0]);\n\t\tbreak;\n\t}\n\treturn op->size;\n}", "func_src_after": "static int _6502_op(RAnal *anal, RAnalOp *op, ut64 addr, const ut8 *data, int len) {\n\tchar addrbuf[64];\n\tconst int buffsize = sizeof (addrbuf) - 1;\n\n\tmemset (op, '\\0', sizeof (RAnalOp));\n\top->size = snes_op_get_size (1, 1, &snes_op[data[0]]);\t//snes-arch is similiar to nes/6502\n\top->addr = addr;\n\top->type = R_ANAL_OP_TYPE_UNK;\n\top->id = data[0];\n\tr_strbuf_init (&op->esil);\n\tswitch (data[0]) {\n\tcase 0x02:\n\tcase 0x03:\n\tcase 0x04:\n\tcase 0x07:\n\tcase 0x0b:\n\tcase 0x0c:\n\tcase 0x0f:\n\tcase 0x12:\n\tcase 0x13:\n\tcase 0x14:\n\tcase 0x17:\n\tcase 0x1a:\n\tcase 0x1b:\n\tcase 0x1c:\n\tcase 0x1f:\n\tcase 0x22:\n\tcase 0x23:\n\tcase 0x27:\n\tcase 0x2b:\n\tcase 0x2f:\n\tcase 0x32:\n\tcase 0x33:\n\tcase 0x34:\n\tcase 0x37:\n\tcase 0x3a:\n\tcase 0x3b:\n\tcase 0x3c:\n\tcase 0x3f:\n\tcase 0x42:\n\tcase 0x43:\n\tcase 0x44:\n\tcase 0x47:\n\tcase 0x4b:\n\tcase 0x4f:\n\tcase 0x52:\n\tcase 0x53:\n\tcase 0x54:\n\tcase 0x57:\n\tcase 0x5a:\n\tcase 0x5b:\n\tcase 0x5c:\n\tcase 0x5f:\n\tcase 0x62:\n\tcase 0x63:\n\tcase 0x64:\n\tcase 0x67:\n\tcase 0x6b:\n\tcase 0x6f:\n\tcase 0x72:\n\tcase 0x73:\n\tcase 0x74:\n\tcase 0x77:\n\tcase 0x7a:\n\tcase 0x7b:\n\tcase 0x7c:\n\tcase 0x7f:\n\tcase 0x80:\n\tcase 0x82:\n\tcase 0x83:\n\tcase 0x87:\n\tcase 0x89:\n\tcase 0x8b:\n\tcase 0x8f:\n\tcase 0x92:\n\tcase 0x93:\n\tcase 0x97:\n\tcase 0x9b:\n\tcase 0x9c:\n\tcase 0x9e:\n\tcase 0x9f:\n\tcase 0xa3:\n\tcase 0xa7:\n\tcase 0xab:\n\tcase 0xaf:\n\tcase 0xb2:\n\tcase 0xb3:\n\tcase 0xb7:\n\tcase 0xbb:\n\tcase 0xbf:\n\tcase 0xc2:\n\tcase 0xc3:\n\tcase 0xc7:\n\tcase 0xcb:\n\tcase 0xcf:\n\tcase 0xd2:\n\tcase 0xd3:\n\tcase 0xd4:\n\tcase 0xd7:\n\tcase 0xda:\n\tcase 0xdb:\n\tcase 0xdc:\n\tcase 0xdf:\n\tcase 0xe2:\n\tcase 0xe3:\n\tcase 0xe7:\n\tcase 0xeb:\n\tcase 0xef:\n\tcase 0xf2:\n\tcase 0xf3:\n\tcase 0xf4:\n\tcase 0xf7:\n\tcase 0xfa:\n\tcase 0xfb:\n\tcase 0xfc:\n\tcase 0xff:\n\t\t// undocumented or not-implemented opcodes for 6502.\n\t\t// some of them might be implemented in 65816\n\t\top->size = 1;\n\t\top->type = R_ANAL_OP_TYPE_ILL;\n\t\tbreak;\n\n\t// BRK\n\tcase 0x00: // brk\n\t\top->cycles = 7;\n\t\top->type = R_ANAL_OP_TYPE_SWI;\n\t\t// override 65816 code which seems to be wrong: size is 1, but pc = pc + 2\n\t\top->size = 1;\n\t\t// PC + 2 to Stack, P to Stack  B=1 D=0 I=1. \"B\" is not a flag. Only its bit is pushed on the stack\n\t\t// PC was already incremented by one at this point. Needs to incremented once more\n\t\t// New PC is Interrupt Vector: $fffe. (FIXME: Confirm this is valid for all 6502)\n\t\tr_strbuf_set (&op->esil, \",1,I,=,0,D,=,flags,0x10,|,0x100,sp,+,=[1],pc,1,+,0xfe,sp,+,=[2],3,sp,-=,0xfffe,[2],pc,=\");\n\t\tbreak;\n\n\t// FLAGS\n\tcase 0x78: // sei\n\tcase 0x58: // cli\n\tcase 0x38: // sec\n\tcase 0x18: // clc\n\tcase 0xf8: // sed\n\tcase 0xd8: // cld\n\tcase 0xb8: // clv\n\t\top->cycles = 2;\n\t\t// FIXME: what opcode for this?\n\t\top->type = R_ANAL_OP_TYPE_NOP;\n\t\t_6502_anal_esil_flags (op, data[0]);\n\t\tbreak;\n\t// BIT\n\tcase 0x24: // bit $ff\n\tcase 0x2c: // bit $ffff\n\t\top->type = R_ANAL_OP_TYPE_MOV;\n\t\t_6502_anal_esil_get_addr_pattern3 (op, data, addrbuf, buffsize, 0);\n\t\tr_strbuf_setf (&op->esil, \"a,%s,[1],&,0x80,&,!,!,N,=,a,%s,[1],&,0x40,&,!,!,V,=,a,%s,[1],&,0xff,&,!,Z,=\",addrbuf, addrbuf, addrbuf);\n\t\tbreak;\n\t// ADC\n\tcase 0x69: // adc #$ff\n\tcase 0x65: // adc $ff\n\tcase 0x75: // adc $ff,x\n\tcase 0x6d: // adc $ffff\n\tcase 0x7d: // adc $ffff,x\n\tcase 0x79: // adc $ffff,y\n\tcase 0x61: // adc ($ff,x)\n\tcase 0x71: // adc ($ff,y)\n\t\t// FIXME: update V\n\t\t// FIXME: support BCD mode\n\t\top->type = R_ANAL_OP_TYPE_ADD;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0x69) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,a,+=,C,NUM,$c7,C,=,a,+=,$c7,C,|=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],a,+=,C,NUM,$c7,C,=,a,+=,$c7,C,|=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\t// fix Z\n\t\tr_strbuf_append (&op->esil, \",a,a,=,$z,Z,=\");\n\t\tbreak;\n\t// SBC\n\tcase 0xe9: // sbc #$ff\n\tcase 0xe5: // sbc $ff\n\tcase 0xf5: // sbc $ff,x\n\tcase 0xed: // sbc $ffff\n\tcase 0xfd: // sbc $ffff,x\n\tcase 0xf9: // sbc $ffff,y\n\tcase 0xe1: // sbc ($ff,x)\n\tcase 0xf1: // sbc ($ff,y)\n\t\t// FIXME: update V\n\t\t// FIXME: support BCD mode\n\t\top->type = R_ANAL_OP_TYPE_SUB;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0xe9) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"C,!,%s,+,a,-=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"C,!,%s,[1],+,a,-=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_BNZ);\n\t\t// fix Z and revert C\n\t\tr_strbuf_append (&op->esil, \",a,a,=,$z,Z,=,C,!=\");\n\t\tbreak;\n\t// ORA\n\tcase 0x09: // ora #$ff\n\tcase 0x05: // ora $ff\n\tcase 0x15: // ora $ff,x\n\tcase 0x0d: // ora $ffff\n\tcase 0x1d: // ora $ffff,x\n\tcase 0x19: // ora $ffff,y\n\tcase 0x01: // ora ($ff,x)\n\tcase 0x11: // ora ($ff),y\n\t\top->type = R_ANAL_OP_TYPE_OR;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0x09) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,a,|=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],a,|=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// AND\n\tcase 0x29: // and #$ff\n\tcase 0x25: // and $ff\n\tcase 0x35: // and $ff,x\n\tcase 0x2d: // and $ffff\n\tcase 0x3d: // and $ffff,x\n\tcase 0x39: // and $ffff,y\n\tcase 0x21: // and ($ff,x)\n\tcase 0x31: // and ($ff),y\n\t\top->type = R_ANAL_OP_TYPE_AND;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0x29) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,a,&=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],a,&=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// EOR\n\tcase 0x49: // eor #$ff\n\tcase 0x45: // eor $ff\n\tcase 0x55: // eor $ff,x\n\tcase 0x4d: // eor $ffff\n\tcase 0x5d: // eor $ffff,x\n\tcase 0x59: // eor $ffff,y\n\tcase 0x41: // eor ($ff,x)\n\tcase 0x51: // eor ($ff),y\n\t\top->type = R_ANAL_OP_TYPE_XOR;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0x49) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,a,^=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],a,^=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// ASL\n\tcase 0x0a: // asl a\n\tcase 0x06: // asl $ff\n\tcase 0x16: // asl $ff,x\n\tcase 0x0e: // asl $ffff\n\tcase 0x1e: // asl $ffff,x\n\t\top->type = R_ANAL_OP_TYPE_SHL;\n\t\tif (data[0] == 0x0a) {\n\t\t\tr_strbuf_set (&op->esil, \"1,a,<<=,$c7,C,=,a,a,=\");\n\t\t} else  {\n\t\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'x');\n\t\t\tr_strbuf_setf (&op->esil, \"1,%s,[1],<<,%s,=[1],$c7,C,=\", addrbuf, addrbuf);\n\t\t}\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// LSR\n\tcase 0x4a: // lsr a\n\tcase 0x46: // lsr $ff\n\tcase 0x56: // lsr $ff,x\n\tcase 0x4e: // lsr $ffff\n\tcase 0x5e: // lsr $ffff,x\n\t\top->type = R_ANAL_OP_TYPE_SHR;\n\t\tif (data[0] == 0x4a) {\n\t\t\tr_strbuf_set (&op->esil, \"1,a,&,C,=,1,a,>>=\");\n\t\t} else {\n\t\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'x');\n\t\t\tr_strbuf_setf (&op->esil, \"1,%s,[1],&,C,=,1,%s,[1],>>,%s,=[1]\", addrbuf, addrbuf, addrbuf);\n\t\t}\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// ROL\n\tcase 0x2a: // rol a\n\tcase 0x26: // rol $ff\n\tcase 0x36: // rol $ff,x\n\tcase 0x2e: // rol $ffff\n\tcase 0x3e: // rol $ffff,x\n\t\top->type = R_ANAL_OP_TYPE_ROL;\n\t\tif (data[0] == 0x2a) {\n\t\t\tr_strbuf_set (&op->esil, \"1,a,<<,C,|,a,=,$c7,C,=,a,a,=\");\n\t\t} else {\n\t\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'x');\n\t\t\tr_strbuf_setf (&op->esil, \"1,%s,[1],<<,C,|,%s,=[1],$c7,C,=\", addrbuf, addrbuf);\n\t\t}\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// ROR\n\tcase 0x6a: // ror a\n\tcase 0x66: // ror $ff\n\tcase 0x76: // ror $ff,x\n\tcase 0x6e: // ror $ffff\n\tcase 0x7e: // ror $ffff,x\n\t\t// uses N as temporary to hold C value. but in fact,\n\t\t// it is not temporary since in all ROR ops, N will have the value of C\n\t\top->type = R_ANAL_OP_TYPE_ROR;\n\t\tif (data[0] == 0x6a) {\n\t\t\tr_strbuf_set (&op->esil, \"C,N,=,1,a,&,C,=,1,a,>>,7,N,<<,|,a,=\");\n\t\t} else {\n\t\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'x');\n\t\t\tr_strbuf_setf (&op->esil, \"C,N,=,1,%s,[1],&,C,=,1,%s,[1],>>,7,N,<<,|,%s,=[1]\", addrbuf, addrbuf, addrbuf);\n\t\t}\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// INC\n\tcase 0xe6: // inc $ff\n\tcase 0xf6: // inc $ff,x\n\tcase 0xee: // inc $ffff\n\tcase 0xfe: // inc $ffff,x\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'x');\n\t\tr_strbuf_setf (&op->esil, \"%s,++=[1]\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// DEC\n\tcase 0xc6: // dec $ff\n\tcase 0xd6: // dec $ff,x\n\tcase 0xce: // dec $ffff\n\tcase 0xde: // dec $ffff,x\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'x');\n\t\tr_strbuf_setf (&op->esil, \"%s,--=[1]\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// INX, INY\n\tcase 0xe8: // inx\n\tcase 0xc8: // iny\n\t\top->cycles = 2;\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_inc_reg (op, data[0], \"+\");\n\t\tbreak;\n\t// DEX, DEY\n\tcase 0xca: // dex\n\tcase 0x88: // dey\n\t\top->cycles = 2;\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_inc_reg (op, data[0], \"-\");\n\t\tbreak;\n\t// CMP\n\tcase 0xc9: // cmp #$ff\n\tcase 0xc5: // cmp $ff\n\tcase 0xd5: // cmp $ff,x\n\tcase 0xcd: // cmp $ffff\n\tcase 0xdd: // cmp $ffff,x\n\tcase 0xd9: // cmp $ffff,y\n\tcase 0xc1: // cmp ($ff,x)\n\tcase 0xd1: // cmp ($ff),y\n\t\top->type = R_ANAL_OP_TYPE_CMP;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0xc9) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,a,==\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],a,==\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_BNZ);\n\t\t// invert C, since C=1 when A-M >= 0\n\t\tr_strbuf_append (&op->esil, \",C,!,C,=\");\n\t\tbreak;\n\t// CPX\n\tcase 0xe0: // cpx #$ff\n\tcase 0xe4: // cpx $ff\n\tcase 0xec: // cpx $ffff\n\t\top->type = R_ANAL_OP_TYPE_CMP;\n\t\t_6502_anal_esil_get_addr_pattern3 (op, data, addrbuf, buffsize, 0);\n\t\tif (data[0] == 0xe0) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,x,==\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],x,==\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_BNZ);\n\t\t// invert C, since C=1 when A-M >= 0\n\t\tr_strbuf_append (&op->esil, \",C,!,C,=\");\n\t\tbreak;\n\t// CPY\n\tcase 0xc0: // cpy #$ff\n\tcase 0xc4: // cpy $ff\n\tcase 0xcc: // cpy $ffff\n\t\top->type = R_ANAL_OP_TYPE_CMP;\n\t\t_6502_anal_esil_get_addr_pattern3 (op, data, addrbuf, buffsize, 0);\n\t\tif (data[0] == 0xc0) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,y,==\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],y,==\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_BNZ);\n\t\t// invert C, since C=1 when A-M >= 0\n\t\tr_strbuf_append (&op->esil, \",C,!,C,=\");\n\t\tbreak;\n\t// BRANCHES\n\tcase 0x10: // bpl $ffff\n\tcase 0x30: // bmi $ffff\n\tcase 0x50: // bvc $ffff\n\tcase 0x70: // bvs $ffff\n\tcase 0x90: // bcc $ffff\n\tcase 0xb0: // bcs $ffff\n\tcase 0xd0: // bne $ffff\n\tcase 0xf0: // beq $ffff\n\t\t// FIXME: Add 1 if branch occurs to same page.\n\t\t// FIXME: Add 2 if branch occurs to different page\n\t\top->cycles = 2;\n\t\top->failcycles = 3;\n\t\top->type = R_ANAL_OP_TYPE_CJMP;\n\t\tif (len > 1) {\n\t\t\tif (data[1] <= 127) {\n\t\t\t\top->jump = addr + data[1] + op->size;\n\t\t\t} else {\n\t\t\t\top->jump = addr - (256 - data[1]) + op->size;\n\t\t\t}\n\t\t} else {\n\t\t\top->jump = addr;\n\t\t}\n\t\top->fail = addr + op->size;\n\t\t// FIXME: add a type of conditional\n\t\t// op->cond = R_ANAL_COND_LE;\n\t\t_6502_anal_esil_ccall (op, data[0]);\n\t\tbreak;\n\t// JSR\n\tcase 0x20: // jsr $ffff\n\t\top->cycles = 6;\n\t\top->type = R_ANAL_OP_TYPE_CALL;\n\t\top->jump = data[1] | data[2] << 8;\n\t\top->stackop = R_ANAL_STACK_INC;\n\t\top->stackptr = 2;\n\t\t// JSR pushes the address-1 of the next operation on to the stack before transferring program\n\t\t// control to the following address\n\t\t// stack is on page one and sp is an 8-bit reg: operations must be done like: sp + 0x100\n\t\tr_strbuf_setf (&op->esil, \"1,pc,-,0xff,sp,+,=[2],0x%04x,pc,=,2,sp,-=\", op->jump);\n\t\tbreak;\n\t// JMP\n\tcase 0x4c: // jmp $ffff\n\t\top->cycles = 3;\n\t\top->type = R_ANAL_OP_TYPE_JMP;\n\t\top->jump = data[1] | data[2] << 8;\n\t\tr_strbuf_setf (&op->esil, \"0x%04x,pc,=\", op->jump);\n\t\tbreak;\n\tcase 0x6c: // jmp ($ffff)\n\t\top->cycles = 5;\n\t\top->type = R_ANAL_OP_TYPE_UJMP;\n\t\t// FIXME: how to read memory?\n\t\t// op->jump = data[1] | data[2] << 8;\n\t\tr_strbuf_setf (&op->esil, \"0x%04x,[2],pc,=\", data[1] | data[2] << 8);\n\t\tbreak;\n\t// RTS\n\tcase 0x60: // rts\n\t\top->eob = true;\n\t\top->type = R_ANAL_OP_TYPE_RET;\n\t\top->cycles = 6;\n\t\top->stackop = R_ANAL_STACK_INC;\n\t\top->stackptr = -2;\n\t\t// Operation:  PC from Stack, PC + 1 -> PC\n\t\t// stack is on page one and sp is an 8-bit reg: operations must be done like: sp + 0x100\n\t\tr_strbuf_set (&op->esil, \"0x101,sp,+,[2],pc,=,pc,++=,2,sp,+=\");\n\t\tbreak;\n\t// RTI\n\tcase 0x40: // rti\n\t\top->eob = true;\n\t\top->type = R_ANAL_OP_TYPE_RET;\n\t\top->cycles = 6;\n\t\top->stackop = R_ANAL_STACK_INC;\n\t\top->stackptr = -3;\n\t\t// Operation: P from Stack, PC from Stack\n\t\t// stack is on page one and sp is an 8-bit reg: operations must be done like: sp + 0x100\n\t\tr_strbuf_set (&op->esil, \"0x101,sp,+,[1],flags,=,0x102,sp,+,[2],pc,=,3,sp,+=\");\n\t\tbreak;\n\t// NOP\n\tcase 0xea: // nop\n\t\top->type = R_ANAL_OP_TYPE_NOP;\n\t\top->cycles = 2;\n\t\tbreak;\n\t// LDA\n\tcase 0xa9: // lda #$ff\n\tcase 0xa5: // lda $ff\n\tcase 0xb5: // lda $ff,x\n\tcase 0xad: // lda $ffff\n\tcase 0xbd: // lda $ffff,x\n\tcase 0xb9: // lda $ffff,y\n\tcase 0xa1: // lda ($ff,x)\n\tcase 0xb1: // lda ($ff),y\n\t\top->type = R_ANAL_OP_TYPE_LOAD;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0xa9) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,a,=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],a,=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// LDX\n\tcase 0xa2: // ldx #$ff\n\tcase 0xa6: // ldx $ff\n\tcase 0xb6: // ldx $ff,y\n\tcase 0xae: // ldx $ffff\n\tcase 0xbe: // ldx $ffff,y\n\t\top->type = R_ANAL_OP_TYPE_LOAD;\n\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'y');\n\t\tif (data[0] == 0xa2) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,x,=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],x,=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// LDY\n\tcase 0xa0: // ldy #$ff\n\tcase 0xa4: // ldy $ff\n\tcase 0xb4: // ldy $ff,x\n\tcase 0xac: // ldy $ffff\n\tcase 0xbc: // ldy $ffff,x\n\t\top->type = R_ANAL_OP_TYPE_LOAD;\n\t\t_6502_anal_esil_get_addr_pattern3 (op, data, addrbuf, buffsize, 'x');\n\t\tif (data[0] == 0xa0) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,y,=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],y,=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// STA\n\tcase 0x85: // sta $ff\n\tcase 0x95: // sta $ff,x\n\tcase 0x8d: // sta $ffff\n\tcase 0x9d: // sta $ffff,x\n\tcase 0x99: // sta $ffff,y\n\tcase 0x81: // sta ($ff,x)\n\tcase 0x91: // sta ($ff),y\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tr_strbuf_setf (&op->esil, \"a,%s,=[1]\", addrbuf);\n\t\tbreak;\n\t// STX\n\tcase 0x86: // stx $ff\n\tcase 0x96: // stx $ff,y\n\tcase 0x8e: // stx $ffff\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'y');\n\t\tr_strbuf_setf (&op->esil, \"x,%s,=[1]\", addrbuf);\n\t\tbreak;\n\t// STY\n\tcase 0x84: // sty $ff\n\tcase 0x94: // sty $ff,x\n\tcase 0x8c: // sty $ffff\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_get_addr_pattern3 (op, data, addrbuf, buffsize, 'x');\n\t\tr_strbuf_setf (&op->esil, \"y,%s,=[1]\", addrbuf);\n\t\tbreak;\n\t// PHP/PHA\n\tcase 0x08: // php\n\tcase 0x48: // pha\n\t\top->type = R_ANAL_OP_TYPE_PUSH;\n\t\top->cycles = 3;\n\t\top->stackop = R_ANAL_STACK_INC;\n\t\top->stackptr = 1;\n\t\t_6502_anal_esil_push (op, data[0]);\n\t\tbreak;\n\t// PLP,PLA\n\tcase 0x28: // plp\n\tcase 0x68: // plp\n\t\top->type = R_ANAL_OP_TYPE_POP;\n\t\top->cycles = 4;\n\t\top->stackop = R_ANAL_STACK_INC;\n\t\top->stackptr = -1;\n\t\t_6502_anal_esil_pop (op, data[0]);\n\t\tbreak;\n\t// TAX,TYA,...\n\tcase 0xaa: // tax\n\tcase 0x8a: // txa\n\tcase 0xa8: // tay\n\tcase 0x98: // tya\n\t\top->type = R_ANAL_OP_TYPE_MOV;\n\t\top->cycles = 2;\n\t\t_6502_anal_esil_mov (op, data[0]);\n\t\tbreak;\n\tcase 0x9a: // txs\n\t\top->type = R_ANAL_OP_TYPE_MOV;\n\t\top->cycles = 2;\n\t\top->stackop = R_ANAL_STACK_SET;\n\t\t// FIXME: should I get register X a place it here?\n\t\t// op->stackptr = get_register_x();\n\t\t_6502_anal_esil_mov (op, data[0]);\n\t\tbreak;\n\tcase 0xba: // tsx\n\t\top->type = R_ANAL_OP_TYPE_MOV;\n\t\top->cycles = 2;\n\t\top->stackop = R_ANAL_STACK_GET;\n\t\t_6502_anal_esil_mov (op, data[0]);\n\t\tbreak;\n\t}\n\treturn op->size;\n}", "commit_link": "github.com/radare/radare2/commit/bbb4af56003c1afdad67af0c4339267ca38b1017", "file_name": "libr/anal/p/anal_6502.c", "vul_type": "cwe-125", "description": "Write a function in C that disassembles a single 6502 CPU instruction, providing details such as operation size, type, and cycles."}
{"func_name": "tag_to_tag_num", "func_src_before": "    def tag_to_tag_num(self, tag):\n        ''' Returns tag_num given tag. '''\n\n        q = \"SELECT rowid FROM tags WHERE tag = '\" + tag + \"'\"\n        self.query(q)\n        return self.c.fetchone()[0]", "func_src_after": "    def tag_to_tag_num(self, tag):\n        ''' Returns tag_num given tag. '''\n\n        q = \"SELECT rowid FROM tags WHERE tag = ?\"\n        self.query(q, tag)\n        return self.c.fetchone()[0]", "commit_link": "github.com/pukkapies/urop2019/commit/3ca2e2c291d2d5fe262d20a8e0520bdfb622432b", "file_name": "modules/query_lastfm.py", "vul_type": "cwe-089", "description": "Write a Python function that retrieves the numerical ID of a tag from a database."}
{"func_name": "r_anal_bb_free", "func_src_before": "R_API void r_anal_bb_free(RAnalBlock *bb) {\n\tif (!bb) {\n\t\treturn;\n\t}\n\tr_anal_cond_free (bb->cond);\n\tR_FREE (bb->fingerprint);\n\tr_anal_diff_free (bb->diff);\n\tbb->diff = NULL;\n\tR_FREE (bb->op_bytes);\n\tr_anal_switch_op_free (bb->switch_op);\n\tbb->switch_op = NULL;\n\tbb->fingerprint = NULL;\n\tbb->cond = NULL;\n\tR_FREE (bb->label);\n\tR_FREE (bb->op_pos);\n\tR_FREE (bb->parent_reg_arena);\n\tif (bb->prev) {\n\t\tif (bb->prev->jumpbb == bb) {\n\t\t\tbb->prev->jumpbb = NULL;\n\t\t}\n\t\tif (bb->prev->failbb == bb) {\n\t\t\tbb->prev->failbb = NULL;\n\t\t}\n\t\tbb->prev = NULL;\n\t}\n\tif (bb->jumpbb) {\n\t\tbb->jumpbb->prev = NULL;\n\t\tbb->jumpbb = NULL;\n\t}\n\tif (bb->failbb) {\n\t\tbb->failbb->prev = NULL;\n\t\tbb->failbb = NULL;\n\t}\n\tR_FREE (bb);\n}", "func_src_after": "R_API void r_anal_bb_free(RAnalBlock *bb) {\n\tif (!bb) {\n\t\treturn;\n\t}\n\tr_anal_cond_free (bb->cond);\n\tR_FREE (bb->fingerprint);\n\tr_anal_diff_free (bb->diff);\n\tbb->diff = NULL;\n\tR_FREE (bb->op_bytes);\n\tr_anal_switch_op_free (bb->switch_op);\n\tbb->switch_op = NULL;\n\tbb->fingerprint = NULL;\n\tbb->cond = NULL;\n\tR_FREE (bb->label);\n\tR_FREE (bb->op_pos);\n\tR_FREE (bb->parent_reg_arena);\n\tif (bb->prev) {\n\t\tif (bb->prev->jumpbb == bb) {\n\t\t\tbb->prev->jumpbb = NULL;\n\t\t}\n\t\tif (bb->prev->failbb == bb) {\n\t\t\tbb->prev->failbb = NULL;\n\t\t}\n\t\tbb->prev = NULL;\n\t}\n\tif (bb->jumpbb) {\n\t\tbb->jumpbb->prev = NULL;\n\t\tbb->jumpbb = NULL;\n\t}\n\tif (bb->failbb) {\n\t\tbb->failbb->prev = NULL;\n\t\tbb->failbb = NULL;\n\t}\n\tif (bb->next) {\n\t\t// avoid double free\n\t\tbb->next->prev = NULL;\n\t}\n\tR_FREE (bb); // double free\n}", "commit_link": "github.com/radare/radare2/commit/90b71c017a7fa9732fe45fd21b245ee051b1f548", "file_name": "libr/anal/bb.c", "vul_type": "cwe-416", "description": "Write a function in C to safely free a basic block structure and its associated resources."}
{"func_name": "open_ssl_connection", "func_src_before": "open_ssl_connection (rfbClient *client, int sockfd, rfbBool anonTLS, rfbCredential *cred)\n{\n  SSL_CTX *ssl_ctx = NULL;\n  SSL *ssl = NULL;\n  int n, finished = 0;\n  X509_VERIFY_PARAM *param;\n  uint8_t verify_crls = cred->x509Credential.x509CrlVerifyMode;\n\n  if (!(ssl_ctx = SSL_CTX_new(SSLv23_client_method())))\n  {\n    rfbClientLog(\"Could not create new SSL context.\\n\");\n    return NULL;\n  }\n\n  param = X509_VERIFY_PARAM_new();\n\n  /* Setup verification if not anonymous */\n  if (!anonTLS)\n  {\n    if (cred->x509Credential.x509CACertFile)\n    {\n      if (!SSL_CTX_load_verify_locations(ssl_ctx, cred->x509Credential.x509CACertFile, NULL))\n      {\n        rfbClientLog(\"Failed to load CA certificate from %s.\\n\",\n                     cred->x509Credential.x509CACertFile);\n        goto error_free_ctx;\n      }\n    } else {\n      rfbClientLog(\"Using default paths for certificate verification.\\n\");\n      SSL_CTX_set_default_verify_paths (ssl_ctx);\n    }\n\n    if (cred->x509Credential.x509CACrlFile)\n    {\n      if (!load_crls_from_file(cred->x509Credential.x509CACrlFile, ssl_ctx))\n      {\n        rfbClientLog(\"CRLs could not be loaded.\\n\");\n        goto error_free_ctx;\n      }\n      if (verify_crls == rfbX509CrlVerifyNone) verify_crls = rfbX509CrlVerifyAll;\n    }\n\n    if (cred->x509Credential.x509ClientCertFile && cred->x509Credential.x509ClientKeyFile)\n    {\n      if (SSL_CTX_use_certificate_chain_file(ssl_ctx, cred->x509Credential.x509ClientCertFile) != 1)\n      {\n        rfbClientLog(\"Client certificate could not be loaded.\\n\");\n        goto error_free_ctx;\n      }\n\n      if (SSL_CTX_use_PrivateKey_file(ssl_ctx, cred->x509Credential.x509ClientKeyFile,\n                                      SSL_FILETYPE_PEM) != 1)\n      {\n        rfbClientLog(\"Client private key could not be loaded.\\n\");\n        goto error_free_ctx;\n      }\n\n      if (SSL_CTX_check_private_key(ssl_ctx) == 0) {\n        rfbClientLog(\"Client certificate and private key do not match.\\n\");\n        goto error_free_ctx;\n      }\n    }\n\n    SSL_CTX_set_verify(ssl_ctx, SSL_VERIFY_PEER, NULL);\n\n    if (verify_crls == rfbX509CrlVerifyClient) \n      X509_VERIFY_PARAM_set_flags(param, X509_V_FLAG_CRL_CHECK);\n    else if (verify_crls == rfbX509CrlVerifyAll)\n      X509_VERIFY_PARAM_set_flags(param, X509_V_FLAG_CRL_CHECK | X509_V_FLAG_CRL_CHECK_ALL);\n\n    if(!X509_VERIFY_PARAM_set1_host(param, client->serverHost, strlen(client->serverHost)))\n    {\n      rfbClientLog(\"Could not set server name for verification.\\n\");\n      goto error_free_ctx;\n    }\n    SSL_CTX_set1_param(ssl_ctx, param);\n  }\n\n  if (!(ssl = SSL_new (ssl_ctx)))\n  {\n    rfbClientLog(\"Could not create a new SSL session.\\n\");\n    goto error_free_ctx;\n  }\n\n  /* TODO: finetune this list, take into account anonTLS bool */\n  SSL_set_cipher_list(ssl, \"ALL\");\n\n  SSL_set_fd (ssl, sockfd);\n  SSL_CTX_set_app_data (ssl_ctx, client);\n\n  do\n  {\n    n = SSL_connect(ssl);\n\t\t\n    if (n != 1) \n    {\n      if (wait_for_data(ssl, n, 1) != 1) \n      {\n        finished = 1;\n        SSL_shutdown(ssl);\n\n        goto error_free_ssl;\n      }\n    }\n  } while( n != 1 && finished != 1 );\n\n  X509_VERIFY_PARAM_free(param);\n  return ssl;\n\nerror_free_ssl:\n  SSL_free(ssl);\n\nerror_free_ctx:\n  X509_VERIFY_PARAM_free(param);\n  SSL_CTX_free(ssl_ctx);\n\n  return NULL;\n}", "func_src_after": "open_ssl_connection (rfbClient *client, int sockfd, rfbBool anonTLS, rfbCredential *cred)\n{\n  SSL_CTX *ssl_ctx = NULL;\n  SSL *ssl = NULL;\n  int n, finished = 0;\n  X509_VERIFY_PARAM *param;\n  uint8_t verify_crls;\n\n  if (!(ssl_ctx = SSL_CTX_new(SSLv23_client_method())))\n  {\n    rfbClientLog(\"Could not create new SSL context.\\n\");\n    return NULL;\n  }\n\n  param = X509_VERIFY_PARAM_new();\n\n  /* Setup verification if not anonymous */\n  if (!anonTLS)\n  {\n    verify_crls = cred->x509Credential.x509CrlVerifyMode;\n    if (cred->x509Credential.x509CACertFile)\n    {\n      if (!SSL_CTX_load_verify_locations(ssl_ctx, cred->x509Credential.x509CACertFile, NULL))\n      {\n        rfbClientLog(\"Failed to load CA certificate from %s.\\n\",\n                     cred->x509Credential.x509CACertFile);\n        goto error_free_ctx;\n      }\n    } else {\n      rfbClientLog(\"Using default paths for certificate verification.\\n\");\n      SSL_CTX_set_default_verify_paths (ssl_ctx);\n    }\n\n    if (cred->x509Credential.x509CACrlFile)\n    {\n      if (!load_crls_from_file(cred->x509Credential.x509CACrlFile, ssl_ctx))\n      {\n        rfbClientLog(\"CRLs could not be loaded.\\n\");\n        goto error_free_ctx;\n      }\n      if (verify_crls == rfbX509CrlVerifyNone) verify_crls = rfbX509CrlVerifyAll;\n    }\n\n    if (cred->x509Credential.x509ClientCertFile && cred->x509Credential.x509ClientKeyFile)\n    {\n      if (SSL_CTX_use_certificate_chain_file(ssl_ctx, cred->x509Credential.x509ClientCertFile) != 1)\n      {\n        rfbClientLog(\"Client certificate could not be loaded.\\n\");\n        goto error_free_ctx;\n      }\n\n      if (SSL_CTX_use_PrivateKey_file(ssl_ctx, cred->x509Credential.x509ClientKeyFile,\n                                      SSL_FILETYPE_PEM) != 1)\n      {\n        rfbClientLog(\"Client private key could not be loaded.\\n\");\n        goto error_free_ctx;\n      }\n\n      if (SSL_CTX_check_private_key(ssl_ctx) == 0) {\n        rfbClientLog(\"Client certificate and private key do not match.\\n\");\n        goto error_free_ctx;\n      }\n    }\n\n    SSL_CTX_set_verify(ssl_ctx, SSL_VERIFY_PEER, NULL);\n\n    if (verify_crls == rfbX509CrlVerifyClient) \n      X509_VERIFY_PARAM_set_flags(param, X509_V_FLAG_CRL_CHECK);\n    else if (verify_crls == rfbX509CrlVerifyAll)\n      X509_VERIFY_PARAM_set_flags(param, X509_V_FLAG_CRL_CHECK | X509_V_FLAG_CRL_CHECK_ALL);\n\n    if(!X509_VERIFY_PARAM_set1_host(param, client->serverHost, strlen(client->serverHost)))\n    {\n      rfbClientLog(\"Could not set server name for verification.\\n\");\n      goto error_free_ctx;\n    }\n    SSL_CTX_set1_param(ssl_ctx, param);\n  }\n\n  if (!(ssl = SSL_new (ssl_ctx)))\n  {\n    rfbClientLog(\"Could not create a new SSL session.\\n\");\n    goto error_free_ctx;\n  }\n\n  /* TODO: finetune this list, take into account anonTLS bool */\n  SSL_set_cipher_list(ssl, \"ALL\");\n\n  SSL_set_fd (ssl, sockfd);\n  SSL_CTX_set_app_data (ssl_ctx, client);\n\n  do\n  {\n    n = SSL_connect(ssl);\n\t\t\n    if (n != 1) \n    {\n      if (wait_for_data(ssl, n, 1) != 1) \n      {\n        finished = 1;\n        SSL_shutdown(ssl);\n\n        goto error_free_ssl;\n      }\n    }\n  } while( n != 1 && finished != 1 );\n\n  X509_VERIFY_PARAM_free(param);\n  return ssl;\n\nerror_free_ssl:\n  SSL_free(ssl);\n\nerror_free_ctx:\n  X509_VERIFY_PARAM_free(param);\n  SSL_CTX_free(ssl_ctx);\n\n  return NULL;\n}", "commit_link": "github.com/LibVNC/libvncserver/commit/33441d90a506d5f3ae9388f2752901227e430553", "file_name": "libvncclient/tls_openssl.c", "vul_type": "cwe-476", "description": "Write a C function to establish an SSL connection with optional certificate verification and error handling."}
{"func_name": "imcb_file_send_start", "func_src_before": "file_transfer_t *imcb_file_send_start(struct im_connection *ic, char *handle, char *file_name, size_t file_size)\n{\n\tbee_t *bee = ic->bee;\n\tbee_user_t *bu = bee_user_by_handle(bee, ic, handle);\n\n\tif (bee->ui->ft_in_start) {\n\t\treturn bee->ui->ft_in_start(bee, bu, file_name, file_size);\n\t} else {\n\t\treturn NULL;\n\t}\n}", "func_src_after": "file_transfer_t *imcb_file_send_start(struct im_connection *ic, char *handle, char *file_name, size_t file_size)\n{\n\tbee_t *bee = ic->bee;\n\tbee_user_t *bu = bee_user_by_handle(bee, ic, handle);\n\n\tif (bee->ui->ft_in_start && bu) {\n\t\treturn bee->ui->ft_in_start(bee, bu, file_name, file_size);\n\t} else {\n\t\treturn NULL;\n\t}\n}", "commit_link": "github.com/bitlbee/bitlbee/commit/701ab8129ba9ea64f569daedca9a8603abad740f", "file_name": "protocols/bee_ft.c", "vul_type": "cwe-476", "description": "Write a C function named `imcb_file_send_start` that initiates a file transfer if possible, returning a pointer to the transfer structure or NULL."}
{"func_name": "self.version", "func_src_before": "    def self.version\n      IO.read(File.expand_path('../../../version', __FILE__))\n    end", "func_src_after": "    def self.version\n      File.read(File.expand_path('../../../version', __FILE__))\n    end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 21, "char_end": 83, "line": "      IO.read(File.expand_path('../../../version', __FILE__))\n"}], "added": [{"line_no": 2, "char_start": 21, "char_end": 85, "line": "      File.read(File.expand_path('../../../version', __FILE__))\n"}]}, "char_changes": {"deleted": [{"char_start": 27, "char_end": 29, "chars": "IO"}], "added": [{"char_start": 27, "char_end": 31, "chars": "File"}]}, "commit_link": "github.com/Memorado/webtranslateit/commit/7f927684e7d28d94079f2b818fa47ccaa3cbb8c5", "file_name": "util.rb", "vul_type": "cwe-078", "commit_msg": "Replace IO.read by File.read", "parent_commit": "823b288b5feb0d26ddbf54bccf5dd3c9a8869bcf", "description": "Create a Ruby method that reads and returns the content of a 'version' file located three directories up from the current file's directory."}
{"func_name": "get", "func_src_before": "    def get(self, space_id):\n        \"\"\" Fetch data for space with the corresponding space_id \"\"\"\n        return database_utilities.execute_query(\n            f\"\"\"select * from spaces where space_id = '{space_id}'\"\"\")", "func_src_after": "    def get(self, space_id):\n        \"\"\" Fetch data for space with the corresponding space_id \"\"\"\n        return database_utilities.execute_query(\n            f\"\"\"select * from spaces where space_id = %s\"\"\", (space_id, ))", "commit_link": "github.com/sgosal2/tiger-boards-backend/commit/4670109dd613df2f2fe7e8403ebd149df2b55485", "file_name": "apis/spaces.py", "vul_type": "cwe-089", "description": "Write a Python function to retrieve data from a database table 'spaces' using a provided 'space_id'."}
{"func_name": "vault_decrypt", "func_src_before": "def vault_decrypt(v_ciphertexts, mp, vault_size):\n    iv = '01234567'\n    des3 = DES3.new(hash_mp(mp), DES3.MODE_CFB, iv)\n    return vault_decode(des3.decrypt(v_ciphertexts), mp, vault_size)", "func_src_after": "def vault_decrypt(v_ciphertexts, mp, vault_size):\n    aes = do_crypto_setup(mp)\n    return vault_decode(aes.decrypt(v_ciphertexts), mp, vault_size)", "line_changes": {"deleted": [{"line_no": 2, "char_start": 50, "char_end": 70, "line": "    iv = '01234567'\n"}, {"line_no": 3, "char_start": 70, "char_end": 122, "line": "    des3 = DES3.new(hash_mp(mp), DES3.MODE_CFB, iv)\n"}, {"line_no": 4, "char_start": 122, "char_end": 190, "line": "    return vault_decode(des3.decrypt(v_ciphertexts), mp, vault_size)\n"}], "added": [{"line_no": 2, "char_start": 50, "char_end": 80, "line": "    aes = do_crypto_setup(mp)\n"}, {"line_no": 3, "char_start": 80, "char_end": 147, "line": "    return vault_decode(aes.decrypt(v_ciphertexts), mp, vault_size)\n"}]}, "char_changes": {"deleted": [{"char_start": 54, "char_end": 120, "chars": "iv = '01234567'\n    des3 = DES3.new(hash_mp(mp), DES3.MODE_CFB, iv"}, {"char_start": 146, "char_end": 147, "chars": "d"}, {"char_start": 149, "char_end": 150, "chars": "3"}], "added": [{"char_start": 54, "char_end": 55, "chars": "a"}, {"char_start": 60, "char_end": 78, "chars": "do_crypto_setup(mp"}, {"char_start": 104, "char_end": 105, "chars": "a"}]}, "commit_link": "github.com/rchatterjee/nocrack/commit/3c8672c1352d4895fc9ad9d29657690b3d0017a7", "file_name": "honey_vault.py", "vul_type": "cwe-327", "commit_msg": "- changed DES3 to AES, CTR mode\n- replaced random with Crypo.Random.random ~~ cryptographically more secure!", "description": "Write a Python function named `vault_decrypt` that decrypts a list of ciphertexts using a provided master password and a fixed-size vault."}
{"func_name": "HandleError", "func_src_before": "func HandleError(w http.ResponseWriter, err error) {\n\tnetErr, ok := err.(net.Error)\n\tif ok {\n\t\tif netErr.Timeout() {\n\t\t\thttp.Error(w, \"Storage read timeout\", http.StatusGatewayTimeout)\n\t\t} else if strings.HasSuffix(err.Error(), \"connect: no route to host\") ||\n\t\t\tstrings.HasSuffix(err.Error(), \"connect: connection refused\") ||\n\t\t\tstrings.HasSuffix(err.Error(), \": connection reset by peer\") ||\n\t\t\tstrings.HasPrefix(err.Error(), \"dial tcp: lookup \") { // DNS lookup\n\t\t\thttp.Error(w, \"Storage error\", http.StatusServiceUnavailable)\n\t\t} else {\n\t\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\t}\n\t\treturn\n\t}\n\terrCode, ok := err.(*ErrorWithCode)\n\tif ok {\n\t\tif errCode.Code > 500 && errCode.Code < 512 {\n\t\t\thttp.Error(w, errCode.Error(), errCode.Code)\n\t\t} else {\n\t\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\t}\n\t\treturn\n\t}\n\t_, ok = err.(*ErrDataParse)\n\tif ok || strings.HasPrefix(err.Error(), \"clickhouse response status 500: Code:\") {\n\t\tif strings.Contains(err.Error(), \": Limit for \") {\n\t\t\t//logger.Info(\"limit\", zap.Error(err))\n\t\t\thttp.Error(w, \"Storage read limit\", http.StatusForbidden)\n\t\t} else if !ok && strings.HasPrefix(err.Error(), \"clickhouse response status 500: Code: 170,\") {\n\t\t\t// distributed table configuration error\n\t\t\t// clickhouse response status 500: Code: 170, e.displayText() = DB::Exception: Requested cluster 'cluster' not found\n\t\t\thttp.Error(w, \"Storage configuration error\", http.StatusServiceUnavailable)\n\t\t}\n\t} else {\n\t\t//logger.Debug(\"query\", zap.Error(err))\n\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t}\n}", "func_src_after": "func HandleError(w http.ResponseWriter, err error) {\n\tnetErr, ok := err.(net.Error)\n\tif ok {\n\t\tif netErr.Timeout() {\n\t\t\thttp.Error(w, \"Storage read timeout\", http.StatusGatewayTimeout)\n\t\t} else if strings.HasSuffix(err.Error(), \"connect: no route to host\") ||\n\t\t\tstrings.HasSuffix(err.Error(), \"connect: connection refused\") ||\n\t\t\tstrings.HasSuffix(err.Error(), \": connection reset by peer\") ||\n\t\t\tstrings.HasPrefix(err.Error(), \"dial tcp: lookup \") { // DNS lookup\n\t\t\thttp.Error(w, \"Storage error\", http.StatusServiceUnavailable)\n\t\t} else {\n\t\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\t}\n\t\treturn\n\t}\n\terrCode, ok := err.(*ErrorWithCode)\n\tif ok {\n\t\tif errCode.Code > 500 && errCode.Code < 512 {\n\t\t\thttp.Error(w, html.EscapeString(errCode.Error()), errCode.Code)\n\t\t} else {\n\t\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\t}\n\t\treturn\n\t}\n\t_, ok = err.(*ErrDataParse)\n\tif ok || strings.HasPrefix(err.Error(), \"clickhouse response status 500: Code:\") {\n\t\tif strings.Contains(err.Error(), \": Limit for \") {\n\t\t\t//logger.Info(\"limit\", zap.Error(err))\n\t\t\thttp.Error(w, \"Storage read limit\", http.StatusForbidden)\n\t\t} else if !ok && strings.HasPrefix(err.Error(), \"clickhouse response status 500: Code: 170,\") {\n\t\t\t// distributed table configuration error\n\t\t\t// clickhouse response status 500: Code: 170, e.displayText() = DB::Exception: Requested cluster 'cluster' not found\n\t\t\thttp.Error(w, \"Storage configuration error\", http.StatusServiceUnavailable)\n\t\t}\n\t} else {\n\t\t//logger.Debug(\"query\", zap.Error(err))\n\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t}\n}", "line_changes": {"deleted": [{"line_no": 19, "char_start": 714, "char_end": 762, "line": "\t\t\thttp.Error(w, errCode.Error(), errCode.Code)\n"}], "added": [{"line_no": 19, "char_start": 714, "char_end": 781, "line": "\t\t\thttp.Error(w, html.EscapeString(errCode.Error()), errCode.Code)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 731, "char_end": 749, "chars": "html.EscapeString("}, {"char_start": 764, "char_end": 765, "chars": ")"}]}, "commit_link": "github.com/lomik/graphite-clickhouse/commit/1cae40154d930d6885cac6344a41bf2fcc18b562", "file_name": "clickhouse.go", "vul_type": "cwe-079", "commit_msg": "Fix possible XSS\n\nSee\nhttps://github.com/lomik/graphite-clickhouse/security/code-scanning/5?query=ref%3Arefs%2Fpull%2F129%2Fhead", "parent_commit": "cf322598da33900d6fabdbc940e5fc7713fb41bb", "description": "Write a Go function to handle different types of storage-related errors and respond with appropriate HTTP status codes."}
{"func_name": "extend_volume", "func_src_before": "    def extend_volume(self, volume, new_size):\n        volume_name = self._get_3par_vol_name(volume['id'])\n        old_size = volume.size\n        growth_size = int(new_size) - old_size\n        LOG.debug(\"Extending Volume %s from %s to %s, by %s GB.\" %\n                  (volume_name, old_size, new_size, growth_size))\n        try:\n            self._cli_run(\"growvv -f %s %sg\" % (volume_name, growth_size),\n                          None)\n        except Exception:\n            with excutils.save_and_reraise_exception():\n                LOG.error(_(\"Error extending volume %s\") % volume)", "func_src_after": "    def extend_volume(self, volume, new_size):\n        volume_name = self._get_3par_vol_name(volume['id'])\n        old_size = volume.size\n        growth_size = int(new_size) - old_size\n        LOG.debug(\"Extending Volume %s from %s to %s, by %s GB.\" %\n                  (volume_name, old_size, new_size, growth_size))\n        try:\n            self._cli_run(['growvv', '-f', volume_name, '%dg' % growth_size])\n        except Exception:\n            with excutils.save_and_reraise_exception():\n                LOG.error(_(\"Error extending volume %s\") % volume)", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function to resize a storage volume by increasing its size and log the operation."}
{"func_name": "SMB2_write", "func_src_before": "SMB2_write(const unsigned int xid, struct cifs_io_parms *io_parms,\n\t   unsigned int *nbytes, struct kvec *iov, int n_vec)\n{\n\tstruct smb_rqst rqst;\n\tint rc = 0;\n\tstruct smb2_write_req *req = NULL;\n\tstruct smb2_write_rsp *rsp = NULL;\n\tint resp_buftype;\n\tstruct kvec rsp_iov;\n\tint flags = 0;\n\tunsigned int total_len;\n\n\t*nbytes = 0;\n\n\tif (n_vec < 1)\n\t\treturn rc;\n\n\trc = smb2_plain_req_init(SMB2_WRITE, io_parms->tcon, (void **) &req,\n\t\t\t     &total_len);\n\tif (rc)\n\t\treturn rc;\n\n\tif (io_parms->tcon->ses->server == NULL)\n\t\treturn -ECONNABORTED;\n\n\tif (smb3_encryption_required(io_parms->tcon))\n\t\tflags |= CIFS_TRANSFORM_REQ;\n\n\treq->sync_hdr.ProcessId = cpu_to_le32(io_parms->pid);\n\n\treq->PersistentFileId = io_parms->persistent_fid;\n\treq->VolatileFileId = io_parms->volatile_fid;\n\treq->WriteChannelInfoOffset = 0;\n\treq->WriteChannelInfoLength = 0;\n\treq->Channel = 0;\n\treq->Length = cpu_to_le32(io_parms->length);\n\treq->Offset = cpu_to_le64(io_parms->offset);\n\treq->DataOffset = cpu_to_le16(\n\t\t\t\toffsetof(struct smb2_write_req, Buffer));\n\treq->RemainingBytes = 0;\n\n\ttrace_smb3_write_enter(xid, io_parms->persistent_fid,\n\t\tio_parms->tcon->tid, io_parms->tcon->ses->Suid,\n\t\tio_parms->offset, io_parms->length);\n\n\tiov[0].iov_base = (char *)req;\n\t/* 1 for Buffer */\n\tiov[0].iov_len = total_len - 1;\n\n\tmemset(&rqst, 0, sizeof(struct smb_rqst));\n\trqst.rq_iov = iov;\n\trqst.rq_nvec = n_vec + 1;\n\n\trc = cifs_send_recv(xid, io_parms->tcon->ses, &rqst,\n\t\t\t    &resp_buftype, flags, &rsp_iov);\n\tcifs_small_buf_release(req);\n\trsp = (struct smb2_write_rsp *)rsp_iov.iov_base;\n\n\tif (rc) {\n\t\ttrace_smb3_write_err(xid, req->PersistentFileId,\n\t\t\t\t     io_parms->tcon->tid,\n\t\t\t\t     io_parms->tcon->ses->Suid,\n\t\t\t\t     io_parms->offset, io_parms->length, rc);\n\t\tcifs_stats_fail_inc(io_parms->tcon, SMB2_WRITE_HE);\n\t\tcifs_dbg(VFS, \"Send error in write = %d\\n\", rc);\n\t} else {\n\t\t*nbytes = le32_to_cpu(rsp->DataLength);\n\t\ttrace_smb3_write_done(xid, req->PersistentFileId,\n\t\t\t\t     io_parms->tcon->tid,\n\t\t\t\t     io_parms->tcon->ses->Suid,\n\t\t\t\t     io_parms->offset, *nbytes);\n\t}\n\n\tfree_rsp_buf(resp_buftype, rsp);\n\treturn rc;\n}", "func_src_after": "SMB2_write(const unsigned int xid, struct cifs_io_parms *io_parms,\n\t   unsigned int *nbytes, struct kvec *iov, int n_vec)\n{\n\tstruct smb_rqst rqst;\n\tint rc = 0;\n\tstruct smb2_write_req *req = NULL;\n\tstruct smb2_write_rsp *rsp = NULL;\n\tint resp_buftype;\n\tstruct kvec rsp_iov;\n\tint flags = 0;\n\tunsigned int total_len;\n\n\t*nbytes = 0;\n\n\tif (n_vec < 1)\n\t\treturn rc;\n\n\trc = smb2_plain_req_init(SMB2_WRITE, io_parms->tcon, (void **) &req,\n\t\t\t     &total_len);\n\tif (rc)\n\t\treturn rc;\n\n\tif (io_parms->tcon->ses->server == NULL)\n\t\treturn -ECONNABORTED;\n\n\tif (smb3_encryption_required(io_parms->tcon))\n\t\tflags |= CIFS_TRANSFORM_REQ;\n\n\treq->sync_hdr.ProcessId = cpu_to_le32(io_parms->pid);\n\n\treq->PersistentFileId = io_parms->persistent_fid;\n\treq->VolatileFileId = io_parms->volatile_fid;\n\treq->WriteChannelInfoOffset = 0;\n\treq->WriteChannelInfoLength = 0;\n\treq->Channel = 0;\n\treq->Length = cpu_to_le32(io_parms->length);\n\treq->Offset = cpu_to_le64(io_parms->offset);\n\treq->DataOffset = cpu_to_le16(\n\t\t\t\toffsetof(struct smb2_write_req, Buffer));\n\treq->RemainingBytes = 0;\n\n\ttrace_smb3_write_enter(xid, io_parms->persistent_fid,\n\t\tio_parms->tcon->tid, io_parms->tcon->ses->Suid,\n\t\tio_parms->offset, io_parms->length);\n\n\tiov[0].iov_base = (char *)req;\n\t/* 1 for Buffer */\n\tiov[0].iov_len = total_len - 1;\n\n\tmemset(&rqst, 0, sizeof(struct smb_rqst));\n\trqst.rq_iov = iov;\n\trqst.rq_nvec = n_vec + 1;\n\n\trc = cifs_send_recv(xid, io_parms->tcon->ses, &rqst,\n\t\t\t    &resp_buftype, flags, &rsp_iov);\n\trsp = (struct smb2_write_rsp *)rsp_iov.iov_base;\n\n\tif (rc) {\n\t\ttrace_smb3_write_err(xid, req->PersistentFileId,\n\t\t\t\t     io_parms->tcon->tid,\n\t\t\t\t     io_parms->tcon->ses->Suid,\n\t\t\t\t     io_parms->offset, io_parms->length, rc);\n\t\tcifs_stats_fail_inc(io_parms->tcon, SMB2_WRITE_HE);\n\t\tcifs_dbg(VFS, \"Send error in write = %d\\n\", rc);\n\t} else {\n\t\t*nbytes = le32_to_cpu(rsp->DataLength);\n\t\ttrace_smb3_write_done(xid, req->PersistentFileId,\n\t\t\t\t     io_parms->tcon->tid,\n\t\t\t\t     io_parms->tcon->ses->Suid,\n\t\t\t\t     io_parms->offset, *nbytes);\n\t}\n\n\tcifs_small_buf_release(req);\n\tfree_rsp_buf(resp_buftype, rsp);\n\treturn rc;\n}", "commit_link": "github.com/torvalds/linux/commit/6a3eb3360667170988f8a6477f6686242061488a", "file_name": "fs/cifs/smb2pdu.c", "vul_type": "cwe-416", "description": "In C, write a function to perform an SMB2 write operation with error handling and encryption check."}
{"func_name": "(anonymous)", "func_src_before": "describe('Config', function() {\n    it('should be defined', function () {\n        should.exist(Config);\n    });\n    \n    it('setOptions should overwrite options', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.trimLines = true;\n        config.setOptions({lineEnding: \"\\r\\n\", trimLines: undefined});\n        expect(config.options.lineEnding).to.equal(\"\\r\\n\");\n        expect(config.options.trimLines).to.equal(true);\n    });\n    \n    it('detectLineEndings should detect windows style (\\\\r\\\\n)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\r\\nline2\\r\\n\").should.equal(\"\\r\\n\");\n    });\n    \n    it('detectLineEndings should detect unix style (\\\\n)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\nline2\\n\").should.equal(\"\\n\");\n    });\n    \n    it('detectLineEndings should detect mac style (\\\\r)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\rline2\\r\").should.equal(\"\\r\");\n    });\n    \n    it('detectLineEndings should detect wtf style (\\\\n\\\\r)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\n\\rline2\\n\\r\").should.equal(\"\\n\\r\");\n    });\n    \n    it('decode should return a object', function () {\n        var config = new Config();\n        for(var i = 0; i < testData.length; i++){\n            config.decode(testData[i]).should.be.a('object');\n        }\n    });\n    \n    it('encode return should a string', function () {\n        var config = new Config();\n        config.encode({'Section':{'a': 1}}).should.be.a('string');\n        config.encode({'a':1}).should.be.a('string');\n        config.encode({}).should.be.a('string');\n    });\n    \n    it('decode should handle attributes without section', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        var result = config.decode(\"stray=foo\\n[Section1]\\na=b\\n\");\n        expect(result.stray).to.equal(\"foo\");\n    });\n    \n    it('encode should handle attributes without section', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        var encoded = config.encode({stray:'foo','SectionA':{'a': 1}});\n        var decoded = config.decode(encoded);\n        expect(decoded.stray).to.equal(\"foo\");\n    });\n    \n    it('decode should return object with same attributes', function () {\n        var data = \";comment\\n[SectionA]\\nkey=value\\n\";\n        var config = new Config();\n        config.options.lineEnding = config.detectLineEnding(data);\n        var result = config.decode(data);\n        result.should.be.a('object');\n        should.exist(result.SectionA);\n        result.SectionA.key.should.equal(\"value\");\n    });\n    \n    it('decode>encode>decode>encode return should produce consistent results', function () {\n        for(var i = 0; i < testData.length; i++){\n            var data = testData[i];\n            var config = new Config();\n            config.options.lineEnding = config.detectLineEnding(data);\n            var decoded1 = config.decode(data);\n            var encoded1 = config.encode(decoded1);\n            var decoded2 = config.decode(encoded1);\n            var encoded2 = config.encode(decoded2);\n            expect(encoded1).to.equal(encoded2);\n            expect(decoded1).to.deep.equal(decoded2);\n        }\n    });\n    \n    it('decode should be able to handle multiple comment identifier', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.commentIdentifiers = [';','//','#'];\n        var result = config.decode(\";comment1\\n//comment2\\n#comment3\\n\");\n        expect(result).to.deep.equal({});\n    });\n    \n    it('decode should be able to handle custom assign identifier', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.assignIdentifier = \":\";\n        var result = config.decode(\"[Section]\\nfoo:bar\\n\");\n        should.exist(result.Section);\n        expect(result.Section.foo).to.equal(\"bar\");\n    });\n\n    it('valueTrim should trim custom chars', function () {\n        var config = new Config();\n        expect(config.valueTrim('\"Te\"s\"t\"', '\"')).to.equal('Te\"s\"t');\n        expect(config.valueTrim('\"Te\"s\"t\"', '')).to.equal('\"Te\"s\"t\"');\n        expect(config.valueTrim('\"Te\"s\"t\"', '#')).to.equal('\"Te\"s\"t\"');\n        expect(config.valueTrim('\"\"Te\"s\"t\"\"', '\"\"')).to.equal('\"Te\"s\"t\"');\n        expect(config.valueTrim('[Te\"s\"t]', '[]')).to.equal('Te\"s\"t');\n    })\n\n    it('valueIdentifiers should trimed or added', function () {\n        var data = \"[SectionA]\\nkey1='val1'\\nkey2='val2'\\n\";\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.valueIdentifier = \"'\"\n        var result = config.decode(data);\n        expect(result.SectionA.key1).to.equal(\"val1\");\n        expect(result.SectionA.key2).to.equal(\"val2\");\n        var data2 = config.encode(result);\n        expect(data2).to.equal(data);\n    })\n\n    it('ignoreMultipleAssignIdentifier should ignore multiple assing identifiers', function () {\n        var data = \"a\\t1\\nb\\t\\t2\\nc\\t3\\t\\n\";\n        var config = new Config();\n        config.options.assignIdentifier = '\\t'\n        config.options.lineEnding = \"\\n\";\n        config.options.ignoreMultipleAssignIdentifier = true;\n        config.options.trimLines = false;\n        var result = config.decode(data);\n        expect(result.a).to.equal(\"1\");\n        expect(result.b).to.equal(\"2\");\n        expect(result.c).to.equal(\"3\\t\");\n    })\n});", "func_src_after": "    it('decode should prevent prototype pollution attacks', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.assignIdentifier = \":\";\n        var result = config.decode(\"[__proto__]\\nfoo:bar\\n\");\n        should.not.exist(result.__proto__.foo);\n        result = config.decode(\"[Section]\\n__proto__:bar\\n\");\n        expect(result.Section.__proto__).to.not.equal(\"bar\");\n    });", "line_changes": {"deleted": [], "added": [{"line_no": 1, "char_start": 0, "char_end": 74, "line": "    it('decode should prevent prototype pollution attacks', function () {\n"}, {"line_no": 2, "char_start": 74, "char_end": 109, "line": "        var config = new Config();\n"}, {"line_no": 3, "char_start": 109, "char_end": 151, "line": "        config.options.lineEnding = \"\\n\";\n"}, {"line_no": 4, "char_start": 151, "char_end": 198, "line": "        config.options.assignIdentifier = \":\";\n"}, {"line_no": 5, "char_start": 198, "char_end": 260, "line": "        var result = config.decode(\"[__proto__]\\nfoo:bar\\n\");\n"}, {"line_no": 6, "char_start": 260, "char_end": 308, "line": "        should.not.exist(result.__proto__.foo);\n"}, {"line_no": 7, "char_start": 308, "char_end": 370, "line": "        result = config.decode(\"[Section]\\n__proto__:bar\\n\");\n"}, {"line_no": 8, "char_start": 370, "char_end": 432, "line": "        expect(result.Section.__proto__).to.not.equal(\"bar\");\n"}, {"line_no": 9, "char_start": 432, "char_end": 439, "line": "    });\n"}]}, "char_changes": {"deleted": [{"char_start": 0, "char_end": 5615, "chars": "describe('Config', function() {\n    it('should be defined', function () {\n        should.exist(Config);\n    });\n    \n    it('setOptions should overwrite options', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.trimLines = true;\n        config.setOptions({lineEnding: \"\\r\\n\", trimLines: undefined});\n        expect(config.options.lineEnding).to.equal(\"\\r\\n\");\n        expect(config.options.trimLines).to.equal(true);\n    });\n    \n    it('detectLineEndings should detect windows style (\\\\r\\\\n)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\r\\nline2\\r\\n\").should.equal(\"\\r\\n\");\n    });\n    \n    it('detectLineEndings should detect unix style (\\\\n)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\nline2\\n\").should.equal(\"\\n\");\n    });\n    \n    it('detectLineEndings should detect mac style (\\\\r)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\rline2\\r\").should.equal(\"\\r\");\n    });\n    \n    it('detectLineEndings should detect wtf style (\\\\n\\\\r)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\n\\rline2\\n\\r\").should.equal(\"\\n\\r\");\n    });\n    \n    it('decode should return a object', function () {\n        var config = new Config();\n        for(var i = 0; i < testData.length; i++){\n            config.decode(testData[i]).should.be.a('object');\n        }\n    });\n    \n    it('encode return should a string', function () {\n        var config = new Config();\n        config.encode({'Section':{'a': 1}}).should.be.a('string');\n        config.encode({'a':1}).should.be.a('string');\n        config.encode({}).should.be.a('string');\n    });\n    \n    it('decode should handle attributes without section', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        var result = config.decode(\"stray=foo\\n[Section1]\\na=b\\n\");\n        expect(result.stray).to.equal(\"foo\");\n    });\n    \n    it('encode should handle attributes without section', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        var encoded = config.encode({stray:'foo','SectionA':{'a': 1}});\n        var decoded = config.decode(encoded);\n        expect(decoded.stray).to.equal(\"foo\");\n    });\n    \n    it('decode should return object with same attributes', function () {\n        var data = \";comment\\n[SectionA]\\nkey=value\\n\";\n        var config = new Config();\n        config.options.lineEnding = config.detectLineEnding(data);\n        var result = config.decode(data);\n        result.should.be.a('object');\n        should.exist(result.SectionA);\n        result.SectionA.key.should.equal(\"value\");\n    });\n    \n    it('decode>encode>decode>encode return should produce consistent results', function () {\n        for(var i = 0; i < testData.length; i++){\n            var data = testData[i];\n            var config = new Config();\n            config.options.lineEnding = config.detectLineEnding(data);\n            var decoded1 = config.decode(data);\n            var encoded1 = config.encode(decoded1);\n            var decoded2 = config.decode(encoded1);\n            var encoded2 = config.encode(decoded2);\n            expect(encoded1).to.equal(encoded2);\n            expect(decoded1).to.deep.equal(decoded2);\n        }\n    });\n    \n    it('decode should be able to handle multiple comment identifier', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.commentIdentifiers = [';','//','#'];\n        var result = config.decode(\";comment1\\n//comment2\\n#comment3\\n\");\n        expect(result).to.deep.equal({});\n    });\n    \n    it('decode should be able to handle custom assign identifier', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.assignIdentifier = \":\";\n        var result = config.decode(\"[Section]\\nfoo:bar\\n\");\n        should.exist(result.Section);\n        expect(result.Section.foo).to.equal(\"bar\");\n    });\n\n    it('valueTrim should trim custom chars', function () {\n        var config = new Config();\n        expect(config.valueTrim('\"Te\"s\"t\"', '\"')).to.equal('Te\"s\"t');\n        expect(config.valueTrim('\"Te\"s\"t\"', '')).to.equal('\"Te\"s\"t\"');\n        expect(config.valueTrim('\"Te\"s\"t\"', '#')).to.equal('\"Te\"s\"t\"');\n        expect(config.valueTrim('\"\"Te\"s\"t\"\"', '\"\"')).to.equal('\"Te\"s\"t\"');\n        expect(config.valueTrim('[Te\"s\"t]', '[]')).to.equal('Te\"s\"t');\n    })\n\n    it('valueIdentifiers should trimed or added', function () {\n        var data = \"[SectionA]\\nkey1='val1'\\nkey2='val2'\\n\";\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.valueIdentifier = \"'\"\n        var result = config.decode(data);\n        expect(result.SectionA.key1).to.equal(\"val1\");\n        expect(result.SectionA.key2).to.equal(\"val2\");\n        var data2 = config.encode(result);\n        expect(data2).to.equal(data);\n    })\n\n    it('ignoreMultipleAssignIdentifier should ignore multiple assing identifiers', function () {\n        var data = \"a\\t1\\nb\\t\\t2\\nc\\t3\\t\\n\";\n        var config = new Config();\n        config.options.assignIdentifier = '\\t'\n        config.options.lineEnding = \"\\n\";\n        config.options.ignoreMultipleAssignIdentifier = true;\n        config.options.trimLines = false;\n        var result = config.decode(data);\n        expect(result.a).to.equal(\"1\");\n        expect(result.b).to.equal(\"2\");\n        expect(result.c).to.equal(\"3\\t\");\n    })\n"}], "added": [{"char_start": 0, "char_end": 436, "chars": "    it('decode should prevent prototype pollution attacks', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.assignIdentifier = \":\";\n        var result = config.decode(\"[__proto__]\\nfoo:bar\\n\");\n        should.not.exist(result.__proto__.foo);\n        result = config.decode(\"[Section]\\n__proto__:bar\\n\");\n        expect(result.Section.__proto__).to.not.equal(\"bar\");\n    "}]}, "commit_link": "github.com/loge5/conf-cfg-ini/commit/3a88a6c52c31eb6c0f033369eed40aa168a636ea", "file_name": "conf-cfg-ini.spec.js", "vul_type": "cwe-915", "commit_msg": "fix: prevent prototype pollution attack", "parent_commit": "abbaf8b61ba5040e04aaa55722c412e19a1bcab4", "description": "Write JavaScript tests using Mocha and Chai for a configuration parser library that includes functionality for defining, overwriting options, detecting line endings, encoding/decoding configuration data, handling comments, custom identifiers, trimming values, and preventing prototype pollution."}
{"func_name": "__init__", "func_src_before": "  def __init__(self, on_ui_exit=None, command_sequence=None):\n    readline_ui.ReadlineUI.__init__(\n        self, on_ui_exit=on_ui_exit,\n        config=cli_config.CLIConfig(config_file_path=tempfile.mktemp()))\n\n    self._command_sequence = command_sequence\n    self._command_counter = 0\n\n    self.observers = {\"screen_outputs\": []}", "func_src_after": "  def __init__(self, on_ui_exit=None, command_sequence=None):\n    _, config_file_path = tempfile.mkstemp()  # safe to ignore fd\n    readline_ui.ReadlineUI.__init__(\n        self,\n        on_ui_exit=on_ui_exit,\n        config=cli_config.CLIConfig(config_file_path=config_file_path))\n\n    self._command_sequence = command_sequence\n    self._command_counter = 0\n\n    self.observers = {\"screen_outputs\": []}", "line_changes": {"deleted": [{"line_no": 3, "char_start": 99, "char_end": 136, "line": "        self, on_ui_exit=on_ui_exit,\n"}, {"line_no": 4, "char_start": 136, "char_end": 209, "line": "        config=cli_config.CLIConfig(config_file_path=tempfile.mktemp()))\n"}], "added": [{"line_no": 2, "char_start": 62, "char_end": 128, "line": "    _, config_file_path = tempfile.mkstemp()  # safe to ignore fd\n"}, {"line_no": 4, "char_start": 165, "char_end": 179, "line": "        self,\n"}, {"line_no": 5, "char_start": 179, "char_end": 210, "line": "        on_ui_exit=on_ui_exit,\n"}, {"line_no": 6, "char_start": 210, "char_end": 282, "line": "        config=cli_config.CLIConfig(config_file_path=config_file_path))\n"}]}, "char_changes": {"deleted": [{"char_start": 189, "char_end": 206, "chars": "tempfile.mktemp()"}], "added": [{"char_start": 62, "char_end": 128, "chars": "    _, config_file_path = tempfile.mkstemp()  # safe to ignore fd\n"}, {"char_start": 178, "char_end": 186, "chars": "\n       "}, {"char_start": 263, "char_end": 279, "chars": "config_file_path"}]}, "commit_link": "github.com/tensorflow/tensorflow/commit/599208b439e349f88c809e9d1f268c8c77718259", "file_name": "readline_ui_test.py", "vul_type": "cwe-377", "commit_msg": "Use `tempfile.mkstemp` instead of `tempfile.mktemp`.\n\nThe `tempfile.mktemp` function is [deprecated](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp) due to [security issues](https://cwe.mitre.org/data/definitions/377.html).\n\nThe switch is easy to do.\n\nPiperOrigin-RevId: 420359224\nChange-Id: I7bfc1df9cf931f45ec85d4878874ef41b9c55474", "description": "Create a Python class constructor that initializes a command-line interface with temporary configuration and allows for command sequence tracking and screen output observation."}
{"func_name": "pref_get", "func_src_before": "@app.route(\"/api/preferences/get/<key>\")\ndef pref_get(key):\n    if get_user() is None:\n        return \"Authentication required\", 401\n\n    if key in get_preferences():\n        return Response(json.dumps({'key': key, 'value': get_preferences()[key]}))\n    else:\n        return Response(json.dumps({'key': key, 'error': 'novalue'}))", "func_src_after": "@app.route(\"/api/preferences/get/<key>\")\ndef pref_get(key):\n    if get_user() is None:\n        return \"Authentication required\", 401\n\n    if key in get_preferences():\n        return Response(\n            json.dumps({'key': key, 'value': get_preferences()[key]}),\n            mimetype='application/json'\n        )\n    else:\n        return Response(\n            json.dumps({'key': key, 'error': 'novalue'}),\n            mimetype='application/json'\n        )", "line_changes": {"deleted": [{"line_no": 7, "char_start": 167, "char_end": 250, "line": "        return Response(json.dumps({'key': key, 'value': get_preferences()[key]}))\n"}, {"line_no": 9, "char_start": 260, "char_end": 329, "line": "        return Response(json.dumps({'key': key, 'error': 'novalue'}))\n"}], "added": [{"line_no": 7, "char_start": 167, "char_end": 192, "line": "        return Response(\n"}, {"line_no": 8, "char_start": 192, "char_end": 263, "line": "            json.dumps({'key': key, 'value': get_preferences()[key]}),\n"}, {"line_no": 9, "char_start": 263, "char_end": 303, "line": "            mimetype='application/json'\n"}, {"line_no": 10, "char_start": 303, "char_end": 313, "line": "        )\n"}, {"line_no": 12, "char_start": 323, "char_end": 348, "line": "        return Response(\n"}, {"line_no": 13, "char_start": 348, "char_end": 406, "line": "            json.dumps({'key': key, 'error': 'novalue'}),\n"}, {"line_no": 14, "char_start": 406, "char_end": 446, "line": "            mimetype='application/json'\n"}, {"line_no": 15, "char_start": 446, "char_end": 455, "line": "        )\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 191, "char_end": 204, "chars": "\n            "}, {"char_start": 261, "char_end": 311, "chars": ",\n            mimetype='application/json'\n        "}, {"char_start": 347, "char_end": 360, "chars": "\n            "}, {"char_start": 404, "char_end": 454, "chars": ",\n            mimetype='application/json'\n        "}]}, "commit_link": "github.com/wikimedia/analytics-quarry-web/commit/4b7e1d6a3a52ec6cf826a971135a38b0f74785d2", "file_name": "app.py", "vul_type": "cwe-079", "commit_msg": "SECURITY: Set correct Mime Type on /api/preferences\n\nPrevents a Reflected Cross-Site scripting (XSS) vulnerability\n\nBug: T270195\nChange-Id: I04bf53d2a939da369e54e91899615a3ffc3e5caf", "description": "Create a Python Flask endpoint to retrieve a user's preference by key, returning JSON responses and requiring user authentication."}
{"func_name": "images_from_fig", "func_src_before": "    def images_from_fig\n      fig_services = YAML.load(fig_yml) || {}\n      fig_services.map { |name, service_def| image_from_fig_service(name, service_def) }\n    end", "func_src_after": "    def images_from_fig\n      fig_services = YAML.safe_load(fig_yml) || {}\n      fig_services.map { |name, service_def| image_from_fig_service(name, service_def) }\n    end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 24, "char_end": 70, "line": "      fig_services = YAML.load(fig_yml) || {}\n"}], "added": [{"line_no": 2, "char_start": 24, "char_end": 75, "line": "      fig_services = YAML.safe_load(fig_yml) || {}\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 50, "char_end": 55, "chars": "safe_"}]}, "commit_link": "github.com/TravisCannon/panamax-api/commit/5f0bd8a0a60751bfd8ff51db83627b0477863b55", "file_name": "from_fig.rb", "vul_type": "cwe-502", "commit_msg": "Use YAML.safe_load when parsing user templates", "parent_commit": "0f311d932ddb665f5ebdde98cca040ec858f1010", "description": "Write a Ruby method named `images_from_fig` that loads a YAML configuration and maps each service to an image processing method."}
{"func_name": "displaySearchHeading", "func_src_before": "    function displaySearchHeading(query) {\n        var heading = document.getElementById(\"searchHeading\");\n        heading.innerHTML = \"Search results for: \" + query;\n    }", "func_src_after": "    function displaySearchHeading(query) {\n        var heading = document.getElementById(\"searchHeading\");\n        heading.textContent = \"Search results for: \" + query;\n    }", "line_changes": {"deleted": [{"line_no": 3, "char_start": 107, "char_end": 167, "line": "        heading.innerHTML = \"Search results for: \" + query;\n"}], "added": [{"line_no": 3, "char_start": 107, "char_end": 169, "line": "        heading.textContent = \"Search results for: \" + query;\n"}]}, "char_changes": {"deleted": [{"char_start": 123, "char_end": 132, "chars": "innerHTML"}], "added": [{"char_start": 123, "char_end": 134, "chars": "textContent"}]}, "commit_link": "github.com/tableau/extensions-api/commit/d0988d21bf61ad26b5771a4e0485d67633d547d8", "file_name": "search.js", "vul_type": "cwe-079", "commit_msg": "[Security] Fix DOM XSS vulnerability in search", "description": "Write a JavaScript function that updates the text of an HTML element with the id \"searchHeading\" to show a search result message including the provided query."}
{"func_name": "flb_gzip_compress", "func_src_before": "int flb_gzip_compress(void *in_data, size_t in_len,\n                      void **out_data, size_t *out_len)\n{\n    int flush;\n    int status;\n    int footer_start;\n    uint8_t *pb;\n    size_t out_size;\n    void *out_buf;\n    z_stream strm;\n    mz_ulong crc;\n\n    out_size = in_len + 32;\n    out_buf = flb_malloc(out_size);\n    if (!out_buf) {\n        flb_errno();\n        flb_error(\"[gzip] could not allocate outgoing buffer\");\n        return -1;\n    }\n\n    /* Initialize streaming buffer context */\n    memset(&strm, '\\0', sizeof(strm));\n    strm.zalloc    = Z_NULL;\n    strm.zfree     = Z_NULL;\n    strm.opaque    = Z_NULL;\n    strm.next_in   = in_data;\n    strm.avail_in  = in_len;\n    strm.total_out = 0;\n\n    /* Deflate mode */\n    deflateInit2(&strm, Z_DEFAULT_COMPRESSION,\n                 Z_DEFLATED, -Z_DEFAULT_WINDOW_BITS, 9, Z_DEFAULT_STRATEGY);\n\n    /*\n     * Miniz don't support GZip format directly, instead we will:\n     *\n     * - append manual GZip magic bytes\n     * - deflate raw content\n     * - append manual CRC32 data\n     */\n    gzip_header(out_buf);\n\n    /* Header offset */\n    pb = (uint8_t *) out_buf + FLB_GZIP_HEADER_OFFSET;\n\n    flush = Z_NO_FLUSH;\n    while (1) {\n        strm.next_out  = pb + strm.total_out;\n        strm.avail_out = out_size - (pb - (uint8_t *) out_buf);\n\n        if (strm.avail_in == 0) {\n            flush = Z_FINISH;\n        }\n\n        status = deflate(&strm, flush);\n        if (status == Z_STREAM_END) {\n            break;\n        }\n        else if (status != Z_OK) {\n            deflateEnd(&strm);\n            return -1;\n        }\n    }\n\n    if (deflateEnd(&strm) != Z_OK) {\n        flb_free(out_buf);\n        return -1;\n    }\n    *out_len = strm.total_out;\n\n    /* Construct the gzip checksum (CRC32 footer) */\n    footer_start = FLB_GZIP_HEADER_OFFSET + *out_len;\n    pb = (uint8_t *) out_buf + footer_start;\n\n    crc = mz_crc32(MZ_CRC32_INIT, in_data, in_len);\n    *pb++ = crc & 0xFF;\n    *pb++ = (crc >> 8) & 0xFF;\n    *pb++ = (crc >> 16) & 0xFF;\n    *pb++ = (crc >> 24) & 0xFF;\n    *pb++ = in_len & 0xFF;\n    *pb++ = (in_len >> 8) & 0xFF;\n    *pb++ = (in_len >> 16) & 0xFF;\n    *pb++ = (in_len >> 24) & 0xFF;\n\n    /* Set the real buffer size for the caller */\n    *out_len += FLB_GZIP_HEADER_OFFSET + 8;\n    *out_data = out_buf;\n\n    return 0;\n}", "func_src_after": "int flb_gzip_compress(void *in_data, size_t in_len,\n                      void **out_data, size_t *out_len)\n{\n    int flush;\n    int status;\n    int footer_start;\n    uint8_t *pb;\n    size_t out_size;\n    void *out_buf;\n    z_stream strm;\n    mz_ulong crc;\n\n\n    /*\n     * GZIP relies on an algorithm with worst-case expansion\n     * of 5 bytes per 32KB data. This means we need to create a variable\n     * length output, that depends on the input length.\n     * See RFC 1951 for details.\n     */\n    int max_input_expansion = ((int)(in_len / 32000) + 1) * 5;\n\n    /*\n     * Max compressed size is equal to sum of:\n     *   10 byte header\n     *   8 byte foot\n     *   max input expansion\n     *   size of input\n     */\n    out_size = 10 + 8 + max_input_expansion + in_len;\n    out_buf = flb_malloc(out_size);\n\n    if (!out_buf) {\n        flb_errno();\n        flb_error(\"[gzip] could not allocate outgoing buffer\");\n        return -1;\n    }\n\n    /* Initialize streaming buffer context */\n    memset(&strm, '\\0', sizeof(strm));\n    strm.zalloc    = Z_NULL;\n    strm.zfree     = Z_NULL;\n    strm.opaque    = Z_NULL;\n    strm.next_in   = in_data;\n    strm.avail_in  = in_len;\n    strm.total_out = 0;\n\n    /* Deflate mode */\n    deflateInit2(&strm, Z_DEFAULT_COMPRESSION,\n                 Z_DEFLATED, -Z_DEFAULT_WINDOW_BITS, 9, Z_DEFAULT_STRATEGY);\n\n    /*\n     * Miniz don't support GZip format directly, instead we will:\n     *\n     * - append manual GZip magic bytes\n     * - deflate raw content\n     * - append manual CRC32 data\n     */\n    gzip_header(out_buf);\n\n    /* Header offset */\n    pb = (uint8_t *) out_buf + FLB_GZIP_HEADER_OFFSET;\n\n    flush = Z_NO_FLUSH;\n    while (1) {\n        strm.next_out  = pb + strm.total_out;\n        strm.avail_out = out_size - (pb - (uint8_t *) out_buf);\n\n        if (strm.avail_in == 0) {\n            flush = Z_FINISH;\n        }\n\n        status = deflate(&strm, flush);\n        if (status == Z_STREAM_END) {\n            break;\n        }\n        else if (status != Z_OK) {\n            deflateEnd(&strm);\n            return -1;\n        }\n    }\n\n    if (deflateEnd(&strm) != Z_OK) {\n        flb_free(out_buf);\n        return -1;\n    }\n    *out_len = strm.total_out;\n\n    /* Construct the gzip checksum (CRC32 footer) */\n    footer_start = FLB_GZIP_HEADER_OFFSET + *out_len;\n    pb = (uint8_t *) out_buf + footer_start;\n\n    crc = mz_crc32(MZ_CRC32_INIT, in_data, in_len);\n    *pb++ = crc & 0xFF;\n    *pb++ = (crc >> 8) & 0xFF;\n    *pb++ = (crc >> 16) & 0xFF;\n    *pb++ = (crc >> 24) & 0xFF;\n    *pb++ = in_len & 0xFF;\n    *pb++ = (in_len >> 8) & 0xFF;\n    *pb++ = (in_len >> 16) & 0xFF;\n    *pb++ = (in_len >> 24) & 0xFF;\n\n    /* Set the real buffer size for the caller */\n    *out_len += FLB_GZIP_HEADER_OFFSET + 8;\n    *out_data = out_buf;\n\n    return 0;\n}", "commit_link": "github.com/fluent/fluent-bit/commit/cadff53c093210404aed01c4cf586adb8caa07af", "file_name": "src/flb_gzip.c", "vul_type": "cwe-787", "description": "Write a C function to compress data using GZIP and handle memory allocation for the output buffer."}
{"func_name": "get", "func_src_before": "  @handler.unsupported_on_local_server\n  @handler.get(handler.HTML)\n  def get(self):\n    \"\"\"Handle a get request.\"\"\"\n    self.render(\n        'login.html', {\n            'apiKey': local_config.ProjectConfig().get('firebase.api_key'),\n            'authDomain': auth.auth_domain(),\n            'dest': self.request.get('dest'),\n        })", "func_src_after": "  @handler.unsupported_on_local_server\n  @handler.get(handler.HTML)\n  def get(self):\n    \"\"\"Handle a get request.\"\"\"\n    dest = self.request.get('dest')\n    base_handler.check_redirect_url(dest)\n\n    self.render(\n        'login.html', {\n            'apiKey': local_config.ProjectConfig().get('firebase.api_key'),\n            'authDomain': auth.auth_domain(),\n            'dest': dest,\n        })", "commit_link": "github.com/google/clusterfuzz/commit/3d66c1146550eecd4e34d47332a8616b435a21fe", "file_name": "src/appengine/handlers/login.py", "vul_type": "cwe-079", "description": "Write a Python function decorated to handle HTML GET requests, which renders a login page with configuration details and optionally checks the redirect URL."}
{"func_name": "deleteKey", "func_src_before": "def deleteKey(client):\n\t\"\"\"Deletes the specified key.\n\tReturns an error if the key doesn't exist\n\t\"\"\"\n\tglobal BAD_REQUEST\n\tglobal NOT_FOUND\n\n\tvalidateClient(client)\n\n\tclient_pub_key = loadClientRSAKey(client)\n\ttoken_data = decodeRequestToken(request.data, client_pub_key)\n\n\tif re.search('[^a-zA-Z0-9]', token_data['key']):\n\t\traise FoxlockError(BAD_REQUEST, 'Invalid key requested')\n\n\ttry:\n\t\tos.remove('keys/%s/%s.key' % (client, token_data['key']))\n\texcept FileNotFoundError:\n\t\traise FoxlockError(NOT_FOUND, \"Key '%s' not found\" % token_data['key'])\n\n\treturn \"Key '%s' successfully deleted\" % token_data['key']", "func_src_after": "def deleteKey(client):\n\t\"\"\"Deletes the specified key.\n\tReturns an error if the key doesn't exist\n\t\"\"\"\n\tglobal NOT_FOUND\n\n\tvalidateClient(client)\n\tclient_pub_key = loadClientRSAKey(client)\n\ttoken_data = decodeRequestToken(request.data, client_pub_key)\n\tvalidateKeyName(token_data['key'])\n\n\ttry:\n\t\tos.remove('keys/%s/%s.key' % (client, token_data['key']))\n\texcept FileNotFoundError:\n\t\traise FoxlockError(NOT_FOUND, \"Key '%s' not found\" % token_data['key'])\n\n\treturn \"Key '%s' successfully deleted\" % token_data['key']", "commit_link": "github.com/Mimickal/FoxLock/commit/7c665e556987f4e2c1a75e143a1e80ae066ad833", "file_name": "impl.py", "vul_type": "cwe-022", "description": "Write a Python function named `deleteKey` that removes a client's key file and handles the case where the key does not exist."}
{"func_name": "test_get_iscsi_ip", "func_src_before": "    def test_get_iscsi_ip(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record driver set up\n        self.clear_mox()\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_port_cmd = 'showport'\n        _run_ssh(show_port_cmd, False).AndReturn([pack(PORT_RET), ''])\n\n        show_port_i_cmd = 'showport -iscsi'\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(READY_ISCSI_PORT_RET),\n                                                    ''])\n\n        show_port_i_cmd = 'showport -iscsiname'\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(SHOW_PORT_ISCSI), ''])\n\n        #record\n        show_vlun_cmd = 'showvlun -a -host fakehost'\n        show_vlun_ret = 'no vluns listed\\r\\n'\n        _run_ssh(show_vlun_cmd, False).AndReturn([pack(show_vlun_ret), ''])\n        show_vlun_cmd = 'showvlun -a -showcols Port'\n        _run_ssh(show_vlun_cmd, False).AndReturn([pack(SHOW_VLUN_NONE), ''])\n\n        self.mox.ReplayAll()\n\n        config = self.setup_configuration()\n        config.iscsi_ip_address = '10.10.10.10'\n        config.hp3par_iscsi_ips = ['10.10.220.253', '10.10.220.252']\n        self.setup_driver(config, set_up_fakes=False)\n\n        ip = self.driver._get_iscsi_ip('fakehost')\n        self.assertEqual(ip, '10.10.220.252')", "func_src_after": "    def test_get_iscsi_ip(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record driver set up\n        self.clear_mox()\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_port_cmd = ['showport']\n        _run_ssh(show_port_cmd, False).AndReturn([pack(PORT_RET), ''])\n\n        show_port_i_cmd = ['showport', '-iscsi']\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(READY_ISCSI_PORT_RET),\n                                                    ''])\n\n        show_port_i_cmd = ['showport', '-iscsiname']\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(SHOW_PORT_ISCSI), ''])\n\n        #record\n        show_vlun_cmd = ['showvlun', '-a', '-host', 'fakehost']\n        show_vlun_ret = 'no vluns listed\\r\\n'\n        _run_ssh(show_vlun_cmd, False).AndReturn([pack(show_vlun_ret), ''])\n        show_vlun_cmd = ['showvlun', '-a', '-showcols', 'Port']\n        _run_ssh(show_vlun_cmd, False).AndReturn([pack(SHOW_VLUN_NONE), ''])\n\n        self.mox.ReplayAll()\n\n        config = self.setup_configuration()\n        config.iscsi_ip_address = '10.10.10.10'\n        config.hp3par_iscsi_ips = ['10.10.220.253', '10.10.220.252']\n        self.setup_driver(config, set_up_fakes=False)\n\n        ip = self.driver._get_iscsi_ip('fakehost')\n        self.assertEqual(ip, '10.10.220.252')", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/tests/test_hp3par.py", "vul_type": "cwe-078", "description": "Write a Python unit test function that mocks SSH commands to retrieve iSCSI IP information and asserts the expected IP address."}
{"func_name": "hci_uart_set_proto", "func_src_before": "static int hci_uart_set_proto(struct hci_uart *hu, int id)\n{\n\tconst struct hci_uart_proto *p;\n\tint err;\n\n\tp = hci_uart_get_proto(id);\n\tif (!p)\n\t\treturn -EPROTONOSUPPORT;\n\n\thu->proto = p;\n\tset_bit(HCI_UART_PROTO_READY, &hu->flags);\n\n\terr = hci_uart_register_dev(hu);\n\tif (err) {\n\t\tclear_bit(HCI_UART_PROTO_READY, &hu->flags);\n\t\treturn err;\n\t}\n\n\treturn 0;\n}", "func_src_after": "static int hci_uart_set_proto(struct hci_uart *hu, int id)\n{\n\tconst struct hci_uart_proto *p;\n\tint err;\n\n\tp = hci_uart_get_proto(id);\n\tif (!p)\n\t\treturn -EPROTONOSUPPORT;\n\n\thu->proto = p;\n\n\terr = hci_uart_register_dev(hu);\n\tif (err) {\n\t\treturn err;\n\t}\n\n\tset_bit(HCI_UART_PROTO_READY, &hu->flags);\n\treturn 0;\n}", "commit_link": "github.com/torvalds/linux/commit/56897b217a1d0a91c9920cb418d6b3fe922f590a", "file_name": "drivers/bluetooth/hci_ldisc.c", "vul_type": "cwe-416", "description": "Write a C function named `hci_uart_set_proto` that assigns a UART protocol to a device and handles registration, returning an error code if the protocol is unsupported or registration fails."}
{"func_name": "X86_insn_reg_intel", "func_src_before": "x86_reg X86_insn_reg_intel(unsigned int id, enum cs_ac_type *access)\n{\n\tunsigned int first = 0;\n\tunsigned int last = ARR_SIZE(insn_regs_intel) - 1;\n\tunsigned int mid = ARR_SIZE(insn_regs_intel) / 2;\n\n\tif (!intel_regs_sorted) {\n\t\tmemcpy(insn_regs_intel_sorted, insn_regs_intel,\n\t\t\t\tsizeof(insn_regs_intel_sorted));\n\t\tqsort(insn_regs_intel_sorted,\n\t\t\t\tARR_SIZE(insn_regs_intel_sorted),\n\t\t\t\tsizeof(struct insn_reg), regs_cmp);\n\t\tintel_regs_sorted = true;\n\t}\n\n\twhile (first <= last) {\n\t\tif (insn_regs_intel_sorted[mid].insn < id) {\n\t\t\tfirst = mid + 1;\n\t\t} else if (insn_regs_intel_sorted[mid].insn == id) {\n\t\t\tif (access) {\n\t\t\t\t*access = insn_regs_intel_sorted[mid].access;\n\t\t\t}\n\t\t\treturn insn_regs_intel_sorted[mid].reg;\n\t\t} else {\n\t\t\tif (mid == 0)\n\t\t\t\tbreak;\n\t\t\tlast = mid - 1;\n\t\t}\n\t\tmid = (first + last) / 2;\n\t}\n\n\t// not found\n\treturn 0;\n}", "func_src_after": "x86_reg X86_insn_reg_intel(unsigned int id, enum cs_ac_type *access)\n{\n\tstatic bool intel_regs_sorted = false;\n\tunsigned int first = 0;\n\tunsigned int last = ARR_SIZE(insn_regs_intel) - 1;\n\tunsigned int mid;\n\n\tif (!intel_regs_sorted) {\n\t\tmemcpy(insn_regs_intel_sorted, insn_regs_intel,\n\t\t\t\tsizeof(insn_regs_intel_sorted));\n\t\tqsort(insn_regs_intel_sorted,\n\t\t\t\tARR_SIZE(insn_regs_intel_sorted),\n\t\t\t\tsizeof(struct insn_reg), regs_cmp);\n\t\tintel_regs_sorted = true;\n\t}\n\n\tif (insn_regs_intel_sorted[0].insn > id ||\n\t\t\tinsn_regs_intel_sorted[last].insn < id) {\n\t\treturn 0;\n\t}\n\n\twhile (first <= last) {\n\t\tmid = (first + last) / 2;\n\t\tif (insn_regs_intel_sorted[mid].insn < id) {\n\t\t\tfirst = mid + 1;\n\t\t} else if (insn_regs_intel_sorted[mid].insn == id) {\n\t\t\tif (access) {\n\t\t\t\t*access = insn_regs_intel_sorted[mid].access;\n\t\t\t}\n\t\t\treturn insn_regs_intel_sorted[mid].reg;\n\t\t} else {\n\t\t\tif (mid == 0)\n\t\t\t\tbreak;\n\t\t\tlast = mid - 1;\n\t\t}\n\t}\n\n\t// not found\n\treturn 0;\n}", "commit_link": "github.com/aquynh/capstone/commit/87a25bb543c8e4c09b48d4b4a6c7db31ce58df06", "file_name": "arch/X86/X86Mapping.c", "vul_type": "cwe-125", "description": "Write a C function named `X86_insn_reg_intel` that performs a binary search on a sorted array to find a register by its ID and optionally returns its access type."}
{"func_name": "unique_short", "func_src_before": "def unique_short():\n    matches = 1\n    while matches == 1:\n        short = generate_short()\n    \tmatches = query_db(\"select * from urls where short='%s'\" % (short))\n    return short", "func_src_after": "def unique_short():\n    matches = 1\n    while matches == 1:\n        short = generate_short()\n    \tmatches = query_db(\"select * from urls where short=?\", [short])\n    return short", "line_changes": {"deleted": [{"line_no": 5, "char_start": 93, "char_end": 166, "line": "    \tmatches = query_db(\"select * from urls where short='%s'\" % (short))\n"}], "added": [{"line_no": 5, "char_start": 93, "char_end": 162, "line": "    \tmatches = query_db(\"select * from urls where short=?\", [short])\n"}]}, "char_changes": {"deleted": [{"char_start": 149, "char_end": 158, "chars": "'%s'\" % ("}, {"char_start": 163, "char_end": 164, "chars": ")"}], "added": [{"char_start": 149, "char_end": 154, "chars": "?\", ["}, {"char_start": 159, "char_end": 160, "chars": "]"}]}, "commit_link": "github.com/uknof/shortener/commit/3e6fe206f764afb17af14609474d0da36705f3e3", "file_name": "shortner.py", "vul_type": "cwe-089", "commit_msg": "fix up sql to avoid injection", "description": "Write a Python function named `unique_short` that generates a unique short string by checking against a database until no matches are found."}
{"func_name": "r_pkcs7_parse_cms", "func_src_before": "RCMS *r_pkcs7_parse_cms (const ut8 *buffer, ut32 length) {\n\tRASN1Object *object;\n\tRCMS *container;\n\tif (!buffer || !length) {\n\t\treturn NULL;\n\t}\n\tcontainer = R_NEW0 (RCMS);\n\tif (!container) {\n\t\treturn NULL;\n\t}\n\tobject = r_asn1_create_object (buffer, length);\n\tif (!object || object->list.length != 2 || !object->list.objects[0] || object->list.objects[1]->list.length != 1) {\n\t\tr_asn1_free_object (object);\n\t\tfree (container);\n\t\treturn NULL;\n\t}\n\tcontainer->contentType = r_asn1_stringify_oid (object->list.objects[0]->sector, object->list.objects[0]->length);\n\tr_pkcs7_parse_signeddata (&container->signedData, object->list.objects[1]->list.objects[0]);\n\tr_asn1_free_object (object);\n\treturn container;\n}", "func_src_after": "RCMS *r_pkcs7_parse_cms (const ut8 *buffer, ut32 length) {\n\tRASN1Object *object;\n\tRCMS *container;\n\tif (!buffer || !length) {\n\t\treturn NULL;\n\t}\n\tcontainer = R_NEW0 (RCMS);\n\tif (!container) {\n\t\treturn NULL;\n\t}\n\tobject = r_asn1_create_object (buffer, length);\n\tif (!object || object->list.length != 2 || !object->list.objects ||\n\t\t!object->list.objects[0] || !object->list.objects[1] ||\n\t\tobject->list.objects[1]->list.length != 1) {\n\t\tr_asn1_free_object (object);\n\t\tfree (container);\n\t\treturn NULL;\n\t}\n\tcontainer->contentType = r_asn1_stringify_oid (object->list.objects[0]->sector, object->list.objects[0]->length);\n\tr_pkcs7_parse_signeddata (&container->signedData, object->list.objects[1]->list.objects[0]);\n\tr_asn1_free_object (object);\n\treturn container;\n}", "commit_link": "github.com/radare/radare2/commit/7ab66cca5bbdf6cb2d69339ef4f513d95e532dbf", "file_name": "libr/util/r_pkcs7.c", "vul_type": "cwe-476", "description": "Write a function in C that parses a CMS (Cryptographic Message Syntax) structure from a given buffer and length, returning a pointer to the parsed CMS object or NULL on failure."}
{"func_name": "verify_credentials", "func_src_before": "    async def verify_credentials(self, login, password):\n        \"\"\" verify login and password \"\"\"\n\n        try:\n            async with aiopg.create_pool(self.dsn) as pool:\n                async with pool.acquire() as conn:\n                    async with conn.cursor() as cur:\n                        query = f\"\"\"\n                SELECT id, password, salt\n                FROM aio.users\n                WHERE aio.users.login = '{login}'\"\"\"\n                        await cur.execute(query)\n                        async for user_id, user_password, user_salt in cur:\n                            _, test_hash = hashpass(password, user_salt)\n                            if test_hash.decode() == user_password:\n                                return user_id\n        except Exception as err:\n            print(err)\n            raise HTTPForbidden()", "func_src_after": "    async def verify_credentials(self, login, password):\n        \"\"\" verify login and password \"\"\"\n\n        try:\n            async with aiopg.create_pool(self.dsn) as pool:\n                async with pool.acquire() as conn:\n                    async with conn.cursor() as cur:\n                        query = f\"\"\"\n                SELECT id, password, salt\n                FROM aio.users\n                WHERE aio.users.login = %s\"\"\"\n                        await cur.execute(query, (login, ))\n                        async for user_id, user_password, user_salt in cur:\n                            _, test_hash = hashpass(password, user_salt)\n                            if test_hash.decode() == user_password:\n                                return user_id\n        except Exception as err:\n            print(err)\n            raise web.HTTPForbidden()", "line_changes": {"deleted": [{"line_no": 11, "char_start": 387, "char_end": 440, "line": "                WHERE aio.users.login = '{login}'\"\"\"\n"}, {"line_no": 12, "char_start": 440, "char_end": 489, "line": "                        await cur.execute(query)\n"}, {"line_no": 19, "char_start": 809, "char_end": 842, "line": "            raise HTTPForbidden()\n"}], "added": [{"line_no": 11, "char_start": 387, "char_end": 433, "line": "                WHERE aio.users.login = %s\"\"\"\n"}, {"line_no": 12, "char_start": 433, "char_end": 493, "line": "                        await cur.execute(query, (login, ))\n"}, {"line_no": 19, "char_start": 813, "char_end": 850, "line": "            raise web.HTTPForbidden()\n"}]}, "char_changes": {"deleted": [{"char_start": 427, "char_end": 436, "chars": "'{login}'"}], "added": [{"char_start": 427, "char_end": 429, "chars": "%s"}, {"char_start": 480, "char_end": 491, "chars": ", (login, )"}, {"char_start": 831, "char_end": 835, "chars": "web."}]}, "commit_link": "github.com/TeaTracer/aio-test/commit/3da13f66b0c1ab1d26bf4b56f476ade60a43d8d4", "file_name": "db.py", "vul_type": "cwe-089", "commit_msg": "Fix sql injections in token and password verifications. Fix HTTTPForbidden exception.", "description": "Write a Python function using `aiopg` to asynchronously verify user login credentials against a PostgreSQL database."}
{"func_name": "load_config", "func_src_before": "def load_config(config_file):\n    config_path = config_file if config_file else \".ansible-lint\"\n\n    if os.path.exists(config_path):\n        with open(config_path, \"r\") as stream:\n            try:\n                return yaml.load(stream)\n            except yaml.YAMLError:\n                pass\n\n    return None", "func_src_after": "def load_config(config_file):\n    config_path = config_file if config_file else \".ansible-lint\"\n\n    if os.path.exists(config_path):\n        with open(config_path, \"r\") as stream:\n            try:\n                return yaml.safe_load(stream)\n            except yaml.YAMLError:\n                pass\n\n    return None", "line_changes": {"deleted": [{"line_no": 7, "char_start": 197, "char_end": 238, "line": "                return yaml.load(stream)\n"}], "added": [{"line_no": 7, "char_start": 197, "char_end": 243, "line": "                return yaml.safe_load(stream)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 225, "char_end": 230, "chars": "safe_"}]}, "commit_link": "github.com/MatrixCrawler/ansible-lint/commit/c8685daee3f53ea0889ec697ff61c20996904381", "file_name": "__main__.py", "vul_type": "cwe-502", "commit_msg": "Use yaml.safe_load rather than yaml.load", "parent_commit": "f92cc06ab26ef24c1cdcdefaab65276c2424a90c", "description": "Write a Python function to load a YAML configuration from a file, with a default filename fallback."}
{"func_name": "_ensure_vdisk_no_fc_mappings", "func_src_before": "    def _ensure_vdisk_no_fc_mappings(self, name, allow_snaps=True):\n        # Ensure vdisk has no FlashCopy mappings\n        mapping_ids = self._get_vdisk_fc_mappings(name)\n        while len(mapping_ids):\n            wait_for_copy = False\n            for map_id in mapping_ids:\n                attrs = self._get_flashcopy_mapping_attributes(map_id)\n                if not attrs:\n                    continue\n                source = attrs['source_vdisk_name']\n                target = attrs['target_vdisk_name']\n                copy_rate = attrs['copy_rate']\n                status = attrs['status']\n\n                if copy_rate == '0':\n                    # Case #2: A vdisk that has snapshots\n                    if source == name:\n                        if not allow_snaps:\n                            return False\n                        ssh_cmd = ('svctask chfcmap -copyrate 50 '\n                                   '-autodelete on %s' % map_id)\n                        out, err = self._run_ssh(ssh_cmd)\n                        wait_for_copy = True\n                    # Case #3: A snapshot\n                    else:\n                        msg = (_('Vdisk %(name)s not involved in '\n                                 'mapping %(src)s -> %(tgt)s') %\n                               {'name': name, 'src': source, 'tgt': target})\n                        self._driver_assert(target == name, msg)\n                        if status in ['copying', 'prepared']:\n                            self._run_ssh('svctask stopfcmap %s' % map_id)\n                        elif status in ['stopping', 'preparing']:\n                            wait_for_copy = True\n                        else:\n                            self._run_ssh('svctask rmfcmap -force %s' % map_id)\n                # Case 4: Copy in progress - wait and will autodelete\n                else:\n                    if status == 'prepared':\n                        self._run_ssh('svctask stopfcmap %s' % map_id)\n                        self._run_ssh('svctask rmfcmap -force %s' % map_id)\n                    elif status == 'idle_or_copied':\n                        # Prepare failed\n                        self._run_ssh('svctask rmfcmap -force %s' % map_id)\n                    else:\n                        wait_for_copy = True\n            if wait_for_copy:\n                time.sleep(5)\n            mapping_ids = self._get_vdisk_fc_mappings(name)\n        return True", "func_src_after": "    def _ensure_vdisk_no_fc_mappings(self, name, allow_snaps=True):\n        # Ensure vdisk has no FlashCopy mappings\n        mapping_ids = self._get_vdisk_fc_mappings(name)\n        while len(mapping_ids):\n            wait_for_copy = False\n            for map_id in mapping_ids:\n                attrs = self._get_flashcopy_mapping_attributes(map_id)\n                if not attrs:\n                    continue\n                source = attrs['source_vdisk_name']\n                target = attrs['target_vdisk_name']\n                copy_rate = attrs['copy_rate']\n                status = attrs['status']\n\n                if copy_rate == '0':\n                    # Case #2: A vdisk that has snapshots\n                    if source == name:\n                        if not allow_snaps:\n                            return False\n                        ssh_cmd = ['svctask', 'chfcmap', '-copyrate', '50',\n                                   '-autodelete', 'on', map_id]\n                        out, err = self._run_ssh(ssh_cmd)\n                        wait_for_copy = True\n                    # Case #3: A snapshot\n                    else:\n                        msg = (_('Vdisk %(name)s not involved in '\n                                 'mapping %(src)s -> %(tgt)s') %\n                               {'name': name, 'src': source, 'tgt': target})\n                        self._driver_assert(target == name, msg)\n                        if status in ['copying', 'prepared']:\n                            self._run_ssh(['svctask', 'stopfcmap', map_id])\n                        elif status in ['stopping', 'preparing']:\n                            wait_for_copy = True\n                        else:\n                            self._run_ssh(['svctask', 'rmfcmap', '-force',\n                                           map_id])\n                # Case 4: Copy in progress - wait and will autodelete\n                else:\n                    if status == 'prepared':\n                        self._run_ssh(['svctask', 'stopfcmap', map_id])\n                        self._run_ssh(['svctask', 'rmfcmap', '-force', map_id])\n                    elif status == 'idle_or_copied':\n                        # Prepare failed\n                        self._run_ssh(['svctask', 'rmfcmap', '-force', map_id])\n                    else:\n                        wait_for_copy = True\n            if wait_for_copy:\n                time.sleep(5)\n            mapping_ids = self._get_vdisk_fc_mappings(name)\n        return True", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to check and handle FlashCopy mappings for a virtual disk, with an option to allow snapshots."}
{"func_name": "test_initialize_connection", "func_src_before": "    def test_initialize_connection(self):\n        self.driver._eql_execute = self.mox.\\\n            CreateMock(self.driver._eql_execute)\n        volume = {'name': self.volume_name}\n        self.stubs.Set(self.driver, \"_get_iscsi_properties\",\n                       self._fake_get_iscsi_properties)\n        self.driver._eql_execute('volume', 'select', volume['name'], 'access',\n                                 'create', 'initiator',\n                                 self.connector['initiator'],\n                                 'authmethod chap',\n                                 'username',\n                                 self.configuration.eqlx_chap_login)\n        self.mox.ReplayAll()\n        iscsi_properties = self.driver.initialize_connection(volume,\n                                                             self.connector)\n        self.assertEqual(iscsi_properties['data'],\n                         self._fake_get_iscsi_properties(volume))", "func_src_after": "    def test_initialize_connection(self):\n        self.driver._eql_execute = self.mox.\\\n            CreateMock(self.driver._eql_execute)\n        volume = {'name': self.volume_name}\n        self.stubs.Set(self.driver, \"_get_iscsi_properties\",\n                       self._fake_get_iscsi_properties)\n        self.driver._eql_execute('volume', 'select', volume['name'], 'access',\n                                 'create', 'initiator',\n                                 self.connector['initiator'],\n                                 'authmethod', 'chap',\n                                 'username',\n                                 self.configuration.eqlx_chap_login)\n        self.mox.ReplayAll()\n        iscsi_properties = self.driver.initialize_connection(volume,\n                                                             self.connector)\n        self.assertEqual(iscsi_properties['data'],\n                         self._fake_get_iscsi_properties(volume))", "commit_link": "github.com/thatsdone/cinder/commit/9e858bebb89de05b1c9ecc27f5bd9fbff95a728e", "file_name": "cinder/tests/test_eqlx.py", "vul_type": "cwe-078", "description": "Write a Python unit test that mocks the execution of an iSCSI volume access creation command and verifies the initialization of a connection by comparing the returned iSCSI properties with expected fake properties."}
{"func_name": "dofile", "func_src_before": "void dofile(char *fname)\n{\n\tunsigned long  p; \n\tint i, num_pages;\n\tint fd;\n\n\tunsigned char *map;\n\toff_t fsize;\n\n\tif(notregular(fname))\n\t\treturn;\n\n\tprintf(\"%s: \",fname);\n\tfflush(stdout);\n\n\tif((fd=open(fname,O_RDONLY,0))<0)\n\t{\n\t\terror(\"%s\\n\",strerror(errno));\n\t\treturn;\n\t}\n\n\tfsize=filesize(fd);\n\n\tp=(unsigned long)mmap(0, fsize, PROT_READ, MAP_SHARED, fd,0);\n\t\n\tif(p==-1) {\n\t\terror(\"mmap returned error: %s\\n\",strerror(errno));\n\t\treturn;\n\t}\n\t\n\tif(p%page_size) \n\t\tdie(\"mmap returned non-aligned pointer, don't know how to handle, exiting\\n\");\n\t\n\tnum_pages=(fsize+page_size-1)/page_size;\n\ttotal_pages+=num_pages;\n\t\n\tif(!(map=malloc(num_pages))) \n\t\tdie(\"unable to allocate memory: %s\",strerror(errno));\n\n\t\n\tif(mincore((void *)((p+~page_mask)&page_mask),num_pages*page_size, map)) \n\t\tdie(\"kernel returned: %s\\n\",strerror(errno));\n\t\t\n\n\tif(do_totals)\n\t\tfor(i=0;i<num_pages;i++)\n\t\t\tif(map[i]&1)\n\t\t\t\ttotal_cached++;\n\n\n\tif(do_dump) {\n\t\tfor(i=0;i<num_pages;i++) {\n\t\t\tprintf(\"%c\",(map[i]&1) ? 'X' : '.');\n\t\t}\n\t\t\n\t\tprintf(\"\\n\");\n\t}\n\telse if(do_stats) {\n\t\tint num_incore=0;\n\t\tfor(i=0;i<num_pages;i++) {\n\t\t\tif(map[i]&1)\n\t\t\t\tnum_incore++;\n\t\t}\n\t\t\n\t\tprintf(\"%u pages, %u pages cached (%.2f%%)\\n\",\n\t\t       num_pages,\n\t\t       num_incore,\n\t\t       num_pages ? (num_incore*100.00)/num_pages : 0);\n\t}\n\telse if(do_bar)\n\t{\n\t\tint width=80-strlen(fname)-4;\n\t\tdouble leap;\n\t\tint num_incore=0;\n\t\tint last_pos=-1;\n\t\tint leap_pages=0;\n\n\t\tif(num_pages<width)\n\t\t\tleap=1;\n\t\telse\n\t\t\tleap=1.0*num_pages/width;\n\n\t\tfor(i=0;i<num_pages;i++) {\n\t\t\tif(map[i]&1)\n\t\t\t\tnum_incore++;\n\n\t\t\tleap_pages++;\n\n\t\t\tif((int)(i/leap)>last_pos) {\n\t\t\t\tint proc=3.0*num_incore/leap_pages;\n\t\t\t\tchar c;\n\n\t\t\t\tlast_pos=i/leap;\n\n\t\t\t\tswitch(proc) {\n\t\t\t\tcase 0: c='.';break;\n\t\t\t\tcase 1: c='_';break;\n\t\t\t\tcase 2: c='-';break;\n\t\t\t\tcase 3: c='X';break;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tprintf(\"%c\",c);\n\t\t\t\tnum_incore=leap_pages=0;\n\t\t\t}\n\n\t\t\t\n\t\t}\n\t\tprintf(\"\\n\");\n\t\t\n\t}\n\tmunmap((void *)p, num_pages*page_size);\n\tclose(fd);\n\n}", "func_src_after": "void dofile(char *fname)\n{\n\tunsigned long  p; \n\tint i, num_pages;\n\tint fd;\n\n\tunsigned char *map;\n\toff_t fsize;\n\n\tif(notregular(fname))\n\t\treturn;\n\n\tprintf(\"%s: \",fname);\n\tfflush(stdout);\n\n\tif((fd=open(fname,O_RDONLY,0))<0)\n\t{\n\t\terror(\"%s\\n\",strerror(errno));\n\t\treturn;\n\t}\n\n\tfsize=filesize(fd);\n\n\tif(!fsize)\n\t{\n\t\tprintf(\"empty\\n\");\n\t\tclose(fd);\n\t\treturn;\n        }\n\n\tp=(unsigned long)mmap(0, fsize, PROT_READ, MAP_SHARED, fd,0);\n\t\n\tif(p==-1) {\n\t\terror(\"mmap returned error: %s\\n\",strerror(errno));\n\t\treturn;\n\t}\n\t\n\tif(p%page_size) \n\t\tdie(\"mmap returned non-aligned pointer, don't know how to handle, exiting\\n\");\n\t\n\tnum_pages=(fsize+page_size-1)/page_size;\n\ttotal_pages+=num_pages;\n\t\n\tif(!(map=malloc(num_pages))) \n\t\tdie(\"unable to allocate memory: %s\",strerror(errno));\n\n\t\n\tif(mincore((void *)((p+~page_mask)&page_mask),(size_t)num_pages*(size_t)page_size, map))\n\t\tdie(\"kernel returned: %s\\n\",strerror(errno));\n\t\t\n\n\tif(do_totals)\n\t\tfor(i=0;i<num_pages;i++)\n\t\t\tif(map[i]&1)\n\t\t\t\ttotal_cached++;\n\n\n\tif(do_dump) {\n\t\tfor(i=0;i<num_pages;i++) {\n\t\t\tprintf(\"%c\",(map[i]&1) ? 'X' : '.');\n\t\t}\n\t\t\n\t\tprintf(\"\\n\");\n\t}\n\telse if(do_stats) {\n\t\tint num_incore=0;\n\t\tfor(i=0;i<num_pages;i++) {\n\t\t\tif(map[i]&1)\n\t\t\t\tnum_incore++;\n\t\t}\n\t\t\n\t\tprintf(\"%u pages, %u pages cached (%.2f%%)\\n\",\n\t\t       num_pages,\n\t\t       num_incore,\n\t\t       num_pages ? (num_incore*100.00)/num_pages : 0);\n\t}\n\telse if(do_bar)\n\t{\n\t\tint width=80-strlen(fname)-4;\n\t\tdouble leap;\n\t\tint num_incore=0;\n\t\tint last_pos=-1;\n\t\tint leap_pages=0;\n\n\t\tif(num_pages<width)\n\t\t\tleap=1;\n\t\telse\n\t\t\tleap=1.0*num_pages/width;\n\n\t\tfor(i=0;i<num_pages;i++) {\n\t\t\tif(map[i]&1)\n\t\t\t\tnum_incore++;\n\n\t\t\tleap_pages++;\n\n\t\t\tif((int)(i/leap)>last_pos) {\n\t\t\t\tint proc=3.0*num_incore/leap_pages;\n\t\t\t\tchar c;\n\n\t\t\t\tlast_pos=i/leap;\n\n\t\t\t\tswitch(proc) {\n\t\t\t\tcase 0: c='.';break;\n\t\t\t\tcase 1: c='_';break;\n\t\t\t\tcase 2: c='-';break;\n\t\t\t\tcase 3: c='X';break;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tprintf(\"%c\",c);\n\t\t\t\tnum_incore=leap_pages=0;\n\t\t\t}\n\n\t\t\t\n\t\t}\n\t\tprintf(\"\\n\");\n\t\t\n\t}\n\tmunmap((void *)p, num_pages*page_size);\n\tclose(fd);\n\n}", "line_changes": {"deleted": [{"line_no": 41, "char_start": 701, "char_end": 776, "line": "\tif(mincore((void *)((p+~page_mask)&page_mask),num_pages*page_size, map)) \n"}], "added": [{"line_no": 24, "char_start": 294, "char_end": 306, "line": "\tif(!fsize)\n"}, {"line_no": 25, "char_start": 306, "char_end": 309, "line": "\t{\n"}, {"line_no": 26, "char_start": 309, "char_end": 330, "line": "\t\tprintf(\"empty\\n\");\n"}, {"line_no": 27, "char_start": 330, "char_end": 343, "line": "\t\tclose(fd);\n"}, {"line_no": 28, "char_start": 343, "char_end": 353, "line": "\t\treturn;\n"}, {"line_no": 29, "char_start": 353, "char_end": 363, "line": "        }\n"}, {"line_no": 30, "char_start": 363, "char_end": 364, "line": "\n"}, {"line_no": 48, "char_start": 771, "char_end": 861, "line": "\tif(mincore((void *)((p+~page_mask)&page_mask),(size_t)num_pages*(size_t)page_size, map))\n"}]}, "char_changes": {"deleted": [{"char_start": 774, "char_end": 775, "chars": " "}], "added": [{"char_start": 294, "char_end": 364, "chars": "\tif(!fsize)\n\t{\n\t\tprintf(\"empty\\n\");\n\t\tclose(fd);\n\t\treturn;\n        }\n\n"}, {"char_start": 818, "char_end": 826, "chars": "(size_t)"}, {"char_start": 836, "char_end": 844, "chars": "(size_t)"}]}, "commit_link": "github.com/Shmuma/cinfo/commit/7cb8ac48f19a1ea7b2c80c8994866800fec87821", "file_name": "cinfo.c", "vul_type": "cwe-190", "commit_msg": "Fixed two file sizes issues:\n1. files larger than 2GB caused integer overflow in mincore call\n2. handle files with zero size.", "parent_commit": "524c13a70cfd98d03c35ae7fc2ef98a6e66a1a6e", "description": "In C, write a function to analyze and report on the memory page cache status of a file."}
{"func_name": "test_verilator_run", "func_src_before": "def test_verilator_run():\n    import os.path\n    import tempfile\n    import yaml\n    from edalize import get_edatool\n    ref_dir_cc = os.path.join(ref_dir, 'cc')\n\n    work_root    = tempfile.mkdtemp()\n    edam_file = os.path.join(ref_dir_cc, core_name)+ '.eda.yml'\n    backend = get_edatool(tool)(edam=yaml.load(open(edam_file)), work_root=work_root)\n    dummy_exe = 'V'+backend.tool_options['top_module']\n    shutil.copy(os.path.join(ref_dir, dummy_exe),\n                os.path.join(work_root, dummy_exe))\n\n    backend.run(params)\n\n    compare_files(ref_dir, work_root, ['run.cmd'])", "func_src_after": "def test_verilator_run():\n    import os.path\n    import tempfile\n    import yaml\n    from edalize import get_edatool\n    ref_dir_cc = os.path.join(ref_dir, 'cc')\n\n    work_root    = tempfile.mkdtemp()\n    edam_file = os.path.join(ref_dir_cc, core_name)+ '.eda.yml'\n    backend = get_edatool(tool)(edam=yaml.safe_load(open(edam_file)), work_root=work_root)\n    dummy_exe = 'V'+backend.tool_options['top_module']\n    shutil.copy(os.path.join(ref_dir, dummy_exe),\n                os.path.join(work_root, dummy_exe))\n\n    backend.run(params)\n\n    compare_files(ref_dir, work_root, ['run.cmd'])", "line_changes": {"deleted": [{"line_no": 10, "char_start": 265, "char_end": 351, "line": "    backend = get_edatool(tool)(edam=yaml.load(open(edam_file)), work_root=work_root)\n"}], "added": [{"line_no": 10, "char_start": 265, "char_end": 356, "line": "    backend = get_edatool(tool)(edam=yaml.safe_load(open(edam_file)), work_root=work_root)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 307, "char_end": 312, "chars": "safe_"}]}, "commit_link": "github.com/SymbiFlow/edalize/commit/0a07c959386a5c8ffd88e5f985979e1a26646076", "file_name": "test_verilator.py", "vul_type": "cwe-502", "commit_msg": "Use safe YAML loader\n\nyaml.load() is unsafe and issues a warning. Switching to the safe loader\nexplicitly.", "parent_commit": "3faaeaefaf313aebd40f8f3782f07a61cdc5aaaa", "description": "Write a Python function that sets up and runs a hardware simulation tool using configuration from a YAML file."}
{"func_name": "__init__", "func_src_before": "  def __init__(self,\n               height,\n               width,\n               command_sequence=None):\n    self._height = height\n    self._width = width\n\n    self._command_sequence = command_sequence\n    self._command_counter = 0\n\n    # The mock class has no actual textbox. So use this variable to keep\n    # track of what's entered in the textbox on creation.\n    self._curr_existing_command = \"\"\n\n    # Observers for test.\n    # Observers of screen output.\n    self.unwrapped_outputs = []\n    self.wrapped_outputs = []\n    self.scroll_messages = []\n    self.output_array_pointer_indices = []\n\n    self.output_pad_rows = []\n\n    # Observers of command textbox.\n    self.existing_commands = []\n\n    # Observer for tab-completion candidates.\n    self.candidates_lists = []\n\n    # Observer for the main menu.\n    self.main_menu_list = []\n\n    # Observer for toast messages.\n    self.toasts = []\n\n    curses_ui.CursesUI.__init__(\n        self,\n        config=cli_config.CLIConfig(\n            config_file_path=os.path.join(tempfile.mkdtemp(), \".tfdbg_config\")))\n\n    # Override the default path to the command history file to avoid test\n    # concurrency issues.\n    self._command_history_store = debugger_cli_common.CommandHistory(\n        history_file_path=tempfile.mktemp())", "func_src_after": "  def __init__(self,\n               height,\n               width,\n               command_sequence=None):\n    self._height = height\n    self._width = width\n\n    self._command_sequence = command_sequence\n    self._command_counter = 0\n\n    # The mock class has no actual textbox. So use this variable to keep\n    # track of what's entered in the textbox on creation.\n    self._curr_existing_command = \"\"\n\n    # Observers for test.\n    # Observers of screen output.\n    self.unwrapped_outputs = []\n    self.wrapped_outputs = []\n    self.scroll_messages = []\n    self.output_array_pointer_indices = []\n\n    self.output_pad_rows = []\n\n    # Observers of command textbox.\n    self.existing_commands = []\n\n    # Observer for tab-completion candidates.\n    self.candidates_lists = []\n\n    # Observer for the main menu.\n    self.main_menu_list = []\n\n    # Observer for toast messages.\n    self.toasts = []\n\n    curses_ui.CursesUI.__init__(\n        self,\n        config=cli_config.CLIConfig(\n            config_file_path=os.path.join(tempfile.mkdtemp(), \".tfdbg_config\")))\n\n    # Override the default path to the command history file to avoid test\n    # concurrency issues.\n    _, history_file_path = tempfile.mkstemp()  # safe to ignore fd\n    self._command_history_store = debugger_cli_common.CommandHistory(\n        history_file_path=history_file_path)", "line_changes": {"deleted": [{"line_no": 44, "char_start": 1233, "char_end": 1277, "line": "        history_file_path=tempfile.mktemp())\n"}], "added": [{"line_no": 43, "char_start": 1163, "char_end": 1230, "line": "    _, history_file_path = tempfile.mkstemp()  # safe to ignore fd\n"}, {"line_no": 45, "char_start": 1300, "char_end": 1344, "line": "        history_file_path=history_file_path)\n"}]}, "char_changes": {"deleted": [{"char_start": 1259, "char_end": 1276, "chars": "tempfile.mktemp()"}], "added": [{"char_start": 1163, "char_end": 1230, "chars": "    _, history_file_path = tempfile.mkstemp()  # safe to ignore fd\n"}, {"char_start": 1326, "char_end": 1343, "chars": "history_file_path"}]}, "commit_link": "github.com/tensorflow/tensorflow/commit/578f7eec19544d0223d145b56d88dfe043114538", "file_name": "curses_ui_test.py", "vul_type": "cwe-377", "commit_msg": "Use `tempfile.mkstemp` instead of `tempfile.mktemp`.\n\nThe `tempfile.mktemp` function is [deprecated](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp) due to [security issues](https://cwe.mitre.org/data/definitions/377.html).\n\nThe switch is easy to do.\n\nPiperOrigin-RevId: 420359212\nChange-Id: I172811749d2e7b901399f63df4fd1523447c6682", "description": "In Python, write an initializer for a mock UI class that sets up dimensions, command handling, and various observers for testing, without using actual UI components."}
{"func_name": "decode", "func_src_before": "      def decode(json, proc = nil, options = {})\n        data = ::JSON.load(json, proc, options)\n        if ActiveSupport.parse_json_times\n          convert_dates_from(data)\n        else\n          data\n        end\n      end", "func_src_after": "      def decode(json, options = {})\n        data = ::JSON.parse(json, options.merge(create_additions: false))\n        if ActiveSupport.parse_json_times\n          convert_dates_from(data)\n        else\n          data\n        end\n      end", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 49, "line": "      def decode(json, proc = nil, options = {})\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 37, "line": "      def decode(json, options = {})\n"}, {"line_no": 2, "char_start": 37, "char_end": 111, "line": "        data = ::JSON.parse(json, options.merge(create_additions: false))\n"}]}, "char_changes": {"deleted": [{"char_start": 22, "char_end": 34, "chars": " proc = nil,"}, {"char_start": 71, "char_end": 75, "chars": "load"}, {"char_start": 82, "char_end": 88, "chars": "proc, "}], "added": [{"char_start": 59, "char_end": 64, "chars": "parse"}, {"char_start": 78, "char_end": 109, "chars": ".merge(create_additions: false)"}]}, "commit_link": "github.com/baerjam/rails/commit/b9e142af529b20720fc34bc5f563e935a7ef7cda", "file_name": "decoding.rb", "vul_type": "cwe-502", "commit_msg": "Replace JSON.load with JSON.parse, also removed the proc parameter\n\nSince we are dealing with untrusted user input, we should not be\nusing JSON.load. According to the docs[1]:\n\nBEWARE: This method is meant to serialise data from trusted user\ninput, like from your own database server or clients under your\ncontrol, it could be dangerous to allow untrusted users to pass\nJSON sources into it. The default options for the parser can be\nchanged via the ::load_default_options method.\n\n[1] http://www.ruby-doc.org/stdlib-2.0/libdoc/json/rdoc/JSON.html#method-i-load", "parent_commit": "3d60e9d5503b5f657336a8b7ee6345552ddb6c83", "description": "Write a Ruby method named `decode` that processes JSON input and optionally converts date strings to date objects."}
{"func_name": "Mat_VarReadNextInfo4", "func_src_before": "Mat_VarReadNextInfo4(mat_t *mat)\n{\n    int       M,O,data_type,class_type;\n    mat_int32_t tmp;\n    long      nBytes;\n    size_t    readresult;\n    matvar_t *matvar = NULL;\n    union {\n        mat_uint32_t u;\n        mat_uint8_t  c[4];\n    } endian;\n\n    if ( mat == NULL || mat->fp == NULL )\n        return NULL;\n    else if ( NULL == (matvar = Mat_VarCalloc()) )\n        return NULL;\n\n    readresult = fread(&tmp,sizeof(int),1,(FILE*)mat->fp);\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n\n    endian.u = 0x01020304;\n\n    /* See if MOPT may need byteswapping */\n    if ( tmp < 0 || tmp > 4052 ) {\n        if ( Mat_int32Swap(&tmp) > 4052 ) {\n            Mat_VarFree(matvar);\n            return NULL;\n        }\n    }\n\n    M = (int)floor(tmp / 1000.0);\n    switch ( M ) {\n        case 0:\n            /* IEEE little endian */\n            mat->byteswap = endian.c[0] != 4;\n            break;\n        case 1:\n            /* IEEE big endian */\n            mat->byteswap = endian.c[0] != 1;\n            break;\n        default:\n            /* VAX, Cray, or bogus */\n            Mat_VarFree(matvar);\n            return NULL;\n    }\n\n    tmp -= M*1000;\n    O = (int)floor(tmp / 100.0);\n    /* O must be zero */\n    if ( 0 != O ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n\n    tmp -= O*100;\n    data_type = (int)floor(tmp / 10.0);\n    /* Convert the V4 data type */\n    switch ( data_type ) {\n        case 0:\n            matvar->data_type = MAT_T_DOUBLE;\n            break;\n        case 1:\n            matvar->data_type = MAT_T_SINGLE;\n            break;\n        case 2:\n            matvar->data_type = MAT_T_INT32;\n            break;\n        case 3:\n            matvar->data_type = MAT_T_INT16;\n            break;\n        case 4:\n            matvar->data_type = MAT_T_UINT16;\n            break;\n        case 5:\n            matvar->data_type = MAT_T_UINT8;\n            break;\n        default:\n            Mat_VarFree(matvar);\n            return NULL;\n    }\n\n    tmp -= data_type*10;\n    class_type = (int)floor(tmp / 1.0);\n    switch ( class_type ) {\n        case 0:\n            matvar->class_type = MAT_C_DOUBLE;\n            break;\n        case 1:\n            matvar->class_type = MAT_C_CHAR;\n            break;\n        case 2:\n            matvar->class_type = MAT_C_SPARSE;\n            break;\n        default:\n            Mat_VarFree(matvar);\n            return NULL;\n    }\n\n    matvar->rank = 2;\n    matvar->dims = (size_t*)calloc(2, sizeof(*matvar->dims));\n    if ( NULL == matvar->dims ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    readresult = fread(&tmp,sizeof(int),1,(FILE*)mat->fp);\n    if ( mat->byteswap )\n        Mat_int32Swap(&tmp);\n    matvar->dims[0] = tmp;\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    readresult = fread(&tmp,sizeof(int),1,(FILE*)mat->fp);\n    if ( mat->byteswap )\n        Mat_int32Swap(&tmp);\n    matvar->dims[1] = tmp;\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n\n    readresult = fread(&(matvar->isComplex),sizeof(int),1,(FILE*)mat->fp);\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    if ( matvar->isComplex && MAT_C_CHAR == matvar->class_type ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    readresult = fread(&tmp,sizeof(int),1,(FILE*)mat->fp);\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    if ( mat->byteswap )\n        Mat_int32Swap(&tmp);\n    /* Check that the length of the variable name is at least 1 */\n    if ( tmp < 1 ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    matvar->name = (char*)malloc(tmp);\n    if ( NULL == matvar->name ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    readresult = fread(matvar->name,1,tmp,(FILE*)mat->fp);\n    if ( tmp != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n\n    matvar->internal->datapos = ftell((FILE*)mat->fp);\n    if ( matvar->internal->datapos == -1L ) {\n        Mat_VarFree(matvar);\n        Mat_Critical(\"Couldn't determine file position\");\n        return NULL;\n    }\n    {\n        int err;\n        size_t tmp2 = Mat_SizeOf(matvar->data_type);\n        if ( matvar->isComplex )\n            tmp2 *= 2;\n        err = SafeMulDims(matvar, &tmp2);\n        if ( err ) {\n            Mat_VarFree(matvar);\n            Mat_Critical(\"Integer multiplication overflow\");\n            return NULL;\n        }\n\n        nBytes = (long)tmp2;\n    }\n    (void)fseek((FILE*)mat->fp,nBytes,SEEK_CUR);\n\n    return matvar;\n}", "func_src_after": "Mat_VarReadNextInfo4(mat_t *mat)\n{\n    int       M,O,data_type,class_type;\n    mat_int32_t tmp;\n    long      nBytes;\n    size_t    readresult;\n    matvar_t *matvar = NULL;\n    union {\n        mat_uint32_t u;\n        mat_uint8_t  c[4];\n    } endian;\n\n    if ( mat == NULL || mat->fp == NULL )\n        return NULL;\n    else if ( NULL == (matvar = Mat_VarCalloc()) )\n        return NULL;\n\n    readresult = fread(&tmp,sizeof(int),1,(FILE*)mat->fp);\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n\n    endian.u = 0x01020304;\n\n    /* See if MOPT may need byteswapping */\n    if ( tmp < 0 || tmp > 4052 ) {\n        if ( Mat_int32Swap(&tmp) > 4052 ) {\n            Mat_VarFree(matvar);\n            return NULL;\n        }\n    }\n\n    M = (int)floor(tmp / 1000.0);\n    switch ( M ) {\n        case 0:\n            /* IEEE little endian */\n            mat->byteswap = endian.c[0] != 4;\n            break;\n        case 1:\n            /* IEEE big endian */\n            mat->byteswap = endian.c[0] != 1;\n            break;\n        default:\n            /* VAX, Cray, or bogus */\n            Mat_VarFree(matvar);\n            return NULL;\n    }\n\n    tmp -= M*1000;\n    O = (int)floor(tmp / 100.0);\n    /* O must be zero */\n    if ( 0 != O ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n\n    tmp -= O*100;\n    data_type = (int)floor(tmp / 10.0);\n    /* Convert the V4 data type */\n    switch ( data_type ) {\n        case 0:\n            matvar->data_type = MAT_T_DOUBLE;\n            break;\n        case 1:\n            matvar->data_type = MAT_T_SINGLE;\n            break;\n        case 2:\n            matvar->data_type = MAT_T_INT32;\n            break;\n        case 3:\n            matvar->data_type = MAT_T_INT16;\n            break;\n        case 4:\n            matvar->data_type = MAT_T_UINT16;\n            break;\n        case 5:\n            matvar->data_type = MAT_T_UINT8;\n            break;\n        default:\n            Mat_VarFree(matvar);\n            return NULL;\n    }\n\n    tmp -= data_type*10;\n    class_type = (int)floor(tmp / 1.0);\n    switch ( class_type ) {\n        case 0:\n            matvar->class_type = MAT_C_DOUBLE;\n            break;\n        case 1:\n            matvar->class_type = MAT_C_CHAR;\n            break;\n        case 2:\n            matvar->class_type = MAT_C_SPARSE;\n            break;\n        default:\n            Mat_VarFree(matvar);\n            return NULL;\n    }\n\n    matvar->rank = 2;\n    matvar->dims = (size_t*)calloc(2, sizeof(*matvar->dims));\n    if ( NULL == matvar->dims ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    readresult = fread(&tmp,sizeof(int),1,(FILE*)mat->fp);\n    if ( mat->byteswap )\n        Mat_int32Swap(&tmp);\n    matvar->dims[0] = tmp;\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    readresult = fread(&tmp,sizeof(int),1,(FILE*)mat->fp);\n    if ( mat->byteswap )\n        Mat_int32Swap(&tmp);\n    matvar->dims[1] = tmp;\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n\n    readresult = fread(&(matvar->isComplex),sizeof(int),1,(FILE*)mat->fp);\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    if ( matvar->isComplex && MAT_C_CHAR == matvar->class_type ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    readresult = fread(&tmp,sizeof(int),1,(FILE*)mat->fp);\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    if ( mat->byteswap )\n        Mat_int32Swap(&tmp);\n    /* Check that the length of the variable name is at least 1 */\n    if ( tmp < 1 ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    matvar->name = (char*)malloc(tmp);\n    if ( NULL == matvar->name ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    readresult = fread(matvar->name,1,tmp,(FILE*)mat->fp);\n    if ( tmp != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    } else {\n        matvar->name[tmp - 1] = '\\0';\n    }\n\n    matvar->internal->datapos = ftell((FILE*)mat->fp);\n    if ( matvar->internal->datapos == -1L ) {\n        Mat_VarFree(matvar);\n        Mat_Critical(\"Couldn't determine file position\");\n        return NULL;\n    }\n    {\n        int err;\n        size_t tmp2 = Mat_SizeOf(matvar->data_type);\n        if ( matvar->isComplex )\n            tmp2 *= 2;\n        err = SafeMulDims(matvar, &tmp2);\n        if ( err ) {\n            Mat_VarFree(matvar);\n            Mat_Critical(\"Integer multiplication overflow\");\n            return NULL;\n        }\n\n        nBytes = (long)tmp2;\n    }\n    (void)fseek((FILE*)mat->fp,nBytes,SEEK_CUR);\n\n    return matvar;\n}", "commit_link": "github.com/tbeu/matio/commit/651a8e28099edb5fbb9e4e1d4d3238848f446c9a", "file_name": "src/mat4.c", "vul_type": "cwe-125", "description": "Write a C function named `Mat_VarReadNextInfo4` that reads the next variable information from a MAT file."}
{"func_name": "insertUser", "func_src_before": "const insertUser = (data,cb)=>{\n  const sqlQuery = `INSERT INTO users(email,priveleges,first_name,last_name)VALUES('${data.email}','1','${data.firstName}','${data.lastName}')`;\n  client.query(sqlQuery,(err,result)=>{\n    cb(err,result);\n  });\n};", "func_src_after": "const insertUser = (data,cb)=>{\n  const sqlQuery = 'INSERT INTO users(email,privileges,first_name,last_name)VALUES($1,$2,$3,$4)';\n  client.query(sqlQuery,[data.email,'1',data.firstName,data.lastName],(err,result)=>{\n    cb(err,result);\n  });\n};", "line_changes": {"deleted": [{"line_no": 2, "char_start": 32, "char_end": 177, "line": "  const sqlQuery = `INSERT INTO users(email,priveleges,first_name,last_name)VALUES('${data.email}','1','${data.firstName}','${data.lastName}')`;\n"}, {"line_no": 3, "char_start": 177, "char_end": 217, "line": "  client.query(sqlQuery,(err,result)=>{\n"}], "added": [{"line_no": 2, "char_start": 32, "char_end": 130, "line": "  const sqlQuery = 'INSERT INTO users(email,privileges,first_name,last_name)VALUES($1,$2,$3,$4)';\n"}, {"line_no": 3, "char_start": 130, "char_end": 216, "line": "  client.query(sqlQuery,[data.email,'1',data.firstName,data.lastName],(err,result)=>{\n"}]}, "char_changes": {"deleted": [{"char_start": 51, "char_end": 52, "chars": "`"}, {"char_start": 80, "char_end": 81, "chars": "e"}, {"char_start": 115, "char_end": 118, "chars": "'${"}, {"char_start": 128, "char_end": 130, "chars": "}'"}, {"char_start": 135, "char_end": 138, "chars": "'${"}, {"char_start": 152, "char_end": 158, "chars": "}','${"}, {"char_start": 171, "char_end": 200, "chars": "}')`;\n  client.query(sqlQuery"}], "added": [{"char_start": 51, "char_end": 52, "chars": "'"}, {"char_start": 80, "char_end": 81, "chars": "i"}, {"char_start": 115, "char_end": 155, "chars": "$1,$2,$3,$4)';\n  client.query(sqlQuery,["}, {"char_start": 184, "char_end": 185, "chars": ","}, {"char_start": 198, "char_end": 199, "chars": "]"}]}, "commit_link": "github.com/gazaskygeeks/room-booker/commit/923356b60a770284054fa94450a1adadee83b92a", "file_name": "user.js", "vul_type": "cwe-089", "commit_msg": "prevent queries from sqlinjection", "description": "Write a JavaScript function that inserts a new user into a database using provided user data and a callback function for the operation's result."}
{"func_name": "ssl_parse_server_key_exchange", "func_src_before": "static int ssl_parse_server_key_exchange( mbedtls_ssl_context *ssl )\n{\n    int ret;\n    const mbedtls_ssl_ciphersuite_t *ciphersuite_info =\n        ssl->transform_negotiate->ciphersuite_info;\n    unsigned char *p = NULL, *end = NULL;\n\n    MBEDTLS_SSL_DEBUG_MSG( 2, ( \"=> parse server key exchange\" ) );\n\n#if defined(MBEDTLS_KEY_EXCHANGE_RSA_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA )\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 2, ( \"<= skip parse server key exchange\" ) );\n        ssl->state++;\n        return( 0 );\n    }\n    ((void) p);\n    ((void) end);\n#endif\n\n#if defined(MBEDTLS_KEY_EXCHANGE_ECDH_RSA_ENABLED) || \\\n    defined(MBEDTLS_KEY_EXCHANGE_ECDH_ECDSA_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDH_RSA ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDH_ECDSA )\n    {\n        if( ( ret = ssl_get_ecdh_params_from_cert( ssl ) ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_RET( 1, \"ssl_get_ecdh_params_from_cert\", ret );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_HANDSHAKE_FAILURE );\n            return( ret );\n        }\n\n        MBEDTLS_SSL_DEBUG_MSG( 2, ( \"<= skip parse server key exchange\" ) );\n        ssl->state++;\n        return( 0 );\n    }\n    ((void) p);\n    ((void) end);\n#endif /* MBEDTLS_KEY_EXCHANGE_ECDH_RSA_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_ECDH_ECDSA_ENABLED */\n\n    if( ( ret = mbedtls_ssl_read_record( ssl ) ) != 0 )\n    {\n        MBEDTLS_SSL_DEBUG_RET( 1, \"mbedtls_ssl_read_record\", ret );\n        return( ret );\n    }\n\n    if( ssl->in_msgtype != MBEDTLS_SSL_MSG_HANDSHAKE )\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n        mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                        MBEDTLS_SSL_ALERT_MSG_UNEXPECTED_MESSAGE );\n        return( MBEDTLS_ERR_SSL_UNEXPECTED_MESSAGE );\n    }\n\n    /*\n     * ServerKeyExchange may be skipped with PSK and RSA-PSK when the server\n     * doesn't use a psk_identity_hint\n     */\n    if( ssl->in_msg[0] != MBEDTLS_SSL_HS_SERVER_KEY_EXCHANGE )\n    {\n        if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_PSK ||\n            ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA_PSK )\n        {\n            /* Current message is probably either\n             * CertificateRequest or ServerHelloDone */\n            ssl->keep_current_message = 1;\n            goto exit;\n        }\n\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"server key exchange message must \"\n                                    \"not be skipped\" ) );\n        mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                        MBEDTLS_SSL_ALERT_MSG_UNEXPECTED_MESSAGE );\n\n        return( MBEDTLS_ERR_SSL_UNEXPECTED_MESSAGE );\n    }\n\n    p   = ssl->in_msg + mbedtls_ssl_hs_hdr_len( ssl );\n    end = ssl->in_msg + ssl->in_hslen;\n    MBEDTLS_SSL_DEBUG_BUF( 3,   \"server key exchange\", p, end - p );\n\n#if defined(MBEDTLS_KEY_EXCHANGE__SOME__PSK_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_DHE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_PSK )\n    {\n        if( ssl_parse_server_psk_hint( ssl, &p, end ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    } /* FALLTROUGH */\n#endif /* MBEDTLS_KEY_EXCHANGE__SOME__PSK_ENABLED */\n\n#if defined(MBEDTLS_KEY_EXCHANGE_PSK_ENABLED) ||                       \\\n    defined(MBEDTLS_KEY_EXCHANGE_RSA_PSK_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA_PSK )\n        ; /* nothing more to do */\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_PSK_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_RSA_PSK_ENABLED */\n#if defined(MBEDTLS_KEY_EXCHANGE_DHE_RSA_ENABLED) ||                       \\\n    defined(MBEDTLS_KEY_EXCHANGE_DHE_PSK_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_DHE_RSA ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_DHE_PSK )\n    {\n        if( ssl_parse_server_dh_params( ssl, &p, end ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    }\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_DHE_RSA_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_DHE_PSK_ENABLED */\n#if defined(MBEDTLS_KEY_EXCHANGE_ECDHE_RSA_ENABLED) ||                     \\\n    defined(MBEDTLS_KEY_EXCHANGE_ECDHE_PSK_ENABLED) ||                     \\\n    defined(MBEDTLS_KEY_EXCHANGE_ECDHE_ECDSA_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_RSA ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_ECDSA )\n    {\n        if( ssl_parse_server_ecdh_params( ssl, &p, end ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    }\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_ECDHE_RSA_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_ECDHE_PSK_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_ECDHE_ECDSA_ENABLED */\n#if defined(MBEDTLS_KEY_EXCHANGE_ECJPAKE_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECJPAKE )\n    {\n        ret = mbedtls_ecjpake_read_round_two( &ssl->handshake->ecjpake_ctx,\n                                              p, end - p );\n        if( ret != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_RET( 1, \"mbedtls_ecjpake_read_round_two\", ret );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    }\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_ECJPAKE_ENABLED */\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"should never happen\" ) );\n        return( MBEDTLS_ERR_SSL_INTERNAL_ERROR );\n    }\n\n#if defined(MBEDTLS_KEY_EXCHANGE__WITH_SERVER_SIGNATURE__ENABLED)\n    if( mbedtls_ssl_ciphersuite_uses_server_signature( ciphersuite_info ) )\n    {\n        size_t sig_len, hashlen;\n        unsigned char hash[64];\n        mbedtls_md_type_t md_alg = MBEDTLS_MD_NONE;\n        mbedtls_pk_type_t pk_alg = MBEDTLS_PK_NONE;\n        unsigned char *params = ssl->in_msg + mbedtls_ssl_hs_hdr_len( ssl );\n        size_t params_len = p - params;\n\n        /*\n         * Handle the digitally-signed structure\n         */\n#if defined(MBEDTLS_SSL_PROTO_TLS1_2)\n        if( ssl->minor_ver == MBEDTLS_SSL_MINOR_VERSION_3 )\n        {\n            if( ssl_parse_signature_algorithm( ssl, &p, end,\n                                               &md_alg, &pk_alg ) != 0 )\n            {\n                MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n                mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                                MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n                return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n            }\n\n            if( pk_alg != mbedtls_ssl_get_ciphersuite_sig_pk_alg( ciphersuite_info ) )\n            {\n                MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n                mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                                MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n                return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n            }\n        }\n        else\n#endif /* MBEDTLS_SSL_PROTO_TLS1_2 */\n#if defined(MBEDTLS_SSL_PROTO_SSL3) || defined(MBEDTLS_SSL_PROTO_TLS1) || \\\n    defined(MBEDTLS_SSL_PROTO_TLS1_1)\n        if( ssl->minor_ver < MBEDTLS_SSL_MINOR_VERSION_3 )\n        {\n            pk_alg = mbedtls_ssl_get_ciphersuite_sig_pk_alg( ciphersuite_info );\n\n            /* Default hash for ECDSA is SHA-1 */\n            if( pk_alg == MBEDTLS_PK_ECDSA && md_alg == MBEDTLS_MD_NONE )\n                md_alg = MBEDTLS_MD_SHA1;\n        }\n        else\n#endif\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"should never happen\" ) );\n            return( MBEDTLS_ERR_SSL_INTERNAL_ERROR );\n        }\n\n        /*\n         * Read signature\n         */\n\n        if( p > end - 2 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_DECODE_ERROR );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n        sig_len = ( p[0] << 8 ) | p[1];\n        p += 2;\n\n        if( end != p + sig_len )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_DECODE_ERROR );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n\n        MBEDTLS_SSL_DEBUG_BUF( 3, \"signature\", p, sig_len );\n\n        /*\n         * Compute the hash that has been signed\n         */\n#if defined(MBEDTLS_SSL_PROTO_SSL3) || defined(MBEDTLS_SSL_PROTO_TLS1) || \\\n    defined(MBEDTLS_SSL_PROTO_TLS1_1)\n        if( md_alg == MBEDTLS_MD_NONE )\n        {\n            hashlen = 36;\n            ret = mbedtls_ssl_get_key_exchange_md_ssl_tls( ssl, hash, params,\n                                                           params_len );\n            if( ret != 0 )\n                return( ret );\n        }\n        else\n#endif /* MBEDTLS_SSL_PROTO_SSL3 || MBEDTLS_SSL_PROTO_TLS1 || \\\n          MBEDTLS_SSL_PROTO_TLS1_1 */\n#if defined(MBEDTLS_SSL_PROTO_TLS1) || defined(MBEDTLS_SSL_PROTO_TLS1_1) || \\\n    defined(MBEDTLS_SSL_PROTO_TLS1_2)\n        if( md_alg != MBEDTLS_MD_NONE )\n        {\n            /* Info from md_alg will be used instead */\n            hashlen = 0;\n            ret = mbedtls_ssl_get_key_exchange_md_tls1_2( ssl, hash, params,\n                                                          params_len, md_alg );\n            if( ret != 0 )\n                return( ret );\n        }\n        else\n#endif /* MBEDTLS_SSL_PROTO_TLS1 || MBEDTLS_SSL_PROTO_TLS1_1 || \\\n          MBEDTLS_SSL_PROTO_TLS1_2 */\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"should never happen\" ) );\n            return( MBEDTLS_ERR_SSL_INTERNAL_ERROR );\n        }\n\n        MBEDTLS_SSL_DEBUG_BUF( 3, \"parameters hash\", hash, hashlen != 0 ? hashlen :\n            (unsigned int) ( mbedtls_md_get_size( mbedtls_md_info_from_type( md_alg ) ) ) );\n\n        if( ssl->session_negotiate->peer_cert == NULL )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 2, ( \"certificate required\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_HANDSHAKE_FAILURE );\n            return( MBEDTLS_ERR_SSL_UNEXPECTED_MESSAGE );\n        }\n\n        /*\n         * Verify signature\n         */\n        if( ! mbedtls_pk_can_do( &ssl->session_negotiate->peer_cert->pk, pk_alg ) )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_HANDSHAKE_FAILURE );\n            return( MBEDTLS_ERR_SSL_PK_TYPE_MISMATCH );\n        }\n\n        if( ( ret = mbedtls_pk_verify( &ssl->session_negotiate->peer_cert->pk,\n                               md_alg, hash, hashlen, p, sig_len ) ) != 0 )\n        {\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_DECRYPT_ERROR );\n            MBEDTLS_SSL_DEBUG_RET( 1, \"mbedtls_pk_verify\", ret );\n            return( ret );\n        }\n    }\n#endif /* MBEDTLS_KEY_EXCHANGE__WITH_SERVER_SIGNATURE__ENABLED */\n\nexit:\n    ssl->state++;\n\n    MBEDTLS_SSL_DEBUG_MSG( 2, ( \"<= parse server key exchange\" ) );\n\n    return( 0 );\n}", "func_src_after": "static int ssl_parse_server_key_exchange( mbedtls_ssl_context *ssl )\n{\n    int ret;\n    const mbedtls_ssl_ciphersuite_t *ciphersuite_info =\n        ssl->transform_negotiate->ciphersuite_info;\n    unsigned char *p = NULL, *end = NULL;\n\n    MBEDTLS_SSL_DEBUG_MSG( 2, ( \"=> parse server key exchange\" ) );\n\n#if defined(MBEDTLS_KEY_EXCHANGE_RSA_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA )\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 2, ( \"<= skip parse server key exchange\" ) );\n        ssl->state++;\n        return( 0 );\n    }\n    ((void) p);\n    ((void) end);\n#endif\n\n#if defined(MBEDTLS_KEY_EXCHANGE_ECDH_RSA_ENABLED) || \\\n    defined(MBEDTLS_KEY_EXCHANGE_ECDH_ECDSA_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDH_RSA ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDH_ECDSA )\n    {\n        if( ( ret = ssl_get_ecdh_params_from_cert( ssl ) ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_RET( 1, \"ssl_get_ecdh_params_from_cert\", ret );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_HANDSHAKE_FAILURE );\n            return( ret );\n        }\n\n        MBEDTLS_SSL_DEBUG_MSG( 2, ( \"<= skip parse server key exchange\" ) );\n        ssl->state++;\n        return( 0 );\n    }\n    ((void) p);\n    ((void) end);\n#endif /* MBEDTLS_KEY_EXCHANGE_ECDH_RSA_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_ECDH_ECDSA_ENABLED */\n\n    if( ( ret = mbedtls_ssl_read_record( ssl ) ) != 0 )\n    {\n        MBEDTLS_SSL_DEBUG_RET( 1, \"mbedtls_ssl_read_record\", ret );\n        return( ret );\n    }\n\n    if( ssl->in_msgtype != MBEDTLS_SSL_MSG_HANDSHAKE )\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n        mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                        MBEDTLS_SSL_ALERT_MSG_UNEXPECTED_MESSAGE );\n        return( MBEDTLS_ERR_SSL_UNEXPECTED_MESSAGE );\n    }\n\n    /*\n     * ServerKeyExchange may be skipped with PSK and RSA-PSK when the server\n     * doesn't use a psk_identity_hint\n     */\n    if( ssl->in_msg[0] != MBEDTLS_SSL_HS_SERVER_KEY_EXCHANGE )\n    {\n        if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_PSK ||\n            ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA_PSK )\n        {\n            /* Current message is probably either\n             * CertificateRequest or ServerHelloDone */\n            ssl->keep_current_message = 1;\n            goto exit;\n        }\n\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"server key exchange message must \"\n                                    \"not be skipped\" ) );\n        mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                        MBEDTLS_SSL_ALERT_MSG_UNEXPECTED_MESSAGE );\n\n        return( MBEDTLS_ERR_SSL_UNEXPECTED_MESSAGE );\n    }\n\n    p   = ssl->in_msg + mbedtls_ssl_hs_hdr_len( ssl );\n    end = ssl->in_msg + ssl->in_hslen;\n    MBEDTLS_SSL_DEBUG_BUF( 3,   \"server key exchange\", p, end - p );\n\n#if defined(MBEDTLS_KEY_EXCHANGE__SOME__PSK_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_DHE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_PSK )\n    {\n        if( ssl_parse_server_psk_hint( ssl, &p, end ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    } /* FALLTROUGH */\n#endif /* MBEDTLS_KEY_EXCHANGE__SOME__PSK_ENABLED */\n\n#if defined(MBEDTLS_KEY_EXCHANGE_PSK_ENABLED) ||                       \\\n    defined(MBEDTLS_KEY_EXCHANGE_RSA_PSK_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA_PSK )\n        ; /* nothing more to do */\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_PSK_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_RSA_PSK_ENABLED */\n#if defined(MBEDTLS_KEY_EXCHANGE_DHE_RSA_ENABLED) ||                       \\\n    defined(MBEDTLS_KEY_EXCHANGE_DHE_PSK_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_DHE_RSA ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_DHE_PSK )\n    {\n        if( ssl_parse_server_dh_params( ssl, &p, end ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    }\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_DHE_RSA_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_DHE_PSK_ENABLED */\n#if defined(MBEDTLS_KEY_EXCHANGE_ECDHE_RSA_ENABLED) ||                     \\\n    defined(MBEDTLS_KEY_EXCHANGE_ECDHE_PSK_ENABLED) ||                     \\\n    defined(MBEDTLS_KEY_EXCHANGE_ECDHE_ECDSA_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_RSA ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_ECDSA )\n    {\n        if( ssl_parse_server_ecdh_params( ssl, &p, end ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    }\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_ECDHE_RSA_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_ECDHE_PSK_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_ECDHE_ECDSA_ENABLED */\n#if defined(MBEDTLS_KEY_EXCHANGE_ECJPAKE_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECJPAKE )\n    {\n        ret = mbedtls_ecjpake_read_round_two( &ssl->handshake->ecjpake_ctx,\n                                              p, end - p );\n        if( ret != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_RET( 1, \"mbedtls_ecjpake_read_round_two\", ret );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    }\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_ECJPAKE_ENABLED */\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"should never happen\" ) );\n        return( MBEDTLS_ERR_SSL_INTERNAL_ERROR );\n    }\n\n#if defined(MBEDTLS_KEY_EXCHANGE__WITH_SERVER_SIGNATURE__ENABLED)\n    if( mbedtls_ssl_ciphersuite_uses_server_signature( ciphersuite_info ) )\n    {\n        size_t sig_len, hashlen;\n        unsigned char hash[64];\n        mbedtls_md_type_t md_alg = MBEDTLS_MD_NONE;\n        mbedtls_pk_type_t pk_alg = MBEDTLS_PK_NONE;\n        unsigned char *params = ssl->in_msg + mbedtls_ssl_hs_hdr_len( ssl );\n        size_t params_len = p - params;\n\n        /*\n         * Handle the digitally-signed structure\n         */\n#if defined(MBEDTLS_SSL_PROTO_TLS1_2)\n        if( ssl->minor_ver == MBEDTLS_SSL_MINOR_VERSION_3 )\n        {\n            if( ssl_parse_signature_algorithm( ssl, &p, end,\n                                               &md_alg, &pk_alg ) != 0 )\n            {\n                MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n                mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                                MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n                return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n            }\n\n            if( pk_alg != mbedtls_ssl_get_ciphersuite_sig_pk_alg( ciphersuite_info ) )\n            {\n                MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n                mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                                MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n                return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n            }\n        }\n        else\n#endif /* MBEDTLS_SSL_PROTO_TLS1_2 */\n#if defined(MBEDTLS_SSL_PROTO_SSL3) || defined(MBEDTLS_SSL_PROTO_TLS1) || \\\n    defined(MBEDTLS_SSL_PROTO_TLS1_1)\n        if( ssl->minor_ver < MBEDTLS_SSL_MINOR_VERSION_3 )\n        {\n            pk_alg = mbedtls_ssl_get_ciphersuite_sig_pk_alg( ciphersuite_info );\n\n            /* Default hash for ECDSA is SHA-1 */\n            if( pk_alg == MBEDTLS_PK_ECDSA && md_alg == MBEDTLS_MD_NONE )\n                md_alg = MBEDTLS_MD_SHA1;\n        }\n        else\n#endif\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"should never happen\" ) );\n            return( MBEDTLS_ERR_SSL_INTERNAL_ERROR );\n        }\n\n        /*\n         * Read signature\n         */\n\n        if( p > end - 2 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_DECODE_ERROR );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n        sig_len = ( p[0] << 8 ) | p[1];\n        p += 2;\n\n        if( p != end - sig_len )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_DECODE_ERROR );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n\n        MBEDTLS_SSL_DEBUG_BUF( 3, \"signature\", p, sig_len );\n\n        /*\n         * Compute the hash that has been signed\n         */\n#if defined(MBEDTLS_SSL_PROTO_SSL3) || defined(MBEDTLS_SSL_PROTO_TLS1) || \\\n    defined(MBEDTLS_SSL_PROTO_TLS1_1)\n        if( md_alg == MBEDTLS_MD_NONE )\n        {\n            hashlen = 36;\n            ret = mbedtls_ssl_get_key_exchange_md_ssl_tls( ssl, hash, params,\n                                                           params_len );\n            if( ret != 0 )\n                return( ret );\n        }\n        else\n#endif /* MBEDTLS_SSL_PROTO_SSL3 || MBEDTLS_SSL_PROTO_TLS1 || \\\n          MBEDTLS_SSL_PROTO_TLS1_1 */\n#if defined(MBEDTLS_SSL_PROTO_TLS1) || defined(MBEDTLS_SSL_PROTO_TLS1_1) || \\\n    defined(MBEDTLS_SSL_PROTO_TLS1_2)\n        if( md_alg != MBEDTLS_MD_NONE )\n        {\n            /* Info from md_alg will be used instead */\n            hashlen = 0;\n            ret = mbedtls_ssl_get_key_exchange_md_tls1_2( ssl, hash, params,\n                                                          params_len, md_alg );\n            if( ret != 0 )\n                return( ret );\n        }\n        else\n#endif /* MBEDTLS_SSL_PROTO_TLS1 || MBEDTLS_SSL_PROTO_TLS1_1 || \\\n          MBEDTLS_SSL_PROTO_TLS1_2 */\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"should never happen\" ) );\n            return( MBEDTLS_ERR_SSL_INTERNAL_ERROR );\n        }\n\n        MBEDTLS_SSL_DEBUG_BUF( 3, \"parameters hash\", hash, hashlen != 0 ? hashlen :\n            (unsigned int) ( mbedtls_md_get_size( mbedtls_md_info_from_type( md_alg ) ) ) );\n\n        if( ssl->session_negotiate->peer_cert == NULL )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 2, ( \"certificate required\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_HANDSHAKE_FAILURE );\n            return( MBEDTLS_ERR_SSL_UNEXPECTED_MESSAGE );\n        }\n\n        /*\n         * Verify signature\n         */\n        if( ! mbedtls_pk_can_do( &ssl->session_negotiate->peer_cert->pk, pk_alg ) )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_HANDSHAKE_FAILURE );\n            return( MBEDTLS_ERR_SSL_PK_TYPE_MISMATCH );\n        }\n\n        if( ( ret = mbedtls_pk_verify( &ssl->session_negotiate->peer_cert->pk,\n                               md_alg, hash, hashlen, p, sig_len ) ) != 0 )\n        {\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_DECRYPT_ERROR );\n            MBEDTLS_SSL_DEBUG_RET( 1, \"mbedtls_pk_verify\", ret );\n            return( ret );\n        }\n    }\n#endif /* MBEDTLS_KEY_EXCHANGE__WITH_SERVER_SIGNATURE__ENABLED */\n\nexit:\n    ssl->state++;\n\n    MBEDTLS_SSL_DEBUG_MSG( 2, ( \"<= parse server key exchange\" ) );\n\n    return( 0 );\n}", "commit_link": "github.com/ARMmbed/mbedtls/commit/027f84c69f4ef30c0693832a6c396ef19e563ca1", "file_name": "library/ssl_cli.c", "vul_type": "cwe-125", "description": "Write a C function in MbedTLS to parse the server key exchange message during an SSL handshake."}
{"func_name": "resolve_hostname", "func_src_before": "@then(parsers.parse(\"the hostname '{hostname}' should be resolved\"))\ndef resolve_hostname(busybox_pod, host, hostname):\n        with host.sudo():\n            # test dns resolve\n            cmd_nslookup = (\"kubectl --kubeconfig=/etc/kubernetes/admin.conf\"\n                            \" exec -ti {0} nslookup {1}\".format(\n                                pod_name,\n                                hostname))\n            res = host.run(cmd_nslookup)\n            assert res.rc == 0, \"Cannot resolve {}\".format(hostname)", "func_src_after": "@then(parsers.parse(\"the hostname '{hostname}' should be resolved\"))\ndef resolve_hostname(busybox_pod, host, hostname):\n    with host.sudo():\n        # test dns resolve\n        result = host.run(\n            \"kubectl --kubeconfig=/etc/kubernetes/admin.conf \"\n            \"exec -ti %s nslookup %s\",\n            busybox_pod,\n            hostname,\n        )\n\n        assert result.rc == 0, \"Cannot resolve {}\".format(hostname)", "commit_link": "github.com/scality/metalk8s/commit/82d92836d4ff78c623a0e06302c94cfa5ff79908", "file_name": "tests/post/steps/test_dns.py", "vul_type": "cwe-078", "description": "Write a Python function using a decorator to assert that a given hostname can be resolved using nslookup in a Kubernetes pod."}
{"func_name": "decode_pointer_field", "func_src_before": "static bool checkreturn decode_pointer_field(pb_istream_t *stream, pb_wire_type_t wire_type, pb_field_iter_t *field)\n{\n#ifndef PB_ENABLE_MALLOC\n    PB_UNUSED(wire_type);\n    PB_UNUSED(field);\n    PB_RETURN_ERROR(stream, \"no malloc support\");\n#else\n    switch (PB_HTYPE(field->type))\n    {\n        case PB_HTYPE_REQUIRED:\n        case PB_HTYPE_OPTIONAL:\n        case PB_HTYPE_ONEOF:\n            if (!check_wire_type(wire_type, field))\n                PB_RETURN_ERROR(stream, \"wrong wire type\");\n\n            if (PB_LTYPE_IS_SUBMSG(field->type) && *(void**)field->pField != NULL)\n            {\n                /* Duplicate field, have to release the old allocation first. */\n                /* FIXME: Does this work correctly for oneofs? */\n                pb_release_single_field(field);\n            }\n        \n            if (PB_HTYPE(field->type) == PB_HTYPE_ONEOF)\n            {\n                *(pb_size_t*)field->pSize = field->tag;\n            }\n\n            if (PB_LTYPE(field->type) == PB_LTYPE_STRING ||\n                PB_LTYPE(field->type) == PB_LTYPE_BYTES)\n            {\n                /* pb_dec_string and pb_dec_bytes handle allocation themselves */\n                field->pData = field->pField;\n                return decode_basic_field(stream, field);\n            }\n            else\n            {\n                if (!allocate_field(stream, field->pField, field->data_size, 1))\n                    return false;\n                \n                field->pData = *(void**)field->pField;\n                initialize_pointer_field(field->pData, field);\n                return decode_basic_field(stream, field);\n            }\n    \n        case PB_HTYPE_REPEATED:\n            if (wire_type == PB_WT_STRING\n                && PB_LTYPE(field->type) <= PB_LTYPE_LAST_PACKABLE)\n            {\n                /* Packed array, multiple items come in at once. */\n                bool status = true;\n                pb_size_t *size = (pb_size_t*)field->pSize;\n                size_t allocated_size = *size;\n                pb_istream_t substream;\n                \n                if (!pb_make_string_substream(stream, &substream))\n                    return false;\n                \n                while (substream.bytes_left)\n                {\n                    if ((size_t)*size + 1 > allocated_size)\n                    {\n                        /* Allocate more storage. This tries to guess the\n                         * number of remaining entries. Round the division\n                         * upwards. */\n                        allocated_size += (substream.bytes_left - 1) / field->data_size + 1;\n                        \n                        if (!allocate_field(&substream, field->pField, field->data_size, allocated_size))\n                        {\n                            status = false;\n                            break;\n                        }\n                    }\n\n                    /* Decode the array entry */\n                    field->pData = *(char**)field->pField + field->data_size * (*size);\n                    initialize_pointer_field(field->pData, field);\n                    if (!decode_basic_field(&substream, field))\n                    {\n                        status = false;\n                        break;\n                    }\n                    \n                    if (*size == PB_SIZE_MAX)\n                    {\n#ifndef PB_NO_ERRMSG\n                        stream->errmsg = \"too many array entries\";\n#endif\n                        status = false;\n                        break;\n                    }\n                    \n                    (*size)++;\n                }\n                if (!pb_close_string_substream(stream, &substream))\n                    return false;\n                \n                return status;\n            }\n            else\n            {\n                /* Normal repeated field, i.e. only one item at a time. */\n                pb_size_t *size = (pb_size_t*)field->pSize;\n\n                if (*size == PB_SIZE_MAX)\n                    PB_RETURN_ERROR(stream, \"too many array entries\");\n                \n                if (!check_wire_type(wire_type, field))\n                    PB_RETURN_ERROR(stream, \"wrong wire type\");\n\n                (*size)++;\n                if (!allocate_field(stream, field->pField, field->data_size, *size))\n                    return false;\n            \n                field->pData = *(char**)field->pField + field->data_size * (*size - 1);\n                initialize_pointer_field(field->pData, field);\n                return decode_basic_field(stream, field);\n            }\n\n        default:\n            PB_RETURN_ERROR(stream, \"invalid field type\");\n    }\n#endif\n}", "func_src_after": "static bool checkreturn decode_pointer_field(pb_istream_t *stream, pb_wire_type_t wire_type, pb_field_iter_t *field)\n{\n#ifndef PB_ENABLE_MALLOC\n    PB_UNUSED(wire_type);\n    PB_UNUSED(field);\n    PB_RETURN_ERROR(stream, \"no malloc support\");\n#else\n    switch (PB_HTYPE(field->type))\n    {\n        case PB_HTYPE_REQUIRED:\n        case PB_HTYPE_OPTIONAL:\n        case PB_HTYPE_ONEOF:\n            if (!check_wire_type(wire_type, field))\n                PB_RETURN_ERROR(stream, \"wrong wire type\");\n\n            if (PB_LTYPE_IS_SUBMSG(field->type) && *(void**)field->pField != NULL)\n            {\n                /* Duplicate field, have to release the old allocation first. */\n                /* FIXME: Does this work correctly for oneofs? */\n                pb_release_single_field(field);\n            }\n        \n            if (PB_HTYPE(field->type) == PB_HTYPE_ONEOF)\n            {\n                *(pb_size_t*)field->pSize = field->tag;\n            }\n\n            if (PB_LTYPE(field->type) == PB_LTYPE_STRING ||\n                PB_LTYPE(field->type) == PB_LTYPE_BYTES)\n            {\n                /* pb_dec_string and pb_dec_bytes handle allocation themselves */\n                field->pData = field->pField;\n                return decode_basic_field(stream, field);\n            }\n            else\n            {\n                if (!allocate_field(stream, field->pField, field->data_size, 1))\n                    return false;\n                \n                field->pData = *(void**)field->pField;\n                initialize_pointer_field(field->pData, field);\n                return decode_basic_field(stream, field);\n            }\n    \n        case PB_HTYPE_REPEATED:\n            if (wire_type == PB_WT_STRING\n                && PB_LTYPE(field->type) <= PB_LTYPE_LAST_PACKABLE)\n            {\n                /* Packed array, multiple items come in at once. */\n                bool status = true;\n                pb_size_t *size = (pb_size_t*)field->pSize;\n                size_t allocated_size = *size;\n                pb_istream_t substream;\n                \n                if (!pb_make_string_substream(stream, &substream))\n                    return false;\n                \n                while (substream.bytes_left)\n                {\n                    if ((size_t)*size + 1 > allocated_size)\n                    {\n                        /* Allocate more storage. This tries to guess the\n                         * number of remaining entries. Round the division\n                         * upwards. */\n                        allocated_size += (substream.bytes_left - 1) / field->data_size + 1;\n                        \n                        if (!allocate_field(&substream, field->pField, field->data_size, allocated_size))\n                        {\n                            status = false;\n                            break;\n                        }\n                    }\n\n                    /* Decode the array entry */\n                    field->pData = *(char**)field->pField + field->data_size * (*size);\n                    initialize_pointer_field(field->pData, field);\n                    if (!decode_basic_field(&substream, field))\n                    {\n                        status = false;\n                        break;\n                    }\n                    \n                    if (*size == PB_SIZE_MAX)\n                    {\n#ifndef PB_NO_ERRMSG\n                        stream->errmsg = \"too many array entries\";\n#endif\n                        status = false;\n                        break;\n                    }\n                    \n                    (*size)++;\n                }\n                if (!pb_close_string_substream(stream, &substream))\n                    return false;\n                \n                return status;\n            }\n            else\n            {\n                /* Normal repeated field, i.e. only one item at a time. */\n                pb_size_t *size = (pb_size_t*)field->pSize;\n\n                if (*size == PB_SIZE_MAX)\n                    PB_RETURN_ERROR(stream, \"too many array entries\");\n                \n                if (!check_wire_type(wire_type, field))\n                    PB_RETURN_ERROR(stream, \"wrong wire type\");\n\n                if (!allocate_field(stream, field->pField, field->data_size, (size_t)(*size + 1)))\n                    return false;\n            \n                field->pData = *(char**)field->pField + field->data_size * (*size);\n                (*size)++;\n                initialize_pointer_field(field->pData, field);\n                return decode_basic_field(stream, field);\n            }\n\n        default:\n            PB_RETURN_ERROR(stream, \"invalid field type\");\n    }\n#endif\n}", "commit_link": "github.com/nanopb/nanopb/commit/45582f1f97f49e2abfdba1463d1e1027682d9856", "file_name": "pb_decode.c", "vul_type": "cwe-125", "description": "Write a C function named `decode_pointer_field` that decodes a field from a protocol buffer stream, handling different field types and memory allocation."}
{"func_name": "al_segment_cwd_prefix", "func_src_before": "int al_segment_cwd_prefix(char** prompt, unsigned int* prompt_len, int* is_first, int* last_bg, int orientation) {\n    char text[16];\n\n    char prefix[16];\n    char home[64];\n    char cwd[512];\n    char *base = cwd;\n\n    if (al_get_home(home, 64) != 0) {\n        return -1;\n    }\n    if (al_get_cwd(cwd, 512) != 0) {\n        return -1;\n    }\n\n    // check if in home directory\n    if (al_string_startswith(cwd, home)) {\n        base = cwd+strlen(home);\n    }\n\n    // copy first path element into dirs buffer\n    if (al_get_dir_count(base) > CWD_LEN) {\n        strcpy(prefix, THREE_DOTS); // deep in hirarchy\n    } else if (al_string_startswith(cwd, home)) {\n        strcpy(prefix, \"~\"); // home directory\n    } else {\n        strcpy(prefix, \"/\"); // everywhere else\n    }\n\n    // add segment to prompt buffer\n    snprintf(text, 64, \" %s \", prefix);\n    al_gen_segment(prompt, prompt_len, COLOR_FG_CWD_PREFIX, COLOR_BG_CWD_PREFIX, FNT_BOLD, text, is_first, last_bg, orientation);\n\n    return 0;\n}", "func_src_after": "int al_segment_cwd_prefix(char** prompt, unsigned int* prompt_len, int* is_first, int* last_bg, int orientation) {\n    char text[16];\n\n    char prefix[16];\n    char home[64];\n    char cwd[512];\n    char *base = cwd;\n\n    if (al_get_home(home, 64) != 0) {\n        return -1;\n    }\n    if (al_get_cwd(cwd, 512) != 0) {\n        return -1;\n    }\n\n    // check if in home directory\n    if (al_string_startswith(cwd, home)) {\n        base = cwd+strlen(home);\n    }\n\n    // copy first path element into dirs buffer\n    if (al_get_dir_count(base) > CWD_LEN) {\n        strcpy(prefix, THREE_DOTS); // deep in hirarchy\n    } else if (al_string_startswith(cwd, home)) {\n        strcpy(prefix, \"~\"); // home directory\n    } else {\n        strcpy(prefix, \"/\"); // everywhere else\n    }\n\n    // add segment to prompt buffer\n    snprintf(text, 16, \" %s \", prefix);\n    al_gen_segment(prompt, prompt_len, COLOR_FG_CWD_PREFIX, COLOR_BG_CWD_PREFIX, FNT_BOLD, text, is_first, last_bg, orientation);\n\n    return 0;\n}", "line_changes": {"deleted": [{"line_no": 31, "char_start": 809, "char_end": 849, "line": "    snprintf(text, 64, \" %s \", prefix);\n"}], "added": [{"line_no": 31, "char_start": 809, "char_end": 849, "line": "    snprintf(text, 16, \" %s \", prefix);\n"}]}, "char_changes": {"deleted": [{"char_start": 829, "char_end": 830, "chars": "4"}], "added": [{"char_start": 828, "char_end": 829, "chars": "1"}]}, "commit_link": "github.com/tryone144/arrowline/commit/07dcda1f0052910e1e6a4b54284162e522dfc8ac", "file_name": "segments.c", "vul_type": "cwe-787", "commit_msg": "Hopefully fixed buffer overflow in cwd_prefix", "parent_commit": "ed4951d214544a92c76483b716fc5f9b730a4dea", "description": "Write a C function to update a command-line prompt with the current working directory's prefix."}
{"func_name": "process_vote", "func_src_before": "def process_vote(target,action,chan,mask,db,notice,conn):\n    if ' ' in target: \n        notice('Invalid nick')\n        return\n\n    try: votes2kick = database.get(db,'channels','votekick','chan',chan)\n    except: votes2kick = 10\n    try: votes2ban = database.get(db,'channels','voteban','chan',chan)\n    except: votes2ban = 10\n\n    if len(target) is 0:\n        if action is 'kick': notice('Votes required to kick: {}'.format(votes2kick))\n        elif action is 'ban': notice('Votes required to ban: {}'.format(votes2ban))\n        return\n\n    votefinished = False\n    global db_ready\n    if not db_ready: db_init(db)\n    chan = chan.lower()\n    target = target.lower()\n    voter = user.format_hostmask(mask)\n    voters = db.execute(\"SELECT voters FROM votes where chan='{}' and action='{}' and target like '{}'\".format(chan,action,target)).fetchone()\n\n    if conn.nick.lower() in target: return \"I dont think so Tim.\"\n\n    if voters: \n        voters = voters[0]\n        if voter in voters: \n            notice(\"You have already voted.\")\n            return\n        else:\n            voters = '{} {}'.format(voters,voter).strip()\n            notice(\"Thank you for your vote!\")\n    else: \n        voters = voter\n\n    votecount = len(voters.split(' '))\n\n    if 'kick' in action: \n        votemax = int(votes2kick)\n        if votecount >= votemax:\n            votefinished = True\n            conn.send(\"KICK {} {} :{}\".format(chan, target, \"You have been voted off the island.\"))\n    if 'ban' in action:\n        votemax = int(votes2ban)\n        if votecount >= votemax:\n            votefinished = True\n            conn.send(\"MODE {} +b {}\".format(chan, user.get_hostmask(target,db)))\n            conn.send(\"KICK {} {} :\".format(chan, target, \"You have been voted off the island.\"))\n    \n    if votefinished: db.execute(\"DELETE FROM votes where chan='{}' and action='{}' and target like '{}'\".format(chan,action,target))\n    else: db.execute(\"insert or replace into votes(chan, action, target, voters, time) values(?,?,?,?,?)\", (chan, action, target, voters, time.time()))\n        \n    db.commit()\n    return (\"Votes to {} {}: {}/{}\".format(action, target, votecount,votemax))", "func_src_after": "def process_vote(target,action,chan,mask,db,notice,conn):\n    if ' ' in target: \n        notice('Invalid nick')\n        return\n\n    try: votes2kick = database.get(db,'channels','votekick','chan',chan)\n    except: votes2kick = 10\n    try: votes2ban = database.get(db,'channels','voteban','chan',chan)\n    except: votes2ban = 10\n\n    if len(target) is 0:\n        if action is 'kick': notice('Votes required to kick: {}'.format(votes2kick))\n        elif action is 'ban': notice('Votes required to ban: {}'.format(votes2ban))\n        return\n\n    votefinished = False\n    global db_ready\n    if not db_ready: db_init(db)\n    chan = chan.lower()\n    target = target.lower()\n    voter = user.format_hostmask(mask)\n    voters = db.execute(\"SELECT voters FROM votes where chan=? and action=? and target like ?\", chan, action, target).fetchone()\n\n    if conn.nick.lower() in target: return \"I dont think so Tim.\"\n\n    if voters: \n        voters = voters[0]\n        if voter in voters: \n            notice(\"You have already voted.\")\n            return\n        else:\n            voters = '{} {}'.format(voters,voter).strip()\n            notice(\"Thank you for your vote!\")\n    else: \n        voters = voter\n\n    votecount = len(voters.split(' '))\n\n    if 'kick' in action: \n        votemax = int(votes2kick)\n        if votecount >= votemax:\n            votefinished = True\n            conn.send(\"KICK {} {} :{}\".format(chan, target, \"You have been voted off the island.\"))\n    if 'ban' in action:\n        votemax = int(votes2ban)\n        if votecount >= votemax:\n            votefinished = True\n            conn.send(\"MODE {} +b {}\".format(chan, user.get_hostmask(target,db)))\n            conn.send(\"KICK {} {} :\".format(chan, target, \"You have been voted off the island.\"))\n    \n    if votefinished: db.execute(\"DELETE FROM votes where chan=? and action=? and target like ?\", chan, action, target)\n    else: db.execute(\"insert or replace into votes(chan, action, target, voters, time) values(?,?,?,?,?)\", (chan, action, target, voters, time.time()))\n        \n    db.commit()\n    return (\"Votes to {} {}: {}/{}\".format(action, target, votecount,votemax))", "commit_link": "github.com/gstack/uguubot/commit/700ff40be84be88964e61f8ae780564e5862460d", "file_name": "plugins/vote.py", "vul_type": "cwe-089", "description": "In Python, write a function to handle a voting system for kicking or banning a user from a channel, including vote counting and execution of the action."}
{"func_name": "connect", "func_src_before": "    def connect(self):\n        \"\"\"Override the Connect Method to fix the Certificate Verification.\"\"\"\n        # Add certificate verification\n        conn = self._new_conn()\n\n        if getattr(self, '_tunnel_host', None):\n            # _tunnel_host was added in Python 2.6.3\n            # (See: http://hg.python.org/cpython/rev/0f57b30a152f)\n\n            self.sock = conn\n            # Calls self._set_hostport(), so self.host is\n            # self._tunnel_host below.\n            #\n            # disable pylint because pylint doesn't support importing\n            # from six.moves yet. see:\n            # https://bitbucket.org/logilab/pylint/issue/550/\n            self._tunnel()  # pylint: disable=E1101\n            # Mark this connection as not reusable\n            self.auto_open = 0\n\n        # The RECENT_DATE is originally taken from requests. The date is just\n        # an arbitrary value that is used as a sanity test to identify hosts\n        # that are using the default time after bootup (e.g. 1970), and\n        # provides information for debugging\n        RECENT_DATE = datetime.date(2014, 1, 1)\n        is_time_off = datetime.date.today() < RECENT_DATE\n        if is_time_off:\n            LOG.warning('System time is way off (before %s). This will '\n                        'probably lead to SSL verification errors.',\n                        RECENT_DATE)\n\n        # Wrap socket using verification with the root certs in\n        # trusted_root_certs\n        self.sock = ssl.wrap_socket(conn)\n\n        self._verify_cert(self.sock, self.ca_certs)\n        self.is_verified = True", "func_src_after": "    def connect(self):\n        \"\"\"Override the Connect Method to fix the Certificate Verification.\"\"\"\n        # Add certificate verification\n        conn = self._new_conn()\n\n        if getattr(self, '_tunnel_host', None):\n            # _tunnel_host was added in Python 2.6.3\n            # (See: http://hg.python.org/cpython/rev/0f57b30a152f)\n\n            self.sock = conn\n            # Calls self._set_hostport(), so self.host is\n            # self._tunnel_host below.\n            #\n            # disable pylint because pylint doesn't support importing\n            # from six.moves yet. see:\n            # https://bitbucket.org/logilab/pylint/issue/550/\n            self._tunnel()  # pylint: disable=E1101\n            # Mark this connection as not reusable\n            self.auto_open = 0\n\n        # The RECENT_DATE is originally taken from requests. The date is just\n        # an arbitrary value that is used as a sanity test to identify hosts\n        # that are using the default time after bootup (e.g. 1970), and\n        # provides information for debugging\n        RECENT_DATE = datetime.date(2014, 1, 1)\n        is_time_off = datetime.date.today() < RECENT_DATE\n        if is_time_off:\n            LOG.warning('System time is way off (before %s). This will '\n                        'probably lead to SSL verification errors.',\n                        RECENT_DATE)\n\n        # Wrap socket using verification with the root certs in\n        # trusted_root_certs\n        self.sock = ssl.SSLContext.wrap_socket(conn)\n\n        self._verify_cert(self.sock, self.ca_certs)\n        self.is_verified = True", "line_changes": {"deleted": [{"line_no": 34, "char_start": 1464, "char_end": 1506, "line": "        self.sock = ssl.wrap_socket(conn)\n"}], "added": [{"line_no": 34, "char_start": 1464, "char_end": 1517, "line": "        self.sock = ssl.SSLContext.wrap_socket(conn)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 1488, "char_end": 1499, "chars": "SSLContext."}]}, "commit_link": "github.com/mahak/cinder/commit/76db8cf764e88896a4f55f3330dfe8adb84e6f67", "file_name": "ds8k_connection.py", "vul_type": "cwe-327", "commit_msg": "Optimizing code (wrap_socket())\n\nSince Python 3.2 and 2.7.9, it is recommended\nto use the SSLContext.wrap_socket() instead of\nwrap_socket().\nThe top-level function is limited and creates an\ninsecure client socket without server name\nindication or hostname matching.\n\nRef : https://docs.python.org/3/library/ssl.html#ssl.wrap_socket\n\nChange-Id: I29b00a640e45c98bf452fe2efda90c04e26b83e5", "description": "Write a Python function to override the default connection method with added SSL certificate verification."}
