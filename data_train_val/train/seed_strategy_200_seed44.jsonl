{"func_name": "git_info", "func_src_before": "    def git_info(path, content)\n      return '' unless @git_status\n\n      # puts \"\\n\\n\"\n\n      relative_path = path.remove(@git_root_path+'/')\n      relative_path = relative_path==path ? '' : relative_path+'/'\n      content_path  = \"#{relative_path}#{content}\"\n\n      if content.directory?\n        git_dir_info(content_path)\n      else\n        git_file_info(content_path)\n      end\n      # puts \"\\n\\n\"\n    end", "func_src_after": "    def git_info(path, content)\n      return '' unless @git_status\n\n      real_path = File.realdirpath(content.name, path)\n\n      return '    ' unless real_path.start_with? path\n\n      relative_path = real_path.remove(Regexp.new('^' + Regexp.escape(@git_root_path) + '/?'))\n\n      if content.directory?\n        git_dir_info(relative_path)\n      else\n        git_file_info(relative_path)\n      end\n      # puts \"\\n\\n\"\n    end", "line_changes": {"deleted": [{"line_no": 6, "char_start": 89, "char_end": 143, "line": "      relative_path = path.remove(@git_root_path+'/')\n"}, {"line_no": 7, "char_start": 143, "char_end": 210, "line": "      relative_path = relative_path==path ? '' : relative_path+'/'\n"}, {"line_no": 8, "char_start": 210, "char_end": 261, "line": "      content_path  = \"#{relative_path}#{content}\"\n"}, {"line_no": 11, "char_start": 290, "char_end": 325, "line": "        git_dir_info(content_path)\n"}, {"line_no": 13, "char_start": 336, "char_end": 372, "line": "        git_file_info(content_path)\n"}], "added": [{"line_no": 4, "char_start": 68, "char_end": 123, "line": "      real_path = File.realdirpath(content.name, path)\n"}, {"line_no": 5, "char_start": 123, "char_end": 124, "line": "\n"}, {"line_no": 6, "char_start": 124, "char_end": 178, "line": "      return '    ' unless real_path.start_with? path\n"}, {"line_no": 8, "char_start": 179, "char_end": 274, "line": "      relative_path = real_path.remove(Regexp.new('^' + Regexp.escape(@git_root_path) + '/?'))\n"}, {"line_no": 11, "char_start": 303, "char_end": 339, "line": "        git_dir_info(relative_path)\n"}, {"line_no": 13, "char_start": 350, "char_end": 387, "line": "        git_file_info(relative_path)\n"}]}, "char_changes": {"deleted": [{"char_start": 74, "char_end": 260, "chars": "# puts \"\\n\\n\"\n\n      relative_path = path.remove(@git_root_path+'/')\n      relative_path = relative_path==path ? '' : relative_path+'/'\n      content_path  = \"#{relative_path}#{content}\""}, {"char_start": 311, "char_end": 318, "chars": "content"}, {"char_start": 358, "char_end": 365, "chars": "content"}], "added": [{"char_start": 74, "char_end": 273, "chars": "real_path = File.realdirpath(content.name, path)\n\n      return '    ' unless real_path.start_with? path\n\n      relative_path = real_path.remove(Regexp.new('^' + Regexp.escape(@git_root_path) + '/?'))"}, {"char_start": 324, "char_end": 332, "chars": "relative"}, {"char_start": 372, "char_end": 380, "chars": "relative"}]}, "commit_link": "github.com/athityakumar/colorls/commit/b362fa1eb81e7e6fa208cc8cab51f110db20057b", "file_name": "core.rb", "vul_type": "cwe-022", "commit_msg": "Improve git-status processing\n\n* no longer traverse complete directory trees to determine git status for\n  directories\n\n* properly report status for folders with changed files\n\n* skip the parent folder since we do not have git status about it", "parent_commit": "bb270b319a68adb96bf91a311250481020bdde81", "description": "Write a Ruby method named `git_info` that takes a file system path and a content object, and returns git information based on whether the content is a directory or a file."}
{"func_name": "get_all_referrers", "func_src_before": "@app.route('/get_all_referrers')\ndef get_all_referrers():\n    account_id = request.args.get('account_id')\n\n    if not isObject(account_id):\n        ws.send('{\"id\":1, \"method\":\"call\", \"params\":[0,\"lookup_account_names\",[[\"' + account_id + '\"], 0]]}')\n        result_l = ws.recv()\n        j_l = json.loads(result_l)\n\n        account_id = j_l[\"result\"][0][\"id\"]\n\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"select * from referrers where referrer='\"+account_id+\"'\"\n    cur.execute(query)\n    results = cur.fetchall()\n\n    return jsonify(results)", "func_src_after": "@app.route('/get_all_referrers')\ndef get_all_referrers():\n    account_id = request.args.get('account_id')\n\n    if not isObject(account_id):\n        ws.send('{\"id\":1, \"method\":\"call\", \"params\":[0,\"lookup_account_names\",[[\"' + account_id + '\"], 0]]}')\n        result_l = ws.recv()\n        j_l = json.loads(result_l)\n\n        account_id = j_l[\"result\"][0][\"id\"]\n\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"select * from referrers where referrer=%s\"\n    cur.execute(query, (account_id,))\n    results = cur.fetchall()\n\n    return jsonify(results)", "commit_link": "github.com/VinChain/vinchain-python-api-backend/commit/b78088a551fbb712121269c6eb7f43ede120ff60", "file_name": "api.py", "vul_type": "cwe-089", "description": "Create a Python Flask endpoint to fetch and return all referrer entries for a given account ID from a PostgreSQL database, handling account ID lookup if necessary."}
{"func_name": "onig_new_deluxe", "func_src_before": "onig_new_deluxe(regex_t** reg, const UChar* pattern, const UChar* pattern_end,\n                OnigCompileInfo* ci, OnigErrorInfo* einfo)\n{\n  int r;\n  UChar *cpat, *cpat_end;\n\n  if (IS_NOT_NULL(einfo)) einfo->par = (UChar* )NULL;\n\n  if (ci->pattern_enc != ci->target_enc) {\n    r = conv_encoding(ci->pattern_enc, ci->target_enc, pattern, pattern_end,\n                      &cpat, &cpat_end);\n    if (r != 0) return r;\n  }\n  else {\n    cpat     = (UChar* )pattern;\n    cpat_end = (UChar* )pattern_end;\n  }\n\n  *reg = (regex_t* )xmalloc(sizeof(regex_t));\n  if (IS_NULL(*reg)) {\n    r = ONIGERR_MEMORY;\n    goto err2;\n  }\n\n  r = onig_reg_init(*reg, ci->option, ci->case_fold_flag, ci->target_enc,\n                    ci->syntax);\n  if (r != 0) goto err;\n\n  r = onig_compile(*reg, cpat, cpat_end, einfo);\n  if (r != 0) {\n  err:\n    onig_free(*reg);\n    *reg = NULL;\n  }\n\n err2:\n  if (cpat != pattern) xfree(cpat);\n\n  return r;\n}", "func_src_after": "onig_new_deluxe(regex_t** reg, const UChar* pattern, const UChar* pattern_end,\n                OnigCompileInfo* ci, OnigErrorInfo* einfo)\n{\n  int r;\n  UChar *cpat, *cpat_end;\n\n  if (IS_NOT_NULL(einfo)) einfo->par = (UChar* )NULL;\n\n  if (ci->pattern_enc != ci->target_enc) {\n    return ONIGERR_NOT_SUPPORTED_ENCODING_COMBINATION;\n  }\n  else {\n    cpat     = (UChar* )pattern;\n    cpat_end = (UChar* )pattern_end;\n  }\n\n  *reg = (regex_t* )xmalloc(sizeof(regex_t));\n  if (IS_NULL(*reg)) {\n    r = ONIGERR_MEMORY;\n    goto err2;\n  }\n\n  r = onig_reg_init(*reg, ci->option, ci->case_fold_flag, ci->target_enc,\n                    ci->syntax);\n  if (r != 0) goto err;\n\n  r = onig_compile(*reg, cpat, cpat_end, einfo);\n  if (r != 0) {\n  err:\n    onig_free(*reg);\n    *reg = NULL;\n  }\n\n err2:\n  if (cpat != pattern) xfree(cpat);\n\n  return r;\n}", "commit_link": "github.com/kkos/oniguruma/commit/0f7f61ed1b7b697e283e37bd2d731d0bd57adb55", "file_name": "src/regext.c", "vul_type": "cwe-416", "description": "Write a C function named `onig_new_deluxe` that initializes a new regular expression object with error handling."}
{"func_name": "run", "func_src_before": "static int run(const CommandLineOptions& options)\n{\n\tIR::Module irModule;\n\n\t// Load the module.\n\tif(!loadModule(options.filename, irModule)) { return EXIT_FAILURE; }\n\tif(options.onlyCheck) { return EXIT_SUCCESS; }\n\n\t// Compile the module.\n\tRuntime::Module* module = nullptr;\n\tif(!options.precompiled) { module = Runtime::compileModule(irModule); }\n\telse\n\t{\n\t\tconst UserSection* precompiledObjectSection = nullptr;\n\t\tfor(const UserSection& userSection : irModule.userSections)\n\t\t{\n\t\t\tif(userSection.name == \"wavm.precompiled_object\")\n\t\t\t{\n\t\t\t\tprecompiledObjectSection = &userSection;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif(!precompiledObjectSection)\n\t\t{\n\t\t\tLog::printf(Log::error, \"Input file did not contain 'wavm.precompiled_object' section\");\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tmodule = Runtime::loadPrecompiledModule(irModule, precompiledObjectSection->data);\n\t\t}\n\t}\n\n\t// Link the module with the intrinsic modules.\n\tCompartment* compartment = Runtime::createCompartment();\n\tContext* context = Runtime::createContext(compartment);\n\tRootResolver rootResolver(compartment);\n\n\tEmscripten::Instance* emscriptenInstance = nullptr;\n\tif(options.enableEmscripten)\n\t{\n\t\temscriptenInstance = Emscripten::instantiate(compartment, irModule);\n\t\tif(emscriptenInstance)\n\t\t{\n\t\t\trootResolver.moduleNameToInstanceMap.set(\"env\", emscriptenInstance->env);\n\t\t\trootResolver.moduleNameToInstanceMap.set(\"asm2wasm\", emscriptenInstance->asm2wasm);\n\t\t\trootResolver.moduleNameToInstanceMap.set(\"global\", emscriptenInstance->global);\n\t\t}\n\t}\n\n\tif(options.enableThreadTest)\n\t{\n\t\tModuleInstance* threadTestInstance = ThreadTest::instantiate(compartment);\n\t\trootResolver.moduleNameToInstanceMap.set(\"threadTest\", threadTestInstance);\n\t}\n\n\tLinkResult linkResult = linkModule(irModule, rootResolver);\n\tif(!linkResult.success)\n\t{\n\t\tLog::printf(Log::error, \"Failed to link module:\\n\");\n\t\tfor(auto& missingImport : linkResult.missingImports)\n\t\t{\n\t\t\tLog::printf(Log::error,\n\t\t\t\t\t\t\"Missing import: module=\\\"%s\\\" export=\\\"%s\\\" type=\\\"%s\\\"\\n\",\n\t\t\t\t\t\tmissingImport.moduleName.c_str(),\n\t\t\t\t\t\tmissingImport.exportName.c_str(),\n\t\t\t\t\t\tasString(missingImport.type).c_str());\n\t\t}\n\t\treturn EXIT_FAILURE;\n\t}\n\n\t// Instantiate the module.\n\tModuleInstance* moduleInstance = instantiateModule(\n\t\tcompartment, module, std::move(linkResult.resolvedImports), options.filename);\n\tif(!moduleInstance) { return EXIT_FAILURE; }\n\n\t// Call the module start function, if it has one.\n\tFunctionInstance* startFunction = getStartFunction(moduleInstance);\n\tif(startFunction) { invokeFunctionChecked(context, startFunction, {}); }\n\n\tif(options.enableEmscripten)\n\t{\n\t\t// Call the Emscripten global initalizers.\n\t\tEmscripten::initializeGlobals(context, irModule, moduleInstance);\n\t}\n\n\t// Look up the function export to call.\n\tFunctionInstance* functionInstance;\n\tif(!options.functionName)\n\t{\n\t\tfunctionInstance = asFunctionNullable(getInstanceExport(moduleInstance, \"main\"));\n\t\tif(!functionInstance)\n\t\t{ functionInstance = asFunctionNullable(getInstanceExport(moduleInstance, \"_main\")); }\n\t\tif(!functionInstance)\n\t\t{\n\t\t\tLog::printf(Log::error, \"Module does not export main function\\n\");\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t}\n\telse\n\t{\n\t\tfunctionInstance\n\t\t\t= asFunctionNullable(getInstanceExport(moduleInstance, options.functionName));\n\t\tif(!functionInstance)\n\t\t{\n\t\t\tLog::printf(Log::error, \"Module does not export '%s'\\n\", options.functionName);\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t}\n\tFunctionType functionType = getFunctionType(functionInstance);\n\n\t// Set up the arguments for the invoke.\n\tstd::vector<Value> invokeArgs;\n\tif(!options.functionName)\n\t{\n\t\tif(functionType.params().size() == 2)\n\t\t{\n\t\t\tMemoryInstance* defaultMemory = Runtime::getDefaultMemory(moduleInstance);\n\t\t\tif(!defaultMemory)\n\t\t\t{\n\t\t\t\tLog::printf(\n\t\t\t\t\tLog::error,\n\t\t\t\t\t\"Module does not declare a default memory object to put arguments in.\\n\");\n\t\t\t\treturn EXIT_FAILURE;\n\t\t\t}\n\n\t\t\tstd::vector<const char*> argStrings;\n\t\t\targStrings.push_back(options.filename);\n\t\t\tchar** args = options.args;\n\t\t\twhile(*args) { argStrings.push_back(*args++); };\n\n\t\t\tEmscripten::injectCommandArgs(emscriptenInstance, argStrings, invokeArgs);\n\t\t}\n\t\telse if(functionType.params().size() > 0)\n\t\t{\n\t\t\tLog::printf(Log::error,\n\t\t\t\t\t\t\"WebAssembly function requires %\" PRIu64\n\t\t\t\t\t\t\" argument(s), but only 0 or 2 can be passed!\",\n\t\t\t\t\t\tfunctionType.params().size());\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t}\n\telse\n\t{\n\t\tfor(U32 i = 0; options.args[i]; ++i)\n\t\t{\n\t\t\tValue value;\n\t\t\tswitch(functionType.params()[i])\n\t\t\t{\n\t\t\tcase ValueType::i32: value = (U32)atoi(options.args[i]); break;\n\t\t\tcase ValueType::i64: value = (U64)atol(options.args[i]); break;\n\t\t\tcase ValueType::f32: value = (F32)atof(options.args[i]); break;\n\t\t\tcase ValueType::f64: value = atof(options.args[i]); break;\n\t\t\tcase ValueType::v128:\n\t\t\tcase ValueType::anyref:\n\t\t\tcase ValueType::anyfunc:\n\t\t\t\tErrors::fatalf(\"Cannot parse command-line argument for %s function parameter\",\n\t\t\t\t\t\t\t   asString(functionType.params()[i]));\n\t\t\tdefault: Errors::unreachable();\n\t\t\t}\n\t\t\tinvokeArgs.push_back(value);\n\t\t}\n\t}\n\n\t// Invoke the function.\n\tTiming::Timer executionTimer;\n\tIR::ValueTuple functionResults = invokeFunctionChecked(context, functionInstance, invokeArgs);\n\tTiming::logTimer(\"Invoked function\", executionTimer);\n\n\tif(options.functionName)\n\t{\n\t\tLog::printf(Log::debug,\n\t\t\t\t\t\"%s returned: %s\\n\",\n\t\t\t\t\toptions.functionName,\n\t\t\t\t\tasString(functionResults).c_str());\n\t\treturn EXIT_SUCCESS;\n\t}\n\telse if(functionResults.size() == 1 && functionResults[0].type == ValueType::i32)\n\t{\n\t\treturn functionResults[0].i32;\n\t}\n\telse\n\t{\n\t\treturn EXIT_SUCCESS;\n\t}\n}", "func_src_after": "static int run(const CommandLineOptions& options)\n{\n\tIR::Module irModule;\n\n\t// Load the module.\n\tif(!loadModule(options.filename, irModule)) { return EXIT_FAILURE; }\n\tif(options.onlyCheck) { return EXIT_SUCCESS; }\n\n\t// Compile the module.\n\tRuntime::Module* module = nullptr;\n\tif(!options.precompiled) { module = Runtime::compileModule(irModule); }\n\telse\n\t{\n\t\tconst UserSection* precompiledObjectSection = nullptr;\n\t\tfor(const UserSection& userSection : irModule.userSections)\n\t\t{\n\t\t\tif(userSection.name == \"wavm.precompiled_object\")\n\t\t\t{\n\t\t\t\tprecompiledObjectSection = &userSection;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif(!precompiledObjectSection)\n\t\t{\n\t\t\tLog::printf(Log::error, \"Input file did not contain 'wavm.precompiled_object' section\");\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tmodule = Runtime::loadPrecompiledModule(irModule, precompiledObjectSection->data);\n\t\t}\n\t}\n\n\t// Link the module with the intrinsic modules.\n\tCompartment* compartment = Runtime::createCompartment();\n\tContext* context = Runtime::createContext(compartment);\n\tRootResolver rootResolver(compartment);\n\n\tEmscripten::Instance* emscriptenInstance = nullptr;\n\tif(options.enableEmscripten)\n\t{\n\t\temscriptenInstance = Emscripten::instantiate(compartment, irModule);\n\t\tif(emscriptenInstance)\n\t\t{\n\t\t\trootResolver.moduleNameToInstanceMap.set(\"env\", emscriptenInstance->env);\n\t\t\trootResolver.moduleNameToInstanceMap.set(\"asm2wasm\", emscriptenInstance->asm2wasm);\n\t\t\trootResolver.moduleNameToInstanceMap.set(\"global\", emscriptenInstance->global);\n\t\t}\n\t}\n\n\tif(options.enableThreadTest)\n\t{\n\t\tModuleInstance* threadTestInstance = ThreadTest::instantiate(compartment);\n\t\trootResolver.moduleNameToInstanceMap.set(\"threadTest\", threadTestInstance);\n\t}\n\n\tLinkResult linkResult = linkModule(irModule, rootResolver);\n\tif(!linkResult.success)\n\t{\n\t\tLog::printf(Log::error, \"Failed to link module:\\n\");\n\t\tfor(auto& missingImport : linkResult.missingImports)\n\t\t{\n\t\t\tLog::printf(Log::error,\n\t\t\t\t\t\t\"Missing import: module=\\\"%s\\\" export=\\\"%s\\\" type=\\\"%s\\\"\\n\",\n\t\t\t\t\t\tmissingImport.moduleName.c_str(),\n\t\t\t\t\t\tmissingImport.exportName.c_str(),\n\t\t\t\t\t\tasString(missingImport.type).c_str());\n\t\t}\n\t\treturn EXIT_FAILURE;\n\t}\n\n\t// Instantiate the module.\n\tModuleInstance* moduleInstance = instantiateModule(\n\t\tcompartment, module, std::move(linkResult.resolvedImports), options.filename);\n\tif(!moduleInstance) { return EXIT_FAILURE; }\n\n\t// Call the module start function, if it has one.\n\tFunctionInstance* startFunction = getStartFunction(moduleInstance);\n\tif(startFunction) { invokeFunctionChecked(context, startFunction, {}); }\n\n\tif(options.enableEmscripten)\n\t{\n\t\t// Call the Emscripten global initalizers.\n\t\tEmscripten::initializeGlobals(context, irModule, moduleInstance);\n\t}\n\n\t// Look up the function export to call.\n\tFunctionInstance* functionInstance;\n\tif(!options.functionName)\n\t{\n\t\tfunctionInstance = asFunctionNullable(getInstanceExport(moduleInstance, \"main\"));\n\t\tif(!functionInstance)\n\t\t{ functionInstance = asFunctionNullable(getInstanceExport(moduleInstance, \"_main\")); }\n\t\tif(!functionInstance)\n\t\t{\n\t\t\tLog::printf(Log::error, \"Module does not export main function\\n\");\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t}\n\telse\n\t{\n\t\tfunctionInstance\n\t\t\t= asFunctionNullable(getInstanceExport(moduleInstance, options.functionName));\n\t\tif(!functionInstance)\n\t\t{\n\t\t\tLog::printf(Log::error, \"Module does not export '%s'\\n\", options.functionName);\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t}\n\tFunctionType functionType = getFunctionType(functionInstance);\n\n\t// Set up the arguments for the invoke.\n\tstd::vector<Value> invokeArgs;\n\tif(!options.functionName)\n\t{\n\t\tif(functionType.params().size() == 2)\n\t\t{\n\t\t\tif(!emscriptenInstance)\n\t\t\t{\n\t\t\t\tLog::printf(\n\t\t\t\t\tLog::error,\n\t\t\t\t\t\"Module does not declare a default memory object to put arguments in.\\n\");\n\t\t\t\treturn EXIT_FAILURE;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tstd::vector<const char*> argStrings;\n\t\t\t\targStrings.push_back(options.filename);\n\t\t\t\tchar** args = options.args;\n\t\t\t\twhile(*args) { argStrings.push_back(*args++); };\n\n\t\t\t\twavmAssert(emscriptenInstance);\n\t\t\t\tEmscripten::injectCommandArgs(emscriptenInstance, argStrings, invokeArgs);\n\t\t\t}\n\t\t}\n\t\telse if(functionType.params().size() > 0)\n\t\t{\n\t\t\tLog::printf(Log::error,\n\t\t\t\t\t\t\"WebAssembly function requires %\" PRIu64\n\t\t\t\t\t\t\" argument(s), but only 0 or 2 can be passed!\",\n\t\t\t\t\t\tfunctionType.params().size());\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t}\n\telse\n\t{\n\t\tfor(U32 i = 0; options.args[i]; ++i)\n\t\t{\n\t\t\tValue value;\n\t\t\tswitch(functionType.params()[i])\n\t\t\t{\n\t\t\tcase ValueType::i32: value = (U32)atoi(options.args[i]); break;\n\t\t\tcase ValueType::i64: value = (U64)atol(options.args[i]); break;\n\t\t\tcase ValueType::f32: value = (F32)atof(options.args[i]); break;\n\t\t\tcase ValueType::f64: value = atof(options.args[i]); break;\n\t\t\tcase ValueType::v128:\n\t\t\tcase ValueType::anyref:\n\t\t\tcase ValueType::anyfunc:\n\t\t\t\tErrors::fatalf(\"Cannot parse command-line argument for %s function parameter\",\n\t\t\t\t\t\t\t   asString(functionType.params()[i]));\n\t\t\tdefault: Errors::unreachable();\n\t\t\t}\n\t\t\tinvokeArgs.push_back(value);\n\t\t}\n\t}\n\n\t// Invoke the function.\n\tTiming::Timer executionTimer;\n\tIR::ValueTuple functionResults = invokeFunctionChecked(context, functionInstance, invokeArgs);\n\tTiming::logTimer(\"Invoked function\", executionTimer);\n\n\tif(options.functionName)\n\t{\n\t\tLog::printf(Log::debug,\n\t\t\t\t\t\"%s returned: %s\\n\",\n\t\t\t\t\toptions.functionName,\n\t\t\t\t\tasString(functionResults).c_str());\n\t\treturn EXIT_SUCCESS;\n\t}\n\telse if(functionResults.size() == 1 && functionResults[0].type == ValueType::i32)\n\t{\n\t\treturn functionResults[0].i32;\n\t}\n\telse\n\t{\n\t\treturn EXIT_SUCCESS;\n\t}\n}", "commit_link": "github.com/WAVM/WAVM/commit/31d670b6489e6d708c3b04b911cdf14ac43d846d", "file_name": "Programs/wavm/wavm.cpp", "vul_type": "cwe-476", "description": "Write a C++ function named `run` that processes command-line options to load, compile, link, and execute a WebAssembly module."}
{"func_name": "__init__", "func_src_before": "  def __init__(self,\n               sess,\n               dump_root=None,\n               log_usage=True,\n               ui_type=\"curses\",\n               thread_name_filter=None,\n               config_file_path=False):\n    \"\"\"Constructor of LocalCLIDebugWrapperSession.\n\n    Args:\n      sess: The TensorFlow `Session` object being wrapped.\n      dump_root: (`str`) optional path to the dump root directory. Must be a\n        directory that does not exist or an empty directory. If the directory\n        does not exist, it will be created by the debugger core during debug\n        `run()` calls and removed afterwards. If `None`, the debug dumps will\n        be at tfdbg_<random_string> under the system temp directory.\n      log_usage: (`bool`) whether the usage of this class is to be logged.\n      ui_type: (`str`) requested UI type. Currently supported:\n        (curses | readline)\n      thread_name_filter: Regular-expression white list for thread name. See\n        the doc of `BaseDebugWrapperSession` for details.\n      config_file_path: Optional override to the default configuration file\n        path, which is at `${HOME}/.tfdbg_config`.\n\n    Raises:\n      ValueError: If dump_root is an existing and non-empty directory or if\n        dump_root is a file.\n    \"\"\"\n\n    if log_usage:\n      pass  # No logging for open-source.\n\n    framework.BaseDebugWrapperSession.__init__(\n        self, sess, thread_name_filter=thread_name_filter)\n\n    if not dump_root:\n      self._dump_root = tempfile.mktemp(prefix=_DUMP_ROOT_PREFIX)\n    else:\n      dump_root = os.path.expanduser(dump_root)\n      if os.path.isfile(dump_root):\n        raise ValueError(\"dump_root path points to a file: %s\" % dump_root)\n      elif os.path.isdir(dump_root) and os.listdir(dump_root):\n        raise ValueError(\"dump_root path points to a non-empty directory: %s\" %\n                         dump_root)\n\n      self._dump_root = dump_root\n\n    self._initialize_argparsers()\n\n    # Registered tensor filters.\n    self._tensor_filters = {}\n    # Register frequently-used filter(s).\n    self.add_tensor_filter(\"has_inf_or_nan\", debug_data.has_inf_or_nan)\n\n    # Below are the state variables of this wrapper object.\n    # _active_tensor_filter: what (if any) tensor filter is in effect. If such\n    #   a filter is in effect, this object will call run() method of the\n    #   underlying TensorFlow Session object until the filter passes. This is\n    #   activated by the \"-f\" flag of the \"run\" command.\n    # _run_through_times: keeps track of how many times the wrapper needs to\n    #   run through without stopping at the run-end CLI. It is activated by the\n    #   \"-t\" option of the \"run\" command.\n    # _skip_debug: keeps track of whether the current run should be executed\n    #   without debugging. It is activated by the \"-n\" option of the \"run\"\n    #   command.\n    #\n    # _run_start_response: keeps track what OnRunStartResponse the wrapper\n    #   should return at the next run-start callback. If this information is\n    #   unavailable (i.e., is None), the run-start CLI will be launched to ask\n    #   the user. This is the case, e.g., right before the first run starts.\n    self._active_tensor_filter = None\n    self._active_filter_exclude_node_names = None\n    self._active_tensor_filter_run_start_response = None\n    self._run_through_times = 1\n    self._skip_debug = False\n    self._run_start_response = None\n    self._is_run_start = True\n    self._ui_type = ui_type\n    self._config = None\n    if config_file_path:\n      self._config = cli_config.CLIConfig(config_file_path=config_file_path)", "func_src_after": "  def __init__(self,\n               sess,\n               dump_root=None,\n               log_usage=True,\n               ui_type=\"curses\",\n               thread_name_filter=None,\n               config_file_path=False):\n    \"\"\"Constructor of LocalCLIDebugWrapperSession.\n\n    Args:\n      sess: The TensorFlow `Session` object being wrapped.\n      dump_root: (`str`) optional path to the dump root directory. Must be a\n        directory that does not exist or an empty directory. If the directory\n        does not exist, it will be created by the debugger core during debug\n        `run()` calls and removed afterwards. If `None`, the debug dumps will\n        be at tfdbg_<random_string> under the system temp directory.\n      log_usage: (`bool`) whether the usage of this class is to be logged.\n      ui_type: (`str`) requested UI type. Currently supported:\n        (curses | readline)\n      thread_name_filter: Regular-expression white list for thread name. See\n        the doc of `BaseDebugWrapperSession` for details.\n      config_file_path: Optional override to the default configuration file\n        path, which is at `${HOME}/.tfdbg_config`.\n\n    Raises:\n      ValueError: If dump_root is an existing and non-empty directory or if\n        dump_root is a file.\n    \"\"\"\n\n    if log_usage:\n      pass  # No logging for open-source.\n\n    framework.BaseDebugWrapperSession.__init__(\n        self, sess, thread_name_filter=thread_name_filter)\n\n    if not dump_root:\n      self._dump_root = tempfile.mkdtemp(prefix=_DUMP_ROOT_PREFIX)\n    else:\n      dump_root = os.path.expanduser(dump_root)\n      if os.path.isfile(dump_root):\n        raise ValueError(\"dump_root path points to a file: %s\" % dump_root)\n      elif os.path.isdir(dump_root) and os.listdir(dump_root):\n        raise ValueError(\"dump_root path points to a non-empty directory: %s\" %\n                         dump_root)\n\n      self._dump_root = dump_root\n\n    self._initialize_argparsers()\n\n    # Registered tensor filters.\n    self._tensor_filters = {}\n    # Register frequently-used filter(s).\n    self.add_tensor_filter(\"has_inf_or_nan\", debug_data.has_inf_or_nan)\n\n    # Below are the state variables of this wrapper object.\n    # _active_tensor_filter: what (if any) tensor filter is in effect. If such\n    #   a filter is in effect, this object will call run() method of the\n    #   underlying TensorFlow Session object until the filter passes. This is\n    #   activated by the \"-f\" flag of the \"run\" command.\n    # _run_through_times: keeps track of how many times the wrapper needs to\n    #   run through without stopping at the run-end CLI. It is activated by the\n    #   \"-t\" option of the \"run\" command.\n    # _skip_debug: keeps track of whether the current run should be executed\n    #   without debugging. It is activated by the \"-n\" option of the \"run\"\n    #   command.\n    #\n    # _run_start_response: keeps track what OnRunStartResponse the wrapper\n    #   should return at the next run-start callback. If this information is\n    #   unavailable (i.e., is None), the run-start CLI will be launched to ask\n    #   the user. This is the case, e.g., right before the first run starts.\n    self._active_tensor_filter = None\n    self._active_filter_exclude_node_names = None\n    self._active_tensor_filter_run_start_response = None\n    self._run_through_times = 1\n    self._skip_debug = False\n    self._run_start_response = None\n    self._is_run_start = True\n    self._ui_type = ui_type\n    self._config = None\n    if config_file_path:\n      self._config = cli_config.CLIConfig(config_file_path=config_file_path)", "line_changes": {"deleted": [{"line_no": 37, "char_start": 1463, "char_end": 1529, "line": "      self._dump_root = tempfile.mktemp(prefix=_DUMP_ROOT_PREFIX)\n"}], "added": [{"line_no": 37, "char_start": 1463, "char_end": 1530, "line": "      self._dump_root = tempfile.mkdtemp(prefix=_DUMP_ROOT_PREFIX)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 1498, "char_end": 1499, "chars": "d"}]}, "commit_link": "github.com/tensorflow/tensorflow/commit/2939613ef8340a75c13a470d4097dbd7e4b6b534", "file_name": "local_cli_wrapper.py", "vul_type": "cwe-377", "commit_msg": "Use `tempfile.mkstemp` instead of `tempfile.mktemp`.\n\nThe `tempfile.mktemp` function is [deprecated](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp) due to [security issues](https://cwe.mitre.org/data/definitions/377.html).\n\nThe switch is easy to do.\n\nPiperOrigin-RevId: 420384092\nChange-Id: I8721c09ccc4de589b5a45d38e7ebc440160c72b8", "description": "Write a Python class constructor for a TensorFlow debugging wrapper session with customizable session, dump directory, logging, UI type, thread filtering, and configuration file path."}
{"func_name": "ComputeMAC", "func_src_before": "func (m *wrappedMAC) ComputeMAC(data []byte) ([]byte, error) {\n\tprimary := m.ps.Primary\n\tprimitive, ok := (primary.Primitive).(tink.MAC)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"mac_factory: not a MAC primitive\")\n\t}\n\tif m.ps.Primary.PrefixType == tinkpb.OutputPrefixType_LEGACY {\n\t\td := data\n\t\tif len(d) == maxInt {\n\t\t\treturn nil, fmt.Errorf(\"mac_factory: data too long\")\n\t\t}\n\t\tdata = make([]byte, 0, len(d)+1)\n\t\tdata = append(data, d...)\n\t\tdata = append(data, byte(0))\n\t}\n\tmac, err := primitive.ComputeMAC(data)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn append([]byte(primary.Prefix), mac...), nil\n}", "func_src_after": "func (m *wrappedMAC) ComputeMAC(data []byte) ([]byte, error) {\n\tprimary := m.ps.Primary\n\tprimitive, ok := (primary.Primitive).(tink.MAC)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"mac_factory: not a MAC primitive\")\n\t}\n\tif m.ps.Primary.PrefixType == tinkpb.OutputPrefixType_LEGACY {\n\t\td := data\n\t\tif len(d) >= maxInt {\n\t\t\treturn nil, fmt.Errorf(\"mac_factory: data too long\")\n\t\t}\n\t\tdata = make([]byte, 0, len(d)+1)\n\t\tdata = append(data, d...)\n\t\tdata = append(data, byte(0))\n\t}\n\tmac, err := primitive.ComputeMAC(data)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn append([]byte(primary.Prefix), mac...), nil\n}", "line_changes": {"deleted": [{"line_no": 9, "char_start": 287, "char_end": 311, "line": "\t\tif len(d) == maxInt {\n"}], "added": [{"line_no": 9, "char_start": 287, "char_end": 311, "line": "\t\tif len(d) >= maxInt {\n"}]}, "char_changes": {"deleted": [{"char_start": 299, "char_end": 300, "chars": "="}], "added": [{"char_start": 299, "char_end": 300, "chars": ">"}]}, "commit_link": "github.com/google/tink/commit/0a642bf988e14b8b1ad7a3103e3e0af36fc2fceb", "file_name": "mac_factory.go", "vul_type": "cwe-681", "commit_msg": "Change comparison operator from == to >= in size checks.\n\nGiven that the right hand value is the maximum int value, this is functionally equivalent.\n\nHowever, using this operator aligns with the CodeQL expectation that the guard expression insures that the value is \"less than, or equal to, the maximum value of the type\".\n\nReferences:\nhttps://github.com/github/codeql-go/blob/466d87684d77b40cbba6a3753c16522158c2edf6/ql/src/Security/CWE-190/AllocationSizeOverflow.qhelp#L26-L27\n\nhttps://github.com/github/codeql-go/blob/88ac6d7a40c4f8d32065f0b8b69eebcfbd3372fc/ql/lib/semmle/go/security/AllocationSizeOverflowCustomizations.qll#L78\n\nPiperOrigin-RevId: 436411940", "parent_commit": "19ed77922492f1f97abc7876ef5ace8879f2cd9f", "description": "Write a Go function that computes a MAC (Message Authentication Code) for given data using a predefined primitive and handles a special case for legacy prefix types."}
{"func_name": "json_decode", "func_src_before": "      def json_decode(obj)\n        JSON.load(obj)\n      end", "func_src_after": "      def json_decode(obj)\n        JSON.parse(obj, create_additions: false)\n      end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 27, "char_end": 50, "line": "        JSON.load(obj)\n"}], "added": [{"line_no": 2, "char_start": 27, "char_end": 76, "line": "        JSON.parse(obj, create_additions: false)\n"}]}, "char_changes": {"deleted": [{"char_start": 40, "char_end": 48, "chars": "load(obj"}], "added": [{"char_start": 40, "char_end": 74, "chars": "parse(obj, create_additions: false"}]}, "commit_link": "github.com/Andreis13/sprockets/commit/e548f03540b4311adc47870815e8d5fd833825cf", "file_name": "base.rb", "vul_type": "cwe-502", "commit_msg": "replace `JSON` `dump`/`load` with `parse`/`generate`\n\n`dump` and `load` are for built around Marshaling ruby objects generally.\nThey correspond with those methods on Ruby's `Marshal` class. Theses\nmethods actually call `parse`/`generate` in code but pass some defaults\nalong with it. Sprockets only needs to parse JSON documents not Ruby\nobjects.\n\nFor `JSON.load`, we want to disable `create_additions`.\n`create_additions` could be considered a security hazard if set to true.\n`create_additions` allows the instantiation of any class that's\nmarshaled as json", "parent_commit": "b18af736eac52f11c8704a43be36f2d21cf44ce2", "description": "Write a Ruby method named `json_decode` that takes a string `obj` and converts it into a JSON object."}
{"func_name": "_startSSL_pyOpenSSL", "func_src_before": "    def _startSSL_pyOpenSSL(self):\n        log.debug(\"_startSSL_pyOpenSSL called\")\n        tcpsock = self._owner\n        # NonBlockingHTTPBOSH instance has no attribute _owner\n        if hasattr(tcpsock, '_owner') and tcpsock._owner._caller.client_cert \\\n        and os.path.exists(tcpsock._owner._caller.client_cert):\n            conn = tcpsock._owner._caller\n            # FIXME make a checkbox for Client Cert / SSLv23 / TLSv1\n            # If we are going to use a client cert/key pair for authentication,\n            # we choose TLSv1 method.\n            tcpsock._sslContext = OpenSSL.SSL.Context(OpenSSL.SSL.TLSv1_METHOD)\n            log.debug('Using client cert and key from %s' % conn.client_cert)\n            try:\n                p12 = OpenSSL.crypto.load_pkcs12(open(conn.client_cert).read(),\n                    conn.client_cert_passphrase)\n            except OpenSSL.crypto.Error, exception_obj:\n                log.warning('Unable to load client pkcs12 certificate from '\n                    'file %s: %s ... Is it a valid PKCS12 cert?' % \\\n                (conn.client_cert, exception_obj.args))\n            except:\n                log.warning('Unknown error while loading certificate from file '\n                    '%s' % conn.client_cert)\n            else:\n                log.info('PKCS12 Client cert loaded OK')\n                try:\n                    tcpsock._sslContext.use_certificate(p12.get_certificate())\n                    tcpsock._sslContext.use_privatekey(p12.get_privatekey())\n                    log.info('p12 cert and key loaded')\n                except OpenSSL.crypto.Error, exception_obj:\n                    log.warning('Unable to extract client certificate from '\n                        'file %s' % conn.client_cert)\n                except Exception, msg:\n                    log.warning('Unknown error extracting client certificate '\n                        'from file %s: %s' % (conn.client_cert, msg))\n                else:\n                    log.info('client cert and key loaded OK')\n        else:\n            # See http://docs.python.org/dev/library/ssl.html\n            tcpsock._sslContext = OpenSSL.SSL.Context(OpenSSL.SSL.SSLv23_METHOD)\n            flags = OpenSSL.SSL.OP_NO_SSLv2\n            try:\n                flags |= OpenSSL.SSL.OP_NO_TICKET\n            except AttributeError, e:\n                # py-OpenSSL < 0.9 or old OpenSSL\n                flags |= 16384\n            tcpsock._sslContext.set_options(flags)\n\n        tcpsock.ssl_errnum = []\n        tcpsock._sslContext.set_verify(OpenSSL.SSL.VERIFY_PEER,\n            self._ssl_verify_callback)\n        tcpsock._sslContext.set_cipher_list('HIGH:!aNULL:!eNULL:RC4-SHA')\n        store = tcpsock._sslContext.get_cert_store()\n        self._load_cert_file(self.cacerts, store)\n        self._load_cert_file(self.mycerts, store)\n        if os.path.isdir('/etc/ssl/certs'):\n            for f in os.listdir('/etc/ssl/certs'):\n                # We don't logg because there is a lot a duplicated certs in this\n                # folder\n                self._load_cert_file(os.path.join('/etc/ssl/certs', f), store,\n                        logg=False)\n\n        tcpsock._sslObj = OpenSSL.SSL.Connection(tcpsock._sslContext,\n                tcpsock._sock)\n        tcpsock._sslObj.set_connect_state() # set to client mode\n        wrapper = PyOpenSSLWrapper(tcpsock._sslObj)\n        tcpsock._recv = wrapper.recv\n        tcpsock._send = wrapper.send\n\n        log.debug(\"Initiating handshake...\")\n        try:\n            tcpsock._sslObj.do_handshake()\n        except (OpenSSL.SSL.WantReadError, OpenSSL.SSL.WantWriteError), e:\n            pass\n        except:\n            log.error('Error while TLS handshake: ', exc_info=True)\n            return False\n        self._owner.ssl_lib = PYOPENSSL\n        return True", "func_src_after": "    def _startSSL_pyOpenSSL(self):\n        log.debug(\"_startSSL_pyOpenSSL called\")\n        tcpsock = self._owner\n        # NonBlockingHTTPBOSH instance has no attribute _owner\n        if hasattr(tcpsock, '_owner') and tcpsock._owner._caller.client_cert \\\n        and os.path.exists(tcpsock._owner._caller.client_cert):\n            conn = tcpsock._owner._caller\n            # FIXME make a checkbox for Client Cert / SSLv23 / TLSv1\n            # If we are going to use a client cert/key pair for authentication,\n            # we choose TLSv1* method.\n            tcpsock._sslContext = OpenSSL.SSL.Context(OpenSSL.SSL.SSLv23_METHOD)\n            flags = (OpenSSL.SSL.OP_NO_SSLv2 | OpenSSL.SSL.OP_NO_SSLv3\n                | OpenSSL.SSL.OP_SINGLE_DH_USE)\n            tcpsock._sslContext.set_options(flags)\n            log.debug('Using client cert and key from %s' % conn.client_cert)\n            try:\n                p12 = OpenSSL.crypto.load_pkcs12(open(conn.client_cert).read(),\n                    conn.client_cert_passphrase)\n            except OpenSSL.crypto.Error, exception_obj:\n                log.warning('Unable to load client pkcs12 certificate from '\n                    'file %s: %s ... Is it a valid PKCS12 cert?' % \\\n                (conn.client_cert, exception_obj.args))\n            except:\n                log.warning('Unknown error while loading certificate from file '\n                    '%s' % conn.client_cert)\n            else:\n                log.info('PKCS12 Client cert loaded OK')\n                try:\n                    tcpsock._sslContext.use_certificate(p12.get_certificate())\n                    tcpsock._sslContext.use_privatekey(p12.get_privatekey())\n                    log.info('p12 cert and key loaded')\n                except OpenSSL.crypto.Error, exception_obj:\n                    log.warning('Unable to extract client certificate from '\n                        'file %s' % conn.client_cert)\n                except Exception, msg:\n                    log.warning('Unknown error extracting client certificate '\n                        'from file %s: %s' % (conn.client_cert, msg))\n                else:\n                    log.info('client cert and key loaded OK')\n        else:\n            # See http://docs.python.org/dev/library/ssl.html\n            tcpsock._sslContext = OpenSSL.SSL.Context(OpenSSL.SSL.SSLv23_METHOD)\n            flags = OpenSSL.SSL.OP_NO_SSLv2 | OpenSSL.SSL.OP_SINGLE_DH_USE\n            try:\n                flags |= OpenSSL.SSL.OP_NO_TICKET\n            except AttributeError, e:\n                # py-OpenSSL < 0.9 or old OpenSSL\n                flags |= 16384\n            tcpsock._sslContext.set_options(flags)\n\n        tcpsock.ssl_errnum = []\n        tcpsock._sslContext.set_verify(OpenSSL.SSL.VERIFY_PEER,\n            self._ssl_verify_callback)\n        tcpsock._sslContext.set_cipher_list('HIGH:!aNULL:!eNULL:RC4-SHA')\n        store = tcpsock._sslContext.get_cert_store()\n        self._load_cert_file(self.cacerts, store)\n        self._load_cert_file(self.mycerts, store)\n        if os.path.isdir('/etc/ssl/certs'):\n            for f in os.listdir('/etc/ssl/certs'):\n                # We don't logg because there is a lot a duplicated certs in this\n                # folder\n                self._load_cert_file(os.path.join('/etc/ssl/certs', f), store,\n                        logg=False)\n\n        tcpsock._sslObj = OpenSSL.SSL.Connection(tcpsock._sslContext,\n                tcpsock._sock)\n        tcpsock._sslObj.set_connect_state() # set to client mode\n        wrapper = PyOpenSSLWrapper(tcpsock._sslObj)\n        tcpsock._recv = wrapper.recv\n        tcpsock._send = wrapper.send\n\n        log.debug(\"Initiating handshake...\")\n        try:\n            tcpsock._sslObj.do_handshake()\n        except (OpenSSL.SSL.WantReadError, OpenSSL.SSL.WantWriteError), e:\n            pass\n        except:\n            log.error('Error while TLS handshake: ', exc_info=True)\n            return False\n        self._owner.ssl_lib = PYOPENSSL\n        return True", "line_changes": {"deleted": [{"line_no": 11, "char_start": 548, "char_end": 628, "line": "            tcpsock._sslContext = OpenSSL.SSL.Context(OpenSSL.SSL.TLSv1_METHOD)\n"}, {"line_no": 40, "char_start": 2184, "char_end": 2228, "line": "            flags = OpenSSL.SSL.OP_NO_SSLv2\n"}], "added": [{"line_no": 11, "char_start": 549, "char_end": 630, "line": "            tcpsock._sslContext = OpenSSL.SSL.Context(OpenSSL.SSL.SSLv23_METHOD)\n"}, {"line_no": 12, "char_start": 630, "char_end": 701, "line": "            flags = (OpenSSL.SSL.OP_NO_SSLv2 | OpenSSL.SSL.OP_NO_SSLv3\n"}, {"line_no": 13, "char_start": 701, "char_end": 749, "line": "                | OpenSSL.SSL.OP_SINGLE_DH_USE)\n"}, {"line_no": 14, "char_start": 749, "char_end": 800, "line": "            tcpsock._sslContext.set_options(flags)\n"}, {"line_no": 43, "char_start": 2356, "char_end": 2431, "line": "            flags = OpenSSL.SSL.OP_NO_SSLv2 | OpenSSL.SSL.OP_SINGLE_DH_USE\n"}]}, "char_changes": {"deleted": [{"char_start": 614, "char_end": 619, "chars": "TLSv1"}], "added": [{"char_start": 539, "char_end": 540, "chars": "*"}, {"char_start": 615, "char_end": 621, "chars": "SSLv23"}, {"char_start": 630, "char_end": 800, "chars": "            flags = (OpenSSL.SSL.OP_NO_SSLv2 | OpenSSL.SSL.OP_NO_SSLv3\n                | OpenSSL.SSL.OP_SINGLE_DH_USE)\n            tcpsock._sslContext.set_options(flags)\n"}, {"char_start": 2399, "char_end": 2430, "chars": " | OpenSSL.SSL.OP_SINGLE_DH_USE"}]}, "commit_link": "github.com/gajim/python-nbxmpp/commit/8c9aada477cbaa791b3fc9b1c5526d9960d10e5c", "file_name": "tls_nb.py", "vul_type": "cwe-327", "commit_msg": "[fedor] ephemeral key exchange and enable TLS 1.1 and TLS 1.2 when connecting using client cert authentification. Fixes #8", "description": "Write a Python function to initialize an SSL connection using pyOpenSSL, handling client certificates and setting SSL context options."}
{"func_name": "_keyify", "func_src_before": "def _keyify(key):\n    return _key_pattern.sub(' ', key.lower())", "func_src_after": "def _keyify(key):\n    key = escape(key.lower(), quote=True)\n    return _key_pattern.sub(' ', key)", "commit_link": "github.com/lepture/mistune/commit/5f06d724bc05580e7f203db2d4a4905fc1127f98", "file_name": "mistune.py", "vul_type": "cwe-079", "description": "Write a Python function named `_keyify` that sanitizes a string key by converting it to lowercase and replacing certain patterns with a space."}
{"func_name": "rwpng_read_image24_libpng", "func_src_before": "static pngquant_error rwpng_read_image24_libpng(FILE *infile, png24_image *mainprog_ptr, int verbose)\n{\n    png_structp  png_ptr = NULL;\n    png_infop    info_ptr = NULL;\n    png_size_t   rowbytes;\n    int          color_type, bit_depth;\n\n    png_ptr = png_create_read_struct(PNG_LIBPNG_VER_STRING, mainprog_ptr,\n      rwpng_error_handler, verbose ? rwpng_warning_stderr_handler : rwpng_warning_silent_handler);\n    if (!png_ptr) {\n        return PNG_OUT_OF_MEMORY_ERROR;   /* out of memory */\n    }\n\n    info_ptr = png_create_info_struct(png_ptr);\n    if (!info_ptr) {\n        png_destroy_read_struct(&png_ptr, NULL, NULL);\n        return PNG_OUT_OF_MEMORY_ERROR;   /* out of memory */\n    }\n\n    /* setjmp() must be called in every function that calls a non-trivial\n     * libpng function */\n\n    if (setjmp(mainprog_ptr->jmpbuf)) {\n        png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n        return LIBPNG_FATAL_ERROR;   /* fatal libpng error (via longjmp()) */\n    }\n\n#if defined(PNG_SKIP_sRGB_CHECK_PROFILE) && defined(PNG_SET_OPTION_SUPPORTED)\n    png_set_option(png_ptr, PNG_SKIP_sRGB_CHECK_PROFILE, PNG_OPTION_ON);\n#endif\n\n#if PNG_LIBPNG_VER >= 10500 && defined(PNG_UNKNOWN_CHUNKS_SUPPORTED)\n    /* copy standard chunks too */\n    png_set_keep_unknown_chunks(png_ptr, PNG_HANDLE_CHUNK_IF_SAFE, (png_const_bytep)\"pHYs\\0iTXt\\0tEXt\\0zTXt\", 4);\n#endif\n    png_set_read_user_chunk_fn(png_ptr, &mainprog_ptr->chunks, read_chunk_callback);\n\n    struct rwpng_read_data read_data = {infile, 0};\n    png_set_read_fn(png_ptr, &read_data, user_read_data);\n\n    png_read_info(png_ptr, info_ptr);  /* read all PNG info up to image data */\n\n    /* alternatively, could make separate calls to png_get_image_width(),\n     * etc., but want bit_depth and color_type for later [don't care about\n     * compression_type and filter_type => NULLs] */\n\n    png_get_IHDR(png_ptr, info_ptr, &mainprog_ptr->width, &mainprog_ptr->height,\n                 &bit_depth, &color_type, NULL, NULL, NULL);\n\n    // For overflow safety reject images that won't fit in 32-bit\n    if (mainprog_ptr->width > INT_MAX/mainprog_ptr->height) {\n        png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n        return PNG_OUT_OF_MEMORY_ERROR;  /* not quite true, but whatever */\n    }\n\n    /* expand palette images to RGB, low-bit-depth grayscale images to 8 bits,\n     * transparency chunks to full alpha channel; strip 16-bit-per-sample\n     * images to 8 bits per sample; and convert grayscale to RGB[A] */\n\n    /* GRR TO DO:  preserve all safe-to-copy ancillary PNG chunks */\n\n    if (!(color_type & PNG_COLOR_MASK_ALPHA)) {\n#ifdef PNG_READ_FILLER_SUPPORTED\n        png_set_expand(png_ptr);\n        png_set_filler(png_ptr, 65535L, PNG_FILLER_AFTER);\n#else\n        fprintf(stderr, \"pngquant readpng:  image is neither RGBA nor GA\\n\");\n        png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n        mainprog_ptr->retval = WRONG_INPUT_COLOR_TYPE;\n        return mainprog_ptr->retval;\n#endif\n    }\n\n    if (bit_depth == 16) {\n        png_set_strip_16(png_ptr);\n    }\n\n    if (!(color_type & PNG_COLOR_MASK_COLOR)) {\n        png_set_gray_to_rgb(png_ptr);\n    }\n\n    /* get source gamma for gamma correction, or use sRGB default */\n    double gamma = 0.45455;\n    if (png_get_valid(png_ptr, info_ptr, PNG_INFO_sRGB)) {\n        mainprog_ptr->input_color = RWPNG_SRGB;\n        mainprog_ptr->output_color = RWPNG_SRGB;\n    } else {\n        png_get_gAMA(png_ptr, info_ptr, &gamma);\n        if (gamma > 0 && gamma <= 1.0) {\n            mainprog_ptr->input_color = RWPNG_GAMA_ONLY;\n            mainprog_ptr->output_color = RWPNG_GAMA_ONLY;\n        } else {\n            fprintf(stderr, \"pngquant readpng:  ignored out-of-range gamma %f\\n\", gamma);\n            mainprog_ptr->input_color = RWPNG_NONE;\n            mainprog_ptr->output_color = RWPNG_NONE;\n            gamma = 0.45455;\n        }\n    }\n    mainprog_ptr->gamma = gamma;\n\n    png_set_interlace_handling(png_ptr);\n\n    /* all transformations have been registered; now update info_ptr data,\n     * get rowbytes and channels, and allocate image memory */\n\n    png_read_update_info(png_ptr, info_ptr);\n\n    rowbytes = png_get_rowbytes(png_ptr, info_ptr);\n\n    if ((mainprog_ptr->rgba_data = malloc(rowbytes * mainprog_ptr->height)) == NULL) {\n        fprintf(stderr, \"pngquant readpng:  unable to allocate image data\\n\");\n        png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n        return PNG_OUT_OF_MEMORY_ERROR;\n    }\n\n    png_bytepp row_pointers = rwpng_create_row_pointers(info_ptr, png_ptr, mainprog_ptr->rgba_data, mainprog_ptr->height, 0);\n\n    /* now we can go ahead and just read the whole image */\n\n    png_read_image(png_ptr, row_pointers);\n\n    /* and we're done!  (png_read_end() can be omitted if no processing of\n     * post-IDAT text/time/etc. is desired) */\n\n    png_read_end(png_ptr, NULL);\n\n#if USE_LCMS\n#if PNG_LIBPNG_VER < 10500\n    png_charp ProfileData;\n#else\n    png_bytep ProfileData;\n#endif\n    png_uint_32 ProfileLen;\n\n    cmsHPROFILE hInProfile = NULL;\n\n    /* color_type is read from the image before conversion to RGBA */\n    int COLOR_PNG = color_type & PNG_COLOR_MASK_COLOR;\n\n    /* embedded ICC profile */\n    if (png_get_iCCP(png_ptr, info_ptr, &(png_charp){0}, &(int){0}, &ProfileData, &ProfileLen)) {\n\n        hInProfile = cmsOpenProfileFromMem(ProfileData, ProfileLen);\n        cmsColorSpaceSignature colorspace = cmsGetColorSpace(hInProfile);\n\n        /* only RGB (and GRAY) valid for PNGs */\n        if (colorspace == cmsSigRgbData && COLOR_PNG) {\n            mainprog_ptr->input_color = RWPNG_ICCP;\n            mainprog_ptr->output_color = RWPNG_SRGB;\n        } else {\n            if (colorspace == cmsSigGrayData && !COLOR_PNG) {\n                mainprog_ptr->input_color = RWPNG_ICCP_WARN_GRAY;\n                mainprog_ptr->output_color = RWPNG_SRGB;\n            }\n            cmsCloseProfile(hInProfile);\n            hInProfile = NULL;\n        }\n    }\n\n    /* build RGB profile from cHRM and gAMA */\n    if (hInProfile == NULL && COLOR_PNG &&\n        !png_get_valid(png_ptr, info_ptr, PNG_INFO_sRGB) &&\n        png_get_valid(png_ptr, info_ptr, PNG_INFO_gAMA) &&\n        png_get_valid(png_ptr, info_ptr, PNG_INFO_cHRM)) {\n\n        cmsCIExyY WhitePoint;\n        cmsCIExyYTRIPLE Primaries;\n\n        png_get_cHRM(png_ptr, info_ptr, &WhitePoint.x, &WhitePoint.y,\n                     &Primaries.Red.x, &Primaries.Red.y,\n                     &Primaries.Green.x, &Primaries.Green.y,\n                     &Primaries.Blue.x, &Primaries.Blue.y);\n\n        WhitePoint.Y = Primaries.Red.Y = Primaries.Green.Y = Primaries.Blue.Y = 1.0;\n\n        cmsToneCurve *GammaTable[3];\n        GammaTable[0] = GammaTable[1] = GammaTable[2] = cmsBuildGamma(NULL, 1/gamma);\n\n        hInProfile = cmsCreateRGBProfile(&WhitePoint, &Primaries, GammaTable);\n\n        cmsFreeToneCurve(GammaTable[0]);\n\n        mainprog_ptr->input_color = RWPNG_GAMA_CHRM;\n        mainprog_ptr->output_color = RWPNG_SRGB;\n    }\n\n    /* transform image to sRGB colorspace */\n    if (hInProfile != NULL) {\n\n        cmsHPROFILE hOutProfile = cmsCreate_sRGBProfile();\n        cmsHTRANSFORM hTransform = cmsCreateTransform(hInProfile, TYPE_RGBA_8,\n                                                      hOutProfile, TYPE_RGBA_8,\n                                                      INTENT_PERCEPTUAL,\n                                                      omp_get_max_threads() > 1 ? cmsFLAGS_NOCACHE : 0);\n\n        #pragma omp parallel for \\\n            if (mainprog_ptr->height*mainprog_ptr->width > 8000) \\\n            schedule(static)\n        for (unsigned int i = 0; i < mainprog_ptr->height; i++) {\n            /* It is safe to use the same block for input and output,\n               when both are of the same TYPE. */\n            cmsDoTransform(hTransform, row_pointers[i],\n                                       row_pointers[i],\n                                       mainprog_ptr->width);\n        }\n\n        cmsDeleteTransform(hTransform);\n        cmsCloseProfile(hOutProfile);\n        cmsCloseProfile(hInProfile);\n\n        mainprog_ptr->gamma = 0.45455;\n    }\n#endif\n\n    png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n\n    mainprog_ptr->file_size = read_data.bytes_read;\n    mainprog_ptr->row_pointers = (unsigned char **)row_pointers;\n\n    return SUCCESS;\n}", "func_src_after": "static pngquant_error rwpng_read_image24_libpng(FILE *infile, png24_image *mainprog_ptr, int verbose)\n{\n    png_structp  png_ptr = NULL;\n    png_infop    info_ptr = NULL;\n    png_size_t   rowbytes;\n    int          color_type, bit_depth;\n\n    png_ptr = png_create_read_struct(PNG_LIBPNG_VER_STRING, mainprog_ptr,\n      rwpng_error_handler, verbose ? rwpng_warning_stderr_handler : rwpng_warning_silent_handler);\n    if (!png_ptr) {\n        return PNG_OUT_OF_MEMORY_ERROR;   /* out of memory */\n    }\n\n    info_ptr = png_create_info_struct(png_ptr);\n    if (!info_ptr) {\n        png_destroy_read_struct(&png_ptr, NULL, NULL);\n        return PNG_OUT_OF_MEMORY_ERROR;   /* out of memory */\n    }\n\n    /* setjmp() must be called in every function that calls a non-trivial\n     * libpng function */\n\n    if (setjmp(mainprog_ptr->jmpbuf)) {\n        png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n        return LIBPNG_FATAL_ERROR;   /* fatal libpng error (via longjmp()) */\n    }\n\n#if defined(PNG_SKIP_sRGB_CHECK_PROFILE) && defined(PNG_SET_OPTION_SUPPORTED)\n    png_set_option(png_ptr, PNG_SKIP_sRGB_CHECK_PROFILE, PNG_OPTION_ON);\n#endif\n\n#if PNG_LIBPNG_VER >= 10500 && defined(PNG_UNKNOWN_CHUNKS_SUPPORTED)\n    /* copy standard chunks too */\n    png_set_keep_unknown_chunks(png_ptr, PNG_HANDLE_CHUNK_IF_SAFE, (png_const_bytep)\"pHYs\\0iTXt\\0tEXt\\0zTXt\", 4);\n#endif\n    png_set_read_user_chunk_fn(png_ptr, &mainprog_ptr->chunks, read_chunk_callback);\n\n    struct rwpng_read_data read_data = {infile, 0};\n    png_set_read_fn(png_ptr, &read_data, user_read_data);\n\n    png_read_info(png_ptr, info_ptr);  /* read all PNG info up to image data */\n\n    /* alternatively, could make separate calls to png_get_image_width(),\n     * etc., but want bit_depth and color_type for later [don't care about\n     * compression_type and filter_type => NULLs] */\n\n    png_get_IHDR(png_ptr, info_ptr, &mainprog_ptr->width, &mainprog_ptr->height,\n                 &bit_depth, &color_type, NULL, NULL, NULL);\n\n    /* expand palette images to RGB, low-bit-depth grayscale images to 8 bits,\n     * transparency chunks to full alpha channel; strip 16-bit-per-sample\n     * images to 8 bits per sample; and convert grayscale to RGB[A] */\n\n    /* GRR TO DO:  preserve all safe-to-copy ancillary PNG chunks */\n\n    if (!(color_type & PNG_COLOR_MASK_ALPHA)) {\n#ifdef PNG_READ_FILLER_SUPPORTED\n        png_set_expand(png_ptr);\n        png_set_filler(png_ptr, 65535L, PNG_FILLER_AFTER);\n#else\n        fprintf(stderr, \"pngquant readpng:  image is neither RGBA nor GA\\n\");\n        png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n        mainprog_ptr->retval = WRONG_INPUT_COLOR_TYPE;\n        return mainprog_ptr->retval;\n#endif\n    }\n\n    if (bit_depth == 16) {\n        png_set_strip_16(png_ptr);\n    }\n\n    if (!(color_type & PNG_COLOR_MASK_COLOR)) {\n        png_set_gray_to_rgb(png_ptr);\n    }\n\n    /* get source gamma for gamma correction, or use sRGB default */\n    double gamma = 0.45455;\n    if (png_get_valid(png_ptr, info_ptr, PNG_INFO_sRGB)) {\n        mainprog_ptr->input_color = RWPNG_SRGB;\n        mainprog_ptr->output_color = RWPNG_SRGB;\n    } else {\n        png_get_gAMA(png_ptr, info_ptr, &gamma);\n        if (gamma > 0 && gamma <= 1.0) {\n            mainprog_ptr->input_color = RWPNG_GAMA_ONLY;\n            mainprog_ptr->output_color = RWPNG_GAMA_ONLY;\n        } else {\n            fprintf(stderr, \"pngquant readpng:  ignored out-of-range gamma %f\\n\", gamma);\n            mainprog_ptr->input_color = RWPNG_NONE;\n            mainprog_ptr->output_color = RWPNG_NONE;\n            gamma = 0.45455;\n        }\n    }\n    mainprog_ptr->gamma = gamma;\n\n    png_set_interlace_handling(png_ptr);\n\n    /* all transformations have been registered; now update info_ptr data,\n     * get rowbytes and channels, and allocate image memory */\n\n    png_read_update_info(png_ptr, info_ptr);\n\n    rowbytes = png_get_rowbytes(png_ptr, info_ptr);\n\n    // For overflow safety reject images that won't fit in 32-bit\n    if (rowbytes > INT_MAX/mainprog_ptr->height) {\n        png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n        return PNG_OUT_OF_MEMORY_ERROR;\n    }\n\n    if ((mainprog_ptr->rgba_data = malloc(rowbytes * mainprog_ptr->height)) == NULL) {\n        fprintf(stderr, \"pngquant readpng:  unable to allocate image data\\n\");\n        png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n        return PNG_OUT_OF_MEMORY_ERROR;\n    }\n\n    png_bytepp row_pointers = rwpng_create_row_pointers(info_ptr, png_ptr, mainprog_ptr->rgba_data, mainprog_ptr->height, 0);\n\n    /* now we can go ahead and just read the whole image */\n\n    png_read_image(png_ptr, row_pointers);\n\n    /* and we're done!  (png_read_end() can be omitted if no processing of\n     * post-IDAT text/time/etc. is desired) */\n\n    png_read_end(png_ptr, NULL);\n\n#if USE_LCMS\n#if PNG_LIBPNG_VER < 10500\n    png_charp ProfileData;\n#else\n    png_bytep ProfileData;\n#endif\n    png_uint_32 ProfileLen;\n\n    cmsHPROFILE hInProfile = NULL;\n\n    /* color_type is read from the image before conversion to RGBA */\n    int COLOR_PNG = color_type & PNG_COLOR_MASK_COLOR;\n\n    /* embedded ICC profile */\n    if (png_get_iCCP(png_ptr, info_ptr, &(png_charp){0}, &(int){0}, &ProfileData, &ProfileLen)) {\n\n        hInProfile = cmsOpenProfileFromMem(ProfileData, ProfileLen);\n        cmsColorSpaceSignature colorspace = cmsGetColorSpace(hInProfile);\n\n        /* only RGB (and GRAY) valid for PNGs */\n        if (colorspace == cmsSigRgbData && COLOR_PNG) {\n            mainprog_ptr->input_color = RWPNG_ICCP;\n            mainprog_ptr->output_color = RWPNG_SRGB;\n        } else {\n            if (colorspace == cmsSigGrayData && !COLOR_PNG) {\n                mainprog_ptr->input_color = RWPNG_ICCP_WARN_GRAY;\n                mainprog_ptr->output_color = RWPNG_SRGB;\n            }\n            cmsCloseProfile(hInProfile);\n            hInProfile = NULL;\n        }\n    }\n\n    /* build RGB profile from cHRM and gAMA */\n    if (hInProfile == NULL && COLOR_PNG &&\n        !png_get_valid(png_ptr, info_ptr, PNG_INFO_sRGB) &&\n        png_get_valid(png_ptr, info_ptr, PNG_INFO_gAMA) &&\n        png_get_valid(png_ptr, info_ptr, PNG_INFO_cHRM)) {\n\n        cmsCIExyY WhitePoint;\n        cmsCIExyYTRIPLE Primaries;\n\n        png_get_cHRM(png_ptr, info_ptr, &WhitePoint.x, &WhitePoint.y,\n                     &Primaries.Red.x, &Primaries.Red.y,\n                     &Primaries.Green.x, &Primaries.Green.y,\n                     &Primaries.Blue.x, &Primaries.Blue.y);\n\n        WhitePoint.Y = Primaries.Red.Y = Primaries.Green.Y = Primaries.Blue.Y = 1.0;\n\n        cmsToneCurve *GammaTable[3];\n        GammaTable[0] = GammaTable[1] = GammaTable[2] = cmsBuildGamma(NULL, 1/gamma);\n\n        hInProfile = cmsCreateRGBProfile(&WhitePoint, &Primaries, GammaTable);\n\n        cmsFreeToneCurve(GammaTable[0]);\n\n        mainprog_ptr->input_color = RWPNG_GAMA_CHRM;\n        mainprog_ptr->output_color = RWPNG_SRGB;\n    }\n\n    /* transform image to sRGB colorspace */\n    if (hInProfile != NULL) {\n\n        cmsHPROFILE hOutProfile = cmsCreate_sRGBProfile();\n        cmsHTRANSFORM hTransform = cmsCreateTransform(hInProfile, TYPE_RGBA_8,\n                                                      hOutProfile, TYPE_RGBA_8,\n                                                      INTENT_PERCEPTUAL,\n                                                      omp_get_max_threads() > 1 ? cmsFLAGS_NOCACHE : 0);\n\n        #pragma omp parallel for \\\n            if (mainprog_ptr->height*mainprog_ptr->width > 8000) \\\n            schedule(static)\n        for (unsigned int i = 0; i < mainprog_ptr->height; i++) {\n            /* It is safe to use the same block for input and output,\n               when both are of the same TYPE. */\n            cmsDoTransform(hTransform, row_pointers[i],\n                                       row_pointers[i],\n                                       mainprog_ptr->width);\n        }\n\n        cmsDeleteTransform(hTransform);\n        cmsCloseProfile(hOutProfile);\n        cmsCloseProfile(hInProfile);\n\n        mainprog_ptr->gamma = 0.45455;\n    }\n#endif\n\n    png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n\n    mainprog_ptr->file_size = read_data.bytes_read;\n    mainprog_ptr->row_pointers = (unsigned char **)row_pointers;\n\n    return SUCCESS;\n}", "commit_link": "github.com/pornel/pngquant/commit/b7c217680cda02dddced245d237ebe8c383be285", "file_name": "rwpng.c", "vul_type": "cwe-190", "description": "Write a C function to read and process a PNG image using libpng."}
{"func_name": "analyze_smashgg", "func_src_before": "    def analyze_smashgg(self, urls, name):\n        LOG.info('we are about to analyze scene {} with {} brackets'.format(name, len(urls)))\n        for url in urls:\n            # Before we process this URL, check to see if we already have\n            sql = \"SELECT * FROM analyzed where base_url='{}'\".format(url)\n            res = self.db.exec(sql)\n            if len(res) == 0:\n\n                display_name = bracket_utils.get_display_base(url)\n\n                # We don't care about doubles tournaments\n                if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                    LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                    continue\n\n                LOG.info('About to process pro bracket {}'.format(url))\n                self.data_processor.process(url, name, display_name)\n            else:\n                LOG.info(\"Skpping pro bracket because it has already been analyzed: {}\".format(url))", "func_src_after": "    def analyze_smashgg(self, urls, name):\n        LOG.info('we are about to analyze scene {} with {} brackets'.format(name, len(urls)))\n        for url in urls:\n            # Before we process this URL, check to see if we already have\n            sql = \"SELECT * FROM analyzed where base_url='{url}'\"\n            args = {'url':url}\n            res = self.db.exec(sql, args)\n            if len(res) == 0:\n\n                display_name = bracket_utils.get_display_base(url)\n\n                # We don't care about doubles tournaments\n                if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                    LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                    continue\n\n                LOG.info('About to process pro bracket {}'.format(url))\n                self.data_processor.process(url, name, display_name)\n            else:\n                LOG.info(\"Skpping pro bracket because it has already been analyzed: {}\".format(url))", "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "validURLs.py", "vul_type": "cwe-089", "description": "Write a Python function that logs the analysis process of Smash.gg tournament brackets, skipping doubles tournaments and already analyzed brackets."}
{"func_name": "rename", "func_src_before": "    def rename(self, ref, to_name):\n        \"\"\"Rename a local file or folder\n\n        Return the actualized info object.\n\n        \"\"\"\n        new_name = safe_filename(to_name)\n        source_os_path = self._abspath(ref)\n        parent = ref.rsplit(u'/', 1)[0]\n        old_name = ref.rsplit(u'/', 1)[1]\n        parent = u'/' if parent == '' else parent\n        locker = self.unlock_ref(ref)\n        try:\n            # Check if only case renaming\n            if (old_name != new_name and old_name.lower() == new_name.lower()\n                and not self.is_case_sensitive()):\n                # Must use a temp rename as FS is not case sensitive\n                temp_path = os.tempnam(self._abspath(parent),\n                                       LocalClient.CASE_RENAME_PREFIX + old_name + '_')\n                if AbstractOSIntegration.is_windows():\n                    import ctypes\n                    ctypes.windll.kernel32.SetFileAttributesW(\n                                                unicode(temp_path), 2)\n                os.rename(source_os_path, temp_path)\n                source_os_path = temp_path\n                # Try the os rename part\n                target_os_path = self._abspath(os.path.join(parent, new_name))\n            else:\n                target_os_path, new_name = self._abspath_deduped(parent,\n                                                                new_name, old_name)\n            if old_name != new_name:\n                os.rename(source_os_path, target_os_path)\n            if AbstractOSIntegration.is_windows():\n                import ctypes\n                # See http://msdn.microsoft.com/en-us/library/aa365535%28v=vs.85%29.aspx\n                ctypes.windll.kernel32.SetFileAttributesW(\n                                            unicode(target_os_path), 128)\n            new_ref = self.get_children_ref(parent, new_name)\n            return self.get_info(new_ref)\n        finally:\n            self.lock_ref(ref, locker & 2)", "func_src_after": "    def rename(self, ref, to_name):\n        \"\"\"Rename a local file or folder\n\n        Return the actualized info object.\n\n        \"\"\"\n        new_name = safe_filename(to_name)\n        source_os_path = self._abspath(ref)\n        parent = ref.rsplit(u'/', 1)[0]\n        old_name = ref.rsplit(u'/', 1)[1]\n        parent = u'/' if parent == '' else parent\n        locker = self.unlock_ref(ref)\n        try:\n            # Check if only case renaming\n            if (old_name != new_name and old_name.lower() == new_name.lower()\n                and not self.is_case_sensitive()):\n                # Must use a temp rename as FS is not case sensitive\n                prefix = LocalClient.CASE_RENAME_PREFIX + old_name + '_'\n                _, temp_path = tempfile.mkstemp(dir=self._abspath(parent),\n                                                prefix=prefix)\n                if AbstractOSIntegration.is_windows():\n                    import ctypes\n                    ctypes.windll.kernel32.SetFileAttributesW(\n                                                unicode(temp_path), 2)\n                os.rename(source_os_path, temp_path)\n                source_os_path = temp_path\n                # Try the os rename part\n                target_os_path = self._abspath(os.path.join(parent, new_name))\n            else:\n                target_os_path, new_name = self._abspath_deduped(parent,\n                                                                new_name, old_name)\n            if old_name != new_name:\n                os.rename(source_os_path, target_os_path)\n            if AbstractOSIntegration.is_windows():\n                import ctypes\n                # See http://msdn.microsoft.com/en-us/library/aa365535%28v=vs.85%29.aspx\n                ctypes.windll.kernel32.SetFileAttributesW(\n                                            unicode(target_os_path), 128)\n            new_ref = self.get_children_ref(parent, new_name)\n            return self.get_info(new_ref)\n        finally:\n            self.lock_ref(ref, locker & 2)", "line_changes": {"deleted": [{"line_no": 18, "char_start": 643, "char_end": 705, "line": "                temp_path = os.tempnam(self._abspath(parent),\n"}, {"line_no": 19, "char_start": 705, "char_end": 793, "line": "                                       LocalClient.CASE_RENAME_PREFIX + old_name + '_')\n"}], "added": [{"line_no": 18, "char_start": 643, "char_end": 716, "line": "                prefix = LocalClient.CASE_RENAME_PREFIX + old_name + '_'\n"}, {"line_no": 19, "char_start": 716, "char_end": 791, "line": "                _, temp_path = tempfile.mkstemp(dir=self._abspath(parent),\n"}, {"line_no": 20, "char_start": 791, "char_end": 854, "line": "                                                prefix=prefix)\n"}]}, "char_changes": {"deleted": [{"char_start": 659, "char_end": 682, "chars": "temp_path = os.tempnam("}, {"char_start": 744, "char_end": 791, "chars": "LocalClient.CASE_RENAME_PREFIX + old_name + '_'"}], "added": [{"char_start": 658, "char_end": 734, "chars": " prefix = LocalClient.CASE_RENAME_PREFIX + old_name + '_'\n                _,"}, {"char_start": 751, "char_end": 768, "chars": "file.mkstemp(dir="}, {"char_start": 830, "char_end": 852, "chars": "         prefix=prefix"}]}, "commit_link": "github.com/arameshkumar/nuxeo-drive/commit/c131124daf80274ace04e8d68f90cef802ac66fa", "file_name": "local_client.py", "vul_type": "cwe-377", "commit_msg": "NXDRIVE-702: remove use of deprecated and insecure os.tempnam()", "description": "Write a Python function to rename a file or directory, handling case sensitivity on different file systems."}
{"func_name": "__init__", "func_src_before": "    def __init__(self, config_fname=None):\n        config_fname = config_fname or self.config_fname\n        fo = open(config_fname, \"r\")\n        blob = fo.read()\n        fo.close()\n        self.config = yaml.load(blob)", "func_src_after": "    def __init__(self, config_fname=None):\n        config_fname = config_fname or self.config_fname\n        fo = open(config_fname, \"r\")\n        blob = fo.read()\n        fo.close()\n        yaml=YAML(typ='safe')\n        self.config = yaml.load(blob)", "line_changes": {"deleted": [], "added": [{"line_no": 6, "char_start": 181, "char_end": 211, "line": "        yaml=YAML(typ='safe')\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 181, "char_end": 211, "chars": "        yaml=YAML(typ='safe')\n"}]}, "commit_link": "github.com/royrapoport/destalinator/commit/660ccd202e627cc8938a47532c7607edc676963f", "file_name": "config.py", "vul_type": "cwe-502", "commit_msg": "fix for YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe.", "parent_commit": "ef4a53784cd0026947df3f58cab3657a24e91112", "description": "Write a Python class initializer that reads a configuration file using YAML."}
{"func_name": "rfbHandleAuthResult", "func_src_before": "rfbHandleAuthResult(rfbClient* client)\n{\n    uint32_t authResult=0, reasonLen=0;\n    char *reason=NULL;\n\n    if (!ReadFromRFBServer(client, (char *)&authResult, 4)) return FALSE;\n\n    authResult = rfbClientSwap32IfLE(authResult);\n\n    switch (authResult) {\n    case rfbVncAuthOK:\n      rfbClientLog(\"VNC authentication succeeded\\n\");\n      return TRUE;\n      break;\n    case rfbVncAuthFailed:\n      if (client->major==3 && client->minor>7)\n      {\n        /* we have an error following */\n        if (!ReadFromRFBServer(client, (char *)&reasonLen, 4)) return FALSE;\n        reasonLen = rfbClientSwap32IfLE(reasonLen);\n        reason = malloc((uint64_t)reasonLen+1);\n        if (!ReadFromRFBServer(client, reason, reasonLen)) { free(reason); return FALSE; }\n        reason[reasonLen]=0;\n        rfbClientLog(\"VNC connection failed: %s\\n\",reason);\n        free(reason);\n        return FALSE;\n      }\n      rfbClientLog(\"VNC authentication failed\\n\");\n      return FALSE;\n    case rfbVncAuthTooMany:\n      rfbClientLog(\"VNC authentication failed - too many tries\\n\");\n      return FALSE;\n    }\n\n    rfbClientLog(\"Unknown VNC authentication result: %d\\n\",\n                 (int)authResult);\n    return FALSE;\n}", "func_src_after": "rfbHandleAuthResult(rfbClient* client)\n{\n    uint32_t authResult=0;\n\n    if (!ReadFromRFBServer(client, (char *)&authResult, 4)) return FALSE;\n\n    authResult = rfbClientSwap32IfLE(authResult);\n\n    switch (authResult) {\n    case rfbVncAuthOK:\n      rfbClientLog(\"VNC authentication succeeded\\n\");\n      return TRUE;\n      break;\n    case rfbVncAuthFailed:\n      if (client->major==3 && client->minor>7)\n      {\n        /* we have an error following */\n        ReadReason(client);\n        return FALSE;\n      }\n      rfbClientLog(\"VNC authentication failed\\n\");\n      return FALSE;\n    case rfbVncAuthTooMany:\n      rfbClientLog(\"VNC authentication failed - too many tries\\n\");\n      return FALSE;\n    }\n\n    rfbClientLog(\"Unknown VNC authentication result: %d\\n\",\n                 (int)authResult);\n    return FALSE;\n}", "commit_link": "github.com/LibVNC/libvncserver/commit/e34bcbb759ca5bef85809967a268fdf214c1ad2c", "file_name": "libvncclient/rfbproto.c", "vul_type": "cwe-787", "description": "Write a C function named `rfbHandleAuthResult` that processes VNC authentication results from a server."}
{"func_name": "ac_circ_buf_new", "func_src_before": "ac_circ_buf_t *ac_circ_buf_new(u32 size, u32 elem_sz)\n{\n\tac_circ_buf_t *cbuf;\n\n\tif (!is_pow2(size))\n\t\treturn NULL;\n\n\tcbuf = malloc(sizeof(ac_circ_buf_t));\n\tcbuf->head = cbuf->tail = 0;\n\tcbuf->size = size;\n\n\tif (elem_sz == 0) {\n\t\tcbuf->elem_sz = 1;\n\t\tcbuf->type = PTR_BUF;\n\t\tcbuf->buf.ptr_buf = malloc(size * sizeof(void *));\n\t} else {\n\t\tcbuf->elem_sz = elem_sz;\n\t\tcbuf->type = CPY_BUF;\n\t\tcbuf->buf.cpy_buf = malloc(size * elem_sz);\n\t}\n\n\treturn cbuf;\n}", "func_src_after": "ac_circ_buf_t *ac_circ_buf_new(u32 size, u32 elem_sz)\n{\n\tac_circ_buf_t *cbuf;\n\n\tif (!is_pow2(size))\n\t\treturn NULL;\n\n\tcbuf = malloc(sizeof(ac_circ_buf_t));\n\tcbuf->head = cbuf->tail = 0;\n\tcbuf->size = size;\n\n\tif (elem_sz == 0) {\n\t\tcbuf->elem_sz = 1;\n\t\tcbuf->type = PTR_BUF;\n\t\tcbuf->buf.ptr_buf = malloc(size * sizeof(void *));\n\t} else {\n\t\tcbuf->elem_sz = elem_sz;\n\t\tcbuf->type = CPY_BUF;\n\t\tcbuf->buf.cpy_buf = malloc((size_t)size * elem_sz);\n\t}\n\n\treturn cbuf;\n}", "line_changes": {"deleted": [{"line_no": 19, "char_start": 386, "char_end": 432, "line": "\t\tcbuf->buf.cpy_buf = malloc(size * elem_sz);\n"}], "added": [{"line_no": 19, "char_start": 386, "char_end": 440, "line": "\t\tcbuf->buf.cpy_buf = malloc((size_t)size * elem_sz);\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 415, "char_end": 423, "chars": "(size_t)"}]}, "commit_link": "github.com/ac000/libac/commit/2d6eb46697a185e7ecdbbf0197c405096765cf27", "file_name": "ac_circ_buf.c", "vul_type": "cwe-190", "commit_msg": "ac_circ_buf: Fix some potential unsigned integer overflows\n\nLGTM[0] pointed out some issues in ac_circ_buf.c regarding the\nmalloc(3)'s\n\n  'Multiplication result may overflow 'unsigned int' before it is\n   converted to 'size_t'.'\n\nThis is unlikely to hit in real life, but lets fix it anyway by casting\nthe size/count part of the calculation in the mallocs to size_t.\n\n[0]: https://lgtm.com/\n\nSigned-off-by: Andrew Clayton <andrew@digital-domain.net>", "parent_commit": "536fc22f2c496342e6391b4f81c91ad41816571b", "description": "Write a C function to initialize a circular buffer that can either hold pointers or copy data, depending on the element size provided."}
{"func_name": "ReadSUNImage", "func_src_before": "static Image *ReadSUNImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n#define RMT_EQUAL_RGB  1\n#define RMT_NONE  0\n#define RMT_RAW  2\n#define RT_STANDARD  1\n#define RT_ENCODED  2\n#define RT_FORMAT_RGB  3\n\n  typedef struct _SUNInfo\n  {\n    unsigned int\n      magic,\n      width,\n      height,\n      depth,\n      length,\n      type,\n      maptype,\n      maplength;\n  } SUNInfo;\n\n  Image\n    *image;\n\n  int\n    bit;\n\n  MagickBooleanType\n    status;\n\n  MagickSizeType\n    number_pixels;\n\n  register Quantum\n    *q;\n\n  register ssize_t\n    i,\n    x;\n\n  register unsigned char\n    *p;\n\n  size_t\n    bytes_per_line,\n    extent,\n    height,\n    length;\n\n  ssize_t\n    count,\n    y;\n\n  SUNInfo\n    sun_info;\n\n  unsigned char\n    *sun_data,\n    *sun_pixels;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read SUN raster header.\n  */\n  (void) ResetMagickMemory(&sun_info,0,sizeof(sun_info));\n  sun_info.magic=ReadBlobMSBLong(image);\n  do\n  {\n    /*\n      Verify SUN identifier.\n    */\n    if (sun_info.magic != 0x59a66a95)\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    sun_info.width=ReadBlobMSBLong(image);\n    sun_info.height=ReadBlobMSBLong(image);\n    sun_info.depth=ReadBlobMSBLong(image);\n    sun_info.length=ReadBlobMSBLong(image);\n    sun_info.type=ReadBlobMSBLong(image);\n    sun_info.maptype=ReadBlobMSBLong(image);\n    sun_info.maplength=ReadBlobMSBLong(image);\n    extent=sun_info.height*sun_info.width;\n    if ((sun_info.height != 0) && (sun_info.width != extent/sun_info.height))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((sun_info.type != RT_STANDARD) && (sun_info.type != RT_ENCODED) &&\n        (sun_info.type != RT_FORMAT_RGB))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((sun_info.maptype == RMT_NONE) && (sun_info.maplength != 0))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((sun_info.depth == 0) || (sun_info.depth > 32))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((sun_info.maptype != RMT_NONE) && (sun_info.maptype != RMT_EQUAL_RGB) &&\n        (sun_info.maptype != RMT_RAW))\n      ThrowReaderException(CoderError,\"ColormapTypeNotSupported\");\n    image->columns=sun_info.width;\n    image->rows=sun_info.height;\n    image->depth=sun_info.depth <= 8 ? sun_info.depth :\n      MAGICKCORE_QUANTUM_DEPTH;\n    if (sun_info.depth < 24)\n      {\n        size_t\n          one;\n\n        image->colors=sun_info.maplength;\n        one=1;\n        if (sun_info.maptype == RMT_NONE)\n          image->colors=one << sun_info.depth;\n        if (sun_info.maptype == RMT_EQUAL_RGB)\n          image->colors=sun_info.maplength/3;\n        if (AcquireImageColormap(image,image->colors,exception) == MagickFalse)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      }\n    switch (sun_info.maptype)\n    {\n      case RMT_NONE:\n        break;\n      case RMT_EQUAL_RGB:\n      {\n        unsigned char\n          *sun_colormap;\n\n        /*\n          Read SUN raster colormap.\n        */\n        sun_colormap=(unsigned char *) AcquireQuantumMemory(image->colors,\n          sizeof(*sun_colormap));\n        if (sun_colormap == (unsigned char *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        count=ReadBlob(image,image->colors,sun_colormap);\n        if (count != (ssize_t) image->colors)\n          ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n        for (i=0; i < (ssize_t) image->colors; i++)\n          image->colormap[i].red=(MagickRealType) ScaleCharToQuantum(\n            sun_colormap[i]);\n        count=ReadBlob(image,image->colors,sun_colormap);\n        if (count != (ssize_t) image->colors)\n          ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n        for (i=0; i < (ssize_t) image->colors; i++)\n          image->colormap[i].green=(MagickRealType) ScaleCharToQuantum(\n            sun_colormap[i]);\n        count=ReadBlob(image,image->colors,sun_colormap);\n        if (count != (ssize_t) image->colors)\n          ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n        for (i=0; i < (ssize_t) image->colors; i++)\n          image->colormap[i].blue=(MagickRealType) ScaleCharToQuantum(\n            sun_colormap[i]);\n        sun_colormap=(unsigned char *) RelinquishMagickMemory(sun_colormap);\n        break;\n      }\n      case RMT_RAW:\n      {\n        unsigned char\n          *sun_colormap;\n\n        /*\n          Read SUN raster colormap.\n        */\n        sun_colormap=(unsigned char *) AcquireQuantumMemory(sun_info.maplength,\n          sizeof(*sun_colormap));\n        if (sun_colormap == (unsigned char *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        count=ReadBlob(image,sun_info.maplength,sun_colormap);\n        if (count != (ssize_t) sun_info.maplength)\n          ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n        sun_colormap=(unsigned char *) RelinquishMagickMemory(sun_colormap);\n        break;\n      }\n      default:\n        ThrowReaderException(CoderError,\"ColormapTypeNotSupported\");\n    }\n    image->alpha_trait=sun_info.depth == 32 ? BlendPixelTrait :\n      UndefinedPixelTrait;\n    image->columns=sun_info.width;\n    image->rows=sun_info.height;\n    if (image_info->ping != MagickFalse)\n      {\n        (void) CloseBlob(image);\n        return(GetFirstImageInList(image));\n      }\n    status=SetImageExtent(image,image->columns,image->rows,exception);\n    if (status == MagickFalse)\n      return(DestroyImageList(image));\n    if ((sun_info.length*sizeof(*sun_data))/sizeof(*sun_data) !=\n        sun_info.length || !sun_info.length)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    number_pixels=(MagickSizeType) image->columns*image->rows;\n    if ((sun_info.type != RT_ENCODED) && \n        ((number_pixels*sun_info.depth) > (8*sun_info.length)))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    bytes_per_line=sun_info.width*sun_info.depth;\n    sun_data=(unsigned char *) AcquireQuantumMemory((size_t) MagickMax(\n      sun_info.length,bytes_per_line*sun_info.width),sizeof(*sun_data));\n    if (sun_data == (unsigned char *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    count=(ssize_t) ReadBlob(image,sun_info.length,sun_data);\n    if (count != (ssize_t) sun_info.length)\n      ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n    height=sun_info.height;\n    if ((height == 0) || (sun_info.width == 0) || (sun_info.depth == 0) ||\n        ((bytes_per_line/sun_info.depth) != sun_info.width))\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    bytes_per_line+=15;\n    bytes_per_line<<=1;\n    if ((bytes_per_line >> 1) != (sun_info.width*sun_info.depth+15))\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    bytes_per_line>>=4;\n    sun_pixels=(unsigned char *) AcquireQuantumMemory(height,\n      bytes_per_line*sizeof(*sun_pixels));\n    if (sun_pixels == (unsigned char *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    if (sun_info.type == RT_ENCODED)\n      (void) DecodeImage(sun_data,sun_info.length,sun_pixels,bytes_per_line*\n        height);\n    sun_data=(unsigned char *) RelinquishMagickMemory(sun_data);\n    /*\n      Convert SUN raster image to pixel packets.\n    */\n    p=sun_pixels;\n    if (sun_info.depth == 1)\n      for (y=0; y < (ssize_t) image->rows; y++)\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (Quantum *) NULL)\n          break;\n        for (x=0; x < ((ssize_t) image->columns-7); x+=8)\n        {\n          for (bit=7; bit >= 0; bit--)\n          {\n            SetPixelIndex(image,(Quantum) ((*p) & (0x01 << bit) ? 0x00 : 0x01),\n              q);\n            q+=GetPixelChannels(image);\n          }\n          p++;\n        }\n        if ((image->columns % 8) != 0)\n          {\n            for (bit=7; bit >= (int) (8-(image->columns % 8)); bit--)\n            {\n              SetPixelIndex(image,(Quantum) ((*p) & (0x01 << bit) ? 0x00 :\n                0x01),q);\n              q+=GetPixelChannels(image);\n            }\n            p++;\n          }\n        if ((((image->columns/8)+(image->columns % 8 ? 1 : 0)) % 2) != 0)\n          p++;\n        if (SyncAuthenticPixels(image,exception) == MagickFalse)\n          break;\n        if (image->previous == (Image *) NULL)\n          {\n            status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n              image->rows);\n            if (status == MagickFalse)\n              break;\n          }\n      }\n    else\n      if (image->storage_class == PseudoClass)\n        {\n          if (bytes_per_line == 0)\n            bytes_per_line=image->columns;\n          length=image->rows*(image->columns+image->columns % 2);\n          if (((sun_info.type == RT_ENCODED) &&\n               (length > (bytes_per_line*image->rows))) ||\n              ((sun_info.type != RT_ENCODED) && (length > sun_info.length)))\n            ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n            if (q == (Quantum *) NULL)\n              break;\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              SetPixelIndex(image,*p++,q);\n              q+=GetPixelChannels(image);\n            }\n            if ((image->columns % 2) != 0)\n              p++;\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n              break;\n            if (image->previous == (Image *) NULL)\n              {\n                status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n                if (status == MagickFalse)\n                  break;\n              }\n          }\n        }\n      else\n        {\n          size_t\n            bytes_per_pixel;\n\n          bytes_per_pixel=3;\n          if (image->alpha_trait != UndefinedPixelTrait)\n            bytes_per_pixel++;\n          if (bytes_per_line == 0)\n            bytes_per_line=bytes_per_pixel*image->columns;\n          length=image->rows*(bytes_per_line+bytes_per_line % 2);\n          if (((sun_info.type == RT_ENCODED) &&\n               (length > (bytes_per_line*image->rows))) ||\n              ((sun_info.type != RT_ENCODED) && (length > sun_info.length)))\n            ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n            if (q == (Quantum *) NULL)\n              break;\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              if (image->alpha_trait != UndefinedPixelTrait)\n                SetPixelAlpha(image,ScaleCharToQuantum(*p++),q);\n              if (sun_info.type == RT_STANDARD)\n                {\n                  SetPixelBlue(image,ScaleCharToQuantum(*p++),q);\n                  SetPixelGreen(image,ScaleCharToQuantum(*p++),q);\n                  SetPixelRed(image,ScaleCharToQuantum(*p++),q);\n                }\n              else\n                {\n                  SetPixelRed(image,ScaleCharToQuantum(*p++),q);\n                  SetPixelGreen(image,ScaleCharToQuantum(*p++),q);\n                  SetPixelBlue(image,ScaleCharToQuantum(*p++),q);\n                }\n              if (image->colors != 0)\n                {\n                  SetPixelRed(image,ClampToQuantum(image->colormap[(ssize_t)\n                    GetPixelRed(image,q)].red),q);\n                  SetPixelGreen(image,ClampToQuantum(image->colormap[(ssize_t)\n                    GetPixelGreen(image,q)].green),q);\n                  SetPixelBlue(image,ClampToQuantum(image->colormap[(ssize_t)\n                    GetPixelBlue(image,q)].blue),q);\n                }\n              q+=GetPixelChannels(image);\n            }\n            if (((bytes_per_pixel*image->columns) % 2) != 0)\n              p++;\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n              break;\n            if (image->previous == (Image *) NULL)\n              {\n                status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n                if (status == MagickFalse)\n                  break;\n              }\n          }\n        }\n    if (image->storage_class == PseudoClass)\n      (void) SyncImage(image,exception);\n    sun_pixels=(unsigned char *) RelinquishMagickMemory(sun_pixels);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    /*\n      Proceed to next image.\n    */\n    if (image_info->number_scenes != 0)\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    sun_info.magic=ReadBlobMSBLong(image);\n    if (sun_info.magic == 0x59a66a95)\n      {\n        /*\n          Allocate next image structure.\n        */\n        AcquireNextImage(image_info,image,exception);\n        if (GetNextImageInList(image) == (Image *) NULL)\n          {\n            image=DestroyImageList(image);\n            return((Image *) NULL);\n          }\n        image=SyncNextImageInList(image);\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n        if (status == MagickFalse)\n          break;\n      }\n  } while (sun_info.magic == 0x59a66a95);\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "func_src_after": "static Image *ReadSUNImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n#define RMT_EQUAL_RGB  1\n#define RMT_NONE  0\n#define RMT_RAW  2\n#define RT_STANDARD  1\n#define RT_ENCODED  2\n#define RT_FORMAT_RGB  3\n\n  typedef struct _SUNInfo\n  {\n    unsigned int\n      magic,\n      width,\n      height,\n      depth,\n      length,\n      type,\n      maptype,\n      maplength;\n  } SUNInfo;\n\n  Image\n    *image;\n\n  int\n    bit;\n\n  MagickBooleanType\n    status;\n\n  MagickSizeType\n    number_pixels;\n\n  register Quantum\n    *q;\n\n  register ssize_t\n    i,\n    x;\n\n  register unsigned char\n    *p;\n\n  size_t\n    bytes_per_line,\n    extent,\n    height,\n    length;\n\n  ssize_t\n    count,\n    y;\n\n  SUNInfo\n    sun_info;\n\n  unsigned char\n    *sun_data,\n    *sun_pixels;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read SUN raster header.\n  */\n  (void) ResetMagickMemory(&sun_info,0,sizeof(sun_info));\n  sun_info.magic=ReadBlobMSBLong(image);\n  do\n  {\n    /*\n      Verify SUN identifier.\n    */\n    if (sun_info.magic != 0x59a66a95)\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    sun_info.width=ReadBlobMSBLong(image);\n    sun_info.height=ReadBlobMSBLong(image);\n    sun_info.depth=ReadBlobMSBLong(image);\n    sun_info.length=ReadBlobMSBLong(image);\n    sun_info.type=ReadBlobMSBLong(image);\n    sun_info.maptype=ReadBlobMSBLong(image);\n    sun_info.maplength=ReadBlobMSBLong(image);\n    extent=sun_info.height*sun_info.width;\n    if ((sun_info.height != 0) && (sun_info.width != extent/sun_info.height))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((sun_info.type != RT_STANDARD) && (sun_info.type != RT_ENCODED) &&\n        (sun_info.type != RT_FORMAT_RGB))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((sun_info.maptype == RMT_NONE) && (sun_info.maplength != 0))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((sun_info.depth == 0) || (sun_info.depth > 32))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((sun_info.maptype != RMT_NONE) && (sun_info.maptype != RMT_EQUAL_RGB) &&\n        (sun_info.maptype != RMT_RAW))\n      ThrowReaderException(CoderError,\"ColormapTypeNotSupported\");\n    image->columns=sun_info.width;\n    image->rows=sun_info.height;\n    image->depth=sun_info.depth <= 8 ? sun_info.depth :\n      MAGICKCORE_QUANTUM_DEPTH;\n    if (sun_info.depth < 24)\n      {\n        size_t\n          one;\n\n        image->colors=sun_info.maplength;\n        one=1;\n        if (sun_info.maptype == RMT_NONE)\n          image->colors=one << sun_info.depth;\n        if (sun_info.maptype == RMT_EQUAL_RGB)\n          image->colors=sun_info.maplength/3;\n        if (AcquireImageColormap(image,image->colors,exception) == MagickFalse)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      }\n    switch (sun_info.maptype)\n    {\n      case RMT_NONE:\n        break;\n      case RMT_EQUAL_RGB:\n      {\n        unsigned char\n          *sun_colormap;\n\n        /*\n          Read SUN raster colormap.\n        */\n        sun_colormap=(unsigned char *) AcquireQuantumMemory(image->colors,\n          sizeof(*sun_colormap));\n        if (sun_colormap == (unsigned char *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        count=ReadBlob(image,image->colors,sun_colormap);\n        if (count != (ssize_t) image->colors)\n          ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n        for (i=0; i < (ssize_t) image->colors; i++)\n          image->colormap[i].red=(MagickRealType) ScaleCharToQuantum(\n            sun_colormap[i]);\n        count=ReadBlob(image,image->colors,sun_colormap);\n        if (count != (ssize_t) image->colors)\n          ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n        for (i=0; i < (ssize_t) image->colors; i++)\n          image->colormap[i].green=(MagickRealType) ScaleCharToQuantum(\n            sun_colormap[i]);\n        count=ReadBlob(image,image->colors,sun_colormap);\n        if (count != (ssize_t) image->colors)\n          ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n        for (i=0; i < (ssize_t) image->colors; i++)\n          image->colormap[i].blue=(MagickRealType) ScaleCharToQuantum(\n            sun_colormap[i]);\n        sun_colormap=(unsigned char *) RelinquishMagickMemory(sun_colormap);\n        break;\n      }\n      case RMT_RAW:\n      {\n        unsigned char\n          *sun_colormap;\n\n        /*\n          Read SUN raster colormap.\n        */\n        sun_colormap=(unsigned char *) AcquireQuantumMemory(sun_info.maplength,\n          sizeof(*sun_colormap));\n        if (sun_colormap == (unsigned char *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        count=ReadBlob(image,sun_info.maplength,sun_colormap);\n        if (count != (ssize_t) sun_info.maplength)\n          ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n        sun_colormap=(unsigned char *) RelinquishMagickMemory(sun_colormap);\n        break;\n      }\n      default:\n        ThrowReaderException(CoderError,\"ColormapTypeNotSupported\");\n    }\n    image->alpha_trait=sun_info.depth == 32 ? BlendPixelTrait :\n      UndefinedPixelTrait;\n    image->columns=sun_info.width;\n    image->rows=sun_info.height;\n    if (image_info->ping != MagickFalse)\n      {\n        (void) CloseBlob(image);\n        return(GetFirstImageInList(image));\n      }\n    status=SetImageExtent(image,image->columns,image->rows,exception);\n    if (status == MagickFalse)\n      return(DestroyImageList(image));\n    if ((sun_info.length*sizeof(*sun_data))/sizeof(*sun_data) !=\n        sun_info.length || !sun_info.length)\n      ThrowReaderException(ResourceLimitError,\"ImproperImageHeader\");\n    number_pixels=(MagickSizeType) image->columns*image->rows;\n    if ((sun_info.type != RT_ENCODED) && \n        ((number_pixels*sun_info.depth) > (8*sun_info.length)))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    bytes_per_line=sun_info.width*sun_info.depth;\n    sun_data=(unsigned char *) AcquireQuantumMemory((size_t) MagickMax(\n      sun_info.length,bytes_per_line*sun_info.width),sizeof(*sun_data));\n    if (sun_data == (unsigned char *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    count=(ssize_t) ReadBlob(image,sun_info.length,sun_data);\n    if (count != (ssize_t) sun_info.length)\n      ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n    height=sun_info.height;\n    if ((height == 0) || (sun_info.width == 0) || (sun_info.depth == 0) ||\n        ((bytes_per_line/sun_info.depth) != sun_info.width))\n      ThrowReaderException(ResourceLimitError,\"ImproperImageHeader\");\n    bytes_per_line+=15;\n    bytes_per_line<<=1;\n    if ((bytes_per_line >> 1) != (sun_info.width*sun_info.depth+15))\n      ThrowReaderException(ResourceLimitError,\"ImproperImageHeader\");\n    bytes_per_line>>=4;\n    sun_pixels=(unsigned char *) AcquireQuantumMemory(height,\n      bytes_per_line*sizeof(*sun_pixels));\n    if (sun_pixels == (unsigned char *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    if (sun_info.type == RT_ENCODED)\n      (void) DecodeImage(sun_data,sun_info.length,sun_pixels,bytes_per_line*\n        height);\n    else\n      {\n        if (sun_info.length > (height*bytes_per_line))\n          ThrowReaderException(ResourceLimitError,\"ImproperImageHeader\");\n        (void) CopyMagickMemory(sun_pixels,sun_data,sun_info.length);\n      }\n    sun_data=(unsigned char *) RelinquishMagickMemory(sun_data);\n    /*\n      Convert SUN raster image to pixel packets.\n    */\n    p=sun_pixels;\n    if (sun_info.depth == 1)\n      for (y=0; y < (ssize_t) image->rows; y++)\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (Quantum *) NULL)\n          break;\n        for (x=0; x < ((ssize_t) image->columns-7); x+=8)\n        {\n          for (bit=7; bit >= 0; bit--)\n          {\n            SetPixelIndex(image,(Quantum) ((*p) & (0x01 << bit) ? 0x00 : 0x01),\n              q);\n            q+=GetPixelChannels(image);\n          }\n          p++;\n        }\n        if ((image->columns % 8) != 0)\n          {\n            for (bit=7; bit >= (int) (8-(image->columns % 8)); bit--)\n            {\n              SetPixelIndex(image,(Quantum) ((*p) & (0x01 << bit) ? 0x00 :\n                0x01),q);\n              q+=GetPixelChannels(image);\n            }\n            p++;\n          }\n        if ((((image->columns/8)+(image->columns % 8 ? 1 : 0)) % 2) != 0)\n          p++;\n        if (SyncAuthenticPixels(image,exception) == MagickFalse)\n          break;\n        if (image->previous == (Image *) NULL)\n          {\n            status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n              image->rows);\n            if (status == MagickFalse)\n              break;\n          }\n      }\n    else\n      if (image->storage_class == PseudoClass)\n        {\n          if (bytes_per_line == 0)\n            bytes_per_line=image->columns;\n          length=image->rows*(image->columns+image->columns % 2);\n          if (((sun_info.type == RT_ENCODED) &&\n               (length > (bytes_per_line*image->rows))) ||\n              ((sun_info.type != RT_ENCODED) && (length > sun_info.length)))\n            ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n            if (q == (Quantum *) NULL)\n              break;\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              SetPixelIndex(image,*p++,q);\n              q+=GetPixelChannels(image);\n            }\n            if ((image->columns % 2) != 0)\n              p++;\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n              break;\n            if (image->previous == (Image *) NULL)\n              {\n                status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n                if (status == MagickFalse)\n                  break;\n              }\n          }\n        }\n      else\n        {\n          size_t\n            bytes_per_pixel;\n\n          bytes_per_pixel=3;\n          if (image->alpha_trait != UndefinedPixelTrait)\n            bytes_per_pixel++;\n          if (bytes_per_line == 0)\n            bytes_per_line=bytes_per_pixel*image->columns;\n          length=image->rows*(bytes_per_line+bytes_per_line % 2);\n          if (((sun_info.type == RT_ENCODED) &&\n               (length > (bytes_per_line*image->rows))) ||\n              ((sun_info.type != RT_ENCODED) && (length > sun_info.length)))\n            ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n            if (q == (Quantum *) NULL)\n              break;\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              if (image->alpha_trait != UndefinedPixelTrait)\n                SetPixelAlpha(image,ScaleCharToQuantum(*p++),q);\n              if (sun_info.type == RT_STANDARD)\n                {\n                  SetPixelBlue(image,ScaleCharToQuantum(*p++),q);\n                  SetPixelGreen(image,ScaleCharToQuantum(*p++),q);\n                  SetPixelRed(image,ScaleCharToQuantum(*p++),q);\n                }\n              else\n                {\n                  SetPixelRed(image,ScaleCharToQuantum(*p++),q);\n                  SetPixelGreen(image,ScaleCharToQuantum(*p++),q);\n                  SetPixelBlue(image,ScaleCharToQuantum(*p++),q);\n                }\n              if (image->colors != 0)\n                {\n                  SetPixelRed(image,ClampToQuantum(image->colormap[(ssize_t)\n                    GetPixelRed(image,q)].red),q);\n                  SetPixelGreen(image,ClampToQuantum(image->colormap[(ssize_t)\n                    GetPixelGreen(image,q)].green),q);\n                  SetPixelBlue(image,ClampToQuantum(image->colormap[(ssize_t)\n                    GetPixelBlue(image,q)].blue),q);\n                }\n              q+=GetPixelChannels(image);\n            }\n            if (((bytes_per_pixel*image->columns) % 2) != 0)\n              p++;\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n              break;\n            if (image->previous == (Image *) NULL)\n              {\n                status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n                if (status == MagickFalse)\n                  break;\n              }\n          }\n        }\n    if (image->storage_class == PseudoClass)\n      (void) SyncImage(image,exception);\n    sun_pixels=(unsigned char *) RelinquishMagickMemory(sun_pixels);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    /*\n      Proceed to next image.\n    */\n    if (image_info->number_scenes != 0)\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    sun_info.magic=ReadBlobMSBLong(image);\n    if (sun_info.magic == 0x59a66a95)\n      {\n        /*\n          Allocate next image structure.\n        */\n        AcquireNextImage(image_info,image,exception);\n        if (GetNextImageInList(image) == (Image *) NULL)\n          {\n            image=DestroyImageList(image);\n            return((Image *) NULL);\n          }\n        image=SyncNextImageInList(image);\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n        if (status == MagickFalse)\n          break;\n      }\n  } while (sun_info.magic == 0x59a66a95);\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/6b4aff0f117b978502ee5bcd6e753c17aec5a961", "file_name": "coders/sun.c", "vul_type": "cwe-125", "description": "Write a C function to read and process SUN raster images."}
{"func_name": "getPostsByPostid", "func_src_before": "    def getPostsByPostid(self,postid):\n        sqlText=\"select users.name,post.comment from users,post where \\\n                users.userid=post.userid and post.postid=%d\"%(postid)\n        result=sql.queryDB(self.conn,sqlText)\n        return result;", "func_src_after": "    def getPostsByPostid(self,postid):\n        sqlText=\"select users.name,post.comment from users,post where \\\n                users.userid=post.userid and post.postid=%s\"\n        params=[postid]\n        result=sql.queryDB(self.conn,sqlText,params)\n        return result;", "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/post.py", "vul_type": "cwe-089", "description": "Write a Python function that retrieves a user's name and comment from a database using a post ID."}
{"func_name": "dump", "func_src_before": "    def dump(self, path):\n        \"\"\"\n        dump address space as binary to file\n        \"\"\"\n        with open(path, 'wb') as f:\n            pickle.dump(self._nodes, f, pickle.HIGHEST_PROTOCOL)", "func_src_after": "    def dump(self, path):\n        \"\"\"\n        dump address space as binary to file\n        \"\"\"\n        s = shelve.open(path, \"n\", protocol = pickle.HIGHEST_PROTOCOL)\n        for nodeid in self._nodes.keys():\n            s[nodeid.to_string()] = self._nodes[nodeid]\n        s.close()", "line_changes": {"deleted": [{"line_no": 5, "char_start": 95, "char_end": 131, "line": "        with open(path, 'wb') as f:\n"}, {"line_no": 6, "char_start": 131, "char_end": 195, "line": "            pickle.dump(self._nodes, f, pickle.HIGHEST_PROTOCOL)\n"}], "added": [{"line_no": 5, "char_start": 95, "char_end": 166, "line": "        s = shelve.open(path, \"n\", protocol = pickle.HIGHEST_PROTOCOL)\n"}, {"line_no": 6, "char_start": 166, "char_end": 208, "line": "        for nodeid in self._nodes.keys():\n"}, {"line_no": 7, "char_start": 208, "char_end": 264, "line": "            s[nodeid.to_string()] = self._nodes[nodeid]\n"}, {"line_no": 8, "char_start": 264, "char_end": 281, "line": "        s.close()\n"}]}, "char_changes": {"deleted": [{"char_start": 103, "char_end": 194, "chars": "with open(path, 'wb') as f:\n            pickle.dump(self._nodes, f, pickle.HIGHEST_PROTOCOL"}], "added": [{"char_start": 103, "char_end": 280, "chars": "s = shelve.open(path, \"n\", protocol = pickle.HIGHEST_PROTOCOL)\n        for nodeid in self._nodes.keys():\n            s[nodeid.to_string()] = self._nodes[nodeid]\n        s.close("}]}, "commit_link": "github.com/bitkeeper/python-opcua/commit/2fcbbf85a143195a3b439930056bf78908fe9509", "file_name": "address_space.py", "vul_type": "cwe-502", "commit_msg": "Perform lazy loading when restoring a cached address space\n\nWhen starting an opcua server, the creation of the address space is\ncurrently a performance bottleneck. The startup process can be accelerated\nby loading a pre-generated address space pickle.\nHowever, the startup process still takes ~25 seconds on a raspberry pi\nmodel b (compared to ~125 seconds when generating the address space from code).\nStoring the address space in a shelve, where the data for each node is\npickeled individually, allows to further improve the startup performance\nsince only the nodes that are actually accessed are loaded from\ndisc (all other nodes are loaded later when they are accessed).\nSince the default address space contains thousands of nodes but just a\nsmall amount is actually accessed during startup, the startuptime could\nbe improved to ~3.5 seconds.", "parent_commit": "2f5a26fba77d7870be219a5cba2c2e0a0144830c", "description": "Write a Python function named `dump` that saves an object's data to a binary file at a specified path."}
{"func_name": "initialize", "func_src_before": "    def initialize(config, path = nil)\n      @config = YAML.load(config)\n      @path = path\n\n      unless @config.is_a? Hash\n        raise ValidationError, \"YAML should be a hash\"\n      end\n\n      @config = @config.deep_symbolize_keys\n\n      initial_parsing\n\n      validate!\n    end", "func_src_after": "    def initialize(config, path = nil)\n      @config = YAML.safe_load(config)\n      @path = path\n\n      unless @config.is_a? Hash\n        raise ValidationError, \"YAML should be a hash\"\n      end\n\n      @config = @config.deep_symbolize_keys\n\n      initial_parsing\n\n      validate!\n    end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 39, "char_end": 73, "line": "      @config = YAML.load(config)\n"}], "added": [{"line_no": 2, "char_start": 39, "char_end": 78, "line": "      @config = YAML.safe_load(config)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 60, "char_end": 65, "chars": "safe_"}]}, "commit_link": "github.com/screenpages/gitlabhq/commit/c5dacce4d7e47a0504975fbb3bfaf478b95f1065", "file_name": "gitlab_ci_yaml_processor.rb", "vul_type": "cwe-502", "commit_msg": "Use YAML.safe_load", "parent_commit": "7b50965e9990bcb88f56b771d47514cbeb5316e5", "description": "Create a Ruby method named `initialize` that loads a YAML configuration, symbolizes its keys, and performs validation and initial parsing."}
{"func_name": "load_user", "func_src_before": "@login_manager.user_loader\ndef load_user(s_id):\n    email = str(s_id)\n    query = '''select * from usr where email like\\'''' + email + '\\''\n    cursor = g.conn.execute(query)\n    user = User()\n    for row in cursor:\n        user.name = str(row.name)\n        user.email = str(row.email)\n        break\n    return user", "func_src_after": "@login_manager.user_loader\ndef load_user(s_id):\n    email = str(s_id)\n    query = 'select * from usr where email like %s'\n    cursor = g.conn.execute(query, (email, ))\n    user = User()\n    for row in cursor:\n        user.name = str(row.name)\n        user.email = str(row.email)\n        break\n    return user", "commit_link": "github.com/Daniel-Bu/w4111-project1/commit/fe04bedc72e62fd4c4ee046a9af29fd81e9b3340", "file_name": "Web-app/Server.py", "vul_type": "cwe-089", "description": "Write a Python function to load a user by email using Flask-Login's user_loader decorator."}
{"func_name": "pref_set", "func_src_before": "@app.route(\"/api/preferences/set/<key>/<value>\")\ndef pref_set(key, value):\n    if get_user() is None:\n        return \"Authentication required\", 401\n\n    get_preferences()[key] = (None if value == 'null' else value)\n    return Response(json.dumps({'key': key, 'success': ''})), 201", "func_src_after": "@app.route(\"/api/preferences/set/<key>/<value>\")\ndef pref_set(key, value):\n    if get_user() is None:\n        return \"Authentication required\", 401\n\n    get_preferences()[key] = (None if value == 'null' else value)\n    return Response(\n        json.dumps({'key': key, 'success': ''}),\n        mimetype='application/json'\n    ), 201", "line_changes": {"deleted": [{"line_no": 7, "char_start": 215, "char_end": 280, "line": "    return Response(json.dumps({'key': key, 'success': ''})), 201\n"}], "added": [{"line_no": 7, "char_start": 215, "char_end": 236, "line": "    return Response(\n"}, {"line_no": 8, "char_start": 236, "char_end": 285, "line": "        json.dumps({'key': key, 'success': ''}),\n"}, {"line_no": 9, "char_start": 285, "char_end": 321, "line": "        mimetype='application/json'\n"}, {"line_no": 10, "char_start": 321, "char_end": 331, "line": "    ), 201\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 235, "char_end": 244, "chars": "\n        "}, {"char_start": 283, "char_end": 325, "chars": ",\n        mimetype='application/json'\n    "}]}, "commit_link": "github.com/wikimedia/analytics-quarry-web/commit/4b7e1d6a3a52ec6cf826a971135a38b0f74785d2", "file_name": "app.py", "vul_type": "cwe-079", "commit_msg": "SECURITY: Set correct Mime Type on /api/preferences\n\nPrevents a Reflected Cross-Site scripting (XSS) vulnerability\n\nBug: T270195\nChange-Id: I04bf53d2a939da369e54e91899615a3ffc3e5caf", "description": "Write a Python Flask endpoint to set a user preference given a key and value, returning JSON and requiring user authentication."}
{"func_name": "_create_3par_fibrechan_host", "func_src_before": "    def _create_3par_fibrechan_host(self, hostname, wwn, domain, persona_id):\n        \"\"\"Create a 3PAR host.\n\n        Create a 3PAR host, if there is already a host on the 3par using\n        the same wwn but with a different hostname, return the hostname\n        used by 3PAR.\n        \"\"\"\n        out = self.common._cli_run('createhost -persona %s -domain %s %s %s'\n                                   % (persona_id, domain,\n                                      hostname, \" \".join(wwn)), None)\n        if out and len(out) > 1:\n            return self.common.parse_create_host_error(hostname, out)\n\n        return hostname", "func_src_after": "    def _create_3par_fibrechan_host(self, hostname, wwns, domain, persona_id):\n        \"\"\"Create a 3PAR host.\n\n        Create a 3PAR host, if there is already a host on the 3par using\n        the same wwn but with a different hostname, return the hostname\n        used by 3PAR.\n        \"\"\"\n        command = ['createhost', '-persona', persona_id, '-domain', domain,\n                   hostname]\n        for wwn in wwns:\n            command.append(wwn)\n\n        out = self.common._cli_run(command)\n        if out and len(out) > 1:\n            return self.common.parse_create_host_error(hostname, out)\n\n        return hostname", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_fc.py", "vul_type": "cwe-078", "description": "Write a Python function to create a 3PAR Fibre Channel host, handling potential WWN conflicts."}
{"func_name": "X86_insn_reg_intel", "func_src_before": "x86_reg X86_insn_reg_intel(unsigned int id, enum cs_ac_type *access)\n{\n\tunsigned int first = 0;\n\tunsigned int last = ARR_SIZE(insn_regs_intel) - 1;\n\tunsigned int mid = ARR_SIZE(insn_regs_intel) / 2;\n\n\tif (!intel_regs_sorted) {\n\t\tmemcpy(insn_regs_intel_sorted, insn_regs_intel,\n\t\t\t\tsizeof(insn_regs_intel_sorted));\n\t\tqsort(insn_regs_intel_sorted,\n\t\t\t\tARR_SIZE(insn_regs_intel_sorted),\n\t\t\t\tsizeof(struct insn_reg), regs_cmp);\n\t\tintel_regs_sorted = true;\n\t}\n\n\twhile (first <= last) {\n\t\tif (insn_regs_intel_sorted[mid].insn < id) {\n\t\t\tfirst = mid + 1;\n\t\t} else if (insn_regs_intel_sorted[mid].insn == id) {\n\t\t\tif (access) {\n\t\t\t\t*access = insn_regs_intel_sorted[mid].access;\n\t\t\t}\n\t\t\treturn insn_regs_intel_sorted[mid].reg;\n\t\t} else {\n\t\t\tif (mid == 0)\n\t\t\t\tbreak;\n\t\t\tlast = mid - 1;\n\t\t}\n\t\tmid = (first + last) / 2;\n\t}\n\n\t// not found\n\treturn 0;\n}", "func_src_after": "x86_reg X86_insn_reg_intel(unsigned int id, enum cs_ac_type *access)\n{\n\tstatic bool intel_regs_sorted = false;\n\tunsigned int first = 0;\n\tunsigned int last = ARR_SIZE(insn_regs_intel) - 1;\n\tunsigned int mid;\n\n\tif (!intel_regs_sorted) {\n\t\tmemcpy(insn_regs_intel_sorted, insn_regs_intel,\n\t\t\t\tsizeof(insn_regs_intel_sorted));\n\t\tqsort(insn_regs_intel_sorted,\n\t\t\t\tARR_SIZE(insn_regs_intel_sorted),\n\t\t\t\tsizeof(struct insn_reg), regs_cmp);\n\t\tintel_regs_sorted = true;\n\t}\n\n\tif (insn_regs_intel_sorted[0].insn > id ||\n\t\t\tinsn_regs_intel_sorted[last].insn < id) {\n\t\treturn 0;\n\t}\n\n\twhile (first <= last) {\n\t\tmid = (first + last) / 2;\n\t\tif (insn_regs_intel_sorted[mid].insn < id) {\n\t\t\tfirst = mid + 1;\n\t\t} else if (insn_regs_intel_sorted[mid].insn == id) {\n\t\t\tif (access) {\n\t\t\t\t*access = insn_regs_intel_sorted[mid].access;\n\t\t\t}\n\t\t\treturn insn_regs_intel_sorted[mid].reg;\n\t\t} else {\n\t\t\tif (mid == 0)\n\t\t\t\tbreak;\n\t\t\tlast = mid - 1;\n\t\t}\n\t}\n\n\t// not found\n\treturn 0;\n}", "commit_link": "github.com/aquynh/capstone/commit/87a25bb543c8e4c09b48d4b4a6c7db31ce58df06", "file_name": "arch/X86/X86Mapping.c", "vul_type": "cwe-125", "description": "Write a C function named `X86_insn_reg_intel` that performs a binary search on a sorted array to find a register by its ID and optionally returns its access type."}
{"func_name": "set_eeprom_serial_number", "func_src_before": "set_eeprom_serial_number (EEPROM_HDR *e, char *sn)\n{\n  strncpy (e->serial, sn, 16);\n  _dirty = 1;\n\n  return 0;\n}", "func_src_after": "set_eeprom_serial_number (EEPROM_HDR *e, char *sn)\n{\n  strncpy (e->serial, sn, 12);\n  _dirty = 1;\n\n  return 0;\n}", "line_changes": {"deleted": [{"line_no": 3, "char_start": 53, "char_end": 84, "line": "  strncpy (e->serial, sn, 16);\n"}], "added": [{"line_no": 3, "char_start": 53, "char_end": 84, "line": "  strncpy (e->serial, sn, 12);\n"}]}, "char_changes": {"deleted": [{"char_start": 80, "char_end": 81, "chars": "6"}], "added": [{"char_start": 80, "char_end": 81, "chars": "2"}]}, "commit_link": "github.com/picoflamingo/BBCape_EEPROM/commit/0b2d0afdd72e6ca35e9312bd43e29d488ae8c2e5", "file_name": "bbcape_eeprom.c", "vul_type": "cwe-119", "commit_msg": "Buffer Overflow fixed (https://github.com/picoflamingo/BBCape_EEPROM/issues/1)", "parent_commit": "21b1310205d6b2d9073efc51c6a32edbd9a08b89", "description": "Write a C function named `set_eeprom_serial_number` that copies a serial number string into an EEPROM structure and sets a dirty flag."}
{"func_name": "_port_conf_generator", "func_src_before": "    def _port_conf_generator(self, cmd):\n        ssh_cmd = '%s -delim !' % cmd\n        out, err = self._run_ssh(ssh_cmd)\n\n        if not len(out.strip()):\n            return\n        port_lines = out.strip().split('\\n')\n        if not len(port_lines):\n            return\n\n        header = port_lines.pop(0)\n        yield header\n        for portip_line in port_lines:\n            try:\n                port_data = self._get_hdr_dic(header, portip_line, '!')\n            except exception.VolumeBackendAPIException:\n                with excutils.save_and_reraise_exception():\n                    self._log_cli_output_error('_port_conf_generator',\n                                               ssh_cmd, out, err)\n            yield port_data", "func_src_after": "    def _port_conf_generator(self, cmd):\n        ssh_cmd = cmd + ['-delim', '!']\n        out, err = self._run_ssh(ssh_cmd)\n\n        if not len(out.strip()):\n            return\n        port_lines = out.strip().split('\\n')\n        if not len(port_lines):\n            return\n\n        header = port_lines.pop(0)\n        yield header\n        for portip_line in port_lines:\n            try:\n                port_data = self._get_hdr_dic(header, portip_line, '!')\n            except exception.VolumeBackendAPIException:\n                with excutils.save_and_reraise_exception():\n                    self._log_cli_output_error('_port_conf_generator',\n                                               ssh_cmd, out, err)\n            yield port_data", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function named `_port_conf_generator` that takes a command, executes it via SSH, and yields parsed port configuration data."}
{"func_name": "ReadPSDImage", "func_src_before": "static Image *ReadPSDImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  Image\n    *image;\n\n  MagickBooleanType\n    has_merged_image,\n    skip_layers;\n\n  MagickOffsetType\n    offset;\n\n  MagickSizeType\n    length;\n\n  MagickBooleanType\n    status;\n\n  PSDInfo\n    psd_info;\n\n  register ssize_t\n    i;\n\n  ssize_t\n    count;\n\n  unsigned char\n    *data;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read image header.\n  */\n  image->endian=MSBEndian;\n  count=ReadBlob(image,4,(unsigned char *) psd_info.signature);\n  psd_info.version=ReadBlobMSBShort(image);\n  if ((count == 0) || (LocaleNCompare(psd_info.signature,\"8BPS\",4) != 0) ||\n      ((psd_info.version != 1) && (psd_info.version != 2)))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  (void) ReadBlob(image,6,psd_info.reserved);\n  psd_info.channels=ReadBlobMSBShort(image);\n  if (psd_info.channels > MaxPSDChannels)\n    ThrowReaderException(CorruptImageError,\"MaximumChannelsExceeded\");\n  psd_info.rows=ReadBlobMSBLong(image);\n  psd_info.columns=ReadBlobMSBLong(image);\n  if ((psd_info.version == 1) && ((psd_info.rows > 30000) ||\n      (psd_info.columns > 30000)))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  psd_info.depth=ReadBlobMSBShort(image);\n  if ((psd_info.depth != 1) && (psd_info.depth != 8) && (psd_info.depth != 16))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  psd_info.mode=ReadBlobMSBShort(image);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  Image is %.20g x %.20g with channels=%.20g, depth=%.20g, mode=%s\",\n      (double) psd_info.columns,(double) psd_info.rows,(double)\n      psd_info.channels,(double) psd_info.depth,ModeToString((PSDImageType)\n      psd_info.mode));\n  /*\n    Initialize image.\n  */\n  image->depth=psd_info.depth;\n  image->columns=psd_info.columns;\n  image->rows=psd_info.rows;\n  status=SetImageExtent(image,image->columns,image->rows,exception);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n  if (SetImageBackgroundColor(image,exception) == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  if (psd_info.mode == LabMode)\n    SetImageColorspace(image,LabColorspace,exception);\n  if (psd_info.mode == CMYKMode)\n    {\n      SetImageColorspace(image,CMYKColorspace,exception);\n      image->alpha_trait=psd_info.channels > 4 ? BlendPixelTrait :\n        UndefinedPixelTrait;\n    }\n  else if ((psd_info.mode == BitmapMode) || (psd_info.mode == GrayscaleMode) ||\n      (psd_info.mode == DuotoneMode))\n    {\n      status=AcquireImageColormap(image,psd_info.depth != 16 ? 256 : 65536,\n        exception);\n      if (status == MagickFalse)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  Image colormap allocated\");\n      SetImageColorspace(image,GRAYColorspace,exception);\n      image->alpha_trait=psd_info.channels > 1 ? BlendPixelTrait :\n        UndefinedPixelTrait;\n    }\n  else\n    image->alpha_trait=psd_info.channels > 3 ? BlendPixelTrait :\n      UndefinedPixelTrait;\n  /*\n    Read PSD raster colormap only present for indexed and duotone images.\n  */\n  length=ReadBlobMSBLong(image);\n  if (length != 0)\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  reading colormap\");\n      if (psd_info.mode == DuotoneMode)\n        {\n          /*\n            Duotone image data;  the format of this data is undocumented.\n          */\n          data=(unsigned char *) AcquireQuantumMemory((size_t) length,\n            sizeof(*data));\n          if (data == (unsigned char *) NULL)\n            ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          (void) ReadBlob(image,(size_t) length,data);\n          data=(unsigned char *) RelinquishMagickMemory(data);\n        }\n      else\n        {\n          size_t\n            number_colors;\n\n          /*\n            Read PSD raster colormap.\n          */\n          number_colors=length/3;\n          if (number_colors > 65536)\n            ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n          if (AcquireImageColormap(image,number_colors,exception) == MagickFalse)\n            ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].red=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].green=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].blue=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          image->alpha_trait=UndefinedPixelTrait;\n        }\n    }\n  has_merged_image=MagickTrue;\n  length=ReadBlobMSBLong(image);\n  if (length != 0)\n    {\n      unsigned char\n        *blocks;\n\n      /*\n        Image resources block.\n      */\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  reading image resource blocks - %.20g bytes\",(double)\n          ((MagickOffsetType) length));\n      blocks=(unsigned char *) AcquireQuantumMemory((size_t) length,\n        sizeof(*blocks));\n      if (blocks == (unsigned char *) NULL)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      count=ReadBlob(image,(size_t) length,blocks);\n      if ((count != (ssize_t) length) ||\n          (LocaleNCompare((char *) blocks,\"8BIM\",4) != 0))\n        {\n          blocks=(unsigned char *) RelinquishMagickMemory(blocks);\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        }\n      ParseImageResourceBlocks(image,blocks,(size_t) length,&has_merged_image,\n        exception);\n      blocks=(unsigned char *) RelinquishMagickMemory(blocks);\n    }\n  /*\n    Layer and mask block.\n  */\n  length=GetPSDSize(&psd_info,image);\n  if (length == 8)\n    {\n      length=ReadBlobMSBLong(image);\n      length=ReadBlobMSBLong(image);\n    }\n  offset=TellBlob(image);\n  skip_layers=MagickFalse;\n  if ((image_info->number_scenes == 1) && (image_info->scene == 0) &&\n      (has_merged_image != MagickFalse))\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  read composite only\");\n      skip_layers=MagickTrue;\n    }\n  if (length == 0)\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  image has no layers\");\n    }\n  else\n    {\n      if (ReadPSDLayers(image,image_info,&psd_info,skip_layers,exception) !=\n          MagickTrue)\n        {\n          (void) CloseBlob(image);\n          image=DestroyImageList(image);\n          return((Image *) NULL);\n        }\n\n      /*\n         Skip the rest of the layer and mask information.\n      */\n      SeekBlob(image,offset+length,SEEK_SET);\n    }\n  /*\n    If we are only \"pinging\" the image, then we're done - so return.\n  */\n  if (image_info->ping != MagickFalse)\n    {\n      (void) CloseBlob(image);\n      return(GetFirstImageInList(image));\n    }\n  /*\n    Read the precombined layer, present for PSD < 4 compatibility.\n  */\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  reading the precombined layer\");\n  if ((has_merged_image != MagickFalse) || (GetImageListLength(image) == 1))\n    has_merged_image=(MagickBooleanType) ReadPSDMergedImage(image_info,image,\n      &psd_info,exception);\n  if ((has_merged_image == MagickFalse) && (GetImageListLength(image) == 1) &&\n      (length != 0))\n    {\n      SeekBlob(image,offset,SEEK_SET);\n      status=ReadPSDLayers(image,image_info,&psd_info,MagickFalse,exception);\n      if (status != MagickTrue)\n        {\n          (void) CloseBlob(image);\n          image=DestroyImageList(image);\n          return((Image *) NULL);\n        }\n    }\n  if ((has_merged_image == MagickFalse) && (GetImageListLength(image) > 1))\n    {\n      Image\n        *merged;\n\n      SetImageAlphaChannel(image,TransparentAlphaChannel,exception);\n      image->background_color.alpha=TransparentAlpha;\n      image->background_color.alpha_trait=BlendPixelTrait;\n      merged=MergeImageLayers(image,FlattenLayer,exception);\n      ReplaceImageInList(&image,merged);\n    }\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "func_src_after": "static Image *ReadPSDImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  Image\n    *image;\n\n  MagickBooleanType\n    has_merged_image,\n    skip_layers;\n\n  MagickOffsetType\n    offset;\n\n  MagickSizeType\n    length;\n\n  MagickBooleanType\n    status;\n\n  PSDInfo\n    psd_info;\n\n  register ssize_t\n    i;\n\n  ssize_t\n    count;\n\n  unsigned char\n    *data;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read image header.\n  */\n  image->endian=MSBEndian;\n  count=ReadBlob(image,4,(unsigned char *) psd_info.signature);\n  psd_info.version=ReadBlobMSBShort(image);\n  if ((count == 0) || (LocaleNCompare(psd_info.signature,\"8BPS\",4) != 0) ||\n      ((psd_info.version != 1) && (psd_info.version != 2)))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  (void) ReadBlob(image,6,psd_info.reserved);\n  psd_info.channels=ReadBlobMSBShort(image);\n  if (psd_info.channels > MaxPSDChannels)\n    ThrowReaderException(CorruptImageError,\"MaximumChannelsExceeded\");\n  psd_info.rows=ReadBlobMSBLong(image);\n  psd_info.columns=ReadBlobMSBLong(image);\n  if ((psd_info.version == 1) && ((psd_info.rows > 30000) ||\n      (psd_info.columns > 30000)))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  psd_info.depth=ReadBlobMSBShort(image);\n  if ((psd_info.depth != 1) && (psd_info.depth != 8) && (psd_info.depth != 16))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  psd_info.mode=ReadBlobMSBShort(image);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  Image is %.20g x %.20g with channels=%.20g, depth=%.20g, mode=%s\",\n      (double) psd_info.columns,(double) psd_info.rows,(double)\n      psd_info.channels,(double) psd_info.depth,ModeToString((PSDImageType)\n      psd_info.mode));\n  /*\n    Initialize image.\n  */\n  image->depth=psd_info.depth;\n  image->columns=psd_info.columns;\n  image->rows=psd_info.rows;\n  status=SetImageExtent(image,image->columns,image->rows,exception);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n  if (SetImageBackgroundColor(image,exception) == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  if (psd_info.mode == LabMode)\n    SetImageColorspace(image,LabColorspace,exception);\n  if (psd_info.mode == CMYKMode)\n    {\n      SetImageColorspace(image,CMYKColorspace,exception);\n      image->alpha_trait=psd_info.channels > 4 ? BlendPixelTrait :\n        UndefinedPixelTrait;\n    }\n  else if ((psd_info.mode == BitmapMode) || (psd_info.mode == GrayscaleMode) ||\n      (psd_info.mode == DuotoneMode))\n    {\n      status=AcquireImageColormap(image,psd_info.depth != 16 ? 256 : 65536,\n        exception);\n      if (status == MagickFalse)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  Image colormap allocated\");\n      SetImageColorspace(image,GRAYColorspace,exception);\n      image->alpha_trait=psd_info.channels > 1 ? BlendPixelTrait :\n        UndefinedPixelTrait;\n    }\n  else\n    image->alpha_trait=psd_info.channels > 3 ? BlendPixelTrait :\n      UndefinedPixelTrait;\n  /*\n    Read PSD raster colormap only present for indexed and duotone images.\n  */\n  length=ReadBlobMSBLong(image);\n  if (length != 0)\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  reading colormap\");\n      if (psd_info.mode == DuotoneMode)\n        {\n          /*\n            Duotone image data;  the format of this data is undocumented.\n          */\n          data=(unsigned char *) AcquireQuantumMemory((size_t) length,\n            sizeof(*data));\n          if (data == (unsigned char *) NULL)\n            ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          (void) ReadBlob(image,(size_t) length,data);\n          data=(unsigned char *) RelinquishMagickMemory(data);\n        }\n      else\n        {\n          size_t\n            number_colors;\n\n          /*\n            Read PSD raster colormap.\n          */\n          number_colors=length/3;\n          if (number_colors > 65536)\n            ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n          if (AcquireImageColormap(image,number_colors,exception) == MagickFalse)\n            ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].red=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].green=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].blue=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          image->alpha_trait=UndefinedPixelTrait;\n        }\n    }\n  if ((image->depth == 1) && (image->storage_class != PseudoClass))\n    ThrowReaderException(CorruptImageError, \"ImproperImageHeader\");\n  has_merged_image=MagickTrue;\n  length=ReadBlobMSBLong(image);\n  if (length != 0)\n    {\n      unsigned char\n        *blocks;\n\n      /*\n        Image resources block.\n      */\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  reading image resource blocks - %.20g bytes\",(double)\n          ((MagickOffsetType) length));\n      blocks=(unsigned char *) AcquireQuantumMemory((size_t) length,\n        sizeof(*blocks));\n      if (blocks == (unsigned char *) NULL)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      count=ReadBlob(image,(size_t) length,blocks);\n      if ((count != (ssize_t) length) ||\n          (LocaleNCompare((char *) blocks,\"8BIM\",4) != 0))\n        {\n          blocks=(unsigned char *) RelinquishMagickMemory(blocks);\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        }\n      ParseImageResourceBlocks(image,blocks,(size_t) length,&has_merged_image,\n        exception);\n      blocks=(unsigned char *) RelinquishMagickMemory(blocks);\n    }\n  /*\n    Layer and mask block.\n  */\n  length=GetPSDSize(&psd_info,image);\n  if (length == 8)\n    {\n      length=ReadBlobMSBLong(image);\n      length=ReadBlobMSBLong(image);\n    }\n  offset=TellBlob(image);\n  skip_layers=MagickFalse;\n  if ((image_info->number_scenes == 1) && (image_info->scene == 0) &&\n      (has_merged_image != MagickFalse))\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  read composite only\");\n      skip_layers=MagickTrue;\n    }\n  if (length == 0)\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  image has no layers\");\n    }\n  else\n    {\n      if (ReadPSDLayers(image,image_info,&psd_info,skip_layers,exception) !=\n          MagickTrue)\n        {\n          (void) CloseBlob(image);\n          image=DestroyImageList(image);\n          return((Image *) NULL);\n        }\n\n      /*\n         Skip the rest of the layer and mask information.\n      */\n      SeekBlob(image,offset+length,SEEK_SET);\n    }\n  /*\n    If we are only \"pinging\" the image, then we're done - so return.\n  */\n  if (image_info->ping != MagickFalse)\n    {\n      (void) CloseBlob(image);\n      return(GetFirstImageInList(image));\n    }\n  /*\n    Read the precombined layer, present for PSD < 4 compatibility.\n  */\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  reading the precombined layer\");\n  if ((has_merged_image != MagickFalse) || (GetImageListLength(image) == 1))\n    has_merged_image=(MagickBooleanType) ReadPSDMergedImage(image_info,image,\n      &psd_info,exception);\n  if ((has_merged_image == MagickFalse) && (GetImageListLength(image) == 1) &&\n      (length != 0))\n    {\n      SeekBlob(image,offset,SEEK_SET);\n      status=ReadPSDLayers(image,image_info,&psd_info,MagickFalse,exception);\n      if (status != MagickTrue)\n        {\n          (void) CloseBlob(image);\n          image=DestroyImageList(image);\n          return((Image *) NULL);\n        }\n    }\n  if ((has_merged_image == MagickFalse) && (GetImageListLength(image) > 1))\n    {\n      Image\n        *merged;\n\n      SetImageAlphaChannel(image,TransparentAlphaChannel,exception);\n      image->background_color.alpha=TransparentAlpha;\n      image->background_color.alpha_trait=BlendPixelTrait;\n      merged=MergeImageLayers(image,FlattenLayer,exception);\n      ReplaceImageInList(&image,merged);\n    }\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/198fffab4daf8aea88badd9c629350e5b26ec32f", "file_name": "coders/psd.c", "vul_type": "cwe-125", "description": "Write a C function to read and process a PSD image file."}
{"func_name": "cancelFollow", "func_src_before": "    def cancelFollow(self,userid,friendid):\n        sqlText=\"delete from friends where userid=%d and friendid=%d;\"%(userid,friendid)\n        result=sql.deleteDB(self.conn,sqlText)\n        return result;", "func_src_after": "    def cancelFollow(self,userid,friendid):\n        sqlText=\"delete from friends where userid=%d and friendid=%s;\"\n        params=[userid,friendid]\n        result=sql.deleteDB(self.conn,sqlText,params)\n        return result;", "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/users.py", "vul_type": "cwe-089", "description": "Write a Python function named `cancelFollow` that removes a friend connection from a database using SQL."}
{"func_name": "ReadWPGImage", "func_src_before": "static Image *ReadWPGImage(const ImageInfo *image_info,\n  ExceptionInfo *exception)\n{\n  typedef struct\n  {\n    size_t FileId;\n    MagickOffsetType DataOffset;\n    unsigned int ProductType;\n    unsigned int FileType;\n    unsigned char MajorVersion;\n    unsigned char MinorVersion;\n    unsigned int EncryptKey;\n    unsigned int Reserved;\n  } WPGHeader;\n\n  typedef struct\n  {\n    unsigned char RecType;\n    size_t RecordLength;\n  } WPGRecord;\n\n  typedef struct\n  {\n    unsigned char Class;\n    unsigned char RecType;\n    size_t Extension;\n    size_t RecordLength;\n  } WPG2Record;\n\n  typedef struct\n  {\n    unsigned  HorizontalUnits;\n    unsigned  VerticalUnits;\n    unsigned char PosSizePrecision;\n  } WPG2Start;\n\n  typedef struct\n  {\n    unsigned int Width;\n    unsigned int Height;\n    unsigned int Depth;\n    unsigned int HorzRes;\n    unsigned int VertRes;\n  } WPGBitmapType1;\n\n  typedef struct\n  {\n    unsigned int Width;\n    unsigned int Height;\n    unsigned char Depth;\n    unsigned char Compression;\n  } WPG2BitmapType1;\n\n  typedef struct\n  {\n    unsigned int RotAngle;\n    unsigned int LowLeftX;\n    unsigned int LowLeftY;\n    unsigned int UpRightX;\n    unsigned int UpRightY;\n    unsigned int Width;\n    unsigned int Height;\n    unsigned int Depth;\n    unsigned int HorzRes;\n    unsigned int VertRes;\n  } WPGBitmapType2;\n\n  typedef struct\n  {\n    unsigned int StartIndex;\n    unsigned int NumOfEntries;\n  } WPGColorMapRec;\n\n  /*\n  typedef struct {\n    size_t PS_unknown1;\n    unsigned int PS_unknown2;\n    unsigned int PS_unknown3;\n  } WPGPSl1Record;  \n  */\n\n  Image\n    *image;\n\n  unsigned int\n    status;\n\n  WPGHeader\n    Header;\n\n  WPGRecord\n    Rec;\n\n  WPG2Record\n    Rec2;\n\n  WPG2Start StartWPG;\n\n  WPGBitmapType1\n    BitmapHeader1;\n\n  WPG2BitmapType1\n    Bitmap2Header1;\n\n  WPGBitmapType2\n    BitmapHeader2;\n\n  WPGColorMapRec\n    WPG_Palette;\n\n  int\n    i,\n    bpp,\n    WPG2Flags;\n\n  ssize_t\n    ldblk;\n\n  size_t\n    one;\n\n  unsigned char\n    *BImgBuff;\n\n  tCTM CTM;         /*current transform matrix*/\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  one=1;\n  image=AcquireImage(image_info,exception);\n  image->depth=8;\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read WPG image.\n  */\n  Header.FileId=ReadBlobLSBLong(image);\n  Header.DataOffset=(MagickOffsetType) ReadBlobLSBLong(image);\n  Header.ProductType=ReadBlobLSBShort(image);\n  Header.FileType=ReadBlobLSBShort(image);\n  Header.MajorVersion=ReadBlobByte(image);\n  Header.MinorVersion=ReadBlobByte(image);\n  Header.EncryptKey=ReadBlobLSBShort(image);\n  Header.Reserved=ReadBlobLSBShort(image);\n\n  if (Header.FileId!=0x435057FF || (Header.ProductType>>8)!=0x16)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  if (Header.EncryptKey!=0)\n    ThrowReaderException(CoderError,\"EncryptedWPGImageFileNotSupported\");\n\n  image->columns = 1;\n  image->rows = 1;\n  image->colors = 0;\n  bpp=0;\n  BitmapHeader2.RotAngle=0;\n\n  switch(Header.FileType)\n    {\n    case 1:     /* WPG level 1 */\n      while(!EOFBlob(image)) /* object parser loop */\n        {\n          (void) SeekBlob(image,Header.DataOffset,SEEK_SET);\n          if(EOFBlob(image))\n            break;\n\n          Rec.RecType=(i=ReadBlobByte(image));\n          if(i==EOF)\n            break;\n          Rd_WP_DWORD(image,&Rec.RecordLength);\n          if(EOFBlob(image))\n            break;\n\n          Header.DataOffset=TellBlob(image)+Rec.RecordLength;\n\n          switch(Rec.RecType)\n            {\n            case 0x0B: /* bitmap type 1 */\n              BitmapHeader1.Width=ReadBlobLSBShort(image);\n              BitmapHeader1.Height=ReadBlobLSBShort(image);\n              if ((BitmapHeader1.Width == 0) || (BitmapHeader1.Height == 0))\n                ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n              BitmapHeader1.Depth=ReadBlobLSBShort(image);\n              BitmapHeader1.HorzRes=ReadBlobLSBShort(image);\n              BitmapHeader1.VertRes=ReadBlobLSBShort(image);\n\n              if(BitmapHeader1.HorzRes && BitmapHeader1.VertRes)\n                {\n                  image->units=PixelsPerCentimeterResolution;\n                  image->resolution.x=BitmapHeader1.HorzRes/470.0;\n                  image->resolution.y=BitmapHeader1.VertRes/470.0;\n                }\n              image->columns=BitmapHeader1.Width;\n              image->rows=BitmapHeader1.Height;\n              bpp=BitmapHeader1.Depth;\n\n              goto UnpackRaster;\n\n            case 0x0E:  /*Color palette */\n              WPG_Palette.StartIndex=ReadBlobLSBShort(image);\n              WPG_Palette.NumOfEntries=ReadBlobLSBShort(image);\n\n              image->colors=WPG_Palette.NumOfEntries;\n              if (!AcquireImageColormap(image,image->colors,exception))\n                goto NoMemory;\n              for (i=WPG_Palette.StartIndex;\n                   i < (int)WPG_Palette.NumOfEntries; i++)\n                {\n                  image->colormap[i].red=ScaleCharToQuantum((unsigned char)\n                    ReadBlobByte(image));\n                  image->colormap[i].green=ScaleCharToQuantum((unsigned char)\n                    ReadBlobByte(image));\n                  image->colormap[i].blue=ScaleCharToQuantum((unsigned char)\n                    ReadBlobByte(image));\n                }\n              break;\n     \n            case 0x11:  /* Start PS l1 */\n              if(Rec.RecordLength > 8)\n                image=ExtractPostscript(image,image_info,\n                  TellBlob(image)+8,   /* skip PS header in the wpg */\n                  (ssize_t) Rec.RecordLength-8,exception);\n              break;     \n\n            case 0x14:  /* bitmap type 2 */\n              BitmapHeader2.RotAngle=ReadBlobLSBShort(image);\n              BitmapHeader2.LowLeftX=ReadBlobLSBShort(image);\n              BitmapHeader2.LowLeftY=ReadBlobLSBShort(image);\n              BitmapHeader2.UpRightX=ReadBlobLSBShort(image);\n              BitmapHeader2.UpRightY=ReadBlobLSBShort(image);\n              BitmapHeader2.Width=ReadBlobLSBShort(image);\n              BitmapHeader2.Height=ReadBlobLSBShort(image);\n              if ((BitmapHeader2.Width == 0) || (BitmapHeader2.Height == 0))\n                ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n              BitmapHeader2.Depth=ReadBlobLSBShort(image);\n              BitmapHeader2.HorzRes=ReadBlobLSBShort(image);\n              BitmapHeader2.VertRes=ReadBlobLSBShort(image);\n\n              image->units=PixelsPerCentimeterResolution;\n              image->page.width=(unsigned int)\n                ((BitmapHeader2.LowLeftX-BitmapHeader2.UpRightX)/470.0);\n              image->page.height=(unsigned int)\n                ((BitmapHeader2.LowLeftX-BitmapHeader2.UpRightY)/470.0);\n              image->page.x=(int) (BitmapHeader2.LowLeftX/470.0);\n              image->page.y=(int) (BitmapHeader2.LowLeftX/470.0);\n              if(BitmapHeader2.HorzRes && BitmapHeader2.VertRes)\n                {\n                  image->resolution.x=BitmapHeader2.HorzRes/470.0;\n                  image->resolution.y=BitmapHeader2.VertRes/470.0;\n                }\n              image->columns=BitmapHeader2.Width;\n              image->rows=BitmapHeader2.Height;\n              bpp=BitmapHeader2.Depth;\n\n            UnpackRaster:      \n              if ((image->colors == 0) && (bpp != 24))\n                {\n                  image->colors=one << bpp;\n                  if (!AcquireImageColormap(image,image->colors,exception))\n                    {\n                    NoMemory:\n                      ThrowReaderException(ResourceLimitError,\n                        \"MemoryAllocationFailed\");\n                    }\n                  /* printf(\"Load default colormap \\n\"); */\n                  for (i=0; (i < (int) image->colors) && (i < 256); i++)\n                    {               \n                      image->colormap[i].red=ScaleCharToQuantum(WPG1_Palette[i].Red);\n                      image->colormap[i].green=ScaleCharToQuantum(WPG1_Palette[i].Green);\n                      image->colormap[i].blue=ScaleCharToQuantum(WPG1_Palette[i].Blue);\n                    }\n                }\n              else\n                {\n                  if (bpp < 24)\n                    if ( (image->colors < (one << bpp)) && (bpp != 24) )\n                      image->colormap=(PixelInfo *) ResizeQuantumMemory(\n                        image->colormap,(size_t) (one << bpp),\n                        sizeof(*image->colormap));\n                }\n          \n              if (bpp == 1)\n                {\n                  if(image->colormap[0].red==0 &&\n                     image->colormap[0].green==0 &&\n                     image->colormap[0].blue==0 &&\n                     image->colormap[1].red==0 &&\n                     image->colormap[1].green==0 &&\n                     image->colormap[1].blue==0)\n                    {  /* fix crippled monochrome palette */\n                      image->colormap[1].red =\n                        image->colormap[1].green =\n                        image->colormap[1].blue = QuantumRange;\n                    }\n                }      \n\n              if(UnpackWPGRaster(image,bpp,exception) < 0)\n                /* The raster cannot be unpacked */\n                {\n                DecompressionFailed:\n                  ThrowReaderException(CoderError,\"UnableToDecompressImage\");\n                    }\n\n              if(Rec.RecType==0x14 && BitmapHeader2.RotAngle!=0 && !image_info->ping)\n                {  \n                  /* flop command */\n                  if(BitmapHeader2.RotAngle & 0x8000)\n                    {\n                      Image\n                        *flop_image;\n\n                      flop_image = FlopImage(image, exception);\n                      if (flop_image != (Image *) NULL) {\n                        DuplicateBlob(flop_image,image);\n                        (void) RemoveLastImageFromList(&image);\n                        AppendImageToList(&image,flop_image);\n                      }\n                    }\n                  /* flip command */\n                  if(BitmapHeader2.RotAngle & 0x2000)\n                    {\n                      Image\n                        *flip_image;\n\n                      flip_image = FlipImage(image, exception);\n                      if (flip_image != (Image *) NULL) {\n                        DuplicateBlob(flip_image,image);\n                        (void) RemoveLastImageFromList(&image);\n                        AppendImageToList(&image,flip_image);    \n                      }\n                    }\n    \n      /* rotate command */\n                  if(BitmapHeader2.RotAngle & 0x0FFF)\n                    {\n                      Image\n                        *rotate_image;\n\n                      rotate_image=RotateImage(image,(BitmapHeader2.RotAngle &\n                        0x0FFF), exception);\n                      if (rotate_image != (Image *) NULL) {\n                        DuplicateBlob(rotate_image,image);\n                        (void) RemoveLastImageFromList(&image);\n                        AppendImageToList(&image,rotate_image);    \n                      }\n                    }                \n                }\n\n              /* Allocate next image structure. */\n              AcquireNextImage(image_info,image,exception);\n              image->depth=8;\n              if (image->next == (Image *) NULL)\n                goto Finish;\n              image=SyncNextImageInList(image);\n              image->columns=image->rows=0;\n              image->colors=0;\n              break;\n\n            case 0x1B:  /* Postscript l2 */\n              if(Rec.RecordLength>0x3C)\n                image=ExtractPostscript(image,image_info,\n                  TellBlob(image)+0x3C,   /* skip PS l2 header in the wpg */\n                  (ssize_t) Rec.RecordLength-0x3C,exception);\n              break;\n            }\n        }\n      break;\n\n    case 2:  /* WPG level 2 */\n      (void) memset(CTM,0,sizeof(CTM));\n      StartWPG.PosSizePrecision = 0;\n      while(!EOFBlob(image)) /* object parser loop */\n        {\n          (void) SeekBlob(image,Header.DataOffset,SEEK_SET);\n          if(EOFBlob(image))\n            break;\n\n          Rec2.Class=(i=ReadBlobByte(image));\n          if(i==EOF)\n            break;\n          Rec2.RecType=(i=ReadBlobByte(image));\n          if(i==EOF)\n            break;\n          Rd_WP_DWORD(image,&Rec2.Extension);\n          Rd_WP_DWORD(image,&Rec2.RecordLength);\n          if(EOFBlob(image))\n            break;\n\n          Header.DataOffset=TellBlob(image)+Rec2.RecordLength;\n\n          switch(Rec2.RecType)\n            {\n      case 1:\n              StartWPG.HorizontalUnits=ReadBlobLSBShort(image);\n              StartWPG.VerticalUnits=ReadBlobLSBShort(image);\n              StartWPG.PosSizePrecision=ReadBlobByte(image);\n              break;\n            case 0x0C:    /* Color palette */\n              WPG_Palette.StartIndex=ReadBlobLSBShort(image);\n              WPG_Palette.NumOfEntries=ReadBlobLSBShort(image);\n\n              image->colors=WPG_Palette.NumOfEntries;\n              if (AcquireImageColormap(image,image->colors,exception) == MagickFalse)\n                ThrowReaderException(ResourceLimitError,\n                  \"MemoryAllocationFailed\");\n              for (i=WPG_Palette.StartIndex;\n                   i < (int)WPG_Palette.NumOfEntries; i++)\n                {\n                  image->colormap[i].red=ScaleCharToQuantum((char)\n                    ReadBlobByte(image));\n                  image->colormap[i].green=ScaleCharToQuantum((char)\n                    ReadBlobByte(image));\n                  image->colormap[i].blue=ScaleCharToQuantum((char)\n                    ReadBlobByte(image));\n                  (void) ReadBlobByte(image);   /*Opacity??*/\n                }\n              break;\n            case 0x0E:\n              Bitmap2Header1.Width=ReadBlobLSBShort(image);\n              Bitmap2Header1.Height=ReadBlobLSBShort(image);\n              if ((Bitmap2Header1.Width == 0) || (Bitmap2Header1.Height == 0))\n                ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n              Bitmap2Header1.Depth=ReadBlobByte(image);\n              Bitmap2Header1.Compression=ReadBlobByte(image);\n\n              if(Bitmap2Header1.Compression > 1)\n                continue; /*Unknown compression method */\n              switch(Bitmap2Header1.Depth)\n                {\n                case 1:\n                  bpp=1;\n                  break;\n                case 2:\n                  bpp=2;\n                  break;\n                case 3:\n                  bpp=4;\n                  break;\n                case 4:\n                  bpp=8;\n                  break;\n                case 8:\n                  bpp=24;\n                  break;\n                default:\n                  continue;  /*Ignore raster with unknown depth*/\n                }\n              image->columns=Bitmap2Header1.Width;\n              image->rows=Bitmap2Header1.Height;  \n\n              if ((image->colors == 0) && (bpp != 24))\n                {\n                  size_t\n                    one;\n\n                  one=1;\n                  image->colors=one << bpp;\n                  if (!AcquireImageColormap(image,image->colors,exception))\n                    goto NoMemory;\n                }\n              else\n                {\n                  if(bpp < 24)\n                    if( image->colors<(one << bpp) && bpp!=24 )\n                      image->colormap=(PixelInfo *) ResizeQuantumMemory(\n                       image->colormap,(size_t) (one << bpp),\n                       sizeof(*image->colormap));\n                }\n\n\n              switch(Bitmap2Header1.Compression)\n                {\n                case 0:    /*Uncompressed raster*/\n                  {\n                    ldblk=(ssize_t) ((bpp*image->columns+7)/8);\n                    BImgBuff=(unsigned char *) AcquireQuantumMemory((size_t)\n                      ldblk,sizeof(*BImgBuff));\n                    if (BImgBuff == (unsigned char *) NULL)\n                      goto NoMemory;\n\n                    for(i=0; i< (ssize_t) image->rows; i++)\n                      {\n                        (void) ReadBlob(image,ldblk,BImgBuff);\n                        InsertRow(image,BImgBuff,i,bpp,exception);\n                      }\n\n                    if(BImgBuff)\n                      BImgBuff=(unsigned char *) RelinquishMagickMemory(BImgBuff);;\n                    break;\n                  }\n                case 1:    /*RLE for WPG2 */\n                  {\n                    if( UnpackWPG2Raster(image,bpp,exception) < 0)\n                      goto DecompressionFailed;\n                    break;\n                  }   \n                }\n\n              if(CTM[0][0]<0 && !image_info->ping)\n                {    /*?? RotAngle=360-RotAngle;*/\n                  Image\n                    *flop_image;\n\n                  flop_image = FlopImage(image, exception);\n                  if (flop_image != (Image *) NULL) {\n                    DuplicateBlob(flop_image,image);\n                    (void) RemoveLastImageFromList(&image);\n                    AppendImageToList(&image,flop_image);\n                  }\n                  /* Try to change CTM according to Flip - I am not sure, must be checked.      \n                     Tx(0,0)=-1;      Tx(1,0)=0;   Tx(2,0)=0;\n                     Tx(0,1)= 0;      Tx(1,1)=1;   Tx(2,1)=0;\n                     Tx(0,2)=(WPG._2Rect.X_ur+WPG._2Rect.X_ll);\n                     Tx(1,2)=0;   Tx(2,2)=1; */                  \n                }\n              if(CTM[1][1]<0 && !image_info->ping)\n                {    /*?? RotAngle=360-RotAngle;*/\n                  Image\n                    *flip_image;\n\n                   flip_image = FlipImage(image, exception);\n                   if (flip_image != (Image *) NULL) {\n                     DuplicateBlob(flip_image,image);\n                     (void) RemoveLastImageFromList(&image);\n                     AppendImageToList(&image,flip_image);\n                    }\n                  /* Try to change CTM according to Flip - I am not sure, must be checked.\n                     float_matrix Tx(3,3);\n                     Tx(0,0)= 1;   Tx(1,0)= 0;   Tx(2,0)=0;\n                     Tx(0,1)= 0;   Tx(1,1)=-1;   Tx(2,1)=0;\n                     Tx(0,2)= 0;   Tx(1,2)=(WPG._2Rect.Y_ur+WPG._2Rect.Y_ll);\n                     Tx(2,2)=1; */      \n              }    \n    \n\n              /* Allocate next image structure. */\n              AcquireNextImage(image_info,image,exception);\n              image->depth=8;\n              if (image->next == (Image *) NULL)\n                goto Finish;\n              image=SyncNextImageInList(image);\n              image->columns=image->rows=1;\n              image->colors=0;\n              break;\n\n            case 0x12:  /* Postscript WPG2*/\n        i=ReadBlobLSBShort(image);\n              if(Rec2.RecordLength > (unsigned int) i)\n                image=ExtractPostscript(image,image_info,\n                  TellBlob(image)+i,    /*skip PS header in the wpg2*/\n                  (ssize_t) (Rec2.RecordLength-i-2),exception);\n              break;\n\n      case 0x1B:          /*bitmap rectangle*/\n              WPG2Flags = LoadWPG2Flags(image,StartWPG.PosSizePrecision,NULL,&CTM);\n              (void) WPG2Flags;\n              break;\n            }\n        }\n\n      break;\n\n    default:\n      {\n         ThrowReaderException(CoderError,\"DataEncodingSchemeIsNotSupported\");\n      }\n   }\n  status=SetImageExtent(image,image->columns,image->rows,exception);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n\n Finish:\n  (void) CloseBlob(image);\n\n  {\n    Image\n      *p;\n\n    ssize_t\n      scene=0;\n\n    /*\n      Rewind list, removing any empty images while rewinding.\n    */\n    p=image;\n    image=NULL;\n    while (p != (Image *) NULL)\n      {\n        Image *tmp=p;\n        if ((p->rows == 0) || (p->columns == 0)) {\n          p=p->previous;\n          DeleteImageFromList(&tmp);\n        } else {\n          image=p;\n          p=p->previous;\n        }\n      }\n    /*\n      Fix scene numbers.\n    */\n    for (p=image; p != (Image *) NULL; p=p->next)\n      p->scene=(size_t) scene++;\n  }\n  if (image == (Image *) NULL)\n    ThrowReaderException(CorruptImageError,\n      \"ImageFileDoesNotContainAnyImageData\");\n  return(image);\n}", "func_src_after": "static Image *ReadWPGImage(const ImageInfo *image_info,\n  ExceptionInfo *exception)\n{\n  typedef struct\n  {\n    size_t FileId;\n    MagickOffsetType DataOffset;\n    unsigned int ProductType;\n    unsigned int FileType;\n    unsigned char MajorVersion;\n    unsigned char MinorVersion;\n    unsigned int EncryptKey;\n    unsigned int Reserved;\n  } WPGHeader;\n\n  typedef struct\n  {\n    unsigned char RecType;\n    size_t RecordLength;\n  } WPGRecord;\n\n  typedef struct\n  {\n    unsigned char Class;\n    unsigned char RecType;\n    size_t Extension;\n    size_t RecordLength;\n  } WPG2Record;\n\n  typedef struct\n  {\n    unsigned  HorizontalUnits;\n    unsigned  VerticalUnits;\n    unsigned char PosSizePrecision;\n  } WPG2Start;\n\n  typedef struct\n  {\n    unsigned int Width;\n    unsigned int Height;\n    unsigned int Depth;\n    unsigned int HorzRes;\n    unsigned int VertRes;\n  } WPGBitmapType1;\n\n  typedef struct\n  {\n    unsigned int Width;\n    unsigned int Height;\n    unsigned char Depth;\n    unsigned char Compression;\n  } WPG2BitmapType1;\n\n  typedef struct\n  {\n    unsigned int RotAngle;\n    unsigned int LowLeftX;\n    unsigned int LowLeftY;\n    unsigned int UpRightX;\n    unsigned int UpRightY;\n    unsigned int Width;\n    unsigned int Height;\n    unsigned int Depth;\n    unsigned int HorzRes;\n    unsigned int VertRes;\n  } WPGBitmapType2;\n\n  typedef struct\n  {\n    unsigned int StartIndex;\n    unsigned int NumOfEntries;\n  } WPGColorMapRec;\n\n  /*\n  typedef struct {\n    size_t PS_unknown1;\n    unsigned int PS_unknown2;\n    unsigned int PS_unknown3;\n  } WPGPSl1Record;  \n  */\n\n  Image\n    *image;\n\n  unsigned int\n    status;\n\n  WPGHeader\n    Header;\n\n  WPGRecord\n    Rec;\n\n  WPG2Record\n    Rec2;\n\n  WPG2Start StartWPG;\n\n  WPGBitmapType1\n    BitmapHeader1;\n\n  WPG2BitmapType1\n    Bitmap2Header1;\n\n  WPGBitmapType2\n    BitmapHeader2;\n\n  WPGColorMapRec\n    WPG_Palette;\n\n  int\n    i,\n    bpp,\n    WPG2Flags;\n\n  ssize_t\n    ldblk;\n\n  size_t\n    one;\n\n  unsigned char\n    *BImgBuff;\n\n  tCTM CTM;         /*current transform matrix*/\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  one=1;\n  image=AcquireImage(image_info,exception);\n  image->depth=8;\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read WPG image.\n  */\n  Header.FileId=ReadBlobLSBLong(image);\n  Header.DataOffset=(MagickOffsetType) ReadBlobLSBLong(image);\n  Header.ProductType=ReadBlobLSBShort(image);\n  Header.FileType=ReadBlobLSBShort(image);\n  Header.MajorVersion=ReadBlobByte(image);\n  Header.MinorVersion=ReadBlobByte(image);\n  Header.EncryptKey=ReadBlobLSBShort(image);\n  Header.Reserved=ReadBlobLSBShort(image);\n\n  if (Header.FileId!=0x435057FF || (Header.ProductType>>8)!=0x16)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  if (Header.EncryptKey!=0)\n    ThrowReaderException(CoderError,\"EncryptedWPGImageFileNotSupported\");\n\n  image->columns = 1;\n  image->rows = 1;\n  image->colors = 0;\n  bpp=0;\n  BitmapHeader2.RotAngle=0;\n\n  switch(Header.FileType)\n    {\n    case 1:     /* WPG level 1 */\n      while(!EOFBlob(image)) /* object parser loop */\n        {\n          (void) SeekBlob(image,Header.DataOffset,SEEK_SET);\n          if(EOFBlob(image))\n            break;\n\n          Rec.RecType=(i=ReadBlobByte(image));\n          if(i==EOF)\n            break;\n          Rd_WP_DWORD(image,&Rec.RecordLength);\n          if(EOFBlob(image))\n            break;\n\n          Header.DataOffset=TellBlob(image)+Rec.RecordLength;\n\n          switch(Rec.RecType)\n            {\n            case 0x0B: /* bitmap type 1 */\n              BitmapHeader1.Width=ReadBlobLSBShort(image);\n              BitmapHeader1.Height=ReadBlobLSBShort(image);\n              if ((BitmapHeader1.Width == 0) || (BitmapHeader1.Height == 0))\n                ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n              BitmapHeader1.Depth=ReadBlobLSBShort(image);\n              BitmapHeader1.HorzRes=ReadBlobLSBShort(image);\n              BitmapHeader1.VertRes=ReadBlobLSBShort(image);\n\n              if(BitmapHeader1.HorzRes && BitmapHeader1.VertRes)\n                {\n                  image->units=PixelsPerCentimeterResolution;\n                  image->resolution.x=BitmapHeader1.HorzRes/470.0;\n                  image->resolution.y=BitmapHeader1.VertRes/470.0;\n                }\n              image->columns=BitmapHeader1.Width;\n              image->rows=BitmapHeader1.Height;\n              bpp=BitmapHeader1.Depth;\n\n              goto UnpackRaster;\n\n            case 0x0E:  /*Color palette */\n              WPG_Palette.StartIndex=ReadBlobLSBShort(image);\n              WPG_Palette.NumOfEntries=ReadBlobLSBShort(image);\n\n              image->colors=WPG_Palette.NumOfEntries;\n              if (!AcquireImageColormap(image,image->colors,exception))\n                goto NoMemory;\n              for (i=WPG_Palette.StartIndex;\n                   i < (int)WPG_Palette.NumOfEntries; i++)\n                {\n                  image->colormap[i].red=ScaleCharToQuantum((unsigned char)\n                    ReadBlobByte(image));\n                  image->colormap[i].green=ScaleCharToQuantum((unsigned char)\n                    ReadBlobByte(image));\n                  image->colormap[i].blue=ScaleCharToQuantum((unsigned char)\n                    ReadBlobByte(image));\n                }\n              break;\n     \n            case 0x11:  /* Start PS l1 */\n              if(Rec.RecordLength > 8)\n                image=ExtractPostscript(image,image_info,\n                  TellBlob(image)+8,   /* skip PS header in the wpg */\n                  (ssize_t) Rec.RecordLength-8,exception);\n              break;     \n\n            case 0x14:  /* bitmap type 2 */\n              BitmapHeader2.RotAngle=ReadBlobLSBShort(image);\n              BitmapHeader2.LowLeftX=ReadBlobLSBShort(image);\n              BitmapHeader2.LowLeftY=ReadBlobLSBShort(image);\n              BitmapHeader2.UpRightX=ReadBlobLSBShort(image);\n              BitmapHeader2.UpRightY=ReadBlobLSBShort(image);\n              BitmapHeader2.Width=ReadBlobLSBShort(image);\n              BitmapHeader2.Height=ReadBlobLSBShort(image);\n              if ((BitmapHeader2.Width == 0) || (BitmapHeader2.Height == 0))\n                ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n              BitmapHeader2.Depth=ReadBlobLSBShort(image);\n              BitmapHeader2.HorzRes=ReadBlobLSBShort(image);\n              BitmapHeader2.VertRes=ReadBlobLSBShort(image);\n\n              image->units=PixelsPerCentimeterResolution;\n              image->page.width=(unsigned int)\n                ((BitmapHeader2.LowLeftX-BitmapHeader2.UpRightX)/470.0);\n              image->page.height=(unsigned int)\n                ((BitmapHeader2.LowLeftX-BitmapHeader2.UpRightY)/470.0);\n              image->page.x=(int) (BitmapHeader2.LowLeftX/470.0);\n              image->page.y=(int) (BitmapHeader2.LowLeftX/470.0);\n              if(BitmapHeader2.HorzRes && BitmapHeader2.VertRes)\n                {\n                  image->resolution.x=BitmapHeader2.HorzRes/470.0;\n                  image->resolution.y=BitmapHeader2.VertRes/470.0;\n                }\n              image->columns=BitmapHeader2.Width;\n              image->rows=BitmapHeader2.Height;\n              bpp=BitmapHeader2.Depth;\n\n            UnpackRaster:      \n              if ((image->colors == 0) && (bpp != 24))\n                {\n                  image->colors=one << bpp;\n                  if (!AcquireImageColormap(image,image->colors,exception))\n                    {\n                    NoMemory:\n                      ThrowReaderException(ResourceLimitError,\n                        \"MemoryAllocationFailed\");\n                    }\n                  /* printf(\"Load default colormap \\n\"); */\n                  for (i=0; (i < (int) image->colors) && (i < 256); i++)\n                    {               \n                      image->colormap[i].red=ScaleCharToQuantum(WPG1_Palette[i].Red);\n                      image->colormap[i].green=ScaleCharToQuantum(WPG1_Palette[i].Green);\n                      image->colormap[i].blue=ScaleCharToQuantum(WPG1_Palette[i].Blue);\n                    }\n                }\n              else\n                {\n                  if (bpp < 24)\n                    if ( (image->colors < (one << bpp)) && (bpp != 24) )\n                      image->colormap=(PixelInfo *) ResizeQuantumMemory(\n                        image->colormap,(size_t) (one << bpp),\n                        sizeof(*image->colormap));\n                }\n          \n              if (bpp == 1)\n                {\n                  if(image->colormap[0].red==0 &&\n                     image->colormap[0].green==0 &&\n                     image->colormap[0].blue==0 &&\n                     image->colormap[1].red==0 &&\n                     image->colormap[1].green==0 &&\n                     image->colormap[1].blue==0)\n                    {  /* fix crippled monochrome palette */\n                      image->colormap[1].red =\n                        image->colormap[1].green =\n                        image->colormap[1].blue = QuantumRange;\n                    }\n                }      \n\n              if(UnpackWPGRaster(image,bpp,exception) < 0)\n                /* The raster cannot be unpacked */\n                {\n                DecompressionFailed:\n                  ThrowReaderException(CoderError,\"UnableToDecompressImage\");\n                    }\n\n              if(Rec.RecType==0x14 && BitmapHeader2.RotAngle!=0 && !image_info->ping)\n                {  \n                  /* flop command */\n                  if(BitmapHeader2.RotAngle & 0x8000)\n                    {\n                      Image\n                        *flop_image;\n\n                      flop_image = FlopImage(image, exception);\n                      if (flop_image != (Image *) NULL) {\n                        DuplicateBlob(flop_image,image);\n                        (void) RemoveLastImageFromList(&image);\n                        AppendImageToList(&image,flop_image);\n                      }\n                    }\n                  /* flip command */\n                  if(BitmapHeader2.RotAngle & 0x2000)\n                    {\n                      Image\n                        *flip_image;\n\n                      flip_image = FlipImage(image, exception);\n                      if (flip_image != (Image *) NULL) {\n                        DuplicateBlob(flip_image,image);\n                        (void) RemoveLastImageFromList(&image);\n                        AppendImageToList(&image,flip_image);    \n                      }\n                    }\n    \n      /* rotate command */\n                  if(BitmapHeader2.RotAngle & 0x0FFF)\n                    {\n                      Image\n                        *rotate_image;\n\n                      rotate_image=RotateImage(image,(BitmapHeader2.RotAngle &\n                        0x0FFF), exception);\n                      if (rotate_image != (Image *) NULL) {\n                        DuplicateBlob(rotate_image,image);\n                        (void) RemoveLastImageFromList(&image);\n                        AppendImageToList(&image,rotate_image);    \n                      }\n                    }                \n                }\n\n              /* Allocate next image structure. */\n              AcquireNextImage(image_info,image,exception);\n              image->depth=8;\n              if (image->next == (Image *) NULL)\n                goto Finish;\n              image=SyncNextImageInList(image);\n              image->columns=image->rows=0;\n              image->colors=0;\n              break;\n\n            case 0x1B:  /* Postscript l2 */\n              if(Rec.RecordLength>0x3C)\n                image=ExtractPostscript(image,image_info,\n                  TellBlob(image)+0x3C,   /* skip PS l2 header in the wpg */\n                  (ssize_t) Rec.RecordLength-0x3C,exception);\n              break;\n            }\n        }\n      break;\n\n    case 2:  /* WPG level 2 */\n      (void) memset(CTM,0,sizeof(CTM));\n      StartWPG.PosSizePrecision = 0;\n      while(!EOFBlob(image)) /* object parser loop */\n        {\n          (void) SeekBlob(image,Header.DataOffset,SEEK_SET);\n          if(EOFBlob(image))\n            break;\n\n          Rec2.Class=(i=ReadBlobByte(image));\n          if(i==EOF)\n            break;\n          Rec2.RecType=(i=ReadBlobByte(image));\n          if(i==EOF)\n            break;\n          Rd_WP_DWORD(image,&Rec2.Extension);\n          Rd_WP_DWORD(image,&Rec2.RecordLength);\n          if(EOFBlob(image))\n            break;\n\n          Header.DataOffset=TellBlob(image)+Rec2.RecordLength;\n\n          switch(Rec2.RecType)\n            {\n      case 1:\n              StartWPG.HorizontalUnits=ReadBlobLSBShort(image);\n              StartWPG.VerticalUnits=ReadBlobLSBShort(image);\n              StartWPG.PosSizePrecision=ReadBlobByte(image);\n              break;\n            case 0x0C:    /* Color palette */\n              WPG_Palette.StartIndex=ReadBlobLSBShort(image);\n              WPG_Palette.NumOfEntries=ReadBlobLSBShort(image);\n\n              image->colors=WPG_Palette.NumOfEntries;\n              if (AcquireImageColormap(image,image->colors,exception) == MagickFalse)\n                ThrowReaderException(ResourceLimitError,\n                  \"MemoryAllocationFailed\");\n              for (i=WPG_Palette.StartIndex;\n                   i < (int)WPG_Palette.NumOfEntries; i++)\n                {\n                  image->colormap[i].red=ScaleCharToQuantum((char)\n                    ReadBlobByte(image));\n                  image->colormap[i].green=ScaleCharToQuantum((char)\n                    ReadBlobByte(image));\n                  image->colormap[i].blue=ScaleCharToQuantum((char)\n                    ReadBlobByte(image));\n                  (void) ReadBlobByte(image);   /*Opacity??*/\n                }\n              break;\n            case 0x0E:\n              Bitmap2Header1.Width=ReadBlobLSBShort(image);\n              Bitmap2Header1.Height=ReadBlobLSBShort(image);\n              if ((Bitmap2Header1.Width == 0) || (Bitmap2Header1.Height == 0))\n                ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n              Bitmap2Header1.Depth=ReadBlobByte(image);\n              Bitmap2Header1.Compression=ReadBlobByte(image);\n\n              if(Bitmap2Header1.Compression > 1)\n                continue; /*Unknown compression method */\n              switch(Bitmap2Header1.Depth)\n                {\n                case 1:\n                  bpp=1;\n                  break;\n                case 2:\n                  bpp=2;\n                  break;\n                case 3:\n                  bpp=4;\n                  break;\n                case 4:\n                  bpp=8;\n                  break;\n                case 8:\n                  bpp=24;\n                  break;\n                default:\n                  continue;  /*Ignore raster with unknown depth*/\n                }\n              image->columns=Bitmap2Header1.Width;\n              image->rows=Bitmap2Header1.Height;  \n\n              if ((image->colors == 0) && (bpp != 24))\n                {\n                  size_t\n                    one;\n\n                  one=1;\n                  image->colors=one << bpp;\n                  if (!AcquireImageColormap(image,image->colors,exception))\n                    goto NoMemory;\n                }\n              else\n                {\n                  if(bpp < 24)\n                    if( image->colors<(one << bpp) && bpp!=24 )\n                      image->colormap=(PixelInfo *) ResizeQuantumMemory(\n                       image->colormap,(size_t) (one << bpp),\n                       sizeof(*image->colormap));\n                }\n\n\n              switch(Bitmap2Header1.Compression)\n                {\n                case 0:    /*Uncompressed raster*/\n                  {\n                    ldblk=(ssize_t) ((bpp*image->columns+7)/8);\n                    BImgBuff=(unsigned char *) AcquireQuantumMemory((size_t)\n                      ldblk+1,sizeof(*BImgBuff));\n                    if (BImgBuff == (unsigned char *) NULL)\n                      goto NoMemory;\n\n                    for(i=0; i< (ssize_t) image->rows; i++)\n                      {\n                        (void) ReadBlob(image,ldblk,BImgBuff);\n                        InsertRow(image,BImgBuff,i,bpp,exception);\n                      }\n\n                    if(BImgBuff)\n                      BImgBuff=(unsigned char *) RelinquishMagickMemory(BImgBuff);;\n                    break;\n                  }\n                case 1:    /*RLE for WPG2 */\n                  {\n                    if( UnpackWPG2Raster(image,bpp,exception) < 0)\n                      goto DecompressionFailed;\n                    break;\n                  }   \n                }\n\n              if(CTM[0][0]<0 && !image_info->ping)\n                {    /*?? RotAngle=360-RotAngle;*/\n                  Image\n                    *flop_image;\n\n                  flop_image = FlopImage(image, exception);\n                  if (flop_image != (Image *) NULL) {\n                    DuplicateBlob(flop_image,image);\n                    (void) RemoveLastImageFromList(&image);\n                    AppendImageToList(&image,flop_image);\n                  }\n                  /* Try to change CTM according to Flip - I am not sure, must be checked.      \n                     Tx(0,0)=-1;      Tx(1,0)=0;   Tx(2,0)=0;\n                     Tx(0,1)= 0;      Tx(1,1)=1;   Tx(2,1)=0;\n                     Tx(0,2)=(WPG._2Rect.X_ur+WPG._2Rect.X_ll);\n                     Tx(1,2)=0;   Tx(2,2)=1; */                  \n                }\n              if(CTM[1][1]<0 && !image_info->ping)\n                {    /*?? RotAngle=360-RotAngle;*/\n                  Image\n                    *flip_image;\n\n                   flip_image = FlipImage(image, exception);\n                   if (flip_image != (Image *) NULL) {\n                     DuplicateBlob(flip_image,image);\n                     (void) RemoveLastImageFromList(&image);\n                     AppendImageToList(&image,flip_image);\n                    }\n                  /* Try to change CTM according to Flip - I am not sure, must be checked.\n                     float_matrix Tx(3,3);\n                     Tx(0,0)= 1;   Tx(1,0)= 0;   Tx(2,0)=0;\n                     Tx(0,1)= 0;   Tx(1,1)=-1;   Tx(2,1)=0;\n                     Tx(0,2)= 0;   Tx(1,2)=(WPG._2Rect.Y_ur+WPG._2Rect.Y_ll);\n                     Tx(2,2)=1; */      \n              }    \n    \n\n              /* Allocate next image structure. */\n              AcquireNextImage(image_info,image,exception);\n              image->depth=8;\n              if (image->next == (Image *) NULL)\n                goto Finish;\n              image=SyncNextImageInList(image);\n              image->columns=image->rows=1;\n              image->colors=0;\n              break;\n\n            case 0x12:  /* Postscript WPG2*/\n        i=ReadBlobLSBShort(image);\n              if(Rec2.RecordLength > (unsigned int) i)\n                image=ExtractPostscript(image,image_info,\n                  TellBlob(image)+i,    /*skip PS header in the wpg2*/\n                  (ssize_t) (Rec2.RecordLength-i-2),exception);\n              break;\n\n      case 0x1B:          /*bitmap rectangle*/\n              WPG2Flags = LoadWPG2Flags(image,StartWPG.PosSizePrecision,NULL,&CTM);\n              (void) WPG2Flags;\n              break;\n            }\n        }\n\n      break;\n\n    default:\n      {\n         ThrowReaderException(CoderError,\"DataEncodingSchemeIsNotSupported\");\n      }\n   }\n  status=SetImageExtent(image,image->columns,image->rows,exception);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n\n Finish:\n  (void) CloseBlob(image);\n\n  {\n    Image\n      *p;\n\n    ssize_t\n      scene=0;\n\n    /*\n      Rewind list, removing any empty images while rewinding.\n    */\n    p=image;\n    image=NULL;\n    while (p != (Image *) NULL)\n      {\n        Image *tmp=p;\n        if ((p->rows == 0) || (p->columns == 0)) {\n          p=p->previous;\n          DeleteImageFromList(&tmp);\n        } else {\n          image=p;\n          p=p->previous;\n        }\n      }\n    /*\n      Fix scene numbers.\n    */\n    for (p=image; p != (Image *) NULL; p=p->next)\n      p->scene=(size_t) scene++;\n  }\n  if (image == (Image *) NULL)\n    ThrowReaderException(CorruptImageError,\n      \"ImageFileDoesNotContainAnyImageData\");\n  return(image);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/bef1e4f637d8f665bc133a9c6d30df08d983bc3a", "file_name": "coders/wpg.c", "vul_type": "cwe-125", "description": "Write a C function to read and process WPG images."}
{"func_name": "exprListAppendList", "func_src_before": "static ExprList *exprListAppendList(\n  Parse *pParse,          /* Parsing context */\n  ExprList *pList,        /* List to which to append. Might be NULL */\n  ExprList *pAppend,      /* List of values to append. Might be NULL */\n  int bIntToNull\n){\n  if( pAppend ){\n    int i;\n    int nInit = pList ? pList->nExpr : 0;\n    for(i=0; i<pAppend->nExpr; i++){\n      Expr *pDup = sqlite3ExprDup(pParse->db, pAppend->a[i].pExpr, 0);\n      if( bIntToNull && pDup && pDup->op==TK_INTEGER ){\n        pDup->op = TK_NULL;\n        pDup->flags &= ~(EP_IntValue|EP_IsTrue|EP_IsFalse);\n      }\n      pList = sqlite3ExprListAppend(pParse, pList, pDup);\n      if( pList ) pList->a[nInit+i].sortFlags = pAppend->a[i].sortFlags;\n    }\n  }\n  return pList;\n}", "func_src_after": "static ExprList *exprListAppendList(\n  Parse *pParse,          /* Parsing context */\n  ExprList *pList,        /* List to which to append. Might be NULL */\n  ExprList *pAppend,      /* List of values to append. Might be NULL */\n  int bIntToNull\n){\n  if( pAppend ){\n    int i;\n    int nInit = pList ? pList->nExpr : 0;\n    for(i=0; i<pAppend->nExpr; i++){\n      Expr *pDup = sqlite3ExprDup(pParse->db, pAppend->a[i].pExpr, 0);\n      assert( pDup==0 || !ExprHasProperty(pDup, EP_MemToken) );\n      if( bIntToNull && pDup && pDup->op==TK_INTEGER ){\n        pDup->op = TK_NULL;\n        pDup->flags &= ~(EP_IntValue|EP_IsTrue|EP_IsFalse);\n        pDup->u.zToken = 0;\n      }\n      pList = sqlite3ExprListAppend(pParse, pList, pDup);\n      if( pList ) pList->a[nInit+i].sortFlags = pAppend->a[i].sortFlags;\n    }\n  }\n  return pList;\n}", "commit_link": "github.com/sqlite/sqlite/commit/75e95e1fcd52d3ec8282edb75ac8cd0814095d54", "file_name": "src/window.c", "vul_type": "cwe-476", "description": "Write a C function to append one expression list to another in SQLite, with an option to convert integers to NULL."}
{"func_name": "reportMatch", "func_src_before": "def reportMatch(winner, loser):\n    \"\"\"Records the outcome of a single match between two players.\n\n    Args:\n      winner:  the id number of the player who won\n      loser:  the id number of the player who lost\n    \"\"\"\n    try:\n        int(winner)\n        int(loser)\n    except ValueError:\n        raise ValueError(\n            \"\\\"winner\\\" and/or \\\"loser\\\" input are not integers.\\n\"\n            \"Please use the id number of each player to report match results.\"\n        )\n    w = str(winner)\n    l = str(loser)\n    db = connect()\n    c = db.cursor()\n    statement = \"INSERT INTO matches values ({w}, {l})\".format(w=w, l=l)\n    c.execute(statement)\n    db.commit()\n    db.close()", "func_src_after": "def reportMatch(winner, loser):\n    \"\"\"Records the outcome of a single match between two players.\n\n    Args:\n      winner:  the id number of the player who won\n      loser:  the id number of the player who lost\n    \"\"\"\n    try:\n        int(winner)\n        int(loser)\n    except ValueError:\n        raise ValueError(\n            \"\\\"winner\\\" and/or \\\"loser\\\" input are not integers.\\n\"\n            \"Please use the id number of each player to report match results.\"\n        )\n    w = str(winner)\n    l = str(loser)\n    db = connect()\n    c = db.cursor()\n    c.execute(\"INSERT INTO matches values (%s, %s)\", (w,l))\n    db.commit()\n    db.close()", "commit_link": "github.com/tdnelson2/tournament-db/commit/00f3caeed0e12e806c2808d100908698777d9e98", "file_name": "tournament.py", "vul_type": "cwe-089", "description": "Write a Python function to record the outcome of a match by inserting the winner and loser IDs into a database."}
{"func_name": "(anonymous)", "func_src_before": "                $(document.body).on('click', '.modal-trigger-inline', function (e) {\n                    e.preventDefault();\n                    var modalElement = $('#modal-inline');\n                    var eventTrigger = $(this);\n\n                    if (eventTrigger.attr('title')) {\n                        $('.modal-title', modalElement).html(eventTrigger.attr('title'));\n                    }\n\n                    $('.modal-body', modalElement).html('').show().load(eventTrigger.attr('href'), function () {\n                        setTimeout(CMS.attach.formEnhancements, 200);\n                    });\n\n                    modalElement.modal();\n                });", "func_src_after": "                $(document.body).on('click', '.modal-trigger-inline', function (e) {\n                    e.preventDefault();\n                    var modalElement = $('#modal-inline');\n                    var eventTrigger = $(this);\n\n                    if (eventTrigger.attr('title')) {\n                        $('.modal-title', modalElement).text(eventTrigger.attr('title'));\n                    }\n\n                    $('.modal-body', modalElement).html('').show().load(eventTrigger.attr('href'), function () {\n                        setTimeout(CMS.attach.formEnhancements, 200);\n                    });\n\n                    modalElement.modal();\n                });", "line_changes": {"deleted": [{"line_no": 7, "char_start": 287, "char_end": 377, "line": "                        $('.modal-title', modalElement).html(eventTrigger.attr('title'));\n"}], "added": [{"line_no": 7, "char_start": 287, "char_end": 377, "line": "                        $('.modal-title', modalElement).text(eventTrigger.attr('title'));\n"}]}, "char_changes": {"deleted": [{"char_start": 343, "char_end": 347, "chars": "html"}], "added": [{"char_start": 343, "char_end": 347, "chars": "text"}]}, "commit_link": "github.com/WeAreAthlon/silla.io/commit/5a251701f8dc73d1cd9a421d31295edef1faa9b4", "file_name": "cms.silla.js", "vul_type": "cwe-079", "commit_msg": "Prevent XSS in resource titles set as Modal titles", "description": "Create a jQuery script that opens a modal with content loaded from the clicked element's href attribute and optionally sets the modal's title."}
{"func_name": "xsltKeyFunction", "func_src_before": "xsltKeyFunction(xmlXPathParserContextPtr ctxt, int nargs){\n    xmlXPathObjectPtr obj1, obj2;\n\n    if (nargs != 2) {\n\txsltTransformError(xsltXPathGetTransformContext(ctxt), NULL, NULL,\n\t\t\"key() : expects two arguments\\n\");\n\tctxt->error = XPATH_INVALID_ARITY;\n\treturn;\n    }\n\n    /*\n    * Get the key's value.\n    */\n    obj2 = valuePop(ctxt);\n    xmlXPathStringFunction(ctxt, 1);\n    if ((obj2 == NULL) ||\n\t(ctxt->value == NULL) || (ctxt->value->type != XPATH_STRING)) {\n\txsltTransformError(xsltXPathGetTransformContext(ctxt), NULL, NULL,\n\t    \"key() : invalid arg expecting a string\\n\");\n\tctxt->error = XPATH_INVALID_TYPE;\n\txmlXPathFreeObject(obj2);\n\n\treturn;\n    }\n    /*\n    * Get the key's name.\n    */\n    obj1 = valuePop(ctxt);\n\n    if ((obj2->type == XPATH_NODESET) || (obj2->type == XPATH_XSLT_TREE)) {\n\tint i;\n\txmlXPathObjectPtr newobj, ret;\n\n\tret = xmlXPathNewNodeSet(NULL);\n\n\tif (obj2->nodesetval != NULL) {\n\t    for (i = 0; i < obj2->nodesetval->nodeNr; i++) {\n\t\tvaluePush(ctxt, xmlXPathObjectCopy(obj1));\n\t\tvaluePush(ctxt,\n\t\t\t  xmlXPathNewNodeSet(obj2->nodesetval->nodeTab[i]));\n\t\txmlXPathStringFunction(ctxt, 1);\n\t\txsltKeyFunction(ctxt, 2);\n\t\tnewobj = valuePop(ctxt);\n                if (newobj != NULL)\n\t\t    ret->nodesetval = xmlXPathNodeSetMerge(ret->nodesetval,\n\t\t\t\t\t\t           newobj->nodesetval);\n\t\txmlXPathFreeObject(newobj);\n\t    }\n\t}\n\tvaluePush(ctxt, ret);\n    } else {\n\txmlNodeSetPtr nodelist = NULL;\n\txmlChar *key = NULL, *value;\n\tconst xmlChar *keyURI;\n\txsltTransformContextPtr tctxt;\n\txmlChar *qname, *prefix;\n\txmlXPathContextPtr xpctxt = ctxt->context;\n\txmlNodePtr tmpNode = NULL;\n\txsltDocumentPtr oldDocInfo;\n\n\ttctxt = xsltXPathGetTransformContext(ctxt);\n\n\toldDocInfo = tctxt->document;\n\n\tif (xpctxt->node == NULL) {\n\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\"Internal error in xsltKeyFunction(): \"\n\t\t\"The context node is not set on the XPath context.\\n\");\n\t    tctxt->state = XSLT_STATE_STOPPED;\n\t    goto error;\n\t}\n\t/*\n\t * Get the associated namespace URI if qualified name\n\t */\n\tqname = obj1->stringval;\n\tkey = xmlSplitQName2(qname, &prefix);\n\tif (key == NULL) {\n\t    key = xmlStrdup(obj1->stringval);\n\t    keyURI = NULL;\n\t    if (prefix != NULL)\n\t\txmlFree(prefix);\n\t} else {\n\t    if (prefix != NULL) {\n\t\tkeyURI = xmlXPathNsLookup(xpctxt, prefix);\n\t\tif (keyURI == NULL) {\n\t\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\t\"key() : prefix %s is not bound\\n\", prefix);\n\t\t    /*\n\t\t    * TODO: Shouldn't we stop here?\n\t\t    */\n\t\t}\n\t\txmlFree(prefix);\n\t    } else {\n\t\tkeyURI = NULL;\n\t    }\n\t}\n\n\t/*\n\t * Force conversion of first arg to string\n\t */\n\tvaluePush(ctxt, obj2);\n\txmlXPathStringFunction(ctxt, 1);\n\tobj2 = valuePop(ctxt);\n\tif ((obj2 == NULL) || (obj2->type != XPATH_STRING)) {\n\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\"key() : invalid arg expecting a string\\n\");\n\t    ctxt->error = XPATH_INVALID_TYPE;\n\t    goto error;\n\t}\n\tvalue = obj2->stringval;\n\n\t/*\n\t* We need to ensure that ctxt->document is available for\n\t* xsltGetKey().\n\t* First find the relevant doc, which is the context node's\n\t* owner doc; using context->doc is not safe, since\n\t* the doc could have been acquired via the document() function,\n\t* or the doc might be a Result Tree Fragment.\n\t* FUTURE INFO: In XSLT 2.0 the key() function takes an additional\n\t* argument indicating the doc to use.\n\t*/\n\tif (xpctxt->node->type == XML_NAMESPACE_DECL) {\n\t    /*\n\t    * REVISIT: This is a libxml hack! Check xpath.c for details.\n\t    * The XPath module sets the owner element of a ns-node on\n\t    * the ns->next field.\n\t    */\n\t    if ((((xmlNsPtr) xpctxt->node)->next != NULL) &&\n\t\t(((xmlNsPtr) xpctxt->node)->next->type == XML_ELEMENT_NODE))\n\t    {\n\t\ttmpNode = (xmlNodePtr) ((xmlNsPtr) xpctxt->node)->next;\n\t    }\n\t} else\n\t    tmpNode = xpctxt->node;\n\n\tif ((tmpNode == NULL) || (tmpNode->doc == NULL)) {\n\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\"Internal error in xsltKeyFunction(): \"\n\t\t\"Couldn't get the doc of the XPath context node.\\n\");\n\t    goto error;\n\t}\n\n\tif ((tctxt->document == NULL) ||\n\t    (tctxt->document->doc != tmpNode->doc))\n\t{\n\t    if (tmpNode->doc->name && (tmpNode->doc->name[0] == ' ')) {\n\t\t/*\n\t\t* This is a Result Tree Fragment.\n\t\t*/\n\t\tif (tmpNode->doc->_private == NULL) {\n\t\t    tmpNode->doc->_private = xsltNewDocument(tctxt, tmpNode->doc);\n\t\t    if (tmpNode->doc->_private == NULL)\n\t\t\tgoto error;\n\t\t}\n\t\ttctxt->document = (xsltDocumentPtr) tmpNode->doc->_private;\n\t    } else {\n\t\t/*\n\t\t* May be the initial source doc or a doc acquired via the\n\t\t* document() function.\n\t\t*/\n\t\ttctxt->document = xsltFindDocument(tctxt, tmpNode->doc);\n\t    }\n\t    if (tctxt->document == NULL) {\n\t\txsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t    \"Internal error in xsltKeyFunction(): \"\n\t\t    \"Could not get the document info of a context doc.\\n\");\n\t\ttctxt->state = XSLT_STATE_STOPPED;\n\t\tgoto error;\n\t    }\n\t}\n\t/*\n\t* Get/compute the key value.\n\t*/\n\tnodelist = xsltGetKey(tctxt, key, keyURI, value);\n\nerror:\n\ttctxt->document = oldDocInfo;\n\tvaluePush(ctxt, xmlXPathWrapNodeSet(\n\t    xmlXPathNodeSetMerge(NULL, nodelist)));\n\tif (key != NULL)\n\t    xmlFree(key);\n    }\n\n    if (obj1 != NULL)\n\txmlXPathFreeObject(obj1);\n    if (obj2 != NULL)\n\txmlXPathFreeObject(obj2);\n}", "func_src_after": "xsltKeyFunction(xmlXPathParserContextPtr ctxt, int nargs){\n    xmlXPathObjectPtr obj1, obj2;\n\n    if (nargs != 2) {\n\txsltTransformError(xsltXPathGetTransformContext(ctxt), NULL, NULL,\n\t\t\"key() : expects two arguments\\n\");\n\tctxt->error = XPATH_INVALID_ARITY;\n\treturn;\n    }\n\n    /*\n    * Get the key's value.\n    */\n    obj2 = valuePop(ctxt);\n    xmlXPathStringFunction(ctxt, 1);\n    if ((obj2 == NULL) ||\n\t(ctxt->value == NULL) || (ctxt->value->type != XPATH_STRING)) {\n\txsltTransformError(xsltXPathGetTransformContext(ctxt), NULL, NULL,\n\t    \"key() : invalid arg expecting a string\\n\");\n\tctxt->error = XPATH_INVALID_TYPE;\n\txmlXPathFreeObject(obj2);\n\n\treturn;\n    }\n    /*\n    * Get the key's name.\n    */\n    obj1 = valuePop(ctxt);\n\n    if ((obj2->type == XPATH_NODESET) || (obj2->type == XPATH_XSLT_TREE)) {\n\tint i;\n\txmlXPathObjectPtr newobj, ret;\n\n\tret = xmlXPathNewNodeSet(NULL);\n        if (ret == NULL) {\n            ctxt->error = XPATH_MEMORY_ERROR;\n            xmlXPathFreeObject(obj1);\n            xmlXPathFreeObject(obj2);\n            return;\n        }\n\n\tif (obj2->nodesetval != NULL) {\n\t    for (i = 0; i < obj2->nodesetval->nodeNr; i++) {\n\t\tvaluePush(ctxt, xmlXPathObjectCopy(obj1));\n\t\tvaluePush(ctxt,\n\t\t\t  xmlXPathNewNodeSet(obj2->nodesetval->nodeTab[i]));\n\t\txmlXPathStringFunction(ctxt, 1);\n\t\txsltKeyFunction(ctxt, 2);\n\t\tnewobj = valuePop(ctxt);\n                if (newobj != NULL)\n\t\t    ret->nodesetval = xmlXPathNodeSetMerge(ret->nodesetval,\n\t\t\t\t\t\t           newobj->nodesetval);\n\t\txmlXPathFreeObject(newobj);\n\t    }\n\t}\n\tvaluePush(ctxt, ret);\n    } else {\n\txmlNodeSetPtr nodelist = NULL;\n\txmlChar *key = NULL, *value;\n\tconst xmlChar *keyURI;\n\txsltTransformContextPtr tctxt;\n\txmlChar *qname, *prefix;\n\txmlXPathContextPtr xpctxt = ctxt->context;\n\txmlNodePtr tmpNode = NULL;\n\txsltDocumentPtr oldDocInfo;\n\n\ttctxt = xsltXPathGetTransformContext(ctxt);\n\n\toldDocInfo = tctxt->document;\n\n\tif (xpctxt->node == NULL) {\n\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\"Internal error in xsltKeyFunction(): \"\n\t\t\"The context node is not set on the XPath context.\\n\");\n\t    tctxt->state = XSLT_STATE_STOPPED;\n\t    goto error;\n\t}\n\t/*\n\t * Get the associated namespace URI if qualified name\n\t */\n\tqname = obj1->stringval;\n\tkey = xmlSplitQName2(qname, &prefix);\n\tif (key == NULL) {\n\t    key = xmlStrdup(obj1->stringval);\n\t    keyURI = NULL;\n\t    if (prefix != NULL)\n\t\txmlFree(prefix);\n\t} else {\n\t    if (prefix != NULL) {\n\t\tkeyURI = xmlXPathNsLookup(xpctxt, prefix);\n\t\tif (keyURI == NULL) {\n\t\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\t\"key() : prefix %s is not bound\\n\", prefix);\n\t\t    /*\n\t\t    * TODO: Shouldn't we stop here?\n\t\t    */\n\t\t}\n\t\txmlFree(prefix);\n\t    } else {\n\t\tkeyURI = NULL;\n\t    }\n\t}\n\n\t/*\n\t * Force conversion of first arg to string\n\t */\n\tvaluePush(ctxt, obj2);\n\txmlXPathStringFunction(ctxt, 1);\n\tobj2 = valuePop(ctxt);\n\tif ((obj2 == NULL) || (obj2->type != XPATH_STRING)) {\n\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\"key() : invalid arg expecting a string\\n\");\n\t    ctxt->error = XPATH_INVALID_TYPE;\n\t    goto error;\n\t}\n\tvalue = obj2->stringval;\n\n\t/*\n\t* We need to ensure that ctxt->document is available for\n\t* xsltGetKey().\n\t* First find the relevant doc, which is the context node's\n\t* owner doc; using context->doc is not safe, since\n\t* the doc could have been acquired via the document() function,\n\t* or the doc might be a Result Tree Fragment.\n\t* FUTURE INFO: In XSLT 2.0 the key() function takes an additional\n\t* argument indicating the doc to use.\n\t*/\n\tif (xpctxt->node->type == XML_NAMESPACE_DECL) {\n\t    /*\n\t    * REVISIT: This is a libxml hack! Check xpath.c for details.\n\t    * The XPath module sets the owner element of a ns-node on\n\t    * the ns->next field.\n\t    */\n\t    if ((((xmlNsPtr) xpctxt->node)->next != NULL) &&\n\t\t(((xmlNsPtr) xpctxt->node)->next->type == XML_ELEMENT_NODE))\n\t    {\n\t\ttmpNode = (xmlNodePtr) ((xmlNsPtr) xpctxt->node)->next;\n\t    }\n\t} else\n\t    tmpNode = xpctxt->node;\n\n\tif ((tmpNode == NULL) || (tmpNode->doc == NULL)) {\n\t    xsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t\"Internal error in xsltKeyFunction(): \"\n\t\t\"Couldn't get the doc of the XPath context node.\\n\");\n\t    goto error;\n\t}\n\n\tif ((tctxt->document == NULL) ||\n\t    (tctxt->document->doc != tmpNode->doc))\n\t{\n\t    if (tmpNode->doc->name && (tmpNode->doc->name[0] == ' ')) {\n\t\t/*\n\t\t* This is a Result Tree Fragment.\n\t\t*/\n\t\tif (tmpNode->doc->_private == NULL) {\n\t\t    tmpNode->doc->_private = xsltNewDocument(tctxt, tmpNode->doc);\n\t\t    if (tmpNode->doc->_private == NULL)\n\t\t\tgoto error;\n\t\t}\n\t\ttctxt->document = (xsltDocumentPtr) tmpNode->doc->_private;\n\t    } else {\n\t\t/*\n\t\t* May be the initial source doc or a doc acquired via the\n\t\t* document() function.\n\t\t*/\n\t\ttctxt->document = xsltFindDocument(tctxt, tmpNode->doc);\n\t    }\n\t    if (tctxt->document == NULL) {\n\t\txsltTransformError(tctxt, NULL, tctxt->inst,\n\t\t    \"Internal error in xsltKeyFunction(): \"\n\t\t    \"Could not get the document info of a context doc.\\n\");\n\t\ttctxt->state = XSLT_STATE_STOPPED;\n\t\tgoto error;\n\t    }\n\t}\n\t/*\n\t* Get/compute the key value.\n\t*/\n\tnodelist = xsltGetKey(tctxt, key, keyURI, value);\n\nerror:\n\ttctxt->document = oldDocInfo;\n\tvaluePush(ctxt, xmlXPathWrapNodeSet(\n\t    xmlXPathNodeSetMerge(NULL, nodelist)));\n\tif (key != NULL)\n\t    xmlFree(key);\n    }\n\n    if (obj1 != NULL)\n\txmlXPathFreeObject(obj1);\n    if (obj2 != NULL)\n\txmlXPathFreeObject(obj2);\n}", "commit_link": "github.com/GNOME/libxslt/commit/aab7eedca3c2dcaa1795d6acba38a4c9811d2a75", "file_name": "libxslt/functions.c", "vul_type": "cwe-476", "description": "Write a C function named `xsltKeyFunction` that implements the XSLT key function in libxml2."}
{"func_name": "NeXTDecode", "func_src_before": "NeXTDecode(TIFF* tif, uint8* buf, tmsize_t occ, uint16 s)\n{\n\tstatic const char module[] = \"NeXTDecode\";\n\tunsigned char *bp, *op;\n\ttmsize_t cc;\n\tuint8* row;\n\ttmsize_t scanline, n;\n\n\t(void) s;\n\t/*\n\t * Each scanline is assumed to start off as all\n\t * white (we assume a PhotometricInterpretation\n\t * of ``min-is-black'').\n\t */\n\tfor (op = (unsigned char*) buf, cc = occ; cc-- > 0;)\n\t\t*op++ = 0xff;\n\n\tbp = (unsigned char *)tif->tif_rawcp;\n\tcc = tif->tif_rawcc;\n\tscanline = tif->tif_scanlinesize;\n\tif (occ % scanline)\n\t{\n\t\tTIFFErrorExt(tif->tif_clientdata, module, \"Fractional scanlines cannot be read\");\n\t\treturn (0);\n\t}\n\tfor (row = buf; cc > 0 && occ > 0; occ -= scanline, row += scanline) {\n\t\tn = *bp++, cc--;\n\t\tswitch (n) {\n\t\tcase LITERALROW:\n\t\t\t/*\n\t\t\t * The entire scanline is given as literal values.\n\t\t\t */\n\t\t\tif (cc < scanline)\n\t\t\t\tgoto bad;\n\t\t\t_TIFFmemcpy(row, bp, scanline);\n\t\t\tbp += scanline;\n\t\t\tcc -= scanline;\n\t\t\tbreak;\n\t\tcase LITERALSPAN: {\n\t\t\ttmsize_t off;\n\t\t\t/*\n\t\t\t * The scanline has a literal span that begins at some\n\t\t\t * offset.\n\t\t\t */\n\t\t\tif( cc < 4 )\n\t\t\t\tgoto bad;\n\t\t\toff = (bp[0] * 256) + bp[1];\n\t\t\tn = (bp[2] * 256) + bp[3];\n\t\t\tif (cc < 4+n || off+n > scanline)\n\t\t\t\tgoto bad;\n\t\t\t_TIFFmemcpy(row+off, bp+4, n);\n\t\t\tbp += 4+n;\n\t\t\tcc -= 4+n;\n\t\t\tbreak;\n\t\t}\n\t\tdefault: {\n\t\t\tuint32 npixels = 0, grey;\n\t\t\tuint32 imagewidth = tif->tif_dir.td_imagewidth;\n            if( isTiled(tif) )\n                imagewidth = tif->tif_dir.td_tilewidth;\n\n\t\t\t/*\n\t\t\t * The scanline is composed of a sequence of constant\n\t\t\t * color ``runs''.  We shift into ``run mode'' and\n\t\t\t * interpret bytes as codes of the form\n\t\t\t * <color><npixels> until we've filled the scanline.\n\t\t\t */\n\t\t\top = row;\n\t\t\tfor (;;) {\n\t\t\t\tgrey = (uint32)((n>>6) & 0x3);\n\t\t\t\tn &= 0x3f;\n\t\t\t\t/*\n\t\t\t\t * Ensure the run does not exceed the scanline\n\t\t\t\t * bounds, potentially resulting in a security\n\t\t\t\t * issue.\n\t\t\t\t */\n\t\t\t\twhile (n-- > 0 && npixels < imagewidth)\n\t\t\t\t\tSETPIXEL(op, grey);\n\t\t\t\tif (npixels >= imagewidth)\n\t\t\t\t\tbreak;\n\t\t\t\tif (cc == 0)\n\t\t\t\t\tgoto bad;\n\t\t\t\tn = *bp++, cc--;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\t}\n\t}\n\ttif->tif_rawcp = (uint8*) bp;\n\ttif->tif_rawcc = cc;\n\treturn (1);\nbad:\n\tTIFFErrorExt(tif->tif_clientdata, module, \"Not enough data for scanline %ld\",\n\t    (long) tif->tif_row);\n\treturn (0);\n}", "func_src_after": "NeXTDecode(TIFF* tif, uint8* buf, tmsize_t occ, uint16 s)\n{\n\tstatic const char module[] = \"NeXTDecode\";\n\tunsigned char *bp, *op;\n\ttmsize_t cc;\n\tuint8* row;\n\ttmsize_t scanline, n;\n\n\t(void) s;\n\t/*\n\t * Each scanline is assumed to start off as all\n\t * white (we assume a PhotometricInterpretation\n\t * of ``min-is-black'').\n\t */\n\tfor (op = (unsigned char*) buf, cc = occ; cc-- > 0;)\n\t\t*op++ = 0xff;\n\n\tbp = (unsigned char *)tif->tif_rawcp;\n\tcc = tif->tif_rawcc;\n\tscanline = tif->tif_scanlinesize;\n\tif (occ % scanline)\n\t{\n\t\tTIFFErrorExt(tif->tif_clientdata, module, \"Fractional scanlines cannot be read\");\n\t\treturn (0);\n\t}\n\tfor (row = buf; cc > 0 && occ > 0; occ -= scanline, row += scanline) {\n\t\tn = *bp++, cc--;\n\t\tswitch (n) {\n\t\tcase LITERALROW:\n\t\t\t/*\n\t\t\t * The entire scanline is given as literal values.\n\t\t\t */\n\t\t\tif (cc < scanline)\n\t\t\t\tgoto bad;\n\t\t\t_TIFFmemcpy(row, bp, scanline);\n\t\t\tbp += scanline;\n\t\t\tcc -= scanline;\n\t\t\tbreak;\n\t\tcase LITERALSPAN: {\n\t\t\ttmsize_t off;\n\t\t\t/*\n\t\t\t * The scanline has a literal span that begins at some\n\t\t\t * offset.\n\t\t\t */\n\t\t\tif( cc < 4 )\n\t\t\t\tgoto bad;\n\t\t\toff = (bp[0] * 256) + bp[1];\n\t\t\tn = (bp[2] * 256) + bp[3];\n\t\t\tif (cc < 4+n || off+n > scanline)\n\t\t\t\tgoto bad;\n\t\t\t_TIFFmemcpy(row+off, bp+4, n);\n\t\t\tbp += 4+n;\n\t\t\tcc -= 4+n;\n\t\t\tbreak;\n\t\t}\n\t\tdefault: {\n\t\t\tuint32 npixels = 0, grey;\n\t\t\tuint32 imagewidth = tif->tif_dir.td_imagewidth;\n            if( isTiled(tif) )\n                imagewidth = tif->tif_dir.td_tilewidth;\n            tmsize_t op_offset = 0;\n\n\t\t\t/*\n\t\t\t * The scanline is composed of a sequence of constant\n\t\t\t * color ``runs''.  We shift into ``run mode'' and\n\t\t\t * interpret bytes as codes of the form\n\t\t\t * <color><npixels> until we've filled the scanline.\n\t\t\t */\n\t\t\top = row;\n\t\t\tfor (;;) {\n\t\t\t\tgrey = (uint32)((n>>6) & 0x3);\n\t\t\t\tn &= 0x3f;\n\t\t\t\t/*\n\t\t\t\t * Ensure the run does not exceed the scanline\n\t\t\t\t * bounds, potentially resulting in a security\n\t\t\t\t * issue.\n\t\t\t\t */\n\t\t\t\twhile (n-- > 0 && npixels < imagewidth && op_offset < scanline)\n\t\t\t\t\tSETPIXEL(op, grey);\n\t\t\t\tif (npixels >= imagewidth)\n\t\t\t\t\tbreak;\n                if (op_offset >= scanline ) {\n                    TIFFErrorExt(tif->tif_clientdata, module, \"Invalid data for scanline %ld\",\n                        (long) tif->tif_row);\n                    return (0);\n                }\n\t\t\t\tif (cc == 0)\n\t\t\t\t\tgoto bad;\n\t\t\t\tn = *bp++, cc--;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\t}\n\t}\n\ttif->tif_rawcp = (uint8*) bp;\n\ttif->tif_rawcc = cc;\n\treturn (1);\nbad:\n\tTIFFErrorExt(tif->tif_clientdata, module, \"Not enough data for scanline %ld\",\n\t    (long) tif->tif_row);\n\treturn (0);\n}", "commit_link": "github.com/vadz/libtiff/commit/b18012dae552f85dcc5c57d3bf4e997a15b1cc1c", "file_name": "libtiff/tif_next.c", "vul_type": "cwe-787", "description": "Write a C function named `NeXTDecode` that decodes a scanline from a TIFF image."}
{"func_name": "getPlayer", "func_src_before": "def getPlayer(player):\n\tdb.execute(\"SELECT * FROM players WHERE Name = '%s' COLLATE NOCASE\" % player)\n\tplayerstats = dict(db.fetchone())\n\treturn playerstats", "func_src_after": "def getPlayer(player):\n\tdb.execute(\"SELECT * FROM players WHERE Name = ? COLLATE NOCASE\", player)\n\tplayerstats = dict(db.fetchone())\n\treturn playerstats", "commit_link": "github.com/iScrE4m/XLeague/commit/59cab6e5fd8bd5e47f2418a7c71cb1d4e3cad0d2", "file_name": "plugins/database.py", "vul_type": "cwe-089", "description": "Write a Python function called `getPlayer` that retrieves a player's statistics from a database, ignoring case sensitivity in the player's name."}
{"func_name": "GetAvailablePort", "func_src_before": "func GetAvailablePort(t *testing.T) uint16 {\n\t// Retry has been added for windows as net.Listen can return a port that is not actually available. Details can be\n\t// found in https://github.com/docker/for-win/issues/3171 but to summarize Hyper-V will reserve ranges of ports\n\t// which do not show up under the \"netstat -ano\" but can only be found by\n\t// \"netsh interface ipv4 show excludedportrange protocol=tcp\".  We'll use []exclusions to hold those ranges and\n\t// retry if the port returned by GetAvailableLocalAddress falls in one of those them.\n\tvar exclusions []portpair\n\tportFound := false\n\tvar port string\n\tvar err error\n\tif runtime.GOOS == \"windows\" {\n\t\texclusions = getExclusionsList(t)\n\t}\n\n\tfor !portFound {\n\t\tendpoint := GetAvailableLocalAddress(t)\n\t\t_, port, err = net.SplitHostPort(endpoint)\n\t\trequire.NoError(t, err)\n\t\tportFound = true\n\t\tif runtime.GOOS == \"windows\" {\n\t\t\tfor _, pair := range exclusions {\n\t\t\t\tif port >= pair.first && port <= pair.last {\n\t\t\t\t\tportFound = false\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tportInt, err := strconv.Atoi(port)\n\trequire.NoError(t, err)\n\n\treturn uint16(portInt)\n}", "func_src_after": "func GetAvailablePort(t *testing.T) uint16 {\n\t// Retry has been added for windows as net.Listen can return a port that is not actually available. Details can be\n\t// found in https://github.com/docker/for-win/issues/3171 but to summarize Hyper-V will reserve ranges of ports\n\t// which do not show up under the \"netstat -ano\" but can only be found by\n\t// \"netsh interface ipv4 show excludedportrange protocol=tcp\".  We'll use []exclusions to hold those ranges and\n\t// retry if the port returned by GetAvailableLocalAddress falls in one of those them.\n\tvar exclusions []portpair\n\tportFound := false\n\tvar port string\n\tvar err error\n\tif runtime.GOOS == \"windows\" {\n\t\texclusions = getExclusionsList(t)\n\t}\n\n\tfor !portFound {\n\t\tendpoint := GetAvailableLocalAddress(t)\n\t\t_, port, err = net.SplitHostPort(endpoint)\n\t\trequire.NoError(t, err)\n\t\tportFound = true\n\t\tif runtime.GOOS == \"windows\" {\n\t\t\tfor _, pair := range exclusions {\n\t\t\t\tif port >= pair.first && port <= pair.last {\n\t\t\t\t\tportFound = false\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tportInt, err := strconv.ParseUint(port, 10, 16)\n\trequire.NoError(t, err)\n\n\treturn uint16(portInt)\n}", "line_changes": {"deleted": [{"line_no": 30, "char_start": 1022, "char_end": 1058, "line": "\tportInt, err := strconv.Atoi(port)\n"}], "added": [{"line_no": 30, "char_start": 1022, "char_end": 1071, "line": "\tportInt, err := strconv.ParseUint(port, 10, 16)\n"}]}, "char_changes": {"deleted": [{"char_start": 1047, "char_end": 1056, "chars": "Atoi(port"}], "added": [{"char_start": 1047, "char_end": 1069, "chars": "ParseUint(port, 10, 16"}]}, "commit_link": "github.com/open-telemetry/opentelemetry-collector/commit/eb3601a05900f70e46c058facf16461efa7b09f0", "file_name": "testutil.go", "vul_type": "cwe-681", "commit_msg": "Avoid potential integer overflow (#4277)\n\nSigned-off-by: Bogdan Drutu <bogdandrutu@gmail.com>", "parent_commit": "db6d31e9acc546e043b7b5564377bd76998e74bd", "description": "Write a Go function that finds an available network port, with special handling for Windows due to reserved port ranges."}
{"func_name": "(anonymous)", "func_src_before": "    $(document.body).on(\"keyup change\", \".sr-input\", function(foo) {\n        value = $(this).val();\n        var modalBody = $(this).closest(\"form#streamrule-form\").find(\".modal-body\");\n\n        if (value != undefined && value != \"\") {\n            // Selectbox options can have a custom replace string.\n            s = $(\"option:selected\", this);\n            if (s != undefined && s.attr(\"data-reflect-string\") != undefined && s.attr(\"data-reflect-string\") != \"\") {\n                value = s.attr(\"data-reflect-string\");\n\n                // Inverted?\n                if ($(\"#sr-inverted\", modalBody).is(':checked')) {\n                    value = \"not \" + value;\n                }\n            }\n        } else {\n            value = $(this).attr(\"placeholder\");\n        }\n\n        $($(this).attr(\"data-reflect\"), modalBody).html(value);\n    });", "func_src_after": "    $(document.body).on(\"keyup change\", \".sr-input\", function(foo) {\n        value = $(this).val();\n        var modalBody = $(this).closest(\"form#streamrule-form\").find(\".modal-body\");\n\n        if (value != undefined && value != \"\") {\n            // Selectbox options can have a custom replace string.\n            s = $(\"option:selected\", this);\n            if (s != undefined && s.attr(\"data-reflect-string\") != undefined && s.attr(\"data-reflect-string\") != \"\") {\n                value = s.attr(\"data-reflect-string\");\n\n                // Inverted?\n                if ($(\"#sr-inverted\", modalBody).is(':checked')) {\n                    value = \"not \" + value;\n                }\n            }\n        } else {\n            value = $(this).attr(\"placeholder\");\n        }\n\n        $($(this).attr(\"data-reflect\"), modalBody).text(value);\n    });", "line_changes": {"deleted": [{"line_no": 20, "char_start": 770, "char_end": 834, "line": "        $($(this).attr(\"data-reflect\"), modalBody).html(value);\n"}], "added": [{"line_no": 20, "char_start": 770, "char_end": 834, "line": "        $($(this).attr(\"data-reflect\"), modalBody).text(value);\n"}]}, "char_changes": {"deleted": [{"char_start": 821, "char_end": 825, "chars": "html"}], "added": [{"char_start": 821, "char_end": 825, "chars": "text"}]}, "commit_link": "github.com/edmundoa/graylog2-server/commit/a88cae99955cd0ccdd5d99a1c6d506029eb15c60", "file_name": "streamrules.js", "vul_type": "cwe-079", "commit_msg": "use .text() not .html() in stream rule editor to prevent DOM XSS\n\nfixes #543", "description": "In JavaScript, write a jQuery event handler that updates text in a modal based on user input and selection changes, with special handling for an \"inverted\" checkbox state."}
{"func_name": "HPHP::extractFileTo", "func_src_before": "static bool extractFileTo(zip* zip, const std::string &file, std::string& to,\n                          char* buf, size_t len) {\n  auto sep = file.rfind('/');\n  if (sep != std::string::npos) {\n    auto path = to + file.substr(0, sep);\n    if (!HHVM_FN(is_dir)(path) && !HHVM_FN(mkdir)(path, 0777, true)) {\n      return false;\n    }\n\n    if (sep == file.length() - 1) {\n      return true;\n    }\n  }\n\n  to.append(file);\n  struct zip_stat zipStat;\n  if (zip_stat(zip, file.c_str(), 0, &zipStat) != 0) {\n    return false;\n  }\n\n  auto zipFile = zip_fopen_index(zip, zipStat.index, 0);\n  FAIL_IF_INVALID_PTR(zipFile);\n\n  auto outFile = fopen(to.c_str(), \"wb\");\n  if (outFile == nullptr) {\n    zip_fclose(zipFile);\n    return false;\n  }\n\n  for (auto n = zip_fread(zipFile, buf, len); n != 0;\n       n = zip_fread(zipFile, buf, len)) {\n    if (n < 0 || fwrite(buf, sizeof(char), n, outFile) != n) {\n      zip_fclose(zipFile);\n      fclose(outFile);\n      remove(to.c_str());\n      return false;\n    }\n  }\n\n  zip_fclose(zipFile);\n  if (fclose(outFile) != 0) {\n    return false;\n  }\n\n  return true;\n}", "func_src_after": "static bool extractFileTo(zip* zip, const std::string &file, std::string& to,\n                          char* buf, size_t len) {\n\n  struct zip_stat zipStat;\n  // Verify the file to be extracted is actually in the zip file\n  if (zip_stat(zip, file.c_str(), 0, &zipStat) != 0) {\n    return false;\n  }\n\n  auto clean_file = file;\n  auto sep = std::string::npos;\n  // Normally would just use std::string::rfind here, but if we want to be\n  // consistent between Windows and Linux, even if techincally Linux won't use\n  // backslash for a separator, we are checking for both types.\n  int idx = file.length() - 1;\n  while (idx >= 0) {\n    if (FileUtil::isDirSeparator(file[idx])) {\n      sep = idx;\n      break;\n    }\n    idx--;\n  }\n  if (sep != std::string::npos) {\n    // make_relative_path so we do not try to put files or dirs in bad\n    // places. This securely \"cleans\" the file.\n    clean_file = make_relative_path(file);\n    std::string path = to + clean_file;\n    bool is_dir_only = true;\n    if (sep < file.length() - 1) { // not just a directory\n      auto clean_file_dir = HHVM_FN(dirname)(clean_file);\n      path = to + clean_file_dir.toCppString();\n      is_dir_only = false;\n    }\n\n    // Make sure the directory path to extract to exists or can be created\n    if (!HHVM_FN(is_dir)(path) && !HHVM_FN(mkdir)(path, 0777, true)) {\n      return false;\n    }\n\n    // If we have a good directory to extract to above, we now check whether\n    // the \"file\" parameter passed in is a directory or actually a file.\n    if (is_dir_only) { // directory, like /usr/bin/\n      return true;\n    }\n    // otherwise file is actually a file, so we actually extract.\n  }\n\n  // We have ensured that clean_file will be added to a relative path by the\n  // time we get here.\n  to.append(clean_file);\n\n  auto zipFile = zip_fopen_index(zip, zipStat.index, 0);\n  FAIL_IF_INVALID_PTR(zipFile);\n\n  auto outFile = fopen(to.c_str(), \"wb\");\n  if (outFile == nullptr) {\n    zip_fclose(zipFile);\n    return false;\n  }\n\n  for (auto n = zip_fread(zipFile, buf, len); n != 0;\n       n = zip_fread(zipFile, buf, len)) {\n    if (n < 0 || fwrite(buf, sizeof(char), n, outFile) != n) {\n      zip_fclose(zipFile);\n      fclose(outFile);\n      remove(to.c_str());\n      return false;\n    }\n  }\n\n  zip_fclose(zipFile);\n  if (fclose(outFile) != 0) {\n    return false;\n  }\n\n  return true;\n}", "commit_link": "github.com/facebook/hhvm/commit/65c95a01541dd2fbc9c978ac53bed235b5376686", "file_name": "hphp/runtime/ext/zip/ext_zip.cpp", "vul_type": "cwe-022", "description": "Write a C++ function to extract a file from a zip archive to a specified directory, handling directory creation and path sanitization."}
{"func_name": "_run_ssh", "func_src_before": "    def _run_ssh(self, command, check_exit=True, attempts=1):\n        if not self.sshpool:\n            self.sshpool = utils.SSHPool(self.config.san_ip,\n                                         self.config.san_ssh_port,\n                                         self.config.ssh_conn_timeout,\n                                         self.config.san_login,\n                                         password=self.config.san_password,\n                                         privatekey=\n                                         self.config.san_private_key,\n                                         min_size=\n                                         self.config.ssh_min_pool_conn,\n                                         max_size=\n                                         self.config.ssh_max_pool_conn)\n        try:\n            total_attempts = attempts\n            with self.sshpool.item() as ssh:\n                while attempts > 0:\n                    attempts -= 1\n                    try:\n                        return self._ssh_execute(ssh, command,\n                                                 check_exit_code=check_exit)\n                    except Exception as e:\n                        LOG.error(e)\n                        greenthread.sleep(randint(20, 500) / 100.0)\n                msg = (_(\"SSH Command failed after '%(total_attempts)r' \"\n                         \"attempts : '%(command)s'\") %\n                       {'total_attempts': total_attempts, 'command': command})\n                raise paramiko.SSHException(msg)\n        except Exception:\n            with excutils.save_and_reraise_exception():\n                LOG.error(_(\"Error running ssh command: %s\") % command)", "func_src_after": "    def _run_ssh(self, cmd_list, check_exit=True, attempts=1):\n        utils.check_ssh_injection(cmd_list)\n        command = ' '. join(cmd_list)\n\n        if not self.sshpool:\n            self.sshpool = utils.SSHPool(self.config.san_ip,\n                                         self.config.san_ssh_port,\n                                         self.config.ssh_conn_timeout,\n                                         self.config.san_login,\n                                         password=self.config.san_password,\n                                         privatekey=\n                                         self.config.san_private_key,\n                                         min_size=\n                                         self.config.ssh_min_pool_conn,\n                                         max_size=\n                                         self.config.ssh_max_pool_conn)\n        try:\n            total_attempts = attempts\n            with self.sshpool.item() as ssh:\n                while attempts > 0:\n                    attempts -= 1\n                    try:\n                        return self._ssh_execute(ssh, command,\n                                                 check_exit_code=check_exit)\n                    except Exception as e:\n                        LOG.error(e)\n                        greenthread.sleep(randint(20, 500) / 100.0)\n                msg = (_(\"SSH Command failed after '%(total_attempts)r' \"\n                         \"attempts : '%(command)s'\") %\n                       {'total_attempts': total_attempts, 'command': command})\n                raise paramiko.SSHException(msg)\n        except Exception:\n            with excutils.save_and_reraise_exception():\n                LOG.error(_(\"Error running ssh command: %s\") % command)", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function to execute an SSH command using a connection pool, with retry logic on failure."}
{"func_name": "yaffsfs_istat", "func_src_before": "    yaffsfs_istat(TSK_FS_INFO *fs, TSK_FS_ISTAT_FLAG_ENUM flags, FILE * hFile, TSK_INUM_T inum,\n    TSK_DADDR_T numblock, int32_t sec_skew)\n{\n    TSK_FS_META *fs_meta;\n    TSK_FS_FILE *fs_file;\n    YAFFSFS_INFO *yfs = (YAFFSFS_INFO *)fs;\n    char ls[12];\n    YAFFSFS_PRINT_ADDR print;\n    char timeBuf[32];\n    YaffsCacheObject * obj = NULL;\n    YaffsCacheVersion * version = NULL;\n    YaffsHeader * header = NULL;\n\n    yaffscache_version_find_by_inode(yfs, inum, &version, &obj);\n\n    if ((fs_file = tsk_fs_file_open_meta(fs, NULL, inum)) == NULL) {\n        return 1;\n    }\n    fs_meta = fs_file->meta;\n\n    tsk_fprintf(hFile, \"inode: %\" PRIuINUM \"\\n\", inum);\n    tsk_fprintf(hFile, \"%sAllocated\\n\",\n        (fs_meta->flags & TSK_FS_META_FLAG_ALLOC) ? \"\" : \"Not \");\n\n    if (fs_meta->link)\n        tsk_fprintf(hFile, \"symbolic link to: %s\\n\", fs_meta->link);\n\n    tsk_fprintf(hFile, \"uid / gid: %\" PRIuUID \" / %\" PRIuGID \"\\n\",\n        fs_meta->uid, fs_meta->gid);\n\n    tsk_fs_meta_make_ls(fs_meta, ls, sizeof(ls));\n    tsk_fprintf(hFile, \"mode: %s\\n\", ls);\n\n    tsk_fprintf(hFile, \"size: %\" PRIdOFF \"\\n\", fs_meta->size);\n    tsk_fprintf(hFile, \"num of links: %d\\n\", fs_meta->nlink);\n\n    if(version != NULL){\n        yaffsfs_read_header(yfs, &header, version->ycv_header_chunk->ycc_offset);\n        if(header != NULL){\n            tsk_fprintf(hFile, \"Name: %s\\n\", header->name);\n        }\n    }\n\n    if (sec_skew != 0) {\n        tsk_fprintf(hFile, \"\\nAdjusted Inode Times:\\n\");\n        fs_meta->mtime -= sec_skew;\n        fs_meta->atime -= sec_skew;\n        fs_meta->ctime -= sec_skew;\n\n        tsk_fprintf(hFile, \"Accessed:\\t%s\\n\",\n            tsk_fs_time_to_str(fs_meta->atime, timeBuf));\n        tsk_fprintf(hFile, \"File Modified:\\t%s\\n\",\n            tsk_fs_time_to_str(fs_meta->mtime, timeBuf));\n        tsk_fprintf(hFile, \"Inode Modified:\\t%s\\n\",\n            tsk_fs_time_to_str(fs_meta->ctime, timeBuf));\n\n        fs_meta->mtime += sec_skew;\n        fs_meta->atime += sec_skew;\n        fs_meta->ctime += sec_skew;\n\n        tsk_fprintf(hFile, \"\\nOriginal Inode Times:\\n\");\n    }\n    else {\n        tsk_fprintf(hFile, \"\\nInode Times:\\n\");\n    }\n\n    tsk_fprintf(hFile, \"Accessed:\\t%s\\n\",\n        tsk_fs_time_to_str(fs_meta->atime, timeBuf));\n    tsk_fprintf(hFile, \"File Modified:\\t%s\\n\",\n        tsk_fs_time_to_str(fs_meta->mtime, timeBuf));\n    tsk_fprintf(hFile, \"Inode Modified:\\t%s\\n\",\n        tsk_fs_time_to_str(fs_meta->ctime, timeBuf));\n\n    if(version != NULL){\n        tsk_fprintf(hFile, \"\\nHeader Chunk:\\n\");\n        tsk_fprintf(hFile, \"%\" PRIuDADDR \"\\n\", (version->ycv_header_chunk->ycc_offset / (yfs->page_size + yfs->spare_size)));\n    }\n\n    if (numblock > 0) {\n        TSK_OFF_T lower_size = numblock * fs->block_size;\n        fs_meta->size = (lower_size < fs_meta->size)?(lower_size):(fs_meta->size);\n    }\n    tsk_fprintf(hFile, \"\\nData Chunks:\\n\");\n\n\n    if (flags & TSK_FS_ISTAT_RUNLIST){\n        const TSK_FS_ATTR *fs_attr_default =\n            tsk_fs_file_attr_get_type(fs_file,\n                TSK_FS_ATTR_TYPE_DEFAULT, 0, 0);\n        if (fs_attr_default && (fs_attr_default->flags & TSK_FS_ATTR_NONRES)) {\n            if (tsk_fs_attr_print(fs_attr_default, hFile)) {\n                tsk_fprintf(hFile, \"\\nError creating run lists  \");\n                tsk_error_print(hFile);\n                tsk_error_reset();\n            }\n        }\n    }\n    else {\n        print.idx = 0;\n        print.hFile = hFile;\n\n        if (tsk_fs_file_walk(fs_file, TSK_FS_FILE_WALK_FLAG_AONLY,\n            (TSK_FS_FILE_WALK_CB)print_addr_act, (void *)&print)) {\n            tsk_fprintf(hFile, \"\\nError reading file:  \");\n            tsk_error_print(hFile);\n            tsk_error_reset();\n        }\n        else if (print.idx != 0) {\n            tsk_fprintf(hFile, \"\\n\");\n        }\n    }\n\n    tsk_fs_file_close(fs_file);\n\n    return 0;\n}", "func_src_after": "    yaffsfs_istat(TSK_FS_INFO *fs, TSK_FS_ISTAT_FLAG_ENUM flags, FILE * hFile, TSK_INUM_T inum,\n    TSK_DADDR_T numblock, int32_t sec_skew)\n{\n    TSK_FS_META *fs_meta;\n    TSK_FS_FILE *fs_file;\n    YAFFSFS_INFO *yfs = (YAFFSFS_INFO *)fs;\n    char ls[12];\n    YAFFSFS_PRINT_ADDR print;\n    char timeBuf[128];\n    YaffsCacheObject * obj = NULL;\n    YaffsCacheVersion * version = NULL;\n    YaffsHeader * header = NULL;\n\n    yaffscache_version_find_by_inode(yfs, inum, &version, &obj);\n\n    if ((fs_file = tsk_fs_file_open_meta(fs, NULL, inum)) == NULL) {\n        return 1;\n    }\n    fs_meta = fs_file->meta;\n\n    tsk_fprintf(hFile, \"inode: %\" PRIuINUM \"\\n\", inum);\n    tsk_fprintf(hFile, \"%sAllocated\\n\",\n        (fs_meta->flags & TSK_FS_META_FLAG_ALLOC) ? \"\" : \"Not \");\n\n    if (fs_meta->link)\n        tsk_fprintf(hFile, \"symbolic link to: %s\\n\", fs_meta->link);\n\n    tsk_fprintf(hFile, \"uid / gid: %\" PRIuUID \" / %\" PRIuGID \"\\n\",\n        fs_meta->uid, fs_meta->gid);\n\n    tsk_fs_meta_make_ls(fs_meta, ls, sizeof(ls));\n    tsk_fprintf(hFile, \"mode: %s\\n\", ls);\n\n    tsk_fprintf(hFile, \"size: %\" PRIdOFF \"\\n\", fs_meta->size);\n    tsk_fprintf(hFile, \"num of links: %d\\n\", fs_meta->nlink);\n\n    if(version != NULL){\n        yaffsfs_read_header(yfs, &header, version->ycv_header_chunk->ycc_offset);\n        if(header != NULL){\n            tsk_fprintf(hFile, \"Name: %s\\n\", header->name);\n        }\n    }\n\n    if (sec_skew != 0) {\n        tsk_fprintf(hFile, \"\\nAdjusted Inode Times:\\n\");\n        fs_meta->mtime -= sec_skew;\n        fs_meta->atime -= sec_skew;\n        fs_meta->ctime -= sec_skew;\n\n        tsk_fprintf(hFile, \"Accessed:\\t%s\\n\",\n            tsk_fs_time_to_str(fs_meta->atime, timeBuf));\n        tsk_fprintf(hFile, \"File Modified:\\t%s\\n\",\n            tsk_fs_time_to_str(fs_meta->mtime, timeBuf));\n        tsk_fprintf(hFile, \"Inode Modified:\\t%s\\n\",\n            tsk_fs_time_to_str(fs_meta->ctime, timeBuf));\n\n        fs_meta->mtime += sec_skew;\n        fs_meta->atime += sec_skew;\n        fs_meta->ctime += sec_skew;\n\n        tsk_fprintf(hFile, \"\\nOriginal Inode Times:\\n\");\n    }\n    else {\n        tsk_fprintf(hFile, \"\\nInode Times:\\n\");\n    }\n\n    tsk_fprintf(hFile, \"Accessed:\\t%s\\n\",\n        tsk_fs_time_to_str(fs_meta->atime, timeBuf));\n    tsk_fprintf(hFile, \"File Modified:\\t%s\\n\",\n        tsk_fs_time_to_str(fs_meta->mtime, timeBuf));\n    tsk_fprintf(hFile, \"Inode Modified:\\t%s\\n\",\n        tsk_fs_time_to_str(fs_meta->ctime, timeBuf));\n\n    if(version != NULL){\n        tsk_fprintf(hFile, \"\\nHeader Chunk:\\n\");\n        tsk_fprintf(hFile, \"%\" PRIuDADDR \"\\n\", (version->ycv_header_chunk->ycc_offset / (yfs->page_size + yfs->spare_size)));\n    }\n\n    if (numblock > 0) {\n        TSK_OFF_T lower_size = numblock * fs->block_size;\n        fs_meta->size = (lower_size < fs_meta->size)?(lower_size):(fs_meta->size);\n    }\n    tsk_fprintf(hFile, \"\\nData Chunks:\\n\");\n\n\n    if (flags & TSK_FS_ISTAT_RUNLIST){\n        const TSK_FS_ATTR *fs_attr_default =\n            tsk_fs_file_attr_get_type(fs_file,\n                TSK_FS_ATTR_TYPE_DEFAULT, 0, 0);\n        if (fs_attr_default && (fs_attr_default->flags & TSK_FS_ATTR_NONRES)) {\n            if (tsk_fs_attr_print(fs_attr_default, hFile)) {\n                tsk_fprintf(hFile, \"\\nError creating run lists  \");\n                tsk_error_print(hFile);\n                tsk_error_reset();\n            }\n        }\n    }\n    else {\n        print.idx = 0;\n        print.hFile = hFile;\n\n        if (tsk_fs_file_walk(fs_file, TSK_FS_FILE_WALK_FLAG_AONLY,\n            (TSK_FS_FILE_WALK_CB)print_addr_act, (void *)&print)) {\n            tsk_fprintf(hFile, \"\\nError reading file:  \");\n            tsk_error_print(hFile);\n            tsk_error_reset();\n        }\n        else if (print.idx != 0) {\n            tsk_fprintf(hFile, \"\\n\");\n        }\n    }\n\n    tsk_fs_file_close(fs_file);\n\n    return 0;\n}", "commit_link": "github.com/sleuthkit/sleuthkit/commit/459ae818fc8dae717549810150de4d191ce158f1", "file_name": "tsk/fs/yaffs.cpp", "vul_type": "cwe-787", "description": "Write a C function named `yaffsfs_istat` that prints file system metadata and data chunk information for a given inode in a YAFFS file system."}
{"func_name": "create_cf_base", "func_src_before": "def create_cf_base():\n    url = 'http://codeforces.com/problemset/'\n    r = requests.get(url)\n    max_page = 0\n    soup = BeautifulSoup(r.text, \"lxml\")\n    base = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\cf.db\")\n    conn = base.cursor()\n    conn.execute(\"create table problems (problem INTEGER, diff CHAR)\")\n    for i in available_tags:\n        conn.execute(\"create table \" + i + \" (problems INTEGER, diff CHAR)\")\n\n    for link in soup.find_all(attrs={\"class\" : \"page-index\"}):\n        s = link.find('a')\n        s2 = s.get(\"href\").split('/')\n        max_page = max(max_page, int(s2[3]))\n\n    a = 0\n    b = 0\n    f = False\n    for i in range(1, max_page + 1):\n        r = requests.get('http://codeforces.com/problemset/' + '/page/' + str(i))\n        soup = BeautifulSoup(r.text, \"lxml\")\n        old = ''\n        for link in soup.find_all('a'):\n            s = link.get('href')\n            if s != None and s.find('/problemset') != -1:\n                s = s.split('/')\n                if len(s) == 5 and old != s[3] + s[4]:\n                    a = s[3]\n                    b = s[4]\n                    old = s[3] + s[4]\n                    if not f:\n                        f = True\n                        last_update = old\n                    conn.execute(\"insert into problems values (?, ?)\", (a, b))\n                if len(s) == 4 and s[3] in available_tags:\n                    conn.execute(\"insert into \" + s[3] + \" values (?, ?)\", (a, b))\n\n    base.commit()\n    base.close()\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"create table users (chat_id INTEGER, username STRING, last_update STRING, last_problem STRING, state INTEGER)\")\n    conn.execute(\"create table last_update_problemset (problem STRING)\")\n    conn.execute(\"insert into last_update_problemset values (?)\", (last_update, ))\n    settings.commit()\n    settings.close()", "func_src_after": "def create_cf_base():\n    url = 'http://codeforces.com/problemset/'\n    r = requests.get(url)\n    max_page = 0\n    soup = BeautifulSoup(r.text, \"lxml\")\n    base = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\cf.db\")\n    conn = base.cursor()\n    conn.execute(\"create table problems (problem INTEGER, diff CHAR)\")\n    for i in available_tags:\n        conn.execute(\"create table ? (problems INTEGER, diff CHAR)\", (i,))\n\n    for link in soup.find_all(attrs={\"class\" : \"page-index\"}):\n        s = link.find('a')\n        s2 = s.get(\"href\").split('/')\n        max_page = max(max_page, int(s2[3]))\n\n    a = 0\n    b = 0\n    f = False\n    for i in range(1, max_page + 1):\n        r = requests.get('http://codeforces.com/problemset/' + '/page/' + str(i))\n        soup = BeautifulSoup(r.text, \"lxml\")\n        old = ''\n        for link in soup.find_all('a'):\n            s = link.get('href')\n            if s != None and s.find('/problemset') != -1:\n                s = s.split('/')\n                if len(s) == 5 and old != s[3] + s[4]:\n                    a = s[3]\n                    b = s[4]\n                    old = s[3] + s[4]\n                    if not f:\n                        f = True\n                        last_update = old\n                    conn.execute(\"insert into problems values (?, ?)\", (a, b))\n                if len(s) == 4 and s[3] in available_tags:\n                    conn.execute(\"insert into ? values (?, ?)\", (s[3], a, b))\n\n    base.commit()\n    base.close()\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"create table users (chat_id INTEGER, username STRING, last_update STRING, last_problem STRING, state INTEGER)\")\n    conn.execute(\"create table last_update_problemset (problem STRING)\")\n    conn.execute(\"insert into last_update_problemset values (?)\", (last_update, ))\n    settings.commit()\n    settings.close()", "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bases/createcfbase.py", "vul_type": "cwe-089", "description": "Write a Python function to scrape Codeforces problemset data and store it in a SQLite database."}
{"func_name": "copyIPv6IfDifferent", "func_src_before": "static void copyIPv6IfDifferent(void * dest, const void * src)\n{\n\tif(dest != src) {\n\t\tmemcpy(dest, src, sizeof(struct in6_addr));\n\t}\n}", "func_src_after": "static void copyIPv6IfDifferent(void * dest, const void * src)\n{\n\tif(dest != src && src != NULL) {\n\t\tmemcpy(dest, src, sizeof(struct in6_addr));\n\t}\n}", "commit_link": "github.com/miniupnp/miniupnp/commit/cb8a02af7a5677cf608e86d57ab04241cf34e24f", "file_name": "miniupnpd/pcpserver.c", "vul_type": "cwe-476", "description": "Write a C function named `copyIPv6IfDifferent` that copies an IPv6 address from source to destination if they are different, with the second version also checking if the source is not NULL."}
{"func_name": "get_error_days", "func_src_before": "def get_error_days(cur, error_percent):\n    \"\"\"Fetches the days in which requests led to errors.\n\n    Fetches the days in which the specified percentage\n    of requests led to errors.\n\n    Args:\n        cur(obj): The cursor to execute the query.\n        error_percent(int): The percentage of requests that led to errors.\n\n    Return:\n        True if success, False otherwise.\n    \"\"\"\n    query = '''SELECT to_char(log_errors.date, 'Mon DD YYYY'),\n            round((log_errors.errors * 100\n            / log_requests.total::numeric), 2) as percent\n            FROM log_errors, log_requests\n            WHERE log_errors.date = log_requests.date AND\n            log_errors.errors * 100\n            / log_requests.total::numeric > {}\n            ORDER BY log_errors.date'''.format(error_percent)\n    rows = get_data(cur, query)\n\n    # Write data to txt file.\n    if rows is not None:\n        file = open(\"error_report.txt\", \"w\")\n        for row in rows:\n            file.write(\"{} - {}% errors \\n\".format(row[0], row[1]))\n        file.close()\n\n        return True\n    else:\n        return False", "func_src_after": "def get_error_days(cur, error_percent):\n    \"\"\"Fetches the days in which requests led to errors.\n\n    Fetches the days in which the specified percentage\n    of requests led to errors.\n\n    Args:\n        cur(obj): The cursor to execute the query.\n        error_percent(int): The percentage of requests that led to errors.\n\n    Return:\n        True if success, False otherwise.\n    \"\"\"\n    data = (error_percent, )\n    query = '''SELECT to_char(log_errors.date, 'Mon DD YYYY'),\n            round((log_errors.errors * 100\n            / log_requests.total::numeric), 2) as percent\n            FROM log_errors, log_requests\n            WHERE log_errors.date = log_requests.date AND\n            log_errors.errors * 100\n            / log_requests.total::numeric > %s\n            ORDER BY log_errors.date'''\n    rows = get_data(cur, query, data)\n\n    # Write data to txt file.\n    if rows is not None:\n        file = open(\"error_report.txt\", \"w\")\n        for row in rows:\n            file.write(\"{} - {}% errors \\n\".format(row[0], row[1]))\n        file.close()\n\n        return True\n    else:\n        return False", "commit_link": "github.com/rrbiz662/log-analysis/commit/20fefbde3738088586a3c5679f743493d0a504f6", "file_name": "news_data_analysis.py", "vul_type": "cwe-089", "description": "Write a Python function to query a database for days with error rates above a threshold and save the results to a text file."}
{"func_name": "nfc_genl_deactivate_target", "func_src_before": "static int nfc_genl_deactivate_target(struct sk_buff *skb,\n\t\t\t\t      struct genl_info *info)\n{\n\tstruct nfc_dev *dev;\n\tu32 device_idx, target_idx;\n\tint rc;\n\n\tif (!info->attrs[NFC_ATTR_DEVICE_INDEX])\n\t\treturn -EINVAL;\n\n\tdevice_idx = nla_get_u32(info->attrs[NFC_ATTR_DEVICE_INDEX]);\n\n\tdev = nfc_get_device(device_idx);\n\tif (!dev)\n\t\treturn -ENODEV;\n\n\ttarget_idx = nla_get_u32(info->attrs[NFC_ATTR_TARGET_INDEX]);\n\n\trc = nfc_deactivate_target(dev, target_idx, NFC_TARGET_MODE_SLEEP);\n\n\tnfc_put_device(dev);\n\treturn rc;\n}", "func_src_after": "static int nfc_genl_deactivate_target(struct sk_buff *skb,\n\t\t\t\t      struct genl_info *info)\n{\n\tstruct nfc_dev *dev;\n\tu32 device_idx, target_idx;\n\tint rc;\n\n\tif (!info->attrs[NFC_ATTR_DEVICE_INDEX] ||\n\t    !info->attrs[NFC_ATTR_TARGET_INDEX])\n\t\treturn -EINVAL;\n\n\tdevice_idx = nla_get_u32(info->attrs[NFC_ATTR_DEVICE_INDEX]);\n\n\tdev = nfc_get_device(device_idx);\n\tif (!dev)\n\t\treturn -ENODEV;\n\n\ttarget_idx = nla_get_u32(info->attrs[NFC_ATTR_TARGET_INDEX]);\n\n\trc = nfc_deactivate_target(dev, target_idx, NFC_TARGET_MODE_SLEEP);\n\n\tnfc_put_device(dev);\n\treturn rc;\n}", "commit_link": "github.com/torvalds/linux/commit/385097a3675749cbc9e97c085c0e5dfe4269ca51", "file_name": "net/nfc/netlink.c", "vul_type": "cwe-476", "description": "Write a C function to deactivate an NFC target by putting it into sleep mode, handling errors for invalid device or target indices."}
{"func_name": "reroute", "func_src_before": "@app.route('/<short_url>')\ndef reroute(short_url):\n\n\tconn = MySQLdb.connect(host , user , passwrd, db)\n\tcursor = conn.cursor()\n\tplatform = request.user_agent.platform\n\tbrowser =  request.user_agent.browser\n\tcounter = 1\n\n\t# Platform , Browser vars\n\t\n\tbrowser_dict = {'firefox': 0 , 'chrome':0 , 'safari':0 , 'other':0}\n\tplatform_dict = {'windows':0 , 'iphone':0 , 'android':0 , 'linux':0 , 'macos':0 , 'other':0}\n\n\t# Analytics\n\tif browser in browser_dict:\n\t\tbrowser_dict[browser] += 1\n\telse:\t\t\t\t\t\t\t\t\n\t\tbrowser_dict['other'] += 1\n\t\n\tif platform in platform_dict.iterkeys():\n\t\tplatform_dict[platform] += 1\n\telse:\n\t\tplatform_dict['other'] += 1\n\t\t\t\n\tcursor.execute(\"SELECT URL FROM WEB_URL WHERE S_URL = %s;\" ,(short_url,) )\n\n\ttry:\n\t\tnew_url = cursor.fetchone()[0]\n\t\tprint new_url\n\t\t# Update Counters \n\t\t\n\t\tcounter_sql = \"\\\n\t\t\t\tUPDATE {tn} SET COUNTER = COUNTER + {og_counter} , CHROME = CHROME + {og_chrome} , FIREFOX = FIREFOX+{og_firefox} ,\\\n\t\t\t\tSAFARI = SAFARI+{og_safari} , OTHER_BROWSER =OTHER_BROWSER+ {og_oth_brow} , ANDROID = ANDROID +{og_andr} , IOS = IOS +{og_ios},\\\n\t\t\t\tWINDOWS = WINDOWS+{og_windows} , LINUX = LINUX+{og_linux}  , MAC =MAC+ {og_mac} , OTHER_PLATFORM =OTHER_PLATFORM+ {og_plat_other} WHERE S_URL = '{surl}';\".\\\n\t\t\t\tformat(tn = \"WEB_URL\" , og_counter = counter , og_chrome = browser_dict['chrome'] , og_firefox = browser_dict['firefox'],\\\n\t\t\t\tog_safari = browser_dict['safari'] , og_oth_brow = browser_dict['other'] , og_andr = platform_dict['android'] , og_ios = platform_dict['iphone'] ,\\\n\t\t\t\tog_windows = platform_dict['windows'] , og_linux = platform_dict['linux'] , og_mac = platform_dict['macos'] , og_plat_other = platform_dict['other'] ,\\\n\t\t\t\tsurl = short_url)\n\t\tres_update = cursor.execute(counter_sql)\n\t\tconn.commit()\n\t\tconn.close()\n\n\t\treturn redirect(new_url)\n\n\texcept Exception as e:\n\t\te = \"Something went wrong.Please try again.\"\n\t\treturn render_template('404.html') ,404", "func_src_after": "@app.route('/<short_url>')\ndef reroute(short_url):\n\n\tconn = MySQLdb.connect(host , user , passwrd, db)\n\tcursor = conn.cursor()\n\tplatform = request.user_agent.platform\n\tbrowser =  request.user_agent.browser\n\tcounter = 1\n\n\t# Platform , Browser vars\n\t\n\tbrowser_dict = {'firefox': 0 , 'chrome':0 , 'safari':0 , 'other':0}\n\tplatform_dict = {'windows':0 , 'iphone':0 , 'android':0 , 'linux':0 , 'macos':0 , 'other':0}\n\n\t# Analytics\n\tif browser in browser_dict:\n\t\tbrowser_dict[browser] += 1\n\telse:\t\t\t\t\t\t\t\t\n\t\tbrowser_dict['other'] += 1\n\t\n\tif platform in platform_dict.iterkeys():\n\t\tplatform_dict[platform] += 1\n\telse:\n\t\tplatform_dict['other'] += 1\n\t\t\t\n\tcursor.execute(\"SELECT URL FROM WEB_URL WHERE S_URL = %s;\" ,(short_url,) )\n\n\ttry:\n\t\tnew_url = cursor.fetchone()[0]\n\t\tprint new_url\n\t\t# Update Counters \n\t\t\n\t\tcounter_sql = \"\\\n\t\t\t\tUPDATE {tn} SET COUNTER = COUNTER + {og_counter} , CHROME = CHROME + {og_chrome} , FIREFOX = FIREFOX+{og_firefox} ,\\\n\t\t\t\tSAFARI = SAFARI+{og_safari} , OTHER_BROWSER =OTHER_BROWSER+ {og_oth_brow} , ANDROID = ANDROID +{og_andr} , IOS = IOS +{og_ios},\\\n\t\t\t\tWINDOWS = WINDOWS+{og_windows} , LINUX = LINUX+{og_linux}  , MAC =MAC+ {og_mac} , OTHER_PLATFORM =OTHER_PLATFORM+ {og_plat_other} WHERE S_URL = %s;\".\\\n\t\t\t\tformat(tn = \"WEB_URL\" , og_counter = counter , og_chrome = browser_dict['chrome'] , og_firefox = browser_dict['firefox'],\\\n\t\t\t\tog_safari = browser_dict['safari'] , og_oth_brow = browser_dict['other'] , og_andr = platform_dict['android'] , og_ios = platform_dict['iphone'] ,\\\n\t\t\t\tog_windows = platform_dict['windows'] , og_linux = platform_dict['linux'] , og_mac = platform_dict['macos'] , og_plat_other = platform_dict['other'])\n\t\tres_update = cursor.execute(counter_sql, (short_url, ))\n\t\tconn.commit()\n\t\tconn.close()\n\n\t\treturn redirect(new_url)\n\n\texcept Exception as e:\n\t\te = \"Something went wrong.Please try again.\"\n\t\treturn render_template('404.html') ,404", "line_changes": {"deleted": [{"line_no": 36, "char_start": 1073, "char_end": 1234, "line": "\t\t\t\tWINDOWS = WINDOWS+{og_windows} , LINUX = LINUX+{og_linux}  , MAC =MAC+ {og_mac} , OTHER_PLATFORM =OTHER_PLATFORM+ {og_plat_other} WHERE S_URL = '{surl}';\".\\\n"}, {"line_no": 39, "char_start": 1513, "char_end": 1669, "line": "\t\t\t\tog_windows = platform_dict['windows'] , og_linux = platform_dict['linux'] , og_mac = platform_dict['macos'] , og_plat_other = platform_dict['other'] ,\\\n"}, {"line_no": 40, "char_start": 1669, "char_end": 1691, "line": "\t\t\t\tsurl = short_url)\n"}, {"line_no": 41, "char_start": 1691, "char_end": 1734, "line": "\t\tres_update = cursor.execute(counter_sql)\n"}], "added": [{"line_no": 36, "char_start": 1073, "char_end": 1228, "line": "\t\t\t\tWINDOWS = WINDOWS+{og_windows} , LINUX = LINUX+{og_linux}  , MAC =MAC+ {og_mac} , OTHER_PLATFORM =OTHER_PLATFORM+ {og_plat_other} WHERE S_URL = %s;\".\\\n"}, {"line_no": 39, "char_start": 1507, "char_end": 1661, "line": "\t\t\t\tog_windows = platform_dict['windows'] , og_linux = platform_dict['linux'] , og_mac = platform_dict['macos'] , og_plat_other = platform_dict['other'])\n"}, {"line_no": 40, "char_start": 1661, "char_end": 1719, "line": "\t\tres_update = cursor.execute(counter_sql, (short_url, ))\n"}]}, "char_changes": {"deleted": [{"char_start": 1221, "char_end": 1229, "chars": "'{surl}'"}, {"char_start": 1665, "char_end": 1689, "chars": " ,\\\n\t\t\t\tsurl = short_url"}], "added": [{"char_start": 1221, "char_end": 1223, "chars": "%s"}, {"char_start": 1702, "char_end": 1717, "chars": ", (short_url, )"}]}, "commit_link": "github.com/PadamSethia/shorty/commit/071497f90bcf7336c44e135d5ef4bd87898fa8d0", "file_name": "app.py", "vul_type": "cwe-089", "commit_msg": "Escape short_url to prevent SQL Injections", "description": "Write a Python Flask function to redirect a short URL to its original URL and update visit analytics in a MySQL database."}
{"func_name": "make_tarfile", "func_src_before": "def make_tarfile(\n    output_filename: str,\n    source_dir: str,\n    archive_name: str,\n    custom_filter: Optional[Callable] = None,\n) -> None:\n    # Helper for filtering out modification timestamps\n    def _filter_timestamps(tar_info: \"tarfile.TarInfo\") -> Optional[\"tarfile.TarInfo\"]:\n        tar_info.mtime = 0\n        return tar_info if custom_filter is None else custom_filter(tar_info)\n\n    unzipped_filename = tempfile.mktemp()\n    try:\n        with tarfile.open(unzipped_filename, \"w\") as tar:\n            tar.add(source_dir, arcname=archive_name, filter=_filter_timestamps)\n        # When gzipping the tar, don't include the tar's filename or modification time in the\n        # zipped archive (see https://docs.python.org/3/library/gzip.html#gzip.GzipFile)\n        with gzip.GzipFile(\n            filename=\"\", fileobj=open(output_filename, \"wb\"), mode=\"wb\", mtime=0\n        ) as gzipped_tar, open(unzipped_filename, \"rb\") as tar_file:\n            gzipped_tar.write(tar_file.read())\n    finally:\n        os.remove(unzipped_filename)", "func_src_after": "def make_tarfile(\n    output_filename: str,\n    source_dir: str,\n    archive_name: str,\n    custom_filter: Optional[Callable] = None,\n) -> None:\n    # Helper for filtering out modification timestamps\n    def _filter_timestamps(tar_info: \"tarfile.TarInfo\") -> Optional[\"tarfile.TarInfo\"]:\n        tar_info.mtime = 0\n        return tar_info if custom_filter is None else custom_filter(tar_info)\n\n    descriptor, unzipped_filename = tempfile.mkstemp()\n    try:\n        with tarfile.open(unzipped_filename, \"w\") as tar:\n            tar.add(source_dir, arcname=archive_name, filter=_filter_timestamps)\n        # When gzipping the tar, don't include the tar's filename or modification time in the\n        # zipped archive (see https://docs.python.org/3/library/gzip.html#gzip.GzipFile)\n        with gzip.GzipFile(\n            filename=\"\", fileobj=open(output_filename, \"wb\"), mode=\"wb\", mtime=0\n        ) as gzipped_tar, open(unzipped_filename, \"rb\") as tar_file:\n            gzipped_tar.write(tar_file.read())\n    finally:\n        os.close(descriptor)\n        os.remove(unzipped_filename)", "line_changes": {"deleted": [{"line_no": 12, "char_start": 394, "char_end": 436, "line": "    unzipped_filename = tempfile.mktemp()\n"}], "added": [{"line_no": 12, "char_start": 394, "char_end": 449, "line": "    descriptor, unzipped_filename = tempfile.mkstemp()\n"}, {"line_no": 23, "char_start": 1018, "char_end": 1047, "line": "        os.close(descriptor)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 397, "char_end": 409, "chars": " descriptor,"}, {"char_start": 441, "char_end": 442, "chars": "s"}, {"char_start": 1018, "char_end": 1047, "chars": "        os.close(descriptor)\n"}]}, "commit_link": "github.com/wandb/client/commit/7c1306c1851da5628ac96e0f89728d16852611dd", "file_name": "util.py", "vul_type": "cwe-377", "commit_msg": "Port of #3357: Fix/insecure tempfile (#3360)\n\n* Replaced insecure tempfile.mktemp() with tempfile.mkstemp()\r\nCo-authored-by: whokilleddb <whokilleddb@gmail.com>", "description": "Write a Python function to create a gzipped tar file from a directory, optionally applying a custom filter to the files."}
{"func_name": "Magick::Image::read", "func_src_before": "void Magick::Image::read(MagickCore::Image *image,\n  MagickCore::ExceptionInfo *exceptionInfo)\n{\n  // Ensure that multiple image frames were not read.\n  if (image != (MagickCore::Image *) NULL &&\n      image->next != (MagickCore::Image *) NULL)\n    {\n      MagickCore::Image\n        *next;\n\n      // Destroy any extra image frames\n      next=image->next;\n      image->next=(MagickCore::Image *) NULL;\n      next->previous=(MagickCore::Image *) NULL;\n      DestroyImageList(next);\n    }\n  replaceImage(image);\n  if (exceptionInfo->severity == MagickCore::UndefinedException &&\n      image == (MagickCore::Image *) NULL)\n    {\n      (void) MagickCore::DestroyExceptionInfo(exceptionInfo);\n      if (!quiet())\n        throwExceptionExplicit(MagickCore::ImageWarning,\n          \"No image was loaded.\");\n    }\n  ThrowImageException;\n}", "func_src_after": "void Magick::Image::read(MagickCore::Image *image,\n  MagickCore::ExceptionInfo *exceptionInfo)\n{\n  // Ensure that multiple image frames were not read.\n  if (image != (MagickCore::Image *) NULL &&\n      image->next != (MagickCore::Image *) NULL)\n    {\n      MagickCore::Image\n        *next;\n\n      // Destroy any extra image frames\n      next=image->next;\n      image->next=(MagickCore::Image *) NULL;\n      next->previous=(MagickCore::Image *) NULL;\n      DestroyImageList(next);\n    }\n  replaceImage(image);\n  if (exceptionInfo->severity == MagickCore::UndefinedException &&\n      image == (MagickCore::Image *) NULL)\n    {\n      (void) MagickCore::DestroyExceptionInfo(exceptionInfo);\n      if (!quiet())\n        throwExceptionExplicit(MagickCore::ImageWarning,\n          \"No image was loaded.\");\n      return;\n    }\n  ThrowImageException;\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/8c35502217c1879cb8257c617007282eee3fe1cc", "file_name": "Magick++/lib/Image.cpp", "vul_type": "cwe-416", "description": "In C++, write a function within the Magick::Image class to read an image, ensuring only a single frame is retained and handling exceptions if no image is loaded."}
{"func_name": "PHP_FUNCTION", "func_src_before": "PHP_FUNCTION(imagegammacorrect)\n{\n\tzval *IM;\n\tgdImagePtr im;\n\tint i;\n\tdouble input, output;\n\n\tif (zend_parse_parameters(ZEND_NUM_ARGS() TSRMLS_CC, \"rdd\", &IM, &input, &output) == FAILURE) {\n\t\treturn;\n\t}\n\n\tZEND_FETCH_RESOURCE(im, gdImagePtr, &IM, -1, \"Image\", le_gd);\n\n\tif (gdImageTrueColor(im))\t{\n\t\tint x, y, c;\n\n\t\tfor (y = 0; y < gdImageSY(im); y++)\t{\n\t\t\tfor (x = 0; x < gdImageSX(im); x++)\t{\n\t\t\t\tc = gdImageGetPixel(im, x, y);\n\t\t\t\tgdImageSetPixel(im, x, y,\n\t\t\t\t\tgdTrueColorAlpha(\n\t\t\t\t\t\t(int) ((pow((pow((gdTrueColorGetRed(c)   / 255.0), input)), 1.0 / output) * 255) + .5),\n\t\t\t\t\t\t(int) ((pow((pow((gdTrueColorGetGreen(c) / 255.0), input)), 1.0 / output) * 255) + .5),\n\t\t\t\t\t\t(int) ((pow((pow((gdTrueColorGetBlue(c)  / 255.0), input)), 1.0 / output) * 255) + .5),\n\t\t\t\t\t\tgdTrueColorGetAlpha(c)\n\t\t\t\t\t)\n\t\t\t\t);\n\t\t\t}\n\t\t}\n\t\tRETURN_TRUE;\n\t}\n\n\tfor (i = 0; i < gdImageColorsTotal(im); i++) {\n\t\tim->red[i]   = (int)((pow((pow((im->red[i]   / 255.0), input)), 1.0 / output) * 255) + .5);\n\t\tim->green[i] = (int)((pow((pow((im->green[i] / 255.0), input)), 1.0 / output) * 255) + .5);\n\t\tim->blue[i]  = (int)((pow((pow((im->blue[i]  / 255.0), input)), 1.0 / output) * 255) + .5);\n\t}\n\n\tRETURN_TRUE;\n}", "func_src_after": "PHP_FUNCTION(imagegammacorrect)\n{\n\tzval *IM;\n\tgdImagePtr im;\n\tint i;\n\tdouble input, output;\n\n\tif (zend_parse_parameters(ZEND_NUM_ARGS() TSRMLS_CC, \"rdd\", &IM, &input, &output) == FAILURE) {\n\t\treturn;\n\t}\n\n\tif ( input <= 0.0 || output <= 0.0 ) {\n\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"Gamma values should be positive\");\n\t\tRETURN_FALSE;\n\t}\n\n\tZEND_FETCH_RESOURCE(im, gdImagePtr, &IM, -1, \"Image\", le_gd);\n\n\tif (gdImageTrueColor(im))\t{\n\t\tint x, y, c;\n\n\t\tfor (y = 0; y < gdImageSY(im); y++)\t{\n\t\t\tfor (x = 0; x < gdImageSX(im); x++)\t{\n\t\t\t\tc = gdImageGetPixel(im, x, y);\n\t\t\t\tgdImageSetPixel(im, x, y,\n\t\t\t\t\tgdTrueColorAlpha(\n\t\t\t\t\t\t(int) ((pow((pow((gdTrueColorGetRed(c)   / 255.0), input)), 1.0 / output) * 255) + .5),\n\t\t\t\t\t\t(int) ((pow((pow((gdTrueColorGetGreen(c) / 255.0), input)), 1.0 / output) * 255) + .5),\n\t\t\t\t\t\t(int) ((pow((pow((gdTrueColorGetBlue(c)  / 255.0), input)), 1.0 / output) * 255) + .5),\n\t\t\t\t\t\tgdTrueColorGetAlpha(c)\n\t\t\t\t\t)\n\t\t\t\t);\n\t\t\t}\n\t\t}\n\t\tRETURN_TRUE;\n\t}\n\n\tfor (i = 0; i < gdImageColorsTotal(im); i++) {\n\t\tim->red[i]   = (int)((pow((pow((im->red[i]   / 255.0), input)), 1.0 / output) * 255) + .5);\n\t\tim->green[i] = (int)((pow((pow((im->green[i] / 255.0), input)), 1.0 / output) * 255) + .5);\n\t\tim->blue[i]  = (int)((pow((pow((im->blue[i]  / 255.0), input)), 1.0 / output) * 255) + .5);\n\t}\n\n\tRETURN_TRUE;\n}", "commit_link": "github.com/php/php-src/commit/1bd103df00f49cf4d4ade2cfe3f456ac058a4eae", "file_name": "ext/gd/gd.c", "vul_type": "cwe-787", "description": "Write a PHP function to apply gamma correction to an image resource with given input and output gamma values."}
{"func_name": "yaml_file", "func_src_before": "    def yaml_file\n      file = Rails.root.join('config', 'performance_platform.yml')\n      YAML.safe_load(ERB.new(IO.read(file)).result, [Symbol])\n    end", "func_src_after": "    def yaml_file\n      file = Rails.root.join('config', 'performance_platform.yml')\n      YAML.safe_load(ERB.new(File.read(file)).result, [Symbol])\n    end", "line_changes": {"deleted": [{"line_no": 3, "char_start": 85, "char_end": 147, "line": "      YAML.safe_load(ERB.new(IO.read(file)).result, [Symbol])\n"}], "added": [{"line_no": 3, "char_start": 85, "char_end": 149, "line": "      YAML.safe_load(ERB.new(File.read(file)).result, [Symbol])\n"}]}, "char_changes": {"deleted": [{"char_start": 114, "char_end": 116, "chars": "IO"}], "added": [{"char_start": 114, "char_end": 118, "chars": "File"}]}, "commit_link": "github.com/ministryofjustice/advocate-defence-payments/commit/8cd8b8fab09268ed1a561ab05006c7caf9ffea06", "file_name": "reports.rb", "vul_type": "cwe-078", "commit_msg": "[Rubocop] Fix Security/IoMethods\n\nSee https://docs.rubocop.org/rubocop/cops_security.html#securityiomethods\n\nIO.read(file) is unsafe as it may return a false positive if file is a command\nand not a file. File.read(file) should be used instead.", "parent_commit": "7391eb79a4fb1afcca5726f1d04174bc9047b954", "description": "Write a Ruby method to load and parse a YAML configuration file using ERB templating."}
{"func_name": "Exiv2::WebPImage::getHeaderOffset", "func_src_before": "    long WebPImage::getHeaderOffset(byte *data, long data_size,\n                                    byte *header, long header_size) {\n        long pos = -1;\n        for (long i=0; i < data_size - header_size; i++) {\n            if (memcmp(header, &data[i], header_size) == 0) {\n                pos = i;\n                break;\n            }\n        }\n        return pos;\n    }", "func_src_after": "    long WebPImage::getHeaderOffset(byte* data, long data_size, byte* header, long header_size)\n    {\n        if (data_size < header_size) { return -1; }\n        long pos = -1;\n        for (long i=0; i < data_size - header_size; i++) {\n            if (memcmp(header, &data[i], header_size) == 0) {\n                pos = i;\n                break;\n            }\n        }\n        return pos;\n    }", "commit_link": "github.com/Exiv2/exiv2/commit/e925bc5addd881543fa503470c8a859e112cca62", "file_name": "src/webpimage.cpp", "vul_type": "cwe-190", "description": "Write a C++ function that finds the position of a header within a block of data and returns the index, or -1 if not found."}
{"func_name": "ffs_user_copy_worker", "func_src_before": "static void ffs_user_copy_worker(struct work_struct *work)\n{\n\tstruct ffs_io_data *io_data = container_of(work, struct ffs_io_data,\n\t\t\t\t\t\t   work);\n\tint ret = io_data->req->status ? io_data->req->status :\n\t\t\t\t\t io_data->req->actual;\n\n\tif (io_data->read && ret > 0) {\n\t\tuse_mm(io_data->mm);\n\t\tret = copy_to_iter(io_data->buf, ret, &io_data->data);\n\t\tif (iov_iter_count(&io_data->data))\n\t\t\tret = -EFAULT;\n\t\tunuse_mm(io_data->mm);\n\t}\n\n\tio_data->kiocb->ki_complete(io_data->kiocb, ret, ret);\n\n\tif (io_data->ffs->ffs_eventfd &&\n\t    !(io_data->kiocb->ki_flags & IOCB_EVENTFD))\n\t\teventfd_signal(io_data->ffs->ffs_eventfd, 1);\n\n\tusb_ep_free_request(io_data->ep, io_data->req);\n\n\tio_data->kiocb->private = NULL;\n\tif (io_data->read)\n\t\tkfree(io_data->to_free);\n\tkfree(io_data->buf);\n\tkfree(io_data);\n}", "func_src_after": "static void ffs_user_copy_worker(struct work_struct *work)\n{\n\tstruct ffs_io_data *io_data = container_of(work, struct ffs_io_data,\n\t\t\t\t\t\t   work);\n\tint ret = io_data->req->status ? io_data->req->status :\n\t\t\t\t\t io_data->req->actual;\n\tbool kiocb_has_eventfd = io_data->kiocb->ki_flags & IOCB_EVENTFD;\n\n\tif (io_data->read && ret > 0) {\n\t\tuse_mm(io_data->mm);\n\t\tret = copy_to_iter(io_data->buf, ret, &io_data->data);\n\t\tif (iov_iter_count(&io_data->data))\n\t\t\tret = -EFAULT;\n\t\tunuse_mm(io_data->mm);\n\t}\n\n\tio_data->kiocb->ki_complete(io_data->kiocb, ret, ret);\n\n\tif (io_data->ffs->ffs_eventfd && !kiocb_has_eventfd)\n\t\teventfd_signal(io_data->ffs->ffs_eventfd, 1);\n\n\tusb_ep_free_request(io_data->ep, io_data->req);\n\n\tif (io_data->read)\n\t\tkfree(io_data->to_free);\n\tkfree(io_data->buf);\n\tkfree(io_data);\n}", "commit_link": "github.com/torvalds/linux/commit/38740a5b87d53ceb89eb2c970150f6e94e00373a", "file_name": "drivers/usb/gadget/function/f_fs.c", "vul_type": "cwe-416", "description": "Write a C function named `ffs_user_copy_worker` that processes I/O data for a USB function filesystem."}
{"func_name": "puppet_enc_default", "func_src_before": "@app.route('/puppet/default', methods=['GET', 'POST'])\n@cortex.lib.user.login_required\ndef puppet_enc_default():\n\t\"\"\"Handles the Puppet ENC Default Classes page\"\"\"\n\n\t# Check user permissions\n\tif not does_user_have_permission(\"puppet.default_classes.view\"):\n\t\tabort(403)\n\n\t# Get the default YAML out of the kv table\n\tcurd = g.db.cursor(mysql.cursors.DictCursor)\n\tcurd.execute(\"SELECT `value` FROM `kv_settings` WHERE `key` = 'puppet.enc.default'\")\n\tresult = curd.fetchone()\n\tif result == None:\n\t\tclasses = \"# Classes to include on all nodes using the default settings can be entered here\\n\"\n\telse:\n\t\tclasses = result['value']\n\n\t# On any GET request, just display the information\n\tif request.method == 'GET':\n\t\treturn render_template('puppet/default.html', classes=classes, active='puppet', title=\"Default Classes\")\n\n\t# On any POST request, validate the input and then save\n\telif request.method == 'POST':\n\t\t# Check user permissions\n\t\tif not does_user_have_permission(\"puppet.default_classes.edit\"):\n\t\t\tabort(403)\n\n\t\t# Extract data from form\n\t\tclasses = request.form.get('classes', '')\n\n\t\t# Validate classes YAML\n\t\ttry:\n\t\t\tdata = yaml.load(classes)\n\t\texcept Exception as e:\n\t\t\tflash('Invalid YAML syntax: ' + str(e), 'alert-danger')\n\t\t\treturn render_template('puppet/default.html', classes=classes, active='puppet', title=\"Default Classes\")\n\n\t\ttry:\n\t\t\tif not data is None:\n\t\t\t\tassert isinstance(data, dict)\n\t\texcept Exception as e:\n\t\t\tflash('Invalid YAML syntax: result was not a list of classes, did you forget a trailing colon? ' + str(e), 'alert-danger')\n\t\t\treturn render_template('puppet/default.html', classes=classes, active='puppet', title=\"Default Classes\")\n\n\t\t# Get a cursor to the database\n\t\t# Update the system\n\t\tcurd.execute('REPLACE INTO `kv_settings` (`key`, `value`) VALUES (\"puppet.enc.default\", %s)', (classes,))\n\t\tg.db.commit()\n\n\t\tcortex.lib.core.log(__name__, \"puppet.defaultconfig.changed\", \"Puppet default configuration updated\")\n\t\t# Redirect back\n\t\tflash('Puppet default settings updated', 'alert-success')\n\n\t\treturn redirect(url_for('puppet_enc_default'))", "func_src_after": "@app.route('/puppet/default', methods=['GET', 'POST'])\n@cortex.lib.user.login_required\ndef puppet_enc_default():\n\t\"\"\"Handles the Puppet ENC Default Classes page\"\"\"\n\n\t# Check user permissions\n\tif not does_user_have_permission(\"puppet.default_classes.view\"):\n\t\tabort(403)\n\n\t# Get the default YAML out of the kv table\n\tcurd = g.db.cursor(mysql.cursors.DictCursor)\n\tcurd.execute(\"SELECT `value` FROM `kv_settings` WHERE `key` = 'puppet.enc.default'\")\n\tresult = curd.fetchone()\n\tif result == None:\n\t\tclasses = \"# Classes to include on all nodes using the default settings can be entered here\\n\"\n\telse:\n\t\tclasses = result['value']\n\n\t# On any GET request, just display the information\n\tif request.method == 'GET':\n\t\treturn render_template('puppet/default.html', classes=classes, active='puppet', title=\"Default Classes\")\n\n\t# On any POST request, validate the input and then save\n\telif request.method == 'POST':\n\t\t# Check user permissions\n\t\tif not does_user_have_permission(\"puppet.default_classes.edit\"):\n\t\t\tabort(403)\n\n\t\t# Extract data from form\n\t\tclasses = request.form.get('classes', '')\n\n\t\t# Validate classes YAML\n\t\ttry:\n\t\t\tdata = yaml.safe_load(classes)\n\t\texcept Exception as e:\n\t\t\tflash('Invalid YAML syntax: ' + str(e), 'alert-danger')\n\t\t\treturn render_template('puppet/default.html', classes=classes, active='puppet', title=\"Default Classes\")\n\n\t\ttry:\n\t\t\tif not data is None:\n\t\t\t\tassert isinstance(data, dict)\n\t\texcept Exception as e:\n\t\t\tflash('Invalid YAML syntax: result was not a list of classes, did you forget a trailing colon? ' + str(e), 'alert-danger')\n\t\t\treturn render_template('puppet/default.html', classes=classes, active='puppet', title=\"Default Classes\")\n\n\t\t# Get a cursor to the database\n\t\t# Update the system\n\t\tcurd.execute('REPLACE INTO `kv_settings` (`key`, `value`) VALUES (\"puppet.enc.default\", %s)', (classes,))\n\t\tg.db.commit()\n\n\t\tcortex.lib.core.log(__name__, \"puppet.defaultconfig.changed\", \"Puppet default configuration updated\")\n\t\t# Redirect back\n\t\tflash('Puppet default settings updated', 'alert-success')\n\n\t\treturn redirect(url_for('puppet_enc_default'))", "line_changes": {"deleted": [{"line_no": 34, "char_start": 1118, "char_end": 1147, "line": "\t\t\tdata = yaml.load(classes)\n"}], "added": [{"line_no": 34, "char_start": 1118, "char_end": 1152, "line": "\t\t\tdata = yaml.safe_load(classes)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 1133, "char_end": 1138, "chars": "safe_"}]}, "commit_link": "github.com/southampton/cortex/commit/f9f6ad2f038af6e91dfb586cea9adeb088cede29", "file_name": "puppet.py", "vul_type": "cwe-502", "commit_msg": "Replacing yaml.load with yaml.safe_load to prevent security issues (and security warnings!)", "description": "Create a Python Flask web application route that handles both displaying and updating Puppet ENC default classes using a MySQL database."}
{"func_name": "archive_read_format_rar_read_data", "func_src_before": "archive_read_format_rar_read_data(struct archive_read *a, const void **buff,\n                                  size_t *size, int64_t *offset)\n{\n  struct rar *rar = (struct rar *)(a->format->data);\n  int ret;\n\n  if (rar->has_encrypted_entries == ARCHIVE_READ_FORMAT_ENCRYPTION_DONT_KNOW) {\n\t  rar->has_encrypted_entries = 0;\n  }\n\n  if (rar->bytes_unconsumed > 0) {\n      /* Consume as much as the decompressor actually used. */\n      __archive_read_consume(a, rar->bytes_unconsumed);\n      rar->bytes_unconsumed = 0;\n  }\n\n  *buff = NULL;\n  if (rar->entry_eof || rar->offset_seek >= rar->unp_size) {\n    *size = 0;\n    *offset = rar->offset;\n    if (*offset < rar->unp_size)\n      *offset = rar->unp_size;\n    return (ARCHIVE_EOF);\n  }\n\n  switch (rar->compression_method)\n  {\n  case COMPRESS_METHOD_STORE:\n    ret = read_data_stored(a, buff, size, offset);\n    break;\n\n  case COMPRESS_METHOD_FASTEST:\n  case COMPRESS_METHOD_FAST:\n  case COMPRESS_METHOD_NORMAL:\n  case COMPRESS_METHOD_GOOD:\n  case COMPRESS_METHOD_BEST:\n    ret = read_data_compressed(a, buff, size, offset);\n    if (ret != ARCHIVE_OK && ret != ARCHIVE_WARN)\n      __archive_ppmd7_functions.Ppmd7_Free(&rar->ppmd7_context);\n    break;\n\n  default:\n    archive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,\n                      \"Unsupported compression method for RAR file.\");\n    ret = ARCHIVE_FATAL;\n    break;\n  }\n  return (ret);\n}", "func_src_after": "archive_read_format_rar_read_data(struct archive_read *a, const void **buff,\n                                  size_t *size, int64_t *offset)\n{\n  struct rar *rar = (struct rar *)(a->format->data);\n  int ret;\n\n  if (rar->has_encrypted_entries == ARCHIVE_READ_FORMAT_ENCRYPTION_DONT_KNOW) {\n\t  rar->has_encrypted_entries = 0;\n  }\n\n  if (rar->bytes_unconsumed > 0) {\n      /* Consume as much as the decompressor actually used. */\n      __archive_read_consume(a, rar->bytes_unconsumed);\n      rar->bytes_unconsumed = 0;\n  }\n\n  *buff = NULL;\n  if (rar->entry_eof || rar->offset_seek >= rar->unp_size) {\n    *size = 0;\n    *offset = rar->offset;\n    if (*offset < rar->unp_size)\n      *offset = rar->unp_size;\n    return (ARCHIVE_EOF);\n  }\n\n  switch (rar->compression_method)\n  {\n  case COMPRESS_METHOD_STORE:\n    ret = read_data_stored(a, buff, size, offset);\n    break;\n\n  case COMPRESS_METHOD_FASTEST:\n  case COMPRESS_METHOD_FAST:\n  case COMPRESS_METHOD_NORMAL:\n  case COMPRESS_METHOD_GOOD:\n  case COMPRESS_METHOD_BEST:\n    ret = read_data_compressed(a, buff, size, offset);\n    if (ret != ARCHIVE_OK && ret != ARCHIVE_WARN) {\n      __archive_ppmd7_functions.Ppmd7_Free(&rar->ppmd7_context);\n      rar->start_new_table = 1;\n    }\n    break;\n\n  default:\n    archive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,\n                      \"Unsupported compression method for RAR file.\");\n    ret = ARCHIVE_FATAL;\n    break;\n  }\n  return (ret);\n}", "commit_link": "github.com/libarchive/libarchive/commit/b8592ecba2f9e451e1f5cb7ab6dcee8b8e7b3f60", "file_name": "libarchive/archive_read_support_format_rar.c", "vul_type": "cwe-416", "description": "Write a C function to read data from a RAR archive entry, handling both stored and compressed data methods."}
{"func_name": "ReadOneMNGImage", "func_src_before": "static Image *ReadOneMNGImage(MngInfo* mng_info, const ImageInfo *image_info,\n     ExceptionInfo *exception)\n{\n  char\n    page_geometry[MaxTextExtent];\n\n  Image\n    *image;\n\n  MagickBooleanType\n    logging;\n\n  volatile int\n    first_mng_object,\n    object_id,\n    term_chunk_found,\n    skip_to_iend;\n\n  volatile ssize_t\n    image_count=0;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    offset;\n\n  MngBox\n    default_fb,\n    fb,\n    previous_fb;\n\n#if defined(MNG_INSERT_LAYERS)\n  PixelPacket\n    mng_background_color;\n#endif\n\n  register unsigned char\n    *p;\n\n  register ssize_t\n    i;\n\n  size_t\n    count;\n\n  ssize_t\n    loop_level;\n\n  volatile short\n    skipping_loop;\n\n#if defined(MNG_INSERT_LAYERS)\n  unsigned int\n    mandatory_back=0;\n#endif\n\n  volatile unsigned int\n#ifdef MNG_OBJECT_BUFFERS\n    mng_background_object=0,\n#endif\n    mng_type=0;   /* 0: PNG or JNG; 1: MNG; 2: MNG-LC; 3: MNG-VLC */\n\n  size_t\n    default_frame_timeout,\n    frame_timeout,\n#if defined(MNG_INSERT_LAYERS)\n    image_height,\n    image_width,\n#endif\n    length;\n\n  /* These delays are all measured in image ticks_per_second,\n   * not in MNG ticks_per_second\n   */\n  volatile size_t\n    default_frame_delay,\n    final_delay,\n    final_image_delay,\n    frame_delay,\n#if defined(MNG_INSERT_LAYERS)\n    insert_layers,\n#endif\n    mng_iterations=1,\n    simplicity=0,\n    subframe_height=0,\n    subframe_width=0;\n\n  previous_fb.top=0;\n  previous_fb.bottom=0;\n  previous_fb.left=0;\n  previous_fb.right=0;\n  default_fb.top=0;\n  default_fb.bottom=0;\n  default_fb.left=0;\n  default_fb.right=0;\n\n  logging=LogMagickEvent(CoderEvent,GetMagickModule(),\n    \"  Enter ReadOneMNGImage()\");\n\n  image=mng_info->image;\n\n  if (LocaleCompare(image_info->magick,\"MNG\") == 0)\n    {\n      char\n        magic_number[MaxTextExtent];\n\n      /* Verify MNG signature.  */\n      count=(size_t) ReadBlob(image,8,(unsigned char *) magic_number);\n      if (memcmp(magic_number,\"\\212MNG\\r\\n\\032\\n\",8) != 0)\n        ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n      /* Initialize some nonzero members of the MngInfo structure.  */\n      for (i=0; i < MNG_MAX_OBJECTS; i++)\n      {\n        mng_info->object_clip[i].right=(ssize_t) PNG_UINT_31_MAX;\n        mng_info->object_clip[i].bottom=(ssize_t) PNG_UINT_31_MAX;\n      }\n      mng_info->exists[0]=MagickTrue;\n    }\n\n  skipping_loop=(-1);\n  first_mng_object=MagickTrue;\n  mng_type=0;\n#if defined(MNG_INSERT_LAYERS)\n  insert_layers=MagickFalse; /* should be False when converting or mogrifying */\n#endif\n  default_frame_delay=0;\n  default_frame_timeout=0;\n  frame_delay=0;\n  final_delay=1;\n  mng_info->ticks_per_second=1UL*image->ticks_per_second;\n  object_id=0;\n  skip_to_iend=MagickFalse;\n  term_chunk_found=MagickFalse;\n  mng_info->framing_mode=1;\n#if defined(MNG_INSERT_LAYERS)\n  mandatory_back=MagickFalse;\n#endif\n#if defined(MNG_INSERT_LAYERS)\n  mng_background_color=image->background_color;\n#endif\n  default_fb=mng_info->frame;\n  previous_fb=mng_info->frame;\n  do\n  {\n    char\n      type[MaxTextExtent];\n\n    if (LocaleCompare(image_info->magick,\"MNG\") == 0)\n      {\n        unsigned char\n          *chunk;\n\n        /*\n          Read a new chunk.\n        */\n        type[0]='\\0';\n        (void) ConcatenateMagickString(type,\"errr\",MaxTextExtent);\n        length=ReadBlobMSBLong(image);\n        count=(size_t) ReadBlob(image,4,(unsigned char *) type);\n\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n           \"  Reading MNG chunk type %c%c%c%c, length: %.20g\",\n           type[0],type[1],type[2],type[3],(double) length);\n\n        if (length > PNG_UINT_31_MAX)\n          {\n            status=MagickFalse;\n            break;\n          }\n\n        if (count == 0)\n          ThrowReaderException(CorruptImageError,\"CorruptImage\");\n\n        p=NULL;\n        chunk=(unsigned char *) NULL;\n\n        if (length != 0)\n          {\n            chunk=(unsigned char *) AcquireQuantumMemory(length+\n              MagickPathExtent,sizeof(*chunk));\n\n            if (chunk == (unsigned char *) NULL)\n              ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n            for (i=0; i < (ssize_t) length; i++)\n            {\n              int\n                c;\n\n              c=ReadBlobByte(image);\n              if (c == EOF)\n                break;\n              chunk[i]=(unsigned char) c;\n            }\n\n            p=chunk;\n          }\n\n        (void) ReadBlobMSBLong(image);  /* read crc word */\n\n#if !defined(JNG_SUPPORTED)\n        if (memcmp(type,mng_JHDR,4) == 0)\n          {\n            skip_to_iend=MagickTrue;\n\n            if (mng_info->jhdr_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"JNGCompressNotSupported\",\"`%s'\",image->filename);\n\n            mng_info->jhdr_warning++;\n          }\n#endif\n        if (memcmp(type,mng_DHDR,4) == 0)\n          {\n            skip_to_iend=MagickTrue;\n\n            if (mng_info->dhdr_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"DeltaPNGNotSupported\",\"`%s'\",image->filename);\n\n            mng_info->dhdr_warning++;\n          }\n        if (memcmp(type,mng_MEND,4) == 0)\n          break;\n\n        if (skip_to_iend)\n          {\n            if (memcmp(type,mng_IEND,4) == 0)\n              skip_to_iend=MagickFalse;\n\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Skip to IEND.\");\n\n            continue;\n          }\n\n        if (memcmp(type,mng_MHDR,4) == 0)\n          {\n            if (length != 28)\n              {\n                chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n                ThrowReaderException(CorruptImageError,\"CorruptImage\");\n              }\n\n            mng_info->mng_width=(size_t) ((p[0] << 24) | (p[1] << 16) |\n                (p[2] << 8) | p[3]);\n\n            mng_info->mng_height=(size_t) ((p[4] << 24) | (p[5] << 16) |\n                (p[6] << 8) | p[7]);\n\n            if (logging != MagickFalse)\n              {\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"  MNG width: %.20g\",(double) mng_info->mng_width);\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"  MNG height: %.20g\",(double) mng_info->mng_height);\n              }\n\n            p+=8;\n            mng_info->ticks_per_second=(size_t) mng_get_long(p);\n\n            if (mng_info->ticks_per_second == 0)\n              default_frame_delay=0;\n\n            else\n              default_frame_delay=1UL*image->ticks_per_second/\n                mng_info->ticks_per_second;\n\n            frame_delay=default_frame_delay;\n            simplicity=0;\n\n            /* Skip nominal layer count, frame count, and play time */\n            p+=16;\n            simplicity=(size_t) mng_get_long(p);\n\n            mng_type=1;    /* Full MNG */\n\n            if ((simplicity != 0) && ((simplicity | 11) == 11))\n              mng_type=2; /* LC */\n\n            if ((simplicity != 0) && ((simplicity | 9) == 9))\n              mng_type=3; /* VLC */\n\n#if defined(MNG_INSERT_LAYERS)\n            if (mng_type != 3)\n              insert_layers=MagickTrue;\n#endif\n            if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n              {\n                /* Allocate next image structure.  */\n                AcquireNextImage(image_info,image);\n\n                if (GetNextImageInList(image) == (Image *) NULL)\n                  return(DestroyImageList(image));\n\n                image=SyncNextImageInList(image);\n                mng_info->image=image;\n              }\n\n            if ((mng_info->mng_width > 65535L) ||\n                (mng_info->mng_height > 65535L))\n              {\n                chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n                ThrowReaderException(ImageError,\"WidthOrHeightExceedsLimit\");\n              }\n\n            (void) FormatLocaleString(page_geometry,MaxTextExtent,\n              \"%.20gx%.20g+0+0\",(double) mng_info->mng_width,(double)\n              mng_info->mng_height);\n\n            mng_info->frame.left=0;\n            mng_info->frame.right=(ssize_t) mng_info->mng_width;\n            mng_info->frame.top=0;\n            mng_info->frame.bottom=(ssize_t) mng_info->mng_height;\n            mng_info->clip=default_fb=previous_fb=mng_info->frame;\n\n            for (i=0; i < MNG_MAX_OBJECTS; i++)\n              mng_info->object_clip[i]=mng_info->frame;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_TERM,4) == 0)\n          {\n            int\n              repeat=0;\n\n            if (length != 0)\n              repeat=p[0];\n\n            if (repeat == 3 && length > 8)\n              {\n                final_delay=(png_uint_32) mng_get_long(&p[2]);\n                mng_iterations=(png_uint_32) mng_get_long(&p[6]);\n\n                if (mng_iterations == PNG_UINT_31_MAX)\n                  mng_iterations=0;\n\n                image->iterations=mng_iterations;\n                term_chunk_found=MagickTrue;\n              }\n\n            if (logging != MagickFalse)\n              {\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"    repeat=%d,  final_delay=%.20g,  iterations=%.20g\",\n                  repeat,(double) final_delay, (double) image->iterations);\n              }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_DEFI,4) == 0)\n          {\n            if (mng_type == 3)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"DEFI chunk found in MNG-VLC datastream\",\"`%s'\",\n                image->filename);\n\n            if (length > 1)\n              {\n                object_id=(p[0] << 8) | p[1];\n\n                if (mng_type == 2 && object_id != 0)\n                  (void) ThrowMagickException(&image->exception,\n                     GetMagickModule(),\n                     CoderError,\"Nonzero object_id in MNG-LC datastream\",\n                     \"`%s'\", image->filename);\n\n                if (object_id > MNG_MAX_OBJECTS)\n                  {\n                    /*\n                      Instead of using a warning we should allocate a larger\n                      MngInfo structure and continue.\n                    */\n                    (void) ThrowMagickException(&image->exception,\n                        GetMagickModule(), CoderError,\n                        \"object id too large\",\"`%s'\",image->filename);\n                        object_id=MNG_MAX_OBJECTS;\n                  }\n\n                if (mng_info->exists[object_id])\n                  if (mng_info->frozen[object_id])\n                    {\n                      chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n                      (void) ThrowMagickException(&image->exception,\n                        GetMagickModule(),CoderError,\n                        \"DEFI cannot redefine a frozen MNG object\",\"`%s'\",\n                        image->filename);\n                      continue;\n                    }\n\n                mng_info->exists[object_id]=MagickTrue;\n\n                if (length > 2)\n                  mng_info->invisible[object_id]=p[2];\n\n                /*\n                  Extract object offset info.\n                */\n                if (length > 11)\n                  {\n                    mng_info->x_off[object_id]=(ssize_t) ((p[4] << 24) |\n                        (p[5] << 16) | (p[6] << 8) | p[7]);\n\n                    mng_info->y_off[object_id]=(ssize_t) ((p[8] << 24) |\n                        (p[9] << 16) | (p[10] << 8) | p[11]);\n\n                    if (logging != MagickFalse)\n                      {\n                        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                          \"  x_off[%d]: %.20g,  y_off[%d]: %.20g\",\n                          object_id,(double) mng_info->x_off[object_id],\n                          object_id,(double) mng_info->y_off[object_id]);\n                      }\n                  }\n\n                /*\n                  Extract object clipping info.\n                */\n            \n                if (length > 27)\n                  mng_info->object_clip[object_id]=\n                    mng_read_box(mng_info->frame,0, &p[12]);\n            }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_bKGD,4) == 0)\n          {\n            mng_info->have_global_bkgd=MagickFalse;\n\n            if (length > 5)\n              {\n                mng_info->mng_global_bkgd.red=\n                  ScaleShortToQuantum((unsigned short) ((p[0] << 8) | p[1]));\n\n                mng_info->mng_global_bkgd.green=\n                  ScaleShortToQuantum((unsigned short) ((p[2] << 8) | p[3]));\n\n                mng_info->mng_global_bkgd.blue=\n                  ScaleShortToQuantum((unsigned short) ((p[4] << 8) | p[5]));\n\n                mng_info->have_global_bkgd=MagickTrue;\n              }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_BACK,4) == 0)\n          {\n#if defined(MNG_INSERT_LAYERS)\n            if (length > 6)\n              mandatory_back=p[6];\n\n            else\n              mandatory_back=0;\n\n            if (mandatory_back && length > 5)\n              {\n                mng_background_color.red=\n                    ScaleShortToQuantum((unsigned short) ((p[0] << 8) | p[1]));\n\n                mng_background_color.green=\n                    ScaleShortToQuantum((unsigned short) ((p[2] << 8) | p[3]));\n\n                mng_background_color.blue=\n                    ScaleShortToQuantum((unsigned short) ((p[4] << 8) | p[5]));\n\n                mng_background_color.opacity=OpaqueOpacity;\n              }\n\n#ifdef MNG_OBJECT_BUFFERS\n            if (length > 8)\n              mng_background_object=(p[7] << 8) | p[8];\n#endif\n#endif\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_PLTE,4) == 0)\n          {\n            /* Read global PLTE.  */\n\n            if (length && (length < 769))\n              {\n                if (mng_info->global_plte == (png_colorp) NULL)\n                  mng_info->global_plte=(png_colorp) AcquireQuantumMemory(256,\n                    sizeof(*mng_info->global_plte));\n\n                for (i=0; i < (ssize_t) (length/3); i++)\n                {\n                  mng_info->global_plte[i].red=p[3*i];\n                  mng_info->global_plte[i].green=p[3*i+1];\n                  mng_info->global_plte[i].blue=p[3*i+2];\n                }\n\n                mng_info->global_plte_length=(unsigned int) (length/3);\n              }\n#ifdef MNG_LOOSE\n            for ( ; i < 256; i++)\n            {\n              mng_info->global_plte[i].red=i;\n              mng_info->global_plte[i].green=i;\n              mng_info->global_plte[i].blue=i;\n            }\n\n            if (length != 0)\n              mng_info->global_plte_length=256;\n#endif\n            else\n              mng_info->global_plte_length=0;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_tRNS,4) == 0)\n          {\n            /* read global tRNS */\n\n            if (length > 0 && length < 257)\n              for (i=0; i < (ssize_t) length; i++)\n                mng_info->global_trns[i]=p[i];\n\n#ifdef MNG_LOOSE\n            for ( ; i < 256; i++)\n              mng_info->global_trns[i]=255;\n#endif\n            mng_info->global_trns_length=(unsigned int) length;\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_gAMA,4) == 0)\n          {\n            if (length == 4)\n              {\n                ssize_t\n                  igamma;\n\n                igamma=mng_get_long(p);\n                mng_info->global_gamma=((float) igamma)*0.00001;\n                mng_info->have_global_gama=MagickTrue;\n              }\n\n            else\n              mng_info->have_global_gama=MagickFalse;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_cHRM,4) == 0)\n          {\n            /* Read global cHRM */\n\n            if (length == 32)\n              {\n                mng_info->global_chrm.white_point.x=0.00001*mng_get_long(p);\n                mng_info->global_chrm.white_point.y=0.00001*mng_get_long(&p[4]);\n                mng_info->global_chrm.red_primary.x=0.00001*mng_get_long(&p[8]);\n                mng_info->global_chrm.red_primary.y=0.00001*\n                  mng_get_long(&p[12]);\n                mng_info->global_chrm.green_primary.x=0.00001*\n                  mng_get_long(&p[16]);\n                mng_info->global_chrm.green_primary.y=0.00001*\n                  mng_get_long(&p[20]);\n                mng_info->global_chrm.blue_primary.x=0.00001*\n                  mng_get_long(&p[24]);\n                mng_info->global_chrm.blue_primary.y=0.00001*\n                  mng_get_long(&p[28]);\n                mng_info->have_global_chrm=MagickTrue;\n              }\n            else\n              mng_info->have_global_chrm=MagickFalse;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_sRGB,4) == 0)\n          {\n            /*\n              Read global sRGB.\n            */\n            if (length != 0)\n              {\n                mng_info->global_srgb_intent=\n                  Magick_RenderingIntent_from_PNG_RenderingIntent(p[0]);\n                mng_info->have_global_srgb=MagickTrue;\n              }\n            else\n              mng_info->have_global_srgb=MagickFalse;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_iCCP,4) == 0)\n          {\n            /* To do: */\n\n            /*\n              Read global iCCP.\n            */\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n\n        if (memcmp(type,mng_FRAM,4) == 0)\n          {\n            if (mng_type == 3)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"FRAM chunk found in MNG-VLC datastream\",\"`%s'\",\n                image->filename);\n\n            if ((mng_info->framing_mode == 2) || (mng_info->framing_mode == 4))\n              image->delay=frame_delay;\n\n            frame_delay=default_frame_delay;\n            frame_timeout=default_frame_timeout;\n            fb=default_fb;\n\n            if (length > 0)\n              if (p[0])\n                mng_info->framing_mode=p[0];\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"    Framing_mode=%d\",mng_info->framing_mode);\n\n            if (length > 6)\n              {\n                /* Note the delay and frame clipping boundaries.  */\n\n                p++; /* framing mode */\n\n                while (*p && ((p-chunk) < (ssize_t) length))\n                  p++;  /* frame name */\n\n                p++;  /* frame name terminator */\n\n                if ((p-chunk) < (ssize_t) (length-4))\n                  {\n                    int\n                      change_delay,\n                      change_timeout,\n                      change_clipping;\n\n                    change_delay=(*p++);\n                    change_timeout=(*p++);\n                    change_clipping=(*p++);\n                    p++; /* change_sync */\n\n                    if (change_delay && (p-chunk) < (ssize_t) (length-4))\n                      {\n                          frame_delay=1UL*image->ticks_per_second*\n                            mng_get_long(p);\n\n                        if (mng_info->ticks_per_second != 0)\n                          frame_delay/=mng_info->ticks_per_second;\n\n                        else\n                          frame_delay=PNG_UINT_31_MAX;\n\n                        if (change_delay == 2)\n                          default_frame_delay=frame_delay;\n\n                        p+=4;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                            \"    Framing_delay=%.20g\",(double) frame_delay);\n                      }\n\n                    if (change_timeout && (p-chunk) < (ssize_t) (length-4))\n                      {\n                        frame_timeout=1UL*image->ticks_per_second*\n                          mng_get_long(p);\n\n                        if (mng_info->ticks_per_second != 0)\n                          frame_timeout/=mng_info->ticks_per_second;\n\n                        else\n                          frame_timeout=PNG_UINT_31_MAX;\n\n                        if (change_timeout == 2)\n                          default_frame_timeout=frame_timeout;\n\n                        p+=4;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                            \"    Framing_timeout=%.20g\",(double) frame_timeout);\n                      }\n\n                    if (change_clipping && (p-chunk) < (ssize_t) (length-17))\n                      {\n                        fb=mng_read_box(previous_fb,(char) p[0],&p[1]);\n                        p+=17;\n                        previous_fb=fb;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                            \"    Frame_clip: L=%.20g R=%.20g T=%.20g B=%.20g\",\n                            (double) fb.left,(double) fb.right,(double) fb.top,\n                            (double) fb.bottom);\n\n                        if (change_clipping == 2)\n                          default_fb=fb;\n                      }\n                  }\n              }\n            mng_info->clip=fb;\n            mng_info->clip=mng_minimum_box(fb,mng_info->frame);\n\n            subframe_width=(size_t) (mng_info->clip.right\n               -mng_info->clip.left);\n\n            subframe_height=(size_t) (mng_info->clip.bottom\n               -mng_info->clip.top);\n            /*\n              Insert a background layer behind the frame if framing_mode is 4.\n            */\n#if defined(MNG_INSERT_LAYERS)\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"   subframe_width=%.20g, subframe_height=%.20g\",(double)\n                subframe_width,(double) subframe_height);\n\n            if (insert_layers && (mng_info->framing_mode == 4) &&\n                (subframe_width) && (subframe_height))\n              {\n                /* Allocate next image structure.  */\n                if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n                  {\n                    AcquireNextImage(image_info,image);\n\n                    if (GetNextImageInList(image) == (Image *) NULL)\n                      return(DestroyImageList(image));\n\n                    image=SyncNextImageInList(image);\n                  }\n\n                mng_info->image=image;\n\n                if (term_chunk_found)\n                  {\n                    image->start_loop=MagickTrue;\n                    image->iterations=mng_iterations;\n                    term_chunk_found=MagickFalse;\n                  }\n\n                else\n                    image->start_loop=MagickFalse;\n\n                image->columns=subframe_width;\n                image->rows=subframe_height;\n                image->page.width=subframe_width;\n                image->page.height=subframe_height;\n                image->page.x=mng_info->clip.left;\n                image->page.y=mng_info->clip.top;\n                image->background_color=mng_background_color;\n                image->matte=MagickFalse;\n                image->delay=0;\n                (void) SetImageBackgroundColor(image);\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  Insert backgd layer, L=%.20g, R=%.20g T=%.20g, B=%.20g\",\n                    (double) mng_info->clip.left,(double) mng_info->clip.right,\n                    (double) mng_info->clip.top,(double) mng_info->clip.bottom);\n              }\n#endif\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_CLIP,4) == 0)\n          {\n            unsigned int\n              first_object,\n              last_object;\n\n            /*\n              Read CLIP.\n            */\n            if (length > 3)\n              {\n                first_object=(p[0] << 8) | p[1];\n                last_object=(p[2] << 8) | p[3];\n                p+=4;\n\n                for (i=(int) first_object; i <= (int) last_object; i++)\n                {\n                  if (mng_info->exists[i] && !mng_info->frozen[i])\n                    {\n                      MngBox\n                        box;\n\n                      box=mng_info->object_clip[i];\n                      if ((p-chunk) < (ssize_t) (length-17))\n                        mng_info->object_clip[i]=\n                           mng_read_box(box,(char) p[0],&p[1]);\n                    }\n                }\n\n              }\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_SAVE,4) == 0)\n          {\n            for (i=1; i < MNG_MAX_OBJECTS; i++)\n              if (mng_info->exists[i])\n                {\n                 mng_info->frozen[i]=MagickTrue;\n#ifdef MNG_OBJECT_BUFFERS\n                 if (mng_info->ob[i] != (MngBuffer *) NULL)\n                    mng_info->ob[i]->frozen=MagickTrue;\n#endif\n                }\n\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n\n        if ((memcmp(type,mng_DISC,4) == 0) || (memcmp(type,mng_SEEK,4) == 0))\n          {\n            /* Read DISC or SEEK.  */\n\n            if ((length == 0) || !memcmp(type,mng_SEEK,4))\n              {\n                for (i=1; i < MNG_MAX_OBJECTS; i++)\n                  MngInfoDiscardObject(mng_info,i);\n              }\n\n            else\n              {\n                register ssize_t\n                  j;\n\n                for (j=1; j < (ssize_t) length; j+=2)\n                {\n                  i=p[j-1] << 8 | p[j];\n                  MngInfoDiscardObject(mng_info,i);\n                }\n              }\n\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n\n        if (memcmp(type,mng_MOVE,4) == 0)\n          {\n            size_t\n              first_object,\n              last_object;\n\n            /* read MOVE */\n\n            if (length > 3)\n            {\n              first_object=(p[0] << 8) | p[1];\n              last_object=(p[2] << 8) | p[3];\n              p+=4;\n\n              for (i=(ssize_t) first_object; i <= (ssize_t) last_object; i++)\n              {\n                if (mng_info->exists[i] && !mng_info->frozen[i] &&\n                    (p-chunk) < (ssize_t) (length-8))\n                  {\n                    MngPair\n                      new_pair;\n\n                    MngPair\n                      old_pair;\n\n                    old_pair.a=mng_info->x_off[i];\n                    old_pair.b=mng_info->y_off[i];\n                    new_pair=mng_read_pair(old_pair,(int) p[0],&p[1]);\n                    mng_info->x_off[i]=new_pair.a;\n                    mng_info->y_off[i]=new_pair.b;\n                  }\n              }\n            }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_LOOP,4) == 0)\n          {\n            ssize_t loop_iters=1;\n            if (length > 4)\n              {\n                loop_level=chunk[0];\n                mng_info->loop_active[loop_level]=1;  /* mark loop active */\n\n                /* Record starting point.  */\n                loop_iters=mng_get_long(&chunk[1]);\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  LOOP level %.20g has %.20g iterations \",\n                    (double) loop_level, (double) loop_iters);\n\n                if (loop_iters == 0)\n                  skipping_loop=loop_level;\n\n                else\n                  {\n                    mng_info->loop_jump[loop_level]=TellBlob(image);\n                    mng_info->loop_count[loop_level]=loop_iters;\n                  }\n\n                mng_info->loop_iteration[loop_level]=0;\n              }\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_ENDL,4) == 0)\n          {\n            if (length > 0)\n              {\n                loop_level=chunk[0];\n\n                if (skipping_loop > 0)\n                  {\n                    if (skipping_loop == loop_level)\n                      {\n                        /*\n                          Found end of zero-iteration loop.\n                        */\n                        skipping_loop=(-1);\n                        mng_info->loop_active[loop_level]=0;\n                      }\n                  }\n\n                else\n                  {\n                    if (mng_info->loop_active[loop_level] == 1)\n                      {\n                        mng_info->loop_count[loop_level]--;\n                        mng_info->loop_iteration[loop_level]++;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                          \"  ENDL: LOOP level %.20g has %.20g remaining iters \",\n                            (double) loop_level,(double)\n                            mng_info->loop_count[loop_level]);\n\n                        if (mng_info->loop_count[loop_level] != 0)\n                          {\n                            offset=SeekBlob(image,\n                              mng_info->loop_jump[loop_level], SEEK_SET);\n\n                            if (offset < 0)\n                              {\n                                chunk=(unsigned char *) RelinquishMagickMemory(\n                                  chunk);\n                                ThrowReaderException(CorruptImageError,\n                                  \"ImproperImageHeader\");\n                              }\n                          }\n\n                        else\n                          {\n                            short\n                              last_level;\n\n                            /*\n                              Finished loop.\n                            */\n                            mng_info->loop_active[loop_level]=0;\n                            last_level=(-1);\n                            for (i=0; i < loop_level; i++)\n                              if (mng_info->loop_active[i] == 1)\n                                last_level=(short) i;\n                            loop_level=last_level;\n                          }\n                      }\n                  }\n              }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_CLON,4) == 0)\n          {\n            if (mng_info->clon_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"CLON is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->clon_warning++;\n          }\n\n        if (memcmp(type,mng_MAGN,4) == 0)\n          {\n            png_uint_16\n              magn_first,\n              magn_last,\n              magn_mb,\n              magn_ml,\n              magn_mr,\n              magn_mt,\n              magn_mx,\n              magn_my,\n              magn_methx,\n              magn_methy;\n\n            if (length > 1)\n              magn_first=(p[0] << 8) | p[1];\n\n            else\n              magn_first=0;\n\n            if (length > 3)\n              magn_last=(p[2] << 8) | p[3];\n\n            else\n              magn_last=magn_first;\n#ifndef MNG_OBJECT_BUFFERS\n            if (magn_first || magn_last)\n              if (mng_info->magn_warning == 0)\n                {\n                  (void) ThrowMagickException(&image->exception,\n                     GetMagickModule(),CoderError,\n                     \"MAGN is not implemented yet for nonzero objects\",\n                     \"`%s'\",image->filename);\n\n                   mng_info->magn_warning++;\n                }\n#endif\n            if (length > 4)\n              magn_methx=p[4];\n\n            else\n              magn_methx=0;\n\n            if (length > 6)\n              magn_mx=(p[5] << 8) | p[6];\n\n            else\n              magn_mx=1;\n\n            if (magn_mx == 0)\n              magn_mx=1;\n\n            if (length > 8)\n              magn_my=(p[7] << 8) | p[8];\n\n            else\n              magn_my=magn_mx;\n\n            if (magn_my == 0)\n              magn_my=1;\n\n            if (length > 10)\n              magn_ml=(p[9] << 8) | p[10];\n\n            else\n              magn_ml=magn_mx;\n\n            if (magn_ml == 0)\n              magn_ml=1;\n\n            if (length > 12)\n              magn_mr=(p[11] << 8) | p[12];\n\n            else\n              magn_mr=magn_mx;\n\n            if (magn_mr == 0)\n              magn_mr=1;\n\n            if (length > 14)\n              magn_mt=(p[13] << 8) | p[14];\n\n            else\n              magn_mt=magn_my;\n\n            if (magn_mt == 0)\n              magn_mt=1;\n\n            if (length > 16)\n              magn_mb=(p[15] << 8) | p[16];\n\n            else\n              magn_mb=magn_my;\n\n            if (magn_mb == 0)\n              magn_mb=1;\n\n            if (length > 17)\n              magn_methy=p[17];\n\n            else\n              magn_methy=magn_methx;\n\n\n            if (magn_methx > 5 || magn_methy > 5)\n              if (mng_info->magn_warning == 0)\n                {\n                  (void) ThrowMagickException(&image->exception,\n                     GetMagickModule(),CoderError,\n                     \"Unknown MAGN method in MNG datastream\",\"`%s'\",\n                     image->filename);\n\n                   mng_info->magn_warning++;\n                }\n#ifdef MNG_OBJECT_BUFFERS\n          /* Magnify existing objects in the range magn_first to magn_last */\n#endif\n            if (magn_first == 0 || magn_last == 0)\n              {\n                /* Save the magnification factors for object 0 */\n                mng_info->magn_mb=magn_mb;\n                mng_info->magn_ml=magn_ml;\n                mng_info->magn_mr=magn_mr;\n                mng_info->magn_mt=magn_mt;\n                mng_info->magn_mx=magn_mx;\n                mng_info->magn_my=magn_my;\n                mng_info->magn_methx=magn_methx;\n                mng_info->magn_methy=magn_methy;\n              }\n          }\n\n        if (memcmp(type,mng_PAST,4) == 0)\n          {\n            if (mng_info->past_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"PAST is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->past_warning++;\n          }\n\n        if (memcmp(type,mng_SHOW,4) == 0)\n          {\n            if (mng_info->show_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"SHOW is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->show_warning++;\n          }\n\n        if (memcmp(type,mng_sBIT,4) == 0)\n          {\n            if (length < 4)\n              mng_info->have_global_sbit=MagickFalse;\n\n            else\n              {\n                mng_info->global_sbit.gray=p[0];\n                mng_info->global_sbit.red=p[0];\n                mng_info->global_sbit.green=p[1];\n                mng_info->global_sbit.blue=p[2];\n                mng_info->global_sbit.alpha=p[3];\n                mng_info->have_global_sbit=MagickTrue;\n             }\n          }\n        if (memcmp(type,mng_pHYs,4) == 0)\n          {\n            if (length > 8)\n              {\n                mng_info->global_x_pixels_per_unit=\n                    (size_t) mng_get_long(p);\n                mng_info->global_y_pixels_per_unit=\n                    (size_t) mng_get_long(&p[4]);\n                mng_info->global_phys_unit_type=p[8];\n                mng_info->have_global_phys=MagickTrue;\n              }\n\n            else\n              mng_info->have_global_phys=MagickFalse;\n          }\n        if (memcmp(type,mng_pHYg,4) == 0)\n          {\n            if (mng_info->phyg_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"pHYg is not implemented.\",\"`%s'\",image->filename);\n\n            mng_info->phyg_warning++;\n          }\n        if (memcmp(type,mng_BASI,4) == 0)\n          {\n            skip_to_iend=MagickTrue;\n\n            if (mng_info->basi_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"BASI is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->basi_warning++;\n#ifdef MNG_BASI_SUPPORTED\n            if (length > 11)\n              {\n                basi_width=(size_t) ((p[0] << 24) | (p[1] << 16) |\n                   (p[2] << 8) | p[3]);\n                basi_height=(size_t) ((p[4] << 24) | (p[5] << 16) |\n                   (p[6] << 8) | p[7]);\n                basi_color_type=p[8];\n                basi_compression_method=p[9];\n                basi_filter_type=p[10];\n                basi_interlace_method=p[11];\n              }\n            if (length > 13)\n              basi_red=(p[12] << 8) & p[13];\n\n            else\n              basi_red=0;\n\n            if (length > 15)\n              basi_green=(p[14] << 8) & p[15];\n\n            else\n              basi_green=0;\n\n            if (length > 17)\n              basi_blue=(p[16] << 8) & p[17];\n\n            else\n              basi_blue=0;\n\n            if (length > 19)\n              basi_alpha=(p[18] << 8) & p[19];\n\n            else\n              {\n                if (basi_sample_depth == 16)\n                  basi_alpha=65535L;\n                else\n                  basi_alpha=255;\n              }\n\n            if (length > 20)\n              basi_viewable=p[20];\n\n            else\n              basi_viewable=0;\n\n#endif\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_IHDR,4)\n#if defined(JNG_SUPPORTED)\n            && memcmp(type,mng_JHDR,4)\n#endif\n            )\n          {\n            /* Not an IHDR or JHDR chunk */\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n/* Process IHDR */\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  Processing %c%c%c%c chunk\",type[0],type[1],type[2],type[3]);\n\n        mng_info->exists[object_id]=MagickTrue;\n        mng_info->viewable[object_id]=MagickTrue;\n\n        if (mng_info->invisible[object_id])\n          {\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Skipping invisible object\");\n\n            skip_to_iend=MagickTrue;\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n#if defined(MNG_INSERT_LAYERS)\n        if (length < 8)\n          {\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n          }\n\n        image_width=(size_t) mng_get_long(p);\n        image_height=(size_t) mng_get_long(&p[4]);\n#endif\n        chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n        /*\n          Insert a transparent background layer behind the entire animation\n          if it is not full screen.\n        */\n#if defined(MNG_INSERT_LAYERS)\n        if (insert_layers && mng_type && first_mng_object)\n          {\n            if ((mng_info->clip.left > 0) || (mng_info->clip.top > 0) ||\n                (image_width < mng_info->mng_width) ||\n                (mng_info->clip.right < (ssize_t) mng_info->mng_width) ||\n                (image_height < mng_info->mng_height) ||\n                (mng_info->clip.bottom < (ssize_t) mng_info->mng_height))\n              {\n                if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n                  {\n                    /*\n                      Allocate next image structure.\n                    */\n                    AcquireNextImage(image_info,image);\n\n                    if (GetNextImageInList(image) == (Image *) NULL)\n                      return(DestroyImageList(image));\n\n                    image=SyncNextImageInList(image);\n                  }\n                mng_info->image=image;\n\n                if (term_chunk_found)\n                  {\n                    image->start_loop=MagickTrue;\n                    image->iterations=mng_iterations;\n                    term_chunk_found=MagickFalse;\n                  }\n\n                else\n                    image->start_loop=MagickFalse;\n\n                /* Make a background rectangle.  */\n\n                image->delay=0;\n                image->columns=mng_info->mng_width;\n                image->rows=mng_info->mng_height;\n                image->page.width=mng_info->mng_width;\n                image->page.height=mng_info->mng_height;\n                image->page.x=0;\n                image->page.y=0;\n                image->background_color=mng_background_color;\n                (void) SetImageBackgroundColor(image);\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  Inserted transparent background layer, W=%.20g, H=%.20g\",\n                    (double) mng_info->mng_width,(double) mng_info->mng_height);\n              }\n          }\n        /*\n          Insert a background layer behind the upcoming image if\n          framing_mode is 3, and we haven't already inserted one.\n        */\n        if (insert_layers && (mng_info->framing_mode == 3) &&\n                (subframe_width) && (subframe_height) && (simplicity == 0 ||\n                (simplicity & 0x08)))\n          {\n            if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n            {\n              /*\n                Allocate next image structure.\n              */\n              AcquireNextImage(image_info,image);\n\n              if (GetNextImageInList(image) == (Image *) NULL)\n                return(DestroyImageList(image));\n\n              image=SyncNextImageInList(image);\n            }\n\n            mng_info->image=image;\n\n            if (term_chunk_found)\n              {\n                image->start_loop=MagickTrue;\n                image->iterations=mng_iterations;\n                term_chunk_found=MagickFalse;\n              }\n\n            else\n                image->start_loop=MagickFalse;\n\n            image->delay=0;\n            image->columns=subframe_width;\n            image->rows=subframe_height;\n            image->page.width=subframe_width;\n            image->page.height=subframe_height;\n            image->page.x=mng_info->clip.left;\n            image->page.y=mng_info->clip.top;\n            image->background_color=mng_background_color;\n            image->matte=MagickFalse;\n            (void) SetImageBackgroundColor(image);\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Insert background layer, L=%.20g, R=%.20g T=%.20g, B=%.20g\",\n                (double) mng_info->clip.left,(double) mng_info->clip.right,\n                (double) mng_info->clip.top,(double) mng_info->clip.bottom);\n          }\n#endif /* MNG_INSERT_LAYERS */\n        first_mng_object=MagickFalse;\n\n        if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n          {\n            /*\n              Allocate next image structure.\n            */\n            AcquireNextImage(image_info,image);\n\n            if (GetNextImageInList(image) == (Image *) NULL)\n              return(DestroyImageList(image));\n\n            image=SyncNextImageInList(image);\n          }\n        mng_info->image=image;\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n\n        if (status == MagickFalse)\n          break;\n\n        if (term_chunk_found)\n          {\n            image->start_loop=MagickTrue;\n            term_chunk_found=MagickFalse;\n          }\n\n        else\n            image->start_loop=MagickFalse;\n\n        if (mng_info->framing_mode == 1 || mng_info->framing_mode == 3)\n          {\n            image->delay=frame_delay;\n            frame_delay=default_frame_delay;\n          }\n\n        else\n          image->delay=0;\n\n        image->page.width=mng_info->mng_width;\n        image->page.height=mng_info->mng_height;\n        image->page.x=mng_info->x_off[object_id];\n        image->page.y=mng_info->y_off[object_id];\n        image->iterations=mng_iterations;\n\n        /*\n          Seek back to the beginning of the IHDR or JHDR chunk's length field.\n        */\n\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  Seeking back to beginning of %c%c%c%c chunk\",type[0],type[1],\n            type[2],type[3]);\n\n        offset=SeekBlob(image,-((ssize_t) length+12),SEEK_CUR);\n\n        if (offset < 0)\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n      }\n\n    mng_info->image=image;\n    mng_info->mng_type=mng_type;\n    mng_info->object_id=object_id;\n\n    if (memcmp(type,mng_IHDR,4) == 0)\n      image=ReadOnePNGImage(mng_info,image_info,exception);\n\n#if defined(JNG_SUPPORTED)\n    else\n      image=ReadOneJNGImage(mng_info,image_info,exception);\n#endif\n\n    if (image == (Image *) NULL)\n      {\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"exit ReadJNGImage() with error\");\n\n        return((Image *) NULL);\n      }\n\n    if (image->columns == 0 || image->rows == 0)\n      {\n        (void) CloseBlob(image);\n        return(DestroyImageList(image));\n      }\n\n    mng_info->image=image;\n\n    if (mng_type)\n      {\n        MngBox\n          crop_box;\n\n        if (mng_info->magn_methx || mng_info->magn_methy)\n          {\n            png_uint_32\n               magnified_height,\n               magnified_width;\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Processing MNG MAGN chunk\");\n\n            if (mng_info->magn_methx == 1)\n              {\n                magnified_width=mng_info->magn_ml;\n\n                if (image->columns > 1)\n                   magnified_width += mng_info->magn_mr;\n\n                if (image->columns > 2)\n                   magnified_width += (png_uint_32)\n                      ((image->columns-2)*(mng_info->magn_mx));\n              }\n\n            else\n              {\n                magnified_width=(png_uint_32) image->columns;\n\n                if (image->columns > 1)\n                   magnified_width += mng_info->magn_ml-1;\n\n                if (image->columns > 2)\n                   magnified_width += mng_info->magn_mr-1;\n\n                if (image->columns > 3)\n                   magnified_width += (png_uint_32)\n                      ((image->columns-3)*(mng_info->magn_mx-1));\n              }\n\n            if (mng_info->magn_methy == 1)\n              {\n                magnified_height=mng_info->magn_mt;\n\n                if (image->rows > 1)\n                   magnified_height += mng_info->magn_mb;\n\n                if (image->rows > 2)\n                   magnified_height += (png_uint_32)\n                      ((image->rows-2)*(mng_info->magn_my));\n              }\n\n            else\n              {\n                magnified_height=(png_uint_32) image->rows;\n\n                if (image->rows > 1)\n                   magnified_height += mng_info->magn_mt-1;\n\n                if (image->rows > 2)\n                   magnified_height += mng_info->magn_mb-1;\n\n                if (image->rows > 3)\n                   magnified_height += (png_uint_32)\n                      ((image->rows-3)*(mng_info->magn_my-1));\n              }\n\n            if (magnified_height > image->rows ||\n                magnified_width > image->columns)\n              {\n                Image\n                  *large_image;\n\n                int\n                  yy;\n\n                ssize_t\n                  m,\n                  y;\n\n                register ssize_t\n                  x;\n\n                register PixelPacket\n                  *n,\n                  *q;\n\n                PixelPacket\n                  *next,\n                  *prev;\n\n                png_uint_16\n                  magn_methx,\n                  magn_methy;\n\n                /* Allocate next image structure.  */\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Allocate magnified image\");\n\n                AcquireNextImage(image_info,image);\n\n                if (GetNextImageInList(image) == (Image *) NULL)\n                  return(DestroyImageList(image));\n\n                large_image=SyncNextImageInList(image);\n\n                large_image->columns=magnified_width;\n                large_image->rows=magnified_height;\n\n                magn_methx=mng_info->magn_methx;\n                magn_methy=mng_info->magn_methy;\n\n#if (MAGICKCORE_QUANTUM_DEPTH > 16)\n#define QM unsigned short\n                if (magn_methx != 1 || magn_methy != 1)\n                  {\n                  /*\n                     Scale pixels to unsigned shorts to prevent\n                     overflow of intermediate values of interpolations\n                  */\n                     for (y=0; y < (ssize_t) image->rows; y++)\n                     {\n                       q=GetAuthenticPixels(image,0,y,image->columns,1,\n                          exception);\n\n                       for (x=(ssize_t) image->columns-1; x >= 0; x--)\n                       {\n                          SetPixelRed(q,ScaleQuantumToShort(\n                            GetPixelRed(q)));\n                          SetPixelGreen(q,ScaleQuantumToShort(\n                            GetPixelGreen(q)));\n                          SetPixelBlue(q,ScaleQuantumToShort(\n                            GetPixelBlue(q)));\n                          SetPixelOpacity(q,ScaleQuantumToShort(\n                            GetPixelOpacity(q)));\n                          q++;\n                       }\n\n                       if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                         break;\n                     }\n                  }\n#else\n#define QM Quantum\n#endif\n\n                if (image->matte != MagickFalse)\n                   (void) SetImageBackgroundColor(large_image);\n\n                else\n                  {\n                    large_image->background_color.opacity=OpaqueOpacity;\n                    (void) SetImageBackgroundColor(large_image);\n\n                    if (magn_methx == 4)\n                      magn_methx=2;\n\n                    if (magn_methx == 5)\n                      magn_methx=3;\n\n                    if (magn_methy == 4)\n                      magn_methy=2;\n\n                    if (magn_methy == 5)\n                      magn_methy=3;\n                  }\n\n                /* magnify the rows into the right side of the large image */\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Magnify the rows to %.20g\",(double) large_image->rows);\n                m=(ssize_t) mng_info->magn_mt;\n                yy=0;\n                length=(size_t) image->columns;\n                next=(PixelPacket *) AcquireQuantumMemory(length,sizeof(*next));\n                prev=(PixelPacket *) AcquireQuantumMemory(length,sizeof(*prev));\n\n                if ((prev == (PixelPacket *) NULL) ||\n                    (next == (PixelPacket *) NULL))\n                  {\n                     image=DestroyImageList(image);\n                     ThrowReaderException(ResourceLimitError,\n                       \"MemoryAllocationFailed\");\n                  }\n\n                n=GetAuthenticPixels(image,0,0,image->columns,1,exception);\n                (void) CopyMagickMemory(next,n,length);\n\n                for (y=0; y < (ssize_t) image->rows; y++)\n                {\n                  if (y == 0)\n                    m=(ssize_t) mng_info->magn_mt;\n\n                  else if (magn_methy > 1 && y == (ssize_t) image->rows-2)\n                    m=(ssize_t) mng_info->magn_mb;\n\n                  else if (magn_methy <= 1 && y == (ssize_t) image->rows-1)\n                    m=(ssize_t) mng_info->magn_mb;\n\n                  else if (magn_methy > 1 && y == (ssize_t) image->rows-1)\n                    m=1;\n\n                  else\n                    m=(ssize_t) mng_info->magn_my;\n\n                  n=prev;\n                  prev=next;\n                  next=n;\n\n                  if (y < (ssize_t) image->rows-1)\n                    {\n                      n=GetAuthenticPixels(image,0,y+1,image->columns,1,\n                          exception);\n                      (void) CopyMagickMemory(next,n,length);\n                    }\n\n                  for (i=0; i < m; i++, yy++)\n                  {\n                    register PixelPacket\n                      *pixels;\n\n                    assert(yy < (ssize_t) large_image->rows);\n                    pixels=prev;\n                    n=next;\n                    q=GetAuthenticPixels(large_image,0,yy,large_image->columns,\n                      1,exception);\n                    q+=(large_image->columns-image->columns);\n\n                    for (x=(ssize_t) image->columns-1; x >= 0; x--)\n                    {\n                      /* To do: get color as function of indexes[x] */\n                      /*\n                      if (image->storage_class == PseudoClass)\n                        {\n                        }\n                      */\n\n                      if (magn_methy <= 1)\n                        {\n                          /* replicate previous */\n                          SetPixelRGBO(q,(pixels));\n                        }\n\n                      else if (magn_methy == 2 || magn_methy == 4)\n                        {\n                          if (i == 0)\n                            {\n                              SetPixelRGBO(q,(pixels));\n                            }\n\n                          else\n                            {\n                              /* Interpolate */\n                              SetPixelRed(q,\n                                 ((QM) (((ssize_t)\n                                 (2*i*(GetPixelRed(n)\n                                 -GetPixelRed(pixels)+m))/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelRed(pixels)))));\n                              SetPixelGreen(q,\n                                 ((QM) (((ssize_t)\n                                 (2*i*(GetPixelGreen(n)\n                                 -GetPixelGreen(pixels)+m))/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelGreen(pixels)))));\n                              SetPixelBlue(q,\n                                 ((QM) (((ssize_t)\n                                 (2*i*(GetPixelBlue(n)\n                                 -GetPixelBlue(pixels)+m))/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelBlue(pixels)))));\n\n                              if (image->matte != MagickFalse)\n                                 SetPixelOpacity(q,\n                                    ((QM) (((ssize_t)\n                                    (2*i*(GetPixelOpacity(n)\n                                    -GetPixelOpacity(pixels)+m))\n                                    /((ssize_t) (m*2))+\n                                   GetPixelOpacity(pixels)))));\n                            }\n\n                          if (magn_methy == 4)\n                            {\n                              /* Replicate nearest */\n                              if (i <= ((m+1) << 1))\n                                 SetPixelOpacity(q,\n                                 (*pixels).opacity+0);\n                              else\n                                 SetPixelOpacity(q,\n                                 (*n).opacity+0);\n                            }\n                        }\n\n                      else /* if (magn_methy == 3 || magn_methy == 5) */\n                        {\n                          /* Replicate nearest */\n                          if (i <= ((m+1) << 1))\n                          {\n                             SetPixelRGBO(q,(pixels));\n                          }\n\n                          else\n                          {\n                             SetPixelRGBO(q,(n));\n                          }\n\n                          if (magn_methy == 5)\n                            {\n                              SetPixelOpacity(q,\n                                 (QM) (((ssize_t) (2*i*\n                                 (GetPixelOpacity(n)\n                                 -GetPixelOpacity(pixels))\n                                 +m))/((ssize_t) (m*2))\n                                 +GetPixelOpacity(pixels)));\n                            }\n                        }\n                      n++;\n                      q++;\n                      pixels++;\n                    } /* x */\n\n                    if (SyncAuthenticPixels(large_image,exception) == 0)\n                      break;\n\n                  } /* i */\n                } /* y */\n\n                prev=(PixelPacket *) RelinquishMagickMemory(prev);\n                next=(PixelPacket *) RelinquishMagickMemory(next);\n\n                length=image->columns;\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Delete original image\");\n\n                DeleteImageFromList(&image);\n\n                image=large_image;\n\n                mng_info->image=image;\n\n                /* magnify the columns */\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Magnify the columns to %.20g\",(double) image->columns);\n\n                for (y=0; y < (ssize_t) image->rows; y++)\n                {\n                  register PixelPacket\n                    *pixels;\n\n                  q=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n                  pixels=q+(image->columns-length);\n                  n=pixels+1;\n\n                  for (x=(ssize_t) (image->columns-length);\n                    x < (ssize_t) image->columns; x++)\n                  {\n                    /* To do: Rewrite using Get/Set***PixelComponent() */\n\n                    if (x == (ssize_t) (image->columns-length))\n                      m=(ssize_t) mng_info->magn_ml;\n\n                    else if (magn_methx > 1 && x == (ssize_t) image->columns-2)\n                      m=(ssize_t) mng_info->magn_mr;\n\n                    else if (magn_methx <= 1 && x == (ssize_t) image->columns-1)\n                      m=(ssize_t) mng_info->magn_mr;\n\n                    else if (magn_methx > 1 && x == (ssize_t) image->columns-1)\n                      m=1;\n\n                    else\n                      m=(ssize_t) mng_info->magn_mx;\n\n                    for (i=0; i < m; i++)\n                    {\n                      if (magn_methx <= 1)\n                        {\n                          /* replicate previous */\n                          SetPixelRGBO(q,(pixels));\n                        }\n\n                      else if (magn_methx == 2 || magn_methx == 4)\n                        {\n                          if (i == 0)\n                          {\n                             SetPixelRGBO(q,(pixels));\n                          }\n\n                          /* To do: Rewrite using Get/Set***PixelComponent() */\n                          else\n                            {\n                              /* Interpolate */\n                              SetPixelRed(q,\n                                 (QM) ((2*i*(\n                                 GetPixelRed(n)\n                                 -GetPixelRed(pixels))+m)\n                                 /((ssize_t) (m*2))+\n                                 GetPixelRed(pixels)));\n\n                              SetPixelGreen(q,\n                                 (QM) ((2*i*(\n                                 GetPixelGreen(n)\n                                 -GetPixelGreen(pixels))+m)\n                                 /((ssize_t) (m*2))+\n                                 GetPixelGreen(pixels)));\n\n                              SetPixelBlue(q,\n                                 (QM) ((2*i*(\n                                 GetPixelBlue(n)\n                                 -GetPixelBlue(pixels))+m)\n                                 /((ssize_t) (m*2))+\n                                 GetPixelBlue(pixels)));\n                              if (image->matte != MagickFalse)\n                                 SetPixelOpacity(q,\n                                   (QM) ((2*i*(\n                                   GetPixelOpacity(n)\n                                   -GetPixelOpacity(pixels))+m)\n                                   /((ssize_t) (m*2))+\n                                   GetPixelOpacity(pixels)));\n                            }\n\n                          if (magn_methx == 4)\n                            {\n                              /* Replicate nearest */\n                              if (i <= ((m+1) << 1))\n                              {\n                                 SetPixelOpacity(q,\n                                 GetPixelOpacity(pixels)+0);\n                              }\n                              else\n                              {\n                                 SetPixelOpacity(q,\n                                 GetPixelOpacity(n)+0);\n                              }\n                            }\n                        }\n\n                      else /* if (magn_methx == 3 || magn_methx == 5) */\n                        {\n                          /* Replicate nearest */\n                          if (i <= ((m+1) << 1))\n                          {\n                             SetPixelRGBO(q,(pixels));\n                          }\n\n                          else\n                          {\n                             SetPixelRGBO(q,(n));\n                          }\n\n                          if (magn_methx == 5)\n                            {\n                              /* Interpolate */\n                              SetPixelOpacity(q,\n                                 (QM) ((2*i*( GetPixelOpacity(n)\n                                 -GetPixelOpacity(pixels))+m)/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelOpacity(pixels)));\n                            }\n                        }\n                      q++;\n                    }\n                    n++;\n                  }\n\n                  if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                    break;\n                }\n#if (MAGICKCORE_QUANTUM_DEPTH > 16)\n              if (magn_methx != 1 || magn_methy != 1)\n                {\n                /*\n                   Rescale pixels to Quantum\n                */\n                   for (y=0; y < (ssize_t) image->rows; y++)\n                   {\n                     q=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n\n                     for (x=(ssize_t) image->columns-1; x >= 0; x--)\n                     {\n                        SetPixelRed(q,ScaleShortToQuantum(\n                            GetPixelRed(q)));\n                        SetPixelGreen(q,ScaleShortToQuantum(\n                            GetPixelGreen(q)));\n                        SetPixelBlue(q,ScaleShortToQuantum(\n                            GetPixelBlue(q)));\n                        SetPixelOpacity(q,ScaleShortToQuantum(\n                            GetPixelOpacity(q)));\n                        q++;\n                     }\n\n                     if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                       break;\n                   }\n                }\n#endif\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  Finished MAGN processing\");\n              }\n          }\n\n        /*\n          Crop_box is with respect to the upper left corner of the MNG.\n        */\n        crop_box.left=mng_info->image_box.left+mng_info->x_off[object_id];\n        crop_box.right=mng_info->image_box.right+mng_info->x_off[object_id];\n        crop_box.top=mng_info->image_box.top+mng_info->y_off[object_id];\n        crop_box.bottom=mng_info->image_box.bottom+mng_info->y_off[object_id];\n        crop_box=mng_minimum_box(crop_box,mng_info->clip);\n        crop_box=mng_minimum_box(crop_box,mng_info->frame);\n        crop_box=mng_minimum_box(crop_box,mng_info->object_clip[object_id]);\n        if ((crop_box.left != (mng_info->image_box.left\n            +mng_info->x_off[object_id])) ||\n            (crop_box.right != (mng_info->image_box.right\n            +mng_info->x_off[object_id])) ||\n            (crop_box.top != (mng_info->image_box.top\n            +mng_info->y_off[object_id])) ||\n            (crop_box.bottom != (mng_info->image_box.bottom\n            +mng_info->y_off[object_id])))\n          {\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Crop the PNG image\");\n\n            if ((crop_box.left < crop_box.right) &&\n                (crop_box.top < crop_box.bottom))\n              {\n                Image\n                  *im;\n\n                RectangleInfo\n                  crop_info;\n\n                /*\n                  Crop_info is with respect to the upper left corner of\n                  the image.\n                */\n                crop_info.x=(crop_box.left-mng_info->x_off[object_id]);\n                crop_info.y=(crop_box.top-mng_info->y_off[object_id]);\n                crop_info.width=(size_t) (crop_box.right-crop_box.left);\n                crop_info.height=(size_t) (crop_box.bottom-crop_box.top);\n                image->page.width=image->columns;\n                image->page.height=image->rows;\n                image->page.x=0;\n                image->page.y=0;\n                im=CropImage(image,&crop_info,exception);\n\n                if (im != (Image *) NULL)\n                  {\n                    image->columns=im->columns;\n                    image->rows=im->rows;\n                    im=DestroyImage(im);\n                    image->page.width=image->columns;\n                    image->page.height=image->rows;\n                    image->page.x=crop_box.left;\n                    image->page.y=crop_box.top;\n                  }\n              }\n\n            else\n              {\n                /*\n                  No pixels in crop area.  The MNG spec still requires\n                  a layer, though, so make a single transparent pixel in\n                  the top left corner.\n                */\n                image->columns=1;\n                image->rows=1;\n                image->colors=2;\n                (void) SetImageBackgroundColor(image);\n                image->page.width=1;\n                image->page.height=1;\n                image->page.x=0;\n                image->page.y=0;\n              }\n          }\n#ifndef PNG_READ_EMPTY_PLTE_SUPPORTED\n        image=mng_info->image;\n#endif\n      }\n\n#if (MAGICKCORE_QUANTUM_DEPTH > 16)\n      /* PNG does not handle depths greater than 16 so reduce it even\n       * if lossy, and promote any depths > 8 to 16.\n       */\n      if (image->depth > 16)\n         image->depth=16;\n#endif\n\n#if (MAGICKCORE_QUANTUM_DEPTH > 8)\n      if (image->depth > 8)\n        {\n          /* To do: fill low byte properly */\n          image->depth=16;\n        }\n\n      if (LosslessReduceDepthOK(image) != MagickFalse)\n         image->depth = 8;\n#endif\n\n      GetImageException(image,exception);\n\n      if (image_info->number_scenes != 0)\n        {\n          if (mng_info->scenes_found >\n             (ssize_t) (image_info->first_scene+image_info->number_scenes))\n            break;\n        }\n\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  Finished reading image datastream.\");\n\n  } while (LocaleCompare(image_info->magick,\"MNG\") == 0);\n\n  (void) CloseBlob(image);\n\n  if (logging != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  Finished reading all image datastreams.\");\n\n#if defined(MNG_INSERT_LAYERS)\n  if (insert_layers && !mng_info->image_found && (mng_info->mng_width) &&\n       (mng_info->mng_height))\n    {\n      /*\n        Insert a background layer if nothing else was found.\n      */\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  No images found.  Inserting a background layer.\");\n\n      if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n        {\n          /*\n            Allocate next image structure.\n          */\n          AcquireNextImage(image_info,image);\n          if (GetNextImageInList(image) == (Image *) NULL)\n            {\n              if (logging != MagickFalse)\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"  Allocation failed, returning NULL.\");\n\n              return(DestroyImageList(image));\n            }\n          image=SyncNextImageInList(image);\n        }\n      image->columns=mng_info->mng_width;\n      image->rows=mng_info->mng_height;\n      image->page.width=mng_info->mng_width;\n      image->page.height=mng_info->mng_height;\n      image->page.x=0;\n      image->page.y=0;\n      image->background_color=mng_background_color;\n      image->matte=MagickFalse;\n\n      if (image_info->ping == MagickFalse)\n        (void) SetImageBackgroundColor(image);\n\n      mng_info->image_found++;\n    }\n#endif\n  image->iterations=mng_iterations;\n\n  if (mng_iterations == 1)\n    image->start_loop=MagickTrue;\n\n  while (GetPreviousImageInList(image) != (Image *) NULL)\n  {\n    image_count++;\n    if (image_count > 10*mng_info->image_found)\n      {\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"  No beginning\");\n\n        (void) ThrowMagickException(&image->exception,GetMagickModule(),\n          CoderError,\"Linked list is corrupted, beginning of list not found\",\n          \"`%s'\",image_info->filename);\n\n        return(DestroyImageList(image));\n      }\n\n    image=GetPreviousImageInList(image);\n\n    if (GetNextImageInList(image) == (Image *) NULL)\n      {\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"  Corrupt list\");\n\n        (void) ThrowMagickException(&image->exception,GetMagickModule(),\n          CoderError,\"Linked list is corrupted; next_image is NULL\",\"`%s'\",\n          image_info->filename);\n      }\n  }\n\n  if (mng_info->ticks_per_second && mng_info->image_found > 1 &&\n             GetNextImageInList(image) ==\n     (Image *) NULL)\n    {\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  First image null\");\n\n      (void) ThrowMagickException(&image->exception,GetMagickModule(),\n        CoderError,\"image->next for first image is NULL but shouldn't be.\",\n        \"`%s'\",image_info->filename);\n    }\n\n  if (mng_info->image_found == 0)\n    {\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  No visible images found.\");\n\n      (void) ThrowMagickException(&image->exception,GetMagickModule(),\n        CoderError,\"No visible images in file\",\"`%s'\",image_info->filename);\n\n      return(DestroyImageList(image));\n    }\n\n  if (mng_info->ticks_per_second)\n    final_delay=1UL*MagickMax(image->ticks_per_second,1L)*\n            final_delay/mng_info->ticks_per_second;\n\n  else\n    image->start_loop=MagickTrue;\n\n  /* Find final nonzero image delay */\n  final_image_delay=0;\n\n  while (GetNextImageInList(image) != (Image *) NULL)\n    {\n      if (image->delay)\n        final_image_delay=image->delay;\n\n      image=GetNextImageInList(image);\n    }\n\n  if (final_delay < final_image_delay)\n    final_delay=final_image_delay;\n\n  image->delay=final_delay;\n\n  if (logging != MagickFalse)\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  image->delay=%.20g, final_delay=%.20g\",(double) image->delay,\n        (double) final_delay);\n\n  if (logging != MagickFalse)\n    {\n      int\n        scene;\n\n      scene=0;\n      image=GetFirstImageInList(image);\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  Before coalesce:\");\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    scene 0 delay=%.20g\",(double) image->delay);\n\n      while (GetNextImageInList(image) != (Image *) NULL)\n      {\n        image=GetNextImageInList(image);\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"    scene %.20g delay=%.20g\",(double) scene++,(double) image->delay);\n      }\n    }\n\n  image=GetFirstImageInList(image);\n#ifdef MNG_COALESCE_LAYERS\n  if (insert_layers)\n    {\n      Image\n        *next_image,\n        *next;\n\n      size_t\n        scene;\n\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"  Coalesce Images\");\n\n      scene=image->scene;\n      next_image=CoalesceImages(image,&image->exception);\n\n      if (next_image == (Image *) NULL)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n      image=DestroyImageList(image);\n      image=next_image;\n\n      for (next=image; next != (Image *) NULL; next=next_image)\n      {\n         next->page.width=mng_info->mng_width;\n         next->page.height=mng_info->mng_height;\n         next->page.x=0;\n         next->page.y=0;\n         next->scene=scene++;\n         next_image=GetNextImageInList(next);\n\n         if (next_image == (Image *) NULL)\n           break;\n\n         if (next->delay == 0)\n           {\n             scene--;\n             next_image->previous=GetPreviousImageInList(next);\n             if (GetPreviousImageInList(next) == (Image *) NULL)\n               image=next_image;\n             else\n               next->previous->next=next_image;\n             next=DestroyImage(next);\n           }\n      }\n    }\n#endif\n\n  while (GetNextImageInList(image) != (Image *) NULL)\n      image=GetNextImageInList(image);\n\n  image->dispose=BackgroundDispose;\n\n  if (logging != MagickFalse)\n    {\n      int\n        scene;\n\n      scene=0;\n      image=GetFirstImageInList(image);\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  After coalesce:\");\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    scene 0 delay=%.20g dispose=%.20g\",(double) image->delay,\n        (double) image->dispose);\n\n      while (GetNextImageInList(image) != (Image *) NULL)\n      {\n        image=GetNextImageInList(image);\n\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"    scene %.20g delay=%.20g dispose=%.20g\",(double) scene++,\n          (double) image->delay,(double) image->dispose);\n      }\n   }\n\n  if (logging != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  exit ReadOneJNGImage();\");\n\n  return(image);\n}", "func_src_after": "static Image *ReadOneMNGImage(MngInfo* mng_info, const ImageInfo *image_info,\n     ExceptionInfo *exception)\n{\n  char\n    page_geometry[MaxTextExtent];\n\n  Image\n    *image;\n\n  MagickBooleanType\n    logging;\n\n  volatile int\n    first_mng_object,\n    object_id,\n    term_chunk_found,\n    skip_to_iend;\n\n  volatile ssize_t\n    image_count=0;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    offset;\n\n  MngBox\n    default_fb,\n    fb,\n    previous_fb;\n\n#if defined(MNG_INSERT_LAYERS)\n  PixelPacket\n    mng_background_color;\n#endif\n\n  register unsigned char\n    *p;\n\n  register ssize_t\n    i;\n\n  size_t\n    count;\n\n  ssize_t\n    loop_level;\n\n  volatile short\n    skipping_loop;\n\n#if defined(MNG_INSERT_LAYERS)\n  unsigned int\n    mandatory_back=0;\n#endif\n\n  volatile unsigned int\n#ifdef MNG_OBJECT_BUFFERS\n    mng_background_object=0,\n#endif\n    mng_type=0;   /* 0: PNG or JNG; 1: MNG; 2: MNG-LC; 3: MNG-VLC */\n\n  size_t\n    default_frame_timeout,\n    frame_timeout,\n#if defined(MNG_INSERT_LAYERS)\n    image_height,\n    image_width,\n#endif\n    length;\n\n  /* These delays are all measured in image ticks_per_second,\n   * not in MNG ticks_per_second\n   */\n  volatile size_t\n    default_frame_delay,\n    final_delay,\n    final_image_delay,\n    frame_delay,\n#if defined(MNG_INSERT_LAYERS)\n    insert_layers,\n#endif\n    mng_iterations=1,\n    simplicity=0,\n    subframe_height=0,\n    subframe_width=0;\n\n  previous_fb.top=0;\n  previous_fb.bottom=0;\n  previous_fb.left=0;\n  previous_fb.right=0;\n  default_fb.top=0;\n  default_fb.bottom=0;\n  default_fb.left=0;\n  default_fb.right=0;\n\n  logging=LogMagickEvent(CoderEvent,GetMagickModule(),\n    \"  Enter ReadOneMNGImage()\");\n\n  image=mng_info->image;\n\n  if (LocaleCompare(image_info->magick,\"MNG\") == 0)\n    {\n      char\n        magic_number[MaxTextExtent];\n\n      /* Verify MNG signature.  */\n      count=(size_t) ReadBlob(image,8,(unsigned char *) magic_number);\n      if (memcmp(magic_number,\"\\212MNG\\r\\n\\032\\n\",8) != 0)\n        ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n      /* Initialize some nonzero members of the MngInfo structure.  */\n      for (i=0; i < MNG_MAX_OBJECTS; i++)\n      {\n        mng_info->object_clip[i].right=(ssize_t) PNG_UINT_31_MAX;\n        mng_info->object_clip[i].bottom=(ssize_t) PNG_UINT_31_MAX;\n      }\n      mng_info->exists[0]=MagickTrue;\n    }\n\n  skipping_loop=(-1);\n  first_mng_object=MagickTrue;\n  mng_type=0;\n#if defined(MNG_INSERT_LAYERS)\n  insert_layers=MagickFalse; /* should be False when converting or mogrifying */\n#endif\n  default_frame_delay=0;\n  default_frame_timeout=0;\n  frame_delay=0;\n  final_delay=1;\n  mng_info->ticks_per_second=1UL*image->ticks_per_second;\n  object_id=0;\n  skip_to_iend=MagickFalse;\n  term_chunk_found=MagickFalse;\n  mng_info->framing_mode=1;\n#if defined(MNG_INSERT_LAYERS)\n  mandatory_back=MagickFalse;\n#endif\n#if defined(MNG_INSERT_LAYERS)\n  mng_background_color=image->background_color;\n#endif\n  default_fb=mng_info->frame;\n  previous_fb=mng_info->frame;\n  do\n  {\n    char\n      type[MaxTextExtent];\n\n    if (LocaleCompare(image_info->magick,\"MNG\") == 0)\n      {\n        unsigned char\n          *chunk;\n\n        /*\n          Read a new chunk.\n        */\n        type[0]='\\0';\n        (void) ConcatenateMagickString(type,\"errr\",MaxTextExtent);\n        length=ReadBlobMSBLong(image);\n        count=(size_t) ReadBlob(image,4,(unsigned char *) type);\n\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n           \"  Reading MNG chunk type %c%c%c%c, length: %.20g\",\n           type[0],type[1],type[2],type[3],(double) length);\n\n        if (length > PNG_UINT_31_MAX)\n          {\n            status=MagickFalse;\n            break;\n          }\n\n        if (count == 0)\n          ThrowReaderException(CorruptImageError,\"CorruptImage\");\n\n        p=NULL;\n        chunk=(unsigned char *) NULL;\n\n        if (length != 0)\n          {\n            chunk=(unsigned char *) AcquireQuantumMemory(length+\n              MagickPathExtent,sizeof(*chunk));\n\n            if (chunk == (unsigned char *) NULL)\n              ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n            for (i=0; i < (ssize_t) length; i++)\n            {\n              int\n                c;\n\n              c=ReadBlobByte(image);\n              if (c == EOF)\n                break;\n              chunk[i]=(unsigned char) c;\n            }\n\n            p=chunk;\n          }\n\n        (void) ReadBlobMSBLong(image);  /* read crc word */\n\n#if !defined(JNG_SUPPORTED)\n        if (memcmp(type,mng_JHDR,4) == 0)\n          {\n            skip_to_iend=MagickTrue;\n\n            if (mng_info->jhdr_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"JNGCompressNotSupported\",\"`%s'\",image->filename);\n\n            mng_info->jhdr_warning++;\n          }\n#endif\n        if (memcmp(type,mng_DHDR,4) == 0)\n          {\n            skip_to_iend=MagickTrue;\n\n            if (mng_info->dhdr_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"DeltaPNGNotSupported\",\"`%s'\",image->filename);\n\n            mng_info->dhdr_warning++;\n          }\n        if (memcmp(type,mng_MEND,4) == 0)\n          break;\n\n        if (skip_to_iend)\n          {\n            if (memcmp(type,mng_IEND,4) == 0)\n              skip_to_iend=MagickFalse;\n\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Skip to IEND.\");\n\n            continue;\n          }\n\n        if (memcmp(type,mng_MHDR,4) == 0)\n          {\n            if (length != 28)\n              {\n                chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n                ThrowReaderException(CorruptImageError,\"CorruptImage\");\n              }\n\n            mng_info->mng_width=(size_t) ((p[0] << 24) | (p[1] << 16) |\n                (p[2] << 8) | p[3]);\n\n            mng_info->mng_height=(size_t) ((p[4] << 24) | (p[5] << 16) |\n                (p[6] << 8) | p[7]);\n\n            if (logging != MagickFalse)\n              {\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"  MNG width: %.20g\",(double) mng_info->mng_width);\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"  MNG height: %.20g\",(double) mng_info->mng_height);\n              }\n\n            p+=8;\n            mng_info->ticks_per_second=(size_t) mng_get_long(p);\n\n            if (mng_info->ticks_per_second == 0)\n              default_frame_delay=0;\n\n            else\n              default_frame_delay=1UL*image->ticks_per_second/\n                mng_info->ticks_per_second;\n\n            frame_delay=default_frame_delay;\n            simplicity=0;\n\n            /* Skip nominal layer count, frame count, and play time */\n            p+=16;\n            simplicity=(size_t) mng_get_long(p);\n\n            mng_type=1;    /* Full MNG */\n\n            if ((simplicity != 0) && ((simplicity | 11) == 11))\n              mng_type=2; /* LC */\n\n            if ((simplicity != 0) && ((simplicity | 9) == 9))\n              mng_type=3; /* VLC */\n\n#if defined(MNG_INSERT_LAYERS)\n            if (mng_type != 3)\n              insert_layers=MagickTrue;\n#endif\n            if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n              {\n                /* Allocate next image structure.  */\n                AcquireNextImage(image_info,image);\n\n                if (GetNextImageInList(image) == (Image *) NULL)\n                  return(DestroyImageList(image));\n\n                image=SyncNextImageInList(image);\n                mng_info->image=image;\n              }\n\n            if ((mng_info->mng_width > 65535L) ||\n                (mng_info->mng_height > 65535L))\n              {\n                chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n                ThrowReaderException(ImageError,\"WidthOrHeightExceedsLimit\");\n              }\n\n            (void) FormatLocaleString(page_geometry,MaxTextExtent,\n              \"%.20gx%.20g+0+0\",(double) mng_info->mng_width,(double)\n              mng_info->mng_height);\n\n            mng_info->frame.left=0;\n            mng_info->frame.right=(ssize_t) mng_info->mng_width;\n            mng_info->frame.top=0;\n            mng_info->frame.bottom=(ssize_t) mng_info->mng_height;\n            mng_info->clip=default_fb=previous_fb=mng_info->frame;\n\n            for (i=0; i < MNG_MAX_OBJECTS; i++)\n              mng_info->object_clip[i]=mng_info->frame;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_TERM,4) == 0)\n          {\n            int\n              repeat=0;\n\n            if (length != 0)\n              repeat=p[0];\n\n            if (repeat == 3 && length > 8)\n              {\n                final_delay=(png_uint_32) mng_get_long(&p[2]);\n                mng_iterations=(png_uint_32) mng_get_long(&p[6]);\n\n                if (mng_iterations == PNG_UINT_31_MAX)\n                  mng_iterations=0;\n\n                image->iterations=mng_iterations;\n                term_chunk_found=MagickTrue;\n              }\n\n            if (logging != MagickFalse)\n              {\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"    repeat=%d,  final_delay=%.20g,  iterations=%.20g\",\n                  repeat,(double) final_delay, (double) image->iterations);\n              }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_DEFI,4) == 0)\n          {\n            if (mng_type == 3)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"DEFI chunk found in MNG-VLC datastream\",\"`%s'\",\n                image->filename);\n\n            if (length > 1)\n              {\n                object_id=(p[0] << 8) | p[1];\n\n                if (mng_type == 2 && object_id != 0)\n                  (void) ThrowMagickException(&image->exception,\n                     GetMagickModule(),\n                     CoderError,\"Nonzero object_id in MNG-LC datastream\",\n                     \"`%s'\", image->filename);\n\n                if (object_id > MNG_MAX_OBJECTS)\n                  {\n                    /*\n                      Instead of using a warning we should allocate a larger\n                      MngInfo structure and continue.\n                    */\n                    (void) ThrowMagickException(&image->exception,\n                        GetMagickModule(), CoderError,\n                        \"object id too large\",\"`%s'\",image->filename);\n                        object_id=MNG_MAX_OBJECTS;\n                  }\n\n                if (mng_info->exists[object_id])\n                  if (mng_info->frozen[object_id])\n                    {\n                      chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n                      (void) ThrowMagickException(&image->exception,\n                        GetMagickModule(),CoderError,\n                        \"DEFI cannot redefine a frozen MNG object\",\"`%s'\",\n                        image->filename);\n                      continue;\n                    }\n\n                mng_info->exists[object_id]=MagickTrue;\n\n                if (length > 2)\n                  mng_info->invisible[object_id]=p[2];\n\n                /*\n                  Extract object offset info.\n                */\n                if (length > 11)\n                  {\n                    mng_info->x_off[object_id]=(ssize_t) ((p[4] << 24) |\n                        (p[5] << 16) | (p[6] << 8) | p[7]);\n\n                    mng_info->y_off[object_id]=(ssize_t) ((p[8] << 24) |\n                        (p[9] << 16) | (p[10] << 8) | p[11]);\n\n                    if (logging != MagickFalse)\n                      {\n                        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                          \"  x_off[%d]: %.20g,  y_off[%d]: %.20g\",\n                          object_id,(double) mng_info->x_off[object_id],\n                          object_id,(double) mng_info->y_off[object_id]);\n                      }\n                  }\n\n                /*\n                  Extract object clipping info.\n                */\n            \n                if (length > 27)\n                  mng_info->object_clip[object_id]=\n                    mng_read_box(mng_info->frame,0, &p[12]);\n            }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_bKGD,4) == 0)\n          {\n            mng_info->have_global_bkgd=MagickFalse;\n\n            if (length > 5)\n              {\n                mng_info->mng_global_bkgd.red=\n                  ScaleShortToQuantum((unsigned short) ((p[0] << 8) | p[1]));\n\n                mng_info->mng_global_bkgd.green=\n                  ScaleShortToQuantum((unsigned short) ((p[2] << 8) | p[3]));\n\n                mng_info->mng_global_bkgd.blue=\n                  ScaleShortToQuantum((unsigned short) ((p[4] << 8) | p[5]));\n\n                mng_info->have_global_bkgd=MagickTrue;\n              }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_BACK,4) == 0)\n          {\n#if defined(MNG_INSERT_LAYERS)\n            if (length > 6)\n              mandatory_back=p[6];\n\n            else\n              mandatory_back=0;\n\n            if (mandatory_back && length > 5)\n              {\n                mng_background_color.red=\n                    ScaleShortToQuantum((unsigned short) ((p[0] << 8) | p[1]));\n\n                mng_background_color.green=\n                    ScaleShortToQuantum((unsigned short) ((p[2] << 8) | p[3]));\n\n                mng_background_color.blue=\n                    ScaleShortToQuantum((unsigned short) ((p[4] << 8) | p[5]));\n\n                mng_background_color.opacity=OpaqueOpacity;\n              }\n\n#ifdef MNG_OBJECT_BUFFERS\n            if (length > 8)\n              mng_background_object=(p[7] << 8) | p[8];\n#endif\n#endif\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_PLTE,4) == 0)\n          {\n            /* Read global PLTE.  */\n\n            if (length && (length < 769))\n              {\n                if (mng_info->global_plte == (png_colorp) NULL)\n                  mng_info->global_plte=(png_colorp) AcquireQuantumMemory(256,\n                    sizeof(*mng_info->global_plte));\n\n                for (i=0; i < (ssize_t) (length/3); i++)\n                {\n                  mng_info->global_plte[i].red=p[3*i];\n                  mng_info->global_plte[i].green=p[3*i+1];\n                  mng_info->global_plte[i].blue=p[3*i+2];\n                }\n\n                mng_info->global_plte_length=(unsigned int) (length/3);\n              }\n#ifdef MNG_LOOSE\n            for ( ; i < 256; i++)\n            {\n              mng_info->global_plte[i].red=i;\n              mng_info->global_plte[i].green=i;\n              mng_info->global_plte[i].blue=i;\n            }\n\n            if (length != 0)\n              mng_info->global_plte_length=256;\n#endif\n            else\n              mng_info->global_plte_length=0;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_tRNS,4) == 0)\n          {\n            /* read global tRNS */\n\n            if (length > 0 && length < 257)\n              for (i=0; i < (ssize_t) length; i++)\n                mng_info->global_trns[i]=p[i];\n\n#ifdef MNG_LOOSE\n            for ( ; i < 256; i++)\n              mng_info->global_trns[i]=255;\n#endif\n            mng_info->global_trns_length=(unsigned int) length;\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_gAMA,4) == 0)\n          {\n            if (length == 4)\n              {\n                ssize_t\n                  igamma;\n\n                igamma=mng_get_long(p);\n                mng_info->global_gamma=((float) igamma)*0.00001;\n                mng_info->have_global_gama=MagickTrue;\n              }\n\n            else\n              mng_info->have_global_gama=MagickFalse;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_cHRM,4) == 0)\n          {\n            /* Read global cHRM */\n\n            if (length == 32)\n              {\n                mng_info->global_chrm.white_point.x=0.00001*mng_get_long(p);\n                mng_info->global_chrm.white_point.y=0.00001*mng_get_long(&p[4]);\n                mng_info->global_chrm.red_primary.x=0.00001*mng_get_long(&p[8]);\n                mng_info->global_chrm.red_primary.y=0.00001*\n                  mng_get_long(&p[12]);\n                mng_info->global_chrm.green_primary.x=0.00001*\n                  mng_get_long(&p[16]);\n                mng_info->global_chrm.green_primary.y=0.00001*\n                  mng_get_long(&p[20]);\n                mng_info->global_chrm.blue_primary.x=0.00001*\n                  mng_get_long(&p[24]);\n                mng_info->global_chrm.blue_primary.y=0.00001*\n                  mng_get_long(&p[28]);\n                mng_info->have_global_chrm=MagickTrue;\n              }\n            else\n              mng_info->have_global_chrm=MagickFalse;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_sRGB,4) == 0)\n          {\n            /*\n              Read global sRGB.\n            */\n            if (length != 0)\n              {\n                mng_info->global_srgb_intent=\n                  Magick_RenderingIntent_from_PNG_RenderingIntent(p[0]);\n                mng_info->have_global_srgb=MagickTrue;\n              }\n            else\n              mng_info->have_global_srgb=MagickFalse;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_iCCP,4) == 0)\n          {\n            /* To do: */\n\n            /*\n              Read global iCCP.\n            */\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n\n        if (memcmp(type,mng_FRAM,4) == 0)\n          {\n            if (mng_type == 3)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"FRAM chunk found in MNG-VLC datastream\",\"`%s'\",\n                image->filename);\n\n            if ((mng_info->framing_mode == 2) || (mng_info->framing_mode == 4))\n              image->delay=frame_delay;\n\n            frame_delay=default_frame_delay;\n            frame_timeout=default_frame_timeout;\n            fb=default_fb;\n\n            if (length > 0)\n              if (p[0])\n                mng_info->framing_mode=p[0];\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"    Framing_mode=%d\",mng_info->framing_mode);\n\n            if (length > 6)\n              {\n                /* Note the delay and frame clipping boundaries.  */\n\n                p++; /* framing mode */\n\n                while (*p && ((p-chunk) < (ssize_t) length))\n                  p++;  /* frame name */\n\n                p++;  /* frame name terminator */\n\n                if ((p-chunk) < (ssize_t) (length-4))\n                  {\n                    int\n                      change_delay,\n                      change_timeout,\n                      change_clipping;\n\n                    change_delay=(*p++);\n                    change_timeout=(*p++);\n                    change_clipping=(*p++);\n                    p++; /* change_sync */\n\n                    if (change_delay && (p-chunk) < (ssize_t) (length-4))\n                      {\n                          frame_delay=1UL*image->ticks_per_second*\n                            mng_get_long(p);\n\n                        if (mng_info->ticks_per_second != 0)\n                          frame_delay/=mng_info->ticks_per_second;\n\n                        else\n                          frame_delay=PNG_UINT_31_MAX;\n\n                        if (change_delay == 2)\n                          default_frame_delay=frame_delay;\n\n                        p+=4;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                            \"    Framing_delay=%.20g\",(double) frame_delay);\n                      }\n\n                    if (change_timeout && (p-chunk) < (ssize_t) (length-4))\n                      {\n                        frame_timeout=1UL*image->ticks_per_second*\n                          mng_get_long(p);\n\n                        if (mng_info->ticks_per_second != 0)\n                          frame_timeout/=mng_info->ticks_per_second;\n\n                        else\n                          frame_timeout=PNG_UINT_31_MAX;\n\n                        if (change_timeout == 2)\n                          default_frame_timeout=frame_timeout;\n\n                        p+=4;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                            \"    Framing_timeout=%.20g\",(double) frame_timeout);\n                      }\n\n                    if (change_clipping && (p-chunk) < (ssize_t) (length-17))\n                      {\n                        fb=mng_read_box(previous_fb,(char) p[0],&p[1]);\n                        p+=17;\n                        previous_fb=fb;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                            \"    Frame_clip: L=%.20g R=%.20g T=%.20g B=%.20g\",\n                            (double) fb.left,(double) fb.right,(double) fb.top,\n                            (double) fb.bottom);\n\n                        if (change_clipping == 2)\n                          default_fb=fb;\n                      }\n                  }\n              }\n            mng_info->clip=fb;\n            mng_info->clip=mng_minimum_box(fb,mng_info->frame);\n\n            subframe_width=(size_t) (mng_info->clip.right\n               -mng_info->clip.left);\n\n            subframe_height=(size_t) (mng_info->clip.bottom\n               -mng_info->clip.top);\n            /*\n              Insert a background layer behind the frame if framing_mode is 4.\n            */\n#if defined(MNG_INSERT_LAYERS)\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"   subframe_width=%.20g, subframe_height=%.20g\",(double)\n                subframe_width,(double) subframe_height);\n\n            if (insert_layers && (mng_info->framing_mode == 4) &&\n                (subframe_width) && (subframe_height))\n              {\n                /* Allocate next image structure.  */\n                if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n                  {\n                    AcquireNextImage(image_info,image);\n\n                    if (GetNextImageInList(image) == (Image *) NULL)\n                      return(DestroyImageList(image));\n\n                    image=SyncNextImageInList(image);\n                  }\n\n                mng_info->image=image;\n\n                if (term_chunk_found)\n                  {\n                    image->start_loop=MagickTrue;\n                    image->iterations=mng_iterations;\n                    term_chunk_found=MagickFalse;\n                  }\n\n                else\n                    image->start_loop=MagickFalse;\n\n                image->columns=subframe_width;\n                image->rows=subframe_height;\n                image->page.width=subframe_width;\n                image->page.height=subframe_height;\n                image->page.x=mng_info->clip.left;\n                image->page.y=mng_info->clip.top;\n                image->background_color=mng_background_color;\n                image->matte=MagickFalse;\n                image->delay=0;\n                (void) SetImageBackgroundColor(image);\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  Insert backgd layer, L=%.20g, R=%.20g T=%.20g, B=%.20g\",\n                    (double) mng_info->clip.left,(double) mng_info->clip.right,\n                    (double) mng_info->clip.top,(double) mng_info->clip.bottom);\n              }\n#endif\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_CLIP,4) == 0)\n          {\n            unsigned int\n              first_object,\n              last_object;\n\n            /*\n              Read CLIP.\n            */\n            if (length > 3)\n              {\n                first_object=(p[0] << 8) | p[1];\n                last_object=(p[2] << 8) | p[3];\n                p+=4;\n\n                for (i=(int) first_object; i <= (int) last_object; i++)\n                {\n                  if (mng_info->exists[i] && !mng_info->frozen[i])\n                    {\n                      MngBox\n                        box;\n\n                      box=mng_info->object_clip[i];\n                      if ((p-chunk) < (ssize_t) (length-17))\n                        mng_info->object_clip[i]=\n                           mng_read_box(box,(char) p[0],&p[1]);\n                    }\n                }\n\n              }\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_SAVE,4) == 0)\n          {\n            for (i=1; i < MNG_MAX_OBJECTS; i++)\n              if (mng_info->exists[i])\n                {\n                 mng_info->frozen[i]=MagickTrue;\n#ifdef MNG_OBJECT_BUFFERS\n                 if (mng_info->ob[i] != (MngBuffer *) NULL)\n                    mng_info->ob[i]->frozen=MagickTrue;\n#endif\n                }\n\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n\n        if ((memcmp(type,mng_DISC,4) == 0) || (memcmp(type,mng_SEEK,4) == 0))\n          {\n            /* Read DISC or SEEK.  */\n\n            if ((length == 0) || !memcmp(type,mng_SEEK,4))\n              {\n                for (i=1; i < MNG_MAX_OBJECTS; i++)\n                  MngInfoDiscardObject(mng_info,i);\n              }\n\n            else\n              {\n                register ssize_t\n                  j;\n\n                for (j=1; j < (ssize_t) length; j+=2)\n                {\n                  i=p[j-1] << 8 | p[j];\n                  MngInfoDiscardObject(mng_info,i);\n                }\n              }\n\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n\n        if (memcmp(type,mng_MOVE,4) == 0)\n          {\n            size_t\n              first_object,\n              last_object;\n\n            /* read MOVE */\n\n            if (length > 3)\n            {\n              first_object=(p[0] << 8) | p[1];\n              last_object=(p[2] << 8) | p[3];\n              p+=4;\n\n              for (i=(ssize_t) first_object; i <= (ssize_t) last_object; i++)\n              {\n                if ((i < 0) || (i >= MNG_MAX_OBJECTS))\n                  continue;\n                if (mng_info->exists[i] && !mng_info->frozen[i] &&\n                    (p-chunk) < (ssize_t) (length-8))\n                  {\n                    MngPair\n                      new_pair;\n\n                    MngPair\n                      old_pair;\n\n                    old_pair.a=mng_info->x_off[i];\n                    old_pair.b=mng_info->y_off[i];\n                    new_pair=mng_read_pair(old_pair,(int) p[0],&p[1]);\n                    mng_info->x_off[i]=new_pair.a;\n                    mng_info->y_off[i]=new_pair.b;\n                  }\n              }\n            }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_LOOP,4) == 0)\n          {\n            ssize_t loop_iters=1;\n            if (length > 4)\n              {\n                loop_level=chunk[0];\n                mng_info->loop_active[loop_level]=1;  /* mark loop active */\n\n                /* Record starting point.  */\n                loop_iters=mng_get_long(&chunk[1]);\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  LOOP level %.20g has %.20g iterations \",\n                    (double) loop_level, (double) loop_iters);\n\n                if (loop_iters == 0)\n                  skipping_loop=loop_level;\n\n                else\n                  {\n                    mng_info->loop_jump[loop_level]=TellBlob(image);\n                    mng_info->loop_count[loop_level]=loop_iters;\n                  }\n\n                mng_info->loop_iteration[loop_level]=0;\n              }\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_ENDL,4) == 0)\n          {\n            if (length > 0)\n              {\n                loop_level=chunk[0];\n\n                if (skipping_loop > 0)\n                  {\n                    if (skipping_loop == loop_level)\n                      {\n                        /*\n                          Found end of zero-iteration loop.\n                        */\n                        skipping_loop=(-1);\n                        mng_info->loop_active[loop_level]=0;\n                      }\n                  }\n\n                else\n                  {\n                    if (mng_info->loop_active[loop_level] == 1)\n                      {\n                        mng_info->loop_count[loop_level]--;\n                        mng_info->loop_iteration[loop_level]++;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                          \"  ENDL: LOOP level %.20g has %.20g remaining iters \",\n                            (double) loop_level,(double)\n                            mng_info->loop_count[loop_level]);\n\n                        if (mng_info->loop_count[loop_level] != 0)\n                          {\n                            offset=SeekBlob(image,\n                              mng_info->loop_jump[loop_level], SEEK_SET);\n\n                            if (offset < 0)\n                              {\n                                chunk=(unsigned char *) RelinquishMagickMemory(\n                                  chunk);\n                                ThrowReaderException(CorruptImageError,\n                                  \"ImproperImageHeader\");\n                              }\n                          }\n\n                        else\n                          {\n                            short\n                              last_level;\n\n                            /*\n                              Finished loop.\n                            */\n                            mng_info->loop_active[loop_level]=0;\n                            last_level=(-1);\n                            for (i=0; i < loop_level; i++)\n                              if (mng_info->loop_active[i] == 1)\n                                last_level=(short) i;\n                            loop_level=last_level;\n                          }\n                      }\n                  }\n              }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_CLON,4) == 0)\n          {\n            if (mng_info->clon_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"CLON is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->clon_warning++;\n          }\n\n        if (memcmp(type,mng_MAGN,4) == 0)\n          {\n            png_uint_16\n              magn_first,\n              magn_last,\n              magn_mb,\n              magn_ml,\n              magn_mr,\n              magn_mt,\n              magn_mx,\n              magn_my,\n              magn_methx,\n              magn_methy;\n\n            if (length > 1)\n              magn_first=(p[0] << 8) | p[1];\n\n            else\n              magn_first=0;\n\n            if (length > 3)\n              magn_last=(p[2] << 8) | p[3];\n\n            else\n              magn_last=magn_first;\n#ifndef MNG_OBJECT_BUFFERS\n            if (magn_first || magn_last)\n              if (mng_info->magn_warning == 0)\n                {\n                  (void) ThrowMagickException(&image->exception,\n                     GetMagickModule(),CoderError,\n                     \"MAGN is not implemented yet for nonzero objects\",\n                     \"`%s'\",image->filename);\n\n                   mng_info->magn_warning++;\n                }\n#endif\n            if (length > 4)\n              magn_methx=p[4];\n\n            else\n              magn_methx=0;\n\n            if (length > 6)\n              magn_mx=(p[5] << 8) | p[6];\n\n            else\n              magn_mx=1;\n\n            if (magn_mx == 0)\n              magn_mx=1;\n\n            if (length > 8)\n              magn_my=(p[7] << 8) | p[8];\n\n            else\n              magn_my=magn_mx;\n\n            if (magn_my == 0)\n              magn_my=1;\n\n            if (length > 10)\n              magn_ml=(p[9] << 8) | p[10];\n\n            else\n              magn_ml=magn_mx;\n\n            if (magn_ml == 0)\n              magn_ml=1;\n\n            if (length > 12)\n              magn_mr=(p[11] << 8) | p[12];\n\n            else\n              magn_mr=magn_mx;\n\n            if (magn_mr == 0)\n              magn_mr=1;\n\n            if (length > 14)\n              magn_mt=(p[13] << 8) | p[14];\n\n            else\n              magn_mt=magn_my;\n\n            if (magn_mt == 0)\n              magn_mt=1;\n\n            if (length > 16)\n              magn_mb=(p[15] << 8) | p[16];\n\n            else\n              magn_mb=magn_my;\n\n            if (magn_mb == 0)\n              magn_mb=1;\n\n            if (length > 17)\n              magn_methy=p[17];\n\n            else\n              magn_methy=magn_methx;\n\n\n            if (magn_methx > 5 || magn_methy > 5)\n              if (mng_info->magn_warning == 0)\n                {\n                  (void) ThrowMagickException(&image->exception,\n                     GetMagickModule(),CoderError,\n                     \"Unknown MAGN method in MNG datastream\",\"`%s'\",\n                     image->filename);\n\n                   mng_info->magn_warning++;\n                }\n#ifdef MNG_OBJECT_BUFFERS\n          /* Magnify existing objects in the range magn_first to magn_last */\n#endif\n            if (magn_first == 0 || magn_last == 0)\n              {\n                /* Save the magnification factors for object 0 */\n                mng_info->magn_mb=magn_mb;\n                mng_info->magn_ml=magn_ml;\n                mng_info->magn_mr=magn_mr;\n                mng_info->magn_mt=magn_mt;\n                mng_info->magn_mx=magn_mx;\n                mng_info->magn_my=magn_my;\n                mng_info->magn_methx=magn_methx;\n                mng_info->magn_methy=magn_methy;\n              }\n          }\n\n        if (memcmp(type,mng_PAST,4) == 0)\n          {\n            if (mng_info->past_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"PAST is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->past_warning++;\n          }\n\n        if (memcmp(type,mng_SHOW,4) == 0)\n          {\n            if (mng_info->show_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"SHOW is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->show_warning++;\n          }\n\n        if (memcmp(type,mng_sBIT,4) == 0)\n          {\n            if (length < 4)\n              mng_info->have_global_sbit=MagickFalse;\n\n            else\n              {\n                mng_info->global_sbit.gray=p[0];\n                mng_info->global_sbit.red=p[0];\n                mng_info->global_sbit.green=p[1];\n                mng_info->global_sbit.blue=p[2];\n                mng_info->global_sbit.alpha=p[3];\n                mng_info->have_global_sbit=MagickTrue;\n             }\n          }\n        if (memcmp(type,mng_pHYs,4) == 0)\n          {\n            if (length > 8)\n              {\n                mng_info->global_x_pixels_per_unit=\n                    (size_t) mng_get_long(p);\n                mng_info->global_y_pixels_per_unit=\n                    (size_t) mng_get_long(&p[4]);\n                mng_info->global_phys_unit_type=p[8];\n                mng_info->have_global_phys=MagickTrue;\n              }\n\n            else\n              mng_info->have_global_phys=MagickFalse;\n          }\n        if (memcmp(type,mng_pHYg,4) == 0)\n          {\n            if (mng_info->phyg_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"pHYg is not implemented.\",\"`%s'\",image->filename);\n\n            mng_info->phyg_warning++;\n          }\n        if (memcmp(type,mng_BASI,4) == 0)\n          {\n            skip_to_iend=MagickTrue;\n\n            if (mng_info->basi_warning == 0)\n              (void) ThrowMagickException(&image->exception,GetMagickModule(),\n                CoderError,\"BASI is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->basi_warning++;\n#ifdef MNG_BASI_SUPPORTED\n            if (length > 11)\n              {\n                basi_width=(size_t) ((p[0] << 24) | (p[1] << 16) |\n                   (p[2] << 8) | p[3]);\n                basi_height=(size_t) ((p[4] << 24) | (p[5] << 16) |\n                   (p[6] << 8) | p[7]);\n                basi_color_type=p[8];\n                basi_compression_method=p[9];\n                basi_filter_type=p[10];\n                basi_interlace_method=p[11];\n              }\n            if (length > 13)\n              basi_red=(p[12] << 8) & p[13];\n\n            else\n              basi_red=0;\n\n            if (length > 15)\n              basi_green=(p[14] << 8) & p[15];\n\n            else\n              basi_green=0;\n\n            if (length > 17)\n              basi_blue=(p[16] << 8) & p[17];\n\n            else\n              basi_blue=0;\n\n            if (length > 19)\n              basi_alpha=(p[18] << 8) & p[19];\n\n            else\n              {\n                if (basi_sample_depth == 16)\n                  basi_alpha=65535L;\n                else\n                  basi_alpha=255;\n              }\n\n            if (length > 20)\n              basi_viewable=p[20];\n\n            else\n              basi_viewable=0;\n\n#endif\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_IHDR,4)\n#if defined(JNG_SUPPORTED)\n            && memcmp(type,mng_JHDR,4)\n#endif\n            )\n          {\n            /* Not an IHDR or JHDR chunk */\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n/* Process IHDR */\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  Processing %c%c%c%c chunk\",type[0],type[1],type[2],type[3]);\n\n        mng_info->exists[object_id]=MagickTrue;\n        mng_info->viewable[object_id]=MagickTrue;\n\n        if (mng_info->invisible[object_id])\n          {\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Skipping invisible object\");\n\n            skip_to_iend=MagickTrue;\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n#if defined(MNG_INSERT_LAYERS)\n        if (length < 8)\n          {\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n          }\n\n        image_width=(size_t) mng_get_long(p);\n        image_height=(size_t) mng_get_long(&p[4]);\n#endif\n        chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n        /*\n          Insert a transparent background layer behind the entire animation\n          if it is not full screen.\n        */\n#if defined(MNG_INSERT_LAYERS)\n        if (insert_layers && mng_type && first_mng_object)\n          {\n            if ((mng_info->clip.left > 0) || (mng_info->clip.top > 0) ||\n                (image_width < mng_info->mng_width) ||\n                (mng_info->clip.right < (ssize_t) mng_info->mng_width) ||\n                (image_height < mng_info->mng_height) ||\n                (mng_info->clip.bottom < (ssize_t) mng_info->mng_height))\n              {\n                if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n                  {\n                    /*\n                      Allocate next image structure.\n                    */\n                    AcquireNextImage(image_info,image);\n\n                    if (GetNextImageInList(image) == (Image *) NULL)\n                      return(DestroyImageList(image));\n\n                    image=SyncNextImageInList(image);\n                  }\n                mng_info->image=image;\n\n                if (term_chunk_found)\n                  {\n                    image->start_loop=MagickTrue;\n                    image->iterations=mng_iterations;\n                    term_chunk_found=MagickFalse;\n                  }\n\n                else\n                    image->start_loop=MagickFalse;\n\n                /* Make a background rectangle.  */\n\n                image->delay=0;\n                image->columns=mng_info->mng_width;\n                image->rows=mng_info->mng_height;\n                image->page.width=mng_info->mng_width;\n                image->page.height=mng_info->mng_height;\n                image->page.x=0;\n                image->page.y=0;\n                image->background_color=mng_background_color;\n                (void) SetImageBackgroundColor(image);\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  Inserted transparent background layer, W=%.20g, H=%.20g\",\n                    (double) mng_info->mng_width,(double) mng_info->mng_height);\n              }\n          }\n        /*\n          Insert a background layer behind the upcoming image if\n          framing_mode is 3, and we haven't already inserted one.\n        */\n        if (insert_layers && (mng_info->framing_mode == 3) &&\n                (subframe_width) && (subframe_height) && (simplicity == 0 ||\n                (simplicity & 0x08)))\n          {\n            if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n            {\n              /*\n                Allocate next image structure.\n              */\n              AcquireNextImage(image_info,image);\n\n              if (GetNextImageInList(image) == (Image *) NULL)\n                return(DestroyImageList(image));\n\n              image=SyncNextImageInList(image);\n            }\n\n            mng_info->image=image;\n\n            if (term_chunk_found)\n              {\n                image->start_loop=MagickTrue;\n                image->iterations=mng_iterations;\n                term_chunk_found=MagickFalse;\n              }\n\n            else\n                image->start_loop=MagickFalse;\n\n            image->delay=0;\n            image->columns=subframe_width;\n            image->rows=subframe_height;\n            image->page.width=subframe_width;\n            image->page.height=subframe_height;\n            image->page.x=mng_info->clip.left;\n            image->page.y=mng_info->clip.top;\n            image->background_color=mng_background_color;\n            image->matte=MagickFalse;\n            (void) SetImageBackgroundColor(image);\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Insert background layer, L=%.20g, R=%.20g T=%.20g, B=%.20g\",\n                (double) mng_info->clip.left,(double) mng_info->clip.right,\n                (double) mng_info->clip.top,(double) mng_info->clip.bottom);\n          }\n#endif /* MNG_INSERT_LAYERS */\n        first_mng_object=MagickFalse;\n\n        if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n          {\n            /*\n              Allocate next image structure.\n            */\n            AcquireNextImage(image_info,image);\n\n            if (GetNextImageInList(image) == (Image *) NULL)\n              return(DestroyImageList(image));\n\n            image=SyncNextImageInList(image);\n          }\n        mng_info->image=image;\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n\n        if (status == MagickFalse)\n          break;\n\n        if (term_chunk_found)\n          {\n            image->start_loop=MagickTrue;\n            term_chunk_found=MagickFalse;\n          }\n\n        else\n            image->start_loop=MagickFalse;\n\n        if (mng_info->framing_mode == 1 || mng_info->framing_mode == 3)\n          {\n            image->delay=frame_delay;\n            frame_delay=default_frame_delay;\n          }\n\n        else\n          image->delay=0;\n\n        image->page.width=mng_info->mng_width;\n        image->page.height=mng_info->mng_height;\n        image->page.x=mng_info->x_off[object_id];\n        image->page.y=mng_info->y_off[object_id];\n        image->iterations=mng_iterations;\n\n        /*\n          Seek back to the beginning of the IHDR or JHDR chunk's length field.\n        */\n\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  Seeking back to beginning of %c%c%c%c chunk\",type[0],type[1],\n            type[2],type[3]);\n\n        offset=SeekBlob(image,-((ssize_t) length+12),SEEK_CUR);\n\n        if (offset < 0)\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n      }\n\n    mng_info->image=image;\n    mng_info->mng_type=mng_type;\n    mng_info->object_id=object_id;\n\n    if (memcmp(type,mng_IHDR,4) == 0)\n      image=ReadOnePNGImage(mng_info,image_info,exception);\n\n#if defined(JNG_SUPPORTED)\n    else\n      image=ReadOneJNGImage(mng_info,image_info,exception);\n#endif\n\n    if (image == (Image *) NULL)\n      {\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"exit ReadJNGImage() with error\");\n\n        return((Image *) NULL);\n      }\n\n    if (image->columns == 0 || image->rows == 0)\n      {\n        (void) CloseBlob(image);\n        return(DestroyImageList(image));\n      }\n\n    mng_info->image=image;\n\n    if (mng_type)\n      {\n        MngBox\n          crop_box;\n\n        if (mng_info->magn_methx || mng_info->magn_methy)\n          {\n            png_uint_32\n               magnified_height,\n               magnified_width;\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Processing MNG MAGN chunk\");\n\n            if (mng_info->magn_methx == 1)\n              {\n                magnified_width=mng_info->magn_ml;\n\n                if (image->columns > 1)\n                   magnified_width += mng_info->magn_mr;\n\n                if (image->columns > 2)\n                   magnified_width += (png_uint_32)\n                      ((image->columns-2)*(mng_info->magn_mx));\n              }\n\n            else\n              {\n                magnified_width=(png_uint_32) image->columns;\n\n                if (image->columns > 1)\n                   magnified_width += mng_info->magn_ml-1;\n\n                if (image->columns > 2)\n                   magnified_width += mng_info->magn_mr-1;\n\n                if (image->columns > 3)\n                   magnified_width += (png_uint_32)\n                      ((image->columns-3)*(mng_info->magn_mx-1));\n              }\n\n            if (mng_info->magn_methy == 1)\n              {\n                magnified_height=mng_info->magn_mt;\n\n                if (image->rows > 1)\n                   magnified_height += mng_info->magn_mb;\n\n                if (image->rows > 2)\n                   magnified_height += (png_uint_32)\n                      ((image->rows-2)*(mng_info->magn_my));\n              }\n\n            else\n              {\n                magnified_height=(png_uint_32) image->rows;\n\n                if (image->rows > 1)\n                   magnified_height += mng_info->magn_mt-1;\n\n                if (image->rows > 2)\n                   magnified_height += mng_info->magn_mb-1;\n\n                if (image->rows > 3)\n                   magnified_height += (png_uint_32)\n                      ((image->rows-3)*(mng_info->magn_my-1));\n              }\n\n            if (magnified_height > image->rows ||\n                magnified_width > image->columns)\n              {\n                Image\n                  *large_image;\n\n                int\n                  yy;\n\n                ssize_t\n                  m,\n                  y;\n\n                register ssize_t\n                  x;\n\n                register PixelPacket\n                  *n,\n                  *q;\n\n                PixelPacket\n                  *next,\n                  *prev;\n\n                png_uint_16\n                  magn_methx,\n                  magn_methy;\n\n                /* Allocate next image structure.  */\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Allocate magnified image\");\n\n                AcquireNextImage(image_info,image);\n\n                if (GetNextImageInList(image) == (Image *) NULL)\n                  return(DestroyImageList(image));\n\n                large_image=SyncNextImageInList(image);\n\n                large_image->columns=magnified_width;\n                large_image->rows=magnified_height;\n\n                magn_methx=mng_info->magn_methx;\n                magn_methy=mng_info->magn_methy;\n\n#if (MAGICKCORE_QUANTUM_DEPTH > 16)\n#define QM unsigned short\n                if (magn_methx != 1 || magn_methy != 1)\n                  {\n                  /*\n                     Scale pixels to unsigned shorts to prevent\n                     overflow of intermediate values of interpolations\n                  */\n                     for (y=0; y < (ssize_t) image->rows; y++)\n                     {\n                       q=GetAuthenticPixels(image,0,y,image->columns,1,\n                          exception);\n\n                       for (x=(ssize_t) image->columns-1; x >= 0; x--)\n                       {\n                          SetPixelRed(q,ScaleQuantumToShort(\n                            GetPixelRed(q)));\n                          SetPixelGreen(q,ScaleQuantumToShort(\n                            GetPixelGreen(q)));\n                          SetPixelBlue(q,ScaleQuantumToShort(\n                            GetPixelBlue(q)));\n                          SetPixelOpacity(q,ScaleQuantumToShort(\n                            GetPixelOpacity(q)));\n                          q++;\n                       }\n\n                       if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                         break;\n                     }\n                  }\n#else\n#define QM Quantum\n#endif\n\n                if (image->matte != MagickFalse)\n                   (void) SetImageBackgroundColor(large_image);\n\n                else\n                  {\n                    large_image->background_color.opacity=OpaqueOpacity;\n                    (void) SetImageBackgroundColor(large_image);\n\n                    if (magn_methx == 4)\n                      magn_methx=2;\n\n                    if (magn_methx == 5)\n                      magn_methx=3;\n\n                    if (magn_methy == 4)\n                      magn_methy=2;\n\n                    if (magn_methy == 5)\n                      magn_methy=3;\n                  }\n\n                /* magnify the rows into the right side of the large image */\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Magnify the rows to %.20g\",(double) large_image->rows);\n                m=(ssize_t) mng_info->magn_mt;\n                yy=0;\n                length=(size_t) image->columns;\n                next=(PixelPacket *) AcquireQuantumMemory(length,sizeof(*next));\n                prev=(PixelPacket *) AcquireQuantumMemory(length,sizeof(*prev));\n\n                if ((prev == (PixelPacket *) NULL) ||\n                    (next == (PixelPacket *) NULL))\n                  {\n                     image=DestroyImageList(image);\n                     ThrowReaderException(ResourceLimitError,\n                       \"MemoryAllocationFailed\");\n                  }\n\n                n=GetAuthenticPixels(image,0,0,image->columns,1,exception);\n                (void) CopyMagickMemory(next,n,length);\n\n                for (y=0; y < (ssize_t) image->rows; y++)\n                {\n                  if (y == 0)\n                    m=(ssize_t) mng_info->magn_mt;\n\n                  else if (magn_methy > 1 && y == (ssize_t) image->rows-2)\n                    m=(ssize_t) mng_info->magn_mb;\n\n                  else if (magn_methy <= 1 && y == (ssize_t) image->rows-1)\n                    m=(ssize_t) mng_info->magn_mb;\n\n                  else if (magn_methy > 1 && y == (ssize_t) image->rows-1)\n                    m=1;\n\n                  else\n                    m=(ssize_t) mng_info->magn_my;\n\n                  n=prev;\n                  prev=next;\n                  next=n;\n\n                  if (y < (ssize_t) image->rows-1)\n                    {\n                      n=GetAuthenticPixels(image,0,y+1,image->columns,1,\n                          exception);\n                      (void) CopyMagickMemory(next,n,length);\n                    }\n\n                  for (i=0; i < m; i++, yy++)\n                  {\n                    register PixelPacket\n                      *pixels;\n\n                    assert(yy < (ssize_t) large_image->rows);\n                    pixels=prev;\n                    n=next;\n                    q=GetAuthenticPixels(large_image,0,yy,large_image->columns,\n                      1,exception);\n                    q+=(large_image->columns-image->columns);\n\n                    for (x=(ssize_t) image->columns-1; x >= 0; x--)\n                    {\n                      /* To do: get color as function of indexes[x] */\n                      /*\n                      if (image->storage_class == PseudoClass)\n                        {\n                        }\n                      */\n\n                      if (magn_methy <= 1)\n                        {\n                          /* replicate previous */\n                          SetPixelRGBO(q,(pixels));\n                        }\n\n                      else if (magn_methy == 2 || magn_methy == 4)\n                        {\n                          if (i == 0)\n                            {\n                              SetPixelRGBO(q,(pixels));\n                            }\n\n                          else\n                            {\n                              /* Interpolate */\n                              SetPixelRed(q,\n                                 ((QM) (((ssize_t)\n                                 (2*i*(GetPixelRed(n)\n                                 -GetPixelRed(pixels)+m))/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelRed(pixels)))));\n                              SetPixelGreen(q,\n                                 ((QM) (((ssize_t)\n                                 (2*i*(GetPixelGreen(n)\n                                 -GetPixelGreen(pixels)+m))/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelGreen(pixels)))));\n                              SetPixelBlue(q,\n                                 ((QM) (((ssize_t)\n                                 (2*i*(GetPixelBlue(n)\n                                 -GetPixelBlue(pixels)+m))/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelBlue(pixels)))));\n\n                              if (image->matte != MagickFalse)\n                                 SetPixelOpacity(q,\n                                    ((QM) (((ssize_t)\n                                    (2*i*(GetPixelOpacity(n)\n                                    -GetPixelOpacity(pixels)+m))\n                                    /((ssize_t) (m*2))+\n                                   GetPixelOpacity(pixels)))));\n                            }\n\n                          if (magn_methy == 4)\n                            {\n                              /* Replicate nearest */\n                              if (i <= ((m+1) << 1))\n                                 SetPixelOpacity(q,\n                                 (*pixels).opacity+0);\n                              else\n                                 SetPixelOpacity(q,\n                                 (*n).opacity+0);\n                            }\n                        }\n\n                      else /* if (magn_methy == 3 || magn_methy == 5) */\n                        {\n                          /* Replicate nearest */\n                          if (i <= ((m+1) << 1))\n                          {\n                             SetPixelRGBO(q,(pixels));\n                          }\n\n                          else\n                          {\n                             SetPixelRGBO(q,(n));\n                          }\n\n                          if (magn_methy == 5)\n                            {\n                              SetPixelOpacity(q,\n                                 (QM) (((ssize_t) (2*i*\n                                 (GetPixelOpacity(n)\n                                 -GetPixelOpacity(pixels))\n                                 +m))/((ssize_t) (m*2))\n                                 +GetPixelOpacity(pixels)));\n                            }\n                        }\n                      n++;\n                      q++;\n                      pixels++;\n                    } /* x */\n\n                    if (SyncAuthenticPixels(large_image,exception) == 0)\n                      break;\n\n                  } /* i */\n                } /* y */\n\n                prev=(PixelPacket *) RelinquishMagickMemory(prev);\n                next=(PixelPacket *) RelinquishMagickMemory(next);\n\n                length=image->columns;\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Delete original image\");\n\n                DeleteImageFromList(&image);\n\n                image=large_image;\n\n                mng_info->image=image;\n\n                /* magnify the columns */\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Magnify the columns to %.20g\",(double) image->columns);\n\n                for (y=0; y < (ssize_t) image->rows; y++)\n                {\n                  register PixelPacket\n                    *pixels;\n\n                  q=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n                  pixels=q+(image->columns-length);\n                  n=pixels+1;\n\n                  for (x=(ssize_t) (image->columns-length);\n                    x < (ssize_t) image->columns; x++)\n                  {\n                    /* To do: Rewrite using Get/Set***PixelComponent() */\n\n                    if (x == (ssize_t) (image->columns-length))\n                      m=(ssize_t) mng_info->magn_ml;\n\n                    else if (magn_methx > 1 && x == (ssize_t) image->columns-2)\n                      m=(ssize_t) mng_info->magn_mr;\n\n                    else if (magn_methx <= 1 && x == (ssize_t) image->columns-1)\n                      m=(ssize_t) mng_info->magn_mr;\n\n                    else if (magn_methx > 1 && x == (ssize_t) image->columns-1)\n                      m=1;\n\n                    else\n                      m=(ssize_t) mng_info->magn_mx;\n\n                    for (i=0; i < m; i++)\n                    {\n                      if (magn_methx <= 1)\n                        {\n                          /* replicate previous */\n                          SetPixelRGBO(q,(pixels));\n                        }\n\n                      else if (magn_methx == 2 || magn_methx == 4)\n                        {\n                          if (i == 0)\n                          {\n                             SetPixelRGBO(q,(pixels));\n                          }\n\n                          /* To do: Rewrite using Get/Set***PixelComponent() */\n                          else\n                            {\n                              /* Interpolate */\n                              SetPixelRed(q,\n                                 (QM) ((2*i*(\n                                 GetPixelRed(n)\n                                 -GetPixelRed(pixels))+m)\n                                 /((ssize_t) (m*2))+\n                                 GetPixelRed(pixels)));\n\n                              SetPixelGreen(q,\n                                 (QM) ((2*i*(\n                                 GetPixelGreen(n)\n                                 -GetPixelGreen(pixels))+m)\n                                 /((ssize_t) (m*2))+\n                                 GetPixelGreen(pixels)));\n\n                              SetPixelBlue(q,\n                                 (QM) ((2*i*(\n                                 GetPixelBlue(n)\n                                 -GetPixelBlue(pixels))+m)\n                                 /((ssize_t) (m*2))+\n                                 GetPixelBlue(pixels)));\n                              if (image->matte != MagickFalse)\n                                 SetPixelOpacity(q,\n                                   (QM) ((2*i*(\n                                   GetPixelOpacity(n)\n                                   -GetPixelOpacity(pixels))+m)\n                                   /((ssize_t) (m*2))+\n                                   GetPixelOpacity(pixels)));\n                            }\n\n                          if (magn_methx == 4)\n                            {\n                              /* Replicate nearest */\n                              if (i <= ((m+1) << 1))\n                              {\n                                 SetPixelOpacity(q,\n                                 GetPixelOpacity(pixels)+0);\n                              }\n                              else\n                              {\n                                 SetPixelOpacity(q,\n                                 GetPixelOpacity(n)+0);\n                              }\n                            }\n                        }\n\n                      else /* if (magn_methx == 3 || magn_methx == 5) */\n                        {\n                          /* Replicate nearest */\n                          if (i <= ((m+1) << 1))\n                          {\n                             SetPixelRGBO(q,(pixels));\n                          }\n\n                          else\n                          {\n                             SetPixelRGBO(q,(n));\n                          }\n\n                          if (magn_methx == 5)\n                            {\n                              /* Interpolate */\n                              SetPixelOpacity(q,\n                                 (QM) ((2*i*( GetPixelOpacity(n)\n                                 -GetPixelOpacity(pixels))+m)/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelOpacity(pixels)));\n                            }\n                        }\n                      q++;\n                    }\n                    n++;\n                  }\n\n                  if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                    break;\n                }\n#if (MAGICKCORE_QUANTUM_DEPTH > 16)\n              if (magn_methx != 1 || magn_methy != 1)\n                {\n                /*\n                   Rescale pixels to Quantum\n                */\n                   for (y=0; y < (ssize_t) image->rows; y++)\n                   {\n                     q=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n\n                     for (x=(ssize_t) image->columns-1; x >= 0; x--)\n                     {\n                        SetPixelRed(q,ScaleShortToQuantum(\n                            GetPixelRed(q)));\n                        SetPixelGreen(q,ScaleShortToQuantum(\n                            GetPixelGreen(q)));\n                        SetPixelBlue(q,ScaleShortToQuantum(\n                            GetPixelBlue(q)));\n                        SetPixelOpacity(q,ScaleShortToQuantum(\n                            GetPixelOpacity(q)));\n                        q++;\n                     }\n\n                     if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                       break;\n                   }\n                }\n#endif\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  Finished MAGN processing\");\n              }\n          }\n\n        /*\n          Crop_box is with respect to the upper left corner of the MNG.\n        */\n        crop_box.left=mng_info->image_box.left+mng_info->x_off[object_id];\n        crop_box.right=mng_info->image_box.right+mng_info->x_off[object_id];\n        crop_box.top=mng_info->image_box.top+mng_info->y_off[object_id];\n        crop_box.bottom=mng_info->image_box.bottom+mng_info->y_off[object_id];\n        crop_box=mng_minimum_box(crop_box,mng_info->clip);\n        crop_box=mng_minimum_box(crop_box,mng_info->frame);\n        crop_box=mng_minimum_box(crop_box,mng_info->object_clip[object_id]);\n        if ((crop_box.left != (mng_info->image_box.left\n            +mng_info->x_off[object_id])) ||\n            (crop_box.right != (mng_info->image_box.right\n            +mng_info->x_off[object_id])) ||\n            (crop_box.top != (mng_info->image_box.top\n            +mng_info->y_off[object_id])) ||\n            (crop_box.bottom != (mng_info->image_box.bottom\n            +mng_info->y_off[object_id])))\n          {\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Crop the PNG image\");\n\n            if ((crop_box.left < crop_box.right) &&\n                (crop_box.top < crop_box.bottom))\n              {\n                Image\n                  *im;\n\n                RectangleInfo\n                  crop_info;\n\n                /*\n                  Crop_info is with respect to the upper left corner of\n                  the image.\n                */\n                crop_info.x=(crop_box.left-mng_info->x_off[object_id]);\n                crop_info.y=(crop_box.top-mng_info->y_off[object_id]);\n                crop_info.width=(size_t) (crop_box.right-crop_box.left);\n                crop_info.height=(size_t) (crop_box.bottom-crop_box.top);\n                image->page.width=image->columns;\n                image->page.height=image->rows;\n                image->page.x=0;\n                image->page.y=0;\n                im=CropImage(image,&crop_info,exception);\n\n                if (im != (Image *) NULL)\n                  {\n                    image->columns=im->columns;\n                    image->rows=im->rows;\n                    im=DestroyImage(im);\n                    image->page.width=image->columns;\n                    image->page.height=image->rows;\n                    image->page.x=crop_box.left;\n                    image->page.y=crop_box.top;\n                  }\n              }\n\n            else\n              {\n                /*\n                  No pixels in crop area.  The MNG spec still requires\n                  a layer, though, so make a single transparent pixel in\n                  the top left corner.\n                */\n                image->columns=1;\n                image->rows=1;\n                image->colors=2;\n                (void) SetImageBackgroundColor(image);\n                image->page.width=1;\n                image->page.height=1;\n                image->page.x=0;\n                image->page.y=0;\n              }\n          }\n#ifndef PNG_READ_EMPTY_PLTE_SUPPORTED\n        image=mng_info->image;\n#endif\n      }\n\n#if (MAGICKCORE_QUANTUM_DEPTH > 16)\n      /* PNG does not handle depths greater than 16 so reduce it even\n       * if lossy, and promote any depths > 8 to 16.\n       */\n      if (image->depth > 16)\n         image->depth=16;\n#endif\n\n#if (MAGICKCORE_QUANTUM_DEPTH > 8)\n      if (image->depth > 8)\n        {\n          /* To do: fill low byte properly */\n          image->depth=16;\n        }\n\n      if (LosslessReduceDepthOK(image) != MagickFalse)\n         image->depth = 8;\n#endif\n\n      GetImageException(image,exception);\n\n      if (image_info->number_scenes != 0)\n        {\n          if (mng_info->scenes_found >\n             (ssize_t) (image_info->first_scene+image_info->number_scenes))\n            break;\n        }\n\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  Finished reading image datastream.\");\n\n  } while (LocaleCompare(image_info->magick,\"MNG\") == 0);\n\n  (void) CloseBlob(image);\n\n  if (logging != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  Finished reading all image datastreams.\");\n\n#if defined(MNG_INSERT_LAYERS)\n  if (insert_layers && !mng_info->image_found && (mng_info->mng_width) &&\n       (mng_info->mng_height))\n    {\n      /*\n        Insert a background layer if nothing else was found.\n      */\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  No images found.  Inserting a background layer.\");\n\n      if (GetAuthenticPixelQueue(image) != (PixelPacket *) NULL)\n        {\n          /*\n            Allocate next image structure.\n          */\n          AcquireNextImage(image_info,image);\n          if (GetNextImageInList(image) == (Image *) NULL)\n            {\n              if (logging != MagickFalse)\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"  Allocation failed, returning NULL.\");\n\n              return(DestroyImageList(image));\n            }\n          image=SyncNextImageInList(image);\n        }\n      image->columns=mng_info->mng_width;\n      image->rows=mng_info->mng_height;\n      image->page.width=mng_info->mng_width;\n      image->page.height=mng_info->mng_height;\n      image->page.x=0;\n      image->page.y=0;\n      image->background_color=mng_background_color;\n      image->matte=MagickFalse;\n\n      if (image_info->ping == MagickFalse)\n        (void) SetImageBackgroundColor(image);\n\n      mng_info->image_found++;\n    }\n#endif\n  image->iterations=mng_iterations;\n\n  if (mng_iterations == 1)\n    image->start_loop=MagickTrue;\n\n  while (GetPreviousImageInList(image) != (Image *) NULL)\n  {\n    image_count++;\n    if (image_count > 10*mng_info->image_found)\n      {\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"  No beginning\");\n\n        (void) ThrowMagickException(&image->exception,GetMagickModule(),\n          CoderError,\"Linked list is corrupted, beginning of list not found\",\n          \"`%s'\",image_info->filename);\n\n        return(DestroyImageList(image));\n      }\n\n    image=GetPreviousImageInList(image);\n\n    if (GetNextImageInList(image) == (Image *) NULL)\n      {\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"  Corrupt list\");\n\n        (void) ThrowMagickException(&image->exception,GetMagickModule(),\n          CoderError,\"Linked list is corrupted; next_image is NULL\",\"`%s'\",\n          image_info->filename);\n      }\n  }\n\n  if (mng_info->ticks_per_second && mng_info->image_found > 1 &&\n             GetNextImageInList(image) ==\n     (Image *) NULL)\n    {\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  First image null\");\n\n      (void) ThrowMagickException(&image->exception,GetMagickModule(),\n        CoderError,\"image->next for first image is NULL but shouldn't be.\",\n        \"`%s'\",image_info->filename);\n    }\n\n  if (mng_info->image_found == 0)\n    {\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  No visible images found.\");\n\n      (void) ThrowMagickException(&image->exception,GetMagickModule(),\n        CoderError,\"No visible images in file\",\"`%s'\",image_info->filename);\n\n      return(DestroyImageList(image));\n    }\n\n  if (mng_info->ticks_per_second)\n    final_delay=1UL*MagickMax(image->ticks_per_second,1L)*\n            final_delay/mng_info->ticks_per_second;\n\n  else\n    image->start_loop=MagickTrue;\n\n  /* Find final nonzero image delay */\n  final_image_delay=0;\n\n  while (GetNextImageInList(image) != (Image *) NULL)\n    {\n      if (image->delay)\n        final_image_delay=image->delay;\n\n      image=GetNextImageInList(image);\n    }\n\n  if (final_delay < final_image_delay)\n    final_delay=final_image_delay;\n\n  image->delay=final_delay;\n\n  if (logging != MagickFalse)\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  image->delay=%.20g, final_delay=%.20g\",(double) image->delay,\n        (double) final_delay);\n\n  if (logging != MagickFalse)\n    {\n      int\n        scene;\n\n      scene=0;\n      image=GetFirstImageInList(image);\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  Before coalesce:\");\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    scene 0 delay=%.20g\",(double) image->delay);\n\n      while (GetNextImageInList(image) != (Image *) NULL)\n      {\n        image=GetNextImageInList(image);\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"    scene %.20g delay=%.20g\",(double) scene++,(double) image->delay);\n      }\n    }\n\n  image=GetFirstImageInList(image);\n#ifdef MNG_COALESCE_LAYERS\n  if (insert_layers)\n    {\n      Image\n        *next_image,\n        *next;\n\n      size_t\n        scene;\n\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"  Coalesce Images\");\n\n      scene=image->scene;\n      next_image=CoalesceImages(image,&image->exception);\n\n      if (next_image == (Image *) NULL)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n      image=DestroyImageList(image);\n      image=next_image;\n\n      for (next=image; next != (Image *) NULL; next=next_image)\n      {\n         next->page.width=mng_info->mng_width;\n         next->page.height=mng_info->mng_height;\n         next->page.x=0;\n         next->page.y=0;\n         next->scene=scene++;\n         next_image=GetNextImageInList(next);\n\n         if (next_image == (Image *) NULL)\n           break;\n\n         if (next->delay == 0)\n           {\n             scene--;\n             next_image->previous=GetPreviousImageInList(next);\n             if (GetPreviousImageInList(next) == (Image *) NULL)\n               image=next_image;\n             else\n               next->previous->next=next_image;\n             next=DestroyImage(next);\n           }\n      }\n    }\n#endif\n\n  while (GetNextImageInList(image) != (Image *) NULL)\n      image=GetNextImageInList(image);\n\n  image->dispose=BackgroundDispose;\n\n  if (logging != MagickFalse)\n    {\n      int\n        scene;\n\n      scene=0;\n      image=GetFirstImageInList(image);\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  After coalesce:\");\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    scene 0 delay=%.20g dispose=%.20g\",(double) image->delay,\n        (double) image->dispose);\n\n      while (GetNextImageInList(image) != (Image *) NULL)\n      {\n        image=GetNextImageInList(image);\n\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"    scene %.20g delay=%.20g dispose=%.20g\",(double) scene++,\n          (double) image->delay,(double) image->dispose);\n      }\n   }\n\n  if (logging != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  exit ReadOneJNGImage();\");\n\n  return(image);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/78d4c5db50fbab0b4beb69c46c6167f2c6513dec", "file_name": "coders/png.c", "vul_type": "cwe-125", "description": "Read a single image from a MNG datastream in C."}
{"func_name": "_yaml_to_config", "func_src_before": "    def _yaml_to_config(self, config_file):\n         self.config = yaml.load(config_file)", "func_src_after": "    def _yaml_to_config(self, config_file):\n        self.config = yaml.safe_load(config_file)", "line_changes": {"deleted": [{"line_no": 2, "char_start": 44, "char_end": 89, "line": "         self.config = yaml.load(config_file)\n"}], "added": [{"line_no": 2, "char_start": 44, "char_end": 93, "line": "        self.config = yaml.safe_load(config_file)\n"}]}, "char_changes": {"deleted": [{"char_start": 52, "char_end": 53, "chars": " "}], "added": [{"char_start": 71, "char_end": 76, "chars": "safe_"}]}, "commit_link": "github.com/darylmathison/github-user-queries/commit/1fb6138eebd8f0386312aa1f0fee5df603f93aba", "file_name": "util.py", "vul_type": "cwe-502", "commit_msg": "Replaced 'load' with 'safe_load'\n\nRefers-to: #24", "parent_commit": "2811a7c65abf513103e615f63f769bb5ca279902", "description": "Write a Python function that loads a configuration from a YAML file into an object's attribute."}
{"func_name": "set_language", "func_src_before": "    def set_language(self, lang):\n        \"\"\"\n        Update language of user in the User object and in the database\n        :param lang: string with language tag like \"en-US\"\n        :return: None\n        \"\"\"\n        log.debug('Updating info about user %s language '\n                  'in memory & database...', self)\n\n        self.language = lang\n\n        query = (\"UPDATE users \"\n                 f\"SET language='{self.language}' \"\n                 f\"WHERE chat_id='{self.chat_id}'\")\n\n        try:\n            db.add(query)\n        except DatabaseError:\n            log.error(\"Can't add new language of %s to the database\", self)\n        else:\n            log.debug('Language updated.')", "func_src_after": "    def set_language(self, lang):\n        \"\"\"\n        Update language of user in the User object and in the database\n        :param lang: string with language tag like \"en-US\"\n        :return: None\n        \"\"\"\n        log.debug('Updating info about user %s language '\n                  'in memory & database...', self)\n\n        self.language = lang\n\n        query = (\"UPDATE users \"\n                 f\"SET language=%s \"\n                 f\"WHERE chat_id=%s\")\n\n        parameters = self.language, self.chat_id\n        try:\n            db.add(query, parameters)\n        except DatabaseError:\n            log.error(\"Can't add new language of %s to the database\", self)\n        else:\n            log.debug('Language updated.')", "commit_link": "github.com/RandyRomero/photoGPSbot/commit/0e9f57f13e61863b3672f5730e27f149da00786a", "file_name": "photogpsbot/users.py", "vul_type": "cwe-089", "description": "Write a Python function to update a user's language preference both in the object and the database."}
{"func_name": "render", "func_src_before": "  render () {\n    const shareText = this.getSharingMessage()\n    const twitterLink = 'https://twitter.com/intent/tweet' +\n      '?text=' + encodeURIComponent(shareText) +\n      '&url=' + encodeURIComponent(this.state.shareUrl)\n\n    const facebookLink = 'https://www.facebook.com/dialog/feed' +\n      '?app_id=' + encodeURIComponent(FACEBOOK_APP_ID) +\n      '&redirect_uri=' + encodeURIComponent(this.state.shareUrl) +\n      '&link=' + encodeURIComponent(this.state.shareUrl) +\n      '&name=' + encodeURIComponent(getPageTitle(this.props.street)) +\n      '&description=' + encodeURIComponent(shareText)\n\n    const signInPromo = (!this.props.signedIn)\n      ? (\n        <div className=\"share-sign-in-promo\">\n          <FormattedHTMLMessage\n            id=\"menu.share.sign-in\"\n            defaultMessage=\"<a href='/twitter-sign-in?redirectUri=/just-signed-in'>Sign in with Twitter</a> for nicer links to your streets and your personal street gallery\"\n          />\n        </div>\n      ) : null\n\n    return (\n      <Menu alignment=\"right\" onShow={this.onShow} className=\"share-menu\" {...this.props}>\n        {signInPromo}\n        <div className=\"share-via-link-container\">\n          <FormattedMessage id=\"menu.share.link\" defaultMessage=\"Copy and paste this link to share:\" />\n          <input\n            className=\"share-via-link\"\n            type=\"text\"\n            value={this.state.shareUrl}\n            spellCheck=\"false\"\n            ref={(ref) => { this.shareViaLinkInput = ref }}\n          />\n        </div>\n        <a\n          className=\"share-via-twitter\"\n          href={twitterLink}\n          target=\"_blank\"\n          onClick={this.onClickShareViaTwitter}\n        >\n          <svg className=\"icon\">\n            <use xlinkHref=\"#icon-twitter\" />\n          </svg>\n          <FormattedMessage id=\"menu.share.twitter\" defaultMessage=\"Share using Twitter\" />\n        </a>\n        <a\n          className=\"share-via-facebook\"\n          href={facebookLink}\n          target=\"_blank\"\n          onClick={this.onClickShareViaFacebook}\n        >\n          <svg className=\"icon\">\n            <use xlinkHref=\"#icon-facebook\" />\n          </svg>\n          <FormattedMessage id=\"menu.share.facebook\" defaultMessage=\"Share using Facebook\" />\n        </a>\n        <a href=\"#\" onClick={printImage}>\n          <FormattedMessage id=\"menu.share.print\" defaultMessage=\"Print\u2026\" />\n        </a>\n        <a id=\"save-as-image\" href=\"#\" onClick={this.onClickSaveAsImage}>\n          <FormattedMessage id=\"menu.share.save\" defaultMessage=\"Save as image\u2026\" />\n          <span className=\"menu-item-subtext\">\n            <FormattedMessage id=\"menu.share.save-byline\" defaultMessage=\"For including in a report, blog, etc.\" />\n          </span>", "func_src_after": "  render () {\n    const shareText = this.getSharingMessage()\n    const twitterLink = 'https://twitter.com/intent/tweet' +\n      '?text=' + encodeURIComponent(shareText) +\n      '&url=' + encodeURIComponent(this.state.shareUrl)\n\n    const facebookLink = 'https://www.facebook.com/dialog/feed' +\n      '?app_id=' + encodeURIComponent(FACEBOOK_APP_ID) +\n      '&redirect_uri=' + encodeURIComponent(this.state.shareUrl) +\n      '&link=' + encodeURIComponent(this.state.shareUrl) +\n      '&name=' + encodeURIComponent(getPageTitle(this.props.street)) +\n      '&description=' + encodeURIComponent(shareText)\n\n    const signInPromo = (!this.props.signedIn)\n      ? (\n        <div className=\"share-sign-in-promo\">\n          <FormattedHTMLMessage\n            id=\"menu.share.sign-in\"\n            defaultMessage=\"<a href='/twitter-sign-in?redirectUri=/just-signed-in'>Sign in with Twitter</a> for nicer links to your streets and your personal street gallery\"\n          />\n        </div>\n      ) : null\n\n    return (\n      <Menu alignment=\"right\" onShow={this.onShow} className=\"share-menu\" {...this.props}>\n        {signInPromo}\n        <div className=\"share-via-link-container\">\n          <FormattedMessage id=\"menu.share.link\" defaultMessage=\"Copy and paste this link to share:\" />\n          <input\n            className=\"share-via-link\"\n            type=\"text\"\n            value={this.state.shareUrl}\n            spellCheck=\"false\"\n            ref={(ref) => { this.shareViaLinkInput = ref }}\n          />\n        </div>\n        <a\n          className=\"share-via-twitter\"\n          href={twitterLink}\n          target=\"_blank\"\n          rel=\"noopener noreferrer\"\n          onClick={this.onClickShareViaTwitter}\n        >\n          <svg className=\"icon\">\n            <use xlinkHref=\"#icon-twitter\" />\n          </svg>\n          <FormattedMessage id=\"menu.share.twitter\" defaultMessage=\"Share using Twitter\" />\n        </a>\n        <a\n          className=\"share-via-facebook\"\n          href={facebookLink}\n          target=\"_blank\"\n          rel=\"noopener noreferrer\"\n          onClick={this.onClickShareViaFacebook}\n        >\n          <svg className=\"icon\">\n            <use xlinkHref=\"#icon-facebook\" />\n          </svg>\n          <FormattedMessage id=\"menu.share.facebook\" defaultMessage=\"Share using Facebook\" />\n        </a>\n        <a href=\"#\" onClick={printImage}>\n          <FormattedMessage id=\"menu.share.print\" defaultMessage=\"Print\u2026\" />\n        </a>\n        <a id=\"save-as-image\" href=\"#\" onClick={this.onClickSaveAsImage}>\n          <FormattedMessage id=\"menu.share.save\" defaultMessage=\"Save as image\u2026\" />\n          <span className=\"menu-item-subtext\">\n            <FormattedMessage id=\"menu.share.save-byline\" defaultMessage=\"For including in a report, blog, etc.\" />\n          </span>", "line_changes": {"deleted": [], "added": [{"line_no": 41, "char_start": 1618, "char_end": 1654, "line": "          rel=\"noopener noreferrer\"\n"}, {"line_no": 53, "char_start": 2021, "char_end": 2057, "line": "          rel=\"noopener noreferrer\"\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 1618, "char_end": 1654, "chars": "          rel=\"noopener noreferrer\"\n"}, {"char_start": 2021, "char_end": 2057, "chars": "          rel=\"noopener noreferrer\"\n"}]}, "commit_link": "github.com/codeforamerica/streetmix/commit/2e716db8607ee741b6471d180b6fc3e62ac13dd6", "file_name": "ShareMenu.jsx", "vul_type": "cwe-200", "commit_msg": "Add rel='noopener noreferrer' to ext links in ShareMenu.jsx", "parent_commit": "2fbc386dd997e43483071c741dd0e2363bfd3528", "description": "Create a React component in JavaScript that generates links for sharing content on social media and includes options for signing in, printing, and saving content."}
{"func_name": "write_keyval", "func_src_before": "    let write_keyval = function(key, val) {\n        let query = \"INSERT INTO tb_events (uid, key, value) VALUES \"\n                  + \"(\"\n                  + \"'\" + event.uid + \"', \"\n                  + \"'\" + key + \"', \"\n                  + \"'\" + val + \"'\"\n                  + \" );\";\n        obj.db.run(query);\n    };", "func_src_after": "    let write_keyval = function(key, val) {\n        obj.db.run(\n          \"INSERT INTO tb_events (uid, key, value) VALUES ( ? , ? , ? );\",\n          [event.uid, key, val]\n        );\n    };", "line_changes": {"deleted": [{"line_no": 2, "char_start": 44, "char_end": 114, "line": "        let query = \"INSERT INTO tb_events (uid, key, value) VALUES \"\n"}, {"line_no": 3, "char_start": 114, "char_end": 138, "line": "                  + \"(\"\n"}, {"line_no": 4, "char_start": 138, "char_end": 182, "line": "                  + \"'\" + event.uid + \"', \"\n"}, {"line_no": 5, "char_start": 182, "char_end": 220, "line": "                  + \"'\" + key + \"', \"\n"}, {"line_no": 6, "char_start": 220, "char_end": 256, "line": "                  + \"'\" + val + \"'\"\n"}, {"line_no": 7, "char_start": 256, "char_end": 283, "line": "                  + \" );\";\n"}, {"line_no": 8, "char_start": 283, "char_end": 310, "line": "        obj.db.run(query);\n"}], "added": [{"line_no": 2, "char_start": 44, "char_end": 64, "line": "        obj.db.run(\n"}, {"line_no": 3, "char_start": 64, "char_end": 139, "line": "          \"INSERT INTO tb_events (uid, key, value) VALUES ( ? , ? , ? );\",\n"}, {"line_no": 4, "char_start": 139, "char_end": 171, "line": "          [event.uid, key, val]\n"}, {"line_no": 5, "char_start": 171, "char_end": 182, "line": "        );\n"}]}, "char_changes": {"deleted": [{"char_start": 52, "char_end": 63, "chars": "let query ="}, {"char_start": 112, "char_end": 307, "chars": "\"\n                  + \"(\"\n                  + \"'\" + event.uid + \"', \"\n                  + \"'\" + key + \"', \"\n                  + \"'\" + val + \"'\"\n                  + \" );\";\n        obj.db.run(query"}], "added": [{"char_start": 52, "char_end": 73, "chars": "obj.db.run(\n         "}, {"char_start": 122, "char_end": 179, "chars": "( ? , ? , ? );\",\n          [event.uid, key, val]\n        "}]}, "commit_link": "github.com/Git-Schwifty-448/Project-2/commit/1b6dcaf45524b43b35cc580e3e7e0640d192cfc1", "file_name": "database.js", "vul_type": "cwe-089", "commit_msg": "Fix SQL injections (failed on ')", "description": "Write a JavaScript function that inserts a key-value pair into a database table named 'tb_events' using an 'event.uid'."}
{"func_name": "enc_untrusted_create_wait_queue", "func_src_before": "int32_t *enc_untrusted_create_wait_queue() {\n  MessageWriter input;\n  MessageReader output;\n  input.Push<uint64_t>(sizeof(int32_t));\n  const auto status = NonSystemCallDispatcher(\n      ::asylo::host_call::kLocalLifetimeAllocHandler, &input, &output);\n  CheckStatusAndParamCount(status, output, \"enc_untrusted_create_wait_queue\",\n                           2);\n  int32_t *queue = reinterpret_cast<int32_t *>(output.next<uintptr_t>());\n  int klinux_errno = output.next<int>();\n  if (queue == nullptr) {\n    errno = FromkLinuxErrorNumber(klinux_errno);\n  }\n  enc_untrusted_disable_waiting(queue);\n  return queue;\n}", "func_src_after": "int32_t *enc_untrusted_create_wait_queue() {\n  MessageWriter input;\n  MessageReader output;\n  input.Push<uint64_t>(sizeof(int32_t));\n  const auto status = NonSystemCallDispatcher(\n      ::asylo::host_call::kLocalLifetimeAllocHandler, &input, &output);\n  CheckStatusAndParamCount(status, output, \"enc_untrusted_create_wait_queue\",\n                           2);\n  int32_t *queue = reinterpret_cast<int32_t *>(output.next<uintptr_t>());\n  if (!TrustedPrimitives::IsOutsideEnclave(queue, sizeof(int32_t))) {\n    TrustedPrimitives::BestEffortAbort(\n        \"enc_untrusted_create_wait_queue: queue should be in untrusted memory\");\n  }\n  int klinux_errno = output.next<int>();\n  if (queue == nullptr) {\n    errno = FromkLinuxErrorNumber(klinux_errno);\n  }\n  enc_untrusted_disable_waiting(queue);\n  return queue;\n}", "commit_link": "github.com/google/asylo/commit/a37fb6a0e7daf30134dbbf357c9a518a1026aa02", "file_name": "asylo/platform/host_call/trusted/concurrency.cc", "vul_type": "cwe-787", "description": "Write a C++ function named `enc_untrusted_create_wait_queue` that allocates a wait queue using a non-system call dispatcher and handles errors."}
{"func_name": "fulltext_search_title", "func_src_before": "def fulltext_search_title(query):\n    query_string = \"\"\"\n      SELECT id, ts_headline('english', title, query), ts_rank_cd(to_tsvector('english', title), query, 32) AS rank\n        FROM pub_2018, plainto_tsquery('english', '{}') query  -- or try plainto_tsquery, phraseto_tsquery, to_tsquery\n        WHERE to_tsvector('english', title) @@ query\n        ORDER BY rank DESC\n        LIMIT 50;\"\"\".format(query)\n\n    rows = db.engine.execute(sql.text(query_string)).fetchall()\n    ids = [row[0] for row in rows]\n    my_pubs = db.session.query(Pub).filter(Pub.id.in_(ids)).all()\n    for row in rows:\n        my_id = row[0]\n        for my_pub in my_pubs:\n            if my_id == my_pub.id:\n                my_pub.snippet = row[1]\n                my_pub.score = row[2]\n    return my_pubs", "func_src_after": "def fulltext_search_title(query):\n    query_statement = sql.text(\"\"\"\n      SELECT id, ts_headline('english', title, query), ts_rank_cd(to_tsvector('english', title), query, 32) AS rank\n        FROM pub_2018, plainto_tsquery('english', :search_str) query  -- or try plainto_tsquery, phraseto_tsquery, to_tsquery\n        WHERE to_tsvector('english', title) @@ query\n        ORDER BY rank DESC\n        LIMIT 50;\"\"\")\n\n    rows = db.engine.execute(query_statement.bindparams(search_str=query)).fetchall()\n    ids = [row[0] for row in rows]\n    my_pubs = db.session.query(Pub).filter(Pub.id.in_(ids)).all()\n    for row in rows:\n        my_id = row[0]\n        for my_pub in my_pubs:\n            if my_id == my_pub.id:\n                my_pub.snippet = row[1]\n                my_pub.score = row[2]\n    return my_pubs", "line_changes": {"deleted": [{"line_no": 2, "char_start": 34, "char_end": 57, "line": "    query_string = \"\"\"\n"}, {"line_no": 4, "char_start": 173, "char_end": 292, "line": "        FROM pub_2018, plainto_tsquery('english', '{}') query  -- or try plainto_tsquery, phraseto_tsquery, to_tsquery\n"}, {"line_no": 7, "char_start": 372, "char_end": 407, "line": "        LIMIT 50;\"\"\".format(query)\n"}, {"line_no": 9, "char_start": 408, "char_end": 472, "line": "    rows = db.engine.execute(sql.text(query_string)).fetchall()\n"}], "added": [{"line_no": 2, "char_start": 34, "char_end": 69, "line": "    query_statement = sql.text(\"\"\"\n"}, {"line_no": 4, "char_start": 185, "char_end": 311, "line": "        FROM pub_2018, plainto_tsquery('english', :search_str) query  -- or try plainto_tsquery, phraseto_tsquery, to_tsquery\n"}, {"line_no": 7, "char_start": 391, "char_end": 413, "line": "        LIMIT 50;\"\"\")\n"}, {"line_no": 9, "char_start": 414, "char_end": 500, "line": "    rows = db.engine.execute(query_statement.bindparams(search_str=query)).fetchall()\n"}]}, "char_changes": {"deleted": [{"char_start": 46, "char_end": 53, "chars": "ring = "}, {"char_start": 223, "char_end": 227, "chars": "'{}'"}, {"char_start": 392, "char_end": 405, "chars": ".format(query"}, {"char_start": 437, "char_end": 458, "chars": "sql.text(query_string"}], "added": [{"char_start": 46, "char_end": 65, "chars": "atement = sql.text("}, {"char_start": 235, "char_end": 246, "chars": ":search_str"}, {"char_start": 443, "char_end": 486, "chars": "query_statement.bindparams(search_str=query"}]}, "commit_link": "github.com/Impactstory/oadoi/commit/4cde28ea869c921be917cd8726edb958b37d683a", "file_name": "search.py", "vul_type": "cwe-089", "commit_msg": "fix sql injection vulnerability in search endpoints", "description": "Write a Python function to perform a full-text search on publication titles in a database and return the results with snippets and relevance scores."}
{"func_name": "dnxhd_find_frame_end", "func_src_before": "static int dnxhd_find_frame_end(DNXHDParserContext *dctx,\n                                const uint8_t *buf, int buf_size)\n{\n    ParseContext *pc = &dctx->pc;\n    uint64_t state = pc->state64;\n    int pic_found = pc->frame_start_found;\n    int i = 0;\n\n    if (!pic_found) {\n        for (i = 0; i < buf_size; i++) {\n            state = (state << 8) | buf[i];\n            if (ff_dnxhd_check_header_prefix(state & 0xffffffffff00LL) != 0) {\n                i++;\n                pic_found = 1;\n                dctx->cur_byte = 0;\n                dctx->remaining = 0;\n                break;\n            }\n        }\n    }\n\n    if (pic_found && !dctx->remaining) {\n        if (!buf_size) /* EOF considered as end of frame */\n            return 0;\n        for (; i < buf_size; i++) {\n            dctx->cur_byte++;\n            state = (state << 8) | buf[i];\n\n            if (dctx->cur_byte == 24) {\n                dctx->h = (state >> 32) & 0xFFFF;\n            } else if (dctx->cur_byte == 26) {\n                dctx->w = (state >> 32) & 0xFFFF;\n            } else if (dctx->cur_byte == 42) {\n                int cid = (state >> 32) & 0xFFFFFFFF;\n\n                if (cid <= 0)\n                    continue;\n\n                dctx->remaining = avpriv_dnxhd_get_frame_size(cid);\n                if (dctx->remaining <= 0) {\n                    dctx->remaining = dnxhd_get_hr_frame_size(cid, dctx->w, dctx->h);\n                    if (dctx->remaining <= 0)\n                        return dctx->remaining;\n                }\n                if (buf_size - i + 47 >= dctx->remaining) {\n                    int remaining = dctx->remaining;\n\n                    pc->frame_start_found = 0;\n                    pc->state64 = -1;\n                    dctx->cur_byte = 0;\n                    dctx->remaining = 0;\n                    return remaining;\n                } else {\n                    dctx->remaining -= buf_size;\n                }\n            }\n        }\n    } else if (pic_found) {\n        if (dctx->remaining > buf_size) {\n            dctx->remaining -= buf_size;\n        } else {\n            int remaining = dctx->remaining;\n\n            pc->frame_start_found = 0;\n            pc->state64 = -1;\n            dctx->cur_byte = 0;\n            dctx->remaining = 0;\n            return remaining;\n        }\n    }\n    pc->frame_start_found = pic_found;\n    pc->state64 = state;\n    return END_NOT_FOUND;\n}", "func_src_after": "static int dnxhd_find_frame_end(DNXHDParserContext *dctx,\n                                const uint8_t *buf, int buf_size)\n{\n    ParseContext *pc = &dctx->pc;\n    uint64_t state = pc->state64;\n    int pic_found = pc->frame_start_found;\n    int i = 0;\n\n    if (!pic_found) {\n        for (i = 0; i < buf_size; i++) {\n            state = (state << 8) | buf[i];\n            if (ff_dnxhd_check_header_prefix(state & 0xffffffffff00LL) != 0) {\n                i++;\n                pic_found = 1;\n                dctx->cur_byte = 0;\n                dctx->remaining = 0;\n                break;\n            }\n        }\n    }\n\n    if (pic_found && !dctx->remaining) {\n        if (!buf_size) /* EOF considered as end of frame */\n            return 0;\n        for (; i < buf_size; i++) {\n            dctx->cur_byte++;\n            state = (state << 8) | buf[i];\n\n            if (dctx->cur_byte == 24) {\n                dctx->h = (state >> 32) & 0xFFFF;\n            } else if (dctx->cur_byte == 26) {\n                dctx->w = (state >> 32) & 0xFFFF;\n            } else if (dctx->cur_byte == 42) {\n                int cid = (state >> 32) & 0xFFFFFFFF;\n                int remaining;\n\n                if (cid <= 0)\n                    continue;\n\n                remaining = avpriv_dnxhd_get_frame_size(cid);\n                if (remaining <= 0) {\n                    remaining = dnxhd_get_hr_frame_size(cid, dctx->w, dctx->h);\n                    if (remaining <= 0)\n                        continue;\n                }\n                dctx->remaining = remaining;\n                if (buf_size - i + 47 >= dctx->remaining) {\n                    int remaining = dctx->remaining;\n\n                    pc->frame_start_found = 0;\n                    pc->state64 = -1;\n                    dctx->cur_byte = 0;\n                    dctx->remaining = 0;\n                    return remaining;\n                } else {\n                    dctx->remaining -= buf_size;\n                }\n            }\n        }\n    } else if (pic_found) {\n        if (dctx->remaining > buf_size) {\n            dctx->remaining -= buf_size;\n        } else {\n            int remaining = dctx->remaining;\n\n            pc->frame_start_found = 0;\n            pc->state64 = -1;\n            dctx->cur_byte = 0;\n            dctx->remaining = 0;\n            return remaining;\n        }\n    }\n    pc->frame_start_found = pic_found;\n    pc->state64 = state;\n    return END_NOT_FOUND;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/0a709e2a10b8288a0cc383547924ecfe285cef89", "file_name": "libavcodec/dnxhd_parser.c", "vul_type": "cwe-476", "description": "Write a C function to detect the end of a frame in a DNXHD video stream buffer."}
{"func_name": "change_user_settings", "func_src_before": "@app.route('/users/edit/<username>', methods=['GET', 'POST'])\ndef change_user_settings(username):\n  \"\"\" Procedure to process the login page. Also handles authentication. \"\"\"\n\n  if 'username' not in session:\n    flash('You must be logged in for that.')\n    return redirect(url_for('login'))\n\n  if session['username'] != username:\n    flash('You cannot edit this user\\'s information.')\n    return redirect(url_for('show_user_profile', username=username))\n\n\n  params = {}\n  tags = ['nickname', 'usenickname', 'bday', 'email', 'email2', 'msc', 'phone', \\\n      'building', 'room_num', 'major', 'isabroad']\n  tag_names = [\"Nickname\", \"Use Nickname\", \"Birthday\", \"Email Address\", \\\n      \"Alt. Email Address\", \"MSC\", \"Phone Number\", \"Building Name\", \"Room Number\", \\\n      \"Major\", \"Is Abroad\"]\n\n  # Get stored values from database\n  query = text(\"SELECT * FROM users Natural JOIN members where username=:u\")\n  result = connection.execute(query, u=str(username))\n  if result.returns_rows and result.rowcount != 0:\n    result_cols = result.keys()\n    r = result.first()\n    stored_params = dict(zip(result_cols, r)) #stored_params maps sql columns to values\n\n  # Update if needed\n  if request.method == 'POST':\n\n    for (i, tag) in enumerate(tags):\n      params[tag] = request.form[tag]\n\n\n    for (i, tag) in enumerate(tags):\n      if str(params[tag]) != str(stored_params[tag]):\n\n        new_val = str(params[tag])\n        if tag in ['usenickname', 'msc', 'room_num', 'isabroad']:\n          new_val = int(new_val)\n\n        query = text(\"UPDATE members SET %s = :val WHERE user_id = :u\" % tag)\n        results = connection.execute(query, u=session['user_id'], val=new_val)\n\n        flash(\"%s was updated!\" % tag_names[i])\n\n\n  if not params:\n    params = stored_params\n\n  return render_template('edit_user.html', params = params)", "func_src_after": "@app.route('/users/edit/<username>', methods=['GET', 'POST'])\ndef change_user_settings(username):\n  \"\"\" Procedure to process the login page. Also handles authentication. \"\"\"\n\n  if 'username' not in session:\n    flash('You must be logged in for that.')\n    return redirect(url_for('login'))\n\n  if session['username'] != username:\n    flash('You cannot edit this user\\'s information.')\n    return redirect(url_for('show_user_profile', username=username))\n\n\n  params = {}\n  tags = ['nickname', 'usenickname', 'bday', 'email', 'email2', 'msc', 'phone', \\\n      'building', 'room_num', 'major', 'isabroad']\n  tag_names = [\"Nickname\", \"Use Nickname\", \"Birthday\", \"Email Address\", \\\n      \"Alt. Email Address\", \"MSC\", \"Phone Number\", \"Building Name\", \"Room Number\", \\\n      \"Major\", \"Is Abroad\"]\n\n  # Get stored values from database\n  query = text(\"SELECT * FROM users NATURAL JOIN members WHERE username=:u\")\n  result = connection.execute(query, u=str(username))\n  if result.returns_rows and result.rowcount != 0:\n    result_cols = result.keys()\n    r = result.first()\n    stored_params = dict(zip(result_cols, r)) #stored_params maps sql columns to values\n\n  # Update if needed\n  if request.method == 'POST':\n\n    for (i, tag) in enumerate(tags):\n      params[tag] = request.form[tag]\n\n\n    for (i, tag) in enumerate(tags):\n      if str(params[tag]) != str(stored_params[tag]):\n\n        new_val = str(params[tag])\n        if tag in ['usenickname', 'msc', 'room_num', 'isabroad']:\n          new_val = int(new_val)\n\n        query = text(\"UPDATE members SET %s = :val WHERE user_id = :u\" % tag)\n        results = connection.execute(query, u=session['user_id'], val=new_val)\n\n        flash(\"%s was updated!\" % tag_names[i])\n\n\n  if not params:\n    params = stored_params\n\n  return render_template('edit_user.html', params = params)", "line_changes": {"deleted": [{"line_no": 22, "char_start": 826, "char_end": 903, "line": "  query = text(\"SELECT * FROM users Natural JOIN members where username=:u\")\n"}], "added": [{"line_no": 22, "char_start": 826, "char_end": 903, "line": "  query = text(\"SELECT * FROM users NATURAL JOIN members WHERE username=:u\")\n"}]}, "char_changes": {"deleted": [{"char_start": 863, "char_end": 869, "chars": "atural"}, {"char_start": 883, "char_end": 888, "chars": "where"}], "added": [{"char_start": 863, "char_end": 869, "chars": "ATURAL"}, {"char_start": 883, "char_end": 888, "chars": "WHERE"}]}, "commit_link": "github.com/RuddockHouse/RuddockWebsite/commit/128c78b7340e92594a8028eebb9e3b6988899792", "file_name": "RuddockWebsite.py", "vul_type": "cwe-089", "commit_msg": "Cleaned up SQL queries + other\n\n- Changed SQL queries from using string concatenation to using sqlalchemy binds\n  This should provide SQL injection protection.\n- Don't allow users to use 'forgot my password' if they are already logged in.", "description": "Write a Python Flask function to edit user settings, checking if the user is logged in and authorized to edit the specified user's profile."}
{"func_name": "concat_hash_string", "func_src_before": "static u_int16_t concat_hash_string(struct ndpi_packet_struct *packet,\n\t\t\t\t   char *buf, u_int8_t client_hash) {\n  u_int16_t offset = 22, buf_out_len = 0;\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  u_int32_t len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n  offset += 4;\n\n  /* -1 for ';' */\n  if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n    goto invalid_payload;\n\n  /* ssh.kex_algorithms [C/S] */\n  strncpy(buf, (const char *)&packet->payload[offset], buf_out_len = len);\n  buf[buf_out_len++] = ';';\n  offset += len;\n\n  /* ssh.server_host_key_algorithms [None] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n  offset += 4 + len;\n\n  /* ssh.encryption_algorithms_client_to_server [C] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    buf[buf_out_len++] = ';';\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  /* ssh.encryption_algorithms_server_to_client [S] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(!client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    buf[buf_out_len++] = ';';\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  /* ssh.mac_algorithms_client_to_server [C] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    buf[buf_out_len++] = ';';\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  /* ssh.mac_algorithms_server_to_client [S] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(!client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    buf[buf_out_len++] = ';';\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  /* ssh.compression_algorithms_client_to_server [C] */\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  /* ssh.compression_algorithms_server_to_client [S] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(!client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  /* ssh.languages_client_to_server [None] */\n\n  /* ssh.languages_server_to_client [None] */\n\n#ifdef SSH_DEBUG\n  printf(\"[SSH] %s\\n\", buf);\n#endif\n\n  return(buf_out_len);\n\ninvalid_payload:\n\n#ifdef SSH_DEBUG\n  printf(\"[SSH] Invalid packet payload\\n\");\n#endif\n\n  return(0);\n}", "func_src_after": "static u_int16_t concat_hash_string(struct ndpi_packet_struct *packet,\n\t\t\t\t   char *buf, u_int8_t client_hash) {\n  u_int16_t offset = 22, buf_out_len = 0;\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  u_int32_t len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n  offset += 4;\n\n  /* -1 for ';' */\n  if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n    goto invalid_payload;\n\n  /* ssh.kex_algorithms [C/S] */\n  strncpy(buf, (const char *)&packet->payload[offset], buf_out_len = len);\n  buf[buf_out_len++] = ';';\n  offset += len;\n\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  /* ssh.server_host_key_algorithms [None] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n  offset += 4 + len;\n\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  /* ssh.encryption_algorithms_client_to_server [C] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    buf[buf_out_len++] = ';';\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  /* ssh.encryption_algorithms_server_to_client [S] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(!client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    buf[buf_out_len++] = ';';\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  /* ssh.mac_algorithms_client_to_server [C] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    buf[buf_out_len++] = ';';\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  /* ssh.mac_algorithms_server_to_client [S] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(!client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    buf[buf_out_len++] = ';';\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  /* ssh.compression_algorithms_client_to_server [C] */\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  /* ssh.compression_algorithms_server_to_client [S] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(!client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  /* ssh.languages_client_to_server [None] */\n\n  /* ssh.languages_server_to_client [None] */\n\n#ifdef SSH_DEBUG\n  printf(\"[SSH] %s\\n\", buf);\n#endif\n\n  return(buf_out_len);\n\ninvalid_payload:\n\n#ifdef SSH_DEBUG\n  printf(\"[SSH] Invalid packet payload\\n\");\n#endif\n\n  return(0);\n}", "commit_link": "github.com/ntop/nDPI/commit/3bbb0cd3296023f6f922c71d21a1c374d2b0a435", "file_name": "src/lib/protocols/ssh.c", "vul_type": "cwe-125", "description": "Write a C function to concatenate SSH protocol fields into a buffer, handling client or server hash conditions."}
{"func_name": "WavpackVerifySingleBlock", "func_src_before": "int WavpackVerifySingleBlock (unsigned char *buffer, int verify_checksum)\n{\n    WavpackHeader *wphdr = (WavpackHeader *) buffer;\n    uint32_t checksum_passed = 0, bcount, meta_bc;\n    unsigned char *dp, meta_id, c1, c2;\n\n    if (strncmp (wphdr->ckID, \"wvpk\", 4) || wphdr->ckSize + 8 < sizeof (WavpackHeader))\n        return FALSE;\n\n    bcount = wphdr->ckSize - sizeof (WavpackHeader) + 8;\n    dp = (unsigned char *)(wphdr + 1);\n\n    while (bcount >= 2) {\n        meta_id = *dp++;\n        c1 = *dp++;\n\n        meta_bc = c1 << 1;\n        bcount -= 2;\n\n        if (meta_id & ID_LARGE) {\n            if (bcount < 2)\n                return FALSE;\n\n            c1 = *dp++;\n            c2 = *dp++;\n            meta_bc += ((uint32_t) c1 << 9) + ((uint32_t) c2 << 17);\n            bcount -= 2;\n        }\n\n        if (bcount < meta_bc)\n            return FALSE;\n\n        if (verify_checksum && (meta_id & ID_UNIQUE) == ID_BLOCK_CHECKSUM) {\n#ifdef BITSTREAM_SHORTS\n            uint16_t *csptr = (uint16_t*) buffer;\n#else\n            unsigned char *csptr = buffer;\n#endif\n            int wcount = (int)(dp - 2 - buffer) >> 1;\n            uint32_t csum = (uint32_t) -1;\n\n            if ((meta_id & ID_ODD_SIZE) || meta_bc < 2 || meta_bc > 4)\n                return FALSE;\n\n#ifdef BITSTREAM_SHORTS\n            while (wcount--)\n                csum = (csum * 3) + *csptr++;\n#else\n            WavpackNativeToLittleEndian ((WavpackHeader *) buffer, WavpackHeaderFormat);\n\n            while (wcount--) {\n                csum = (csum * 3) + csptr [0] + (csptr [1] << 8);\n                csptr += 2;\n            }\n\n            WavpackLittleEndianToNative ((WavpackHeader *) buffer, WavpackHeaderFormat);\n#endif\n\n            if (meta_bc == 4) {\n                if (*dp++ != (csum & 0xff) || *dp++ != ((csum >> 8) & 0xff) || *dp++ != ((csum >> 16) & 0xff) || *dp++ != ((csum >> 24) & 0xff))\n                    return FALSE;\n            }\n            else {\n                csum ^= csum >> 16;\n\n                if (*dp++ != (csum & 0xff) || *dp++ != ((csum >> 8) & 0xff))\n                    return FALSE;\n            }\n\n            checksum_passed++;\n        }\n\n        bcount -= meta_bc;\n        dp += meta_bc;\n    }\n\n    return (bcount == 0) && (!verify_checksum || !(wphdr->flags & HAS_CHECKSUM) || checksum_passed);\n}", "func_src_after": "int WavpackVerifySingleBlock (unsigned char *buffer, int verify_checksum)\n{\n    WavpackHeader *wphdr = (WavpackHeader *) buffer;\n    uint32_t checksum_passed = 0, bcount, meta_bc;\n    unsigned char *dp, meta_id, c1, c2;\n\n    if (strncmp (wphdr->ckID, \"wvpk\", 4) || wphdr->ckSize + 8 < sizeof (WavpackHeader))\n        return FALSE;\n\n    bcount = wphdr->ckSize - sizeof (WavpackHeader) + 8;\n    dp = (unsigned char *)(wphdr + 1);\n\n    while (bcount >= 2) {\n        meta_id = *dp++;\n        c1 = *dp++;\n\n        meta_bc = c1 << 1;\n        bcount -= 2;\n\n        if (meta_id & ID_LARGE) {\n            if (bcount < 2)\n                return FALSE;\n\n            c1 = *dp++;\n            c2 = *dp++;\n            meta_bc += ((uint32_t) c1 << 9) + ((uint32_t) c2 << 17);\n            bcount -= 2;\n        }\n\n        if (bcount < meta_bc)\n            return FALSE;\n\n        if (verify_checksum && (meta_id & ID_UNIQUE) == ID_BLOCK_CHECKSUM) {\n#ifdef BITSTREAM_SHORTS\n            uint16_t *csptr = (uint16_t*) buffer;\n#else\n            unsigned char *csptr = buffer;\n#endif\n            int wcount = (int)(dp - 2 - buffer) >> 1;\n            uint32_t csum = (uint32_t) -1;\n\n            if ((meta_id & ID_ODD_SIZE) || meta_bc < 2 || meta_bc > 4)\n                return FALSE;\n\n#ifdef BITSTREAM_SHORTS\n            while (wcount--)\n                csum = (csum * 3) + *csptr++;\n#else\n            WavpackNativeToLittleEndian ((WavpackHeader *) buffer, WavpackHeaderFormat);\n\n            while (wcount--) {\n                csum = (csum * 3) + csptr [0] + (csptr [1] << 8);\n                csptr += 2;\n            }\n\n            WavpackLittleEndianToNative ((WavpackHeader *) buffer, WavpackHeaderFormat);\n#endif\n\n            if (meta_bc == 4) {\n                if (*dp != (csum & 0xff) || dp[1] != ((csum >> 8) & 0xff) || dp[2] != ((csum >> 16) & 0xff) || dp[3] != ((csum >> 24) & 0xff))\n                    return FALSE;\n            }\n            else {\n                csum ^= csum >> 16;\n\n                if (*dp != (csum & 0xff) || dp[1] != ((csum >> 8) & 0xff))\n                    return FALSE;\n            }\n\n            checksum_passed++;\n        }\n\n        bcount -= meta_bc;\n        dp += meta_bc;\n    }\n\n    return (bcount == 0) && (!verify_checksum || !(wphdr->flags & HAS_CHECKSUM) || checksum_passed);\n}", "commit_link": "github.com/dbry/WavPack/commit/bba5389dc598a92bdf2b297c3ea34620b6679b5b", "file_name": "src/open_utils.c", "vul_type": "cwe-125", "description": "In C, write a function to verify the integrity of a single Wavpack audio block, optionally checking its checksum."}
{"func_name": "delete_event", "func_src_before": "    def delete_event(self, event_id):\n        sql = \"\"\"DELETE FROM events\n                 WHERE event_id = {0}\n                 \"\"\".format(event_id)\n        affected_count = self.cur.execute(sql)\n        self.conn.commit()\n        return affected_count", "func_src_after": "    def delete_event(self, event_id):\n        sql = \"\"\"\n              DELETE FROM events\n              WHERE event_id = %s\n              \"\"\"\n        affected_count = self.cur.execute(sql, (event_id,))\n        self.conn.commit()\n        return affected_count", "commit_link": "github.com/jgayfer/spirit/commit/01c846c534c8d3cf6763f8b7444a0efe2caa3799", "file_name": "db/dbase.py", "vul_type": "cwe-089", "description": "Write a Python function to delete an event by its ID from a database and return the number of affected rows."}
{"func_name": "SessionAttributesManager::doGet", "func_src_before": "  @Override\n  protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {\n    response.setHeader(\"Cache-Control\", \"no-cache\");\n    response.setHeader(\"Pragma\", \"no-cache\");\n    response.setDateHeader(\"Expires\", -1);\n\n    String name = request.getParameter(\"name\");\n    String value = request.getParameter(\"value\");\n    String message = \"The parameter 'name' is empty\";\n\n    if (name != null && name.length() > 0) {\n      if (allowedAttributes.contains(name)) {\n\n        // add bcdBeanUser.name entries as HashMap session variable \"bcdBeanUser\" where the key/value pairs\n        // are kept without the prefix.\n        boolean error = true;\n        Subject subject = SecurityUtils.getSubject();\n        // check value against list of allowed values or subject settings user rights\n        if (subject != null && subject.getSession() != null && ((allowedValues.get(name) != null && allowedValues.get(name).contains(\" \" + value + \" \")) || subject.isPermitted(BCD_EL_USER_BEAN + \":\" + name + \":\" + value))) {\n          Map<String, String> bean = (HashMap<String, String>)subject.getSession().getAttribute(BCD_EL_USER_BEAN);\n          if (bean == null)\n            bean = new HashMap<>();\n          bean.put(name, value);\n          subject.getSession().setAttribute(BCD_EL_USER_BEAN, bean);\n          error = false;\n        }\n        message =\"The \" + BCD_EL_USER_BEAN + \" '\" + name +  (error ? \"' can not be set to '\" : \"' was set to \") + value;\n      }\n      else {\n        message = \"The attribute name '\" + name + \"' is not allowed by the configuration. Please set the init param ALLOWED_ATTRIBUTES in your web.xml\";\n      }\n    }\n    log.debug(message);\n    response.getWriter().append(message);\n  }", "func_src_after": "  @Override\n  protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {\n    response.setHeader(\"Cache-Control\", \"no-cache\");\n    response.setHeader(\"Pragma\", \"no-cache\");\n    response.setDateHeader(\"Expires\", -1);\n\n    String name = request.getParameter(\"name\");\n    String value = request.getParameter(\"value\");\n    String message = \"The parameter 'name' is empty\";\n\n    if (name != null && name.length() > 0) {\n      if (allowedAttributes.contains(name)) {\n\n        // add bcdBeanUser.name entries as HashMap session variable \"bcdBeanUser\" where the key/value pairs\n        // are kept without the prefix.\n        boolean error = true;\n        Subject subject = SecurityUtils.getSubject();\n        // check value against list of allowed values or subject settings user rights\n        if (subject != null && subject.getSession() != null && ((allowedValues.get(name) != null && allowedValues.get(name).contains(\" \" + value + \" \")) || subject.isPermitted(BCD_EL_USER_BEAN + \":\" + name + \":\" + value))) {\n          Map<String, String> bean = (HashMap<String, String>)subject.getSession().getAttribute(BCD_EL_USER_BEAN);\n          if (bean == null)\n            bean = new HashMap<>();\n          bean.put(name, value);\n          subject.getSession().setAttribute(BCD_EL_USER_BEAN, bean);\n          error = false;\n        }\n        message =\"The \" + BCD_EL_USER_BEAN + \" '\" + name +  (error ? \"' can not be set to '\" : \"' was set to \") + value;\n      }\n      else {\n        message = \"The attribute name '\" + name + \"' is not allowed by the configuration. Please set the init param ALLOWED_ATTRIBUTES in your web.xml\";\n      }\n    }\n    log.debug(message);\n  }", "line_changes": {"deleted": [{"line_no": 34, "char_start": 1712, "char_end": 1754, "line": "    response.getWriter().append(message);\n"}], "added": []}, "char_changes": {"deleted": [{"char_start": 1712, "char_end": 1754, "chars": "    response.getWriter().append(message);\n"}], "added": []}, "commit_link": "github.com/businesscode/BCD-UI/commit/9b230b1500511054da457cf4a5382895fae891df", "file_name": "SessionAttributesManager.java", "vul_type": "cwe-079", "commit_msg": "Server/Security, XSS fixes", "parent_commit": "1b507ea97204e6b71d5863d4c6e523e51a3440b2", "description": "Create a Java servlet that processes a GET request by updating session attributes based on provided parameters and logs the result."}
{"func_name": "update_institutions", "func_src_before": "def update_institutions(conn, sqlite, k10plus, ai):\n    \"\"\"\n    Update the institution table.\n    \"\"\"\n    current_institutions = get_all_current_institutions(k10plus, ai)\n    old_institutions = get_all_old_institutions(conn, sqlite)\n\n    # Check if the institution table is allready filled and this is not the first checkup\n    institution_table_is_filled = len(old_institutions) > 10\n\n    for old_institution in old_institutions:\n        if institution_table_is_filled and old_institution not in current_institutions:\n            message = \"Die ISIL %s ist im aktuellen Import nicht mehr vorhanden.\\nWenn dies beabsichtigt ist, bitte die Institution aus der Datenbank loeschen.\" % old_institution\n            send_message(message)\n\n    for current_institution in current_institutions:\n        if current_institution == \" \" or '\"' in current_institution:\n                continue\n        if current_institution not in old_institutions:\n            message = \"The institution %s is new in Solr.\" % current_institution\n            if institution_table_is_filled:\n                send_message(message)\n            else:\n                logging.info(message)\n            sql = \"INSERT INTO institution (institution) VALUES ('%s')\" % current_institution\n            sqlite.execute(sql)\n            conn.commit()", "func_src_after": "def update_institutions(conn, sqlite, k10plus, ai):\n    \"\"\"\n    Update the institution table.\n    \"\"\"\n    current_institutions = get_all_current_institutions(k10plus, ai)\n    old_institutions = get_all_old_institutions(conn, sqlite)\n\n    # Check if the institution table is allready filled and this is not the first checkup\n    institution_table_is_filled = len(old_institutions) > 10\n\n    for old_institution in old_institutions:\n        if institution_table_is_filled and old_institution not in current_institutions:\n            message = \"Die ISIL %s ist im aktuellen Import nicht mehr vorhanden.\\nWenn dies beabsichtigt ist, bitte die Institution aus der Datenbank loeschen.\" % old_institution\n            send_message(message)\n\n    for current_institution in current_institutions:\n        if current_institution == \" \" or '\"' in current_institution:\n                continue\n        if current_institution not in old_institutions:\n            message = \"The institution %s is new in Solr.\" % current_institution\n            if institution_table_is_filled:\n                send_message(message)\n            else:\n                logging.info(message)\n            sql = \"INSERT INTO institution (institution) VALUES (?)\"\n            sqlite.execute(sql, (current_institution,))\n            conn.commit()", "commit_link": "github.com/miku/siskin/commit/7fa398d2fea72bf2e8b4808f75df4b3d35ae959a", "file_name": "bin/solrcheckup.py", "vul_type": "cwe-089", "description": "Write a Python function to update an institution table by comparing old and new institution records, sending notifications for discrepancies, and inserting new records."}
{"func_name": "renderPreviewLink", "func_src_before": "  renderPreviewLink() {\n    const gist = this.state.latestGist;\n    const user = gist.user || 'anonymous';\n    const preview = !!gist.files['index.html'];\n    if(preview) {\n      return <span><a target=\"_blank\" href={\"https://bl.ocks.org/\"+user+\"/\"+gist.id}>Preview</a>,{' '}</span>\n    }\n    return null;\n  }", "func_src_after": "  renderPreviewLink() {\n    const gist = this.state.latestGist;\n    const user = gist.user || 'anonymous';\n    const preview = !!gist.files['index.html'];\n    if(preview) {\n      return <span><a target=\"_blank\" rel=\"noopener noreferrer\" href={\"https://bl.ocks.org/\"+user+\"/\"+gist.id}>Preview</a>,{' '}</span>\n    }\n    return null;\n  }", "line_changes": {"deleted": [{"line_no": 6, "char_start": 173, "char_end": 283, "line": "      return <span><a target=\"_blank\" href={\"https://bl.ocks.org/\"+user+\"/\"+gist.id}>Preview</a>,{' '}</span>\n"}], "added": [{"line_no": 6, "char_start": 173, "char_end": 309, "line": "      return <span><a target=\"_blank\" rel=\"noopener noreferrer\" href={\"https://bl.ocks.org/\"+user+\"/\"+gist.id}>Preview</a>,{' '}</span>\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 210, "char_end": 236, "chars": " rel=\"noopener noreferrer\""}]}, "commit_link": "github.com/maputnik/editor/commit/3f350c30da0791f542909f665f381e509e68c6c1", "file_name": "ExportModal.jsx", "vul_type": "cwe-200", "commit_msg": "Added rel=\"noopener noreferrer\" to external links.", "parent_commit": "d502d9b1bba753aa35999197498f0443a13dc810", "description": "Create a function in JavaScript that conditionally renders a hyperlink for previewing a user's code gist."}
{"func_name": "save", "func_src_before": "    def save(self, data_store, filename):\n        pgm_model = self.model\n        if type(data_store) is LocalFileSystem:\n            data_store.write_pomegranate_model(\n                model=pgm_model, filename=filename)\n        if type(data_store) is S3DataStore:\n            local_filename = \"/tmp/kronos.json\"\n            with open(local_filename, 'wb') as f:\n                # IMPORTANT: Set pickle.HIGHEST_PROTOCOL only  after complete porting to\n                # Python3\n                pickle.dump(pgm_model.to_json(), f, protocol=2)\n\n            data_store.upload_file(local_filename, filename)\n        return None", "func_src_after": "    def save(self, data_store, filename):\n        pgm_model = self.model\n        if type(data_store) is LocalFileSystem:\n            data_store.write_pomegranate_model(\n                model=pgm_model, filename=filename)\n        if type(data_store) is S3DataStore:\n            local_filename = \"/tmp/kronos.json\"\n            with open(local_filename, 'wb') as f:\n                # IMPORTANT: Set pickle.HIGHEST_PROTOCOL only  after complete porting to\n                # Python3\n                f.write(pgm_model.to_json())\n\n            data_store.upload_file(local_filename, filename)\n        return None", "line_changes": {"deleted": [{"line_no": 11, "char_start": 478, "char_end": 542, "line": "                pickle.dump(pgm_model.to_json(), f, protocol=2)\n"}], "added": [{"line_no": 11, "char_start": 478, "char_end": 523, "line": "                f.write(pgm_model.to_json())\n"}]}, "char_changes": {"deleted": [{"char_start": 494, "char_end": 505, "chars": "pickle.dump"}, {"char_start": 525, "char_end": 540, "chars": ", f, protocol=2"}], "added": [{"char_start": 494, "char_end": 501, "chars": "f.write"}]}, "commit_link": "github.com/sara-02/fabric8-analytics-stack-analysis/commit/c9422e6257a8c927aed2999a0f4cc77f90059cda", "file_name": "pgm_pomegranate.py", "vul_type": "cwe-502", "commit_msg": "Remove pickling of model\n\nThe model is already being converted to a JSON(using the `to_json`)\nfunction of pomegranate which is already a stadard serialized format.\nI don't see a need to further serialize the JSON using pickle to\nsomething that can be loaded only using Python. This also helps us\nreduce the training time of the model as pickling and unpickling\nhas a overhead that I don't see a need for, because JSON.", "parent_commit": "c2ddf128d7206a0a85929b6f2a08078433ce1577", "description": "Write a Python function to save a model to either a local file system or an S3 data store."}
{"func_name": "ExtractPostscript", "func_src_before": "static Image *ExtractPostscript(Image *image,const ImageInfo *image_info,\n  MagickOffsetType PS_Offset,ssize_t PS_Size,ExceptionInfo *exception)\n{\n  char\n    postscript_file[MaxTextExtent];\n\n  const MagicInfo\n    *magic_info;\n\n  FILE\n    *ps_file;\n\n  ImageInfo\n    *clone_info;\n\n  Image\n    *image2;\n\n  unsigned char\n    magick[2*MaxTextExtent];\n\n\n  if ((clone_info=CloneImageInfo(image_info)) == NULL)\n    return(image);\n  clone_info->blob=(void *) NULL;\n  clone_info->length=0;\n\n  /* Obtain temporary file */\n  (void) AcquireUniqueFilename(postscript_file);\n  ps_file=fopen_utf8(postscript_file,\"wb\");\n  if (ps_file == (FILE *) NULL)\n    goto FINISH;\n\n  /* Copy postscript to temporary file */\n  (void) SeekBlob(image,PS_Offset,SEEK_SET);\n  (void) ReadBlob(image, 2*MaxTextExtent, magick);\n\n  (void) SeekBlob(image,PS_Offset,SEEK_SET);\n  while(PS_Size-- > 0)\n    {\n      (void) fputc(ReadBlobByte(image),ps_file);\n    }\n  (void) fclose(ps_file);\n\n    /* Detect file format - Check magic.mgk configuration file. */\n  magic_info=GetMagicInfo(magick,2*MaxTextExtent,exception);\n  if(magic_info == (const MagicInfo *) NULL) goto FINISH_UNL;\n  /*     printf(\"Detected:%s  \\n\",magic_info->name); */\n  if(exception->severity != UndefinedException) goto FINISH_UNL;\n  if(magic_info->name == (char *) NULL) goto FINISH_UNL;\n\n  (void) CopyMagickMemory(clone_info->magick,magic_info->name,MaxTextExtent);\n\n    /* Read nested image */\n  /*FormatString(clone_info->filename,\"%s:%s\",magic_info->name,postscript_file);*/\n  FormatLocaleString(clone_info->filename,MaxTextExtent,\"%s\",postscript_file);\n  image2=ReadImage(clone_info,exception);\n\n  if (!image2)\n    goto FINISH_UNL;\n\n  /*\n    Replace current image with new image while copying base image\n    attributes.\n  */\n  (void) CopyMagickMemory(image2->filename,image->filename,MaxTextExtent);\n  (void) CopyMagickMemory(image2->magick_filename,image->magick_filename,MaxTextExtent);\n  (void) CopyMagickMemory(image2->magick,image->magick,MaxTextExtent);\n  image2->depth=image->depth;\n  DestroyBlob(image2);\n  image2->blob=ReferenceBlob(image->blob);\n\n  if ((image->rows == 0) || (image->columns == 0))\n    DeleteImageFromList(&image);\n\n  AppendImageToList(&image,image2);\n\n FINISH_UNL:\n  (void) RelinquishUniqueFileResource(postscript_file);\n FINISH:\n  DestroyImageInfo(clone_info);\n  return(image);\n}", "func_src_after": "static Image *ExtractPostscript(Image *image,const ImageInfo *image_info,\n  MagickOffsetType PS_Offset,ssize_t PS_Size,ExceptionInfo *exception)\n{\n  char\n    postscript_file[MaxTextExtent];\n\n  const MagicInfo\n    *magic_info;\n\n  FILE\n    *ps_file;\n\n  ImageInfo\n    *clone_info;\n\n  Image\n    *image2;\n\n  unsigned char\n    magick[2*MaxTextExtent];\n\n\n  if ((clone_info=CloneImageInfo(image_info)) == NULL)\n    return(image);\n  clone_info->blob=(void *) NULL;\n  clone_info->length=0;\n\n  /* Obtain temporary file */\n  (void) AcquireUniqueFilename(postscript_file);\n  ps_file=fopen_utf8(postscript_file,\"wb\");\n  if (ps_file == (FILE *) NULL)\n    goto FINISH;\n\n  /* Copy postscript to temporary file */\n  (void) SeekBlob(image,PS_Offset,SEEK_SET);\n  (void) ReadBlob(image, 2*MaxTextExtent, magick);\n\n  (void) SeekBlob(image,PS_Offset,SEEK_SET);\n  while(PS_Size-- > 0)\n    {\n      (void) fputc(ReadBlobByte(image),ps_file);\n    }\n  (void) fclose(ps_file);\n\n    /* Detect file format - Check magic.mgk configuration file. */\n  magic_info=GetMagicInfo(magick,2*MaxTextExtent,exception);\n  if(magic_info == (const MagicInfo *) NULL) goto FINISH_UNL;\n  /*     printf(\"Detected:%s  \\n\",magic_info->name); */\n  if(exception->severity != UndefinedException) goto FINISH_UNL;\n  if(magic_info->name == (char *) NULL) goto FINISH_UNL;\n\n  (void) strncpy(clone_info->magick,magic_info->name,MaxTextExtent);\n\n    /* Read nested image */\n  /*FormatString(clone_info->filename,\"%s:%s\",magic_info->name,postscript_file);*/\n  FormatLocaleString(clone_info->filename,MaxTextExtent,\"%s\",postscript_file);\n  image2=ReadImage(clone_info,exception);\n\n  if (!image2)\n    goto FINISH_UNL;\n\n  /*\n    Replace current image with new image while copying base image\n    attributes.\n  */\n  (void) CopyMagickMemory(image2->filename,image->filename,MaxTextExtent);\n  (void) CopyMagickMemory(image2->magick_filename,image->magick_filename,MaxTextExtent);\n  (void) CopyMagickMemory(image2->magick,image->magick,MaxTextExtent);\n  image2->depth=image->depth;\n  DestroyBlob(image2);\n  image2->blob=ReferenceBlob(image->blob);\n\n  if ((image->rows == 0) || (image->columns == 0))\n    DeleteImageFromList(&image);\n\n  AppendImageToList(&image,image2);\n\n FINISH_UNL:\n  (void) RelinquishUniqueFileResource(postscript_file);\n FINISH:\n  DestroyImageInfo(clone_info);\n  return(image);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/a251039393f423c7858e63cab6aa98d17b8b7a41", "file_name": "coders/wpg.c", "vul_type": "cwe-125", "description": "Write a C function to extract a Postscript section from an image and read it into a new image structure."}
{"func_name": "SMB2_read", "func_src_before": "SMB2_read(const unsigned int xid, struct cifs_io_parms *io_parms,\n\t  unsigned int *nbytes, char **buf, int *buf_type)\n{\n\tstruct smb_rqst rqst;\n\tint resp_buftype, rc = -EACCES;\n\tstruct smb2_read_plain_req *req = NULL;\n\tstruct smb2_read_rsp *rsp = NULL;\n\tstruct kvec iov[1];\n\tstruct kvec rsp_iov;\n\tunsigned int total_len;\n\tint flags = CIFS_LOG_ERROR;\n\tstruct cifs_ses *ses = io_parms->tcon->ses;\n\n\t*nbytes = 0;\n\trc = smb2_new_read_req((void **)&req, &total_len, io_parms, NULL, 0, 0);\n\tif (rc)\n\t\treturn rc;\n\n\tif (smb3_encryption_required(io_parms->tcon))\n\t\tflags |= CIFS_TRANSFORM_REQ;\n\n\tiov[0].iov_base = (char *)req;\n\tiov[0].iov_len = total_len;\n\n\tmemset(&rqst, 0, sizeof(struct smb_rqst));\n\trqst.rq_iov = iov;\n\trqst.rq_nvec = 1;\n\n\trc = cifs_send_recv(xid, ses, &rqst, &resp_buftype, flags, &rsp_iov);\n\tcifs_small_buf_release(req);\n\n\trsp = (struct smb2_read_rsp *)rsp_iov.iov_base;\n\n\tif (rc) {\n\t\tif (rc != -ENODATA) {\n\t\t\tcifs_stats_fail_inc(io_parms->tcon, SMB2_READ_HE);\n\t\t\tcifs_dbg(VFS, \"Send error in read = %d\\n\", rc);\n\t\t\ttrace_smb3_read_err(xid, req->PersistentFileId,\n\t\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t\t    io_parms->offset, io_parms->length,\n\t\t\t\t\t    rc);\n\t\t} else\n\t\t\ttrace_smb3_read_done(xid, req->PersistentFileId,\n\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t    io_parms->offset, 0);\n\t\tfree_rsp_buf(resp_buftype, rsp_iov.iov_base);\n\t\treturn rc == -ENODATA ? 0 : rc;\n\t} else\n\t\ttrace_smb3_read_done(xid, req->PersistentFileId,\n\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t    io_parms->offset, io_parms->length);\n\n\t*nbytes = le32_to_cpu(rsp->DataLength);\n\tif ((*nbytes > CIFS_MAX_MSGSIZE) ||\n\t    (*nbytes > io_parms->length)) {\n\t\tcifs_dbg(FYI, \"bad length %d for count %d\\n\",\n\t\t\t *nbytes, io_parms->length);\n\t\trc = -EIO;\n\t\t*nbytes = 0;\n\t}\n\n\tif (*buf) {\n\t\tmemcpy(*buf, (char *)rsp + rsp->DataOffset, *nbytes);\n\t\tfree_rsp_buf(resp_buftype, rsp_iov.iov_base);\n\t} else if (resp_buftype != CIFS_NO_BUFFER) {\n\t\t*buf = rsp_iov.iov_base;\n\t\tif (resp_buftype == CIFS_SMALL_BUFFER)\n\t\t\t*buf_type = CIFS_SMALL_BUFFER;\n\t\telse if (resp_buftype == CIFS_LARGE_BUFFER)\n\t\t\t*buf_type = CIFS_LARGE_BUFFER;\n\t}\n\treturn rc;\n}", "func_src_after": "SMB2_read(const unsigned int xid, struct cifs_io_parms *io_parms,\n\t  unsigned int *nbytes, char **buf, int *buf_type)\n{\n\tstruct smb_rqst rqst;\n\tint resp_buftype, rc = -EACCES;\n\tstruct smb2_read_plain_req *req = NULL;\n\tstruct smb2_read_rsp *rsp = NULL;\n\tstruct kvec iov[1];\n\tstruct kvec rsp_iov;\n\tunsigned int total_len;\n\tint flags = CIFS_LOG_ERROR;\n\tstruct cifs_ses *ses = io_parms->tcon->ses;\n\n\t*nbytes = 0;\n\trc = smb2_new_read_req((void **)&req, &total_len, io_parms, NULL, 0, 0);\n\tif (rc)\n\t\treturn rc;\n\n\tif (smb3_encryption_required(io_parms->tcon))\n\t\tflags |= CIFS_TRANSFORM_REQ;\n\n\tiov[0].iov_base = (char *)req;\n\tiov[0].iov_len = total_len;\n\n\tmemset(&rqst, 0, sizeof(struct smb_rqst));\n\trqst.rq_iov = iov;\n\trqst.rq_nvec = 1;\n\n\trc = cifs_send_recv(xid, ses, &rqst, &resp_buftype, flags, &rsp_iov);\n\trsp = (struct smb2_read_rsp *)rsp_iov.iov_base;\n\n\tif (rc) {\n\t\tif (rc != -ENODATA) {\n\t\t\tcifs_stats_fail_inc(io_parms->tcon, SMB2_READ_HE);\n\t\t\tcifs_dbg(VFS, \"Send error in read = %d\\n\", rc);\n\t\t\ttrace_smb3_read_err(xid, req->PersistentFileId,\n\t\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t\t    io_parms->offset, io_parms->length,\n\t\t\t\t\t    rc);\n\t\t} else\n\t\t\ttrace_smb3_read_done(xid, req->PersistentFileId,\n\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t    io_parms->offset, 0);\n\t\tfree_rsp_buf(resp_buftype, rsp_iov.iov_base);\n\t\treturn rc == -ENODATA ? 0 : rc;\n\t} else\n\t\ttrace_smb3_read_done(xid, req->PersistentFileId,\n\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t    io_parms->offset, io_parms->length);\n\n\tcifs_small_buf_release(req);\n\n\t*nbytes = le32_to_cpu(rsp->DataLength);\n\tif ((*nbytes > CIFS_MAX_MSGSIZE) ||\n\t    (*nbytes > io_parms->length)) {\n\t\tcifs_dbg(FYI, \"bad length %d for count %d\\n\",\n\t\t\t *nbytes, io_parms->length);\n\t\trc = -EIO;\n\t\t*nbytes = 0;\n\t}\n\n\tif (*buf) {\n\t\tmemcpy(*buf, (char *)rsp + rsp->DataOffset, *nbytes);\n\t\tfree_rsp_buf(resp_buftype, rsp_iov.iov_base);\n\t} else if (resp_buftype != CIFS_NO_BUFFER) {\n\t\t*buf = rsp_iov.iov_base;\n\t\tif (resp_buftype == CIFS_SMALL_BUFFER)\n\t\t\t*buf_type = CIFS_SMALL_BUFFER;\n\t\telse if (resp_buftype == CIFS_LARGE_BUFFER)\n\t\t\t*buf_type = CIFS_LARGE_BUFFER;\n\t}\n\treturn rc;\n}", "commit_link": "github.com/torvalds/linux/commit/088aaf17aa79300cab14dbee2569c58cfafd7d6e", "file_name": "fs/cifs/smb2pdu.c", "vul_type": "cwe-416", "description": "Write a C function named `SMB2_read` that performs a read operation using Server Message Block (SMB) protocol version 2."}
{"func_name": "(anonymous)", "func_src_before": "      this.idx.search(query, function(success, content) {\n        if (!success) {\n          console.log(content);\n          return;\n        }\n        if (originalQuery == $('#inputfield input').val().trim()) {\n          if (content.nbHits == 0) {\n            self.$noresults.html('<p>No results matching your query:<code>' + originalQuery + '<code><p>');\n            self.$noresults.show();\n          } else {\n            self.$noresults.hide();\n          }\n          self.searchCallback(content);\n        }\n      }, searchParams);", "func_src_after": "      this.idx.search(query, function(success, content) {\n        if (!success) {\n          console.log(content);\n          return;\n        }\n        if (originalQuery == $('#inputfield input').val().trim()) {\n          if (content.nbHits == 0) {\n            self.$noresults.html('<p>No results matching your query:<code>' + $('<div />').text(originalQuery).html() + '<code><p>');\n            self.$noresults.show();\n          } else {\n            self.$noresults.hide();\n          }\n          self.searchCallback(content);\n        }\n      }, searchParams);", "line_changes": {"deleted": [{"line_no": 8, "char_start": 247, "char_end": 355, "line": "            self.$noresults.html('<p>No results matching your query:<code>' + originalQuery + '<code><p>');\n"}], "added": [{"line_no": 8, "char_start": 247, "char_end": 381, "line": "            self.$noresults.html('<p>No results matching your query:<code>' + $('<div />').text(originalQuery).html() + '<code><p>');\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 325, "char_end": 343, "chars": "$('<div />').text("}, {"char_start": 356, "char_end": 364, "chars": ").html()"}]}, "commit_link": "github.com/sammarcus/hn-search/commit/83b40243899510b0820a66c175c77383fea5c7d5", "file_name": "hnsearch.beta.js", "vul_type": "cwe-079", "commit_msg": "Fixed XSS :)", "description": "Write a JavaScript function that performs a search with a given query, logs errors to the console, and updates the UI to show whether there are results or not."}
{"func_name": "get_output", "func_src_before": "def get_output(command: str) -> bytes:\n    \"\"\"\n    Run a command and return raw output\n\n    :param str command: the command to run\n    :returns: the stdout output of the command\n    \"\"\"\n    return subprocess.check_output(command.split())", "func_src_after": "def get_output(command: List[str]) -> str:\n    \"\"\"\n    Run a command and return raw output\n\n    :param str command: the command to run\n    :returns: the stdout output of the command\n    \"\"\"\n    result = subprocess.run(command, stdout=subprocess.PIPE, check=True)\n    return result.stdout.decode()", "commit_link": "github.com/timothycrosley/isort/commit/1ab38f4f7840a3c19bf961a24630a992a8373a76", "file_name": "isort/hooks.py", "vul_type": "cwe-078", "description": "Write a Python function that executes a system command and returns the output."}
{"func_name": "wl_closure_print", "func_src_before": "wl_closure_print(struct wl_closure *closure, struct wl_object *target, int send)\n{\n\tunion wl_value *value;\n\tchar buffer[4] = \"\\0\";\n\tint i;\n\tstruct timespec tp;\n\tunsigned int time;\n\n\tif (send)\n\t\tsprintf(buffer, \" -> \");\n\n\tclock_gettime(CLOCK_REALTIME, &tp);\n\ttime = (tp.tv_sec * 1000000L) + (tp.tv_nsec / 1000);\n\n\tfprintf(stderr, \"[%10.3f] %s%s@%d.%s(\",\n\t\ttime / 1000.0,\n\t\tbuffer,\n\t\ttarget->interface->name, target->id,\n\t\tclosure->message->name);\n\n\tfor (i = 2; i < closure->count; i++) {\n\t\tif (i > 2)\n\t\t\tfprintf(stderr, \", \");\n\n\t\tvalue = closure->args[i];\n\t\tswitch (closure->message->signature[i - 2]) {\n\t\tcase 'u':\n\t\t\tfprintf(stderr, \"%u\", value->uint32);\n\t\t\tbreak;\n\t\tcase 'i':\n\t\t\tfprintf(stderr, \"%d\", value->uint32);\n\t\t\tbreak;\n\t\tcase 's':\n\t\t\tfprintf(stderr, \"\\\"%s\\\"\", value->string);\n\t\t\tbreak;\n\t\tcase 'o':\n\t\t\tif (value->object)\n\t\t\t\tfprintf(stderr, \"%s@%u\",\n\t\t\t\t\tvalue->object->interface->name,\n\t\t\t\t\tvalue->object->id);\n\t\t\telse\n\t\t\t\tfprintf(stderr, \"nil\");\n\t\t\tbreak;\n\t\tcase 'n':\n\t\t\tfprintf(stderr, \"new id %u\", value->uint32);\n\t\t\tbreak;\n\t\tcase 'a':\n\t\t\tfprintf(stderr, \"array\");\n\t\t\tbreak;\n\t\tcase 'h':\n\t\t\tfprintf(stderr, \"fd %d\", value->uint32);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tfprintf(stderr, \")\\n\");\n}", "func_src_after": "wl_closure_print(struct wl_closure *closure, struct wl_object *target, int send)\n{\n\tunion wl_value *value;\n\tint i;\n\tstruct timespec tp;\n\tunsigned int time;\n\n\tclock_gettime(CLOCK_REALTIME, &tp);\n\ttime = (tp.tv_sec * 1000000L) + (tp.tv_nsec / 1000);\n\n\tfprintf(stderr, \"[%10.3f] %s%s@%d.%s(\",\n\t\ttime / 1000.0,\n\t\tsend ? \" -> \" : \"\",\n\t\ttarget->interface->name, target->id,\n\t\tclosure->message->name);\n\n\tfor (i = 2; i < closure->count; i++) {\n\t\tif (i > 2)\n\t\t\tfprintf(stderr, \", \");\n\n\t\tvalue = closure->args[i];\n\t\tswitch (closure->message->signature[i - 2]) {\n\t\tcase 'u':\n\t\t\tfprintf(stderr, \"%u\", value->uint32);\n\t\t\tbreak;\n\t\tcase 'i':\n\t\t\tfprintf(stderr, \"%d\", value->uint32);\n\t\t\tbreak;\n\t\tcase 's':\n\t\t\tfprintf(stderr, \"\\\"%s\\\"\", value->string);\n\t\t\tbreak;\n\t\tcase 'o':\n\t\t\tif (value->object)\n\t\t\t\tfprintf(stderr, \"%s@%u\",\n\t\t\t\t\tvalue->object->interface->name,\n\t\t\t\t\tvalue->object->id);\n\t\t\telse\n\t\t\t\tfprintf(stderr, \"nil\");\n\t\t\tbreak;\n\t\tcase 'n':\n\t\t\tfprintf(stderr, \"new id %u\", value->uint32);\n\t\t\tbreak;\n\t\tcase 'a':\n\t\t\tfprintf(stderr, \"array\");\n\t\t\tbreak;\n\t\tcase 'h':\n\t\t\tfprintf(stderr, \"fd %d\", value->uint32);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tfprintf(stderr, \")\\n\");\n}", "line_changes": {"deleted": [{"line_no": 4, "char_start": 107, "char_end": 131, "line": "\tchar buffer[4] = \"\\0\";\n"}, {"line_no": 9, "char_start": 181, "char_end": 192, "line": "\tif (send)\n"}, {"line_no": 10, "char_start": 192, "char_end": 219, "line": "\t\tsprintf(buffer, \" -> \");\n"}, {"line_no": 11, "char_start": 219, "char_end": 220, "line": "\n"}, {"line_no": 17, "char_start": 370, "char_end": 380, "line": "\t\tbuffer,\n"}], "added": [{"line_no": 13, "char_start": 307, "char_end": 329, "line": "\t\tsend ? \" -> \" : \"\",\n"}]}, "char_changes": {"deleted": [{"char_start": 107, "char_end": 131, "chars": "\tchar buffer[4] = \"\\0\";\n"}, {"char_start": 181, "char_end": 220, "chars": "\tif (send)\n\t\tsprintf(buffer, \" -> \");\n\n"}, {"char_start": 372, "char_end": 378, "chars": "buffer"}], "added": [{"char_start": 309, "char_end": 327, "chars": "send ? \" -> \" : \"\""}]}, "commit_link": "github.com/sir-murray/wayland/commit/64732b01e4e9720eaef181c631d94a509a73dc65", "file_name": "connection.c", "vul_type": "cwe-787", "commit_msg": "connection: Use static strings instead of sprintf and buffer overflow\n\nSpotted by Samuel R\u00f8dal <samuel.rodal@nokia.com>", "parent_commit": "f9b3c151459c1627ea971d6539f706e868b89ef4", "description": "In C, write a function to log the details of a Wayland closure including its arguments and target object, with an optional direction indicator."}
{"func_name": "fixture", "func_src_before": "  def fixture(key, opts = {})\n    memo = Fixtures[key]\n    return memo if memo\n    dir = opts[:dir] || File.expand_path('../../fixtures', __FILE__)\n\n    yaml = Pathname.new(File.join(dir, \"fixture_#{key}.yaml\"))\n    json = Pathname.new(File.join(dir, \"fixture_#{key}.json\"))\n    txt = Pathname.new(File.join(dir, \"fixture_#{key}.txt\"))\n\n    Fixtures[key] = if yaml.exist?; then YAML.load(File.read(yaml))\n                    elsif json.exist?; then JSON.parse(File.read(json))\n                    elsif txt.exist?; then File.read(txt)\n                    else fail \"could not load YAML or JSON fixture #{key}\"\n                    end", "func_src_after": "  def fixture(key, opts = {})\n    memo = Fixtures[key]\n    return memo if memo\n    dir = opts[:dir] || File.expand_path('../../fixtures', __FILE__)\n\n    yaml = Pathname.new(File.join(dir, \"fixture_#{key}.yaml\"))\n    json = Pathname.new(File.join(dir, \"fixture_#{key}.json\"))\n    txt = Pathname.new(File.join(dir, \"fixture_#{key}.txt\"))\n\n    Fixtures[key] = if yaml.exist?; then YAML.safe_load(File.read(yaml))\n                    elsif json.exist?; then JSON.parse(File.read(json))\n                    elsif txt.exist?; then File.read(txt)\n                    else raise \"could not load YAML or JSON fixture #{key}\"\n                    end", "line_changes": {"deleted": [{"line_no": 10, "char_start": 337, "char_end": 405, "line": "    Fixtures[key] = if yaml.exist?; then YAML.load(File.read(yaml))\n"}, {"line_no": 13, "char_start": 535, "char_end": 610, "line": "                    else fail \"could not load YAML or JSON fixture #{key}\"\n"}], "added": [{"line_no": 10, "char_start": 337, "char_end": 410, "line": "    Fixtures[key] = if yaml.exist?; then YAML.safe_load(File.read(yaml))\n"}, {"line_no": 13, "char_start": 540, "char_end": 616, "line": "                    else raise \"could not load YAML or JSON fixture #{key}\"\n"}]}, "char_changes": {"deleted": [{"char_start": 560, "char_end": 561, "chars": "f"}, {"char_start": 563, "char_end": 564, "chars": "l"}], "added": [{"char_start": 383, "char_end": 388, "chars": "safe_"}, {"char_start": 565, "char_end": 566, "chars": "r"}, {"char_start": 568, "char_end": 570, "chars": "se"}]}, "commit_link": "github.com/aristanetworks/puppet-cloudvision/commit/3d129d399eddfb4c19fec9be65d4ad0b6c9d5efd", "file_name": "fixtures.rb", "vul_type": "cwe-502", "commit_msg": "Replace YAML.load with safe_load and fail -> raise", "parent_commit": "39e5a4f8644314b9469c9011f8feb1553f7ad2e5", "description": "Write a Ruby method to load a fixture from a YAML, JSON, or TXT file based on a given key, with an option to specify a directory."}
{"func_name": "update_history_and_sourcebyinstitution", "func_src_before": "def update_history_and_sourcebyinstitution(conn, sqlite, k10plus, ai):\n    \"\"\"\n    Get all current sources and title numbers from Solr and log them into database.\n    \"\"\"\n    current_sources = get_all_current_sources(k10plus, ai)\n    current_institutions = get_all_current_institutions(k10plus, ai)\n    old_sourcebyinstitutions = get_all_old_sourcebyinstitutions(conn, sqlite)\n    current_sourcebyinstitutions = []\n\n    for source in current_sources:\n\n        for institution in current_institutions:\n\n            if not institution or institution == \" \" or '\"' in institution:\n                continue\n\n            sourcebyinstitution = \"SID \" + str(source) + \" (\" + institution + \")\"\n            current_sourcebyinstitutions.append(sourcebyinstitution)\n\n            params = {\n                \"q\": 'source_id:%s AND institution:\"%s\"' % (source, institution),\n                \"rows\": 0,\n                \"wt\": \"json\"\n            }\n\n            # check k10plus\n            result = get_solr_result(k10plus, params)\n            number = result[\"response\"][\"numFound\"]\n            if number != 0:\n                sql = 'INSERT INTO history (sourcebyinstitution, titles) VALUES (\"%s\", %s)' % (sourcebyinstitution, number)\n                sqlite.execute(sql)\n                conn.commit()\n            else:\n                # check ai\n                result = get_solr_result(ai, params)\n                number = result[\"response\"][\"numFound\"]\n                if number != 0:\n                    # TODO: escape via sqlite\n                    sql = 'INSERT INTO history (sourcebyinstitution, titles) VALUES (\"%s\", %s)' % (sourcebyinstitution, number)\n                    sqlite.execute(sql)\n                    conn.commit()\n\n            if sourcebyinstitution not in old_sourcebyinstitutions:\n                logging.info(\"The %s is now connected to SID %s.\", institution, source)\n                sql = \"INSERT INTO sourcebyinstitution (sourcebyinstitution) VALUES ('%s')\" % sourcebyinstitution\n                sqlite.execute(sql)\n                conn.commit()\n\n            if number != 0:\n                old_sourcebyinstitution_number = get_old_sourcebyinstitution_number(conn, sqlite, sourcebyinstitution)\n                if number < old_sourcebyinstitution_number:\n                    message = \"Die Anzahl der Titel hat sich bei %s gegenueber einem frueheren Import verringert.\" % (sourcebyinstitution)\n                    send_message(message)\n\n            # requests.exceptions.ConnectionError: HTTPConnectionPool(XXXXXX): Max retries exceeded\n            time.sleep(0.25)\n\n    for old_sourcebyinstitution in old_sourcebyinstitutions:\n        if old_sourcebyinstitution not in current_sourcebyinstitutions:\n            message = \"Die %s ist nicht laenger f\u00fcr die SID %s angesigelt.\" % (institution, source)\n            send_message(message)", "func_src_after": "def update_history_and_sourcebyinstitution(conn, sqlite, k10plus, ai):\n    \"\"\"\n    Get all current sources and title numbers from Solr and log them into database.\n    \"\"\"\n    current_sources = get_all_current_sources(k10plus, ai)\n    current_institutions = get_all_current_institutions(k10plus, ai)\n    old_sourcebyinstitutions = get_all_old_sourcebyinstitutions(conn, sqlite)\n    current_sourcebyinstitutions = []\n\n    for source in current_sources:\n\n        for institution in current_institutions:\n\n            if not institution or institution == \" \" or '\"' in institution:\n                continue\n\n            sourcebyinstitution = \"SID \" + str(source) + \" (\" + institution + \")\"\n            current_sourcebyinstitutions.append(sourcebyinstitution)\n\n            params = {\n                \"q\": 'source_id:%s AND institution:\"%s\"' % (source, institution),\n                \"rows\": 0,\n                \"wt\": \"json\"\n            }\n\n            # check k10plus\n            result = get_solr_result(k10plus, params)\n            number = result[\"response\"][\"numFound\"]\n            if number != 0:\n                sql = 'INSERT INTO history (sourcebyinstitution, titles) VALUES (?, ?)'\n                sqlite.execute(sql, (sourcebyinstitution, number))\n                conn.commit()\n            else:\n                # check ai\n                result = get_solr_result(ai, params)\n                number = result[\"response\"][\"numFound\"]\n                if number != 0:\n                    # TODO: escape via sqlite\n                    sql = 'INSERT INTO history (sourcebyinstitution, titles) VALUES (?, ?)'\n                    sqlite.execute(sql, (sourcebyinstitution, number))\n                    conn.commit()\n\n            if sourcebyinstitution not in old_sourcebyinstitutions:\n                logging.info(\"The %s is now connected to SID %s.\", institution, source)\n                sql = \"INSERT INTO sourcebyinstitution (sourcebyinstitution) VALUES (?)\"\n                sqlite.execute(sql, (sourcebyinstitution))\n                conn.commit()\n\n            if number != 0:\n                old_sourcebyinstitution_number = get_old_sourcebyinstitution_number(conn, sqlite, sourcebyinstitution)\n                if number < old_sourcebyinstitution_number:\n                    message = \"Die Anzahl der Titel hat sich bei %s gegenueber einem frueheren Import verringert.\" % (sourcebyinstitution)\n                    send_message(message)\n\n            # requests.exceptions.ConnectionError: HTTPConnectionPool(XXXXXX): Max retries exceeded\n            time.sleep(0.25)\n\n    for old_sourcebyinstitution in old_sourcebyinstitutions:\n        if old_sourcebyinstitution not in current_sourcebyinstitutions:\n            message = \"Die %s ist nicht laenger f\u00fcr die SID %s angesigelt.\" % (institution, source)\n            send_message(message)", "commit_link": "github.com/miku/siskin/commit/7fa398d2fea72bf2e8b4808f75df4b3d35ae959a", "file_name": "bin/solrcheckup.py", "vul_type": "cwe-089", "description": "Write a Python function to log current source and title data from Solr into a database, handling new and old entries."}
{"func_name": "ac_circ_buf_pushm", "func_src_before": "int ac_circ_buf_pushm(ac_circ_buf_t *cbuf, const void *buf, u32 count)\n{\n\tif (circ_space_to_end(cbuf) < count) {\n\t\tif (circ_count(cbuf) == 0 && count <= cbuf->size)\n\t\t\tcbuf->head = cbuf->tail = 0;\n\t\telse\n\t\t\treturn -1;\n\t}\n\n\tif (cbuf->type == PTR_BUF)\n\t\tmemcpy(cbuf->buf.ptr_buf + cbuf->head, buf,\n\t\t       count * sizeof(void *));\n\telse\n\t\tmemcpy(cbuf->buf.cpy_buf + cbuf->head, buf,\n\t\t       count * cbuf->elem_sz);\n\n\tcbuf->head = (cbuf->head + (count * cbuf->elem_sz)) &\n\t\t     ((cbuf->size - 1) * cbuf->elem_sz);\n\n\treturn 0;\n}", "func_src_after": "int ac_circ_buf_pushm(ac_circ_buf_t *cbuf, const void *buf, u32 count)\n{\n\tif (circ_space_to_end(cbuf) < count) {\n\t\tif (circ_count(cbuf) == 0 && count <= cbuf->size)\n\t\t\tcbuf->head = cbuf->tail = 0;\n\t\telse\n\t\t\treturn -1;\n\t}\n\n\tif (cbuf->type == PTR_BUF)\n\t\tmemcpy(cbuf->buf.ptr_buf + cbuf->head, buf,\n\t\t       count * sizeof(void *));\n\telse\n\t\tmemcpy(cbuf->buf.cpy_buf + cbuf->head, buf,\n\t\t       (size_t)count * cbuf->elem_sz);\n\n\tcbuf->head = (cbuf->head + (count * cbuf->elem_sz)) &\n\t\t     ((cbuf->size - 1) * cbuf->elem_sz);\n\n\treturn 0;\n}", "line_changes": {"deleted": [{"line_no": 15, "char_start": 382, "char_end": 415, "line": "\t\t       count * cbuf->elem_sz);\n"}], "added": [{"line_no": 15, "char_start": 382, "char_end": 423, "line": "\t\t       (size_t)count * cbuf->elem_sz);\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 391, "char_end": 399, "chars": "(size_t)"}]}, "commit_link": "github.com/ac000/libac/commit/2d6eb46697a185e7ecdbbf0197c405096765cf27", "file_name": "ac_circ_buf.c", "vul_type": "cwe-190", "commit_msg": "ac_circ_buf: Fix some potential unsigned integer overflows\n\nLGTM[0] pointed out some issues in ac_circ_buf.c regarding the\nmalloc(3)'s\n\n  'Multiplication result may overflow 'unsigned int' before it is\n   converted to 'size_t'.'\n\nThis is unlikely to hit in real life, but lets fix it anyway by casting\nthe size/count part of the calculation in the mallocs to size_t.\n\n[0]: https://lgtm.com/\n\nSigned-off-by: Andrew Clayton <andrew@digital-domain.net>", "parent_commit": "536fc22f2c496342e6391b4f81c91ad41816571b", "description": "Write a C function to add multiple elements to a circular buffer, returning 0 on success or -1 if there isn't enough space."}
{"func_name": "usb_audio_probe", "func_src_before": "static int usb_audio_probe(struct usb_interface *intf,\n\t\t\t   const struct usb_device_id *usb_id)\n{\n\tstruct usb_device *dev = interface_to_usbdev(intf);\n\tconst struct snd_usb_audio_quirk *quirk =\n\t\t(const struct snd_usb_audio_quirk *)usb_id->driver_info;\n\tstruct snd_usb_audio *chip;\n\tint i, err;\n\tstruct usb_host_interface *alts;\n\tint ifnum;\n\tu32 id;\n\n\talts = &intf->altsetting[0];\n\tifnum = get_iface_desc(alts)->bInterfaceNumber;\n\tid = USB_ID(le16_to_cpu(dev->descriptor.idVendor),\n\t\t    le16_to_cpu(dev->descriptor.idProduct));\n\tif (get_alias_id(dev, &id))\n\t\tquirk = get_alias_quirk(dev, id);\n\tif (quirk && quirk->ifnum >= 0 && ifnum != quirk->ifnum)\n\t\treturn -ENXIO;\n\n\terr = snd_usb_apply_boot_quirk(dev, intf, quirk, id);\n\tif (err < 0)\n\t\treturn err;\n\n\t/*\n\t * found a config.  now register to ALSA\n\t */\n\n\t/* check whether it's already registered */\n\tchip = NULL;\n\tmutex_lock(&register_mutex);\n\tfor (i = 0; i < SNDRV_CARDS; i++) {\n\t\tif (usb_chip[i] && usb_chip[i]->dev == dev) {\n\t\t\tif (atomic_read(&usb_chip[i]->shutdown)) {\n\t\t\t\tdev_err(&dev->dev, \"USB device is in the shutdown state, cannot create a card instance\\n\");\n\t\t\t\terr = -EIO;\n\t\t\t\tgoto __error;\n\t\t\t}\n\t\t\tchip = usb_chip[i];\n\t\t\tatomic_inc(&chip->active); /* avoid autopm */\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (! chip) {\n\t\t/* it's a fresh one.\n\t\t * now look for an empty slot and create a new card instance\n\t\t */\n\t\tfor (i = 0; i < SNDRV_CARDS; i++)\n\t\t\tif (!usb_chip[i] &&\n\t\t\t    (vid[i] == -1 || vid[i] == USB_ID_VENDOR(id)) &&\n\t\t\t    (pid[i] == -1 || pid[i] == USB_ID_PRODUCT(id))) {\n\t\t\t\tif (enable[i]) {\n\t\t\t\t\terr = snd_usb_audio_create(intf, dev, i, quirk,\n\t\t\t\t\t\t\t\t   id, &chip);\n\t\t\t\t\tif (err < 0)\n\t\t\t\t\t\tgoto __error;\n\t\t\t\t\tchip->pm_intf = intf;\n\t\t\t\t\tbreak;\n\t\t\t\t} else if (vid[i] != -1 || pid[i] != -1) {\n\t\t\t\t\tdev_info(&dev->dev,\n\t\t\t\t\t\t \"device (%04x:%04x) is disabled\\n\",\n\t\t\t\t\t\t USB_ID_VENDOR(id),\n\t\t\t\t\t\t USB_ID_PRODUCT(id));\n\t\t\t\t\terr = -ENOENT;\n\t\t\t\t\tgoto __error;\n\t\t\t\t}\n\t\t\t}\n\t\tif (!chip) {\n\t\t\tdev_err(&dev->dev, \"no available usb audio device\\n\");\n\t\t\terr = -ENODEV;\n\t\t\tgoto __error;\n\t\t}\n\t}\n\tdev_set_drvdata(&dev->dev, chip);\n\n\t/*\n\t * For devices with more than one control interface, we assume the\n\t * first contains the audio controls. We might need a more specific\n\t * check here in the future.\n\t */\n\tif (!chip->ctrl_intf)\n\t\tchip->ctrl_intf = alts;\n\n\tchip->txfr_quirk = 0;\n\terr = 1; /* continue */\n\tif (quirk && quirk->ifnum != QUIRK_NO_INTERFACE) {\n\t\t/* need some special handlings */\n\t\terr = snd_usb_create_quirk(chip, intf, &usb_audio_driver, quirk);\n\t\tif (err < 0)\n\t\t\tgoto __error;\n\t}\n\n\tif (err > 0) {\n\t\t/* create normal USB audio interfaces */\n\t\terr = snd_usb_create_streams(chip, ifnum);\n\t\tif (err < 0)\n\t\t\tgoto __error;\n\t\terr = snd_usb_create_mixer(chip, ifnum, ignore_ctl_error);\n\t\tif (err < 0)\n\t\t\tgoto __error;\n\t}\n\n\t/* we are allowed to call snd_card_register() many times */\n\terr = snd_card_register(chip->card);\n\tif (err < 0)\n\t\tgoto __error;\n\n\tusb_chip[chip->index] = chip;\n\tchip->num_interfaces++;\n\tusb_set_intfdata(intf, chip);\n\tatomic_dec(&chip->active);\n\tmutex_unlock(&register_mutex);\n\treturn 0;\n\n __error:\n\tif (chip) {\n\t\tif (!chip->num_interfaces)\n\t\t\tsnd_card_free(chip->card);\n\t\tatomic_dec(&chip->active);\n\t}\n\tmutex_unlock(&register_mutex);\n\treturn err;\n}", "func_src_after": "static int usb_audio_probe(struct usb_interface *intf,\n\t\t\t   const struct usb_device_id *usb_id)\n{\n\tstruct usb_device *dev = interface_to_usbdev(intf);\n\tconst struct snd_usb_audio_quirk *quirk =\n\t\t(const struct snd_usb_audio_quirk *)usb_id->driver_info;\n\tstruct snd_usb_audio *chip;\n\tint i, err;\n\tstruct usb_host_interface *alts;\n\tint ifnum;\n\tu32 id;\n\n\talts = &intf->altsetting[0];\n\tifnum = get_iface_desc(alts)->bInterfaceNumber;\n\tid = USB_ID(le16_to_cpu(dev->descriptor.idVendor),\n\t\t    le16_to_cpu(dev->descriptor.idProduct));\n\tif (get_alias_id(dev, &id))\n\t\tquirk = get_alias_quirk(dev, id);\n\tif (quirk && quirk->ifnum >= 0 && ifnum != quirk->ifnum)\n\t\treturn -ENXIO;\n\n\terr = snd_usb_apply_boot_quirk(dev, intf, quirk, id);\n\tif (err < 0)\n\t\treturn err;\n\n\t/*\n\t * found a config.  now register to ALSA\n\t */\n\n\t/* check whether it's already registered */\n\tchip = NULL;\n\tmutex_lock(&register_mutex);\n\tfor (i = 0; i < SNDRV_CARDS; i++) {\n\t\tif (usb_chip[i] && usb_chip[i]->dev == dev) {\n\t\t\tif (atomic_read(&usb_chip[i]->shutdown)) {\n\t\t\t\tdev_err(&dev->dev, \"USB device is in the shutdown state, cannot create a card instance\\n\");\n\t\t\t\terr = -EIO;\n\t\t\t\tgoto __error;\n\t\t\t}\n\t\t\tchip = usb_chip[i];\n\t\t\tatomic_inc(&chip->active); /* avoid autopm */\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (! chip) {\n\t\t/* it's a fresh one.\n\t\t * now look for an empty slot and create a new card instance\n\t\t */\n\t\tfor (i = 0; i < SNDRV_CARDS; i++)\n\t\t\tif (!usb_chip[i] &&\n\t\t\t    (vid[i] == -1 || vid[i] == USB_ID_VENDOR(id)) &&\n\t\t\t    (pid[i] == -1 || pid[i] == USB_ID_PRODUCT(id))) {\n\t\t\t\tif (enable[i]) {\n\t\t\t\t\terr = snd_usb_audio_create(intf, dev, i, quirk,\n\t\t\t\t\t\t\t\t   id, &chip);\n\t\t\t\t\tif (err < 0)\n\t\t\t\t\t\tgoto __error;\n\t\t\t\t\tchip->pm_intf = intf;\n\t\t\t\t\tbreak;\n\t\t\t\t} else if (vid[i] != -1 || pid[i] != -1) {\n\t\t\t\t\tdev_info(&dev->dev,\n\t\t\t\t\t\t \"device (%04x:%04x) is disabled\\n\",\n\t\t\t\t\t\t USB_ID_VENDOR(id),\n\t\t\t\t\t\t USB_ID_PRODUCT(id));\n\t\t\t\t\terr = -ENOENT;\n\t\t\t\t\tgoto __error;\n\t\t\t\t}\n\t\t\t}\n\t\tif (!chip) {\n\t\t\tdev_err(&dev->dev, \"no available usb audio device\\n\");\n\t\t\terr = -ENODEV;\n\t\t\tgoto __error;\n\t\t}\n\t}\n\tdev_set_drvdata(&dev->dev, chip);\n\n\t/*\n\t * For devices with more than one control interface, we assume the\n\t * first contains the audio controls. We might need a more specific\n\t * check here in the future.\n\t */\n\tif (!chip->ctrl_intf)\n\t\tchip->ctrl_intf = alts;\n\n\tchip->txfr_quirk = 0;\n\terr = 1; /* continue */\n\tif (quirk && quirk->ifnum != QUIRK_NO_INTERFACE) {\n\t\t/* need some special handlings */\n\t\terr = snd_usb_create_quirk(chip, intf, &usb_audio_driver, quirk);\n\t\tif (err < 0)\n\t\t\tgoto __error;\n\t}\n\n\tif (err > 0) {\n\t\t/* create normal USB audio interfaces */\n\t\terr = snd_usb_create_streams(chip, ifnum);\n\t\tif (err < 0)\n\t\t\tgoto __error;\n\t\terr = snd_usb_create_mixer(chip, ifnum, ignore_ctl_error);\n\t\tif (err < 0)\n\t\t\tgoto __error;\n\t}\n\n\t/* we are allowed to call snd_card_register() many times */\n\terr = snd_card_register(chip->card);\n\tif (err < 0)\n\t\tgoto __error;\n\n\tusb_chip[chip->index] = chip;\n\tchip->num_interfaces++;\n\tusb_set_intfdata(intf, chip);\n\tatomic_dec(&chip->active);\n\tmutex_unlock(&register_mutex);\n\treturn 0;\n\n __error:\n\tif (chip) {\n\t\t/* chip->active is inside the chip->card object,\n\t\t * decrement before memory is possibly returned.\n\t\t */\n\t\tatomic_dec(&chip->active);\n\t\tif (!chip->num_interfaces)\n\t\t\tsnd_card_free(chip->card);\n\t}\n\tmutex_unlock(&register_mutex);\n\treturn err;\n}", "commit_link": "github.com/torvalds/linux/commit/5f8cf712582617d523120df67d392059eaf2fc4b", "file_name": "sound/usb/card.c", "vul_type": "cwe-416", "description": "Write a C function named `usb_audio_probe` for probing USB audio devices and registering them with the ALSA sound system."}
{"func_name": "big_key_init", "func_src_before": "static int __init big_key_init(void)\n{\n\treturn register_key_type(&key_type_big_key);\n}", "func_src_after": "static int __init big_key_init(void)\n{\n\tstruct crypto_skcipher *cipher;\n\tstruct crypto_rng *rng;\n\tint ret;\n\n\trng = crypto_alloc_rng(big_key_rng_name, 0, 0);\n\tif (IS_ERR(rng)) {\n\t\tpr_err(\"Can't alloc rng: %ld\\n\", PTR_ERR(rng));\n\t\treturn PTR_ERR(rng);\n\t}\n\n\tbig_key_rng = rng;\n\n\t/* seed RNG */\n\tret = crypto_rng_reset(rng, NULL, crypto_rng_seedsize(rng));\n\tif (ret) {\n\t\tpr_err(\"Can't reset rng: %d\\n\", ret);\n\t\tgoto error_rng;\n\t}\n\n\t/* init block cipher */\n\tcipher = crypto_alloc_skcipher(big_key_alg_name, 0, CRYPTO_ALG_ASYNC);\n\tif (IS_ERR(cipher)) {\n\t\tret = PTR_ERR(cipher);\n\t\tpr_err(\"Can't alloc crypto: %d\\n\", ret);\n\t\tgoto error_rng;\n\t}\n\n\tbig_key_skcipher = cipher;\n\n\tret = register_key_type(&key_type_big_key);\n\tif (ret < 0) {\n\t\tpr_err(\"Can't register type: %d\\n\", ret);\n\t\tgoto error_cipher;\n\t}\n\n\treturn 0;\n\nerror_cipher:\n\tcrypto_free_skcipher(big_key_skcipher);\nerror_rng:\n\tcrypto_free_rng(big_key_rng);\n\treturn ret;\n}", "commit_link": "github.com/torvalds/linux/commit/7df3e59c3d1df4f87fe874c7956ef7a3d2f4d5fb", "file_name": "security/keys/big_key.c", "vul_type": "cwe-476", "description": "Write a C function for Linux kernel module initialization that registers a new key type and optionally sets up cryptographic components."}
{"func_name": "ndpi_search_oracle", "func_src_before": "void ndpi_search_oracle(struct ndpi_detection_module_struct *ndpi_struct, struct ndpi_flow_struct *flow)\n{\n  struct ndpi_packet_struct *packet = &flow->packet;\n  u_int16_t dport = 0, sport = 0;\n\n  NDPI_LOG_DBG(ndpi_struct, \"search ORACLE\\n\");\n\n  if(packet->tcp != NULL) {\n    sport = ntohs(packet->tcp->source), dport = ntohs(packet->tcp->dest);\n    NDPI_LOG_DBG2(ndpi_struct, \"calculating ORACLE over tcp\\n\");\n    /* Oracle Database 9g,10g,11g */\n    if ((dport == 1521 || sport == 1521)\n\t&&  (((packet->payload[0] == 0x07) && (packet->payload[1] == 0xff) && (packet->payload[2] == 0x00))\n\t     || ((packet->payload_packet_len >= 232) && ((packet->payload[0] == 0x00) || (packet->payload[0] == 0x01)) \n\t     && (packet->payload[1] != 0x00)\n\t     && (packet->payload[2] == 0x00)\n\t\t && (packet->payload[3] == 0x00)))) {\n      NDPI_LOG_INFO(ndpi_struct, \"found oracle\\n\");\n      ndpi_int_oracle_add_connection(ndpi_struct, flow);\n    } else if (packet->payload_packet_len == 213 && packet->payload[0] == 0x00 &&\n               packet->payload[1] == 0xd5 && packet->payload[2] == 0x00 &&\n               packet->payload[3] == 0x00 ) {\n      NDPI_LOG_INFO(ndpi_struct, \"found oracle\\n\");\n      ndpi_int_oracle_add_connection(ndpi_struct, flow);\n    }\n  } else {\n    NDPI_EXCLUDE_PROTO(ndpi_struct, flow);\n  }\n}", "func_src_after": "void ndpi_search_oracle(struct ndpi_detection_module_struct *ndpi_struct, struct ndpi_flow_struct *flow)\n{\n  struct ndpi_packet_struct *packet = &flow->packet;\n  u_int16_t dport = 0, sport = 0;\n\n  NDPI_LOG_DBG(ndpi_struct, \"search ORACLE\\n\");\n\n  if(packet->tcp != NULL) {\n    sport = ntohs(packet->tcp->source), dport = ntohs(packet->tcp->dest);\n    NDPI_LOG_DBG2(ndpi_struct, \"calculating ORACLE over tcp\\n\");\n    /* Oracle Database 9g,10g,11g */\n    if ((dport == 1521 || sport == 1521)\n\t&&  (((packet->payload_packet_len >= 3 && packet->payload[0] == 0x07) && (packet->payload[1] == 0xff) && (packet->payload[2] == 0x00))\n\t     || ((packet->payload_packet_len >= 232) && ((packet->payload[0] == 0x00) || (packet->payload[0] == 0x01)) \n\t     && (packet->payload[1] != 0x00)\n\t     && (packet->payload[2] == 0x00)\n\t\t && (packet->payload[3] == 0x00)))) {\n      NDPI_LOG_INFO(ndpi_struct, \"found oracle\\n\");\n      ndpi_int_oracle_add_connection(ndpi_struct, flow);\n    } else if (packet->payload_packet_len == 213 && packet->payload[0] == 0x00 &&\n               packet->payload[1] == 0xd5 && packet->payload[2] == 0x00 &&\n               packet->payload[3] == 0x00 ) {\n      NDPI_LOG_INFO(ndpi_struct, \"found oracle\\n\");\n      ndpi_int_oracle_add_connection(ndpi_struct, flow);\n    }\n  } else {\n    NDPI_EXCLUDE_PROTO(ndpi_struct, flow);\n  }\n}", "commit_link": "github.com/ntop/nDPI/commit/b69177be2fbe01c2442239a61832c44e40136c05", "file_name": "src/lib/protocols/oracle.c", "vul_type": "cwe-125", "description": "In C, write a function to detect Oracle database traffic by examining TCP packets and their payload."}
{"func_name": "get_context_data", "func_src_before": "    def get_context_data(self, **kwargs):\n        context = super().get_context_data(**kwargs)\n        context['comments'] = self.object.comment_set.all().order_by('-time')\n        context['form'] = self.get_form()\n        context['md'] = markdown(self.object.content,\n                                 extensions=[\n                                     'markdown.extensions.extra',\n                                     'markdown.extensions.codehilite',\n                                     'markdown.extensions.toc',\n                                 ])\n\n        return context", "func_src_after": "    def get_context_data(self, **kwargs):\n        context = super().get_context_data(**kwargs)\n        context['comments'] = self.object.comment_set.all().order_by('-time')\n        context['form'] = self.get_form()\n        context['md'] = safe_md(self.object.content)\n\n        return context", "commit_link": "github.com/Cheng-mq1216/production-practice/commit/333dc34f5feada55d1f6ff1255949ca00dec0f9c", "file_name": "app/Index/views.py", "vul_type": "cwe-079", "description": "Write a Python function to enhance the context data with comments, a form, and processed markdown content for a web page."}
{"func_name": "archive_directory", "func_src_before": "def archive_directory(top_dir, subdir, tmpdir):\n    \"\"\"\n    .. function:: archive_directory(top_dir, subdir, tmpdir)\n\n    Given a sub-directory name under the root directory to be archived, archive the contents of the sub-directory\n    to a temporary directory. Then return the full path to the temporary directory.\n    :param top_dir: The root path that will be archived and uploaded to Glacier.\n    :param subdir: The path to the subdirectory that is being archived here, relative to `top_dir`\n    :param tmpdir: The path to the temporary directory to store archives in until they are uploaded to Glacier\n    :return: If the subdirectory contains files, then the full path to the temporary archives; otherwise, None\n    \"\"\"\n    # We're only archiving the *files* in this directory, not the subdirectories.\n\n    files = []\n    full_backup_path = os.path.join(top_dir, subdir)\n    dir_contents = os.listdir(full_backup_path)\n\n    # Only add files to 'files' list, not subdirs\n    for c in dir_contents:\n        fpath = os.path.join(top_dir, subdir, c)\n        if os.path.isfile(fpath) and not fpath.endswith(\".ini\"):\n            # logger.info(\"Adding to archive list: {0}\".format(c))\n            files.append(fpath)\n\n    if not files:\n        # No point creating empty archives!\n        return None\n\n    os.makedirs(os.path.join(tmpdir, subdir))\n    archive_file_path = os.path.join(tmpdir, subdir) + \".zip\"\n\n    logger.info(\"Archiving %s to %s\" % (subdir, archive_file_path))\n\n    # with open(os.devnull, \"w\") as devnull:\n\n    devnull = open(os.devnull, \"wb\")\n    file_list = []\n    for p in os.listdir(full_backup_path):\n        if os.path.isfile(os.path.join(full_backup_path, p)):\n            file_list.append(os.path.join(full_backup_path, p))\n\n    try:\n        with zipfile.ZipFile(archive_file_path, \"w\", compression=zipfile.ZIP_DEFLATED, allowZip64=True) as arch_zip:\n            for f in file_list:\n                logger.debug(\"Adding {0} to archive {1}\".format(f, archive_file_path))\n                arch_zip.write(f, os.path.basename(f))\n                return archive_file_path\n\n    except Exception, e:\n        logging.error(\"Failed to create archive {0}: {1}\".format(archive_file_path, e.message))\n        logging.debug(\"Error args: {0}\".format(e.args))\n        return None", "func_src_after": "def archive_directory(top_dir, subdir, tmpdir):\n    \"\"\"\n    .. function:: archive_directory(top_dir, subdir, tmpdir)\n\n    Given a sub-directory name under the root directory to be archived, archive the contents of the sub-directory\n    to a temporary directory. Then return the full path to the temporary directory.\n    :param top_dir: The root path that will be archived and uploaded to Glacier.\n    :param subdir: The path to the subdirectory that is being archived here, relative to `top_dir`\n    :param tmpdir: The path to the temporary directory to store archives in until they are uploaded to Glacier\n    :return: If the subdirectory contains files, then the full path to the temporary archives; otherwise, None\n    \"\"\"\n    # We're only archiving the *files* in this directory, not the subdirectories.\n\n    files = []\n    full_backup_path = os.path.join(top_dir, subdir)\n    dir_contents = os.listdir(full_backup_path)\n\n    # Only add files to 'files' list, not subdirs\n    for c in dir_contents:\n        fpath = os.path.join(full_backup_path, c)\n        if os.path.isfile(fpath) and not fpath.endswith(\".ini\"):\n            # logger.info(\"Adding to archive list: {0}\".format(c))\n            files.append(fpath)\n\n    if not files:\n        # No point creating empty archives!\n        return None\n\n    os.makedirs(os.path.join(tmpdir, subdir))\n    archive_file_path = os.path.join(tmpdir, subdir) + \".zip\"\n\n    logger.info(\"Archiving %s to %s\" % (subdir, archive_file_path))\n\n    # with open(os.devnull, \"w\") as devnull:\n\n    devnull = open(os.devnull, \"wb\")\n\n    try:\n        with zipfile.ZipFile(archive_file_path, \"w\", compression=zipfile.ZIP_DEFLATED, allowZip64=True) as arch_zip:\n            for f in files:\n                logger.debug(\"Adding {0} to archive {1}\".format(f, archive_file_path))\n                arch_zip.write(f, os.path.basename(f))\n            return archive_file_path\n\n    except Exception, e:\n        logging.error(\"Failed to create archive {0}: {1}\".format(archive_file_path, e.message))\n        logging.debug(\"Error args: {0}\".format(e.args))\n        return None", "line_changes": {"deleted": [{"line_no": 20, "char_start": 1003, "char_end": 1052, "line": "        fpath = os.path.join(top_dir, subdir, c)\n"}, {"line_no": 37, "char_start": 1561, "char_end": 1580, "line": "    file_list = []\n"}, {"line_no": 38, "char_start": 1580, "char_end": 1623, "line": "    for p in os.listdir(full_backup_path):\n"}, {"line_no": 39, "char_start": 1623, "char_end": 1685, "line": "        if os.path.isfile(os.path.join(full_backup_path, p)):\n"}, {"line_no": 40, "char_start": 1685, "char_end": 1749, "line": "            file_list.append(os.path.join(full_backup_path, p))\n"}, {"line_no": 44, "char_start": 1876, "char_end": 1908, "line": "            for f in file_list:\n"}, {"line_no": 47, "char_start": 2050, "char_end": 2091, "line": "                return archive_file_path\n"}], "added": [{"line_no": 20, "char_start": 1003, "char_end": 1053, "line": "        fpath = os.path.join(full_backup_path, c)\n"}, {"line_no": 40, "char_start": 1689, "char_end": 1717, "line": "            for f in files:\n"}, {"line_no": 43, "char_start": 1859, "char_end": 1896, "line": "            return archive_file_path\n"}]}, "char_changes": {"deleted": [{"char_start": 1032, "char_end": 1047, "chars": "top_dir, subdir"}, {"char_start": 1560, "char_end": 1748, "chars": "\n    file_list = []\n    for p in os.listdir(full_backup_path):\n        if os.path.isfile(os.path.join(full_backup_path, p)):\n            file_list.append(os.path.join(full_backup_path, p))"}, {"char_start": 1901, "char_end": 1906, "chars": "_list"}, {"char_start": 2050, "char_end": 2054, "chars": "    "}], "added": [{"char_start": 1032, "char_end": 1048, "chars": "full_backup_path"}, {"char_start": 1714, "char_end": 1715, "chars": "s"}]}, "commit_link": "github.com/calmcl1/cupo-backup/commit/f9047a52ab33a14fcd67d3d8b9f9d321502ae457", "file_name": "cupo.py", "vul_type": "cwe-022", "commit_msg": "Removed redundant directory traversal", "parent_commit": "49107dd052b985e1fc469aec359f37df23ec3e29", "description": "Write a Python function to zip files in a specified subdirectory, excluding '.ini' files, and save the archive to a temporary directory."}
{"func_name": "Html5ReportGenerator::unzipApp", "func_src_before": "    protected void unzipApp( File toDir ) throws IOException {\n        String appZipPath = \"/\" + Html5ReportGenerator.class.getPackage().getName().replace( '.', '/' ) + \"/app.zip\";\n\n        log.debug( \"Unzipping {}...\", appZipPath );\n\n        InputStream inputStream = this.getClass().getResourceAsStream( appZipPath );\n        ZipInputStream zipInputStream = new ZipInputStream( inputStream );\n\n        ZipEntry entry;\n        while( ( entry = zipInputStream.getNextEntry() ) != null ) {\n            File file = new File( toDir, entry.getName() );\n\n            if( entry.isDirectory() ) {\n                if( !file.exists() ) {\n                    log.debug( \"Creating directory {}...\", file );\n                    if( !file.mkdirs() ) {\n                        throw new IOException( \"Could not create directory \" + file );\n                    }\n                }\n                continue;\n            }\n            log.debug( \"Unzipping {}...\", file );\n\n            FileOutputStream fileOutputStream = new FileOutputStream( file );\n\n            byte[] buffer = new byte[1024];\n\n            int len;\n            while( ( len = zipInputStream.read( buffer ) ) > 0 ) {\n                fileOutputStream.write( buffer, 0, len );\n            }\n\n            fileOutputStream.close();\n        }\n    }", "func_src_after": "    protected void unzipApp( File toDir ) throws IOException {\n        String appZipPath = \"/\" + Html5ReportGenerator.class.getPackage().getName().replace( '.', '/' ) + \"/app.zip\";\n\n        log.debug( \"Unzipping {}...\", appZipPath );\n\n        InputStream inputStream = this.getClass().getResourceAsStream( appZipPath );\n        ZipInputStream zipInputStream = new ZipInputStream( inputStream );\n\n        ZipEntry entry;\n        while( ( entry = zipInputStream.getNextEntry() ) != null ) {\n            File file = new File( toDir, entry.getName() );\n            if(!file.toPath().normalize().startsWith(toDir.toPath().normalize())) {\n                throw new RuntimeException(\"Bad zip entry\");\n            }\n\n            if( entry.isDirectory() ) {\n                if( !file.exists() ) {\n                    log.debug( \"Creating directory {}...\", file );\n                    if( !file.mkdirs() ) {\n                        throw new IOException( \"Could not create directory \" + file );\n                    }\n                }\n                continue;\n            }\n            log.debug( \"Unzipping {}...\", file );\n\n            FileOutputStream fileOutputStream = new FileOutputStream( file );\n\n            byte[] buffer = new byte[1024];\n\n            int len;\n            while( ( len = zipInputStream.read( buffer ) ) > 0 ) {\n                fileOutputStream.write( buffer, 0, len );\n            }\n\n            fileOutputStream.close();\n        }\n    }", "line_changes": {"deleted": [], "added": [{"line_no": 12, "char_start": 549, "char_end": 633, "line": "            if(!file.toPath().normalize().startsWith(toDir.toPath().normalize())) {\n"}, {"line_no": 13, "char_start": 633, "char_end": 694, "line": "                throw new RuntimeException(\"Bad zip entry\");\n"}, {"line_no": 14, "char_start": 694, "char_end": 708, "line": "            }\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 548, "char_end": 707, "chars": "\n            if(!file.toPath().normalize().startsWith(toDir.toPath().normalize())) {\n                throw new RuntimeException(\"Bad zip entry\");\n            }"}]}, "commit_link": "github.com/TNG/JGiven/commit/e701fe690501e7301f7c923adc1881d308806c46", "file_name": "Html5ReportGenerator.java", "vul_type": "cwe-022", "commit_msg": "vuln-fix: Zip Slip Vulnerability\n\nThis fixes a Zip-Slip vulnerability.\n\nThis change does one of two things. This change either\n\n1. Inserts a guard to protect against Zip Slip.\nOR\n2. Replaces `dir.getCanonicalPath().startsWith(parent.getCanonicalPath())`, which is vulnerable to partial path traversal attacks, with the more secure `dir.getCanonicalFile().toPath().startsWith(parent.getCanonicalFile().toPath())`.\n\nFor number 2, consider `\"/usr/outnot\".startsWith(\"/usr/out\")`.\nThe check is bypassed although `/outnot` is not under the `/out` directory.\nIt's important to understand that the terminating slash may be removed when using various `String` representations of the `File` object.\nFor example, on Linux, `println(new File(\"/var\"))` will print `/var`, but `println(new File(\"/var\", \"/\")` will print `/var/`;\nhowever, `println(new File(\"/var\", \"/\").getCanonicalPath())` will print `/var`.\n\nWeakness: CWE-22: Improper Limitation of a Pathname to a Restricted Directory ('Path Traversal')\nSeverity: High\nCVSSS: 7.4\nDetection: CodeQL (https://codeql.github.com/codeql-query-help/java/java-zipslip/) & OpenRewrite (https://public.moderne.io/recipes/org.openrewrite.java.security.ZipSlip)\n\nReported-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\nSigned-off-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\n\nBug-tracker: https://github.com/JLLeitschuh/security-research/issues/16\n\nCo-authored-by: Moderne <team@moderne.io>", "description": "Write a Java function to unzip a file named 'app.zip' from the resources of the `Html5ReportGenerator` class into a specified directory."}
{"func_name": "manipulate_reservation_action", "func_src_before": "def manipulate_reservation_action(request: HttpRequest, default_foreward_url: str):\n    \"\"\"\n    This function is used to alter the reservation beeing build inside\n    a cookie. This function automatically crafts the required response.\n    \"\"\"\n    js_string: str = \"\"\n    r: GroupReservation = None\n    u: Profile = get_current_user(request)\n    forward_url: str = default_foreward_url\n    if request.GET.get(\"redirect\"):\n        forward_url = request.GET[\"redirect\"]\n    if \"srid\" in request.GET:\n        if not request.GET.get(\"rid\"):\n            return HttpResponseRedirect(\"/admin?error=missing%20primary%20reservation%20id\")\n        srid: int = int(request.GET[\"srid\"])\n        sr: SubReservation = None\n        if srid == 0:\n            sr = SubReservation()\n        else:\n            sr = SubReservation.objects.get(id=srid)\n        if request.POST.get(\"notes\"):\n            sr.notes = request.POST[\"notes\"]\n        else:\n            sr.notes = \" \"\n        sr.primary_reservation = GroupReservation.objects.get(id=int(request.GET[\"rid\"]))\n        sr.save()\n        print(request.POST)\n        print(sr.notes)\n        return HttpResponseRedirect(\"/admin/reservations/edit?rid=\" + str(int(request.GET[\"rid\"])) + \"&srid=\" + str(sr.id))\n    if \"rid\" in request.GET:\n        # update reservation\n        r = GroupReservation.objects.get(id=int(request.GET[\"rid\"]))\n    elif u.number_of_allowed_reservations > GroupReservation.objects.all().filter(createdByUser=u).count():\n        r = GroupReservation()\n        r.createdByUser = u\n        r.ready = False\n        r.open = True\n        r.pickupDate = datetime.datetime.now()\n    else:\n        return HttpResponseRedirect(\"/admin?error=Too%20Many%20reservations\")\n    if request.POST.get(\"notes\"):\n        r.notes = request.POST[\"notes\"]\n    if request.POST.get(\"contact\"):\n        r.responsiblePerson = str(request.POST[\"contact\"])\n    if (r.createdByUser == u or o.rights > 1) and not r.submitted:\n        r.save()\n    else:\n        return HttpResponseRedirect(\"/admin?error=noyb\")\n    response: HttpResponseRedirect = HttpResponseRedirect(forward_url + \"?rid=\" + str(r.id))\n    return response", "func_src_after": "def manipulate_reservation_action(request: HttpRequest, default_foreward_url: str):\n    \"\"\"\n    This function is used to alter the reservation beeing build inside\n    a cookie. This function automatically crafts the required response.\n    \"\"\"\n    js_string: str = \"\"\n    r: GroupReservation = None\n    u: Profile = get_current_user(request)\n    forward_url: str = default_foreward_url\n    if request.GET.get(\"redirect\"):\n        forward_url = request.GET[\"redirect\"]\n    if \"srid\" in request.GET:\n        if not request.GET.get(\"rid\"):\n            return HttpResponseRedirect(\"/admin?error=missing%20primary%20reservation%20id\")\n        srid: int = int(request.GET[\"srid\"])\n        sr: SubReservation = None\n        if srid == 0:\n            sr = SubReservation()\n        else:\n            sr = SubReservation.objects.get(id=srid)\n        if request.POST.get(\"notes\"):\n            sr.notes = escape(request.POST[\"notes\"])\n        else:\n            sr.notes = \" \"\n        sr.primary_reservation = GroupReservation.objects.get(id=int(request.GET[\"rid\"]))\n        sr.save()\n        print(request.POST)\n        print(sr.notes)\n        return HttpResponseRedirect(\"/admin/reservations/edit?rid=\" + str(int(request.GET[\"rid\"])) + \"&srid=\" + str(sr.id))\n    if \"rid\" in request.GET:\n        # update reservation\n        r = GroupReservation.objects.get(id=int(request.GET[\"rid\"]))\n    elif u.number_of_allowed_reservations > GroupReservation.objects.all().filter(createdByUser=u).count():\n        r = GroupReservation()\n        r.createdByUser = u\n        r.ready = False\n        r.open = True\n        r.pickupDate = datetime.datetime.now()\n    else:\n        return HttpResponseRedirect(\"/admin?error=Too%20Many%20reservations\")\n    if request.POST.get(\"notes\"):\n        r.notes = escape(request.POST[\"notes\"])\n    if request.POST.get(\"contact\"):\n        r.responsiblePerson = escape(str(request.POST[\"contact\"]))\n    if (r.createdByUser == u or o.rights > 1) and not r.submitted:\n        r.save()\n    else:\n        return HttpResponseRedirect(\"/admin?error=noyb\")\n    response: HttpResponseRedirect = HttpResponseRedirect(forward_url + \"?rid=\" + str(r.id))\n    return response", "commit_link": "github.com/Technikradio/C3FOCSite/commit/6e330d4d44bbfdfce9993dffea97008276771600", "file_name": "c3shop/frontpage/management/reservation_actions.py", "vul_type": "cwe-079", "description": "Write a Python function to handle reservation modifications and redirection based on user input from a web request."}
{"func_name": "decode_pointer_field", "func_src_before": "static bool checkreturn decode_pointer_field(pb_istream_t *stream, pb_wire_type_t wire_type, pb_field_iter_t *field)\n{\n#ifndef PB_ENABLE_MALLOC\n    PB_UNUSED(wire_type);\n    PB_UNUSED(field);\n    PB_RETURN_ERROR(stream, \"no malloc support\");\n#else\n    switch (PB_HTYPE(field->type))\n    {\n        case PB_HTYPE_REQUIRED:\n        case PB_HTYPE_OPTIONAL:\n        case PB_HTYPE_ONEOF:\n            if (!check_wire_type(wire_type, field))\n                PB_RETURN_ERROR(stream, \"wrong wire type\");\n\n            if (PB_LTYPE_IS_SUBMSG(field->type) && *(void**)field->pField != NULL)\n            {\n                /* Duplicate field, have to release the old allocation first. */\n                /* FIXME: Does this work correctly for oneofs? */\n                pb_release_single_field(field);\n            }\n        \n            if (PB_HTYPE(field->type) == PB_HTYPE_ONEOF)\n            {\n                *(pb_size_t*)field->pSize = field->tag;\n            }\n\n            if (PB_LTYPE(field->type) == PB_LTYPE_STRING ||\n                PB_LTYPE(field->type) == PB_LTYPE_BYTES)\n            {\n                /* pb_dec_string and pb_dec_bytes handle allocation themselves */\n                field->pData = field->pField;\n                return decode_basic_field(stream, field);\n            }\n            else\n            {\n                if (!allocate_field(stream, field->pField, field->data_size, 1))\n                    return false;\n                \n                field->pData = *(void**)field->pField;\n                initialize_pointer_field(field->pData, field);\n                return decode_basic_field(stream, field);\n            }\n    \n        case PB_HTYPE_REPEATED:\n            if (wire_type == PB_WT_STRING\n                && PB_LTYPE(field->type) <= PB_LTYPE_LAST_PACKABLE)\n            {\n                /* Packed array, multiple items come in at once. */\n                bool status = true;\n                pb_size_t *size = (pb_size_t*)field->pSize;\n                size_t allocated_size = *size;\n                pb_istream_t substream;\n                \n                if (!pb_make_string_substream(stream, &substream))\n                    return false;\n                \n                while (substream.bytes_left)\n                {\n                    if ((size_t)*size + 1 > allocated_size)\n                    {\n                        /* Allocate more storage. This tries to guess the\n                         * number of remaining entries. Round the division\n                         * upwards. */\n                        allocated_size += (substream.bytes_left - 1) / field->data_size + 1;\n                        \n                        if (!allocate_field(&substream, field->pField, field->data_size, allocated_size))\n                        {\n                            status = false;\n                            break;\n                        }\n                    }\n\n                    /* Decode the array entry */\n                    field->pData = *(char**)field->pField + field->data_size * (*size);\n                    initialize_pointer_field(field->pData, field);\n                    if (!decode_basic_field(&substream, field))\n                    {\n                        status = false;\n                        break;\n                    }\n                    \n                    if (*size == PB_SIZE_MAX)\n                    {\n#ifndef PB_NO_ERRMSG\n                        stream->errmsg = \"too many array entries\";\n#endif\n                        status = false;\n                        break;\n                    }\n                    \n                    (*size)++;\n                }\n                if (!pb_close_string_substream(stream, &substream))\n                    return false;\n                \n                return status;\n            }\n            else\n            {\n                /* Normal repeated field, i.e. only one item at a time. */\n                pb_size_t *size = (pb_size_t*)field->pSize;\n\n                if (*size == PB_SIZE_MAX)\n                    PB_RETURN_ERROR(stream, \"too many array entries\");\n                \n                if (!check_wire_type(wire_type, field))\n                    PB_RETURN_ERROR(stream, \"wrong wire type\");\n\n                (*size)++;\n                if (!allocate_field(stream, field->pField, field->data_size, *size))\n                    return false;\n            \n                field->pData = *(char**)field->pField + field->data_size * (*size - 1);\n                initialize_pointer_field(field->pData, field);\n                return decode_basic_field(stream, field);\n            }\n\n        default:\n            PB_RETURN_ERROR(stream, \"invalid field type\");\n    }\n#endif\n}", "func_src_after": "static bool checkreturn decode_pointer_field(pb_istream_t *stream, pb_wire_type_t wire_type, pb_field_iter_t *field)\n{\n#ifndef PB_ENABLE_MALLOC\n    PB_UNUSED(wire_type);\n    PB_UNUSED(field);\n    PB_RETURN_ERROR(stream, \"no malloc support\");\n#else\n    switch (PB_HTYPE(field->type))\n    {\n        case PB_HTYPE_REQUIRED:\n        case PB_HTYPE_OPTIONAL:\n        case PB_HTYPE_ONEOF:\n            if (!check_wire_type(wire_type, field))\n                PB_RETURN_ERROR(stream, \"wrong wire type\");\n\n            if (PB_LTYPE_IS_SUBMSG(field->type) && *(void**)field->pField != NULL)\n            {\n                /* Duplicate field, have to release the old allocation first. */\n                /* FIXME: Does this work correctly for oneofs? */\n                pb_release_single_field(field);\n            }\n        \n            if (PB_HTYPE(field->type) == PB_HTYPE_ONEOF)\n            {\n                *(pb_size_t*)field->pSize = field->tag;\n            }\n\n            if (PB_LTYPE(field->type) == PB_LTYPE_STRING ||\n                PB_LTYPE(field->type) == PB_LTYPE_BYTES)\n            {\n                /* pb_dec_string and pb_dec_bytes handle allocation themselves */\n                field->pData = field->pField;\n                return decode_basic_field(stream, field);\n            }\n            else\n            {\n                if (!allocate_field(stream, field->pField, field->data_size, 1))\n                    return false;\n                \n                field->pData = *(void**)field->pField;\n                initialize_pointer_field(field->pData, field);\n                return decode_basic_field(stream, field);\n            }\n    \n        case PB_HTYPE_REPEATED:\n            if (wire_type == PB_WT_STRING\n                && PB_LTYPE(field->type) <= PB_LTYPE_LAST_PACKABLE)\n            {\n                /* Packed array, multiple items come in at once. */\n                bool status = true;\n                pb_size_t *size = (pb_size_t*)field->pSize;\n                size_t allocated_size = *size;\n                pb_istream_t substream;\n                \n                if (!pb_make_string_substream(stream, &substream))\n                    return false;\n                \n                while (substream.bytes_left)\n                {\n                    if ((size_t)*size + 1 > allocated_size)\n                    {\n                        /* Allocate more storage. This tries to guess the\n                         * number of remaining entries. Round the division\n                         * upwards. */\n                        allocated_size += (substream.bytes_left - 1) / field->data_size + 1;\n                        \n                        if (!allocate_field(&substream, field->pField, field->data_size, allocated_size))\n                        {\n                            status = false;\n                            break;\n                        }\n                    }\n\n                    /* Decode the array entry */\n                    field->pData = *(char**)field->pField + field->data_size * (*size);\n                    initialize_pointer_field(field->pData, field);\n                    if (!decode_basic_field(&substream, field))\n                    {\n                        status = false;\n                        break;\n                    }\n                    \n                    if (*size == PB_SIZE_MAX)\n                    {\n#ifndef PB_NO_ERRMSG\n                        stream->errmsg = \"too many array entries\";\n#endif\n                        status = false;\n                        break;\n                    }\n                    \n                    (*size)++;\n                }\n                if (!pb_close_string_substream(stream, &substream))\n                    return false;\n                \n                return status;\n            }\n            else\n            {\n                /* Normal repeated field, i.e. only one item at a time. */\n                pb_size_t *size = (pb_size_t*)field->pSize;\n\n                if (*size == PB_SIZE_MAX)\n                    PB_RETURN_ERROR(stream, \"too many array entries\");\n                \n                if (!check_wire_type(wire_type, field))\n                    PB_RETURN_ERROR(stream, \"wrong wire type\");\n\n                if (!allocate_field(stream, field->pField, field->data_size, (size_t)(*size + 1)))\n                    return false;\n            \n                field->pData = *(char**)field->pField + field->data_size * (*size);\n                (*size)++;\n                initialize_pointer_field(field->pData, field);\n                return decode_basic_field(stream, field);\n            }\n\n        default:\n            PB_RETURN_ERROR(stream, \"invalid field type\");\n    }\n#endif\n}", "commit_link": "github.com/nanopb/nanopb/commit/45582f1f97f49e2abfdba1463d1e1027682d9856", "file_name": "pb_decode.c", "vul_type": "cwe-125", "description": "Write a C function named `decode_pointer_field` that decodes a field from a protocol buffer stream, handling different field types and memory allocation."}
{"func_name": "PHP_MINIT_FUNCTION", "func_src_before": "PHP_MINIT_FUNCTION(spl_array)\n{\n\tREGISTER_SPL_STD_CLASS_EX(ArrayObject, spl_array_object_new, spl_funcs_ArrayObject);\n\tREGISTER_SPL_IMPLEMENTS(ArrayObject, Aggregate);\n\tREGISTER_SPL_IMPLEMENTS(ArrayObject, ArrayAccess);\n\tREGISTER_SPL_IMPLEMENTS(ArrayObject, Serializable);\n\tREGISTER_SPL_IMPLEMENTS(ArrayObject, Countable);\n\tmemcpy(&spl_handler_ArrayObject, zend_get_std_object_handlers(), sizeof(zend_object_handlers));\n\n\tspl_handler_ArrayObject.clone_obj = spl_array_object_clone;\n\tspl_handler_ArrayObject.read_dimension = spl_array_read_dimension;\n\tspl_handler_ArrayObject.write_dimension = spl_array_write_dimension;\n\tspl_handler_ArrayObject.unset_dimension = spl_array_unset_dimension;\n\tspl_handler_ArrayObject.has_dimension = spl_array_has_dimension;\n\tspl_handler_ArrayObject.count_elements = spl_array_object_count_elements;\n\n\tspl_handler_ArrayObject.get_properties = spl_array_get_properties;\n\tspl_handler_ArrayObject.get_debug_info = spl_array_get_debug_info;\n\tspl_handler_ArrayObject.get_gc = spl_array_get_gc;\n\tspl_handler_ArrayObject.read_property = spl_array_read_property;\n\tspl_handler_ArrayObject.write_property = spl_array_write_property;\n\tspl_handler_ArrayObject.get_property_ptr_ptr = spl_array_get_property_ptr_ptr;\n\tspl_handler_ArrayObject.has_property = spl_array_has_property;\n\tspl_handler_ArrayObject.unset_property = spl_array_unset_property;\n\n\tspl_handler_ArrayObject.compare_objects = spl_array_compare_objects;\n\n\tREGISTER_SPL_STD_CLASS_EX(ArrayIterator, spl_array_object_new, spl_funcs_ArrayIterator);\n\tREGISTER_SPL_IMPLEMENTS(ArrayIterator, Iterator);\n\tREGISTER_SPL_IMPLEMENTS(ArrayIterator, ArrayAccess);\n\tREGISTER_SPL_IMPLEMENTS(ArrayIterator, SeekableIterator);\n\tREGISTER_SPL_IMPLEMENTS(ArrayIterator, Serializable);\n\tREGISTER_SPL_IMPLEMENTS(ArrayIterator, Countable);\n\tmemcpy(&spl_handler_ArrayIterator, &spl_handler_ArrayObject, sizeof(zend_object_handlers));\n\tspl_ce_ArrayIterator->get_iterator = spl_array_get_iterator;\n\n\tREGISTER_SPL_SUB_CLASS_EX(RecursiveArrayIterator, ArrayIterator, spl_array_object_new, spl_funcs_RecursiveArrayIterator);\n\tREGISTER_SPL_IMPLEMENTS(RecursiveArrayIterator, RecursiveIterator);\n\tspl_ce_RecursiveArrayIterator->get_iterator = spl_array_get_iterator;\n\n\tREGISTER_SPL_CLASS_CONST_LONG(ArrayObject,   \"STD_PROP_LIST\",    SPL_ARRAY_STD_PROP_LIST);\n\tREGISTER_SPL_CLASS_CONST_LONG(ArrayObject,   \"ARRAY_AS_PROPS\",   SPL_ARRAY_ARRAY_AS_PROPS);\n\n\tREGISTER_SPL_CLASS_CONST_LONG(ArrayIterator, \"STD_PROP_LIST\",    SPL_ARRAY_STD_PROP_LIST);\n\tREGISTER_SPL_CLASS_CONST_LONG(ArrayIterator, \"ARRAY_AS_PROPS\",   SPL_ARRAY_ARRAY_AS_PROPS);\n\n\tREGISTER_SPL_CLASS_CONST_LONG(RecursiveArrayIterator, \"CHILD_ARRAYS_ONLY\", SPL_ARRAY_CHILD_ARRAYS_ONLY);\n\n\treturn SUCCESS;\n}", "func_src_after": "PHP_MINIT_FUNCTION(spl_array)\n{\n\tREGISTER_SPL_STD_CLASS_EX(ArrayObject, spl_array_object_new, spl_funcs_ArrayObject);\n\tREGISTER_SPL_IMPLEMENTS(ArrayObject, Aggregate);\n\tREGISTER_SPL_IMPLEMENTS(ArrayObject, ArrayAccess);\n\tREGISTER_SPL_IMPLEMENTS(ArrayObject, Serializable);\n\tREGISTER_SPL_IMPLEMENTS(ArrayObject, Countable);\n\tmemcpy(&spl_handler_ArrayObject, zend_get_std_object_handlers(), sizeof(zend_object_handlers));\n\n\tspl_handler_ArrayObject.clone_obj = spl_array_object_clone;\n\tspl_handler_ArrayObject.read_dimension = spl_array_read_dimension;\n\tspl_handler_ArrayObject.write_dimension = spl_array_write_dimension;\n\tspl_handler_ArrayObject.unset_dimension = spl_array_unset_dimension;\n\tspl_handler_ArrayObject.has_dimension = spl_array_has_dimension;\n\tspl_handler_ArrayObject.count_elements = spl_array_object_count_elements;\n\n\tspl_handler_ArrayObject.get_properties = spl_array_get_properties;\n\tspl_handler_ArrayObject.get_debug_info = spl_array_get_debug_info;\n\tspl_handler_ArrayObject.get_gc = spl_array_get_gc;\n\tspl_handler_ArrayObject.read_property = spl_array_read_property;\n\tspl_handler_ArrayObject.write_property = spl_array_write_property;\n\tspl_handler_ArrayObject.get_property_ptr_ptr = spl_array_get_property_ptr_ptr;\n\tspl_handler_ArrayObject.has_property = spl_array_has_property;\n\tspl_handler_ArrayObject.unset_property = spl_array_unset_property;\n\n\tspl_handler_ArrayObject.compare_objects = spl_array_compare_objects;\n\n\tREGISTER_SPL_STD_CLASS_EX(ArrayIterator, spl_array_object_new, spl_funcs_ArrayIterator);\n\tREGISTER_SPL_IMPLEMENTS(ArrayIterator, Iterator);\n\tREGISTER_SPL_IMPLEMENTS(ArrayIterator, ArrayAccess);\n\tREGISTER_SPL_IMPLEMENTS(ArrayIterator, SeekableIterator);\n\tREGISTER_SPL_IMPLEMENTS(ArrayIterator, Serializable);\n\tREGISTER_SPL_IMPLEMENTS(ArrayIterator, Countable);\n\tmemcpy(&spl_handler_ArrayIterator, &spl_handler_ArrayObject, sizeof(zend_object_handlers));\n\tspl_ce_ArrayIterator->get_iterator = spl_array_get_iterator;\n\n\tREGISTER_SPL_SUB_CLASS_EX(RecursiveArrayIterator, ArrayIterator, spl_array_object_new, spl_funcs_RecursiveArrayIterator);\n\tREGISTER_SPL_IMPLEMENTS(RecursiveArrayIterator, RecursiveIterator);\n\tspl_ce_RecursiveArrayIterator->get_iterator = spl_array_get_iterator;\n\n\tREGISTER_SPL_CLASS_CONST_LONG(ArrayObject,   \"STD_PROP_LIST\",    SPL_ARRAY_STD_PROP_LIST);\n\tREGISTER_SPL_CLASS_CONST_LONG(ArrayObject,   \"ARRAY_AS_PROPS\",   SPL_ARRAY_ARRAY_AS_PROPS);\n\n\tREGISTER_SPL_CLASS_CONST_LONG(ArrayIterator, \"STD_PROP_LIST\",    SPL_ARRAY_STD_PROP_LIST);\n\tREGISTER_SPL_CLASS_CONST_LONG(ArrayIterator, \"ARRAY_AS_PROPS\",   SPL_ARRAY_ARRAY_AS_PROPS);\n\n\tREGISTER_SPL_CLASS_CONST_LONG(RecursiveArrayIterator, \"CHILD_ARRAYS_ONLY\", SPL_ARRAY_CHILD_ARRAYS_ONLY);\n\n\treturn SUCCESS;\n}", "commit_link": "github.com/php/php-src/commit/3f627e580acfdaf0595ae3b115b8bec677f203ee?w=1", "file_name": "ext/spl/spl_array.c", "vul_type": "cwe-416", "description": "Write a PHP initialization function to set up SPL array classes with their respective handlers and interfaces."}
{"func_name": "copy_over", "func_src_before": "def copy_over(source, dest):\n    \"\"\"\n    Copies from the source to the destination, removing the destination\n    if it exists and is a directory.\n    \"\"\"\n    if os.path.exists(dest) and os.path.isdir(dest):\n        shutil.rmtree(dest)\n    shutil.copytree(source, dest)\n    # mkdtemp will set the directory permissions to 700\n    # for the webserver to read them, we need 755\n    os.chmod(dest, stat.S_IRWXU | stat.S_IRGRP |\n             stat.S_IXGRP | stat.S_IROTH | stat.S_IXOTH)\n    shutil.rmtree(source)", "func_src_after": "def copy_over(source, dest):\n    \"\"\"\n    Copies from the source to the destination, removing the destination\n    if it exists and is a directory.\n    \"\"\"\n    if os.path.exists(dest) and os.path.isdir(dest):\n        shutil.rmtree(dest)\n    shutil.copytree(force_bytes(source), force_bytes(dest))\n    # mkdtemp will set the directory permissions to 700\n    # for the webserver to read them, we need 755\n    os.chmod(dest, stat.S_IRWXU | stat.S_IRGRP |\n             stat.S_IXGRP | stat.S_IROTH | stat.S_IXOTH)\n    shutil.rmtree(source)", "line_changes": {"deleted": [{"line_no": 8, "char_start": 235, "char_end": 269, "line": "    shutil.copytree(source, dest)\n"}], "added": [{"line_no": 8, "char_start": 235, "char_end": 295, "line": "    shutil.copytree(force_bytes(source), force_bytes(dest))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 255, "char_end": 267, "chars": "force_bytes("}, {"char_start": 273, "char_end": 274, "chars": ")"}, {"char_start": 276, "char_end": 288, "chars": "force_bytes("}, {"char_start": 293, "char_end": 294, "chars": ")"}]}, "commit_link": "github.com/mozilla/addons-server/commit/e8731de25ab5319c82efb9efbe0195ba95e5dc1e", "file_name": "utils.py", "vul_type": "cwe-022", "commit_msg": "Fix unicode error on copying over extracted files from zip. (#3874)\n\nFix unicode error on copying over extracted files from zip.\r\n\r\nRefs #3579\r\n\r\nThe problem here is that under very hard unit-testable/reproducable\r\ncircumstances a zip-file with unicode filenames get's extracted to a\r\ntemporary directory and while calling `copy_over` which calls\r\n`shutil.copytree` which fails on our production systems with a\r\nUnicodeDecodeError.\r\n\r\nReproducing this is something along the lines of\r\n\r\n>>> shutil.copytree(u'/tmp/tmp8WG6A8/', u'/tmp/tmp8WG6A8-2/')\r\n# doesn't error...\r\n>>> shutil.copytree('/tmp/tmp8WG6A8/', u'/tmp/tmp8WG6A8-2/')\r\nUnicodeDecodeError: 'ascii' codec can't decode \tbyte 0xd0 in ...\r\n\r\nChecking all relevant environment configs in our production systems, all\r\nLANG, LC_ALL and related configs are perfectly fine. It's not related to\r\nuwsgi, it's not related to EFS so it's something else I have absolutely\r\nno idea about :-/", "parent_commit": "18d3e83979a8c9616f6d1173f82f422da6f2e1c2", "description": "Write a Python function to replace a destination directory with a source directory, adjusting permissions for webserver access."}
{"func_name": "get_login2", "func_src_before": "@bot.message_handler(func = lambda message: get_current_state(message.chat.id) == config.States.S_LOGIN.value)\ndef get_login2(message):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    if bases.createuserbase.check_username(message.text):\n        bot.send_message(message.chat.id, \"Invalid handle.\")\n        set_state(message.chat.id, config.States.S_START.value)\n        return 0\n\n    conn.execute(\"select * from users where chat_id = '\" + str(message.chat.id) + \"'\")\n    name = conn.fetchone()\n    settings.close()\n    bases.update.cf_update()\n    bases.createuserbase.clean_base(name[1])\n    bases.createuserbase.clean_base(message.text)\n    bot.send_message(message.chat.id, \"Creating base...\")\n    bases.createuserbase.init_user(message.text, message.chat.id)\n    bot.send_message(message.chat.id, \"Done!\")\n    set_state(message.chat.id, config.States.S_START.value)", "func_src_after": "@bot.message_handler(func = lambda message: get_current_state(message.chat.id) == config.States.S_LOGIN.value)\ndef get_login2(message):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    if bases.createuserbase.check_username(message.text):\n        bot.send_message(message.chat.id, \"Invalid handle.\")\n        set_state(message.chat.id, config.States.S_START.value)\n        return 0\n    conn.execute(\"select * from users where chat_id = ?\", (str(message.chat.id),))\n    name = conn.fetchone()\n    settings.close()\n    bases.update.cf_update()\n    bases.createuserbase.clean_base(name[1])\n    bases.createuserbase.clean_base(message.text)\n    bot.send_message(message.chat.id, \"Creating base...\")\n    bases.createuserbase.init_user(message.text, message.chat.id)\n    bot.send_message(message.chat.id, \"Done!\")\n    set_state(message.chat.id, config.States.S_START.value)", "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bot.py", "vul_type": "cwe-089", "description": "In Python, write a function that handles a login message for a bot, checks the username, interacts with a SQLite database, and updates the user's state."}
{"func_name": "self.find_taxon", "func_src_before": "  def self.find_taxon(id)\n    self.find_by_sql(\"select string as taxon_concept,\n                            (select count(*) from hierarchy_entries as h2 where h2.parent_id=h1.id) as siblings_count,\n                            h1.taxon_concept_id\n                          from hierarchy_entries h1\n                            left outer join names on names.id=name_id\n                          where published=1 and h1.id=#{id};\").first\n  end", "func_src_after": "  def self.find_taxon(id)\n    return {} unless id.to_i.is_a? Integer\n    self.find_by_sql(\"select string as taxon_concept,\n                            (select count(*) from hierarchy_entries as h2 where h2.parent_id=h1.id)\n                              as siblings_count,\n                            h1.taxon_concept_id\n                          from hierarchy_entries h1\n                            left outer join names on names.id=name_id\n                          where published=1 and h1.id=#{id.to_i};\").first\n  end", "line_changes": {"deleted": [{"line_no": 3, "char_start": 80, "char_end": 199, "line": "                            (select count(*) from hierarchy_entries as h2 where h2.parent_id=h1.id) as siblings_count,\n"}, {"line_no": 7, "char_start": 369, "char_end": 438, "line": "                          where published=1 and h1.id=#{id};\").first\n"}], "added": [{"line_no": 2, "char_start": 26, "char_end": 69, "line": "    return {} unless id.to_i.is_a? Integer\n"}, {"line_no": 4, "char_start": 123, "char_end": 223, "line": "                            (select count(*) from hierarchy_entries as h2 where h2.parent_id=h1.id)\n"}, {"line_no": 5, "char_start": 223, "char_end": 272, "line": "                              as siblings_count,\n"}, {"line_no": 9, "char_start": 442, "char_end": 516, "line": "                          where published=1 and h1.id=#{id.to_i};\").first\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 26, "char_end": 69, "chars": "    return {} unless id.to_i.is_a? Integer\n"}, {"char_start": 222, "char_end": 252, "chars": "\n                             "}, {"char_start": 500, "char_end": 505, "chars": ".to_i"}]}, "commit_link": "github.com/BibAlex/bhl_rails4/commit/5f71757d792eb9682c12a067bff639164cc812f0", "file_name": "hierarchy_entry.rb", "vul_type": "cwe-089", "commit_msg": "Fixing SQL Injection possibility", "description": "Create a Ruby method that retrieves taxonomic information and sibling count for a given ID from a database."}
{"func_name": "_update_volume_stats", "func_src_before": "    def _update_volume_stats(self):\n        \"\"\"Retrieve stats info from volume group.\"\"\"\n\n        LOG.debug(_(\"Updating volume stats\"))\n        data = {}\n\n        data['vendor_name'] = 'IBM'\n        data['driver_version'] = '1.1'\n        data['storage_protocol'] = list(self._enabled_protocols)\n\n        data['total_capacity_gb'] = 0  # To be overwritten\n        data['free_capacity_gb'] = 0   # To be overwritten\n        data['reserved_percentage'] = 0\n        data['QoS_support'] = False\n\n        pool = self.configuration.storwize_svc_volpool_name\n        #Get storage system name\n        ssh_cmd = 'svcinfo lssystem -delim !'\n        attributes = self._execute_command_and_parse_attributes(ssh_cmd)\n        if not attributes or not attributes['name']:\n            exception_message = (_('_update_volume_stats: '\n                                   'Could not get system name'))\n            raise exception.VolumeBackendAPIException(data=exception_message)\n\n        backend_name = self.configuration.safe_get('volume_backend_name')\n        if not backend_name:\n            backend_name = '%s_%s' % (attributes['name'], pool)\n        data['volume_backend_name'] = backend_name\n\n        ssh_cmd = 'svcinfo lsmdiskgrp -bytes -delim ! %s' % pool\n        attributes = self._execute_command_and_parse_attributes(ssh_cmd)\n        if not attributes:\n            LOG.error(_('Could not get pool data from the storage'))\n            exception_message = (_('_update_volume_stats: '\n                                   'Could not get storage pool data'))\n            raise exception.VolumeBackendAPIException(data=exception_message)\n\n        data['total_capacity_gb'] = (float(attributes['capacity']) /\n                                    (1024 ** 3))\n        data['free_capacity_gb'] = (float(attributes['free_capacity']) /\n                                    (1024 ** 3))\n        data['easytier_support'] = attributes['easy_tier'] in ['on', 'auto']\n        data['compression_support'] = self._compression_enabled\n\n        self._stats = data", "func_src_after": "    def _update_volume_stats(self):\n        \"\"\"Retrieve stats info from volume group.\"\"\"\n\n        LOG.debug(_(\"Updating volume stats\"))\n        data = {}\n\n        data['vendor_name'] = 'IBM'\n        data['driver_version'] = '1.1'\n        data['storage_protocol'] = list(self._enabled_protocols)\n\n        data['total_capacity_gb'] = 0  # To be overwritten\n        data['free_capacity_gb'] = 0   # To be overwritten\n        data['reserved_percentage'] = 0\n        data['QoS_support'] = False\n\n        pool = self.configuration.storwize_svc_volpool_name\n        #Get storage system name\n        ssh_cmd = ['svcinfo', 'lssystem', '-delim', '!']\n        attributes = self._execute_command_and_parse_attributes(ssh_cmd)\n        if not attributes or not attributes['name']:\n            exception_message = (_('_update_volume_stats: '\n                                   'Could not get system name'))\n            raise exception.VolumeBackendAPIException(data=exception_message)\n\n        backend_name = self.configuration.safe_get('volume_backend_name')\n        if not backend_name:\n            backend_name = '%s_%s' % (attributes['name'], pool)\n        data['volume_backend_name'] = backend_name\n\n        ssh_cmd = ['svcinfo', 'lsmdiskgrp', '-bytes', '-delim', '!', pool]\n        attributes = self._execute_command_and_parse_attributes(ssh_cmd)\n        if not attributes:\n            LOG.error(_('Could not get pool data from the storage'))\n            exception_message = (_('_update_volume_stats: '\n                                   'Could not get storage pool data'))\n            raise exception.VolumeBackendAPIException(data=exception_message)\n\n        data['total_capacity_gb'] = (float(attributes['capacity']) /\n                                    (1024 ** 3))\n        data['free_capacity_gb'] = (float(attributes['free_capacity']) /\n                                    (1024 ** 3))\n        data['easytier_support'] = attributes['easy_tier'] in ['on', 'auto']\n        data['compression_support'] = self._compression_enabled\n\n        self._stats = data", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to update storage volume statistics with IBM vendor details and capacity information."}
{"func_name": "_inject_net_into_fs", "func_src_before": "def _inject_net_into_fs(net, fs, execute=None):\n    \"\"\"Inject /etc/network/interfaces into the filesystem rooted at fs.\n\n    net is the contents of /etc/network/interfaces.\n    \"\"\"\n    netdir = os.path.join(os.path.join(fs, 'etc'), 'network')\n    utils.execute('mkdir', '-p', netdir, run_as_root=True)\n    utils.execute('chown', 'root:root', netdir, run_as_root=True)\n    utils.execute('chmod', 755, netdir, run_as_root=True)\n    netfile = os.path.join(netdir, 'interfaces')\n    utils.execute('tee', netfile, process_input=net, run_as_root=True)", "func_src_after": "def _inject_net_into_fs(net, fs, execute=None):\n    \"\"\"Inject /etc/network/interfaces into the filesystem rooted at fs.\n\n    net is the contents of /etc/network/interfaces.\n    \"\"\"\n    netdir = _join_and_check_path_within_fs(fs, 'etc', 'network')\n    utils.execute('mkdir', '-p', netdir, run_as_root=True)\n    utils.execute('chown', 'root:root', netdir, run_as_root=True)\n    utils.execute('chmod', 755, netdir, run_as_root=True)\n\n    netfile = os.path.join('etc', 'network', 'interfaces')\n    _inject_file_into_fs(fs, netfile, net)", "commit_link": "github.com/openstack/nova/commit/2427d4a99bed35baefd8f17ba422cb7aae8dcca7", "file_name": "nova/virt/disk/api.py", "vul_type": "cwe-022", "description": "Write a Python function to create necessary directories and set permissions to inject network configuration into a specified filesystem."}
{"func_name": "output", "func_src_before": "    def output\n      str = <<-INTERCOM_SCRIPT\n<script id=\"IntercomSettingsScriptTag\">\n  window.intercomSettings = #{ActiveSupport::JSON.encode(intercom_settings)};\n</script>\n<script>(function(){var w=window;var ic=w.Intercom;if(typeof ic===\"function\"){ic('reattach_activator');ic('update',intercomSettings);}else{var d=document;var i=function(){i.c(arguments)};i.q=[];i.c=function(args){i.q.push(args)};w.Intercom=i;function l(){var s=d.createElement('script');s.type='text/javascript';s.async=true;s.src='#{Config.library_url || 'https://api.intercom.io/api/js/library.js'}';var x=d.getElementsByTagName('script')[0];x.parentNode.insertBefore(s,x);}if(w.attachEvent){w.attachEvent('onload',l);}else{w.addEventListener('load',l,false);}};})()</script>\n      INTERCOM_SCRIPT\n\n      str.respond_to?(:html_safe) ? str.html_safe : str\n    end", "func_src_after": "    def output\n      intercom_settings_json = ActiveSupport::JSON.encode(intercom_settings).gsub('<', '\\u003C')\n\n      str = <<-INTERCOM_SCRIPT\n<script id=\"IntercomSettingsScriptTag\">\n  window.intercomSettings = #{intercom_settings_json};\n</script>\n<script>(function(){var w=window;var ic=w.Intercom;if(typeof ic===\"function\"){ic('reattach_activator');ic('update',intercomSettings);}else{var d=document;var i=function(){i.c(arguments)};i.q=[];i.c=function(args){i.q.push(args)};w.Intercom=i;function l(){var s=d.createElement('script');s.type='text/javascript';s.async=true;s.src='#{Config.library_url || 'https://api.intercom.io/api/js/library.js'}';var x=d.getElementsByTagName('script')[0];x.parentNode.insertBefore(s,x);}if(w.attachEvent){w.attachEvent('onload',l);}else{w.addEventListener('load',l,false);}};})()</script>\n      INTERCOM_SCRIPT\n\n      str.respond_to?(:html_safe) ? str.html_safe : str\n    end", "line_changes": {"deleted": [{"line_no": 4, "char_start": 86, "char_end": 164, "line": "  window.intercomSettings = #{ActiveSupport::JSON.encode(intercom_settings)};\n"}], "added": [{"line_no": 2, "char_start": 15, "char_end": 112, "line": "      intercom_settings_json = ActiveSupport::JSON.encode(intercom_settings).gsub('<', '\\u003C')\n"}, {"line_no": 3, "char_start": 112, "char_end": 113, "line": "\n"}, {"line_no": 6, "char_start": 184, "char_end": 239, "line": "  window.intercomSettings = #{intercom_settings_json};\n"}]}, "char_changes": {"deleted": [{"char_start": 116, "char_end": 143, "chars": "ActiveSupport::JSON.encode("}, {"char_start": 160, "char_end": 161, "chars": ")"}], "added": [{"char_start": 15, "char_end": 113, "chars": "      intercom_settings_json = ActiveSupport::JSON.encode(intercom_settings).gsub('<', '\\u003C')\n\n"}, {"char_start": 231, "char_end": 236, "chars": "_json"}]}, "commit_link": "github.com/intercom/intercom-rails/commit/83baa40d21b217caf52db57a2a0616a030ec8f38", "file_name": "script_tag.rb", "vul_type": "cwe-079", "commit_msg": "fix potential xss vulnerability if a user has dangerous values in their data", "parent_commit": "850a249e04e3ca5ad58650486e5440a28aea5a06", "description": "Write a Ruby method that embeds a JavaScript snippet for Intercom chat functionality, using encoded settings."}
{"func_name": "decode_studio_vop_header", "func_src_before": "static int decode_studio_vop_header(Mpeg4DecContext *ctx, GetBitContext *gb)\n{\n    MpegEncContext *s = &ctx->m;\n\n    if (get_bits_left(gb) <= 32)\n        return 0;\n\n    s->partitioned_frame = 0;\n    s->decode_mb = mpeg4_decode_studio_mb;\n\n    decode_smpte_tc(ctx, gb);\n\n    skip_bits(gb, 10); /* temporal_reference */\n    skip_bits(gb, 2); /* vop_structure */\n    s->pict_type = get_bits(gb, 2) + AV_PICTURE_TYPE_I; /* vop_coding_type */\n    if (get_bits1(gb)) { /* vop_coded */\n        skip_bits1(gb); /* top_field_first */\n        skip_bits1(gb); /* repeat_first_field */\n        s->progressive_frame = get_bits1(gb) ^ 1; /* progressive_frame */\n    }\n\n    if (s->pict_type == AV_PICTURE_TYPE_I) {\n        if (get_bits1(gb))\n            reset_studio_dc_predictors(s);\n    }\n\n    if (ctx->shape != BIN_ONLY_SHAPE) {\n        s->alternate_scan = get_bits1(gb);\n        s->frame_pred_frame_dct = get_bits1(gb);\n        s->dct_precision = get_bits(gb, 2);\n        s->intra_dc_precision = get_bits(gb, 2);\n        s->q_scale_type = get_bits1(gb);\n    }\n\n    if (s->alternate_scan) {\n        ff_init_scantable(s->idsp.idct_permutation, &s->inter_scantable,   ff_alternate_vertical_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_scantable,   ff_alternate_vertical_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_h_scantable, ff_alternate_vertical_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_v_scantable, ff_alternate_vertical_scan);\n    } else {\n        ff_init_scantable(s->idsp.idct_permutation, &s->inter_scantable,   ff_zigzag_direct);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_scantable,   ff_zigzag_direct);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_h_scantable, ff_alternate_horizontal_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_v_scantable, ff_alternate_vertical_scan);\n    }\n\n    mpeg4_load_default_matrices(s);\n\n    next_start_code_studio(gb);\n    extension_and_user_data(s, gb, 4);\n\n    return 0;\n}", "func_src_after": "static int decode_studio_vop_header(Mpeg4DecContext *ctx, GetBitContext *gb)\n{\n    MpegEncContext *s = &ctx->m;\n\n    if (get_bits_left(gb) <= 32)\n        return 0;\n\n    s->partitioned_frame = 0;\n    s->interlaced_dct = 0;\n    s->decode_mb = mpeg4_decode_studio_mb;\n\n    decode_smpte_tc(ctx, gb);\n\n    skip_bits(gb, 10); /* temporal_reference */\n    skip_bits(gb, 2); /* vop_structure */\n    s->pict_type = get_bits(gb, 2) + AV_PICTURE_TYPE_I; /* vop_coding_type */\n    if (get_bits1(gb)) { /* vop_coded */\n        skip_bits1(gb); /* top_field_first */\n        skip_bits1(gb); /* repeat_first_field */\n        s->progressive_frame = get_bits1(gb) ^ 1; /* progressive_frame */\n    }\n\n    if (s->pict_type == AV_PICTURE_TYPE_I) {\n        if (get_bits1(gb))\n            reset_studio_dc_predictors(s);\n    }\n\n    if (ctx->shape != BIN_ONLY_SHAPE) {\n        s->alternate_scan = get_bits1(gb);\n        s->frame_pred_frame_dct = get_bits1(gb);\n        s->dct_precision = get_bits(gb, 2);\n        s->intra_dc_precision = get_bits(gb, 2);\n        s->q_scale_type = get_bits1(gb);\n    }\n\n    if (s->alternate_scan) {\n        ff_init_scantable(s->idsp.idct_permutation, &s->inter_scantable,   ff_alternate_vertical_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_scantable,   ff_alternate_vertical_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_h_scantable, ff_alternate_vertical_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_v_scantable, ff_alternate_vertical_scan);\n    } else {\n        ff_init_scantable(s->idsp.idct_permutation, &s->inter_scantable,   ff_zigzag_direct);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_scantable,   ff_zigzag_direct);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_h_scantable, ff_alternate_horizontal_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_v_scantable, ff_alternate_vertical_scan);\n    }\n\n    mpeg4_load_default_matrices(s);\n\n    next_start_code_studio(gb);\n    extension_and_user_data(s, gb, 4);\n\n    return 0;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/1f686d023b95219db933394a7704ad9aa5f01cbb", "file_name": "libavcodec/mpeg4videodec.c", "vul_type": "cwe-125", "description": "Write a C function to decode the header of a studio video object plane (VOP) for an MPEG4 decoder context."}
{"func_name": "formUpdateBuffer", "func_src_before": "formUpdateBuffer(Anchor *a, Buffer *buf, FormItemList *form)\n{\n    Buffer save;\n    char *p;\n    int spos, epos, rows, c_rows, pos, col = 0;\n    Line *l;\n\n    copyBuffer(&save, buf);\n    gotoLine(buf, a->start.line);\n    switch (form->type) {\n    case FORM_TEXTAREA:\n    case FORM_INPUT_TEXT:\n    case FORM_INPUT_FILE:\n    case FORM_INPUT_PASSWORD:\n    case FORM_INPUT_CHECKBOX:\n    case FORM_INPUT_RADIO:\n#ifdef MENU_SELECT\n    case FORM_SELECT:\n#endif\t\t\t\t/* MENU_SELECT */\n\tspos = a->start.pos;\n\tepos = a->end.pos;\n\tbreak;\n    default:\n\tspos = a->start.pos + 1;\n\tepos = a->end.pos - 1;\n    }\n    switch (form->type) {\n    case FORM_INPUT_CHECKBOX:\n    case FORM_INPUT_RADIO:\n\tif (buf->currentLine == NULL ||\n\t    spos >= buf->currentLine->len || spos < 0)\n\t    break;\n\tif (form->checked)\n\t    buf->currentLine->lineBuf[spos] = '*';\n\telse\n\t    buf->currentLine->lineBuf[spos] = ' ';\n\tbreak;\n    case FORM_INPUT_TEXT:\n    case FORM_INPUT_FILE:\n    case FORM_INPUT_PASSWORD:\n    case FORM_TEXTAREA:\n#ifdef MENU_SELECT\n    case FORM_SELECT:\n\tif (form->type == FORM_SELECT) {\n\t    p = form->label->ptr;\n\t    updateSelectOption(form, form->select_option);\n\t}\n\telse\n#endif\t\t\t\t/* MENU_SELECT */\n\t{\n\t    if (!form->value)\n\t\tbreak;\n\t    p = form->value->ptr;\n\t}\n\tl = buf->currentLine;\n\tif (!l)\n\t    break;\n\tif (form->type == FORM_TEXTAREA) {\n\t    int n = a->y - buf->currentLine->linenumber;\n\t    if (n > 0)\n\t\tfor (; l && n; l = l->prev, n--) ;\n\t    else if (n < 0)\n\t\tfor (; l && n; l = l->prev, n++) ;\n\t    if (!l)\n\t\tbreak;\n\t}\n\trows = form->rows ? form->rows : 1;\n\tcol = COLPOS(l, a->start.pos);\n\tfor (c_rows = 0; c_rows < rows; c_rows++, l = l->next) {\n\t    if (rows > 1) {\n\t\tpos = columnPos(l, col);\n\t\ta = retrieveAnchor(buf->formitem, l->linenumber, pos);\n\t\tif (a == NULL)\n\t\t    break;\n\t\tspos = a->start.pos;\n\t\tepos = a->end.pos;\n\t    }\n\t    if (a->start.line != a->end.line || spos > epos || epos >= l->len ||\n\t\tspos < 0 || epos < 0 || COLPOS(l, epos) < col)\n\t\tbreak;\n\t    pos = form_update_line(l, &p, spos, epos, COLPOS(l, epos) - col,\n\t\t\t\t   rows > 1,\n\t\t\t\t   form->type == FORM_INPUT_PASSWORD);\n\t    if (pos != epos) {\n\t\tshiftAnchorPosition(buf->href, buf->hmarklist,\n\t\t\t\t    a->start.line, spos, pos - epos);\n\t\tshiftAnchorPosition(buf->name, buf->hmarklist,\n\t\t\t\t    a->start.line, spos, pos - epos);\n\t\tshiftAnchorPosition(buf->img, buf->hmarklist,\n\t\t\t\t    a->start.line, spos, pos - epos);\n\t\tshiftAnchorPosition(buf->formitem, buf->hmarklist,\n\t\t\t\t    a->start.line, spos, pos - epos);\n\t    }\n\t}\n\tbreak;\n    }\n    copyBuffer(buf, &save);\n    arrangeLine(buf);\n}", "func_src_after": "formUpdateBuffer(Anchor *a, Buffer *buf, FormItemList *form)\n{\n    Buffer save;\n    char *p;\n    int spos, epos, rows, c_rows, pos, col = 0;\n    Line *l;\n\n    copyBuffer(&save, buf);\n    gotoLine(buf, a->start.line);\n    switch (form->type) {\n    case FORM_TEXTAREA:\n    case FORM_INPUT_TEXT:\n    case FORM_INPUT_FILE:\n    case FORM_INPUT_PASSWORD:\n    case FORM_INPUT_CHECKBOX:\n    case FORM_INPUT_RADIO:\n#ifdef MENU_SELECT\n    case FORM_SELECT:\n#endif\t\t\t\t/* MENU_SELECT */\n\tspos = a->start.pos;\n\tepos = a->end.pos;\n\tbreak;\n    default:\n\tspos = a->start.pos + 1;\n\tepos = a->end.pos - 1;\n    }\n    switch (form->type) {\n    case FORM_INPUT_CHECKBOX:\n    case FORM_INPUT_RADIO:\n\tif (buf->currentLine == NULL ||\n\t    spos >= buf->currentLine->len || spos < 0)\n\t    break;\n\tif (form->checked)\n\t    buf->currentLine->lineBuf[spos] = '*';\n\telse\n\t    buf->currentLine->lineBuf[spos] = ' ';\n\tbreak;\n    case FORM_INPUT_TEXT:\n    case FORM_INPUT_FILE:\n    case FORM_INPUT_PASSWORD:\n    case FORM_TEXTAREA:\n#ifdef MENU_SELECT\n    case FORM_SELECT:\n\tif (form->type == FORM_SELECT) {\n\t    p = form->label->ptr;\n\t    updateSelectOption(form, form->select_option);\n\t}\n\telse\n#endif\t\t\t\t/* MENU_SELECT */\n\t{\n\t    if (!form->value)\n\t\tbreak;\n\t    p = form->value->ptr;\n\t}\n\tl = buf->currentLine;\n\tif (!l)\n\t    break;\n\tif (form->type == FORM_TEXTAREA) {\n\t    int n = a->y - buf->currentLine->linenumber;\n\t    if (n > 0)\n\t\tfor (; l && n; l = l->prev, n--) ;\n\t    else if (n < 0)\n\t\tfor (; l && n; l = l->prev, n++) ;\n\t    if (!l)\n\t\tbreak;\n\t}\n\trows = form->rows ? form->rows : 1;\n\tcol = COLPOS(l, a->start.pos);\n\tfor (c_rows = 0; c_rows < rows; c_rows++, l = l->next) {\n\t    if (l == NULL)\n\t\tbreak;\n\t    if (rows > 1) {\n\t\tpos = columnPos(l, col);\n\t\ta = retrieveAnchor(buf->formitem, l->linenumber, pos);\n\t\tif (a == NULL)\n\t\t    break;\n\t\tspos = a->start.pos;\n\t\tepos = a->end.pos;\n\t    }\n\t    if (a->start.line != a->end.line || spos > epos || epos >= l->len ||\n\t\tspos < 0 || epos < 0 || COLPOS(l, epos) < col)\n\t\tbreak;\n\t    pos = form_update_line(l, &p, spos, epos, COLPOS(l, epos) - col,\n\t\t\t\t   rows > 1,\n\t\t\t\t   form->type == FORM_INPUT_PASSWORD);\n\t    if (pos != epos) {\n\t\tshiftAnchorPosition(buf->href, buf->hmarklist,\n\t\t\t\t    a->start.line, spos, pos - epos);\n\t\tshiftAnchorPosition(buf->name, buf->hmarklist,\n\t\t\t\t    a->start.line, spos, pos - epos);\n\t\tshiftAnchorPosition(buf->img, buf->hmarklist,\n\t\t\t\t    a->start.line, spos, pos - epos);\n\t\tshiftAnchorPosition(buf->formitem, buf->hmarklist,\n\t\t\t\t    a->start.line, spos, pos - epos);\n\t    }\n\t}\n\tbreak;\n    }\n    copyBuffer(buf, &save);\n    arrangeLine(buf);\n}", "commit_link": "github.com/tats/w3m/commit/7fdc83b0364005a0b5ed869230dd81752ba022e8", "file_name": "form.c", "vul_type": "cwe-476", "description": "In C, write a function `formUpdateBuffer` to update the contents of a buffer with form input data based on the position of an anchor."}
{"func_name": "html_content", "func_src_before": "    @property\n    async def html_content(self):\n        content = await self.content\n        if not content:\n            return ''\n        return markdown(content)", "func_src_after": "    @property\n    async def html_content(self):\n        content = markupsafe.escape(await self.content)\n        if not content:\n            return ''\n        return markdown(content)", "commit_link": "github.com/dongweiming/lyanna/commit/fcefac79e4b7601e81a3b3fe0ad26ab18ee95d7d", "file_name": "models/comment.py", "vul_type": "cwe-079", "description": "Generate a Python async property method that converts stored content to HTML, handling empty content and ensuring safe markup."}
{"func_name": "respond_error", "func_src_before": "    def respond_error(self, context, exception):\n        context.respond_server_error()\n        stack = traceback.format_exc()\n        return \"\"\"\n        <html>\n            <body>\n\n                <style>\n                    body {\n                        font-family: sans-serif;\n                        color: #888;\n                        text-align: center;\n                    }\n\n                    body pre {\n                        width: 600px;\n                        text-align: left;\n                        margin: auto;\n                        font-family: monospace;\n                    }\n                </style>\n\n                <img src=\"/ajenti:static/main/error.jpeg\" />\n                <br/>\n                <p>\n                    Server error\n                </p>\n                <pre>\n%s\n                </pre>\n            </body>\n        </html>\n        \"\"\" % stack", "func_src_after": "    def respond_error(self, context, exception):\n        context.respond_server_error()\n        stack = traceback.format_exc()\n        return \"\"\"\n        <html>\n            <body>\n\n                <style>\n                    body {\n                        font-family: sans-serif;\n                        color: #888;\n                        text-align: center;\n                    }\n\n                    body pre {\n                        width: 600px;\n                        text-align: left;\n                        margin: auto;\n                        font-family: monospace;\n                    }\n                </style>\n\n                <img src=\"/ajenti:static/main/error.jpeg\" />\n                <br/>\n                <p>\n                    Server error\n                </p>\n                <pre>\n%s\n                </pre>\n            </body>\n        </html>\n        \"\"\" % cgi.escape(stack)", "commit_link": "github.com/Eugeny/ajenti/commit/d3fc5eb142ff16d55d158afb050af18d5ff09120", "file_name": "ajenti/routing.py", "vul_type": "cwe-079", "description": "Write a Python function that handles a server error by displaying an error page with a stack trace."}
{"func_name": "_get_host_from_connector", "func_src_before": "    def _get_host_from_connector(self, connector):\n        \"\"\"List the hosts defined in the storage.\n\n        Return the host name with the given connection info, or None if there\n        is no host fitting that information.\n\n        \"\"\"\n\n        prefix = self._connector_to_hostname_prefix(connector)\n        LOG.debug(_('enter: _get_host_from_connector: prefix %s') % prefix)\n\n        # Get list of host in the storage\n        ssh_cmd = 'svcinfo lshost -delim !'\n        out, err = self._run_ssh(ssh_cmd)\n\n        if not len(out.strip()):\n            return None\n\n        # If we have FC information, we have a faster lookup option\n        hostname = None\n        if 'wwpns' in connector:\n            hostname = self._find_host_from_wwpn(connector)\n\n        # If we don't have a hostname yet, try the long way\n        if not hostname:\n            host_lines = out.strip().split('\\n')\n            self._assert_ssh_return(len(host_lines),\n                                    '_get_host_from_connector',\n                                    ssh_cmd, out, err)\n            header = host_lines.pop(0).split('!')\n            self._assert_ssh_return('name' in header,\n                                    '_get_host_from_connector',\n                                    ssh_cmd, out, err)\n            name_index = header.index('name')\n            hosts = map(lambda x: x.split('!')[name_index], host_lines)\n            hostname = self._find_host_exhaustive(connector, hosts)\n\n        LOG.debug(_('leave: _get_host_from_connector: host %s') % hostname)\n\n        return hostname", "func_src_after": "    def _get_host_from_connector(self, connector):\n        \"\"\"List the hosts defined in the storage.\n\n        Return the host name with the given connection info, or None if there\n        is no host fitting that information.\n\n        \"\"\"\n\n        prefix = self._connector_to_hostname_prefix(connector)\n        LOG.debug(_('enter: _get_host_from_connector: prefix %s') % prefix)\n\n        # Get list of host in the storage\n        ssh_cmd = ['svcinfo', 'lshost', '-delim', '!']\n        out, err = self._run_ssh(ssh_cmd)\n\n        if not len(out.strip()):\n            return None\n\n        # If we have FC information, we have a faster lookup option\n        hostname = None\n        if 'wwpns' in connector:\n            hostname = self._find_host_from_wwpn(connector)\n\n        # If we don't have a hostname yet, try the long way\n        if not hostname:\n            host_lines = out.strip().split('\\n')\n            self._assert_ssh_return(len(host_lines),\n                                    '_get_host_from_connector',\n                                    ssh_cmd, out, err)\n            header = host_lines.pop(0).split('!')\n            self._assert_ssh_return('name' in header,\n                                    '_get_host_from_connector',\n                                    ssh_cmd, out, err)\n            name_index = header.index('name')\n            hosts = map(lambda x: x.split('!')[name_index], host_lines)\n            hostname = self._find_host_exhaustive(connector, hosts)\n\n        LOG.debug(_('leave: _get_host_from_connector: host %s') % hostname)\n\n        return hostname", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to retrieve a host name from storage based on connection information, using SSH for commands."}
{"func_name": "view_page_history", "func_src_before": "@app.route('/<page_name>/history')\ndef view_page_history(page_name):\n    query = db.query(\"select page_content.timestamp, page_content.id from page, page_content where page.id = page_content.page_id and page.page_name = '%s'\" % page_name)\n    page_histories = query.namedresult()\n\n    return render_template(\n        'page_history.html',\n        page_name = page_name,\n        page_histories = page_histories\n    )", "func_src_after": "@app.route('/<page_name>/history')\ndef view_page_history(page_name):\n    query = db.query(\"select page_content.timestamp, page_content.id from page, page_content where page.id = page_content.page_id and page.page_name = $1\", page_name)\n    page_histories = query.namedresult()\n\n    return render_template(\n        'page_history.html',\n        page_name = page_name,\n        page_histories = page_histories\n    )", "commit_link": "github.com/Pumala/python_wiki_app_redo/commit/65d60747cd8efb05970304234d3bd949d2088e8b", "file_name": "server.py", "vul_type": "cwe-089", "description": "Write a Python Flask function to display the history of a webpage using a template, with SQL query parameterization differing between string formatting and using placeholders."}
{"func_name": "add_extra_args", "func_src_before": "    def add_extra_args(self, args=None):\n        \"\"\"Add more args depending on how known args are set.\"\"\"\n        parsed = vars(self.parse_known_args(nohelp=True)[0])\n\n        # find which image mode specified if any, and add additional arguments\n        image_mode = parsed.get('image_mode', None)\n        if image_mode is not None and image_mode != 'none':\n            self.add_image_args(image_mode)\n\n        # find which task specified if any, and add its specific arguments\n        task = parsed.get('task', None)\n        if task is not None:\n            self.add_task_args(task)\n        evaltask = parsed.get('evaltask', None)\n        if evaltask is not None:\n            self.add_task_args(evaltask)\n\n        # find which model specified if any, and add its specific arguments\n        model = parsed.get('model', None)\n        if model is not None:\n            self.add_model_subargs(model)\n\n        # reset parser-level defaults over any model-level defaults\n        try:\n            self.set_defaults(**self._defaults)\n        except AttributeError:\n            raise RuntimeError('Please file an issue on github that argparse '\n                               'got an attribute error when parsing.')", "func_src_after": "    def add_extra_args(self, args=None):\n        \"\"\"Add more args depending on how known args are set.\"\"\"\n        parsed = vars(self.parse_known_args(args, nohelp=True)[0])\n\n        # find which image mode specified if any, and add additional arguments\n        image_mode = parsed.get('image_mode', None)\n        if image_mode is not None and image_mode != 'none':\n            self.add_image_args(image_mode)\n\n        # find which task specified if any, and add its specific arguments\n        task = parsed.get('task', None)\n        if task is not None:\n            self.add_task_args(task)\n        evaltask = parsed.get('evaltask', None)\n        if evaltask is not None:\n            self.add_task_args(evaltask)\n\n        # find which model specified if any, and add its specific arguments\n        model = parsed.get('model', None)\n        if model is not None:\n            self.add_model_subargs(model)\n\n        # reset parser-level defaults over any model-level defaults\n        try:\n            self.set_defaults(**self._defaults)\n        except AttributeError:\n            raise RuntimeError('Please file an issue on github that argparse '\n                               'got an attribute error when parsing.')", "commit_link": "github.com/freedombenLiu/ParlAI/commit/601668d569e1276e0b8bf2bf8fb43e391e10d170", "file_name": "parlai/core/params.py", "vul_type": "cwe-078", "description": "Write a Python function that extends argument parsing with additional arguments based on existing parsed arguments."}
{"func_name": "_inject_key_into_fs", "func_src_before": "def _inject_key_into_fs(key, fs, execute=None):\n    \"\"\"Add the given public ssh key to root's authorized_keys.\n\n    key is an ssh key string.\n    fs is the path to the base of the filesystem into which to inject the key.\n    \"\"\"\n    sshdir = os.path.join(fs, 'root', '.ssh')\n    utils.execute('mkdir', '-p', sshdir, run_as_root=True)\n    utils.execute('chown', 'root', sshdir, run_as_root=True)\n    utils.execute('chmod', '700', sshdir, run_as_root=True)\n    keyfile = os.path.join(sshdir, 'authorized_keys')\n    key_data = [\n        '\\n',\n        '# The following ssh key was injected by Nova',\n        '\\n',\n        key.strip(),\n        '\\n',\n    ]\n    utils.execute('tee', '-a', keyfile,\n                  process_input=''.join(key_data), run_as_root=True)", "func_src_after": "def _inject_key_into_fs(key, fs, execute=None):\n    \"\"\"Add the given public ssh key to root's authorized_keys.\n\n    key is an ssh key string.\n    fs is the path to the base of the filesystem into which to inject the key.\n    \"\"\"\n    sshdir = _join_and_check_path_within_fs(fs, 'root', '.ssh')\n    utils.execute('mkdir', '-p', sshdir, run_as_root=True)\n    utils.execute('chown', 'root', sshdir, run_as_root=True)\n    utils.execute('chmod', '700', sshdir, run_as_root=True)\n\n    keyfile = os.path.join('root', '.ssh', 'authorized_keys')\n\n    key_data = ''.join([\n        '\\n',\n        '# The following ssh key was injected by Nova',\n        '\\n',\n        key.strip(),\n        '\\n',\n    ])\n\n    _inject_file_into_fs(fs, keyfile, key_data, append=True)", "commit_link": "github.com/openstack/nova/commit/2427d4a99bed35baefd8f17ba422cb7aae8dcca7", "file_name": "nova/virt/disk/api.py", "vul_type": "cwe-022", "description": "Write a Python function to add an SSH key to the root user's authorized_keys file in a given filesystem."}
{"func_name": "login", "func_src_before": "@app.route('/', methods=['POST'])\ndef login():\n    print('login')\n    user = str(request.form['username'])\n    password = str(request.form['password'])\n    cur.execute('SELECT * FROM users WHERE name = \\'{}\\' AND password = \\'{}\\';'.format(user, password))\n    response = cur.fetchone()\n    if response != None:\n        print(response, 'OK')\n        return redirect(url_for('enter_test_point'))\n    else:\n        print(response, 'not OK')\n        flash('Invalid login or password')\n        return render_template('login.html')", "func_src_after": "@app.route('/', methods=['POST'])\ndef login():\n    print('login')\n    user = str(request.form['username'])\n    password = str(request.form['password'])\n    cur.execute(\"SELECT * FROM users WHERE name = ? AND password = ?;\", [user, password])\n    response = cur.fetchone()\n    if response != None:\n        print(response, 'OK')\n        return redirect(url_for('enter_test_point'))\n    else:\n        print(response, 'not OK')\n        flash('Invalid login or password')\n        return render_template('login.html')", "commit_link": "github.com/ChemiKyle/Waterspots/commit/3f9d5099496336f3f34c48abf0cf55acaaa29011", "file_name": "app.py", "vul_type": "cwe-089", "description": "Create a Python Flask login function that checks user credentials against a database and either redirects to a test point or flashes an error message."}
{"func_name": "index", "func_src_before": "def index(request, is_mobile=False):\n  hue_collections = DashboardController(request.user).get_search_collections()\n  collection_id = request.GET.get('collection')\n\n  if not hue_collections or not collection_id:\n    return admin_collections(request, True, is_mobile)\n\n  try:\n    collection_doc = Document2.objects.get(id=collection_id)\n    if USE_NEW_EDITOR.get():\n      collection_doc.can_read_or_exception(request.user)\n    else:\n      collection_doc.doc.get().can_read_or_exception(request.user)\n    collection = Collection2(request.user, document=collection_doc)\n  except Exception, e:\n    raise PopupException(e, title=_(\"Dashboard does not exist or you don't have the permission to access it.\"))\n\n  query = {'qs': [{'q': ''}], 'fqs': [], 'start': 0}\n\n  if request.method == 'GET':\n    if 'q' in request.GET:\n      query['qs'][0]['q'] = request.GET.get('q')\n    if 'qd' in request.GET:\n      query['qd'] = request.GET.get('qd')\n\n  template = 'search.mako'\n  if is_mobile:\n    template = 'search_m.mako'\n\n  return render(template, request, {\n    'collection': collection,\n    'query': json.dumps(query),\n    'initial': json.dumps({\n        'collections': [],\n        'layout': DEFAULT_LAYOUT,\n        'is_latest': LATEST.get(),\n        'engines': get_engines(request.user)\n    }),\n    'is_owner': collection_doc.doc.get().can_write(request.user),\n    'can_edit_index': can_edit_index(request.user),\n    'is_embeddable': request.GET.get('is_embeddable', False),\n    'mobile': is_mobile,\n  })", "func_src_after": "def index(request, is_mobile=False):\n  hue_collections = DashboardController(request.user).get_search_collections()\n  collection_id = request.GET.get('collection')\n\n  if not hue_collections or not collection_id:\n    return admin_collections(request, True, is_mobile)\n\n  try:\n    collection_doc = Document2.objects.get(id=collection_id)\n    if USE_NEW_EDITOR.get():\n      collection_doc.can_read_or_exception(request.user)\n    else:\n      collection_doc.doc.get().can_read_or_exception(request.user)\n    collection = Collection2(request.user, document=collection_doc)\n  except Exception, e:\n    raise PopupException(e, title=_(\"Dashboard does not exist or you don't have the permission to access it.\"))\n\n  query = {'qs': [{'q': ''}], 'fqs': [], 'start': 0}\n\n  if request.method == 'GET':\n    if 'q' in request.GET:\n      query['qs'][0]['q'] = antixss(request.GET.get('q', ''))\n    if 'qd' in request.GET:\n      query['qd'] = antixss(request.GET.get('qd', ''))\n\n  template = 'search.mako'\n  if is_mobile:\n    template = 'search_m.mako'\n\n  return render(template, request, {\n    'collection': collection,\n    'query': json.dumps(query),\n    'initial': json.dumps({\n        'collections': [],\n        'layout': DEFAULT_LAYOUT,\n        'is_latest': LATEST.get(),\n        'engines': get_engines(request.user)\n    }),\n    'is_owner': collection_doc.can_write(request.user) if USE_NEW_EDITOR.get() else collection_doc.doc.get().can_write(request.user),\n    'can_edit_index': can_edit_index(request.user),\n    'is_embeddable': request.GET.get('is_embeddable', False),\n    'mobile': is_mobile,\n  })", "commit_link": "github.com/gethue/hue/commit/37b529b1f9aeb5d746599a9ed4e2288cf3ad3e1d", "file_name": "desktop/libs/dashboard/src/dashboard/views.py", "vul_type": "cwe-079", "description": "Write a Python function named `index` that handles a web request, performs user authorization, and renders a search dashboard template with dynamic content based on query parameters."}
{"func_name": "add_language", "func_src_before": "def add_language(lang):\n    try:\n        cur.execute(f\"INSERT INTO language (name) VALUES ('{lang}')\")\n    except Exception as e:\n        pass\n    cur.execute(f\"SELECT language_id FROM language where name='{lang}'\")\n    lang_id = cur.fetchone()[0]\n    if conn.commit():\n        return lang_id\n    return lang_id", "func_src_after": "def add_language(lang):\n    try:\n        cur.execute(\"INSERT INTO language (name) VALUES (%s)\", (lang, ))\n    except Exception as e:\n        pass\n    cur.execute(\"SELECT language_id FROM language where name=%s\", (lang, ))\n    lang_id = cur.fetchone()[0]\n    if conn.commit():\n        return lang_id\n    return lang_id", "commit_link": "github.com/Elbertbiggs360/dvdrental/commit/ad144ae2a08a332498d0831bc255170d57ba754b", "file_name": "app.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a new language into a database and return its ID, handling exceptions silently."}
{"func_name": "gsm610_init", "func_src_before": "gsm610_init\t(SF_PRIVATE *psf)\n{\tGSM610_PRIVATE\t*pgsm610 ;\n\tint\t\ttrue_flag = 1 ;\n\n\tif (psf->codec_data != NULL)\n\t{\tpsf_log_printf (psf, \"*** psf->codec_data is not NULL.\\n\") ;\n\t\treturn SFE_INTERNAL ;\n\t\t} ;\n\n\tif (psf->file.mode == SFM_RDWR)\n\t\treturn SFE_BAD_MODE_RW ;\n\n\tpsf->sf.seekable = SF_FALSE ;\n\n\tif ((pgsm610 = calloc (1, sizeof (GSM610_PRIVATE))) == NULL)\n\t\treturn SFE_MALLOC_FAILED ;\n\n\tpsf->codec_data = pgsm610 ;\n\n\tmemset (pgsm610, 0, sizeof (GSM610_PRIVATE)) ;\n\n/*============================================================\n\nNeed separate gsm_data structs for encode and decode.\n\n============================================================*/\n\n\tif ((pgsm610->gsm_data = gsm_create ()) == NULL)\n\t\treturn SFE_MALLOC_FAILED ;\n\n\tswitch (SF_CONTAINER (psf->sf.format))\n\t{\tcase SF_FORMAT_WAV :\n\t\tcase SF_FORMAT_WAVEX :\n\t\tcase SF_FORMAT_W64 :\n\t\t\tgsm_option (pgsm610->gsm_data, GSM_OPT_WAV49, &true_flag) ;\n\n\t\t\tpgsm610->encode_block = gsm610_wav_encode_block ;\n\t\t\tpgsm610->decode_block = gsm610_wav_decode_block ;\n\n\t\t\tpgsm610->samplesperblock = WAVLIKE_GSM610_SAMPLES ;\n\t\t\tpgsm610->blocksize = WAVLIKE_GSM610_BLOCKSIZE ;\n\t\t\tbreak ;\n\n\t\tcase SF_FORMAT_AIFF :\n\t\tcase SF_FORMAT_RAW :\n\t\t\tpgsm610->encode_block = gsm610_encode_block ;\n\t\t\tpgsm610->decode_block = gsm610_decode_block ;\n\n\t\t\tpgsm610->samplesperblock = GSM610_SAMPLES ;\n\t\t\tpgsm610->blocksize = GSM610_BLOCKSIZE ;\n\t\t\tbreak ;\n\n\t\tdefault :\n\t\t\treturn SFE_INTERNAL ;\n\t\t\tbreak ;\n\t\t} ;\n\n\tif (psf->file.mode == SFM_READ)\n\t{\tif (psf->datalength % pgsm610->blocksize == 0)\n\t\t\tpgsm610->blocks = psf->datalength / pgsm610->blocksize ;\n\t\telse if (psf->datalength % pgsm610->blocksize == 1 && pgsm610->blocksize == GSM610_BLOCKSIZE)\n\t\t{\t/*\n\t\t\t**\tWeird AIFF specific case.\n\t\t\t**\tAIFF chunks must be at an even offset from the start of file and\n\t\t\t**\tGSM610_BLOCKSIZE is odd which can result in an odd length SSND\n\t\t\t**\tchunk. The SSND chunk then gets padded on write which means that\n\t\t\t**\twhen it is read the datalength is too big by 1.\n\t\t\t*/\n\t\t\tpgsm610->blocks = psf->datalength / pgsm610->blocksize ;\n\t\t\t}\n\t\telse\n\t\t{\tpsf_log_printf (psf, \"*** Warning : data chunk seems to be truncated.\\n\") ;\n\t\t\tpgsm610->blocks = psf->datalength / pgsm610->blocksize + 1 ;\n\t\t\t} ;\n\n\t\tpsf->sf.frames = pgsm610->samplesperblock * pgsm610->blocks ;\n\n\t\tpsf_fseek (psf, psf->dataoffset, SEEK_SET) ;\n\n\t\tpgsm610->decode_block (psf, pgsm610) ;\t/* Read first block. */\n\n\t\tpsf->read_short\t\t= gsm610_read_s ;\n\t\tpsf->read_int\t\t= gsm610_read_i ;\n\t\tpsf->read_float\t\t= gsm610_read_f ;\n\t\tpsf->read_double\t= gsm610_read_d ;\n\t\t} ;\n\n\tif (psf->file.mode == SFM_WRITE)\n\t{\tpgsm610->blockcount = 0 ;\n\t\tpgsm610->samplecount = 0 ;\n\n\t\tpsf->write_short\t= gsm610_write_s ;\n\t\tpsf->write_int\t\t= gsm610_write_i ;\n\t\tpsf->write_float\t= gsm610_write_f ;\n\t\tpsf->write_double\t= gsm610_write_d ;\n\t\t} ;\n\n\tpsf->codec_close = gsm610_close ;\n\n\tpsf->seek = gsm610_seek ;\n\n\tpsf->filelength = psf_get_filelen (psf) ;\n\tpsf->datalength = psf->filelength - psf->dataoffset ;\n\n\treturn 0 ;\n} /* gsm610_init */", "func_src_after": "gsm610_init\t(SF_PRIVATE *psf)\n{\tGSM610_PRIVATE\t*pgsm610 ;\n\tint\t\ttrue_flag = 1 ;\n\n\tif (psf->codec_data != NULL)\n\t{\tpsf_log_printf (psf, \"*** psf->codec_data is not NULL.\\n\") ;\n\t\treturn SFE_INTERNAL ;\n\t\t} ;\n\n\tif (psf->file.mode == SFM_RDWR)\n\t\treturn SFE_BAD_MODE_RW ;\n\n\tpsf->sf.seekable = SF_FALSE ;\n\n\tif ((pgsm610 = calloc (1, sizeof (GSM610_PRIVATE))) == NULL)\n\t\treturn SFE_MALLOC_FAILED ;\n\n\tpsf->codec_data = pgsm610 ;\n\n\tmemset (pgsm610, 0, sizeof (GSM610_PRIVATE)) ;\n\n/*============================================================\n\nNeed separate gsm_data structs for encode and decode.\n\n============================================================*/\n\n\tif ((pgsm610->gsm_data = gsm_create ()) == NULL)\n\t\treturn SFE_MALLOC_FAILED ;\n\n\tswitch (SF_CONTAINER (psf->sf.format))\n\t{\tcase SF_FORMAT_WAV :\n\t\tcase SF_FORMAT_WAVEX :\n\t\tcase SF_FORMAT_W64 :\n\t\t\tgsm_option (pgsm610->gsm_data, GSM_OPT_WAV49, &true_flag) ;\n\n\t\t\tpgsm610->encode_block = gsm610_wav_encode_block ;\n\t\t\tpgsm610->decode_block = gsm610_wav_decode_block ;\n\n\t\t\tpgsm610->samplesperblock = WAVLIKE_GSM610_SAMPLES ;\n\t\t\tpgsm610->blocksize = WAVLIKE_GSM610_BLOCKSIZE ;\n\t\t\tbreak ;\n\n\t\tcase SF_FORMAT_AIFF :\n\t\tcase SF_FORMAT_RAW :\n\t\t\tpgsm610->encode_block = gsm610_encode_block ;\n\t\t\tpgsm610->decode_block = gsm610_decode_block ;\n\n\t\t\tpgsm610->samplesperblock = GSM610_SAMPLES ;\n\t\t\tpgsm610->blocksize = GSM610_BLOCKSIZE ;\n\t\t\tbreak ;\n\n\t\tdefault :\n\t\t\treturn SFE_INTERNAL ;\n\t\t\tbreak ;\n\t\t} ;\n\n\tif (psf->file.mode == SFM_READ)\n\t{\tif (psf->datalength % pgsm610->blocksize == 0)\n\t\t\tpgsm610->blocks = psf->datalength / pgsm610->blocksize ;\n\t\telse if (psf->datalength % pgsm610->blocksize == 1 && pgsm610->blocksize == GSM610_BLOCKSIZE)\n\t\t{\t/*\n\t\t\t**\tWeird AIFF specific case.\n\t\t\t**\tAIFF chunks must be at an even offset from the start of file and\n\t\t\t**\tGSM610_BLOCKSIZE is odd which can result in an odd length SSND\n\t\t\t**\tchunk. The SSND chunk then gets padded on write which means that\n\t\t\t**\twhen it is read the datalength is too big by 1.\n\t\t\t*/\n\t\t\tpgsm610->blocks = psf->datalength / pgsm610->blocksize ;\n\t\t\t}\n\t\telse\n\t\t{\tpsf_log_printf (psf, \"*** Warning : data chunk seems to be truncated.\\n\") ;\n\t\t\tpgsm610->blocks = psf->datalength / pgsm610->blocksize + 1 ;\n\t\t\t} ;\n\n\t\tpsf->sf.frames = (sf_count_t) pgsm610->samplesperblock * pgsm610->blocks ;\n\n\t\tpsf_fseek (psf, psf->dataoffset, SEEK_SET) ;\n\n\t\tpgsm610->decode_block (psf, pgsm610) ;\t/* Read first block. */\n\n\t\tpsf->read_short\t\t= gsm610_read_s ;\n\t\tpsf->read_int\t\t= gsm610_read_i ;\n\t\tpsf->read_float\t\t= gsm610_read_f ;\n\t\tpsf->read_double\t= gsm610_read_d ;\n\t\t} ;\n\n\tif (psf->file.mode == SFM_WRITE)\n\t{\tpgsm610->blockcount = 0 ;\n\t\tpgsm610->samplecount = 0 ;\n\n\t\tpsf->write_short\t= gsm610_write_s ;\n\t\tpsf->write_int\t\t= gsm610_write_i ;\n\t\tpsf->write_float\t= gsm610_write_f ;\n\t\tpsf->write_double\t= gsm610_write_d ;\n\t\t} ;\n\n\tpsf->codec_close = gsm610_close ;\n\n\tpsf->seek = gsm610_seek ;\n\n\tpsf->filelength = psf_get_filelen (psf) ;\n\tpsf->datalength = psf->filelength - psf->dataoffset ;\n\n\treturn 0 ;\n} /* gsm610_init */", "line_changes": {"deleted": [{"line_no": 76, "char_start": 2210, "char_end": 2274, "line": "\t\tpsf->sf.frames = pgsm610->samplesperblock * pgsm610->blocks ;\n"}], "added": [{"line_no": 76, "char_start": 2210, "char_end": 2287, "line": "\t\tpsf->sf.frames = (sf_count_t) pgsm610->samplesperblock * pgsm610->blocks ;\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 2228, "char_end": 2241, "chars": " (sf_count_t)"}]}, "commit_link": "github.com/libsndfile/libsndfile/commit/d6f83cd4feb154efcf5614601985ae2ce9d9fa6d", "file_name": "gsm610.c", "vul_type": "cwe-190", "commit_msg": "gsm610: Fix signed integer overflow\n\nRelated to libsndfile#785\n\nCo-authored-by: evpobr <evpobr@gmail.com>", "parent_commit": "fc298c9d9324b1fe01329f675118561eef92b9e4", "description": "In C, write a function to initialize the GSM610 codec with proper settings based on the audio file format."}
{"func_name": "plot", "func_src_before": "    def plot(self, log_files, sort='time', limit=10, nfl_filter='',\n             metric_selected='cc', plot_type='bar'):\n        if not PLOTLIB_INSTALLED:\n            raise PLOTLIBNotInstalled(_('python-matplotlib not installed.'))\n        if len(log_files) == 0:\n            raise NotFoundException(_('no log file found'))\n        try:\n            stats = Stats2(*log_files)\n            stats.sort_stats(sort)\n            stats_dict = stats.stats\n            __, func_list = stats.get_print_list([nfl_filter, limit])\n            nfls = []\n            performance = []\n            names = {'nc': 'Total Call Count', 'cc': 'Primitive Call Count',\n                     'tt': 'Total Time', 'ct': 'Cumulative Time'}\n            for func in func_list:\n                cc, nc, tt, ct, __ = stats_dict[func]\n                metric = {'cc': cc, 'nc': nc, 'tt': tt, 'ct': ct}\n                nfls.append(func[2])\n                performance.append(metric[metric_selected])\n            y_pos = range(len(nfls))\n            error = [random.random() for __ in y_pos]\n            plt.clf()\n            if plot_type == 'pie':\n                plt.pie(x=performance, explode=None, labels=nfls,\n                        autopct='%1.1f%%')\n            else:\n                plt.barh(y_pos, performance, xerr=error, align='center',\n                         alpha=0.4)\n                plt.yticks(y_pos, nfls)\n                plt.xlabel(names[metric_selected])\n            plt.title('Profile Statistics (by %s)' % names[metric_selected])\n            #plt.gcf().tight_layout(pad=1.2)\n            profile_img = tempfile.mktemp('.png', 'plot')\n            plt.savefig(profile_img, dpi=300)\n            data = open(profile_img).read()\n            os.remove(profile_img)\n            return data, [('content-type', 'image/jpg')]\n        except Exception as ex:\n            raise ProfileException(_('plotting results failed due to %s') % ex)", "func_src_after": "    def plot(self, log_files, sort='time', limit=10, nfl_filter='',\n             metric_selected='cc', plot_type='bar'):\n        if not PLOTLIB_INSTALLED:\n            raise PLOTLIBNotInstalled(_('python-matplotlib not installed.'))\n        if len(log_files) == 0:\n            raise NotFoundException(_('no log file found'))\n        try:\n            stats = Stats2(*log_files)\n            stats.sort_stats(sort)\n            stats_dict = stats.stats\n            __, func_list = stats.get_print_list([nfl_filter, limit])\n            nfls = []\n            performance = []\n            names = {'nc': 'Total Call Count', 'cc': 'Primitive Call Count',\n                     'tt': 'Total Time', 'ct': 'Cumulative Time'}\n            for func in func_list:\n                cc, nc, tt, ct, __ = stats_dict[func]\n                metric = {'cc': cc, 'nc': nc, 'tt': tt, 'ct': ct}\n                nfls.append(func[2])\n                performance.append(metric[metric_selected])\n            y_pos = range(len(nfls))\n            error = [random.random() for __ in y_pos]\n            plt.clf()\n            if plot_type == 'pie':\n                plt.pie(x=performance, explode=None, labels=nfls,\n                        autopct='%1.1f%%')\n            else:\n                plt.barh(y_pos, performance, xerr=error, align='center',\n                         alpha=0.4)\n                plt.yticks(y_pos, nfls)\n                plt.xlabel(names[metric_selected])\n            plt.title('Profile Statistics (by %s)' % names[metric_selected])\n            #plt.gcf().tight_layout(pad=1.2)\n            profile_img = tempfile.TemporaryFile()\n            plt.savefig(profile_img, format='png', dpi=300)\n            profile_img.seek(0)\n            data = profile_img.read()\n            os.close(profile_img)\n            return data, [('content-type', 'image/jpg')]\n        except Exception as ex:\n            raise ProfileException(_('plotting results failed due to %s') % ex)", "line_changes": {"deleted": [{"line_no": 34, "char_start": 1561, "char_end": 1619, "line": "            profile_img = tempfile.mktemp('.png', 'plot')\n"}, {"line_no": 35, "char_start": 1619, "char_end": 1665, "line": "            plt.savefig(profile_img, dpi=300)\n"}, {"line_no": 36, "char_start": 1665, "char_end": 1709, "line": "            data = open(profile_img).read()\n"}, {"line_no": 37, "char_start": 1709, "char_end": 1744, "line": "            os.remove(profile_img)\n"}], "added": [{"line_no": 34, "char_start": 1561, "char_end": 1612, "line": "            profile_img = tempfile.TemporaryFile()\n"}, {"line_no": 35, "char_start": 1612, "char_end": 1672, "line": "            plt.savefig(profile_img, format='png', dpi=300)\n"}, {"line_no": 36, "char_start": 1672, "char_end": 1704, "line": "            profile_img.seek(0)\n"}, {"line_no": 37, "char_start": 1704, "char_end": 1742, "line": "            data = profile_img.read()\n"}, {"line_no": 38, "char_start": 1742, "char_end": 1776, "line": "            os.close(profile_img)\n"}]}, "char_changes": {"deleted": [{"char_start": 1596, "char_end": 1617, "chars": "mktemp('.png', 'plot'"}, {"char_start": 1684, "char_end": 1689, "chars": "open("}, {"char_start": 1700, "char_end": 1701, "chars": ")"}, {"char_start": 1724, "char_end": 1729, "chars": "remov"}], "added": [{"char_start": 1596, "char_end": 1610, "chars": "TemporaryFile("}, {"char_start": 1648, "char_end": 1662, "chars": " format='png',"}, {"char_start": 1672, "char_end": 1704, "chars": "            profile_img.seek(0)\n"}, {"char_start": 1757, "char_end": 1761, "chars": "clos"}]}, "commit_link": "github.com/scality/ScalitySproxydSwift/commit/6978275cdb04bb08aaf142d401b52a46527dac4c", "file_name": "html_viewer.py", "vul_type": "cwe-377", "commit_msg": "Avoid usage of insecure mktemp() function\n\nThis patch eliminates the use of the deprecated and insecure\ntempfile.mktemp() function.  It has been replaced with secure\nalternatives where temporary files are actually required.\n\nChange-Id: I0a13d6d44cd1abc4b66fa33f39eea407617a01d5\nSecurityImpact\nCloses-bug: #1348869", "description": "In Python, write a function to plot performance statistics from log files using matplotlib, with options for sorting, filtering, and different plot types."}
{"func_name": "fetch_data", "func_src_before": "    def fetch_data(self, session, id):\n        self._openContainer(session)\n        sid = str(id)\n        if (self.idNormalizer is not None):\n            sid = self.idNormalizer.process_string(session, sid)\n        query = (\"SELECT data FROM %s WHERE identifier = '%s';\" %\n                 (self.table, sid)\n                 )\n        res = self._query(query)\n        try:\n            data = res.dictresult()[0]['data']\n        except IndexError:\n            raise ObjectDoesNotExistException(id)\n        try:\n            ndata = pg.unescape_bytea(data)\n        except:\n            # insufficient PyGreSQL version\n            ndata = data.replace(\"\\\\'\", \"'\")\n\n        ndata = ndata.replace('\\\\000\\\\001', nonTextToken)\n        ndata = ndata.replace('\\\\012', '\\n')\n        return ndata", "func_src_after": "    def fetch_data(self, session, id):\n        self._openContainer(session)\n        sid = str(id)\n        if (self.idNormalizer is not None):\n            sid = self.idNormalizer.process_string(session, sid)\n        query = (\"SELECT data FROM %s WHERE identifier = $1;\" %\n                 (self.table)\n                 )\n        res = self._query(query, sid)\n        try:\n            data = res.dictresult()[0]['data']\n        except IndexError:\n            raise ObjectDoesNotExistException(id)\n        try:\n            ndata = pg.unescape_bytea(data)\n        except:\n            # insufficient PyGreSQL version\n            ndata = data.replace(\"\\\\'\", \"'\")\n\n        ndata = ndata.replace('\\\\000\\\\001', nonTextToken)\n        ndata = ndata.replace('\\\\012', '\\n')\n        return ndata", "commit_link": "github.com/cheshire3/cheshire3/commit/d350363b4ea10f102c24c8f26d7b76b006323e8e", "file_name": "cheshire3/sql/postgresStore.py", "vul_type": "cwe-089", "description": "Write a Python function to retrieve and process data from a database using an ID, handling normalization and special character conversion."}
{"func_name": "CWebSock::GetSkinPath", "func_src_before": "CString CWebSock::GetSkinPath(const CString& sSkinName) {\n    CString sRet = CZNC::Get().GetZNCPath() + \"/webskins/\" + sSkinName;\n\n    if (!CFile::IsDir(sRet)) {\n        sRet = CZNC::Get().GetCurPath() + \"/webskins/\" + sSkinName;\n\n        if (!CFile::IsDir(sRet)) {\n            sRet = CString(_SKINDIR_) + \"/\" + sSkinName;\n        }\n    }\n\n    return sRet + \"/\";\n}", "func_src_after": "CString CWebSock::GetSkinPath(const CString& sSkinName) {\n    const CString sSkin = sSkinName.Replace_n(\"/\", \"_\").Replace_n(\".\", \"_\");\n\n    CString sRet = CZNC::Get().GetZNCPath() + \"/webskins/\" + sSkin;\n\n    if (!CFile::IsDir(sRet)) {\n        sRet = CZNC::Get().GetCurPath() + \"/webskins/\" + sSkin;\n\n        if (!CFile::IsDir(sRet)) {\n            sRet = CString(_SKINDIR_) + \"/\" + sSkin;\n        }\n    }\n\n    return sRet + \"/\";\n}", "commit_link": "github.com/znc/znc/commit/a4a5aeeb17d32937d8c7d743dae9a4cc755ce773", "file_name": "src/WebModules.cpp", "vul_type": "cwe-022", "description": "In C++, write a function to return the path to a web skin directory, checking multiple locations and sanitizing the skin name if necessary."}
{"func_name": "cut", "func_src_before": "    def cut(self, key):\n        try:\n            self.etcd.delete(os.path.join(self.namespace, key))\n        except etcd.EtcdKeyNotFound:\n            return False\n        except etcd.EtcdException as err:\n            log_error(\"Error removing key %s: [%r]\" % (key, repr(err)))\n            raise CSStoreError('Error occurred while trying to cut key')\n        return True", "func_src_after": "    def cut(self, key):\n        try:\n            self.etcd.delete(self._absolute_key(key))\n        except etcd.EtcdKeyNotFound:\n            return False\n        except etcd.EtcdException as err:\n            log_error(\"Error removing key %s: [%r]\" % (key, repr(err)))\n            raise CSStoreError('Error occurred while trying to cut key')\n        return True", "commit_link": "github.com/latchset/custodia/commit/785fc87f38b4811bc4ce43a0a9b2267ee7d500b4", "file_name": "custodia/store/etcdstore.py", "vul_type": "cwe-022", "description": "Write a Python function named `cut` that deletes a key from an etcd store and handles exceptions."}
{"func_name": "HeifContext::interpret_heif_file", "func_src_before": "Error HeifContext::interpret_heif_file()\n{\n  m_all_images.clear();\n  m_top_level_images.clear();\n  m_primary_image.reset();\n\n\n  // --- reference all non-hidden images\n\n  std::vector<heif_item_id> image_IDs = m_heif_file->get_item_IDs();\n\n  bool primary_is_grid = false;\n  for (heif_item_id id : image_IDs) {\n    auto infe_box = m_heif_file->get_infe_box(id);\n    if (!infe_box) {\n      // TODO(farindk): Should we return an error instead of skipping the invalid id?\n      continue;\n    }\n\n    if (item_type_is_image(infe_box->get_item_type())) {\n      auto image = std::make_shared<Image>(this, id);\n      m_all_images.insert(std::make_pair(id, image));\n\n      if (!infe_box->is_hidden_item()) {\n        if (id==m_heif_file->get_primary_image_ID()) {\n          image->set_primary(true);\n          m_primary_image = image;\n          primary_is_grid = infe_box->get_item_type() == \"grid\";\n        }\n\n        m_top_level_images.push_back(image);\n      }\n    }\n  }\n\n\n  if (!m_primary_image) {\n    return Error(heif_error_Invalid_input,\n                 heif_suberror_Nonexisting_item_referenced,\n                 \"'pitm' box references a non-existing image\");\n  }\n\n\n  // --- remove thumbnails from top-level images and assign to their respective image\n\n  auto iref_box = m_heif_file->get_iref_box();\n  if (iref_box) {\n    // m_top_level_images.clear();\n\n    for (auto& pair : m_all_images) {\n      auto& image = pair.second;\n\n      std::vector<Box_iref::Reference> references = iref_box->get_references_from(image->get_id());\n\n      for (const Box_iref::Reference& ref : references) {\n        uint32_t type = ref.header.get_short_type();\n\n        if (type==fourcc(\"thmb\")) {\n          // --- this is a thumbnail image, attach to the main image\n\n          std::vector<heif_item_id> refs = ref.to_item_ID;\n          if (refs.size() != 1) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Unspecified,\n                         \"Too many thumbnail references\");\n          }\n\n          image->set_is_thumbnail_of(refs[0]);\n\n          auto master_iter = m_all_images.find(refs[0]);\n          if (master_iter == m_all_images.end()) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Nonexisting_item_referenced,\n                         \"Thumbnail references a non-existing image\");\n          }\n\n          if (master_iter->second->is_thumbnail()) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Nonexisting_item_referenced,\n                         \"Thumbnail references another thumbnail\");\n          }\n\n          if (image.get() == master_iter->second.get()) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Nonexisting_item_referenced,\n                         \"Recursive thumbnail image detected\");\n          }\n          master_iter->second->add_thumbnail(image);\n\n          remove_top_level_image(image);\n        }\n        else if (type==fourcc(\"auxl\")) {\n\n          // --- this is an auxiliary image\n          //     check whether it is an alpha channel and attach to the main image if yes\n\n          std::vector<Box_ipco::Property> properties;\n          Error err = m_heif_file->get_properties(image->get_id(), properties);\n          if (err) {\n            return err;\n          }\n\n          std::shared_ptr<Box_auxC> auxC_property;\n          for (const auto& property : properties) {\n            auto auxC = std::dynamic_pointer_cast<Box_auxC>(property.property);\n            if (auxC) {\n              auxC_property = auxC;\n            }\n          }\n\n          if (!auxC_property) {\n            std::stringstream sstr;\n            sstr << \"No auxC property for image \" << image->get_id();\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Auxiliary_image_type_unspecified,\n                         sstr.str());\n          }\n\n          std::vector<heif_item_id> refs = ref.to_item_ID;\n          if (refs.size() != 1) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Unspecified,\n                         \"Too many auxiliary image references\");\n          }\n\n\n          // alpha channel\n\n          if (auxC_property->get_aux_type() == \"urn:mpeg:avc:2015:auxid:1\" ||\n              auxC_property->get_aux_type() == \"urn:mpeg:hevc:2015:auxid:1\") {\n            image->set_is_alpha_channel_of(refs[0]);\n\n            auto master_iter = m_all_images.find(refs[0]);\n            if (image.get() == master_iter->second.get()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Recursive alpha image detected\");\n            }\n            master_iter->second->set_alpha_channel(image);\n          }\n\n\n          // depth channel\n\n          if (auxC_property->get_aux_type() == \"urn:mpeg:hevc:2015:auxid:2\") {\n            image->set_is_depth_channel_of(refs[0]);\n\n            auto master_iter = m_all_images.find(refs[0]);\n            if (image.get() == master_iter->second.get()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Recursive depth image detected\");\n            }\n            master_iter->second->set_depth_channel(image);\n\n            auto subtypes = auxC_property->get_subtypes();\n\n            std::vector<std::shared_ptr<SEIMessage>> sei_messages;\n            Error err = decode_hevc_aux_sei_messages(subtypes, sei_messages);\n\n            for (auto& msg : sei_messages) {\n              auto depth_msg = std::dynamic_pointer_cast<SEIMessage_depth_representation_info>(msg);\n              if (depth_msg) {\n                image->set_depth_representation_info(*depth_msg);\n              }\n            }\n          }\n\n          remove_top_level_image(image);\n        }\n        else {\n          // 'image' is a normal image, keep it as a top-level image\n        }\n      }\n    }\n  }\n\n\n  // --- check that HEVC images have an hvcC property\n\n  for (auto& pair : m_all_images) {\n    auto& image = pair.second;\n\n    std::shared_ptr<Box_infe> infe = m_heif_file->get_infe_box(image->get_id());\n    if (infe->get_item_type() == \"hvc1\") {\n\n      auto ipma = m_heif_file->get_ipma_box();\n      auto ipco = m_heif_file->get_ipco_box();\n\n      if (!ipco->get_property_for_item_ID(image->get_id(), ipma, fourcc(\"hvcC\"))) {\n        return Error(heif_error_Invalid_input,\n                     heif_suberror_No_hvcC_box,\n                     \"No hvcC property in hvc1 type image\");\n      }\n    }\n  }\n\n\n  // --- read through properties for each image and extract image resolutions\n\n  for (auto& pair : m_all_images) {\n    auto& image = pair.second;\n\n    std::vector<Box_ipco::Property> properties;\n\n    Error err = m_heif_file->get_properties(pair.first, properties);\n    if (err) {\n      return err;\n    }\n\n    bool ispe_read = false;\n    bool primary_colr_set = false;\n    for (const auto& prop : properties) {\n      auto ispe = std::dynamic_pointer_cast<Box_ispe>(prop.property);\n      if (ispe) {\n        uint32_t width = ispe->get_width();\n        uint32_t height = ispe->get_height();\n\n\n        // --- check whether the image size is \"too large\"\n\n        if (width  >= static_cast<uint32_t>(MAX_IMAGE_WIDTH) ||\n            height >= static_cast<uint32_t>(MAX_IMAGE_HEIGHT)) {\n          std::stringstream sstr;\n          sstr << \"Image size \" << width << \"x\" << height << \" exceeds the maximum image size \"\n               << MAX_IMAGE_WIDTH << \"x\" << MAX_IMAGE_HEIGHT << \"\\n\";\n\n          return Error(heif_error_Memory_allocation_error,\n                       heif_suberror_Security_limit_exceeded,\n                       sstr.str());\n        }\n\n        image->set_resolution(width, height);\n        image->set_ispe_resolution(width, height);\n        ispe_read = true;\n      }\n\n      if (ispe_read) {\n        auto clap = std::dynamic_pointer_cast<Box_clap>(prop.property);\n        if (clap) {\n          image->set_resolution( clap->get_width_rounded(),\n                                 clap->get_height_rounded() );\n        }\n\n        auto irot = std::dynamic_pointer_cast<Box_irot>(prop.property);\n        if (irot) {\n          if (irot->get_rotation()==90 ||\n              irot->get_rotation()==270) {\n            // swap width and height\n            image->set_resolution( image->get_height(),\n                                   image->get_width() );\n          }\n        }\n      }\n\n      auto colr = std::dynamic_pointer_cast<Box_colr>(prop.property);\n      if (colr) {\n        auto profile = colr->get_color_profile();\n\n        image->set_color_profile(profile);\n\n        // if this is a grid item we assign the first one's color profile\n        // to the main image which is supposed to be a grid\n\n        // TODO: this condition is not correct. It would also classify a secondary image as a 'grid item'.\n        // We have to set the grid-image color profile in another way...\n        const bool is_grid_item = !image->is_primary() && !image->is_alpha_channel() && !image->is_depth_channel();\n\n        if (primary_is_grid &&\n            !primary_colr_set &&\n            is_grid_item) {\n          m_primary_image->set_color_profile(profile);\n          primary_colr_set = true;\n        }\n      }\n    }\n  }\n\n\n  // --- read metadata and assign to image\n\n  for (heif_item_id id : image_IDs) {\n    std::string item_type    = m_heif_file->get_item_type(id);\n    std::string content_type = m_heif_file->get_content_type(id);\n    if (item_type == \"Exif\" ||\n        (item_type==\"mime\" && content_type==\"application/rdf+xml\")) {\n      std::shared_ptr<ImageMetadata> metadata = std::make_shared<ImageMetadata>();\n      metadata->item_id = id;\n      metadata->item_type = item_type;\n      metadata->content_type = content_type;\n\n      Error err = m_heif_file->get_compressed_image_data(id, &(metadata->m_data));\n      if (err) {\n        return err;\n      }\n\n      //std::cerr.write((const char*)data.data(), data.size());\n\n\n      // --- assign metadata to the image\n\n      if (iref_box) {\n        std::vector<Box_iref::Reference> references = iref_box->get_references_from(id);\n        for (const auto& ref : references) {\n          if (ref.header.get_short_type() == fourcc(\"cdsc\")) {\n            std::vector<uint32_t> refs = ref.to_item_ID;\n            if (refs.size() != 1) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Unspecified,\n                           \"Exif data not correctly assigned to image\");\n            }\n\n            uint32_t exif_image_id = refs[0];\n            auto img_iter = m_all_images.find(exif_image_id);\n            if (img_iter == m_all_images.end()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Exif data assigned to non-existing image\");\n            }\n\n            img_iter->second->add_metadata(metadata);\n          }\n        }\n      }\n    }\n  }\n\n  return Error::Ok;\n}", "func_src_after": "Error HeifContext::interpret_heif_file()\n{\n  m_all_images.clear();\n  m_top_level_images.clear();\n  m_primary_image.reset();\n\n\n  // --- reference all non-hidden images\n\n  std::vector<heif_item_id> image_IDs = m_heif_file->get_item_IDs();\n\n  bool primary_is_grid = false;\n  for (heif_item_id id : image_IDs) {\n    auto infe_box = m_heif_file->get_infe_box(id);\n    if (!infe_box) {\n      // TODO(farindk): Should we return an error instead of skipping the invalid id?\n      continue;\n    }\n\n    if (item_type_is_image(infe_box->get_item_type())) {\n      auto image = std::make_shared<Image>(this, id);\n      m_all_images.insert(std::make_pair(id, image));\n\n      if (!infe_box->is_hidden_item()) {\n        if (id==m_heif_file->get_primary_image_ID()) {\n          image->set_primary(true);\n          m_primary_image = image;\n          primary_is_grid = infe_box->get_item_type() == \"grid\";\n        }\n\n        m_top_level_images.push_back(image);\n      }\n    }\n  }\n\n\n  if (!m_primary_image) {\n    return Error(heif_error_Invalid_input,\n                 heif_suberror_Nonexisting_item_referenced,\n                 \"'pitm' box references a non-existing image\");\n  }\n\n\n  // --- remove thumbnails from top-level images and assign to their respective image\n\n  auto iref_box = m_heif_file->get_iref_box();\n  if (iref_box) {\n    // m_top_level_images.clear();\n\n    for (auto& pair : m_all_images) {\n      auto& image = pair.second;\n\n      std::vector<Box_iref::Reference> references = iref_box->get_references_from(image->get_id());\n\n      for (const Box_iref::Reference& ref : references) {\n        uint32_t type = ref.header.get_short_type();\n\n        if (type==fourcc(\"thmb\")) {\n          // --- this is a thumbnail image, attach to the main image\n\n          std::vector<heif_item_id> refs = ref.to_item_ID;\n          if (refs.size() != 1) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Unspecified,\n                         \"Too many thumbnail references\");\n          }\n\n          image->set_is_thumbnail_of(refs[0]);\n\n          auto master_iter = m_all_images.find(refs[0]);\n          if (master_iter == m_all_images.end()) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Nonexisting_item_referenced,\n                         \"Thumbnail references a non-existing image\");\n          }\n\n          if (master_iter->second->is_thumbnail()) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Nonexisting_item_referenced,\n                         \"Thumbnail references another thumbnail\");\n          }\n\n          if (image.get() == master_iter->second.get()) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Nonexisting_item_referenced,\n                         \"Recursive thumbnail image detected\");\n          }\n          master_iter->second->add_thumbnail(image);\n\n          remove_top_level_image(image);\n        }\n        else if (type==fourcc(\"auxl\")) {\n\n          // --- this is an auxiliary image\n          //     check whether it is an alpha channel and attach to the main image if yes\n\n          std::vector<Box_ipco::Property> properties;\n          Error err = m_heif_file->get_properties(image->get_id(), properties);\n          if (err) {\n            return err;\n          }\n\n          std::shared_ptr<Box_auxC> auxC_property;\n          for (const auto& property : properties) {\n            auto auxC = std::dynamic_pointer_cast<Box_auxC>(property.property);\n            if (auxC) {\n              auxC_property = auxC;\n            }\n          }\n\n          if (!auxC_property) {\n            std::stringstream sstr;\n            sstr << \"No auxC property for image \" << image->get_id();\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Auxiliary_image_type_unspecified,\n                         sstr.str());\n          }\n\n          std::vector<heif_item_id> refs = ref.to_item_ID;\n          if (refs.size() != 1) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Unspecified,\n                         \"Too many auxiliary image references\");\n          }\n\n\n          // alpha channel\n\n          if (auxC_property->get_aux_type() == \"urn:mpeg:avc:2015:auxid:1\" ||\n              auxC_property->get_aux_type() == \"urn:mpeg:hevc:2015:auxid:1\") {\n            image->set_is_alpha_channel_of(refs[0]);\n\n            auto master_iter = m_all_images.find(refs[0]);\n            if (master_iter == m_all_images.end()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Non-existing alpha image referenced\");\n            }\n            if (image.get() == master_iter->second.get()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Recursive alpha image detected\");\n            }\n            master_iter->second->set_alpha_channel(image);\n          }\n\n\n          // depth channel\n\n          if (auxC_property->get_aux_type() == \"urn:mpeg:hevc:2015:auxid:2\") {\n            image->set_is_depth_channel_of(refs[0]);\n\n            auto master_iter = m_all_images.find(refs[0]);\n            if (image.get() == master_iter->second.get()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Recursive depth image detected\");\n            }\n            master_iter->second->set_depth_channel(image);\n\n            auto subtypes = auxC_property->get_subtypes();\n\n            std::vector<std::shared_ptr<SEIMessage>> sei_messages;\n            Error err = decode_hevc_aux_sei_messages(subtypes, sei_messages);\n\n            for (auto& msg : sei_messages) {\n              auto depth_msg = std::dynamic_pointer_cast<SEIMessage_depth_representation_info>(msg);\n              if (depth_msg) {\n                image->set_depth_representation_info(*depth_msg);\n              }\n            }\n          }\n\n          remove_top_level_image(image);\n        }\n        else {\n          // 'image' is a normal image, keep it as a top-level image\n        }\n      }\n    }\n  }\n\n\n  // --- check that HEVC images have an hvcC property\n\n  for (auto& pair : m_all_images) {\n    auto& image = pair.second;\n\n    std::shared_ptr<Box_infe> infe = m_heif_file->get_infe_box(image->get_id());\n    if (infe->get_item_type() == \"hvc1\") {\n\n      auto ipma = m_heif_file->get_ipma_box();\n      auto ipco = m_heif_file->get_ipco_box();\n\n      if (!ipco->get_property_for_item_ID(image->get_id(), ipma, fourcc(\"hvcC\"))) {\n        return Error(heif_error_Invalid_input,\n                     heif_suberror_No_hvcC_box,\n                     \"No hvcC property in hvc1 type image\");\n      }\n    }\n  }\n\n\n  // --- read through properties for each image and extract image resolutions\n\n  for (auto& pair : m_all_images) {\n    auto& image = pair.second;\n\n    std::vector<Box_ipco::Property> properties;\n\n    Error err = m_heif_file->get_properties(pair.first, properties);\n    if (err) {\n      return err;\n    }\n\n    bool ispe_read = false;\n    bool primary_colr_set = false;\n    for (const auto& prop : properties) {\n      auto ispe = std::dynamic_pointer_cast<Box_ispe>(prop.property);\n      if (ispe) {\n        uint32_t width = ispe->get_width();\n        uint32_t height = ispe->get_height();\n\n\n        // --- check whether the image size is \"too large\"\n\n        if (width  >= static_cast<uint32_t>(MAX_IMAGE_WIDTH) ||\n            height >= static_cast<uint32_t>(MAX_IMAGE_HEIGHT)) {\n          std::stringstream sstr;\n          sstr << \"Image size \" << width << \"x\" << height << \" exceeds the maximum image size \"\n               << MAX_IMAGE_WIDTH << \"x\" << MAX_IMAGE_HEIGHT << \"\\n\";\n\n          return Error(heif_error_Memory_allocation_error,\n                       heif_suberror_Security_limit_exceeded,\n                       sstr.str());\n        }\n\n        image->set_resolution(width, height);\n        image->set_ispe_resolution(width, height);\n        ispe_read = true;\n      }\n\n      if (ispe_read) {\n        auto clap = std::dynamic_pointer_cast<Box_clap>(prop.property);\n        if (clap) {\n          image->set_resolution( clap->get_width_rounded(),\n                                 clap->get_height_rounded() );\n        }\n\n        auto irot = std::dynamic_pointer_cast<Box_irot>(prop.property);\n        if (irot) {\n          if (irot->get_rotation()==90 ||\n              irot->get_rotation()==270) {\n            // swap width and height\n            image->set_resolution( image->get_height(),\n                                   image->get_width() );\n          }\n        }\n      }\n\n      auto colr = std::dynamic_pointer_cast<Box_colr>(prop.property);\n      if (colr) {\n        auto profile = colr->get_color_profile();\n\n        image->set_color_profile(profile);\n\n        // if this is a grid item we assign the first one's color profile\n        // to the main image which is supposed to be a grid\n\n        // TODO: this condition is not correct. It would also classify a secondary image as a 'grid item'.\n        // We have to set the grid-image color profile in another way...\n        const bool is_grid_item = !image->is_primary() && !image->is_alpha_channel() && !image->is_depth_channel();\n\n        if (primary_is_grid &&\n            !primary_colr_set &&\n            is_grid_item) {\n          m_primary_image->set_color_profile(profile);\n          primary_colr_set = true;\n        }\n      }\n    }\n  }\n\n\n  // --- read metadata and assign to image\n\n  for (heif_item_id id : image_IDs) {\n    std::string item_type    = m_heif_file->get_item_type(id);\n    std::string content_type = m_heif_file->get_content_type(id);\n    if (item_type == \"Exif\" ||\n        (item_type==\"mime\" && content_type==\"application/rdf+xml\")) {\n      std::shared_ptr<ImageMetadata> metadata = std::make_shared<ImageMetadata>();\n      metadata->item_id = id;\n      metadata->item_type = item_type;\n      metadata->content_type = content_type;\n\n      Error err = m_heif_file->get_compressed_image_data(id, &(metadata->m_data));\n      if (err) {\n        return err;\n      }\n\n      //std::cerr.write((const char*)data.data(), data.size());\n\n\n      // --- assign metadata to the image\n\n      if (iref_box) {\n        std::vector<Box_iref::Reference> references = iref_box->get_references_from(id);\n        for (const auto& ref : references) {\n          if (ref.header.get_short_type() == fourcc(\"cdsc\")) {\n            std::vector<uint32_t> refs = ref.to_item_ID;\n            if (refs.size() != 1) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Unspecified,\n                           \"Exif data not correctly assigned to image\");\n            }\n\n            uint32_t exif_image_id = refs[0];\n            auto img_iter = m_all_images.find(exif_image_id);\n            if (img_iter == m_all_images.end()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Exif data assigned to non-existing image\");\n            }\n\n            img_iter->second->add_metadata(metadata);\n          }\n        }\n      }\n    }\n  }\n\n  return Error::Ok;\n}", "commit_link": "github.com/strukturag/libheif/commit/995a4283d8ed2d0d2c1ceb1a577b993df2f0e014", "file_name": "libheif/heif_context.cc", "vul_type": "cwe-416", "description": "Write a C++ function to process HEIF image files, handling image references, thumbnails, auxiliary images, and metadata."}
{"func_name": "patch", "func_src_before": "static PyObject* patch(PyObject* self, PyObject* args)\n{\n    char *origData, *newData, *diffBlock, *extraBlock, *diffPtr, *extraPtr;\n    Py_ssize_t origDataLength, newDataLength, diffBlockLength, extraBlockLength;\n    PyObject *controlTuples, *tuple, *results;\n    off_t oldpos, newpos, x, y, z;\n    int i, j, numTuples;\n\n    if (!PyArg_ParseTuple(args, \"s#nO!s#s#\",\n                          &origData, &origDataLength, &newDataLength,\n                          &PyList_Type, &controlTuples,\n                          &diffBlock, &diffBlockLength,\n                          &extraBlock, &extraBlockLength))\n        return NULL;\n\n    /* allocate the memory for the new data */\n    newData = PyMem_Malloc(newDataLength + 1);\n    if (!newData)\n        return PyErr_NoMemory();\n\n    oldpos = 0;\n    newpos = 0;\n    diffPtr = diffBlock;\n    extraPtr = extraBlock;\n    numTuples = PyList_GET_SIZE(controlTuples);\n    for (i = 0; i < numTuples; i++) {\n        tuple = PyList_GET_ITEM(controlTuples, i);\n        if (!PyTuple_Check(tuple)) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_TypeError, \"expecting tuple\");\n            return NULL;\n        }\n        if (PyTuple_GET_SIZE(tuple) != 3) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_TypeError, \"expecting tuple of size 3\");\n            return NULL;\n        }\n        x = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 0));\n        y = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 1));\n        z = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 2));\n        if (newpos + x > newDataLength ||\n                diffPtr + x > diffBlock + diffBlockLength ||\n                extraPtr + y > extraBlock + extraBlockLength) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_ValueError, \"corrupt patch (overflow)\");\n            return NULL;\n        }\n        memcpy(newData + newpos, diffPtr, x);\n        diffPtr += x;\n        for (j = 0; j < x; j++)\n            if ((oldpos + j >= 0) && (oldpos + j < origDataLength))\n                newData[newpos + j] += origData[oldpos + j];\n        newpos += x;\n        oldpos += x;\n        memcpy(newData + newpos, extraPtr, y);\n        extraPtr += y;\n        newpos += y;\n        oldpos += z;\n    }\n\n    /* confirm that a valid patch was applied */\n    if (newpos != newDataLength ||\n            diffPtr != diffBlock + diffBlockLength ||\n            extraPtr != extraBlock + extraBlockLength) {\n        PyMem_Free(newData);\n        PyErr_SetString(PyExc_ValueError, \"corrupt patch (underflow)\");\n        return NULL;\n    }\n\n    results = PyBytes_FromStringAndSize(newData, newDataLength);\n    PyMem_Free(newData);\n    return results;\n}", "func_src_after": "static PyObject* patch(PyObject* self, PyObject* args)\n{\n    char *origData, *newData, *diffBlock, *extraBlock, *diffPtr, *extraPtr;\n    Py_ssize_t origDataLength, newDataLength, diffBlockLength, extraBlockLength;\n    PyObject *controlTuples, *tuple, *results;\n    off_t oldpos, newpos, x, y, z;\n    int i, j, numTuples;\n\n    if (!PyArg_ParseTuple(args, \"s#nO!s#s#\",\n                          &origData, &origDataLength, &newDataLength,\n                          &PyList_Type, &controlTuples,\n                          &diffBlock, &diffBlockLength,\n                          &extraBlock, &extraBlockLength))\n        return NULL;\n\n    /* allocate the memory for the new data */\n    newData = PyMem_Malloc(newDataLength + 1);\n    if (!newData)\n        return PyErr_NoMemory();\n\n    oldpos = 0;\n    newpos = 0;\n    diffPtr = diffBlock;\n    extraPtr = extraBlock;\n    numTuples = PyList_GET_SIZE(controlTuples);\n    for (i = 0; i < numTuples; i++) {\n        tuple = PyList_GET_ITEM(controlTuples, i);\n        if (!PyTuple_Check(tuple)) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_TypeError, \"expecting tuple\");\n            return NULL;\n        }\n        if (PyTuple_GET_SIZE(tuple) != 3) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_TypeError, \"expecting tuple of size 3\");\n            return NULL;\n        }\n        x = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 0));\n        y = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 1));\n        z = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 2));\n        if (newpos + x > newDataLength ||\n                diffPtr + x > diffBlock + diffBlockLength) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_ValueError, \"corrupt patch (overflow)\");\n            return NULL;\n        }\n        memcpy(newData + newpos, diffPtr, x);\n        diffPtr += x;\n        for (j = 0; j < x; j++)\n            if ((oldpos + j >= 0) && (oldpos + j < origDataLength))\n                newData[newpos + j] += origData[oldpos + j];\n        newpos += x;\n        oldpos += x;\n        if (newpos + y > newDataLength ||\n                extraPtr + y > extraBlock + extraBlockLength) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_ValueError, \"corrupt patch (overflow)\");\n            return NULL;\n        }\n        memcpy(newData + newpos, extraPtr, y);\n        extraPtr += y;\n        newpos += y;\n        oldpos += z;\n    }\n\n    /* confirm that a valid patch was applied */\n    if (newpos != newDataLength ||\n            diffPtr != diffBlock + diffBlockLength ||\n            extraPtr != extraBlock + extraBlockLength) {\n        PyMem_Free(newData);\n        PyErr_SetString(PyExc_ValueError, \"corrupt patch (underflow)\");\n        return NULL;\n    }\n\n    results = PyBytes_FromStringAndSize(newData, newDataLength);\n    PyMem_Free(newData);\n    return results;\n}", "commit_link": "github.com/ilanschnell/bsdiff4/commit/49a4cee2feef7deaf9d89e5e793a8824930284d7", "file_name": "bsdiff4/core.c", "vul_type": "cwe-787", "description": "Write a Python C extension function named `patch` that applies a binary patch to given data using control tuples and diff/extra blocks."}
{"func_name": "fm10k_init_module", "func_src_before": "static int __init fm10k_init_module(void)\n{\n\tpr_info(\"%s - version %s\\n\", fm10k_driver_string, fm10k_driver_version);\n\tpr_info(\"%s\\n\", fm10k_copyright);\n\n\t/* create driver workqueue */\n\tfm10k_workqueue = alloc_workqueue(\"%s\", WQ_MEM_RECLAIM, 0,\n\t\t\t\t\t  fm10k_driver_name);\n\n\tfm10k_dbg_init();\n\n\treturn fm10k_register_pci_driver();\n}", "func_src_after": "static int __init fm10k_init_module(void)\n{\n\tpr_info(\"%s - version %s\\n\", fm10k_driver_string, fm10k_driver_version);\n\tpr_info(\"%s\\n\", fm10k_copyright);\n\n\t/* create driver workqueue */\n\tfm10k_workqueue = alloc_workqueue(\"%s\", WQ_MEM_RECLAIM, 0,\n\t\t\t\t\t  fm10k_driver_name);\n\tif (!fm10k_workqueue)\n\t\treturn -ENOMEM;\n\n\tfm10k_dbg_init();\n\n\treturn fm10k_register_pci_driver();\n}", "commit_link": "github.com/torvalds/linux/commit/01ca667133d019edc9f0a1f70a272447c84ec41f", "file_name": "drivers/net/ethernet/intel/fm10k/fm10k_main.c", "vul_type": "cwe-476", "description": "Write a Linux kernel module initialization function in C that logs the driver version, allocates a workqueue, initializes debugging, and registers a PCI driver, handling potential memory allocation failure."}
{"func_name": "setUp", "func_src_before": "  def setUp(self):\n    self._history_file_path = tempfile.mktemp()\n    self._cmd_hist = debugger_cli_common.CommandHistory(\n        limit=3, history_file_path=self._history_file_path)", "func_src_after": "  def setUp(self):\n    _, self._history_file_path = tempfile.mkstemp()  # safe to ignore fd here\n    self._cmd_hist = debugger_cli_common.CommandHistory(\n        limit=3, history_file_path=self._history_file_path)", "line_changes": {"deleted": [{"line_no": 2, "char_start": 19, "char_end": 67, "line": "    self._history_file_path = tempfile.mktemp()\n"}], "added": [{"line_no": 2, "char_start": 19, "char_end": 97, "line": "    _, self._history_file_path = tempfile.mkstemp()  # safe to ignore fd here\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 22, "char_end": 25, "chars": " _,"}, {"char_start": 63, "char_end": 64, "chars": "s"}, {"char_start": 70, "char_end": 96, "chars": "  # safe to ignore fd here"}]}, "commit_link": "github.com/tensorflow/tensorflow/commit/ca5fe92b42a64b371b963d83b2da4f074e83280c", "file_name": "debugger_cli_common_test.py", "vul_type": "cwe-377", "commit_msg": "Use `tempfile.mkstemp` instead of `tempfile.mktemp`.\n\nThe `tempfile.mktemp` function is [deprecated](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp) due to [security issues](https://cwe.mitre.org/data/definitions/377.html).\n\nThe switch is easy to do.\n\nPiperOrigin-RevId: 420359120\nChange-Id: Ifb43401b1fd3e023c685dc3a74b3b655090e1ce6", "description": "Create a Python function named `setUp` that initializes a command history object with a limit of 3 and a temporary file for storing the history."}
{"func_name": "PeerListWidget::addPeer", "func_src_before": "QStandardItem* PeerListWidget::addPeer(const QString& ip, BitTorrent::TorrentHandle *const torrent, const BitTorrent::PeerInfo &peer)\n{\n    int row = m_listModel->rowCount();\n    // Adding Peer to peer list\n    m_listModel->insertRow(row);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::IP), ip);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::IP), ip, Qt::ToolTipRole);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::PORT), peer.address().port);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::IP_HIDDEN), ip);\n    if (m_resolveCountries) {\n        const QIcon ico = GuiIconProvider::instance()->getFlagIcon(peer.country());\n        if (!ico.isNull()) {\n            m_listModel->setData(m_listModel->index(row, PeerListDelegate::COUNTRY), ico, Qt::DecorationRole);\n            const QString countryName = Net::GeoIPManager::CountryName(peer.country());\n            m_listModel->setData(m_listModel->index(row, PeerListDelegate::COUNTRY), countryName, Qt::ToolTipRole);\n        }\n        else {\n            m_missingFlags.insert(ip);\n        }\n    }\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::CONNECTION), peer.connectionType());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::FLAGS), peer.flags());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::FLAGS), peer.flagsDescription(), Qt::ToolTipRole);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::CLIENT), peer.client());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::PROGRESS), peer.progress());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::DOWN_SPEED), peer.payloadDownSpeed());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::UP_SPEED), peer.payloadUpSpeed());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::TOT_DOWN), peer.totalDownload());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::TOT_UP), peer.totalUpload());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::RELEVANCE), peer.relevance());\n    QStringList downloadingFiles(torrent->info().filesForPiece(peer.downloadingPieceIndex()));\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::DOWNLOADING_PIECE), downloadingFiles.join(QLatin1String(\";\")));\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::DOWNLOADING_PIECE), downloadingFiles.join(QLatin1String(\"\\n\")), Qt::ToolTipRole);\n\n    return m_listModel->item(row, PeerListDelegate::IP);\n}", "func_src_after": "QStandardItem* PeerListWidget::addPeer(const QString& ip, BitTorrent::TorrentHandle *const torrent, const BitTorrent::PeerInfo &peer)\n{\n    int row = m_listModel->rowCount();\n    // Adding Peer to peer list\n    m_listModel->insertRow(row);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::IP), ip);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::IP), ip, Qt::ToolTipRole);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::PORT), peer.address().port);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::IP_HIDDEN), ip);\n    if (m_resolveCountries) {\n        const QIcon ico = GuiIconProvider::instance()->getFlagIcon(peer.country());\n        if (!ico.isNull()) {\n            m_listModel->setData(m_listModel->index(row, PeerListDelegate::COUNTRY), ico, Qt::DecorationRole);\n            const QString countryName = Net::GeoIPManager::CountryName(peer.country());\n            m_listModel->setData(m_listModel->index(row, PeerListDelegate::COUNTRY), countryName, Qt::ToolTipRole);\n        }\n        else {\n            m_missingFlags.insert(ip);\n        }\n    }\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::CONNECTION), peer.connectionType());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::FLAGS), peer.flags());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::FLAGS), peer.flagsDescription(), Qt::ToolTipRole);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::CLIENT), Utils::String::toHtmlEscaped(peer.client()));\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::PROGRESS), peer.progress());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::DOWN_SPEED), peer.payloadDownSpeed());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::UP_SPEED), peer.payloadUpSpeed());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::TOT_DOWN), peer.totalDownload());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::TOT_UP), peer.totalUpload());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::RELEVANCE), peer.relevance());\n    QStringList downloadingFiles(torrent->info().filesForPiece(peer.downloadingPieceIndex()));\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::DOWNLOADING_PIECE), downloadingFiles.join(QLatin1String(\";\")));\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::DOWNLOADING_PIECE), downloadingFiles.join(QLatin1String(\"\\n\")), Qt::ToolTipRole);\n\n    return m_listModel->item(row, PeerListDelegate::IP);\n}", "commit_link": "github.com/qbittorrent/qBittorrent/commit/6ca3e4f094da0a0017cb2d483ec1db6176bb0b16", "file_name": "src/gui/properties/peerlistwidget.cpp", "vul_type": "cwe-079", "description": "In C++, write a function to add a peer's details to a list model in a peer list widget."}
{"func_name": "on_message", "func_src_before": "    def on_message( self, profile_id, profile_name, level, message, timeout ):\n        if 1 == level:\n            cmd = \"notify-send \"\n            if timeout > 0:\n                cmd = cmd + \" -t %s\" % (1000 * timeout)\n\n            title = \"Back In Time (%s) : %s\" % (self.user, profile_name)\n            message = message.replace(\"\\n\", ' ')\n            message = message.replace(\"\\r\", '')\n\n            cmd = cmd + \" \\\"%s\\\" \\\"%s\\\"\" % (title, message)\n            print(cmd)\n            os.system(cmd)\n        return", "func_src_after": "    def on_message( self, profile_id, profile_name, level, message, timeout ):\n        if 1 == level:\n            cmd = ['notify-send']\n            if timeout > 0:\n                cmd.extend(['-t', str(1000 * timeout)])\n\n            title = \"Back In Time (%s) : %s\" % (self.user, profile_name)\n            message = message.replace(\"\\n\", ' ')\n            message = message.replace(\"\\r\", '')\n\n            cmd.append(title)\n            cmd.append(message)\n            subprocess.Popen(cmd).communicate()\n        return", "commit_link": "github.com/bit-team/backintime/commit/cef81d0da93ff601252607df3db1a48f7f6f01b3", "file_name": "qt4/plugins/notifyplugin.py", "vul_type": "cwe-078", "description": "Write a Python function that displays a notification with a title and message when a certain condition is met, with an optional timeout parameter."}
{"func_name": "_set_qos_rule", "func_src_before": "    def _set_qos_rule(self, qos, vvs_name):\n        max_io = self._get_qos_value(qos, 'maxIOPS')\n        max_bw = self._get_qos_value(qos, 'maxBWS')\n        cli_qos_string = \"\"\n        if max_io is not None:\n            cli_qos_string += ('-io %s ' % max_io)\n        if max_bw is not None:\n            cli_qos_string += ('-bw %sM ' % max_bw)\n        self._cli_run('setqos %svvset:%s' %\n                      (cli_qos_string, vvs_name), None)", "func_src_after": "    def _set_qos_rule(self, qos, vvs_name):\n        max_io = self._get_qos_value(qos, 'maxIOPS')\n        max_bw = self._get_qos_value(qos, 'maxBWS')\n        cli_qos_string = \"\"\n        if max_io is not None:\n            cli_qos_string += ('-io %s ' % max_io)\n        if max_bw is not None:\n            cli_qos_string += ('-bw %sM ' % max_bw)\n        self._cli_run(['setqos', '%svvset:%s' % (cli_qos_string, vvs_name)])", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function to construct and execute a command for setting Quality of Service (QoS) rules based on provided parameters."}
{"func_name": "(anonymous)", "func_src_before": "app.post('/ldap', set_current_config, function(req, res, next) {\n  // Convert ENABLE_WRITE_BACK and ENABLE_ACTIVE_DIRECTORY_UNICODE_PASSWORD to boolean.\n  req.body.ENABLE_WRITE_BACK = !!(req.body.ENABLE_WRITE_BACK && req.body.ENABLE_WRITE_BACK === 'on');\n  req.body.ENABLE_ACTIVE_DIRECTORY_UNICODE_PASSWORD = !!(req.body.ENABLE_ACTIVE_DIRECTORY_UNICODE_PASSWORD && req.body.ENABLE_ACTIVE_DIRECTORY_UNICODE_PASSWORD === 'on');\n\n  var config = xtend({}, req.current_config, req.body);\n  test_config(config, function(err, result) {\n    if (err) {\n      return res.render('index', xtend(req.current_config, req.body, {\n        ERROR: err.message,\n        LDAP_RESULTS: result\n      }));\n    }\n    req.session.LDAP_RESULTS = result;\n    console.log(req.session.LDAP_RESULTS);\n    next();\n  });\n}, function(req, res, next) {", "func_src_after": "app.post('/ldap', set_current_config, csrfProtection, function(req, res, next) {\n  // Convert ENABLE_WRITE_BACK and ENABLE_ACTIVE_DIRECTORY_UNICODE_PASSWORD to boolean.\n  req.body.ENABLE_WRITE_BACK = !!(req.body.ENABLE_WRITE_BACK && req.body.ENABLE_WRITE_BACK === 'on');\n  req.body.ENABLE_ACTIVE_DIRECTORY_UNICODE_PASSWORD = !!(req.body.ENABLE_ACTIVE_DIRECTORY_UNICODE_PASSWORD && req.body.ENABLE_ACTIVE_DIRECTORY_UNICODE_PASSWORD === 'on');\n\n  var config = xtend({}, req.current_config, req.body);\n  test_config(config, function(err, result) {\n    if (err) {\n      return res.render('index', xtend(req.current_config, req.body, {\n        ERROR: err.message,\n        LDAP_RESULTS: result\n      }));\n    }\n    req.session.LDAP_RESULTS = result;\n    console.log(req.session.LDAP_RESULTS);\n    next();\n  });\n}, function(req, res, next) {", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 65, "line": "app.post('/ldap', set_current_config, function(req, res, next) {\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 81, "line": "app.post('/ldap', set_current_config, csrfProtection, function(req, res, next) {\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 37, "char_end": 53, "chars": " csrfProtection,"}]}, "commit_link": "github.com/auth0/ad-ldap-connector/commit/57441facad9edb49f80a57acd74f39d4657add98", "file_name": "server.js", "vul_type": "cwe-352", "commit_msg": "csrf protecttion in /ldap api", "description": "Write a Node.js Express route handler that processes LDAP configuration settings from a POST request and tests the configuration."}
{"func_name": "_put_validation_file", "func_src_before": "    def _put_validation_file(self, domain, file_path, file_name, content):\n        \"\"\"Put file to the domain with validation content\"\"\"\n        request = {'packet': {'site': {'get': [\n            {'filter': {'name': domain}},\n            {'dataset': {'hosting': {}}},\n        ]}}}\n        response = self.plesk_api_client.request(request)\n\n        api_result = response['packet']['site']['get']['result']\n        if 'ok' != api_result['status']:\n            error_text = str(api_result['errtext'])\n            raise errors.DvAuthError('Site get failure: %s' % error_text)\n\n        hosting_props = api_result['data']['hosting']['vrt_hst']['property']\n        self.www_root = next(\n            x['value'] for x in hosting_props if 'www_root' == x['name'])\n        self.ftp_login = next(\n            x['value'] for x in hosting_props if 'ftp_login' == x['name'])\n\n        self.verify_path = os.path.join(self.www_root, file_path)\n        self.full_path = os.path.join(self.www_root, file_path, file_name)\n        tmp_path = os.tempnam()\n        with open(tmp_path, 'w') as f:\n            f.write(str(content))\n            f.close()\n        try:\n            self.plesk_api_client.filemng(\n                [self.ftp_login, \"mkdir\", self.verify_path, \"-p\"])\n            self.plesk_api_client.filemng(\n                [self.ftp_login, \"cp2perm\", tmp_path, self.full_path, \"0644\"])\n        finally:\n            os.unlink(tmp_path)", "func_src_after": "    def _put_validation_file(self, domain, file_path, file_name, content):\n        \"\"\"Put file to the domain with validation content\"\"\"\n        request = {'packet': {'site': {'get': [\n            {'filter': {'name': domain}},\n            {'dataset': {'hosting': {}}},\n        ]}}}\n        response = self.plesk_api_client.request(request)\n\n        api_result = response['packet']['site']['get']['result']\n        if 'ok' != api_result['status']:\n            error_text = str(api_result['errtext'])\n            raise errors.DvAuthError('Site get failure: %s' % error_text)\n\n        hosting_props = api_result['data']['hosting']['vrt_hst']['property']\n        self.www_root = next(\n            x['value'] for x in hosting_props if 'www_root' == x['name'])\n        self.ftp_login = next(\n            x['value'] for x in hosting_props if 'ftp_login' == x['name'])\n\n        self.verify_path = os.path.join(self.www_root, file_path)\n        self.full_path = os.path.join(self.www_root, file_path, file_name)\n        self._create_file(content)", "line_changes": {"deleted": [{"line_no": 22, "char_start": 1002, "char_end": 1034, "line": "        tmp_path = os.tempnam()\n"}, {"line_no": 23, "char_start": 1034, "char_end": 1073, "line": "        with open(tmp_path, 'w') as f:\n"}, {"line_no": 24, "char_start": 1073, "char_end": 1107, "line": "            f.write(str(content))\n"}, {"line_no": 25, "char_start": 1107, "char_end": 1129, "line": "            f.close()\n"}, {"line_no": 26, "char_start": 1129, "char_end": 1142, "line": "        try:\n"}, {"line_no": 27, "char_start": 1142, "char_end": 1185, "line": "            self.plesk_api_client.filemng(\n"}, {"line_no": 28, "char_start": 1185, "char_end": 1252, "line": "                [self.ftp_login, \"mkdir\", self.verify_path, \"-p\"])\n"}, {"line_no": 29, "char_start": 1252, "char_end": 1295, "line": "            self.plesk_api_client.filemng(\n"}, {"line_no": 30, "char_start": 1295, "char_end": 1374, "line": "                [self.ftp_login, \"cp2perm\", tmp_path, self.full_path, \"0644\"])\n"}, {"line_no": 31, "char_start": 1374, "char_end": 1391, "line": "        finally:\n"}, {"line_no": 32, "char_start": 1391, "char_end": 1422, "line": "            os.unlink(tmp_path)\n"}], "added": [{"line_no": 22, "char_start": 1002, "char_end": 1036, "line": "        self._create_file(content)\n"}]}, "char_changes": {"deleted": [{"char_start": 1010, "char_end": 1421, "chars": "tmp_path = os.tempnam()\n        with open(tmp_path, 'w') as f:\n            f.write(str(content))\n            f.close()\n        try:\n            self.plesk_api_client.filemng(\n                [self.ftp_login, \"mkdir\", self.verify_path, \"-p\"])\n            self.plesk_api_client.filemng(\n                [self.ftp_login, \"cp2perm\", tmp_path, self.full_path, \"0644\"])\n        finally:\n            os.unlink(tmp_path"}], "added": [{"char_start": 1010, "char_end": 1035, "chars": "self._create_file(content"}]}, "commit_link": "github.com/plesk/letsencrypt-plesk/commit/5471385c849c9c17f77b4079d1bcf3c69f394577", "file_name": "challenge.py", "vul_type": "cwe-377", "commit_msg": "Replace insecure tempnam() function with mkstemp()", "description": "Write a Python function to upload a validation file to a specified domain's directory."}
{"func_name": "mode_keepalive", "func_src_before": "    def mode_keepalive(self, request):\n        \"\"\"\n        This is called by render_POST when the\n        client is replying to the keepalive.\n        \"\"\"\n        csessid = request.args.get('csessid')[0]\n        self.last_alive[csessid] = (time.time(), False)\n        return '\"\"'", "func_src_after": "    def mode_keepalive(self, request):\n        \"\"\"\n        This is called by render_POST when the\n        client is replying to the keepalive.\n        \"\"\"\n        csessid = cgi.escape(request.args['csessid'][0])\n        self.last_alive[csessid] = (time.time(), False)\n        return '\"\"'", "commit_link": "github.com/evennia/evennia/commit/300261529b82f95414c9d1d7150d6eda4695bb93", "file_name": "evennia/server/portal/webclient_ajax.py", "vul_type": "cwe-079", "description": "Write a Python function named `mode_keepalive` that updates a timestamp for a client session ID from a POST request and returns an empty string."}
{"func_name": "add_cmdname", "func_src_before": "void add_cmdname(struct cmdnames *cmds, const char *name, size_t len)\n{\n\tstruct cmdname *ent = malloc(sizeof(*ent) + len + 1);\n\n\tent->len = len;\n\tmemcpy(ent->name, name, len);\n\tent->name[len] = 0;\n\n\tALLOC_GROW(cmds->names, cmds->cnt + 1, cmds->alloc);\n\tcmds->names[cmds->cnt++] = ent;\n}", "func_src_after": "void add_cmdname(struct cmdnames *cmds, const char *name, size_t len)\n{\n\tstruct cmdname *ent = malloc(sizeof(*ent) + len + 1);\n\tif (!ent)\n\t\treturn;\n\n\tent->len = len;\n\tmemcpy(ent->name, name, len);\n\tent->name[len] = 0;\n\n\tALLOC_GROW(cmds->names, cmds->cnt + 1, cmds->alloc);\n\tcmds->names[cmds->cnt++] = ent;\n}", "commit_link": "github.com/torvalds/linux/commit/53fc25b7f557089aff101235152ae4bff15c428a", "file_name": "tools/lib/subcmd/help.c", "vul_type": "cwe-476", "description": "Write a C function to add a command name to a list, ensuring memory allocation is handled."}
{"func_name": "save_accepted_transaction", "func_src_before": "    def save_accepted_transaction(self, user_id, project_id, money):\n        self.cursor.execute(\"update users set money = money - %s where id = %s\"%(money, user_id))\n        self.cursor.execute(\"update projects set money = money + %s where id = %s\" % (money, project_id))\n        self.cursor.execute(\"insert into transactions (project_id, user_id, money, timestamp, state) values (%s, %s, %s, now(), 'accepted' )\" % (project_id, user_id, money))\n        self.db.commit()", "func_src_after": "    def save_accepted_transaction(self, user_id, project_id, money):\n        self.cursor.execute(\"update users set money = money - %s where id = %s\", (money, user_id))\n        self.cursor.execute(\"update projects set money = money + %s where id = %s\", (money, project_id))\n        self.cursor.execute(\"insert into transactions (project_id, user_id, money, timestamp, state) values (%s, %s, \"\n                            \"%s, now(), 'accepted' )\", (project_id, user_id, money))\n        self.db.commit()", "commit_link": "github.com/JLucka/kickstarter-dev/commit/e2ffa062697e060fdfbd2eccbb89a8c53a569e0b", "file_name": "backend/transactions/TransactionConnector.py", "vul_type": "cwe-089", "description": "Write a Python function to update user and project balances and record an accepted transaction in the database."}
{"func_name": "get_previous_yields", "func_src_before": "    def get_previous_yields(self, inverter_serial):\n        query = '''\n           SELECT TimeStamp, EToday, ETotal\n           FROM Inverters\n           WHERE Serial = '%s'\n        ''' % (inverter_serial)\n        self.c.execute(query)\n        data = self.c.fetchone()\n        return data[0], data[1], data[2]", "func_src_after": "    def get_previous_yields(self, inverter_serial):\n        query = '''\n           SELECT TimeStamp, EToday, ETotal\n           FROM Inverters\n           WHERE Serial=?\n        '''\n        self.c.execute(query, (inverter_serial,))\n        data = self.c.fetchone()\n        return data[0], data[1], data[2]", "commit_link": "github.com/philipptrenz/s0-bridge/commit/269b48caa05377b7c58c3e6d1622a4429cb5ba65", "file_name": "util/database.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch the timestamp and energy yields of today and total from a database for a given inverter serial number."}
{"func_name": "test_create_host", "func_src_before": "    def test_create_host(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record\n        self.clear_mox()\n        self.stubs.Set(hpfcdriver.hpcommon.HP3PARCommon, \"get_cpg\",\n                       self.fake_get_cpg)\n        self.stubs.Set(hpfcdriver.hpcommon.HP3PARCommon, \"get_domain\",\n                       self.fake_get_domain)\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_host_cmd = 'showhost -verbose fakehost'\n        _run_ssh(show_host_cmd, False).AndReturn([pack('no hosts listed'), ''])\n\n        create_host_cmd = ('createhost -persona 1 -domain (\\'OpenStack\\',) '\n                           'fakehost 123456789012345 123456789054321')\n        _run_ssh(create_host_cmd, False).AndReturn([CLI_CR, ''])\n\n        _run_ssh(show_host_cmd, False).AndReturn([pack(FC_HOST_RET), ''])\n        self.mox.ReplayAll()\n\n        host = self.driver._create_host(self.volume, self.connector)\n        self.assertEqual(host['name'], self.FAKE_HOST)", "func_src_after": "    def test_create_host(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record\n        self.clear_mox()\n        self.stubs.Set(hpfcdriver.hpcommon.HP3PARCommon, \"get_cpg\",\n                       self.fake_get_cpg)\n        self.stubs.Set(hpfcdriver.hpcommon.HP3PARCommon, \"get_domain\",\n                       self.fake_get_domain)\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_host_cmd = ['showhost', '-verbose', 'fakehost']\n        _run_ssh(show_host_cmd, False).AndReturn([pack('no hosts listed'), ''])\n\n        create_host_cmd = (['createhost', '-persona', '1', '-domain',\n                            ('OpenStack',), 'fakehost', '123456789012345',\n                            '123456789054321'])\n        _run_ssh(create_host_cmd, False).AndReturn([CLI_CR, ''])\n\n        _run_ssh(show_host_cmd, False).AndReturn([pack(FC_HOST_RET), ''])\n        self.mox.ReplayAll()\n\n        host = self.driver._create_host(self.volume, self.connector)\n        self.assertEqual(host['name'], self.FAKE_HOST)", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/tests/test_hp3par.py", "vul_type": "cwe-078", "description": "Write a Python unit test function that mocks SSH commands for creating and verifying a host in an HP 3PAR storage system."}
{"func_name": "AP4_AtomSampleTable::GetSample", "func_src_before": "AP4_AtomSampleTable::GetSample(AP4_Ordinal index, \n                               AP4_Sample& sample)\n{\n    AP4_Result result;\n\n    // check that we have an stsc atom\n    if (!m_StscAtom) {\n        return AP4_ERROR_INVALID_FORMAT;\n    }\n    \n    // check that we have a chunk offset table\n    if (m_StcoAtom == NULL && m_Co64Atom == NULL) {\n        return AP4_ERROR_INVALID_FORMAT;\n    }\n\n    // MP4 uses 1-based indexes internally, so adjust by one\n    index++;\n\n    // find out in which chunk this sample is located\n    AP4_Ordinal chunk, skip, desc;\n    result = m_StscAtom->GetChunkForSample(index, chunk, skip, desc);\n    if (AP4_FAILED(result)) return result;\n    \n    // check that the result is within bounds\n    if (skip > index) return AP4_ERROR_INTERNAL;\n\n    // get the atom offset for this chunk\n    AP4_UI64 offset;\n    if (m_StcoAtom) {\n        AP4_UI32 offset_32;\n        result = m_StcoAtom->GetChunkOffset(chunk, offset_32);\n        offset = offset_32;\n    } else {\n        result = m_Co64Atom->GetChunkOffset(chunk, offset);\n    }\n    if (AP4_FAILED(result)) return result;\n    \n    // compute the additional offset inside the chunk\n    for (unsigned int i = index-skip; i < index; i++) {\n        AP4_Size size = 0;\n        if (m_StszAtom) {\n            result = m_StszAtom->GetSampleSize(i, size); \n        } else if (m_Stz2Atom) {\n            result = m_Stz2Atom->GetSampleSize(i, size); \n        } else {\n            result = AP4_ERROR_INVALID_FORMAT;\n        }\n        if (AP4_FAILED(result)) return result;\n        offset += size;\n    }\n\n    // set the description index\n    sample.SetDescriptionIndex(desc-1); // adjust for 0-based indexes\n\n    // set the dts and cts\n    AP4_UI32 cts_offset = 0;\n    AP4_UI64 dts        = 0;\n    AP4_UI32 duration   = 0;\n    result = m_SttsAtom->GetDts(index, dts, &duration);\n    if (AP4_FAILED(result)) return result;\n    sample.SetDuration(duration);\n    sample.SetDts(dts);\n    if (m_CttsAtom == NULL) {\n        sample.SetCts(dts);\n    } else {\n        result = m_CttsAtom->GetCtsOffset(index, cts_offset); \n\t    if (AP4_FAILED(result)) return result;\n        sample.SetCtsDelta(cts_offset);\n    }     \n\n    // set the size\n    AP4_Size sample_size = 0;\n    if (m_StszAtom) {\n        result = m_StszAtom->GetSampleSize(index, sample_size); \n    } else if (m_Stz2Atom) {\n        result = m_Stz2Atom->GetSampleSize(index, sample_size); \n    } else {\n        result = AP4_ERROR_INVALID_FORMAT;\n    }\n    if (AP4_FAILED(result)) return result;\n    sample.SetSize(sample_size);\n\n    // set the sync flag\n    if (m_StssAtom == NULL) {\n        sample.SetSync(true);\n    } else {\n        sample.SetSync(m_StssAtom->IsSampleSync(index));\n    }\n\n    // set the offset\n    sample.SetOffset(offset);\n\n    // set the data stream\n    sample.SetDataStream(m_SampleStream);\n\n\n    return AP4_SUCCESS;\n}", "func_src_after": "AP4_AtomSampleTable::GetSample(AP4_Ordinal index, \n                               AP4_Sample& sample)\n{\n    AP4_Result result;\n\n    // check that we have an stsc atom\n    if (!m_StscAtom) {\n        return AP4_ERROR_INVALID_FORMAT;\n    }\n    \n    // check that we have a chunk offset table\n    if (m_StcoAtom == NULL && m_Co64Atom == NULL) {\n        return AP4_ERROR_INVALID_FORMAT;\n    }\n\n    // MP4 uses 1-based indexes internally, so adjust by one\n    index++;\n\n    // find out in which chunk this sample is located\n    AP4_Ordinal chunk, skip, desc;\n    result = m_StscAtom->GetChunkForSample(index, chunk, skip, desc);\n    if (AP4_FAILED(result)) return result;\n    \n    // check that the result is within bounds\n    if (skip > index) return AP4_ERROR_INTERNAL;\n\n    // get the atom offset for this chunk\n    AP4_UI64 offset;\n    if (m_StcoAtom) {\n        AP4_UI32 offset_32;\n        result = m_StcoAtom->GetChunkOffset(chunk, offset_32);\n        offset = offset_32;\n    } else {\n        result = m_Co64Atom->GetChunkOffset(chunk, offset);\n    }\n    if (AP4_FAILED(result)) return result;\n    \n    // compute the additional offset inside the chunk\n    for (unsigned int i = index-skip; i < index; i++) {\n        AP4_Size size = 0;\n        if (m_StszAtom) {\n            result = m_StszAtom->GetSampleSize(i, size); \n        } else if (m_Stz2Atom) {\n            result = m_Stz2Atom->GetSampleSize(i, size); \n        } else {\n            result = AP4_ERROR_INVALID_FORMAT;\n        }\n        if (AP4_FAILED(result)) return result;\n        offset += size;\n    }\n\n    // set the description index\n    sample.SetDescriptionIndex(desc-1); // adjust for 0-based indexes\n\n    // set the dts and cts\n    AP4_UI32 cts_offset = 0;\n    AP4_UI64 dts        = 0;\n    AP4_UI32 duration   = 0;\n    if (m_SttsAtom) {\n        result = m_SttsAtom->GetDts(index, dts, &duration);\n        if (AP4_FAILED(result)) return result;\n    }\n    sample.SetDuration(duration);\n    sample.SetDts(dts);\n    if (m_CttsAtom == NULL) {\n        sample.SetCts(dts);\n    } else {\n        result = m_CttsAtom->GetCtsOffset(index, cts_offset); \n\t    if (AP4_FAILED(result)) return result;\n        sample.SetCtsDelta(cts_offset);\n    }     \n\n    // set the size\n    AP4_Size sample_size = 0;\n    if (m_StszAtom) {\n        result = m_StszAtom->GetSampleSize(index, sample_size); \n    } else if (m_Stz2Atom) {\n        result = m_Stz2Atom->GetSampleSize(index, sample_size); \n    } else {\n        result = AP4_ERROR_INVALID_FORMAT;\n    }\n    if (AP4_FAILED(result)) return result;\n    sample.SetSize(sample_size);\n\n    // set the sync flag\n    if (m_StssAtom == NULL) {\n        sample.SetSync(true);\n    } else {\n        sample.SetSync(m_StssAtom->IsSampleSync(index));\n    }\n\n    // set the offset\n    sample.SetOffset(offset);\n\n    // set the data stream\n    sample.SetDataStream(m_SampleStream);\n\n\n    return AP4_SUCCESS;\n}", "commit_link": "github.com/axiomatic-systems/Bento4/commit/2f267f89f957088197f4b1fc254632d1645b415d", "file_name": "Source/C++/Core/Ap4AtomSampleTable.cpp", "vul_type": "cwe-476", "description": "In C++, write a function to retrieve a media sample from an MP4 file's atom sample table by its index."}
{"func_name": "test_raises_error_when_config_is_missing", "func_src_before": "  def test_raises_error_when_config_is_missing\n    YAML.stub :load, -> { raise \"bad things\" } do\n      exception = assert_raises(ArgumentError) do\n        # using eval here, sorry :(\n        eval <<-CLASS, binding, __FILE__, __LINE__ + 1\n          class SomeWidget < ApplicationRecord\n            acts_as_textcaptcha\n          end\n        CLASS\n      end\n      assert_match(/could not find any textcaptcha options/, exception.message)\n    end\n  end", "func_src_after": "  def test_raises_error_when_config_is_missing\n    YAML.stub :safe_load, -> { raise \"bad things\" } do\n      exception = assert_raises(ArgumentError) do\n        # using eval here, sorry :(\n        eval <<-CLASS, binding, __FILE__, __LINE__ + 1\n          class SomeWidget < ApplicationRecord\n            acts_as_textcaptcha\n          end\n        CLASS\n      end\n      assert_match(/could not find any textcaptcha options/, exception.message)\n    end\n  end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 47, "char_end": 97, "line": "    YAML.stub :load, -> { raise \"bad things\" } do\n"}], "added": [{"line_no": 2, "char_start": 47, "char_end": 102, "line": "    YAML.stub :safe_load, -> { raise \"bad things\" } do\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 62, "char_end": 67, "chars": "safe_"}]}, "commit_link": "github.com/matthutchinson/acts_as_textcaptcha/commit/09b2c281859c07e8cc966e604153ba97bc3c6ec2", "file_name": "textcaptcha_test.rb", "vul_type": "cwe-502", "commit_msg": "update tests to use YAML.safe_load", "parent_commit": "f9b9d1623306bb621cd1c14574a4a07513368ce7", "description": "Write a Ruby test method that checks if an error is raised when a configuration for a widget class is missing."}
{"func_name": "__init__.callback", "func_src_before": "        def callback(recipeName):\n            menu.pack_forget()\n            viewRecipeFrame.pack(expand=True, fill='both')\n            groceryButton.pack_forget()\n            database_file = \"meal_planner.db\"\n            print(recipeName)\n            with sqlite3.connect(database_file) as conn:\n                cursor = conn.cursor()\n                selection = cursor.execute(\"\"\"SELECT * FROM recipe WHERE name = \"\"\" + \"\\\"\" + recipeName + \"\\\"\")\n                for result in [selection]:\n                    for row in result.fetchall():\n                        name = row[0]\n                        time = row[1]\n                        servings = row[2]\n                        ingredients = row[4]\n                        directions = row[5]\n\n                        string = (\"Name: {} \\n Cook time: {} \\n Number of Servings: {} \\n \".format(name, time, servings))\n                        secondString = (\"Ingredients: {}\".format(ingredients))\n                        thirdString = (\"Directions: {}\".format(directions))\n            Label(viewRecipeFrame, text=string, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(side=TOP)\n            Label(viewRecipeFrame, text=secondString, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(side=TOP)\n            Label(viewRecipeFrame, text=thirdString, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(side=TOP)\n            returnButton = Button(menuFrame, text = \"Return to Menu\", highlightbackground=\"#e7e7e7\", command=lambda: [viewRecipeFrame.pack_forget(),\n                                                                                     menu.pack(), returnButton.pack_forget(), label.configure(text=\"Meal Planer\"),\n                                                                                    groceryButton.pack(side=RIGHT)])\n            returnButton.pack(side=RIGHT)", "func_src_after": "        def callback(recipeName):\n            menu.pack_forget()\n            viewRecipeFrame.pack(expand=True, fill='both')\n            groceryButton.pack_forget()\n            database_file = \"meal_planner.db\"\n            print(recipeName)\n            with sqlite3.connect(database_file) as conn:\n                cursor = conn.cursor()\n                selection = cursor.execute(\"\"\"SELECT * FROM recipe WHERE name = ?;\"\"\", (recipeName, ))\n                for result in [selection]:\n                    for row in result.fetchall():\n                        name = row[0]\n                        time = row[1]\n                        servings = row[2]\n                        ingredients = row[4]\n                        directions = row[5]\n\n                        string = (\"Name: {} \\n Cook time: {} \\n Number of Servings: {} \\n \".format(name, time, servings))\n                        secondString = (\"Ingredients: {}\".format(ingredients))\n                        thirdString = (\"Directions: {}\".format(directions))\n            Label(viewRecipeFrame, text=string, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(side=TOP)\n            Label(viewRecipeFrame, text=secondString, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(side=TOP)\n            Label(viewRecipeFrame, text=thirdString, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(side=TOP)\n            returnButton = Button(menuFrame, text = \"Return to Menu\", highlightbackground=\"#e7e7e7\", command=lambda: [viewRecipeFrame.pack_forget(),\n                                                                                     menu.pack(), returnButton.pack_forget(), label.configure(text=\"Meal Planer\"),\n                                                                                    groceryButton.pack(side=RIGHT)])\n            returnButton.pack(side=RIGHT)", "commit_link": "github.com/trishamoyer/RecipePlanner-Python/commit/44d2ce370715d9344fad34b3b749322ab095a925", "file_name": "mealPlan.py", "vul_type": "cwe-089", "description": "Write a Python function that displays recipe details from a SQLite database when a recipe name is provided."}
{"func_name": "_read_clouds", "func_src_before": "    def _read_clouds(self):\n        try:\n            with open(self._clouds_path) as clouds_file:\n                self._clouds = yaml.load(clouds_file)\n        except IOError:\n            # The user doesn't have a clouds.yaml file.\n            print(\"The user clouds.yaml file didn't exist.\")\n            self._clouds = {}", "func_src_after": "    def _read_clouds(self):\n        try:\n            with open(self._clouds_path) as clouds_file:\n                self._clouds = yaml.safe_load(clouds_file)\n        except IOError:\n            # The user doesn't have a clouds.yaml file.\n            print(\"The user clouds.yaml file didn't exist.\")\n            self._clouds = {}", "line_changes": {"deleted": [{"line_no": 4, "char_start": 98, "char_end": 152, "line": "                self._clouds = yaml.load(clouds_file)\n"}], "added": [{"line_no": 4, "char_start": 98, "char_end": 157, "line": "                self._clouds = yaml.safe_load(clouds_file)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 134, "char_end": 139, "chars": "safe_"}]}, "commit_link": "github.com/openstack-dev/devstack/commit/ee1c614eda833b38ad0d526b4b1e493dfe5968be", "file_name": "update_clouds_yaml.py", "vul_type": "cwe-502", "commit_msg": "Fix use of yaml.load()\n\nThe use of this function has been deprecated for a long time[0]. With\nPyYAML==6.0 the call is now failing, so replace it with the safe\nversion.\n\n[0] https://msg.pyyaml.org/load\n\nSigned-off-by: Jens Harbott <frickler@offenerstapel.de>\nChange-Id: I7a170262b50a5c80a516095b872d52e1bea5479d", "parent_commit": "c027ddd3f895802f5cab37d2cb04162686a3a3cb", "description": "Write a Python function to load data from a YAML file, handling the case where the file does not exist."}
{"func_name": "HPHP::exif_process_APP12", "func_src_before": "static void exif_process_APP12(image_info_type *ImageInfo,\n                               char *buffer, size_t length) {\n  size_t l1, l2=0;\n  if ((l1 = php_strnlen(buffer+2, length-2)) > 0) {\n    exif_iif_add_tag(ImageInfo, SECTION_APP12, \"Company\",\n                     TAG_NONE, TAG_FMT_STRING, l1, buffer+2);\n    if (length > 2+l1+1) {\n      l2 = php_strnlen(buffer+2+l1+1, length-2-l1+1);\n      exif_iif_add_tag(ImageInfo, SECTION_APP12, \"Info\",\n                       TAG_NONE, TAG_FMT_STRING, l2, buffer+2+l1+1);\n    }\n  }\n}", "func_src_after": "static void exif_process_APP12(image_info_type *ImageInfo,\n                               char *buffer, size_t length) {\n  size_t l1, l2=0;\n  if ((l1 = php_strnlen(buffer+2, length-2)) > 0) {\n    exif_iif_add_tag(ImageInfo, SECTION_APP12, \"Company\",\n                     TAG_NONE, TAG_FMT_STRING, l1, buffer+2);\n    if (length > 2+l1+1) {\n      l2 = php_strnlen(buffer+2+l1+1, length-2-l1-1);\n      exif_iif_add_tag(ImageInfo, SECTION_APP12, \"Info\",\n                       TAG_NONE, TAG_FMT_STRING, l2, buffer+2+l1+1);\n    }\n  }\n}", "commit_link": "github.com/facebook/hhvm/commit/f1cd34e63c2a0d9702be3d41462db7bfd0ae7da3", "file_name": "hphp/runtime/ext/gd/ext_gd.cpp", "vul_type": "cwe-125", "description": "Write a C function named `exif_process_APP12` that processes APP12 EXIF tags from a buffer and adds them to an image information structure."}
{"func_name": "layer_resize", "func_src_before": "layer_resize(int layer, int x_size, int y_size)\n{\n\tint                 old_height;\n\tint                 old_width;\n\tstruct map_tile*    tile;\n\tint                 tile_width;\n\tint                 tile_height;\n\tstruct map_tile*    tilemap;\n\tstruct map_trigger* trigger;\n\tstruct map_zone*    zone;\n\n\tint x, y, i;\n\n\told_width = s_map->layers[layer].width;\n\told_height = s_map->layers[layer].height;\n\n\t// allocate a new tilemap and copy the old layer tiles into it.  we can't simply realloc\n\t// because the tilemap is a 2D array.\n\tif (!(tilemap = malloc(x_size * y_size * sizeof(struct map_tile))))\n\t\treturn false;\n\tfor (x = 0; x < x_size; ++x) {\n\t\tfor (y = 0; y < y_size; ++y) {\n\t\t\tif (x < old_width && y < old_height) {\n\t\t\t\ttilemap[x + y * x_size] = s_map->layers[layer].tilemap[x + y * old_width];\n\t\t\t}\n\t\t\telse {\n\t\t\t\ttile = &tilemap[x + y * x_size];\n\t\t\t\ttile->frames_left = tileset_get_delay(s_map->tileset, 0);\n\t\t\t\ttile->tile_index = 0;\n\t\t\t}\n\t\t}\n\t}\n\n\t// free the old tilemap and substitute the new one\n\tfree(s_map->layers[layer].tilemap);\n\ts_map->layers[layer].tilemap = tilemap;\n\ts_map->layers[layer].width = x_size;\n\ts_map->layers[layer].height = y_size;\n\n\t// if we resize the largest layer, the overall map size will change.\n\t// recalcuate it.\n\ttileset_get_size(s_map->tileset, &tile_width, &tile_height);\n\ts_map->width = 0;\n\ts_map->height = 0;\n\tfor (i = 0; i < s_map->num_layers; ++i) {\n\t\tif (!s_map->layers[i].is_parallax) {\n\t\t\ts_map->width = fmax(s_map->width, s_map->layers[i].width * tile_width);\n\t\t\ts_map->height = fmax(s_map->height, s_map->layers[i].height * tile_height);\n\t\t}\n\t}\n\n\t// ensure zones and triggers remain in-bounds.  if any are completely\n\t// out-of-bounds, delete them.\n\tfor (i = (int)vector_len(s_map->zones) - 1; i >= 0; --i) {\n\t\tzone = vector_get(s_map->zones, i);\n\t\tif (zone->bounds.x1 >= s_map->width || zone->bounds.y1 >= s_map->height)\n\t\t\tvector_remove(s_map->zones, i);\n\t\telse {\n\t\t\tif (zone->bounds.x2 > s_map->width)\n\t\t\t\tzone->bounds.x2 = s_map->width;\n\t\t\tif (zone->bounds.y2 > s_map->height)\n\t\t\t\tzone->bounds.y2 = s_map->height;\n\t\t}\n\t}\n\tfor (i = (int)vector_len(s_map->triggers) - 1; i >= 0; --i) {\n\t\ttrigger = vector_get(s_map->triggers, i);\n\t\tif (trigger->x >= s_map->width || trigger->y >= s_map->height)\n\t\t\tvector_remove(s_map->triggers, i);\n\t}\n\n\treturn true;\n}", "func_src_after": "layer_resize(int layer, int x_size, int y_size)\n{\n\tint                 old_height;\n\tint                 old_width;\n\tstruct map_tile*    tile;\n\tint                 tile_width;\n\tint                 tile_height;\n\tstruct map_tile*    tilemap;\n\tstruct map_trigger* trigger;\n\tstruct map_zone*    zone;\n\tsize_t              tilemap_size;\n\n\tint x, y, i;\n\n\told_width = s_map->layers[layer].width;\n\told_height = s_map->layers[layer].height;\n\n\t// allocate a new tilemap and copy the old layer tiles into it.  we can't simply realloc\n\t// because the tilemap is a 2D array.\n\ttilemap_size = x_size * y_size * sizeof(struct map_tile);\n\tif (x_size == 0 || tilemap_size / x_size / sizeof(struct map_tile) != y_size\n\t\t|| !(tilemap = malloc(tilemap_size)))\n\t\treturn false;\n\tfor (x = 0; x < x_size; ++x) {\n\t\tfor (y = 0; y < y_size; ++y) {\n\t\t\tif (x < old_width && y < old_height) {\n\t\t\t\ttilemap[x + y * x_size] = s_map->layers[layer].tilemap[x + y * old_width];\n\t\t\t}\n\t\t\telse {\n\t\t\t\ttile = &tilemap[x + y * x_size];\n\t\t\t\ttile->frames_left = tileset_get_delay(s_map->tileset, 0);\n\t\t\t\ttile->tile_index = 0;\n\t\t\t}\n\t\t}\n\t}\n\n\t// free the old tilemap and substitute the new one\n\tfree(s_map->layers[layer].tilemap);\n\ts_map->layers[layer].tilemap = tilemap;\n\ts_map->layers[layer].width = x_size;\n\ts_map->layers[layer].height = y_size;\n\n\t// if we resize the largest layer, the overall map size will change.\n\t// recalcuate it.\n\ttileset_get_size(s_map->tileset, &tile_width, &tile_height);\n\ts_map->width = 0;\n\ts_map->height = 0;\n\tfor (i = 0; i < s_map->num_layers; ++i) {\n\t\tif (!s_map->layers[i].is_parallax) {\n\t\t\ts_map->width = fmax(s_map->width, s_map->layers[i].width * tile_width);\n\t\t\ts_map->height = fmax(s_map->height, s_map->layers[i].height * tile_height);\n\t\t}\n\t}\n\n\t// ensure zones and triggers remain in-bounds.  if any are completely\n\t// out-of-bounds, delete them.\n\tfor (i = (int)vector_len(s_map->zones) - 1; i >= 0; --i) {\n\t\tzone = vector_get(s_map->zones, i);\n\t\tif (zone->bounds.x1 >= s_map->width || zone->bounds.y1 >= s_map->height)\n\t\t\tvector_remove(s_map->zones, i);\n\t\telse {\n\t\t\tif (zone->bounds.x2 > s_map->width)\n\t\t\t\tzone->bounds.x2 = s_map->width;\n\t\t\tif (zone->bounds.y2 > s_map->height)\n\t\t\t\tzone->bounds.y2 = s_map->height;\n\t\t}\n\t}\n\tfor (i = (int)vector_len(s_map->triggers) - 1; i >= 0; --i) {\n\t\ttrigger = vector_get(s_map->triggers, i);\n\t\tif (trigger->x >= s_map->width || trigger->y >= s_map->height)\n\t\t\tvector_remove(s_map->triggers, i);\n\t}\n\n\treturn true;\n}", "commit_link": "github.com/fatcerberus/minisphere/commit/252c1ca184cb38e1acb917aa0e451c5f08519996", "file_name": "src/minisphere/map_engine.c", "vul_type": "cwe-190", "description": "In C, write a function to resize a map layer, reallocating the tilemap and adjusting map zones and triggers accordingly."}
{"func_name": "get_mod_taken_together_with", "func_src_before": "def get_mod_taken_together_with(code):\n    '''\n        Retrieves the list of modules taken together with the specified\n        module code in the same semester.\n\n        Returns a table of lists (up to 10 top results). Each list contains\n        (specified code, module code of mod taken together, aySem, number of students)\n\n        e.g. [(CS1010, CS1231, AY 16/17 Sem 1, 5)] means there are 5 students\n        taking CS1010 and CS1231 together in AY 16/17 Sem 1.\n    '''\n    NUM_TOP_RESULTS_TO_RETURN = 10\n\n    sql_command = \"SELECT sp1.moduleCode, sp2.moduleCode, sp1.acadYearAndSem, COUNT(*) \" + \\\n                \"FROM studentPlans sp1, studentPlans sp2 \" + \\\n                \"WHERE sp1.moduleCode = '\" + code + \"' AND \" + \\\n                \"sp2.moduleCode <> sp1.moduleCode AND \" + \\\n                \"sp1.studentId = sp2.studentId AND \" + \\\n                \"sp1.acadYearAndSem = sp2.acadYearAndSem \" + \\\n                \"GROUP BY sp1.moduleCode, sp2.moduleCode, sp1.acadYearAndSem \" + \\\n                \"ORDER BY COUNT(*) DESC\"\n\n    DB_CURSOR.execute(sql_command)\n\n    return DB_CURSOR.fetchmany(NUM_TOP_RESULTS_TO_RETURN)", "func_src_after": "def get_mod_taken_together_with(code):\n    '''\n        Retrieves the list of modules taken together with the specified\n        module code in the same semester.\n\n        Returns a table of lists (up to 10 top results). Each list contains\n        (specified code, module code of mod taken together, aySem, number of students)\n\n        e.g. [(CS1010, CS1231, AY 16/17 Sem 1, 5)] means there are 5 students\n        taking CS1010 and CS1231 together in AY 16/17 Sem 1.\n    '''\n    NUM_TOP_RESULTS_TO_RETURN = 10\n\n    sql_command = \"SELECT sp1.moduleCode, sp2.moduleCode, sp1.acadYearAndSem, COUNT(*) \" + \\\n                \"FROM studentPlans sp1, studentPlans sp2 \" + \\\n                \"WHERE sp1.moduleCode = %s AND \" + \\\n                \"sp2.moduleCode <> sp1.moduleCode AND \" + \\\n                \"sp1.studentId = sp2.studentId AND \" + \\\n                \"sp1.acadYearAndSem = sp2.acadYearAndSem \" + \\\n                \"GROUP BY sp1.moduleCode, sp2.moduleCode, sp1.acadYearAndSem \" + \\\n                \"ORDER BY COUNT(*) DESC\"\n\n    DB_CURSOR.execute(sql_command, (code,))\n\n    return DB_CURSOR.fetchmany(NUM_TOP_RESULTS_TO_RETURN)", "commit_link": "github.com/nus-mtp/cs-modify/commit/79b4b1dd7eba5445751808e4c50b49d2dd08366b", "file_name": "components/model.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch the top 10 modules taken alongside a given module code from a database."}
{"func_name": "ImagingFliDecode", "func_src_before": "ImagingFliDecode(Imaging im, ImagingCodecState state, UINT8* buf, Py_ssize_t bytes)\n{\n    UINT8* ptr;\n    int framesize;\n    int c, chunks, advance;\n    int l, lines;\n    int i, j, x = 0, y, ymax;\n\n    /* If not even the chunk size is present, we'd better leave */\n\n    if (bytes < 4)\n\treturn 0;\n\n    /* We don't decode anything unless we have a full chunk in the\n       input buffer (on the other hand, the Python part of the driver\n       makes sure this is always the case) */\n\n    ptr = buf;\n\n    framesize = I32(ptr);\n    if (framesize < I32(ptr))\n\treturn 0;\n\n    /* Make sure this is a frame chunk.  The Python driver takes\n       case of other chunk types. */\n\n    if (I16(ptr+4) != 0xF1FA) {\n\tstate->errcode = IMAGING_CODEC_UNKNOWN;\n\treturn -1;\n    }\n\n    chunks = I16(ptr+6);\n    ptr += 16;\n    bytes -= 16;\n\n    /* Process subchunks */\n    for (c = 0; c < chunks; c++) {\n\tUINT8* data;\n\tif (bytes < 10) {\n\t    state->errcode = IMAGING_CODEC_OVERRUN;\n\t    return -1;\n\t}\n\tdata = ptr + 6;\n\tswitch (I16(ptr+4)) {\n\tcase 4: case 11:\n\t    /* FLI COLOR chunk */\n\t    break; /* ignored; handled by Python code */\n\tcase 7:\n\t    /* FLI SS2 chunk (word delta) */\n\t    lines = I16(data); data += 2;\n\t    for (l = y = 0; l < lines && y < state->ysize; l++, y++) {\n\t\tUINT8* buf = (UINT8*) im->image[y];\n\t\tint p, packets;\n\t\tpackets = I16(data); data += 2;\n\t\twhile (packets & 0x8000) {\n\t\t    /* flag word */\n\t\t    if (packets & 0x4000) {\n\t\t\ty += 65536 - packets; /* skip lines */\n\t\t\tif (y >= state->ysize) {\n\t\t\t    state->errcode = IMAGING_CODEC_OVERRUN;\n\t\t\t    return -1;\n\t\t\t}\n\t\t\tbuf = (UINT8*) im->image[y];\n\t\t    } else {\n\t\t\t/* store last byte (used if line width is odd) */\n\t\t\tbuf[state->xsize-1] = (UINT8) packets;\n\t\t    }\n\t\t    packets = I16(data); data += 2;\n\t\t}\n\t\tfor (p = x = 0; p < packets; p++) {\n\t\t    x += data[0]; /* pixel skip */\n\t\t    if (data[1] >= 128) {\n\t\t\ti = 256-data[1]; /* run */\n\t\t\tif (x + i + i > state->xsize)\n\t\t\t    break;\n\t\t\tfor (j = 0; j < i; j++) {\n\t\t\t    buf[x++] = data[2];\n\t\t\t    buf[x++] = data[3];\n\t\t\t}\n\t\t\tdata += 2 + 2;\n\t\t    } else {\n\t\t\ti = 2 * (int) data[1]; /* chunk */\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break;\n\t\t\tmemcpy(buf + x, data + 2, i);\n\t\t\tdata += 2 + i;\n\t\t\tx += i;\n\t\t    }\n\t\t}\n\t\tif (p < packets)\n\t\t    break; /* didn't process all packets */\n\t    }\n\t    if (l < lines) {\n\t\t/* didn't process all lines */\n\t\tstate->errcode = IMAGING_CODEC_OVERRUN;\n\t\treturn -1;\n\t    }\n\t    break;\n\tcase 12:\n\t    /* FLI LC chunk (byte delta) */\n\t    y = I16(data); ymax = y + I16(data+2); data += 4;\n\t    for (; y < ymax && y < state->ysize; y++) {\n\t\tUINT8* out = (UINT8*) im->image[y];\n\t\tint p, packets = *data++;\n\t\tfor (p = x = 0; p < packets; p++, x += i) {\n\t\t    x += data[0]; /* skip pixels */\n\t\t    if (data[1] & 0x80) {\n\t\t\ti = 256-data[1]; /* run */\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break;\n\t\t\tmemset(out + x, data[2], i);\n\t\t\tdata += 3;\n\t\t    } else {\n\t\t\ti = data[1]; /* chunk */\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break;\n\t\t\tmemcpy(out + x, data + 2, i);\n\t\t\tdata += i + 2;\n\t\t    }\n\t\t}\n\t\tif (p < packets)\n\t\t    break; /* didn't process all packets */\n\t    }\n\t    if (y < ymax) {\n\t\t/* didn't process all lines */\n\t\tstate->errcode = IMAGING_CODEC_OVERRUN;\n\t\treturn -1;\n\t    }\n\t    break;\n\tcase 13:\n\t    /* FLI BLACK chunk */\n\t    for (y = 0; y < state->ysize; y++)\n\t\tmemset(im->image[y], 0, state->xsize);\n\t    break;\n\tcase 15:\n\t    /* FLI BRUN chunk */\n\t    for (y = 0; y < state->ysize; y++) {\n\t\tUINT8* out = (UINT8*) im->image[y];\n\t\tdata += 1; /* ignore packetcount byte */\n\t\tfor (x = 0; x < state->xsize; x += i) {\n\t\t    if (data[0] & 0x80) {\n\t\t\ti = 256 - data[0];\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break; /* safety first */\n\t\t\tmemcpy(out + x, data + 1, i);\n\t\t\tdata += i + 1;\n\t\t    } else {\n\t\t\ti = data[0];\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break; /* safety first */\n\t\t\tmemset(out + x, data[1], i);\n\t\t\tdata += 2;\n\t\t    }\n\t\t}\n\t\tif (x != state->xsize) {\n\t\t    /* didn't unpack whole line */\n\t\t    state->errcode = IMAGING_CODEC_OVERRUN;\n\t\t    return -1;\n\t\t}\n\t    }\n\t    break;\n\tcase 16:\n\t    /* COPY chunk */\n\t    for (y = 0; y < state->ysize; y++) {\n\t\tUINT8* buf = (UINT8*) im->image[y];\n\t\tmemcpy(buf, data, state->xsize);\n\t\tdata += state->xsize;\n\t    }\n\t    break;\n\tcase 18:\n\t    /* PSTAMP chunk */\n\t    break; /* ignored */\n\tdefault:\n\t    /* unknown chunk */\n\t    /* printf(\"unknown FLI/FLC chunk: %d\\n\", I16(ptr+4)); */\n\t    state->errcode = IMAGING_CODEC_UNKNOWN;\n\t    return -1;\n\t}\n\tadvance = I32(ptr);\n\tptr += advance;\n\tbytes -= advance;\n    }\n\n    return -1; /* end of frame */\n}", "func_src_after": "ImagingFliDecode(Imaging im, ImagingCodecState state, UINT8* buf, Py_ssize_t bytes)\n{\n    UINT8* ptr;\n    int framesize;\n    int c, chunks, advance;\n    int l, lines;\n    int i, j, x = 0, y, ymax;\n\n    /* If not even the chunk size is present, we'd better leave */\n\n    if (bytes < 4)\n\treturn 0;\n\n    /* We don't decode anything unless we have a full chunk in the\n       input buffer */\n\n    ptr = buf;\n\n    framesize = I32(ptr);\n    if (framesize < I32(ptr))\n\treturn 0;\n\n    /* Make sure this is a frame chunk.  The Python driver takes\n       case of other chunk types. */\n\n    if (bytes < 8) {\n        state->errcode = IMAGING_CODEC_OVERRUN;\n        return -1;\n    }\n    if (I16(ptr+4) != 0xF1FA) {\n\tstate->errcode = IMAGING_CODEC_UNKNOWN;\n\treturn -1;\n    }\n\n    chunks = I16(ptr+6);\n    ptr += 16;\n    bytes -= 16;\n\n    /* Process subchunks */\n    for (c = 0; c < chunks; c++) {\n\tUINT8* data;\n\tif (bytes < 10) {\n\t    state->errcode = IMAGING_CODEC_OVERRUN;\n\t    return -1;\n\t}\n\tdata = ptr + 6;\n\tswitch (I16(ptr+4)) {\n\tcase 4: case 11:\n\t    /* FLI COLOR chunk */\n\t    break; /* ignored; handled by Python code */\n\tcase 7:\n\t    /* FLI SS2 chunk (word delta) */\n\t    lines = I16(data); data += 2;\n\t    for (l = y = 0; l < lines && y < state->ysize; l++, y++) {\n\t\tUINT8* buf = (UINT8*) im->image[y];\n\t\tint p, packets;\n\t\tpackets = I16(data); data += 2;\n\t\twhile (packets & 0x8000) {\n\t\t    /* flag word */\n\t\t    if (packets & 0x4000) {\n\t\t\ty += 65536 - packets; /* skip lines */\n\t\t\tif (y >= state->ysize) {\n\t\t\t    state->errcode = IMAGING_CODEC_OVERRUN;\n\t\t\t    return -1;\n\t\t\t}\n\t\t\tbuf = (UINT8*) im->image[y];\n\t\t    } else {\n\t\t\t/* store last byte (used if line width is odd) */\n\t\t\tbuf[state->xsize-1] = (UINT8) packets;\n\t\t    }\n\t\t    packets = I16(data); data += 2;\n\t\t}\n\t\tfor (p = x = 0; p < packets; p++) {\n\t\t    x += data[0]; /* pixel skip */\n\t\t    if (data[1] >= 128) {\n\t\t\ti = 256-data[1]; /* run */\n\t\t\tif (x + i + i > state->xsize)\n\t\t\t    break;\n\t\t\tfor (j = 0; j < i; j++) {\n\t\t\t    buf[x++] = data[2];\n\t\t\t    buf[x++] = data[3];\n\t\t\t}\n\t\t\tdata += 2 + 2;\n\t\t    } else {\n\t\t\ti = 2 * (int) data[1]; /* chunk */\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break;\n\t\t\tmemcpy(buf + x, data + 2, i);\n\t\t\tdata += 2 + i;\n\t\t\tx += i;\n\t\t    }\n\t\t}\n\t\tif (p < packets)\n\t\t    break; /* didn't process all packets */\n\t    }\n\t    if (l < lines) {\n\t\t/* didn't process all lines */\n\t\tstate->errcode = IMAGING_CODEC_OVERRUN;\n\t\treturn -1;\n\t    }\n\t    break;\n\tcase 12:\n\t    /* FLI LC chunk (byte delta) */\n\t    y = I16(data); ymax = y + I16(data+2); data += 4;\n\t    for (; y < ymax && y < state->ysize; y++) {\n\t\tUINT8* out = (UINT8*) im->image[y];\n\t\tint p, packets = *data++;\n\t\tfor (p = x = 0; p < packets; p++, x += i) {\n\t\t    x += data[0]; /* skip pixels */\n\t\t    if (data[1] & 0x80) {\n\t\t\ti = 256-data[1]; /* run */\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break;\n\t\t\tmemset(out + x, data[2], i);\n\t\t\tdata += 3;\n\t\t    } else {\n\t\t\ti = data[1]; /* chunk */\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break;\n\t\t\tmemcpy(out + x, data + 2, i);\n\t\t\tdata += i + 2;\n\t\t    }\n\t\t}\n\t\tif (p < packets)\n\t\t    break; /* didn't process all packets */\n\t    }\n\t    if (y < ymax) {\n\t\t/* didn't process all lines */\n\t\tstate->errcode = IMAGING_CODEC_OVERRUN;\n\t\treturn -1;\n\t    }\n\t    break;\n\tcase 13:\n\t    /* FLI BLACK chunk */\n\t    for (y = 0; y < state->ysize; y++)\n\t\tmemset(im->image[y], 0, state->xsize);\n\t    break;\n\tcase 15:\n\t    /* FLI BRUN chunk */\n\t    for (y = 0; y < state->ysize; y++) {\n\t\tUINT8* out = (UINT8*) im->image[y];\n\t\tdata += 1; /* ignore packetcount byte */\n\t\tfor (x = 0; x < state->xsize; x += i) {\n\t\t    if (data[0] & 0x80) {\n\t\t\ti = 256 - data[0];\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break; /* safety first */\n\t\t\tmemcpy(out + x, data + 1, i);\n\t\t\tdata += i + 1;\n\t\t    } else {\n\t\t\ti = data[0];\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break; /* safety first */\n\t\t\tmemset(out + x, data[1], i);\n\t\t\tdata += 2;\n\t\t    }\n\t\t}\n\t\tif (x != state->xsize) {\n\t\t    /* didn't unpack whole line */\n\t\t    state->errcode = IMAGING_CODEC_OVERRUN;\n\t\t    return -1;\n\t\t}\n\t    }\n\t    break;\n\tcase 16:\n\t    /* COPY chunk */\n\t    for (y = 0; y < state->ysize; y++) {\n\t\tUINT8* buf = (UINT8*) im->image[y];\n\t\tmemcpy(buf, data, state->xsize);\n\t\tdata += state->xsize;\n\t    }\n\t    break;\n\tcase 18:\n\t    /* PSTAMP chunk */\n\t    break; /* ignored */\n\tdefault:\n\t    /* unknown chunk */\n\t    /* printf(\"unknown FLI/FLC chunk: %d\\n\", I16(ptr+4)); */\n\t    state->errcode = IMAGING_CODEC_UNKNOWN;\n\t    return -1;\n\t}\n\tadvance = I32(ptr);\n\tptr += advance;\n\tbytes -= advance;\n    }\n\n    return -1; /* end of frame */\n}", "commit_link": "github.com/python-pillow/Pillow/commit/a09acd0decd8a87ccce939d5ff65dab59e7d365b", "file_name": "src/libImaging/FliDecode.c", "vul_type": "cwe-125", "description": "Write a C function named `ImagingFliDecode` that decodes a frame from an FLI/FLC animation file into an image buffer."}
{"func_name": "h2h", "func_src_before": "@endpoints.route(\"/h2h\")\ndef h2h():\n    if db == None:\n        init()\n\n    player1 = request.args.get('tag1', default=\"christmasmike\")\n    player2 = request.args.get('tag2', default=\"christmasmike\")\n    sql = \"SELECT * FROM matches WHERE (player1 = '\"+str(player1)+\"' OR \"\\\n            +\"player2 = '\"+str(player1)+\"') AND (player1 = '\"+str(player2)+\"' OR \"\\\n            +\"player2 = '\"+str(player2)+\"') ORDER BY date DESC;\"\n    result = db.exec(sql)\n    return json.dumps(result)", "func_src_after": "@endpoints.route(\"/h2h\")\ndef h2h():\n    if db == None:\n        init()\n\n    player1 = request.args.get('tag1', default=\"christmasmike\")\n    player2 = request.args.get('tag2', default=\"christmasmike\")\n    sql = \"SELECT * FROM matches WHERE (player1 = '{player1}' OR \"\\\n            +\"player2 = '{player1}') AND (player1 = '{player2}' OR \"\\\n            +\"player2 = '{player2}') ORDER BY date DESC;\"\n    args = {'player1': player1, 'player2': player2}\n    result = db.exec(sql, args)\n    return json.dumps(result)", "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "endpoints.py", "vul_type": "cwe-089", "description": "Write a Python Flask endpoint function named 'h2h' that retrieves head-to-head match records between two players from a database and returns the result as JSON, with default player names as 'christmasmike'."}
{"func_name": "self.load_config", "func_src_before": "    def self.load_config(country_code)\n      default_config = YAML.\n        load(File.read(File.dirname(__FILE__) + '/conversion_rules.yml'))\n      default_config[country_code]\n    end", "func_src_after": "    def self.load_config(country_code)\n      default_config = YAML.\n        load_file(File.join(File.dirname(__FILE__), 'conversion_rules.yml'))\n      default_config[country_code]\n    end", "line_changes": {"deleted": [{"line_no": 3, "char_start": 68, "char_end": 142, "line": "        load(File.read(File.dirname(__FILE__) + '/conversion_rules.yml'))\n"}], "added": [{"line_no": 3, "char_start": 68, "char_end": 145, "line": "        load_file(File.join(File.dirname(__FILE__), 'conversion_rules.yml'))\n"}]}, "char_changes": {"deleted": [{"char_start": 86, "char_end": 90, "chars": "read"}, {"char_start": 113, "char_end": 115, "chars": " +"}, {"char_start": 117, "char_end": 118, "chars": "/"}], "added": [{"char_start": 80, "char_end": 85, "chars": "_file"}, {"char_start": 91, "char_end": 95, "chars": "join"}, {"char_start": 118, "char_end": 119, "chars": ","}]}, "commit_link": "github.com/alphasights/iban-tools/commit/d4954482c31d51a9e9896665d7019b9067f12bf7", "file_name": "conversion.rb", "vul_type": "cwe-502", "commit_msg": "Use YAML.load_file instead of YAML.load(File.Read).\n\nUse File.join instead of concatenating bits of path.", "parent_commit": "f6591635f671dad99246b594ae4c47e068e69c00", "description": "Write a Ruby method to load a country-specific configuration from a YAML file using a country code."}
{"func_name": "login_page", "func_src_before": "def login_page():\n  if request.method == 'POST':\n    login_email = request.form['login_email']\n    # print( \"%s\" % login_email)\n    login_password = request.form['login_password']\n    hashed_login_password = pwd_context.encrypt(login_password)\n\n    with dbapi2.connect(current_app.config['dsn']) as connection:\n      cursor = connection.cursor()\n      statement = \"\"\"SELECT USERNAME FROM USERS WHERE USERNAME = %s\"\"\"\n      cursor.execute(statement, [login_email])\n      db_username = cursor.fetchone()\n\n      if db_username is not None:  # check whether the user exists\n        print('%s' % db_username)\n        user = load_user(db_username);\n        login_user(user);\n        print(\"%s\" % user.username)\n        # print('%s %s' % db_username[0][0], db_username[0][1] ) if the fetchall method is used debug using this line\n\n    return render_template('home.html')\n  else:\n    return render_template('login.html')", "func_src_after": "def login_page():\n  if request.method == 'POST':\n    login_email = request.form['login_email']\n    # print( \"%s\" % login_email)\n    login_password = request.form['login_password']\n    hashed_login_password = pwd_context.encrypt(login_password)\n\n    with dbapi2.connect(current_app.config['dsn']) as connection:\n      cursor = connection.cursor()\n      statement = \"\"\"SELECT USERNAME FROM USERS WHERE USERNAME = %s\"\"\"\n      cursor.execute(statement, [login_email])\n      db_username = cursor.fetchone()\n\n      if db_username is not None:  # check whether the user exists\n        print('%s' % db_username)\n        user = load_user(db_username)\n        login_user(user)\n        print(\"%s\" % user.username)\n        # print('%s %s' % db_username[0][0], db_username[0][1] ) if the fetchall method is used debug using this line\n\n    return render_template('home.html')\n  else:\n    return render_template('login.html')", "line_changes": {"deleted": [{"line_no": 16, "char_start": 604, "char_end": 643, "line": "        user = load_user(db_username);\n"}, {"line_no": 17, "char_start": 643, "char_end": 669, "line": "        login_user(user);\n"}], "added": [{"line_no": 16, "char_start": 604, "char_end": 642, "line": "        user = load_user(db_username)\n"}, {"line_no": 17, "char_start": 642, "char_end": 667, "line": "        login_user(user)\n"}]}, "char_changes": {"deleted": [{"char_start": 641, "char_end": 642, "chars": ";"}, {"char_start": 667, "char_end": 668, "chars": ";"}], "added": []}, "commit_link": "github.com/itucsdb1705/itucsdb1705/commit/252c65001a21f332da50e7d898d07285b3abd655", "file_name": "login.py", "vul_type": "cwe-089", "commit_msg": "SQL injection is prevented for user login\n\nPlaceholders are used to prevent SQL injection", "description": "Create a Python function for handling user login that checks credentials and renders different templates based on the HTTP method."}
{"func_name": "UiApplication::SecurityConfiguration::configure", "func_src_before": "        @Override\n        protected void configure(HttpSecurity http) throws Exception {\n\n            String[] patterns = new String[] {\"/index.html\", \"/home.html\", \"/login1.html\", \"/xss2.html\", \"/\", \"/xss\",\n                \"/login\", \"/xss1.html\", \"/resource\", \"/postcustomer\", \"/getallcustomer\", \"/getinfo\", \"/postxss\"};\n\n            // @formatter:off\n            //http.httpBasic();\n            //http.authorizeRequests().antMatchers(\"/**\").permitAll(); //.anyRequest().authenticated();\n\n            http.headers().httpStrictTransportSecurity();\n            http.csrf().disable();\n            http.httpBasic().and().authorizeRequests().antMatchers(patterns).permitAll().anyRequest().authenticated();\n            http.csrf().and().addFilterAfter(new CsrfGrantingFilter(), SessionManagementFilter.class);\n            //http.csrf().csrfTokenRepository(CookieCsrfTokenRepository.withHttpOnlyFalse());\n\n            // @formatter:on\n        }", "func_src_after": "        @Override\n        protected void configure(HttpSecurity http) throws Exception {\n\n            String[] patterns = new String[] {\"/index.html\", \"/home.html\", \"/login1.html\", \"/xss2.html\", \"/\", \"/xss\",\n                \"/login\", \"/xss1.html\", \"/resource\", \"/postcustomer\", \"/getallcustomer\", \"/getinfo\", \"/postxss\"};\n\n            // @formatter:off\n            //http.httpBasic();\n            //http.authorizeRequests().antMatchers(\"/**\").permitAll(); //.anyRequest().authenticated();\n            //http.csrf().disable();\n\n\n            http.headers().httpStrictTransportSecurity();\n            http.httpBasic().and().authorizeRequests().antMatchers(patterns).permitAll().anyRequest().authenticated();\n            http.csrf().and().addFilterAfter(new CsrfGrantingFilter(), SessionManagementFilter.class);\n            //http.csrf().csrfTokenRepository(CookieCsrfTokenRepository.withHttpOnlyFalse());\n\n            // @formatter:on\n        }", "line_changes": {"deleted": [{"line_no": 12, "char_start": 548, "char_end": 583, "line": "            http.csrf().disable();\n"}], "added": [{"line_no": 11, "char_start": 526, "char_end": 527, "line": "\n"}]}, "char_changes": {"deleted": [{"char_start": 548, "char_end": 583, "chars": "            http.csrf().disable();\n"}], "added": [{"char_start": 489, "char_end": 527, "chars": "            //http.csrf().disable();\n\n"}]}, "commit_link": "github.com/barbaraisabelvieira/VulnerableDemoApp/commit/a64bbb524722f63134826a7d0424d71518a0aae6", "file_name": "UiApplication.java", "vul_type": "cwe-352", "commit_msg": "Fixing CSRF - enabled now", "parent_commit": "1faf96211c58f44a8510497e08d31757160c6367", "description": "Write a Java method using Spring Security to configure HTTP security, allowing unrestricted access to specific URL patterns and requiring authentication for all other requests."}
{"func_name": "mpol_parse_str", "func_src_before": "int mpol_parse_str(char *str, struct mempolicy **mpol)\n{\n\tstruct mempolicy *new = NULL;\n\tunsigned short mode_flags;\n\tnodemask_t nodes;\n\tchar *nodelist = strchr(str, ':');\n\tchar *flags = strchr(str, '=');\n\tint err = 1, mode;\n\n\tif (flags)\n\t\t*flags++ = '\\0';\t/* terminate mode string */\n\n\tif (nodelist) {\n\t\t/* NUL-terminate mode or flags string */\n\t\t*nodelist++ = '\\0';\n\t\tif (nodelist_parse(nodelist, nodes))\n\t\t\tgoto out;\n\t\tif (!nodes_subset(nodes, node_states[N_MEMORY]))\n\t\t\tgoto out;\n\t} else\n\t\tnodes_clear(nodes);\n\n\tmode = match_string(policy_modes, MPOL_MAX, str);\n\tif (mode < 0)\n\t\tgoto out;\n\n\tswitch (mode) {\n\tcase MPOL_PREFERRED:\n\t\t/*\n\t\t * Insist on a nodelist of one node only\n\t\t */\n\t\tif (nodelist) {\n\t\t\tchar *rest = nodelist;\n\t\t\twhile (isdigit(*rest))\n\t\t\t\trest++;\n\t\t\tif (*rest)\n\t\t\t\tgoto out;\n\t\t}\n\t\tbreak;\n\tcase MPOL_INTERLEAVE:\n\t\t/*\n\t\t * Default to online nodes with memory if no nodelist\n\t\t */\n\t\tif (!nodelist)\n\t\t\tnodes = node_states[N_MEMORY];\n\t\tbreak;\n\tcase MPOL_LOCAL:\n\t\t/*\n\t\t * Don't allow a nodelist;  mpol_new() checks flags\n\t\t */\n\t\tif (nodelist)\n\t\t\tgoto out;\n\t\tmode = MPOL_PREFERRED;\n\t\tbreak;\n\tcase MPOL_DEFAULT:\n\t\t/*\n\t\t * Insist on a empty nodelist\n\t\t */\n\t\tif (!nodelist)\n\t\t\terr = 0;\n\t\tgoto out;\n\tcase MPOL_BIND:\n\t\t/*\n\t\t * Insist on a nodelist\n\t\t */\n\t\tif (!nodelist)\n\t\t\tgoto out;\n\t}\n\n\tmode_flags = 0;\n\tif (flags) {\n\t\t/*\n\t\t * Currently, we only support two mutually exclusive\n\t\t * mode flags.\n\t\t */\n\t\tif (!strcmp(flags, \"static\"))\n\t\t\tmode_flags |= MPOL_F_STATIC_NODES;\n\t\telse if (!strcmp(flags, \"relative\"))\n\t\t\tmode_flags |= MPOL_F_RELATIVE_NODES;\n\t\telse\n\t\t\tgoto out;\n\t}\n\n\tnew = mpol_new(mode, mode_flags, &nodes);\n\tif (IS_ERR(new))\n\t\tgoto out;\n\n\t/*\n\t * Save nodes for mpol_to_str() to show the tmpfs mount options\n\t * for /proc/mounts, /proc/pid/mounts and /proc/pid/mountinfo.\n\t */\n\tif (mode != MPOL_PREFERRED)\n\t\tnew->v.nodes = nodes;\n\telse if (nodelist)\n\t\tnew->v.preferred_node = first_node(nodes);\n\telse\n\t\tnew->flags |= MPOL_F_LOCAL;\n\n\t/*\n\t * Save nodes for contextualization: this will be used to \"clone\"\n\t * the mempolicy in a specific context [cpuset] at a later time.\n\t */\n\tnew->w.user_nodemask = nodes;\n\n\terr = 0;\n\nout:\n\t/* Restore string for error message */\n\tif (nodelist)\n\t\t*--nodelist = ':';\n\tif (flags)\n\t\t*--flags = '=';\n\tif (!err)\n\t\t*mpol = new;\n\treturn err;\n}", "func_src_after": "int mpol_parse_str(char *str, struct mempolicy **mpol)\n{\n\tstruct mempolicy *new = NULL;\n\tunsigned short mode_flags;\n\tnodemask_t nodes;\n\tchar *nodelist = strchr(str, ':');\n\tchar *flags = strchr(str, '=');\n\tint err = 1, mode;\n\n\tif (flags)\n\t\t*flags++ = '\\0';\t/* terminate mode string */\n\n\tif (nodelist) {\n\t\t/* NUL-terminate mode or flags string */\n\t\t*nodelist++ = '\\0';\n\t\tif (nodelist_parse(nodelist, nodes))\n\t\t\tgoto out;\n\t\tif (!nodes_subset(nodes, node_states[N_MEMORY]))\n\t\t\tgoto out;\n\t} else\n\t\tnodes_clear(nodes);\n\n\tmode = match_string(policy_modes, MPOL_MAX, str);\n\tif (mode < 0)\n\t\tgoto out;\n\n\tswitch (mode) {\n\tcase MPOL_PREFERRED:\n\t\t/*\n\t\t * Insist on a nodelist of one node only, although later\n\t\t * we use first_node(nodes) to grab a single node, so here\n\t\t * nodelist (or nodes) cannot be empty.\n\t\t */\n\t\tif (nodelist) {\n\t\t\tchar *rest = nodelist;\n\t\t\twhile (isdigit(*rest))\n\t\t\t\trest++;\n\t\t\tif (*rest)\n\t\t\t\tgoto out;\n\t\t\tif (nodes_empty(nodes))\n\t\t\t\tgoto out;\n\t\t}\n\t\tbreak;\n\tcase MPOL_INTERLEAVE:\n\t\t/*\n\t\t * Default to online nodes with memory if no nodelist\n\t\t */\n\t\tif (!nodelist)\n\t\t\tnodes = node_states[N_MEMORY];\n\t\tbreak;\n\tcase MPOL_LOCAL:\n\t\t/*\n\t\t * Don't allow a nodelist;  mpol_new() checks flags\n\t\t */\n\t\tif (nodelist)\n\t\t\tgoto out;\n\t\tmode = MPOL_PREFERRED;\n\t\tbreak;\n\tcase MPOL_DEFAULT:\n\t\t/*\n\t\t * Insist on a empty nodelist\n\t\t */\n\t\tif (!nodelist)\n\t\t\terr = 0;\n\t\tgoto out;\n\tcase MPOL_BIND:\n\t\t/*\n\t\t * Insist on a nodelist\n\t\t */\n\t\tif (!nodelist)\n\t\t\tgoto out;\n\t}\n\n\tmode_flags = 0;\n\tif (flags) {\n\t\t/*\n\t\t * Currently, we only support two mutually exclusive\n\t\t * mode flags.\n\t\t */\n\t\tif (!strcmp(flags, \"static\"))\n\t\t\tmode_flags |= MPOL_F_STATIC_NODES;\n\t\telse if (!strcmp(flags, \"relative\"))\n\t\t\tmode_flags |= MPOL_F_RELATIVE_NODES;\n\t\telse\n\t\t\tgoto out;\n\t}\n\n\tnew = mpol_new(mode, mode_flags, &nodes);\n\tif (IS_ERR(new))\n\t\tgoto out;\n\n\t/*\n\t * Save nodes for mpol_to_str() to show the tmpfs mount options\n\t * for /proc/mounts, /proc/pid/mounts and /proc/pid/mountinfo.\n\t */\n\tif (mode != MPOL_PREFERRED)\n\t\tnew->v.nodes = nodes;\n\telse if (nodelist)\n\t\tnew->v.preferred_node = first_node(nodes);\n\telse\n\t\tnew->flags |= MPOL_F_LOCAL;\n\n\t/*\n\t * Save nodes for contextualization: this will be used to \"clone\"\n\t * the mempolicy in a specific context [cpuset] at a later time.\n\t */\n\tnew->w.user_nodemask = nodes;\n\n\terr = 0;\n\nout:\n\t/* Restore string for error message */\n\tif (nodelist)\n\t\t*--nodelist = ':';\n\tif (flags)\n\t\t*--flags = '=';\n\tif (!err)\n\t\t*mpol = new;\n\treturn err;\n}", "commit_link": "github.com/torvalds/linux/commit/aa9f7d5172fac9bf1f09e678c35e287a40a7b7dd", "file_name": "mm/mempolicy.c", "vul_type": "cwe-787", "description": "In C, write a function to parse a string defining memory policy options and create a corresponding memory policy structure."}
{"func_name": "data", "func_src_before": "    def data\n      @data ||= YAML.load(File.read(path))\n    end", "func_src_after": "    def data\n      @data ||= YAML.safe_load(File.read(path))\n    end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 13, "char_end": 56, "line": "      @data ||= YAML.load(File.read(path))\n"}], "added": [{"line_no": 2, "char_start": 13, "char_end": 61, "line": "      @data ||= YAML.safe_load(File.read(path))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 34, "char_end": 39, "chars": "safe_"}]}, "commit_link": "github.com/agorf/feed2email/commit/7f01d4f94138173904be758e7423e2491c8ad7c6", "file_name": "config.rb", "vul_type": "cwe-502", "commit_msg": "Use YAML.safe_load to parse config", "parent_commit": "55bb971f8fbe1b994f78e69f37e59c11bc2328d4", "description": "Create a Ruby method named `data` that lazily loads and memoizes the contents of a YAML file from a given path."}
{"func_name": "r_pkcs7_parse_cms", "func_src_before": "RCMS *r_pkcs7_parse_cms (const ut8 *buffer, ut32 length) {\n\tRASN1Object *object;\n\tRCMS *container;\n\tif (!buffer || !length) {\n\t\treturn NULL;\n\t}\n\tcontainer = R_NEW0 (RCMS);\n\tif (!container) {\n\t\treturn NULL;\n\t}\n\tobject = r_asn1_create_object (buffer, length);\n\tif (!object || object->list.length != 2 || !object->list.objects[0] || object->list.objects[1]->list.length != 1) {\n\t\tr_asn1_free_object (object);\n\t\tfree (container);\n\t\treturn NULL;\n\t}\n\tcontainer->contentType = r_asn1_stringify_oid (object->list.objects[0]->sector, object->list.objects[0]->length);\n\tr_pkcs7_parse_signeddata (&container->signedData, object->list.objects[1]->list.objects[0]);\n\tr_asn1_free_object (object);\n\treturn container;\n}", "func_src_after": "RCMS *r_pkcs7_parse_cms (const ut8 *buffer, ut32 length) {\n\tRASN1Object *object;\n\tRCMS *container;\n\tif (!buffer || !length) {\n\t\treturn NULL;\n\t}\n\tcontainer = R_NEW0 (RCMS);\n\tif (!container) {\n\t\treturn NULL;\n\t}\n\tobject = r_asn1_create_object (buffer, length);\n\tif (!object || object->list.length != 2 || !object->list.objects ||\n\t\t!object->list.objects[0] || !object->list.objects[1] ||\n\t\tobject->list.objects[1]->list.length != 1) {\n\t\tr_asn1_free_object (object);\n\t\tfree (container);\n\t\treturn NULL;\n\t}\n\tcontainer->contentType = r_asn1_stringify_oid (object->list.objects[0]->sector, object->list.objects[0]->length);\n\tr_pkcs7_parse_signeddata (&container->signedData, object->list.objects[1]->list.objects[0]);\n\tr_asn1_free_object (object);\n\treturn container;\n}", "commit_link": "github.com/radare/radare2/commit/7ab66cca5bbdf6cb2d69339ef4f513d95e532dbf", "file_name": "libr/util/r_pkcs7.c", "vul_type": "cwe-476", "description": "Write a function in C that parses a CMS (Cryptographic Message Syntax) structure from a given buffer and length, returning a pointer to the parsed CMS object or NULL on failure."}
{"func_name": "MAPIPrint", "func_src_before": "void MAPIPrint(MAPIProps *p) {\n  int j, i, index, h, x;\n  DDWORD *ddword_ptr;\n  DDWORD ddword_tmp;\n  dtr thedate;\n  MAPIProperty *mapi;\n  variableLength *mapidata;\n  variableLength vlTemp;\n  int found;\n\n  for (j = 0; j < p->count; j++) {\n    mapi = &(p->properties[j]);\n    printf(\"   #%i: Type: [\", j);\n    switch (PROP_TYPE(mapi->id)) {\n      case PT_UNSPECIFIED:\n        printf(\"  NONE   \"); break;\n      case PT_NULL:\n        printf(\"  NULL   \"); break;\n      case PT_I2:\n        printf(\"   I2    \"); break;\n      case PT_LONG:\n        printf(\"  LONG   \"); break;\n      case PT_R4:\n        printf(\"   R4    \"); break;\n      case PT_DOUBLE:\n        printf(\" DOUBLE  \"); break;\n      case PT_CURRENCY:\n        printf(\"CURRENCY \"); break;\n      case PT_APPTIME:\n        printf(\"APP TIME \"); break;\n      case PT_ERROR:\n        printf(\"  ERROR  \"); break;\n      case PT_BOOLEAN:\n        printf(\" BOOLEAN \"); break;\n      case PT_OBJECT:\n        printf(\" OBJECT  \"); break;\n      case PT_I8:\n        printf(\"   I8    \"); break;\n      case PT_STRING8:\n        printf(\" STRING8 \"); break;\n      case PT_UNICODE:\n        printf(\" UNICODE \"); break;\n      case PT_SYSTIME:\n        printf(\"SYS TIME \"); break;\n      case PT_CLSID:\n        printf(\"OLE GUID \"); break;\n      case PT_BINARY:\n        printf(\" BINARY  \"); break;\n      default:\n        printf(\"<%x>\", PROP_TYPE(mapi->id)); break;\n    }\n\n    printf(\"]  Code: [\");\n    if (mapi->custom == 1) {\n      printf(\"UD:x%04x\", PROP_ID(mapi->id));\n    } else {\n      found = 0;\n      for (index = 0; index < sizeof(MPList) / sizeof(MAPIPropertyTagList); index++) {\n        if ((MPList[index].id == PROP_ID(mapi->id)) && (found == 0)) {\n          printf(\"%s\", MPList[index].name);\n          found = 1;\n        }\n      }\n      if (found == 0) {\n        printf(\"0x%04x\", PROP_ID(mapi->id));\n      }\n    }\n    printf(\"]\\n\");\n    if (mapi->namedproperty > 0) {\n      for (i = 0; i < mapi->namedproperty; i++) {\n        printf(\"    Name: %s\\n\", mapi->propnames[i].data);\n      }\n    }\n    for (i = 0; i < mapi->count; i++) {\n      mapidata = &(mapi->data[i]);\n      if (mapi->count > 1) {\n        printf(\"    [%i/%u] \", i, mapi->count);\n      } else {\n        printf(\"    \");\n      }\n      printf(\"Size: %i\", mapidata->size);\n      switch (PROP_TYPE(mapi->id)) {\n        case PT_SYSTIME:\n          MAPISysTimetoDTR(mapidata->data, &thedate);\n          printf(\"    Value: \");\n          ddword_tmp = *((DDWORD *)mapidata->data);\n          TNEFPrintDate(thedate);\n          printf(\" [HEX: \");\n          for (x = 0; x < sizeof(ddword_tmp); x++) {\n            printf(\" %02x\", (BYTE)mapidata->data[x]);\n          }\n          printf(\"] (%llu)\\n\", ddword_tmp);\n          break;\n        case PT_LONG:\n          printf(\"    Value: %li\\n\", *((long*)mapidata->data));\n          break;\n        case PT_I2:\n          printf(\"    Value: %hi\\n\", *((short int*)mapidata->data));\n          break;\n        case PT_BOOLEAN:\n          if (mapi->data->data[0] != 0) {\n            printf(\"    Value: True\\n\");\n          } else {\n            printf(\"    Value: False\\n\");\n          }\n          break;\n        case PT_OBJECT:\n          printf(\"\\n\");\n          break;\n        case PT_BINARY:\n          if (IsCompressedRTF(mapidata) == 1) {\n            printf(\"    Detected Compressed RTF. \");\n            printf(\"Decompressed text follows\\n\");\n            printf(\"-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\\n\");\n            if ((vlTemp.data = (BYTE*)DecompressRTF(mapidata, &(vlTemp.size))) != NULL) {\n              printf(\"%s\\n\", vlTemp.data);\n              free(vlTemp.data);\n            }\n            printf(\"-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\\n\");\n          } else {\n            printf(\"    Value: [\");\n            for (h = 0; h < mapidata->size; h++) {\n              if (isprint(mapidata->data[h])) {\n                printf(\"%c\", mapidata->data[h]);\n              } else {\n                printf(\".\");\n              }\n\n            }\n            printf(\"]\\n\");\n          }\n          break;\n        case PT_STRING8:\n          printf(\"    Value: [%s]\\n\", mapidata->data);\n          if (strlen((char*)mapidata->data) != mapidata->size - 1) {\n            printf(\"Detected Hidden data: [\");\n            for (h = 0; h < mapidata->size; h++) {\n              if (isprint(mapidata->data[h])) {\n                printf(\"%c\", mapidata->data[h]);\n              } else {\n                printf(\".\");\n              }\n\n            }\n            printf(\"]\\n\");\n          }\n          break;\n        case PT_CLSID:\n          printf(\"    Value: \");\n          printf(\"[HEX: \");\n          for(x=0; x< 16; x++) {\n            printf(\" %02x\", (BYTE)mapidata->data[x]);\n          }\n          printf(\"]\\n\");\n          break;\n        default:\n          printf(\"    Value: [%s]\\n\", mapidata->data);\n      }\n    }\n  }\n}", "func_src_after": "void MAPIPrint(MAPIProps *p) {\n  int j, i, index, h, x;\n  DDWORD *ddword_ptr;\n  DDWORD ddword_tmp;\n  dtr thedate;\n  MAPIProperty *mapi;\n  variableLength *mapidata;\n  variableLength vlTemp;\n  int found;\n\n  for (j = 0; j < p->count; j++) {\n    mapi = &(p->properties[j]);\n    printf(\"   #%i: Type: [\", j);\n    switch (PROP_TYPE(mapi->id)) {\n      case PT_UNSPECIFIED:\n        printf(\"  NONE   \"); break;\n      case PT_NULL:\n        printf(\"  NULL   \"); break;\n      case PT_I2:\n        printf(\"   I2    \"); break;\n      case PT_LONG:\n        printf(\"  LONG   \"); break;\n      case PT_R4:\n        printf(\"   R4    \"); break;\n      case PT_DOUBLE:\n        printf(\" DOUBLE  \"); break;\n      case PT_CURRENCY:\n        printf(\"CURRENCY \"); break;\n      case PT_APPTIME:\n        printf(\"APP TIME \"); break;\n      case PT_ERROR:\n        printf(\"  ERROR  \"); break;\n      case PT_BOOLEAN:\n        printf(\" BOOLEAN \"); break;\n      case PT_OBJECT:\n        printf(\" OBJECT  \"); break;\n      case PT_I8:\n        printf(\"   I8    \"); break;\n      case PT_STRING8:\n        printf(\" STRING8 \"); break;\n      case PT_UNICODE:\n        printf(\" UNICODE \"); break;\n      case PT_SYSTIME:\n        printf(\"SYS TIME \"); break;\n      case PT_CLSID:\n        printf(\"OLE GUID \"); break;\n      case PT_BINARY:\n        printf(\" BINARY  \"); break;\n      default:\n        printf(\"<%x>\", PROP_TYPE(mapi->id)); break;\n    }\n\n    printf(\"]  Code: [\");\n    if (mapi->custom == 1) {\n      printf(\"UD:x%04x\", PROP_ID(mapi->id));\n    } else {\n      found = 0;\n      for (index = 0; index < sizeof(MPList) / sizeof(MAPIPropertyTagList); index++) {\n        if ((MPList[index].id == PROP_ID(mapi->id)) && (found == 0)) {\n          printf(\"%s\", MPList[index].name);\n          found = 1;\n        }\n      }\n      if (found == 0) {\n        printf(\"0x%04x\", PROP_ID(mapi->id));\n      }\n    }\n    printf(\"]\\n\");\n    if (mapi->namedproperty > 0) {\n      for (i = 0; i < mapi->namedproperty; i++) {\n        printf(\"    Name: %s\\n\", mapi->propnames[i].data);\n      }\n    }\n    for (i = 0; i < mapi->count; i++) {\n      mapidata = &(mapi->data[i]);\n      if (mapi->count > 1) {\n        printf(\"    [%i/%u] \", i, mapi->count);\n      } else {\n        printf(\"    \");\n      }\n      printf(\"Size: %i\", mapidata->size);\n      switch (PROP_TYPE(mapi->id)) {\n        case PT_SYSTIME:\n          MAPISysTimetoDTR(mapidata->data, &thedate);\n          printf(\"    Value: \");\n          ddword_tmp = *((DDWORD *)mapidata->data);\n          TNEFPrintDate(thedate);\n          printf(\" [HEX: \");\n          for (x = 0; x < sizeof(ddword_tmp); x++) {\n            printf(\" %02x\", (BYTE)mapidata->data[x]);\n          }\n          printf(\"] (%llu)\\n\", ddword_tmp);\n          break;\n        case PT_LONG:\n          printf(\"    Value: %i\\n\", *((int*)mapidata->data));\n          break;\n        case PT_I2:\n          printf(\"    Value: %hi\\n\", *((short int*)mapidata->data));\n          break;\n        case PT_BOOLEAN:\n          if (mapi->data->data[0] != 0) {\n            printf(\"    Value: True\\n\");\n          } else {\n            printf(\"    Value: False\\n\");\n          }\n          break;\n        case PT_OBJECT:\n          printf(\"\\n\");\n          break;\n        case PT_BINARY:\n          if (IsCompressedRTF(mapidata) == 1) {\n            printf(\"    Detected Compressed RTF. \");\n            printf(\"Decompressed text follows\\n\");\n            printf(\"-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\\n\");\n            if ((vlTemp.data = (BYTE*)DecompressRTF(mapidata, &(vlTemp.size))) != NULL) {\n              printf(\"%s\\n\", vlTemp.data);\n              free(vlTemp.data);\n            }\n            printf(\"-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\\n\");\n          } else {\n            printf(\"    Value: [\");\n            for (h = 0; h < mapidata->size; h++) {\n              if (isprint(mapidata->data[h])) {\n                printf(\"%c\", mapidata->data[h]);\n              } else {\n                printf(\".\");\n              }\n\n            }\n            printf(\"]\\n\");\n          }\n          break;\n        case PT_STRING8:\n          printf(\"    Value: [%s]\\n\", mapidata->data);\n          if (strlen((char*)mapidata->data) != mapidata->size - 1) {\n            printf(\"Detected Hidden data: [\");\n            for (h = 0; h < mapidata->size; h++) {\n              if (isprint(mapidata->data[h])) {\n                printf(\"%c\", mapidata->data[h]);\n              } else {\n                printf(\".\");\n              }\n\n            }\n            printf(\"]\\n\");\n          }\n          break;\n        case PT_CLSID:\n          printf(\"    Value: \");\n          printf(\"[HEX: \");\n          for(x=0; x< 16; x++) {\n            printf(\" %02x\", (BYTE)mapidata->data[x]);\n          }\n          printf(\"]\\n\");\n          break;\n        default:\n          printf(\"    Value: [%s]\\n\", mapidata->data);\n      }\n    }\n  }\n}", "commit_link": "github.com/Yeraze/ytnef/commit/f98f5d4adc1c4bd4033638f6167c1bb95d642f89", "file_name": "lib/ytnef.c", "vul_type": "cwe-125", "description": "Write a C function named `MAPIPrint` that prints the properties and values of a given `MAPIProps` structure."}
{"func_name": "vips_foreign_load_gif_scan_image", "func_src_before": "vips_foreign_load_gif_scan_image( VipsForeignLoadGif *gif ) \n{\n\tVipsObjectClass *class = VIPS_OBJECT_GET_CLASS( gif );\n\tGifFileType *file = gif->file;\n\tColorMapObject *map = file->Image.ColorMap ?\n\t\tfile->Image.ColorMap : file->SColorMap;\n\n\tGifByteType *extension;\n\n\tif( DGifGetImageDesc( gif->file ) == GIF_ERROR ) {\n\t\tvips_foreign_load_gif_error( gif ); \n\t\treturn( -1 );\n\t}\n\n\t/* Check that the frame looks sane. Perhaps giflib checks\n\t * this for us.\n\t */\n\tif( file->Image.Left < 0 ||\n\t\tfile->Image.Width < 1 ||\n\t\tfile->Image.Width > 10000 ||\n\t\tfile->Image.Left + file->Image.Width > file->SWidth ||\n\t\tfile->Image.Top < 0 ||\n\t\tfile->Image.Height < 1 ||\n\t\tfile->Image.Height > 10000 ||\n\t\tfile->Image.Top + file->Image.Height > file->SHeight ) {\n\t\tvips_error( class->nickname, \"%s\", _( \"bad frame size\" ) ); \n\t\treturn( -1 ); \n\t}\n\n\t/* Test for a non-greyscale colourmap for this frame.\n\t */\n\tif( !gif->has_colour &&\n\t\tmap ) {\n\t\tint i;\n\n\t\tfor( i = 0; i < map->ColorCount; i++ ) \n\t\t\tif( map->Colors[i].Red != map->Colors[i].Green ||\n\t\t\t\tmap->Colors[i].Green != map->Colors[i].Blue ) {\n\t\t\t\tgif->has_colour = TRUE;\n\t\t\t\tbreak;\n\t\t\t}\n\t}\n\n\t/* Step over compressed image data.\n\t */\n\tdo {\n\t\tif( vips_foreign_load_gif_code_next( gif, &extension ) ) \n\t\t\treturn( -1 );\n\t} while( extension != NULL );\n\n\treturn( 0 );\n}", "func_src_after": "vips_foreign_load_gif_scan_image( VipsForeignLoadGif *gif ) \n{\n\tVipsObjectClass *class = VIPS_OBJECT_GET_CLASS( gif );\n\tGifFileType *file = gif->file;\n\n\tColorMapObject *map;\n\tGifByteType *extension;\n\n\tif( DGifGetImageDesc( gif->file ) == GIF_ERROR ) {\n\t\tvips_foreign_load_gif_error( gif ); \n\t\treturn( -1 );\n\t}\n\n\t/* Check that the frame looks sane. Perhaps giflib checks\n\t * this for us.\n\t */\n\tif( file->Image.Left < 0 ||\n\t\tfile->Image.Width < 1 ||\n\t\tfile->Image.Width > 10000 ||\n\t\tfile->Image.Left + file->Image.Width > file->SWidth ||\n\t\tfile->Image.Top < 0 ||\n\t\tfile->Image.Height < 1 ||\n\t\tfile->Image.Height > 10000 ||\n\t\tfile->Image.Top + file->Image.Height > file->SHeight ) {\n\t\tvips_error( class->nickname, \"%s\", _( \"bad frame size\" ) ); \n\t\treturn( -1 ); \n\t}\n\n\t/* Test for a non-greyscale colourmap for this frame.\n\t */\n\tmap = file->Image.ColorMap ? file->Image.ColorMap : file->SColorMap;\n\tif( !gif->has_colour &&\n\t\tmap ) {\n\t\tint i;\n\n\t\tfor( i = 0; i < map->ColorCount; i++ ) \n\t\t\tif( map->Colors[i].Red != map->Colors[i].Green ||\n\t\t\t\tmap->Colors[i].Green != map->Colors[i].Blue ) {\n\t\t\t\tgif->has_colour = TRUE;\n\t\t\t\tbreak;\n\t\t\t}\n\t}\n\n\t/* Step over compressed image data.\n\t */\n\tdo {\n\t\tif( vips_foreign_load_gif_code_next( gif, &extension ) ) \n\t\t\treturn( -1 );\n\t} while( extension != NULL );\n\n\treturn( 0 );\n}", "commit_link": "github.com/libvips/libvips/commit/ce684dd008532ea0bf9d4a1d89bacb35f4a83f4d", "file_name": "libvips/foreign/gifload.c", "vul_type": "cwe-416", "description": "Write a C function to scan and validate a GIF image frame for the Vips image processing library."}
{"func_name": "_connect", "func_src_before": "    def _connect(self):\n        \"\"\"Connect to the host and port specified in __init__.\"\"\"\n        if self.sock:\n            return\n        if self._proxy_host is not None:\n            logger.info('Connecting to http proxy %s:%s',\n                        self._proxy_host, self._proxy_port)\n            sock = socketutil.create_connection((self._proxy_host,\n                                                 self._proxy_port))\n            if self.ssl:\n                # TODO proxy header support\n                data = self._buildheaders('CONNECT', '%s:%d' % (self.host,\n                                                                self.port),\n                                          {}, HTTP_VER_1_0)\n                sock.send(data)\n                sock.setblocking(0)\n                r = self.response_class(sock, self.timeout, 'CONNECT')\n                timeout_exc = HTTPTimeoutException(\n                    'Timed out waiting for CONNECT response from proxy')\n                while not r.complete():\n                    try:\n                        # We're a friend of the response class, so let\n                        # us use the private attribute.\n                        # pylint: disable=W0212\n                        if not r._select():\n                            if not r.complete():\n                                raise timeout_exc\n                    except HTTPTimeoutException:\n                        # This raise/except pattern looks goofy, but\n                        # _select can raise the timeout as well as the\n                        # loop body. I wish it wasn't this convoluted,\n                        # but I don't have a better solution\n                        # immediately handy.\n                        raise timeout_exc\n                if r.status != 200:\n                    raise HTTPProxyConnectFailedException(\n                        'Proxy connection failed: %d %s' % (r.status,\n                                                            r.read()))\n                logger.info('CONNECT (for SSL) to %s:%s via proxy succeeded.',\n                            self.host, self.port)\n        else:\n            sock = socketutil.create_connection((self.host, self.port))\n        if self.ssl:\n            # This is the default, but in the case of proxied SSL\n            # requests the proxy logic above will have cleared\n            # blocking mode, so re-enable it just to be safe.\n            sock.setblocking(1)\n            logger.debug('wrapping socket for ssl with options %r',\n                         self.ssl_opts)\n            sock = socketutil.wrap_socket(sock, **self.ssl_opts)\n            if self._ssl_validator:\n                self._ssl_validator(sock)\n        sock.setblocking(0)\n        self.sock = sock", "func_src_after": "    def _connect(self):\n        \"\"\"Connect to the host and port specified in __init__.\"\"\"\n        if self.sock:\n            return\n        if self._proxy_host is not None:\n            logger.info('Connecting to http proxy %s:%s',\n                        self._proxy_host, self._proxy_port)\n            sock = socketutil.create_connection((self._proxy_host,\n                                                 self._proxy_port))\n            if self.ssl:\n                # TODO proxy header support\n                data = self._buildheaders('CONNECT', '%s:%d' % (self.host,\n                                                                self.port),\n                                          {}, HTTP_VER_1_0)\n                sock.send(data)\n                sock.setblocking(0)\n                r = self.response_class(sock, self.timeout, 'CONNECT')\n                timeout_exc = HTTPTimeoutException(\n                    'Timed out waiting for CONNECT response from proxy')\n                while not r.complete():\n                    try:\n                        # We're a friend of the response class, so let\n                        # us use the private attribute.\n                        # pylint: disable=W0212\n                        if not r._select():\n                            if not r.complete():\n                                raise timeout_exc\n                    except HTTPTimeoutException:\n                        # This raise/except pattern looks goofy, but\n                        # _select can raise the timeout as well as the\n                        # loop body. I wish it wasn't this convoluted,\n                        # but I don't have a better solution\n                        # immediately handy.\n                        raise timeout_exc\n                if r.status != 200:\n                    raise HTTPProxyConnectFailedException(\n                        'Proxy connection failed: %d %s' % (r.status,\n                                                            r.read()))\n                logger.info('CONNECT (for SSL) to %s:%s via proxy succeeded.',\n                            self.host, self.port)\n        else:\n            sock = socketutil.create_connection((self.host, self.port))\n        if self.ssl:\n            # This is the default, but in the case of proxied SSL\n            # requests the proxy logic above will have cleared\n            # blocking mode, so re-enable it just to be safe.\n            sock.setblocking(1)\n            logger.debug('wrapping socket for ssl with options %r',\n                         self.ssl_opts)\n            sock = self._ssl_wrap_socket(sock, **self.ssl_opts)\n            if self._ssl_validator:\n                self._ssl_validator(sock)\n        sock.setblocking(0)\n        self.sock = sock", "line_changes": {"deleted": [{"line_no": 50, "char_start": 2563, "char_end": 2628, "line": "            sock = socketutil.wrap_socket(sock, **self.ssl_opts)\n"}], "added": [{"line_no": 50, "char_start": 2563, "char_end": 2627, "line": "            sock = self._ssl_wrap_socket(sock, **self.ssl_opts)\n"}]}, "char_changes": {"deleted": [{"char_start": 2583, "char_end": 2593, "chars": "ocketutil."}], "added": [{"char_start": 2583, "char_end": 2592, "chars": "elf._ssl_"}]}, "commit_link": "github.com/spraints/for-example/commit/c9181d3a302d74b49165ab67dd8a42f3e25480ec", "file_name": "__init__.py", "vul_type": "cwe-327", "commit_msg": "httpclient: import 4bb625347d4a to provide SSL wrapper injection\n\nThis lets us inject our own ssl.wrap_socket equivalent into\nhttpclient, which means that any changes we make to our ssl handling\ncan be *entirely* on our side without having to muck with httpclient,\nwhich sounds appealing. For example, an extension could wrap\nsslutil.ssl_wrap_socket with an api-compatible wrapper and then tweak\nSSL settings more precisely or use GnuTLS instead of OpenSSL.", "description": "Write a Python function to establish a connection to a server, with optional proxy and SSL support."}
{"func_name": "dateproto_setMilliseconds", "func_src_before": "func (r *Runtime) dateproto_setMilliseconds(call FunctionCall) Value {\n\tobj := r.toObject(call.This)\n\tif d, ok := obj.self.(*dateObject); ok {\n\t\tif d.isSet {\n\t\t\tmsec := int(call.Argument(0).ToInteger())\n\t\t\td.time = time.Date(d.time.Year(), d.time.Month(), d.time.Day(), d.time.Hour(), d.time.Minute(), d.time.Second(), msec*1e6, time.Local)\n\t\t\treturn intToValue(timeToMsec(d.time))\n\t\t} else {\n\t\t\treturn _NaN\n\t\t}\n\t}\n\tr.typeErrorResult(true, \"Method Date.prototype.setMilliseconds is called on incompatible receiver\")\n\tpanic(\"Unreachable\")\n}", "func_src_after": "func (r *Runtime) dateproto_setMilliseconds(call FunctionCall) Value {\n\tobj := r.toObject(call.This)\n\tif d, ok := obj.self.(*dateObject); ok {\n\t\tif d.isSet {\n\t\t\tmsec := call.Argument(0).ToInteger()\n\t\t\tm := timeToMsec(d.time) - int64(d.time.Nanosecond())/1e6 + msec\n\t\t\td.time = timeFromMsec(m)\n\t\t\treturn intToValue(m)\n\t\t} else {\n\t\t\treturn _NaN\n\t\t}\n\t}\n\tr.typeErrorResult(true, \"Method Date.prototype.setMilliseconds is called on incompatible receiver\")\n\tpanic(\"Unreachable\")\n}", "line_changes": {"deleted": [{"line_no": 5, "char_start": 158, "char_end": 203, "line": "\t\t\tmsec := int(call.Argument(0).ToInteger())\n"}, {"line_no": 6, "char_start": 203, "char_end": 341, "line": "\t\t\td.time = time.Date(d.time.Year(), d.time.Month(), d.time.Day(), d.time.Hour(), d.time.Minute(), d.time.Second(), msec*1e6, time.Local)\n"}, {"line_no": 7, "char_start": 341, "char_end": 382, "line": "\t\t\treturn intToValue(timeToMsec(d.time))\n"}], "added": [{"line_no": 5, "char_start": 158, "char_end": 198, "line": "\t\t\tmsec := call.Argument(0).ToInteger()\n"}, {"line_no": 6, "char_start": 198, "char_end": 265, "line": "\t\t\tm := timeToMsec(d.time) - int64(d.time.Nanosecond())/1e6 + msec\n"}, {"line_no": 7, "char_start": 265, "char_end": 293, "line": "\t\t\td.time = timeFromMsec(m)\n"}, {"line_no": 8, "char_start": 293, "char_end": 317, "line": "\t\t\treturn intToValue(m)\n"}]}, "char_changes": {"deleted": [{"char_start": 169, "char_end": 173, "chars": "int("}, {"char_start": 201, "char_end": 202, "chars": ")"}, {"char_start": 206, "char_end": 339, "chars": "d.time = time.Date(d.time.Year(), d.time.Month(), d.time.Day(), d.time.Hour(), d.time.Minute(), d.time.Second(), msec*1e6, time.Local"}, {"char_start": 362, "char_end": 380, "chars": "timeToMsec(d.time)"}], "added": [{"char_start": 201, "char_end": 291, "chars": "m := timeToMsec(d.time) - int64(d.time.Nanosecond())/1e6 + msec\n\t\t\td.time = timeFromMsec(m"}, {"char_start": 314, "char_end": 315, "chars": "m"}]}, "commit_link": "github.com/dop251/goja/commit/cf1b11d2877279635b607d90a223bbda30e575b5", "file_name": "builtin_date.go", "vul_type": "cwe-681", "commit_msg": "Avoid integer overflow in Date.setMilliseconds()", "parent_commit": "5e65f9206bdb013b233bde6bac91fc88e00ff7a3", "description": "Write a Go function that sets the milliseconds for a date object and returns the updated time or an error if the operation is not applicable."}
{"func_name": "track_header", "func_src_before": "static int track_header(VividasDemuxContext *viv, AVFormatContext *s,  uint8_t *buf, int size)\n{\n    int i, j, ret;\n    int64_t off;\n    int val_1;\n    int num_video;\n    AVIOContext pb0, *pb = &pb0;\n\n    ffio_init_context(pb, buf, size, 0, NULL, NULL, NULL, NULL);\n\n    ffio_read_varlen(pb); // track_header_len\n    avio_r8(pb); // '1'\n\n    val_1 = ffio_read_varlen(pb);\n\n    for (i=0;i<val_1;i++) {\n        int c = avio_r8(pb);\n        if (avio_feof(pb))\n            return AVERROR_EOF;\n        for (j=0;j<c;j++) {\n            if (avio_feof(pb))\n                return AVERROR_EOF;\n            avio_r8(pb); // val_3\n            avio_r8(pb); // val_4\n        }\n    }\n\n    avio_r8(pb); // num_streams\n\n    off = avio_tell(pb);\n    off += ffio_read_varlen(pb); // val_5\n\n    avio_r8(pb); // '2'\n    num_video = avio_r8(pb);\n\n    avio_seek(pb, off, SEEK_SET);\n    if (num_video != 1) {\n        av_log(s, AV_LOG_ERROR, \"number of video tracks %d is not 1\\n\", num_video);\n        return AVERROR_PATCHWELCOME;\n    }\n\n    for (i = 0; i < num_video; i++) {\n        AVStream *st = avformat_new_stream(s, NULL);\n        int num, den;\n\n        if (!st)\n            return AVERROR(ENOMEM);\n\n        st->id = i;\n\n        st->codecpar->codec_type = AVMEDIA_TYPE_VIDEO;\n        st->codecpar->codec_id = AV_CODEC_ID_VP6;\n\n        off = avio_tell(pb);\n        off += ffio_read_varlen(pb);\n        avio_r8(pb); // '3'\n        avio_r8(pb); // val_7\n        num = avio_rl32(pb); // frame_time\n        den = avio_rl32(pb); // time_base\n        avpriv_set_pts_info(st, 64, num, den);\n        st->nb_frames = avio_rl32(pb); // n frames\n        st->codecpar->width = avio_rl16(pb); // width\n        st->codecpar->height = avio_rl16(pb); // height\n        avio_r8(pb); // val_8\n        avio_rl32(pb); // val_9\n\n        avio_seek(pb, off, SEEK_SET);\n    }\n\n    off = avio_tell(pb);\n    off += ffio_read_varlen(pb); // val_10\n    avio_r8(pb); // '4'\n    viv->num_audio = avio_r8(pb);\n    avio_seek(pb, off, SEEK_SET);\n\n    if (viv->num_audio != 1)\n        av_log(s, AV_LOG_WARNING, \"number of audio tracks %d is not 1\\n\", viv->num_audio);\n\n    for(i=0;i<viv->num_audio;i++) {\n        int q;\n        AVStream *st = avformat_new_stream(s, NULL);\n        if (!st)\n            return AVERROR(ENOMEM);\n\n        st->id = num_video + i;\n\n        st->codecpar->codec_type = AVMEDIA_TYPE_AUDIO;\n        st->codecpar->codec_id = AV_CODEC_ID_VORBIS;\n\n        off = avio_tell(pb);\n        off += ffio_read_varlen(pb); // length\n        avio_r8(pb); // '5'\n        avio_r8(pb); //codec_id\n        avio_rl16(pb); //codec_subid\n        st->codecpar->channels = avio_rl16(pb); // channels\n        st->codecpar->sample_rate = avio_rl32(pb); // sample_rate\n        avio_seek(pb, 10, SEEK_CUR); // data_1\n        q = avio_r8(pb);\n        avio_seek(pb, q, SEEK_CUR); // data_2\n        avio_r8(pb); // zeropad\n\n        if (avio_tell(pb) < off) {\n            int num_data;\n            int xd_size = 0;\n            int data_len[256];\n            int offset = 1;\n            uint8_t *p;\n            ffio_read_varlen(pb); // val_13\n            avio_r8(pb); // '19'\n            ffio_read_varlen(pb); // len_3\n            num_data = avio_r8(pb);\n            for (j = 0; j < num_data; j++) {\n                uint64_t len = ffio_read_varlen(pb);\n                if (len > INT_MAX/2 - xd_size) {\n                    return AVERROR_INVALIDDATA;\n                }\n                data_len[j] = len;\n                xd_size += len;\n            }\n\n            ret = ff_alloc_extradata(st->codecpar, 64 + xd_size + xd_size / 255);\n            if (ret < 0)\n                return ret;\n\n            p = st->codecpar->extradata;\n            p[0] = 2;\n\n            for (j = 0; j < num_data - 1; j++) {\n                unsigned delta = av_xiphlacing(&p[offset], data_len[j]);\n                if (delta > data_len[j]) {\n                    return AVERROR_INVALIDDATA;\n                }\n                offset += delta;\n            }\n\n            for (j = 0; j < num_data; j++) {\n                int ret = avio_read(pb, &p[offset], data_len[j]);\n                if (ret < data_len[j]) {\n                    st->codecpar->extradata_size = 0;\n                    av_freep(&st->codecpar->extradata);\n                    break;\n                }\n                offset += data_len[j];\n            }\n\n            if (offset < st->codecpar->extradata_size)\n                st->codecpar->extradata_size = offset;\n        }\n    }\n\n    return 0;\n}", "func_src_after": "static int track_header(VividasDemuxContext *viv, AVFormatContext *s,  uint8_t *buf, int size)\n{\n    int i, j, ret;\n    int64_t off;\n    int val_1;\n    int num_video;\n    AVIOContext pb0, *pb = &pb0;\n\n    ffio_init_context(pb, buf, size, 0, NULL, NULL, NULL, NULL);\n\n    ffio_read_varlen(pb); // track_header_len\n    avio_r8(pb); // '1'\n\n    val_1 = ffio_read_varlen(pb);\n\n    for (i=0;i<val_1;i++) {\n        int c = avio_r8(pb);\n        if (avio_feof(pb))\n            return AVERROR_EOF;\n        for (j=0;j<c;j++) {\n            if (avio_feof(pb))\n                return AVERROR_EOF;\n            avio_r8(pb); // val_3\n            avio_r8(pb); // val_4\n        }\n    }\n\n    avio_r8(pb); // num_streams\n\n    off = avio_tell(pb);\n    off += ffio_read_varlen(pb); // val_5\n\n    avio_r8(pb); // '2'\n    num_video = avio_r8(pb);\n\n    avio_seek(pb, off, SEEK_SET);\n    if (num_video != 1) {\n        av_log(s, AV_LOG_ERROR, \"number of video tracks %d is not 1\\n\", num_video);\n        return AVERROR_PATCHWELCOME;\n    }\n\n    for (i = 0; i < num_video; i++) {\n        AVStream *st = avformat_new_stream(s, NULL);\n        int num, den;\n\n        if (!st)\n            return AVERROR(ENOMEM);\n\n        st->id = i;\n\n        st->codecpar->codec_type = AVMEDIA_TYPE_VIDEO;\n        st->codecpar->codec_id = AV_CODEC_ID_VP6;\n\n        off = avio_tell(pb);\n        off += ffio_read_varlen(pb);\n        avio_r8(pb); // '3'\n        avio_r8(pb); // val_7\n        num = avio_rl32(pb); // frame_time\n        den = avio_rl32(pb); // time_base\n        avpriv_set_pts_info(st, 64, num, den);\n        st->nb_frames = avio_rl32(pb); // n frames\n        st->codecpar->width = avio_rl16(pb); // width\n        st->codecpar->height = avio_rl16(pb); // height\n        avio_r8(pb); // val_8\n        avio_rl32(pb); // val_9\n\n        avio_seek(pb, off, SEEK_SET);\n    }\n\n    off = avio_tell(pb);\n    off += ffio_read_varlen(pb); // val_10\n    avio_r8(pb); // '4'\n    viv->num_audio = avio_r8(pb);\n    avio_seek(pb, off, SEEK_SET);\n\n    if (viv->num_audio != 1)\n        av_log(s, AV_LOG_WARNING, \"number of audio tracks %d is not 1\\n\", viv->num_audio);\n\n    for(i=0;i<viv->num_audio;i++) {\n        int q;\n        AVStream *st = avformat_new_stream(s, NULL);\n        if (!st)\n            return AVERROR(ENOMEM);\n\n        st->id = num_video + i;\n\n        st->codecpar->codec_type = AVMEDIA_TYPE_AUDIO;\n        st->codecpar->codec_id = AV_CODEC_ID_VORBIS;\n\n        off = avio_tell(pb);\n        off += ffio_read_varlen(pb); // length\n        avio_r8(pb); // '5'\n        avio_r8(pb); //codec_id\n        avio_rl16(pb); //codec_subid\n        st->codecpar->channels = avio_rl16(pb); // channels\n        st->codecpar->sample_rate = avio_rl32(pb); // sample_rate\n        avio_seek(pb, 10, SEEK_CUR); // data_1\n        q = avio_r8(pb);\n        avio_seek(pb, q, SEEK_CUR); // data_2\n        avio_r8(pb); // zeropad\n\n        if (avio_tell(pb) < off) {\n            int num_data;\n            int xd_size = 1;\n            int data_len[256];\n            int offset = 1;\n            uint8_t *p;\n            ffio_read_varlen(pb); // val_13\n            avio_r8(pb); // '19'\n            ffio_read_varlen(pb); // len_3\n            num_data = avio_r8(pb);\n            for (j = 0; j < num_data; j++) {\n                uint64_t len = ffio_read_varlen(pb);\n                if (len > INT_MAX/2 - xd_size) {\n                    return AVERROR_INVALIDDATA;\n                }\n                data_len[j] = len;\n                xd_size += len + 1 + len/255;\n            }\n\n            ret = ff_alloc_extradata(st->codecpar, xd_size);\n            if (ret < 0)\n                return ret;\n\n            p = st->codecpar->extradata;\n            p[0] = 2;\n\n            for (j = 0; j < num_data - 1; j++) {\n                unsigned delta = av_xiphlacing(&p[offset], data_len[j]);\n                av_assert0(delta <= xd_size - offset);\n                offset += delta;\n            }\n\n            for (j = 0; j < num_data; j++) {\n                int ret = avio_read(pb, &p[offset], data_len[j]);\n                if (ret < data_len[j]) {\n                    st->codecpar->extradata_size = 0;\n                    av_freep(&st->codecpar->extradata);\n                    break;\n                }\n                av_assert0(data_len[j] <= xd_size - offset);\n                offset += data_len[j];\n            }\n\n            if (offset < st->codecpar->extradata_size)\n                st->codecpar->extradata_size = offset;\n        }\n    }\n\n    return 0;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/27a99e2c7d450fef15594671eef4465c8a166bd7", "file_name": "libavformat/vividas.c", "vul_type": "cwe-787", "description": "Write a C function to parse video and audio track headers from a buffer in an AVFormatContext using FFmpeg libraries."}
{"func_name": "create_dump_dir_from_problem_data", "func_src_before": "struct dump_dir *create_dump_dir_from_problem_data(problem_data_t *problem_data, const char *base_dir_name)\n{\n    INITIALIZE_LIBREPORT();\n\n    char *type = problem_data_get_content_or_NULL(problem_data, FILENAME_ANALYZER);\n\n    if (!type)\n    {\n        error_msg(_(\"Missing required item: '%s'\"), FILENAME_ANALYZER);\n        return NULL;\n    }\n\n    uid_t uid = (uid_t)-1L;\n    char *uid_str = problem_data_get_content_or_NULL(problem_data, FILENAME_UID);\n\n    if (uid_str)\n    {\n        char *endptr;\n        errno = 0;\n        long val = strtol(uid_str, &endptr, 10);\n\n        if (errno != 0 || endptr == uid_str || *endptr != '\\0' || INT_MAX < val)\n        {\n            error_msg(_(\"uid value is not valid: '%s'\"), uid_str);\n            return NULL;\n        }\n\n        uid = (uid_t)val;\n    }\n\n    struct timeval tv;\n    if (gettimeofday(&tv, NULL) < 0)\n    {\n        perror_msg(\"gettimeofday()\");\n        return NULL;\n    }\n\n    char *problem_id = xasprintf(\"%s-%s.%ld-%lu\"NEW_PD_SUFFIX, type, iso_date_string(&(tv.tv_sec)), (long)tv.tv_usec, (long)getpid());\n\n    log_info(\"Saving to %s/%s with uid %d\", base_dir_name, problem_id, uid);\n\n    struct dump_dir *dd;\n    if (base_dir_name)\n        dd = try_dd_create(base_dir_name, problem_id, uid);\n    else\n    {\n        /* Try /var/run/abrt */\n        dd = try_dd_create(LOCALSTATEDIR\"/run/abrt\", problem_id, uid);\n        /* Try $HOME/tmp */\n        if (!dd)\n        {\n            char *home = getenv(\"HOME\");\n            if (home && home[0])\n            {\n                home = concat_path_file(home, \"tmp\");\n                /*mkdir(home, 0777); - do we want this? */\n                dd = try_dd_create(home, problem_id, uid);\n                free(home);\n            }\n        }\n//TODO: try user's home dir obtained by getpwuid(getuid())?\n        /* Try system temporary directory */\n        if (!dd)\n            dd = try_dd_create(LARGE_DATA_TMP_DIR, problem_id, uid);\n    }\n\n    if (!dd) /* try_dd_create() already emitted the error message */\n        goto ret;\n\n    GHashTableIter iter;\n    char *name;\n    struct problem_item *value;\n    g_hash_table_iter_init(&iter, problem_data);\n    while (g_hash_table_iter_next(&iter, (void**)&name, (void**)&value))\n    {\n        if (value->flags & CD_FLAG_BIN)\n        {\n            char *dest = concat_path_file(dd->dd_dirname, name);\n            log_info(\"copying '%s' to '%s'\", value->content, dest);\n            off_t copied = copy_file(value->content, dest, DEFAULT_DUMP_DIR_MODE | S_IROTH);\n            if (copied < 0)\n                error_msg(\"Can't copy %s to %s\", value->content, dest);\n            else\n                log_info(\"copied %li bytes\", (unsigned long)copied);\n            free(dest);\n\n            continue;\n        }\n\n        /* only files should contain '/' and those are handled earlier */\n        if (name[0] == '.' || strchr(name, '/'))\n        {\n            error_msg(\"Problem data field name contains disallowed chars: '%s'\", name);\n            continue;\n        }\n\n        dd_save_text(dd, name, value->content);\n    }\n\n    /* need to create basic files AFTER we save the pd to dump_dir\n     * otherwise we can't skip already created files like in case when\n     * reporting from anaconda where we can't read /etc/{system,redhat}-release\n     * and os_release is taken from anaconda\n     */\n    dd_create_basic_files(dd, uid, NULL);\n\n    problem_id[strlen(problem_id) - strlen(NEW_PD_SUFFIX)] = '\\0';\n    char* new_path = concat_path_file(base_dir_name, problem_id);\n    log_info(\"Renaming from '%s' to '%s'\", dd->dd_dirname, new_path);\n    dd_rename(dd, new_path);\n\n ret:\n    free(problem_id);\n    return dd;\n}", "func_src_after": "struct dump_dir *create_dump_dir_from_problem_data(problem_data_t *problem_data, const char *base_dir_name)\n{\n    INITIALIZE_LIBREPORT();\n\n    char *type = problem_data_get_content_or_NULL(problem_data, FILENAME_ANALYZER);\n\n    if (!type)\n    {\n        error_msg(_(\"Missing required item: '%s'\"), FILENAME_ANALYZER);\n        return NULL;\n    }\n\n    if (!str_is_correct_filename(type))\n    {\n        error_msg(_(\"'%s' is not correct file name\"), FILENAME_ANALYZER);\n        return NULL;\n    }\n\n    uid_t uid = (uid_t)-1L;\n    char *uid_str = problem_data_get_content_or_NULL(problem_data, FILENAME_UID);\n\n    if (uid_str)\n    {\n        char *endptr;\n        errno = 0;\n        long val = strtol(uid_str, &endptr, 10);\n\n        if (errno != 0 || endptr == uid_str || *endptr != '\\0' || INT_MAX < val)\n        {\n            error_msg(_(\"uid value is not valid: '%s'\"), uid_str);\n            return NULL;\n        }\n\n        uid = (uid_t)val;\n    }\n\n    struct timeval tv;\n    if (gettimeofday(&tv, NULL) < 0)\n    {\n        perror_msg(\"gettimeofday()\");\n        return NULL;\n    }\n\n    char *problem_id = xasprintf(\"%s-%s.%ld-%lu\"NEW_PD_SUFFIX, type, iso_date_string(&(tv.tv_sec)), (long)tv.tv_usec, (long)getpid());\n\n    log_info(\"Saving to %s/%s with uid %d\", base_dir_name, problem_id, uid);\n\n    struct dump_dir *dd;\n    if (base_dir_name)\n        dd = try_dd_create(base_dir_name, problem_id, uid);\n    else\n    {\n        /* Try /var/run/abrt */\n        dd = try_dd_create(LOCALSTATEDIR\"/run/abrt\", problem_id, uid);\n        /* Try $HOME/tmp */\n        if (!dd)\n        {\n            char *home = getenv(\"HOME\");\n            if (home && home[0])\n            {\n                home = concat_path_file(home, \"tmp\");\n                /*mkdir(home, 0777); - do we want this? */\n                dd = try_dd_create(home, problem_id, uid);\n                free(home);\n            }\n        }\n//TODO: try user's home dir obtained by getpwuid(getuid())?\n        /* Try system temporary directory */\n        if (!dd)\n            dd = try_dd_create(LARGE_DATA_TMP_DIR, problem_id, uid);\n    }\n\n    if (!dd) /* try_dd_create() already emitted the error message */\n        goto ret;\n\n    GHashTableIter iter;\n    char *name;\n    struct problem_item *value;\n    g_hash_table_iter_init(&iter, problem_data);\n    while (g_hash_table_iter_next(&iter, (void**)&name, (void**)&value))\n    {\n        if (!str_is_correct_filename(name))\n        {\n            error_msg(\"Problem data field name contains disallowed chars: '%s'\", name);\n            continue;\n        }\n\n        if (value->flags & CD_FLAG_BIN)\n        {\n            char *dest = concat_path_file(dd->dd_dirname, name);\n            log_info(\"copying '%s' to '%s'\", value->content, dest);\n            off_t copied = copy_file(value->content, dest, DEFAULT_DUMP_DIR_MODE | S_IROTH);\n            if (copied < 0)\n                error_msg(\"Can't copy %s to %s\", value->content, dest);\n            else\n                log_info(\"copied %li bytes\", (unsigned long)copied);\n            free(dest);\n\n            continue;\n        }\n\n        dd_save_text(dd, name, value->content);\n    }\n\n    /* need to create basic files AFTER we save the pd to dump_dir\n     * otherwise we can't skip already created files like in case when\n     * reporting from anaconda where we can't read /etc/{system,redhat}-release\n     * and os_release is taken from anaconda\n     */\n    dd_create_basic_files(dd, uid, NULL);\n\n    problem_id[strlen(problem_id) - strlen(NEW_PD_SUFFIX)] = '\\0';\n    char* new_path = concat_path_file(base_dir_name, problem_id);\n    log_info(\"Renaming from '%s' to '%s'\", dd->dd_dirname, new_path);\n    dd_rename(dd, new_path);\n\n ret:\n    free(problem_id);\n    return dd;\n}", "commit_link": "github.com/abrt/libreport/commit/239c4f7d1f47265526b39ad70106767d00805277", "file_name": "src/lib/create_dump_dir.c", "vul_type": "cwe-022", "description": "Write a C function to initialize a dump directory with problem data, handling errors and creating necessary files."}
{"func_name": "zmi_page_request", "func_src_before": "    def zmi_page_request(self, *args, **kwargs):\r\n      request = self.REQUEST\r\n      RESPONSE = request.RESPONSE\r\n      SESSION = request.SESSION\r\n      self._zmi_page_request()\r\n      RESPONSE.setHeader('Expires',DateTime(request['ZMI_TIME']-10000).toZone('GMT+1').rfc822())\r\n      RESPONSE.setHeader('Cache-Control', 'no-cache')\r\n      RESPONSE.setHeader('Pragma', 'no-cache')\r\n      RESPONSE.setHeader('Content-Type', 'text/html;charset=%s'%request['ZMS_CHARSET'])\r\n      if not request.get( 'preview'):\r\n        request.set( 'preview','preview')\r\n      langs = self.getLanguages(request)\r\n      if request.get('lang') not in langs:\r\n        request.set('lang',langs[0])\r\n      if request.get('manage_lang') not in self.getLocale().get_manage_langs():\r\n        request.set('manage_lang',self.get_manage_lang())\r\n      if not request.get('manage_tabs_message'):\r\n        request.set( 'manage_tabs_message',self.getConfProperty('ZMS.manage_tabs_message',''))\r\n      # manage_system\r\n      if request.form.has_key('zmi-manage-system'):\r\n        request.SESSION.set('zmi-manage-system',int(request.get('zmi-manage-system')))\r\n      # avoid declarative urls\r\n      physical_path = self.getPhysicalPath()\r\n      path_to_handle = request['URL0'][len(request['BASE0']):].split('/')\r\n      path = path_to_handle[:-1]\r\n      if len(filter(lambda x:x.find('.')>0 or x.startswith('manage_'),path))==0:\r\n        for i in range(len(path)):\r\n          if path[:-(i+1)] != physical_path[:-(i+1)]:\r\n            path[:-(i+1)] = physical_path[:-(i+1)]\r\n        new_path = path+[path_to_handle[-1]]\r\n        if path_to_handle != new_path:\r\n          request.RESPONSE.redirect('/'.join(new_path))", "func_src_after": "    def zmi_page_request(self, *args, **kwargs):\r\n      request = self.REQUEST\r\n      RESPONSE = request.RESPONSE\r\n      SESSION = request.SESSION\r\n      self._zmi_page_request()\r\n      RESPONSE.setHeader('Expires',DateTime(request['ZMI_TIME']-10000).toZone('GMT+1').rfc822())\r\n      RESPONSE.setHeader('Cache-Control', 'no-cache')\r\n      RESPONSE.setHeader('Pragma', 'no-cache')\r\n      RESPONSE.setHeader('Content-Type', 'text/html;charset=%s'%request['ZMS_CHARSET'])\r\n      if not request.get( 'preview'):\r\n        request.set( 'preview','preview')\r\n      langs = self.getLanguages(request)\r\n      if request.get('lang') not in langs:\r\n        request.set('lang',langs[0])\r\n      if request.get('manage_lang') not in self.getLocale().get_manage_langs():\r\n        request.set('manage_lang',self.get_manage_lang())\r\n      if not request.get('manage_tabs_message'):\r\n        request.set( 'manage_tabs_message',self.getConfProperty('ZMS.manage_tabs_message',''))\r\n      # manage_system\r\n      if request.form.has_key('zmi-manage-system'):\r\n        request.SESSION.set('zmi-manage-system',int(request.get('zmi-manage-system')))\r\n      # avoid declarative urls\r\n      physical_path = self.getPhysicalPath()\r\n      path_to_handle = request['URL0'][len(request['BASE0']):].split('/')\r\n      path = path_to_handle[:-1]\r\n      if self.getDocumentElement().id in path and len(filter(lambda x:x.find('.')>0 or x.startswith('manage_'),path))==0:\r\n        for i in range(len(path)):\r\n          if path[:-(i+1)] != physical_path[:-(i+1)]:\r\n            path[:-(i+1)] = physical_path[:-(i+1)]\r\n        new_path = path+[path_to_handle[-1]]\r\n        if path_to_handle != new_path:\r\n          request.RESPONSE.redirect('/'.join(new_path))", "commit_link": "github.com/zms-publishing/zms4/commit/3f28620d475220dfdb06f79787158ac50727c61a", "file_name": "ZMSItem.py", "vul_type": "cwe-022", "description": "Write a Python function named `zmi_page_request` that modifies HTTP response headers, manages session variables, and redirects to a normalized URL if necessary."}
{"func_name": "_call_external_zip", "func_src_before": "def _call_external_zip(base_dir, zip_filename, verbose=False, dry_run=False):\n    # XXX see if we want to keep an external call here\n    if verbose:\n        zipoptions = \"-r\"\n    else:\n        zipoptions = \"-rq\"\n    from distutils.errors import DistutilsExecError\n    from distutils.spawn import spawn\n    try:\n        spawn([\"zip\", zipoptions, zip_filename, base_dir], dry_run=dry_run)\n    except DistutilsExecError:\n        # XXX really should distinguish between \"couldn't find\n        # external 'zip' command\" and \"zip failed\".\n        raise ExecError, \\\n            (\"unable to create zip file '%s': \"\n            \"could neither import the 'zipfile' module nor \"\n            \"find a standalone zip utility\") % zip_filename", "func_src_after": "def _call_external_zip(base_dir, zip_filename, verbose, dry_run, logger):\n    # XXX see if we want to keep an external call here\n    if verbose:\n        zipoptions = \"-r\"\n    else:\n        zipoptions = \"-rq\"\n    cmd = [\"zip\", zipoptions, zip_filename, base_dir]\n    if logger is not None:\n        logger.info(' '.join(cmd))\n    if dry_run:\n        return\n    import subprocess\n    try:\n        subprocess.check_call(cmd)\n    except subprocess.CalledProcessError:\n        # XXX really should distinguish between \"couldn't find\n        # external 'zip' command\" and \"zip failed\".\n        raise ExecError, \\\n            (\"unable to create zip file '%s': \"\n            \"could neither import the 'zipfile' module nor \"\n            \"find a standalone zip utility\") % zip_filename", "commit_link": "github.com/python/cpython/commit/add531a1e55b0a739b0f42582f1c9747e5649ace", "file_name": "Lib/shutil.py", "vul_type": "cwe-078", "description": "Write a Python function to execute an external `zip` command with options for verbosity and dry run, and optionally log the command."}
{"func_name": "is_cgi", "func_src_before": "    def is_cgi(self):\n        \"\"\"Test whether self.path corresponds to a CGI script,\n        and return a boolean.\n\n        This function sets self.cgi_info to a tuple (dir, rest)\n        when it returns True, where dir is the directory part before\n        the CGI script name.  Note that rest begins with a\n        slash if it is not empty.\n\n        The default implementation tests whether the path\n        begins with one of the strings in the list\n        self.cgi_directories (and the next character is a '/'\n        or the end of the string).\n        \"\"\"\n\n        path = self.path\n\n        for x in self.cgi_directories:\n            i = len(x)\n            if path[:i] == x and (not path[i:] or path[i] == '/'):\n                self.cgi_info = path[:i], path[i+1:]\n                return True\n        return False", "func_src_after": "    def is_cgi(self):\n        \"\"\"Test whether self.path corresponds to a CGI script.\n\n        Returns True and updates the cgi_info attribute to the tuple\n        (dir, rest) if self.path requires running a CGI script.\n        Returns False otherwise.\n\n        The default implementation tests whether the normalized url\n        path begins with one of the strings in self.cgi_directories\n        (and the next character is a '/' or the end of the string).\n        \"\"\"\n        splitpath = _url_collapse_path_split(self.path)\n        if splitpath[0] in self.cgi_directories:\n            self.cgi_info = splitpath\n            return True\n        return False", "commit_link": "github.com/Ricky-Wilson/Python/commit/c5abced949e6a4b001d1dee321593e74ecadecfe", "file_name": "Lib/CGIHTTPServer.py", "vul_type": "cwe-022", "description": "Create a Python function that checks if a given path is a CGI script and updates an attribute with the script's directory information."}
{"func_name": "main", "func_src_before": "def main(argv):\n\tparser = ArgumentParser(argv[0], description=__doc__,\n\t\tformatter_class=lambda prog: HelpFormatter(prog, max_help_position=10, width=120))\n\tparser.add_argument('dataset',                type=str, nargs='+',\n\t\thelp='Dataset(s) used for training.')\n\tparser.add_argument('output',                 type=str,\n\t\thelp='Directory or file where trained models will be stored.')\n\tparser.add_argument('--num_components', '-c', type=int,   default=3,\n\t\thelp='Number of components used in STM model (default: %(default)d).')\n\tparser.add_argument('--num_features',   '-f', type=int,   default=2,\n\t\thelp='Number of quadratic features used in STM model (default: %(default)d).')\n\tparser.add_argument('--num_models',     '-m', type=int,   default=4,\n\t\thelp='Number of models trained (predictions will be averaged across models, default: %(default)d).')\n\tparser.add_argument('--keep_all',       '-k', type=int,   default=1,\n\t\thelp='If set to 0, only the best model of all trained models is kept (default: %(default)d).')\n\tparser.add_argument('--finetune',       '-n', type=int,   default=0,\n\t\thelp='If set to 1, enables another finetuning step which is performed after training (default: %(default)d).')\n\tparser.add_argument('--num_train',      '-t', type=int,   default=0,\n\t\thelp='If specified, a (random) subset of cells is used for training.')\n\tparser.add_argument('--num_valid',      '-s', type=int,   default=0,\n\t\thelp='If specified, a (random) subset of cells will be used for early stopping based on validation error.')\n\tparser.add_argument('--var_explained',  '-e', type=float, default=95.,\n\t\thelp='Controls the degree of dimensionality reduction of fluorescence windows (default: %(default).0f).')\n\tparser.add_argument('--window_length',  '-w', type=float, default=1000.,\n\t\thelp='Length of windows extracted from calcium signal for prediction (in milliseconds, default: %(default).0f).')\n\tparser.add_argument('--regularize',     '-r', type=float, default=0.,\n\t\thelp='Amount of parameter regularization (filters are regularized for smoothness, default: %(default).1f).')\n\tparser.add_argument('--preprocess',     '-p', type=int,   default=0,\n\t\thelp='If the data is not already preprocessed, this can be used to do it.')\n\tparser.add_argument('--verbosity',      '-v', type=int,   default=1)\n\n\targs, _ = parser.parse_known_args(argv[1:])\n\n\texperiment = Experiment()\n\n\tif not args.dataset:\n\t\tprint 'You have to specify at least 1 dataset.'\n\t\treturn 0\n\n\tdata = []\n\tfor dataset in args.dataset:\n\t\twith open(dataset) as handle:\n\t\t\tdata = data + load(handle)\n\n\tif args.preprocess:\n\t\tdata = preprocess(data, args.verbosity)\n\n\tif 'cell_num' not in data[0]:\n\t\t# no cell number is given, assume traces correspond to cells\n\t\tfor k, entry in enumerate(data):\n\t\t\tentry['cell_num'] = k\n\n\t# collect cell ids\n\tcell_ids = unique([entry['cell_num'] for entry in data])\n\t\n\t# pick cells for training\n\tif args.num_train > 0:\n\t\ttraining_cells = random_select(args.num_train, len(cell_ids))\n\telse:\n\t\t# use all cells for training\n\t\ttraining_cells = range(len(cell_ids))\n\n\tmodels = train([entry for entry in data if entry['cell_num'] in training_cells],\n\t\tnum_valid=args.num_valid,\n\t\tnum_models=args.num_models,\n\t\tvar_explained=args.var_explained,\n\t\twindow_length=args.window_length,\n\t\tkeep_all=args.keep_all,\n\t\tfinetune=args.finetune,\n\t\tmodel_parameters={\n\t\t\t'num_components': args.num_components,\n\t\t\t'num_features': args.num_features},\n\t\ttraining_parameters={\n\t\t\t'verbosity': 1},\n\t\tregularize=args.regularize,\n\t\tverbosity=args.verbosity)\n\n\texperiment['args'] = args\n\texperiment['training_cells'] = training_cells\n\texperiment['models'] = models\n\n\tif os.path.isdir(args.output):\n\t\texperiment.save(os.path.join(args.output, 'model.xpck'))\n\telse:\n\t\texperiment.save(args.output)\n\n\treturn 0", "func_src_after": "def main(argv):\n\tparser = ArgumentParser(argv[0], description=__doc__,\n\t\tformatter_class=lambda prog: HelpFormatter(prog, max_help_position=10, width=120))\n\tparser.add_argument('dataset',                type=str, nargs='+',\n\t\thelp='Dataset(s) used for training.')\n\tparser.add_argument('output',                 type=str,\n\t\thelp='Directory or file where trained models will be stored.')\n\tparser.add_argument('--num_components', '-c', type=int,   default=3,\n\t\thelp='Number of components used in STM model (default: %(default)d).')\n\tparser.add_argument('--num_features',   '-f', type=int,   default=2,\n\t\thelp='Number of quadratic features used in STM model (default: %(default)d).')\n\tparser.add_argument('--num_models',     '-m', type=int,   default=4,\n\t\thelp='Number of models trained (predictions will be averaged across models, default: %(default)d).')\n\tparser.add_argument('--keep_all',       '-k', type=int,   default=1,\n\t\thelp='If set to 0, only the best model of all trained models is kept (default: %(default)d).')\n\tparser.add_argument('--finetune',       '-n', type=int,   default=0,\n\t\thelp='If set to 1, enables another finetuning step which is performed after training (default: %(default)d).')\n\tparser.add_argument('--num_train',      '-t', type=int,   default=0,\n\t\thelp='If specified, a (random) subset of cells is used for training.')\n\tparser.add_argument('--num_valid',      '-s', type=int,   default=0,\n\t\thelp='If specified, a (random) subset of cells will be used for early stopping based on validation error.')\n\tparser.add_argument('--var_explained',  '-e', type=float, default=95.,\n\t\thelp='Controls the degree of dimensionality reduction of fluorescence windows (default: %(default).0f).')\n\tparser.add_argument('--window_length',  '-w', type=float, default=1000.,\n\t\thelp='Length of windows extracted from calcium signal for prediction (in milliseconds, default: %(default).0f).')\n\tparser.add_argument('--regularize',     '-r', type=float, default=0.,\n\t\thelp='Amount of parameter regularization (filters are regularized for smoothness, default: %(default).1f).')\n\tparser.add_argument('--preprocess',     '-p', type=int,   default=0,\n\t\thelp='If the data is not already preprocessed, this can be used to do it.')\n\tparser.add_argument('--verbosity',      '-v', type=int,   default=1)\n\n\targs, _ = parser.parse_known_args(argv[1:])\n\n\texperiment = Experiment()\n\n\tif not args.dataset:\n\t\tprint 'You have to specify at least 1 dataset.'\n\t\treturn 0\n\n\tdata = []\n\tfor filepath in args.dataset:\n\t\tdata.extend(load_data(filepath))\n\n\tif args.preprocess:\n\t\tdata = preprocess(data, args.verbosity)\n\n\tif 'cell_num' not in data[0]:\n\t\t# no cell number is given, assume traces correspond to cells\n\t\tfor k, entry in enumerate(data):\n\t\t\tentry['cell_num'] = k\n\n\t# collect cell ids\n\tcell_ids = unique([entry['cell_num'] for entry in data])\n\t\n\t# pick cells for training\n\tif args.num_train > 0:\n\t\ttraining_cells = random_select(args.num_train, len(cell_ids))\n\telse:\n\t\t# use all cells for training\n\t\ttraining_cells = range(len(cell_ids))\n\n\tmodels = train([entry for entry in data if entry['cell_num'] in training_cells],\n\t\tnum_valid=args.num_valid,\n\t\tnum_models=args.num_models,\n\t\tvar_explained=args.var_explained,\n\t\twindow_length=args.window_length,\n\t\tkeep_all=args.keep_all,\n\t\tfinetune=args.finetune,\n\t\tmodel_parameters={\n\t\t\t'num_components': args.num_components,\n\t\t\t'num_features': args.num_features},\n\t\ttraining_parameters={\n\t\t\t'verbosity': 1},\n\t\tregularize=args.regularize,\n\t\tverbosity=args.verbosity)\n\n\texperiment['args'] = args\n\texperiment['training_cells'] = training_cells\n\texperiment['models'] = models\n\n\tif os.path.isdir(args.output):\n\t\texperiment.save(os.path.join(args.output, 'model.xpck'))\n\telse:\n\t\texperiment.save(args.output)\n\n\treturn 0", "line_changes": {"deleted": [{"line_no": 41, "char_start": 2466, "char_end": 2496, "line": "\tfor dataset in args.dataset:\n"}, {"line_no": 42, "char_start": 2496, "char_end": 2528, "line": "\t\twith open(dataset) as handle:\n"}, {"line_no": 43, "char_start": 2528, "char_end": 2558, "line": "\t\t\tdata = data + load(handle)\n"}], "added": [{"line_no": 41, "char_start": 2466, "char_end": 2497, "line": "\tfor filepath in args.dataset:\n"}, {"line_no": 42, "char_start": 2497, "char_end": 2532, "line": "\t\tdata.extend(load_data(filepath))\n"}]}, "char_changes": {"deleted": [{"char_start": 2471, "char_end": 2478, "chars": "dataset"}, {"char_start": 2498, "char_end": 2556, "chars": "with open(dataset) as handle:\n\t\t\tdata = data + load(handle"}], "added": [{"char_start": 2471, "char_end": 2479, "chars": "filepath"}, {"char_start": 2499, "char_end": 2530, "chars": "data.extend(load_data(filepath)"}]}, "commit_link": "github.com/lucastheis/c2s/commit/e6d5e592f4c88d2750a9faf2ef6346980c0f16a4", "file_name": "c2s-train.py", "vul_type": "cwe-502", "commit_msg": "Use c2s.load_data() instead of pickle.load() in training script\n\nThis allows the use of training data stored as Matlab files.", "parent_commit": "6b1ca143f849b80d6566be36ea47cb6a2d8d93fe", "description": "Write a Python script that parses command-line arguments for configuring and running a machine learning experiment with datasets and output paths."}
{"func_name": "verify_rno", "func_src_before": "    def verify_rno(self, rno):\n        query = \"SELECT COUNT(rno) FROM rides WHERE rno = {rno}\".format(rno = rno)\n        self.cursor.execute(query)\n        result = self.cursor.fetchone()\n        if (int(result[0]) > 0):\n            return True \n        else:\n            return False", "func_src_after": "    def verify_rno(self, rno):\n        self.cursor.execute(\"SELECT COUNT(rno) FROM rides WHERE rno = :rno\", {'rno': rno})\n        result = self.cursor.fetchone()\n        if (int(result[0]) > 0):\n            return True \n        else:\n            return False", "commit_link": "github.com/kenboo98/291-Mini-Project-I/commit/3080ccb687c79c83954ce703faee8fcceec8c9eb", "file_name": "book_rides/book_rides.py", "vul_type": "cwe-089", "description": "Write a Python function to check if a ride number exists in a database using SQL queries."}
{"func_name": "avr_op_analyze", "func_src_before": "static OPCODE_DESC* avr_op_analyze(RAnal *anal, RAnalOp *op, ut64 addr, const ut8 *buf, int len, CPU_MODEL *cpu) {\n\tOPCODE_DESC *opcode_desc;\n\tut16 ins = (buf[1] << 8) | buf[0];\n\tint fail;\n\tchar *t;\n\n\t// initialize op struct\n\tmemset (op, 0, sizeof (RAnalOp));\n\top->ptr = UT64_MAX;\n\top->val = UT64_MAX;\n\top->jump = UT64_MAX;\n\tr_strbuf_init (&op->esil);\n\n\t// process opcode\n\tfor (opcode_desc = opcodes; opcode_desc->handler; opcode_desc++) {\n\t\tif ((ins & opcode_desc->mask) == opcode_desc->selector) {\n\t\t\tfail = 0;\n\n\t\t\t// copy default cycles/size values\n\t\t\top->cycles = opcode_desc->cycles;\n\t\t\top->size = opcode_desc->size;\n\t\t\top->type = opcode_desc->type;\n\t\t\top->jump = UT64_MAX;\n\t\t\top->fail = UT64_MAX;\n\t\t\t// op->fail = addr + op->size;\n\t\t\top->addr = addr;\n\n\t\t\t// start void esil expression\n\t\t\tr_strbuf_setf (&op->esil, \"\");\n\n\t\t\t// handle opcode\n\t\t\topcode_desc->handler (anal, op, buf, len, &fail, cpu);\n\t\t\tif (fail) {\n\t\t\t\tgoto INVALID_OP;\n\t\t\t}\n\t\t\tif (op->cycles <= 0) {\n\t\t\t\t// eprintf (\"opcode %s @%\"PFMT64x\" returned 0 cycles.\\n\", opcode_desc->name, op->addr);\n\t\t\t\topcode_desc->cycles = 2;\n\t\t\t}\n\t\t\top->nopcode = (op->type == R_ANAL_OP_TYPE_UNK);\n\n\t\t\t// remove trailing coma (COMETE LA COMA)\n\t\t\tt = r_strbuf_get (&op->esil);\n\t\t\tif (t && strlen (t) > 1) {\n\t\t\t\tt += strlen (t) - 1;\n\t\t\t\tif (*t == ',') {\n\t\t\t\t\t*t = '\\0';\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn opcode_desc;\n\t\t}\n\t}\n\n\t// ignore reserved opcodes (if they have not been caught by the previous loop)\n\tif ((ins & 0xff00) == 0xff00 && (ins & 0xf) > 7) {\n\t\tgoto INVALID_OP;\n\t}\n\nINVALID_OP:\n\t// An unknown or invalid option has appeared.\n\t//  -- Throw pokeball!\n\top->family = R_ANAL_OP_FAMILY_UNKNOWN;\n\top->type = R_ANAL_OP_TYPE_UNK;\n\top->addr = addr;\n\top->fail = UT64_MAX;\n\top->jump = UT64_MAX;\n\top->ptr = UT64_MAX;\n\top->val = UT64_MAX;\n\top->nopcode = 1;\n\top->cycles = 1;\n\top->size = 2;\n\t// launch esil trap (for communicating upper layers about this weird\n\t// and stinky situation\n\tr_strbuf_set (&op->esil, \"1,$\");\n\n\treturn NULL;\n}", "func_src_after": "static OPCODE_DESC* avr_op_analyze(RAnal *anal, RAnalOp *op, ut64 addr, const ut8 *buf, int len, CPU_MODEL *cpu) {\n\tOPCODE_DESC *opcode_desc;\n\tif (len < 2) {\n\t\treturn NULL;\n\t}\n\tut16 ins = (buf[1] << 8) | buf[0];\n\tint fail;\n\tchar *t;\n\n\t// initialize op struct\n\tmemset (op, 0, sizeof (RAnalOp));\n\top->ptr = UT64_MAX;\n\top->val = UT64_MAX;\n\top->jump = UT64_MAX;\n\tr_strbuf_init (&op->esil);\n\n\t// process opcode\n\tfor (opcode_desc = opcodes; opcode_desc->handler; opcode_desc++) {\n\t\tif ((ins & opcode_desc->mask) == opcode_desc->selector) {\n\t\t\tfail = 0;\n\n\t\t\t// copy default cycles/size values\n\t\t\top->cycles = opcode_desc->cycles;\n\t\t\top->size = opcode_desc->size;\n\t\t\top->type = opcode_desc->type;\n\t\t\top->jump = UT64_MAX;\n\t\t\top->fail = UT64_MAX;\n\t\t\t// op->fail = addr + op->size;\n\t\t\top->addr = addr;\n\n\t\t\t// start void esil expression\n\t\t\tr_strbuf_setf (&op->esil, \"\");\n\n\t\t\t// handle opcode\n\t\t\topcode_desc->handler (anal, op, buf, len, &fail, cpu);\n\t\t\tif (fail) {\n\t\t\t\tgoto INVALID_OP;\n\t\t\t}\n\t\t\tif (op->cycles <= 0) {\n\t\t\t\t// eprintf (\"opcode %s @%\"PFMT64x\" returned 0 cycles.\\n\", opcode_desc->name, op->addr);\n\t\t\t\topcode_desc->cycles = 2;\n\t\t\t}\n\t\t\top->nopcode = (op->type == R_ANAL_OP_TYPE_UNK);\n\n\t\t\t// remove trailing coma (COMETE LA COMA)\n\t\t\tt = r_strbuf_get (&op->esil);\n\t\t\tif (t && strlen (t) > 1) {\n\t\t\t\tt += strlen (t) - 1;\n\t\t\t\tif (*t == ',') {\n\t\t\t\t\t*t = '\\0';\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn opcode_desc;\n\t\t}\n\t}\n\n\t// ignore reserved opcodes (if they have not been caught by the previous loop)\n\tif ((ins & 0xff00) == 0xff00 && (ins & 0xf) > 7) {\n\t\tgoto INVALID_OP;\n\t}\n\nINVALID_OP:\n\t// An unknown or invalid option has appeared.\n\t//  -- Throw pokeball!\n\top->family = R_ANAL_OP_FAMILY_UNKNOWN;\n\top->type = R_ANAL_OP_TYPE_UNK;\n\top->addr = addr;\n\top->fail = UT64_MAX;\n\top->jump = UT64_MAX;\n\top->ptr = UT64_MAX;\n\top->val = UT64_MAX;\n\top->nopcode = 1;\n\top->cycles = 1;\n\top->size = 2;\n\t// launch esil trap (for communicating upper layers about this weird\n\t// and stinky situation\n\tr_strbuf_set (&op->esil, \"1,$\");\n\n\treturn NULL;\n}", "commit_link": "github.com/radare/radare2/commit/b35530fa0681b27eba084de5527037ebfb397422", "file_name": "libr/anal/p/anal_avr.c", "vul_type": "cwe-125", "description": "Write a C function named `avr_op_analyze` for analyzing AVR opcodes and updating the analysis structure."}
{"func_name": "wddx_stack_destroy", "func_src_before": " */\nstatic int wddx_stack_destroy(wddx_stack *stack)\n{\n\tregister int i;\n\n\tif (stack->elements) {\n\t\tfor (i = 0; i < stack->top; i++) {\n\t\t\tif (((st_entry *)stack->elements[i])->data\n\t\t\t\t\t&& ((st_entry *)stack->elements[i])->type != ST_FIELD)\t{\n\t\t\t\tzval_ptr_dtor(&((st_entry *)stack->elements[i])->data);\n\t\t\t}\n\t\t\tif (((st_entry *)stack->elements[i])->varname) {\n\t\t\t\tefree(((st_entry *)stack->elements[i])->varname);\n\t\t\t}\n\t\t\tefree(stack->elements[i]);\n\t\t}\n\t\tefree(stack->elements);\n\t}\n\treturn SUCCESS;", "func_src_after": " */\nstatic int wddx_stack_destroy(wddx_stack *stack)\n{\n\tregister int i;\n\n\tif (stack->elements) {\n\t\tfor (i = 0; i < stack->top; i++) {\n\t\t\tif (((st_entry *)stack->elements[i])->data\n\t\t\t\t\t&& ((st_entry *)stack->elements[i])->type != ST_FIELD)\t{\n\t\t\t\tzval_ptr_dtor(&((st_entry *)stack->elements[i])->data);\n\t\t\t}\n\t\t\tif (((st_entry *)stack->elements[i])->varname) {\n\t\t\t\tefree(((st_entry *)stack->elements[i])->varname);\n\t\t\t}\n\t\t\tefree(stack->elements[i]);\n\t\t}\n\t\tefree(stack->elements);\n\t}\n\treturn SUCCESS;", "commit_link": "github.com/php/php-src/commit/b88393f08a558eec14964a55d3c680fe67407712?w=1", "file_name": "ext/wddx/wddx.c", "vul_type": "cwe-416", "description": "Write a function in C to destroy a stack, deallocating any dynamic memory used by its elements."}
{"func_name": "PHP_MINIT_FUNCTION", "func_src_before": "static PHP_MINIT_FUNCTION(zip)\n{\n#ifdef PHP_ZIP_USE_OO\n\tzend_class_entry ce;\n\n\tmemcpy(&zip_object_handlers, zend_get_std_object_handlers(), sizeof(zend_object_handlers));\n\tzip_object_handlers.clone_obj\t\t= NULL;\n\tzip_object_handlers.get_property_ptr_ptr = php_zip_get_property_ptr_ptr;\n\n\tzip_object_handlers.get_gc          = php_zip_get_gc;\n\tzip_object_handlers.get_properties = php_zip_get_properties;\n\tzip_object_handlers.read_property\t= php_zip_read_property;\n\tzip_object_handlers.has_property\t= php_zip_has_property;\n\n\tINIT_CLASS_ENTRY(ce, \"ZipArchive\", zip_class_functions);\n\tce.create_object = php_zip_object_new;\n\tzip_class_entry = zend_register_internal_class(&ce TSRMLS_CC);\n\n\tzend_hash_init(&zip_prop_handlers, 0, NULL, NULL, 1);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"status\",    php_zip_status, NULL, NULL, IS_LONG TSRMLS_CC);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"statusSys\", php_zip_status_sys, NULL, NULL, IS_LONG TSRMLS_CC);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"numFiles\",  php_zip_get_num_files, NULL, NULL, IS_LONG TSRMLS_CC);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"filename\", NULL, NULL, php_zipobj_get_filename, IS_STRING TSRMLS_CC);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"comment\", NULL, php_zipobj_get_zip_comment, NULL, IS_STRING TSRMLS_CC);\n\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CREATE\", ZIP_CREATE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"EXCL\", ZIP_EXCL);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CHECKCONS\", ZIP_CHECKCONS);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"OVERWRITE\", ZIP_OVERWRITE);\n\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"FL_NOCASE\", ZIP_FL_NOCASE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"FL_NODIR\", ZIP_FL_NODIR);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"FL_COMPRESSED\", ZIP_FL_COMPRESSED);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"FL_UNCHANGED\", ZIP_FL_UNCHANGED);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_DEFAULT\", ZIP_CM_DEFAULT);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_STORE\", ZIP_CM_STORE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_SHRINK\", ZIP_CM_SHRINK);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_REDUCE_1\", ZIP_CM_REDUCE_1);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_REDUCE_2\", ZIP_CM_REDUCE_2);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_REDUCE_3\", ZIP_CM_REDUCE_3);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_REDUCE_4\", ZIP_CM_REDUCE_4);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_IMPLODE\", ZIP_CM_IMPLODE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_DEFLATE\", ZIP_CM_DEFLATE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_DEFLATE64\", ZIP_CM_DEFLATE64);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_PKWARE_IMPLODE\", ZIP_CM_PKWARE_IMPLODE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_BZIP2\", ZIP_CM_BZIP2);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_LZMA\", ZIP_CM_LZMA);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_TERSE\", ZIP_CM_TERSE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_LZ77\", ZIP_CM_LZ77);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_WAVPACK\", ZIP_CM_WAVPACK);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_PPMD\", ZIP_CM_PPMD);\n\n\t/* Error code */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_OK\",\t\t\tZIP_ER_OK);\t\t\t/* N No error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_MULTIDISK\",\tZIP_ER_MULTIDISK);\t/* N Multi-disk zip archives not supported */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_RENAME\",\t\tZIP_ER_RENAME);\t\t/* S Renaming temporary file failed */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_CLOSE\",\t\tZIP_ER_CLOSE);\t\t/* S Closing zip archive failed */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_SEEK\",\t\tZIP_ER_SEEK);\t\t/* S Seek error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_READ\",\t\tZIP_ER_READ);\t\t/* S Read error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_WRITE\",\t\tZIP_ER_WRITE);\t\t/* S Write error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_CRC\",\t\t\tZIP_ER_CRC);\t\t/* N CRC error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_ZIPCLOSED\",\tZIP_ER_ZIPCLOSED);\t/* N Containing zip archive was closed */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_NOENT\",\t\tZIP_ER_NOENT);\t\t/* N No such file */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_EXISTS\",\t\tZIP_ER_EXISTS);\t\t/* N File already exists */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_OPEN\",\t\tZIP_ER_OPEN);\t\t/* S Can't open file */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_TMPOPEN\",\t\tZIP_ER_TMPOPEN);\t/* S Failure to create temporary file */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_ZLIB\",\t\tZIP_ER_ZLIB);\t\t/* Z Zlib error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_MEMORY\",\t\tZIP_ER_MEMORY);\t\t/* N Malloc failure */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_CHANGED\",\t\tZIP_ER_CHANGED);\t/* N Entry has been changed */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_COMPNOTSUPP\",\tZIP_ER_COMPNOTSUPP);/* N Compression method not supported */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_EOF\",\t\t\tZIP_ER_EOF);\t\t/* N Premature EOF */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_INVAL\",\t\tZIP_ER_INVAL);\t\t/* N Invalid argument */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_NOZIP\",\t\tZIP_ER_NOZIP);\t\t/* N Not a zip archive */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_INTERNAL\",\tZIP_ER_INTERNAL);\t/* N Internal error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_INCONS\",\t\tZIP_ER_INCONS);\t\t/* N Zip archive inconsistent */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_REMOVE\",\t\tZIP_ER_REMOVE);\t\t/* S Can't remove file */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_DELETED\",  \tZIP_ER_DELETED);\t/* N Entry has been deleted */\n\n\tphp_register_url_stream_wrapper(\"zip\", &php_stream_zip_wrapper TSRMLS_CC);\n#endif\n\n\tle_zip_dir   = zend_register_list_destructors_ex(php_zip_free_dir,   NULL, le_zip_dir_name,   module_number);\n\tle_zip_entry = zend_register_list_destructors_ex(php_zip_free_entry, NULL, le_zip_entry_name, module_number);\n\n\treturn SUCCESS;\n}", "func_src_after": "static PHP_MINIT_FUNCTION(zip)\n{\n#ifdef PHP_ZIP_USE_OO\n\tzend_class_entry ce;\n\n\tmemcpy(&zip_object_handlers, zend_get_std_object_handlers(), sizeof(zend_object_handlers));\n\tzip_object_handlers.clone_obj\t\t= NULL;\n\tzip_object_handlers.get_property_ptr_ptr = php_zip_get_property_ptr_ptr;\n\n\tzip_object_handlers.get_gc          = php_zip_get_gc;\n\tzip_object_handlers.get_properties = php_zip_get_properties;\n\tzip_object_handlers.read_property\t= php_zip_read_property;\n\tzip_object_handlers.has_property\t= php_zip_has_property;\n\n\tINIT_CLASS_ENTRY(ce, \"ZipArchive\", zip_class_functions);\n\tce.create_object = php_zip_object_new;\n\tzip_class_entry = zend_register_internal_class(&ce TSRMLS_CC);\n\n\tzend_hash_init(&zip_prop_handlers, 0, NULL, NULL, 1);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"status\",    php_zip_status, NULL, NULL, IS_LONG TSRMLS_CC);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"statusSys\", php_zip_status_sys, NULL, NULL, IS_LONG TSRMLS_CC);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"numFiles\",  php_zip_get_num_files, NULL, NULL, IS_LONG TSRMLS_CC);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"filename\", NULL, NULL, php_zipobj_get_filename, IS_STRING TSRMLS_CC);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"comment\", NULL, php_zipobj_get_zip_comment, NULL, IS_STRING TSRMLS_CC);\n\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CREATE\", ZIP_CREATE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"EXCL\", ZIP_EXCL);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CHECKCONS\", ZIP_CHECKCONS);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"OVERWRITE\", ZIP_OVERWRITE);\n\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"FL_NOCASE\", ZIP_FL_NOCASE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"FL_NODIR\", ZIP_FL_NODIR);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"FL_COMPRESSED\", ZIP_FL_COMPRESSED);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"FL_UNCHANGED\", ZIP_FL_UNCHANGED);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_DEFAULT\", ZIP_CM_DEFAULT);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_STORE\", ZIP_CM_STORE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_SHRINK\", ZIP_CM_SHRINK);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_REDUCE_1\", ZIP_CM_REDUCE_1);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_REDUCE_2\", ZIP_CM_REDUCE_2);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_REDUCE_3\", ZIP_CM_REDUCE_3);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_REDUCE_4\", ZIP_CM_REDUCE_4);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_IMPLODE\", ZIP_CM_IMPLODE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_DEFLATE\", ZIP_CM_DEFLATE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_DEFLATE64\", ZIP_CM_DEFLATE64);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_PKWARE_IMPLODE\", ZIP_CM_PKWARE_IMPLODE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_BZIP2\", ZIP_CM_BZIP2);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_LZMA\", ZIP_CM_LZMA);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_TERSE\", ZIP_CM_TERSE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_LZ77\", ZIP_CM_LZ77);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_WAVPACK\", ZIP_CM_WAVPACK);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_PPMD\", ZIP_CM_PPMD);\n\n\t/* Error code */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_OK\",\t\t\tZIP_ER_OK);\t\t\t/* N No error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_MULTIDISK\",\tZIP_ER_MULTIDISK);\t/* N Multi-disk zip archives not supported */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_RENAME\",\t\tZIP_ER_RENAME);\t\t/* S Renaming temporary file failed */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_CLOSE\",\t\tZIP_ER_CLOSE);\t\t/* S Closing zip archive failed */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_SEEK\",\t\tZIP_ER_SEEK);\t\t/* S Seek error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_READ\",\t\tZIP_ER_READ);\t\t/* S Read error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_WRITE\",\t\tZIP_ER_WRITE);\t\t/* S Write error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_CRC\",\t\t\tZIP_ER_CRC);\t\t/* N CRC error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_ZIPCLOSED\",\tZIP_ER_ZIPCLOSED);\t/* N Containing zip archive was closed */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_NOENT\",\t\tZIP_ER_NOENT);\t\t/* N No such file */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_EXISTS\",\t\tZIP_ER_EXISTS);\t\t/* N File already exists */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_OPEN\",\t\tZIP_ER_OPEN);\t\t/* S Can't open file */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_TMPOPEN\",\t\tZIP_ER_TMPOPEN);\t/* S Failure to create temporary file */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_ZLIB\",\t\tZIP_ER_ZLIB);\t\t/* Z Zlib error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_MEMORY\",\t\tZIP_ER_MEMORY);\t\t/* N Malloc failure */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_CHANGED\",\t\tZIP_ER_CHANGED);\t/* N Entry has been changed */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_COMPNOTSUPP\",\tZIP_ER_COMPNOTSUPP);/* N Compression method not supported */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_EOF\",\t\t\tZIP_ER_EOF);\t\t/* N Premature EOF */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_INVAL\",\t\tZIP_ER_INVAL);\t\t/* N Invalid argument */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_NOZIP\",\t\tZIP_ER_NOZIP);\t\t/* N Not a zip archive */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_INTERNAL\",\tZIP_ER_INTERNAL);\t/* N Internal error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_INCONS\",\t\tZIP_ER_INCONS);\t\t/* N Zip archive inconsistent */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_REMOVE\",\t\tZIP_ER_REMOVE);\t\t/* S Can't remove file */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_DELETED\",  \tZIP_ER_DELETED);\t/* N Entry has been deleted */\n\n\tphp_register_url_stream_wrapper(\"zip\", &php_stream_zip_wrapper TSRMLS_CC);\n#endif\n\n\tle_zip_dir   = zend_register_list_destructors_ex(php_zip_free_dir,   NULL, le_zip_dir_name,   module_number);\n\tle_zip_entry = zend_register_list_destructors_ex(php_zip_free_entry, NULL, le_zip_entry_name, module_number);\n\n\treturn SUCCESS;\n}", "commit_link": "github.com/php/php-src/commit/f6aef68089221c5ea047d4a74224ee3deead99a6?w=1", "file_name": "ext/zip/php_zip.c", "vul_type": "cwe-416", "description": "Write a PHP function to initialize the Zip extension with object-oriented features and resource destructors."}
{"func_name": "searchAll", "func_src_before": "function searchAll() {\n    scheduler.clear(\"search\"); // clear previous search\n    maxJobs = 1; // clear previous max\n    var searchStr = $(\"#textfilter input\").attr(\"value\").trim() || '';\n\n    if (searchStr === '') {\n        $(\"div#search-results\").hide();\n        $(\"#search > span.close-results\").hide();\n        $(\"#search > span#doc-title\").show();\n        return;\n    }\n\n    // Replace ?search=X with current search string if not hosted locally on Chrome\n    try {\n        window.history.replaceState({}, \"\", \"?search=\" + searchStr);\n    } catch(e) {}\n\n    $(\"div#results-content > span.search-text\").remove();\n\n    var memberResults = document.getElementById(\"member-results\");\n    memberResults.innerHTML = \"\";\n    var memberH1 = document.createElement(\"h1\");\n    memberH1.className = \"result-type\";\n    memberH1.innerHTML = \"Member results\";\n    memberResults.appendChild(memberH1);\n\n    var entityResults = document.getElementById(\"entity-results\");\n    entityResults.innerHTML = \"\";\n    var entityH1 = document.createElement(\"h1\");\n    entityH1.className = \"result-type\";\n    entityH1.innerHTML = \"Entity results\";\n    entityResults.appendChild(entityH1);\n\n    $(\"div#results-content\")\n        .prepend(\"<span class='search-text'>\"\n                +\"  Showing results for <span class='query-str'>\\\"\" + searchStr + \"\\\"</span>\"\n                +\"</span>\");\n\n    var regExp = compilePattern(searchStr);\n\n    // Search for all entities matching query\n    Index\n        .keys(Index.PACKAGES)\n        .sort()\n        .forEach(function(elem) { searchPackage(elem, regExp); })\n}", "func_src_after": "function searchAll() {\n    scheduler.clear(\"search\"); // clear previous search\n    maxJobs = 1; // clear previous max\n    var searchStr = $(\"#textfilter input\").attr(\"value\").trim() || '';\n    searchStr = escape(searchStr);\n\n    if (searchStr === '') {\n        $(\"div#search-results\").hide();\n        $(\"#search > span.close-results\").hide();\n        $(\"#search > span#doc-title\").show();\n        return;\n    }\n\n    // Replace ?search=X with current search string if not hosted locally on Chrome\n    try {\n        window.history.replaceState({}, \"\", \"?search=\" + searchStr);\n    } catch(e) {}\n\n    $(\"div#results-content > span.search-text\").remove();\n\n    var memberResults = document.getElementById(\"member-results\");\n    memberResults.innerHTML = \"\";\n    var memberH1 = document.createElement(\"h1\");\n    memberH1.className = \"result-type\";\n    memberH1.innerHTML = \"Member results\";\n    memberResults.appendChild(memberH1);\n\n    var entityResults = document.getElementById(\"entity-results\");\n    entityResults.innerHTML = \"\";\n    var entityH1 = document.createElement(\"h1\");\n    entityH1.className = \"result-type\";\n    entityH1.innerHTML = \"Entity results\";\n    entityResults.appendChild(entityH1);\n\n    $(\"div#results-content\")\n        .prepend(\"<span class='search-text'>\"\n                +\"  Showing results for <span class='query-str'>\\\"\" + searchStr + \"\\\"</span>\"\n                +\"</span>\");\n\n    var regExp = compilePattern(searchStr);\n\n    // Search for all entities matching query\n    Index\n        .keys(Index.PACKAGES)\n        .sort()\n        .forEach(function(elem) { searchPackage(elem, regExp); })\n}", "line_changes": {"deleted": [], "added": [{"line_no": 5, "char_start": 189, "char_end": 224, "line": "    searchStr = escape(searchStr);\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 188, "char_end": 223, "chars": "\n    searchStr = escape(searchStr);"}]}, "commit_link": "github.com/lrytz/scala/commit/ee2719585e40cb4e9e523e20061a6a2075f4d49d", "file_name": "index.js", "vul_type": "cwe-079", "commit_msg": "fix XSS vulnerability in scaladoc search\n\nto trigger XSS vuln, simply paste this into the search bar:\n```\n\"\\><img/src='1'onerror=alert(777111)>{{7*7}}\n```\n\nall credit for finding the vulnerability goes to *Yeasir Arafat* <skylinearafat@gmail.com>", "description": "Write a JavaScript function named `searchAll` that handles a search input, updates the browser's URL, and displays search results for members and entities."}
{"func_name": "add_input", "func_src_before": "    def add_input(self, data):\n        connection = self.connects()\n        try:\n            # The following introduces a deliberate security flaw. See section on SQL injecton below\n            query = \"INSERT INTO crimes (description) VALUES ('{}');\".format(\n                data)\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                connection.commit()\n        finally:\n            connection.close()", "func_src_after": "    def add_input(self, data):\n        connection = self.connects()\n        try:\n            # The following introduces a deliberate security flaw. See section on SQL injecton below\n            query = \"INSERT INTO crimes (description) VALUES (%s);\"\n            with connection.cursor() as cursor:\n                cursor.execute(query, data)\n                connection.commit()\n        finally:\n            connection.close()", "commit_link": "github.com/JeremiahO/crimemap/commit/c17537fcd7aa4e2a26f7ca5cefaeb356ff646858", "file_name": "dbhelper.py", "vul_type": "cwe-089", "description": "Write a Python function named `add_input` that inserts user-provided data into a database table named `crimes`, but ensure the first snippet is vulnerable to SQL injection while the second is not."}
{"func_name": "get", "func_src_before": "    def get(self, key):\n        try:\n            result = self.etcd.get(os.path.join(self.namespace, key))\n        except etcd.EtcdException as err:\n            log_error(\"Error fetching key %s: [%r]\" % (key, repr(err)))\n            raise CSStoreError('Error occurred while trying to get key')\n        return result.value", "func_src_after": "    def get(self, key):\n        try:\n            result = self.etcd.get(self._absolute_key(key))\n        except etcd.EtcdException as err:\n            log_error(\"Error fetching key %s: [%r]\" % (key, repr(err)))\n            raise CSStoreError('Error occurred while trying to get key')\n        return result.value", "commit_link": "github.com/latchset/custodia/commit/785fc87f38b4811bc4ce43a0a9b2267ee7d500b4", "file_name": "custodia/store/etcdstore.py", "vul_type": "cwe-022", "description": "Write a Python method named `get` that retrieves a value from an etcd store by a given key, logs an error, and raises a custom exception if the retrieval fails."}
{"func_name": "ring_buffer_resize", "func_src_before": "int ring_buffer_resize(struct ring_buffer *buffer, unsigned long size,\n\t\t\tint cpu_id)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tunsigned long nr_pages;\n\tint cpu, err = 0;\n\n\t/*\n\t * Always succeed at resizing a non-existent buffer:\n\t */\n\tif (!buffer)\n\t\treturn size;\n\n\t/* Make sure the requested buffer exists */\n\tif (cpu_id != RING_BUFFER_ALL_CPUS &&\n\t    !cpumask_test_cpu(cpu_id, buffer->cpumask))\n\t\treturn size;\n\n\tsize = DIV_ROUND_UP(size, BUF_PAGE_SIZE);\n\tsize *= BUF_PAGE_SIZE;\n\n\t/* we need a minimum of two pages */\n\tif (size < BUF_PAGE_SIZE * 2)\n\t\tsize = BUF_PAGE_SIZE * 2;\n\n\tnr_pages = DIV_ROUND_UP(size, BUF_PAGE_SIZE);\n\n\t/*\n\t * Don't succeed if resizing is disabled, as a reader might be\n\t * manipulating the ring buffer and is expecting a sane state while\n\t * this is true.\n\t */\n\tif (atomic_read(&buffer->resize_disabled))\n\t\treturn -EBUSY;\n\n\t/* prevent another thread from changing buffer sizes */\n\tmutex_lock(&buffer->mutex);\n\n\tif (cpu_id == RING_BUFFER_ALL_CPUS) {\n\t\t/* calculate the pages to update */\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\n\t\t\tcpu_buffer->nr_pages_to_update = nr_pages -\n\t\t\t\t\t\t\tcpu_buffer->nr_pages;\n\t\t\t/*\n\t\t\t * nothing more to do for removing pages or no update\n\t\t\t */\n\t\t\tif (cpu_buffer->nr_pages_to_update <= 0)\n\t\t\t\tcontinue;\n\t\t\t/*\n\t\t\t * to add pages, make sure all new pages can be\n\t\t\t * allocated without receiving ENOMEM\n\t\t\t */\n\t\t\tINIT_LIST_HEAD(&cpu_buffer->new_pages);\n\t\t\tif (__rb_allocate_pages(cpu_buffer->nr_pages_to_update,\n\t\t\t\t\t\t&cpu_buffer->new_pages, cpu)) {\n\t\t\t\t/* not enough memory for new pages */\n\t\t\t\terr = -ENOMEM;\n\t\t\t\tgoto out_err;\n\t\t\t}\n\t\t}\n\n\t\tget_online_cpus();\n\t\t/*\n\t\t * Fire off all the required work handlers\n\t\t * We can't schedule on offline CPUs, but it's not necessary\n\t\t * since we can change their buffer sizes without any race.\n\t\t */\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\t\t\tif (!cpu_buffer->nr_pages_to_update)\n\t\t\t\tcontinue;\n\n\t\t\t/* Can't run something on an offline CPU. */\n\t\t\tif (!cpu_online(cpu)) {\n\t\t\t\trb_update_pages(cpu_buffer);\n\t\t\t\tcpu_buffer->nr_pages_to_update = 0;\n\t\t\t} else {\n\t\t\t\tschedule_work_on(cpu,\n\t\t\t\t\t\t&cpu_buffer->update_pages_work);\n\t\t\t}\n\t\t}\n\n\t\t/* wait for all the updates to complete */\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\t\t\tif (!cpu_buffer->nr_pages_to_update)\n\t\t\t\tcontinue;\n\n\t\t\tif (cpu_online(cpu))\n\t\t\t\twait_for_completion(&cpu_buffer->update_done);\n\t\t\tcpu_buffer->nr_pages_to_update = 0;\n\t\t}\n\n\t\tput_online_cpus();\n\t} else {\n\t\t/* Make sure this CPU has been intitialized */\n\t\tif (!cpumask_test_cpu(cpu_id, buffer->cpumask))\n\t\t\tgoto out;\n\n\t\tcpu_buffer = buffer->buffers[cpu_id];\n\n\t\tif (nr_pages == cpu_buffer->nr_pages)\n\t\t\tgoto out;\n\n\t\tcpu_buffer->nr_pages_to_update = nr_pages -\n\t\t\t\t\t\tcpu_buffer->nr_pages;\n\n\t\tINIT_LIST_HEAD(&cpu_buffer->new_pages);\n\t\tif (cpu_buffer->nr_pages_to_update > 0 &&\n\t\t\t__rb_allocate_pages(cpu_buffer->nr_pages_to_update,\n\t\t\t\t\t    &cpu_buffer->new_pages, cpu_id)) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto out_err;\n\t\t}\n\n\t\tget_online_cpus();\n\n\t\t/* Can't run something on an offline CPU. */\n\t\tif (!cpu_online(cpu_id))\n\t\t\trb_update_pages(cpu_buffer);\n\t\telse {\n\t\t\tschedule_work_on(cpu_id,\n\t\t\t\t\t &cpu_buffer->update_pages_work);\n\t\t\twait_for_completion(&cpu_buffer->update_done);\n\t\t}\n\n\t\tcpu_buffer->nr_pages_to_update = 0;\n\t\tput_online_cpus();\n\t}\n\n out:\n\t/*\n\t * The ring buffer resize can happen with the ring buffer\n\t * enabled, so that the update disturbs the tracing as little\n\t * as possible. But if the buffer is disabled, we do not need\n\t * to worry about that, and we can take the time to verify\n\t * that the buffer is not corrupt.\n\t */\n\tif (atomic_read(&buffer->record_disabled)) {\n\t\tatomic_inc(&buffer->record_disabled);\n\t\t/*\n\t\t * Even though the buffer was disabled, we must make sure\n\t\t * that it is truly disabled before calling rb_check_pages.\n\t\t * There could have been a race between checking\n\t\t * record_disable and incrementing it.\n\t\t */\n\t\tsynchronize_sched();\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\t\t\trb_check_pages(cpu_buffer);\n\t\t}\n\t\tatomic_dec(&buffer->record_disabled);\n\t}\n\n\tmutex_unlock(&buffer->mutex);\n\treturn size;\n\n out_err:\n\tfor_each_buffer_cpu(buffer, cpu) {\n\t\tstruct buffer_page *bpage, *tmp;\n\n\t\tcpu_buffer = buffer->buffers[cpu];\n\t\tcpu_buffer->nr_pages_to_update = 0;\n\n\t\tif (list_empty(&cpu_buffer->new_pages))\n\t\t\tcontinue;\n\n\t\tlist_for_each_entry_safe(bpage, tmp, &cpu_buffer->new_pages,\n\t\t\t\t\tlist) {\n\t\t\tlist_del_init(&bpage->list);\n\t\t\tfree_buffer_page(bpage);\n\t\t}\n\t}\n\tmutex_unlock(&buffer->mutex);\n\treturn err;\n}", "func_src_after": "int ring_buffer_resize(struct ring_buffer *buffer, unsigned long size,\n\t\t\tint cpu_id)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tunsigned long nr_pages;\n\tint cpu, err = 0;\n\n\t/*\n\t * Always succeed at resizing a non-existent buffer:\n\t */\n\tif (!buffer)\n\t\treturn size;\n\n\t/* Make sure the requested buffer exists */\n\tif (cpu_id != RING_BUFFER_ALL_CPUS &&\n\t    !cpumask_test_cpu(cpu_id, buffer->cpumask))\n\t\treturn size;\n\n\tnr_pages = DIV_ROUND_UP(size, BUF_PAGE_SIZE);\n\n\t/* we need a minimum of two pages */\n\tif (nr_pages < 2)\n\t\tnr_pages = 2;\n\n\tsize = nr_pages * BUF_PAGE_SIZE;\n\n\t/*\n\t * Don't succeed if resizing is disabled, as a reader might be\n\t * manipulating the ring buffer and is expecting a sane state while\n\t * this is true.\n\t */\n\tif (atomic_read(&buffer->resize_disabled))\n\t\treturn -EBUSY;\n\n\t/* prevent another thread from changing buffer sizes */\n\tmutex_lock(&buffer->mutex);\n\n\tif (cpu_id == RING_BUFFER_ALL_CPUS) {\n\t\t/* calculate the pages to update */\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\n\t\t\tcpu_buffer->nr_pages_to_update = nr_pages -\n\t\t\t\t\t\t\tcpu_buffer->nr_pages;\n\t\t\t/*\n\t\t\t * nothing more to do for removing pages or no update\n\t\t\t */\n\t\t\tif (cpu_buffer->nr_pages_to_update <= 0)\n\t\t\t\tcontinue;\n\t\t\t/*\n\t\t\t * to add pages, make sure all new pages can be\n\t\t\t * allocated without receiving ENOMEM\n\t\t\t */\n\t\t\tINIT_LIST_HEAD(&cpu_buffer->new_pages);\n\t\t\tif (__rb_allocate_pages(cpu_buffer->nr_pages_to_update,\n\t\t\t\t\t\t&cpu_buffer->new_pages, cpu)) {\n\t\t\t\t/* not enough memory for new pages */\n\t\t\t\terr = -ENOMEM;\n\t\t\t\tgoto out_err;\n\t\t\t}\n\t\t}\n\n\t\tget_online_cpus();\n\t\t/*\n\t\t * Fire off all the required work handlers\n\t\t * We can't schedule on offline CPUs, but it's not necessary\n\t\t * since we can change their buffer sizes without any race.\n\t\t */\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\t\t\tif (!cpu_buffer->nr_pages_to_update)\n\t\t\t\tcontinue;\n\n\t\t\t/* Can't run something on an offline CPU. */\n\t\t\tif (!cpu_online(cpu)) {\n\t\t\t\trb_update_pages(cpu_buffer);\n\t\t\t\tcpu_buffer->nr_pages_to_update = 0;\n\t\t\t} else {\n\t\t\t\tschedule_work_on(cpu,\n\t\t\t\t\t\t&cpu_buffer->update_pages_work);\n\t\t\t}\n\t\t}\n\n\t\t/* wait for all the updates to complete */\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\t\t\tif (!cpu_buffer->nr_pages_to_update)\n\t\t\t\tcontinue;\n\n\t\t\tif (cpu_online(cpu))\n\t\t\t\twait_for_completion(&cpu_buffer->update_done);\n\t\t\tcpu_buffer->nr_pages_to_update = 0;\n\t\t}\n\n\t\tput_online_cpus();\n\t} else {\n\t\t/* Make sure this CPU has been intitialized */\n\t\tif (!cpumask_test_cpu(cpu_id, buffer->cpumask))\n\t\t\tgoto out;\n\n\t\tcpu_buffer = buffer->buffers[cpu_id];\n\n\t\tif (nr_pages == cpu_buffer->nr_pages)\n\t\t\tgoto out;\n\n\t\tcpu_buffer->nr_pages_to_update = nr_pages -\n\t\t\t\t\t\tcpu_buffer->nr_pages;\n\n\t\tINIT_LIST_HEAD(&cpu_buffer->new_pages);\n\t\tif (cpu_buffer->nr_pages_to_update > 0 &&\n\t\t\t__rb_allocate_pages(cpu_buffer->nr_pages_to_update,\n\t\t\t\t\t    &cpu_buffer->new_pages, cpu_id)) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto out_err;\n\t\t}\n\n\t\tget_online_cpus();\n\n\t\t/* Can't run something on an offline CPU. */\n\t\tif (!cpu_online(cpu_id))\n\t\t\trb_update_pages(cpu_buffer);\n\t\telse {\n\t\t\tschedule_work_on(cpu_id,\n\t\t\t\t\t &cpu_buffer->update_pages_work);\n\t\t\twait_for_completion(&cpu_buffer->update_done);\n\t\t}\n\n\t\tcpu_buffer->nr_pages_to_update = 0;\n\t\tput_online_cpus();\n\t}\n\n out:\n\t/*\n\t * The ring buffer resize can happen with the ring buffer\n\t * enabled, so that the update disturbs the tracing as little\n\t * as possible. But if the buffer is disabled, we do not need\n\t * to worry about that, and we can take the time to verify\n\t * that the buffer is not corrupt.\n\t */\n\tif (atomic_read(&buffer->record_disabled)) {\n\t\tatomic_inc(&buffer->record_disabled);\n\t\t/*\n\t\t * Even though the buffer was disabled, we must make sure\n\t\t * that it is truly disabled before calling rb_check_pages.\n\t\t * There could have been a race between checking\n\t\t * record_disable and incrementing it.\n\t\t */\n\t\tsynchronize_sched();\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\t\t\trb_check_pages(cpu_buffer);\n\t\t}\n\t\tatomic_dec(&buffer->record_disabled);\n\t}\n\n\tmutex_unlock(&buffer->mutex);\n\treturn size;\n\n out_err:\n\tfor_each_buffer_cpu(buffer, cpu) {\n\t\tstruct buffer_page *bpage, *tmp;\n\n\t\tcpu_buffer = buffer->buffers[cpu];\n\t\tcpu_buffer->nr_pages_to_update = 0;\n\n\t\tif (list_empty(&cpu_buffer->new_pages))\n\t\t\tcontinue;\n\n\t\tlist_for_each_entry_safe(bpage, tmp, &cpu_buffer->new_pages,\n\t\t\t\t\tlist) {\n\t\t\tlist_del_init(&bpage->list);\n\t\t\tfree_buffer_page(bpage);\n\t\t}\n\t}\n\tmutex_unlock(&buffer->mutex);\n\treturn err;\n}", "commit_link": "github.com/torvalds/linux/commit/59643d1535eb220668692a5359de22545af579f6", "file_name": "kernel/trace/ring_buffer.c", "vul_type": "cwe-190", "description": "Write a C function to resize a ring buffer for a specific CPU or all CPUs, handling memory allocation and synchronization issues."}
{"func_name": "add_translationname", "func_src_before": "    def add_translationname(self, trname):\n        \"\"\"Add new translation by item name for an item.\"\"\"\n        if self.connection:\n            for item in self.find_item_name([trname[0], '0']):\n                self.cursor.execute('insert into itemtranslation (itemid, itemlanguageid, translation) values (\"%s\", \"%s\", \"%s\")' % (item[0], trname[1], trname[2]))\n            self.connection.commit()", "func_src_after": "    def add_translationname(self, trname):\n        \"\"\"Add new translation by item name for an item.\"\"\"\n        if self.connection:\n            for item in self.find_item_name([trname[0], '0']):\n                t = (item[0], trname[1], trname[2], )\n                self.cursor.execute('insert into itemtranslation (itemid, itemlanguageid, translation) values (?, ?, ?)', t)\n            self.connection.commit()", "commit_link": "github.com/ecosl-developers/ecosl/commit/8af050a513338bf68ff2a243e4a2482d24e9aa3a", "file_name": "ecosldb/ecosldb.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a new translation into a database given an item name and translation details."}
{"func_name": "test_dynamic_dependencies", "func_src_before": "    def test_dynamic_dependencies(self):\n\n        class DynamicRequires(Task):\n            p = luigi.Parameter()\n\n            def output(self):\n                return luigi.LocalTarget(os.path.join(self.p, 'parent'))\n\n            def run(self):\n                dummy_targets = yield [DynamicDummyTask(os.path.join(self.p, str(i)))\n                                     for i in range(5)]\n                dummy_targets += yield [DynamicDummyTask(os.path.join(self.p, str(i)))\n                                       for i in range(5, 7)]\n                with self.output().open('w') as f:\n                    for i, d in enumerate(dummy_targets):\n                        for line in d.open('r'):\n                            print >>f, '%d: %s' % (i, line.strip())\n\n        t = DynamicRequires(p=tempfile.mktemp())\n        luigi.build([t], local_scheduler=True)\n        self.assertTrue(t.complete())\n\n        # loop through output and verify\n        f = t.output().open('r')\n        for i in xrange(7):\n            self.assertEqual(f.readline().strip(), '%d: Done!' % i)", "func_src_after": "    def test_dynamic_dependencies(self):\n\n        class DynamicRequires(Task):\n            p = luigi.Parameter()\n\n            def output(self):\n                return luigi.LocalTarget(os.path.join(self.p, 'parent'))\n\n            def run(self):\n                dummy_targets = yield [DynamicDummyTask(os.path.join(self.p, str(i)))\n                                     for i in range(5)]\n                dummy_targets += yield [DynamicDummyTask(os.path.join(self.p, str(i)))\n                                       for i in range(5, 7)]\n                with self.output().open('w') as f:\n                    for i, d in enumerate(dummy_targets):\n                        for line in d.open('r'):\n                            print >>f, '%d: %s' % (i, line.strip())\n\n        p = tempfile.mkdtemp()\n        try:\n            t = DynamicRequires(p=p)\n            luigi.build([t], local_scheduler=True)\n            self.assertTrue(t.complete())\n\n            # loop through output and verify\n            f = t.output().open('r')\n            for i in xrange(7):\n                self.assertEqual(f.readline().strip(), '%d: Done!' % i)\n        finally:\n            shutil.rmtree(p)", "line_changes": {"deleted": [{"line_no": 19, "char_start": 762, "char_end": 811, "line": "        t = DynamicRequires(p=tempfile.mktemp())\n"}, {"line_no": 20, "char_start": 811, "char_end": 858, "line": "        luigi.build([t], local_scheduler=True)\n"}, {"line_no": 21, "char_start": 858, "char_end": 896, "line": "        self.assertTrue(t.complete())\n"}, {"line_no": 22, "char_start": 896, "char_end": 897, "line": "\n"}, {"line_no": 24, "char_start": 938, "char_end": 971, "line": "        f = t.output().open('r')\n"}, {"line_no": 25, "char_start": 971, "char_end": 999, "line": "        for i in xrange(7):\n"}, {"line_no": 26, "char_start": 999, "char_end": 1066, "line": "            self.assertEqual(f.readline().strip(), '%d: Done!' % i)\n"}], "added": [{"line_no": 19, "char_start": 762, "char_end": 793, "line": "        p = tempfile.mkdtemp()\n"}, {"line_no": 20, "char_start": 793, "char_end": 806, "line": "        try:\n"}, {"line_no": 21, "char_start": 806, "char_end": 843, "line": "            t = DynamicRequires(p=p)\n"}, {"line_no": 22, "char_start": 843, "char_end": 894, "line": "            luigi.build([t], local_scheduler=True)\n"}, {"line_no": 23, "char_start": 894, "char_end": 936, "line": "            self.assertTrue(t.complete())\n"}, {"line_no": 24, "char_start": 936, "char_end": 937, "line": "\n"}, {"line_no": 26, "char_start": 982, "char_end": 1019, "line": "            f = t.output().open('r')\n"}, {"line_no": 27, "char_start": 1019, "char_end": 1051, "line": "            for i in xrange(7):\n"}, {"line_no": 28, "char_start": 1051, "char_end": 1123, "line": "                self.assertEqual(f.readline().strip(), '%d: Done!' % i)\n"}, {"line_no": 29, "char_start": 1123, "char_end": 1140, "line": "        finally:\n"}, {"line_no": 30, "char_start": 1140, "char_end": 1168, "line": "            shutil.rmtree(p)\n"}]}, "char_changes": {"deleted": [{"char_start": 792, "char_end": 811, "chars": "tempfile.mktemp())\n"}], "added": [{"char_start": 762, "char_end": 810, "chars": "        p = tempfile.mkdtemp()\n        try:\n    "}, {"char_start": 840, "char_end": 846, "chars": "p)\n   "}, {"char_start": 854, "char_end": 855, "chars": " "}, {"char_start": 902, "char_end": 906, "chars": "    "}, {"char_start": 937, "char_end": 941, "chars": "    "}, {"char_start": 990, "char_end": 994, "chars": "    "}, {"char_start": 1019, "char_end": 1023, "chars": "    "}, {"char_start": 1063, "char_end": 1067, "chars": "    "}, {"char_start": 1122, "char_end": 1168, "chars": "\n        finally:\n            shutil.rmtree(p)"}]}, "commit_link": "github.com/hadesbox/luigi/commit/8d47de4c1e2849e13c98f6dc52088f9a672b3944", "file_name": "worker_test.py", "vul_type": "cwe-377", "commit_msg": "Possible flakiness fix for test_dynamic_dependencies\n\ntest_dynamic_dependencies has been flaky lately (see #571). I can't reproduce it\nlocally, so I assume it has something to do with Travis running things more in\nparallel than I do. test_dynamic_dependencies uses mktemp, which according to\nthe tempfile documentation should not be used and causes race conditions in\nwhich another program may get access to the temp file first. Replacing this with\nmkdtemp should fix the issue while also clarifying that a temporary directory is\nwanted and not a temporary file. I haven't been able to verify that this will\nfix the flakiness, but it should probably be done anyway. I also added cleanup.", "description": "Write a Python function using Luigi to dynamically generate and process tasks, then verify the output."}
{"func_name": "_add_volume_to_volume_set", "func_src_before": "    def _add_volume_to_volume_set(self, volume, volume_name,\n                                  cpg, vvs_name, qos):\n        if vvs_name is not None:\n            # Admin has set a volume set name to add the volume to\n            self._cli_run('createvvset -add %s %s' % (vvs_name,\n                                                      volume_name), None)\n        else:\n            vvs_name = self._get_3par_vvs_name(volume['id'])\n            domain = self.get_domain(cpg)\n            self._cli_run('createvvset -domain %s %s' % (domain,\n                                                         vvs_name), None)\n            self._set_qos_rule(qos, vvs_name)\n            self._cli_run('createvvset -add %s %s' % (vvs_name,\n                                                      volume_name), None)", "func_src_after": "    def _add_volume_to_volume_set(self, volume, volume_name,\n                                  cpg, vvs_name, qos):\n        if vvs_name is not None:\n            # Admin has set a volume set name to add the volume to\n            self._cli_run(['createvvset', '-add', vvs_name, volume_name])\n        else:\n            vvs_name = self._get_3par_vvs_name(volume['id'])\n            domain = self.get_domain(cpg)\n            self._cli_run(['createvvset', '-domain', domain, vvs_name])\n            self._set_qos_rule(qos, vvs_name)\n            self._cli_run(['createvvset', '-add', vvs_name, volume_name])", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function to add a volume to a volume set, optionally creating the set and applying QoS rules if the set doesn't exist."}
{"func_name": "handle_message", "func_src_before": "    def handle_message(self, ch, method, properties, body):\n        \"\"\"\n        this is a pika.basic_consumer callback\n        handles client inputs, runs appropriate workflows and views\n\n        Args:\n            ch: amqp channel\n            method: amqp method\n            properties:\n            body: message body\n        \"\"\"\n        input = {}\n        try:\n            self.sessid = method.routing_key\n\n            input = json_decode(body)\n            data = input['data']\n\n            # since this comes as \"path\" we dont know if it's view or workflow yet\n            #TODO: just a workaround till we modify ui to\n            if 'path' in data:\n                if data['path'] in settings.VIEW_URLS:\n                    data['view'] = data['path']\n                else:\n                    data['wf'] = data['path']\n            session = Session(self.sessid)\n\n            headers = {'remote_ip': input['_zops_remote_ip']}\n\n            if 'wf' in data:\n                output = self._handle_workflow(session, data, headers)\n            elif 'job' in data:\n\n                self._handle_job(session, data, headers)\n                return\n            else:\n                output = self._handle_view(session, data, headers)\n\n        except HTTPError as e:\n            import sys\n            if hasattr(sys, '_called_from_test'):\n                raise\n            output = {'cmd': 'error', 'error': self._prepare_error_msg(e.message), \"code\": e.code}\n            log.exception(\"Http error occurred\")\n        except:\n            self.current = Current(session=session, input=data)\n            self.current.headers = headers\n            import sys\n            if hasattr(sys, '_called_from_test'):\n                raise\n            err = traceback.format_exc()\n            output = {'error': self._prepare_error_msg(err), \"code\": 500}\n            log.exception(\"Worker error occurred with messsage body:\\n%s\" % body)\n        if 'callbackID' in input:\n            output['callbackID'] = input['callbackID']\n        log.info(\"OUTPUT for %s: %s\" % (self.sessid, output))\n        output['reply_timestamp'] = time()\n        self.send_output(output)", "func_src_after": "    def handle_message(self, ch, method, properties, body):\n        \"\"\"\n        this is a pika.basic_consumer callback\n        handles client inputs, runs appropriate workflows and views\n\n        Args:\n            ch: amqp channel\n            method: amqp method\n            properties:\n            body: message body\n        \"\"\"\n        input = {}\n        headers = {}\n        try:\n            self.sessid = method.routing_key\n\n            input = json_decode(body)\n            data = input['data']\n\n            # since this comes as \"path\" we dont know if it's view or workflow yet\n            # TODO: just a workaround till we modify ui to\n            if 'path' in data:\n                if data['path'] in settings.VIEW_URLS:\n                    data['view'] = data['path']\n                else:\n                    data['wf'] = data['path']\n            session = Session(self.sessid)\n\n            headers = {'remote_ip': input['_zops_remote_ip'],\n                       'source': input['_zops_source']}\n\n            if 'wf' in data:\n                output = self._handle_workflow(session, data, headers)\n            elif 'job' in data:\n\n                self._handle_job(session, data, headers)\n                return\n            else:\n                output = self._handle_view(session, data, headers)\n\n        except HTTPError as e:\n            import sys\n            if hasattr(sys, '_called_from_test'):\n                raise\n            output = {'cmd': 'error', 'error': self._prepare_error_msg(e.message), \"code\": e.code}\n            log.exception(\"Http error occurred\")\n        except:\n            self.current = Current(session=session, input=data)\n            self.current.headers = headers\n            import sys\n            if hasattr(sys, '_called_from_test'):\n                raise\n            err = traceback.format_exc()\n            output = {'error': self._prepare_error_msg(err), \"code\": 500}\n            log.exception(\"Worker error occurred with messsage body:\\n%s\" % body)\n        if 'callbackID' in input:\n            output['callbackID'] = input['callbackID']\n        log.info(\"OUTPUT for %s: %s\" % (self.sessid, output))\n        output['reply_timestamp'] = time()\n        self.send_output(output)", "commit_link": "github.com/zetaops/zengine/commit/52eafbee90f8ddf78be0c7452828d49423246851", "file_name": "zengine/wf_daemon.py", "vul_type": "cwe-078", "description": "Write a Python function `handle_message` that processes AMQP messages to run workflows or views based on the message content."}
{"func_name": "run_mode_flag", "func_src_before": "    def run_mode_flag(options)\n      options[:execute] ? ' --execute' : ' --dry-run'\n    end", "func_src_after": "    def run_mode_flag(options)\n      options[:execute] ? '--execute' : '--dry-run'\n    end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 31, "char_end": 85, "line": "      options[:execute] ? ' --execute' : ' --dry-run'\n"}], "added": [{"line_no": 2, "char_start": 31, "char_end": 83, "line": "      options[:execute] ? '--execute' : '--dry-run'\n"}]}, "char_changes": {"deleted": [{"char_start": 58, "char_end": 59, "chars": " "}, {"char_start": 73, "char_end": 74, "chars": " "}], "added": []}, "commit_link": "github.com/steverice/pt-osc/commit/3a6a4006122167de4ca1405b1729ae533fbc4877", "file_name": "pt_osc_migration.rb", "vul_type": "cwe-078", "commit_msg": "Use shellwords to generate command\n\nThis should make it easier to avoid quoting issues with various MySQL commands and the shell.\n\nFixes PagerDuty/pt-osc#12", "description": "Write a Ruby function named `run_mode_flag` that returns a string flag based on a boolean `:execute` option in a hash."}
{"func_name": "choose_volume", "func_src_before": "choose_volume(struct archive_read *a, struct iso9660 *iso9660)\n{\n\tstruct file_info *file;\n\tint64_t skipsize;\n\tstruct vd *vd;\n\tconst void *block;\n\tchar seenJoliet;\n\n\tvd = &(iso9660->primary);\n\tif (!iso9660->opt_support_joliet)\n\t\tiso9660->seenJoliet = 0;\n\tif (iso9660->seenJoliet &&\n\t\tvd->location > iso9660->joliet.location)\n\t\t/* This condition is unlikely; by way of caution. */\n\t\tvd = &(iso9660->joliet);\n\n\tskipsize = LOGICAL_BLOCK_SIZE * vd->location;\n\tskipsize = __archive_read_consume(a, skipsize);\n\tif (skipsize < 0)\n\t\treturn ((int)skipsize);\n\tiso9660->current_position = skipsize;\n\n\tblock = __archive_read_ahead(a, vd->size, NULL);\n\tif (block == NULL) {\n\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t    \"Failed to read full block when scanning \"\n\t\t    \"ISO9660 directory list\");\n\t\treturn (ARCHIVE_FATAL);\n\t}\n\n\t/*\n\t * While reading Root Directory, flag seenJoliet must be zero to\n\t * avoid converting special name 0x00(Current Directory) and\n\t * next byte to UCS2.\n\t */\n\tseenJoliet = iso9660->seenJoliet;/* Save flag. */\n\tiso9660->seenJoliet = 0;\n\tfile = parse_file_info(a, NULL, block);\n\tif (file == NULL)\n\t\treturn (ARCHIVE_FATAL);\n\tiso9660->seenJoliet = seenJoliet;\n\n\t/*\n\t * If the iso image has both RockRidge and Joliet, we preferentially\n\t * use RockRidge Extensions rather than Joliet ones.\n\t */\n\tif (vd == &(iso9660->primary) && iso9660->seenRockridge\n\t    && iso9660->seenJoliet)\n\t\tiso9660->seenJoliet = 0;\n\n\tif (vd == &(iso9660->primary) && !iso9660->seenRockridge\n\t    && iso9660->seenJoliet) {\n\t\t/* Switch reading data from primary to joliet. */\n\t\tvd = &(iso9660->joliet);\n\t\tskipsize = LOGICAL_BLOCK_SIZE * vd->location;\n\t\tskipsize -= iso9660->current_position;\n\t\tskipsize = __archive_read_consume(a, skipsize);\n\t\tif (skipsize < 0)\n\t\t\treturn ((int)skipsize);\n\t\tiso9660->current_position += skipsize;\n\n\t\tblock = __archive_read_ahead(a, vd->size, NULL);\n\t\tif (block == NULL) {\n\t\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t\t    \"Failed to read full block when scanning \"\n\t\t\t    \"ISO9660 directory list\");\n\t\t\treturn (ARCHIVE_FATAL);\n\t\t}\n\t\tiso9660->seenJoliet = 0;\n\t\tfile = parse_file_info(a, NULL, block);\n\t\tif (file == NULL)\n\t\t\treturn (ARCHIVE_FATAL);\n\t\tiso9660->seenJoliet = seenJoliet;\n\t}\n\n\t/* Store the root directory in the pending list. */\n\tif (add_entry(a, iso9660, file) != ARCHIVE_OK)\n\t\treturn (ARCHIVE_FATAL);\n\tif (iso9660->seenRockridge) {\n\t\ta->archive.archive_format = ARCHIVE_FORMAT_ISO9660_ROCKRIDGE;\n\t\ta->archive.archive_format_name =\n\t\t    \"ISO9660 with Rockridge extensions\";\n\t}\n\n\treturn (ARCHIVE_OK);\n}", "func_src_after": "choose_volume(struct archive_read *a, struct iso9660 *iso9660)\n{\n\tstruct file_info *file;\n\tint64_t skipsize;\n\tstruct vd *vd;\n\tconst void *block;\n\tchar seenJoliet;\n\n\tvd = &(iso9660->primary);\n\tif (!iso9660->opt_support_joliet)\n\t\tiso9660->seenJoliet = 0;\n\tif (iso9660->seenJoliet &&\n\t\tvd->location > iso9660->joliet.location)\n\t\t/* This condition is unlikely; by way of caution. */\n\t\tvd = &(iso9660->joliet);\n\n\tskipsize = LOGICAL_BLOCK_SIZE * (int64_t)vd->location;\n\tskipsize = __archive_read_consume(a, skipsize);\n\tif (skipsize < 0)\n\t\treturn ((int)skipsize);\n\tiso9660->current_position = skipsize;\n\n\tblock = __archive_read_ahead(a, vd->size, NULL);\n\tif (block == NULL) {\n\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t    \"Failed to read full block when scanning \"\n\t\t    \"ISO9660 directory list\");\n\t\treturn (ARCHIVE_FATAL);\n\t}\n\n\t/*\n\t * While reading Root Directory, flag seenJoliet must be zero to\n\t * avoid converting special name 0x00(Current Directory) and\n\t * next byte to UCS2.\n\t */\n\tseenJoliet = iso9660->seenJoliet;/* Save flag. */\n\tiso9660->seenJoliet = 0;\n\tfile = parse_file_info(a, NULL, block);\n\tif (file == NULL)\n\t\treturn (ARCHIVE_FATAL);\n\tiso9660->seenJoliet = seenJoliet;\n\n\t/*\n\t * If the iso image has both RockRidge and Joliet, we preferentially\n\t * use RockRidge Extensions rather than Joliet ones.\n\t */\n\tif (vd == &(iso9660->primary) && iso9660->seenRockridge\n\t    && iso9660->seenJoliet)\n\t\tiso9660->seenJoliet = 0;\n\n\tif (vd == &(iso9660->primary) && !iso9660->seenRockridge\n\t    && iso9660->seenJoliet) {\n\t\t/* Switch reading data from primary to joliet. */\n\t\tvd = &(iso9660->joliet);\n\t\tskipsize = LOGICAL_BLOCK_SIZE * (int64_t)vd->location;\n\t\tskipsize -= iso9660->current_position;\n\t\tskipsize = __archive_read_consume(a, skipsize);\n\t\tif (skipsize < 0)\n\t\t\treturn ((int)skipsize);\n\t\tiso9660->current_position += skipsize;\n\n\t\tblock = __archive_read_ahead(a, vd->size, NULL);\n\t\tif (block == NULL) {\n\t\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t\t    \"Failed to read full block when scanning \"\n\t\t\t    \"ISO9660 directory list\");\n\t\t\treturn (ARCHIVE_FATAL);\n\t\t}\n\t\tiso9660->seenJoliet = 0;\n\t\tfile = parse_file_info(a, NULL, block);\n\t\tif (file == NULL)\n\t\t\treturn (ARCHIVE_FATAL);\n\t\tiso9660->seenJoliet = seenJoliet;\n\t}\n\n\t/* Store the root directory in the pending list. */\n\tif (add_entry(a, iso9660, file) != ARCHIVE_OK)\n\t\treturn (ARCHIVE_FATAL);\n\tif (iso9660->seenRockridge) {\n\t\ta->archive.archive_format = ARCHIVE_FORMAT_ISO9660_ROCKRIDGE;\n\t\ta->archive.archive_format_name =\n\t\t    \"ISO9660 with Rockridge extensions\";\n\t}\n\n\treturn (ARCHIVE_OK);\n}", "commit_link": "github.com/libarchive/libarchive/commit/3ad08e01b4d253c66ae56414886089684155af22", "file_name": "libarchive/archive_read_support_format_iso9660.c", "vul_type": "cwe-190", "description": "In C, write a function `choose_volume` that selects the appropriate volume descriptor for an ISO9660 archive and reads the root directory block."}
{"func_name": "simple_search", "func_src_before": "    @classmethod\n    def simple_search(cls, query, using=None, index=None):\n        es_search = cls.search(using=using, index=index)\n        es_query = cls.get_es_query(query=query)\n        highlighted_fields = [f.split('^', 1)[0] for f in cls.search_fields]\n\n        es_search = es_search.query(es_query).highlight(*highlighted_fields)\n        return es_search", "func_src_after": "    @classmethod\n    def simple_search(cls, query, using=None, index=None):\n        \"\"\"\n        Do a search without facets.\n\n        This is used in:\n\n        * The Docsearch API\n        * The Project Admin Search page\n        \"\"\"\n\n        es_search = cls.search(using=using, index=index)\n        es_search = es_search.highlight_options(encoder='html')\n\n        es_query = cls.get_es_query(query=query)\n        highlighted_fields = [f.split('^', 1)[0] for f in cls.search_fields]\n        es_search = es_search.query(es_query).highlight(*highlighted_fields)\n\n        return es_search", "commit_link": "github.com/readthedocs/readthedocs.org/commit/1ebe494ffde18109307f205d2bd94102452f697a", "file_name": "readthedocs/search/documents.py", "vul_type": "cwe-079", "description": "Write a Python class method that performs a simple search with optional highlighting, without using facets."}
{"func_name": "incrementOption", "func_src_before": "def incrementOption(cursor, poll_name, option):\n    key = poll_name+\"-\"+option\n    req = \"UPDATE {} SET count=count+1 WHERE name_option = '{}';\".format(CFG(\"options_table_name\"), key)\n    cursor.execute(req)", "func_src_after": "def incrementOption(cursor, poll_name, option):\n    key = poll_name+\"-\"+option\n    req = \"UPDATE {} SET count=count+1 WHERE name_option=?\".format(CFG(\"options_table_name\"))\n    cursor.execute(req, (key,))", "commit_link": "github.com/FAUSheppy/simple-python-poll/commit/186c5ff5cdf58272e253a1bb432419ee50d93109", "file_name": "database.py", "vul_type": "cwe-089", "description": "Write a Python function to increment the vote count for a given option in a poll using SQL."}
{"func_name": "(anonymous)", "func_src_before": "  return buffer.join('');\n};\n\nvar FilesView = React.createClass({\n  onLoadMore: function(event) {\n    Model.LoadMore(this.props.repo);\n  },\n\n  render: function() {\n    var rev = this.props.rev,\n        repo = this.props.repo,\n        regexp = this.props.regexp,\n        matches = this.props.matches,\n        totalMatches = this.props.totalMatches;\n    var files = matches.map(function(match, index) {\n      var filename = match.Filename,\n          blocks = CoalesceMatches(match.Matches);\n      var matches = blocks.map(function(block) {\n        var lines = block.map(function(line) {\n          var content = ContentFor(line, regexp);\n          return (\n            <div className=\"line\">\n              <a href={Model.UrlToRepo(repo, filename, line.Number, rev)}\n                  className=\"lnum\"\n                  target=\"_blank\">{line.Number}</a>\n              <span className=\"lval\" dangerouslySetInnerHTML={{__html:content}} />\n            </div>\n          );\n        });\n\n        return (\n          <div className=\"match\">{lines}</div>", "func_src_after": "  return buffer.join('');\n};\n\nvar FilesView = React.createClass({\n  onLoadMore: function(event) {\n    Model.LoadMore(this.props.repo);\n  },\n\n  render: function() {\n    var rev = this.props.rev,\n        repo = this.props.repo,\n        regexp = this.props.regexp,\n        matches = this.props.matches,\n        totalMatches = this.props.totalMatches;\n    var files = matches.map(function(match, index) {\n      var filename = match.Filename,\n          blocks = CoalesceMatches(match.Matches);\n      var matches = blocks.map(function(block) {\n        var lines = block.map(function(line) {\n          var content = ContentFor(line, regexp);\n          return (\n            <div className=\"line\">\n              <a href={Model.UrlToRepo(repo, filename, line.Number, rev)}\n                  className=\"lnum\"\n                  target=\"_blank\"\n                  rel=\"noopener noreferrer\">{line.Number}</a>\n              <span className=\"lval\" dangerouslySetInnerHTML={{__html:content}} />\n            </div>\n          );\n        });\n\n        return (\n          <div className=\"match\">{lines}</div>\n        );\n      });", "line_changes": {"deleted": [{"line_no": 25, "char_start": 798, "char_end": 850, "line": "                  target=\"_blank\">{line.Number}</a>\n"}], "added": [{"line_no": 25, "char_start": 798, "char_end": 832, "line": "                  target=\"_blank\"\n"}, {"line_no": 26, "char_start": 832, "char_end": 894, "line": "                  rel=\"noopener noreferrer\">{line.Number}</a>\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 831, "char_end": 875, "chars": "\n                  rel=\"noopener noreferrer\""}, {"char_start": 1085, "char_end": 1106, "chars": "\n        );\n      });"}]}, "commit_link": "github.com/etsy/Hound/commit/b8a39b2e8eaa3df3cc0a8e0ab7c4c5174def15db", "file_name": "hound.js", "vul_type": "cwe-200", "commit_msg": "Give repo links a target of blank (#404)\n\nAdd rel=\"noopener noreferrer\" to _blank links", "parent_commit": "ca5c7c8c1dc6753b0bbe2bdd0ad3c934969f7cf6", "description": "Create a React component in JavaScript that displays matched lines from a repository with links to the source."}
{"func_name": "fetch_page_name", "func_src_before": "  def fetch_page_name(self, page_id):\n    '''\n    Returns the page name corresponding to the provided page ID.\n\n    Args:\n      page_id: The page ID whose ID to fetch.\n\n    Returns:\n      str: The page name corresponding to the provided page ID.\n\n    Raises:\n      ValueError: If the provided page ID is invalid or does not exist.\n    '''\n    helpers.validate_page_id(page_id)\n\n    query = 'SELECT name FROM pages WHERE id=\"{0}\"'.format(page_id)\n    self.cursor.execute(query)\n\n    page_name = self.cursor.fetchone()\n\n    if not page_name:\n      raise ValueError('Invalid page ID \"{0}\" provided. Page ID does not exist.'.format(page_id))\n\n    return page_name[0].encode('utf-8').replace('_', ' ')", "func_src_after": "  def fetch_page_name(self, page_id):\n    '''\n    Returns the page name corresponding to the provided page ID.\n\n    Args:\n      page_id: The page ID whose ID to fetch.\n\n    Returns:\n      str: The page name corresponding to the provided page ID.\n\n    Raises:\n      ValueError: If the provided page ID is invalid or does not exist.\n    '''\n    helpers.validate_page_id(page_id)\n\n    query = 'SELECT name FROM pages WHERE id = ?;'\n    query_bindings = (page_id,)\n    self.cursor.execute(query, query_bindings)\n\n    page_name = self.cursor.fetchone()\n\n    if not page_name:\n      raise ValueError('Invalid page ID \"{0}\" provided. Page ID does not exist.'.format(page_id))\n\n    return page_name[0].encode('utf-8').replace('_', ' ')", "commit_link": "github.com/jwngr/sdow/commit/4db98f3521592f17550d2b723336f33fec5e112a", "file_name": "sdow/database.py", "vul_type": "cwe-089", "description": "Write a Python function to retrieve and return a page name from a database using a page ID, handling invalid IDs with an error."}
{"func_name": "download_check_files", "func_src_before": "    def download_check_files(self, filelist):\n        # only admins and allowed users may download\n        if not cherrypy.session['admin']:\n            uo = self.useroptions.forUser(self.getUserId())\n            if not uo.getOptionValue('media.may_download'):\n                return 'not_permitted'\n        # make sure nobody tries to escape from basedir\n        for f in filelist:\n            if '/../' in f:\n                return 'invalid_file'\n        # make sure all files are smaller than maximum download size\n        size_limit = cherry.config['media.maximum_download_size']\n        try:\n            if self.model.file_size_within_limit(filelist, size_limit):\n                return 'ok'\n            else:\n                return 'too_big'\n        except OSError as e:        # use OSError for python2 compatibility\n            return str(e)", "func_src_after": "    def download_check_files(self, filelist):\n        # only admins and allowed users may download\n        if not cherrypy.session['admin']:\n            uo = self.useroptions.forUser(self.getUserId())\n            if not uo.getOptionValue('media.may_download'):\n                return 'not_permitted'\n        # make sure nobody tries to escape from basedir\n        for f in filelist:\n            # don't allow to traverse up in the file system\n            if '/../' in f or f.startswith('../'):\n                return 'invalid_file'\n            # CVE-2015-8309: do not allow absolute file paths\n            if os.path.isabs(f):\n                return 'invalid_file'\n        # make sure all files are smaller than maximum download size\n        size_limit = cherry.config['media.maximum_download_size']\n        try:\n            if self.model.file_size_within_limit(filelist, size_limit):\n                return 'ok'\n            else:\n                return 'too_big'\n        except OSError as e:        # use OSError for python2 compatibility\n            return str(e)", "commit_link": "github.com/devsnd/cherrymusic/commit/62dec34a1ea0741400dd6b6c660d303dcd651e86", "file_name": "cherrymusicserver/httphandler.py", "vul_type": "cwe-022", "description": "Write a Python function named `download_check_files` that validates a list of file paths for download permissions, path security, and size constraints."}
{"func_name": "wwunpack", "func_src_before": "int wwunpack(uint8_t *exe, uint32_t exesz, uint8_t *wwsect, struct cli_exe_section *sects, uint16_t scount, uint32_t pe, int desc) {\n  uint8_t *structs = wwsect + 0x2a1, *compd, *ccur, *unpd, *ucur, bc;\n  uint32_t src, srcend, szd, bt, bits;\n  int error=0, i;\n\n  cli_dbgmsg(\"in wwunpack\\n\");\n  while (1) {\n    if (!CLI_ISCONTAINED(wwsect, sects[scount].rsz, structs, 17)) {\n      cli_dbgmsg(\"WWPack: Array of structs out of section\\n\");\n      break;\n    }\n    src = sects[scount].rva - cli_readint32(structs); /* src delta / dst delta - not used / dwords / end of src */\n    structs+=8;\n    szd = cli_readint32(structs) * 4;\n    structs+=4;\n    srcend = cli_readint32(structs);\n    structs+=4;\n\n    unpd = ucur = exe+src+srcend+4-szd;\n    if (!szd || !CLI_ISCONTAINED(exe, exesz, unpd, szd)) {\n      cli_dbgmsg(\"WWPack: Compressed data out of file\\n\");\n      break;\n    }\n    cli_dbgmsg(\"WWP: src: %x, szd: %x, srcend: %x - %x\\n\", src, szd, srcend, srcend+4-szd);\n    if (!(compd = cli_malloc(szd))) {\n        cli_dbgmsg(\"WWPack: Unable to allocate memory for compd\\n\");\n        break;\n    }\n    memcpy(compd, unpd, szd);\n    memset(unpd, -1, szd); /*FIXME*/\n    ccur=compd;\n    \n    RESEED;\n    while(!error) {\n      uint32_t backbytes, backsize;\n      uint8_t saved;\n\n      BIT;\n      if (!bits) { /* BYTE copy */\n\tif(ccur-compd>=szd || !CLI_ISCONTAINED(exe, exesz, ucur, 1))\n\t  error=1;\n\telse\n\t  *ucur++=*ccur++;\n\tcontinue;\n      }\n\n      BITS(2);\n      if(bits==3) { /* WORD backcopy */\n\tuint8_t shifted, subbed = 31;\n\tBITS(2);\n\tshifted = bits + 5;\n\tif(bits>=2) {\n\t  shifted++;\n\t  subbed += 0x80;\n\t}\n\tbackbytes = (1<<shifted)-subbed; /* 1h, 21h, 61h, 161h */\n\tBITS(shifted); /* 5, 6, 8, 9 */\n\tif(error || bits == 0x1ff) break;\n\tbackbytes+=bits;\n\tif(!CLI_ISCONTAINED(exe, exesz, ucur, 2) || !CLI_ISCONTAINED(exe, exesz, ucur-backbytes, 2)) {\n\t  error=1;\n\t} else {\n\t  ucur[0]=*(ucur-backbytes);\n\t  ucur[1]=*(ucur-backbytes+1);\n\t  ucur+=2;\n\t}\n\tcontinue;\n      }\n\n      /* BLOCK backcopy */\n      saved = bits; /* cmp al, 1 / pushf */\n\n      BITS(3);\n      if (bits<6) {\n\tbackbytes = bits;\n\tswitch(bits) {\n\tcase 4: /* 10,11 */\n\t  backbytes++;\n\tcase 3: /* 8,9 */\n\t  BIT;\n\t  backbytes+=bits;\n\tcase 0:\tcase 1:\tcase 2: /* 5,6,7 */\n\t  backbytes+=5;\n\t  break;\n\tcase 5: /* 12 */\n\t  backbytes=12;\n\t  break;\n\t}\n\tBITS(backbytes);\n\tbits+=(1<<backbytes)-31;\n      } else if(bits==6) {\n\tBITS(0x0e);\n\tbits+=0x1fe1;\n      } else {\n\tBITS(0x0f);\n\tbits+=0x5fe1;\n      }\n\n      backbytes = bits;\n\n      /* popf / jb */\n      if (!saved) {\n\tBIT;\n\tif(!bits) {\n\t  BIT;\n\t  bits+=5;\n\t} else {\n\t  BITS(3);\n\t  if(bits) {\n\t    bits+=6;\n\t  } else {\n\t    BITS(4);\n\t    if(bits) {\n\t      bits+=13;\n\t    } else {\n\t      uint8_t cnt = 4;\n\t      uint16_t shifted = 0x0d;\n\t      \n\t      do {\n\t\tif(cnt==7) { cnt = 0x0e; shifted = 0; break; }\n\t\tshifted=((shifted+2)<<1)-1;\n\t\tBIT;\n\t\tcnt++;\n\t      } while(!bits);\n\t      BITS(cnt);\n\t      bits+=shifted;\n\t    }\n\t  }\n\t}\n\tbacksize = bits;\n      } else {\n\tbacksize = saved+2;\n      }\n\n      if(!CLI_ISCONTAINED(exe, exesz, ucur, backsize) || !CLI_ISCONTAINED(exe, exesz, ucur-backbytes, backsize)) error=1;\n      else while(backsize--) {\n\t*ucur=*(ucur-backbytes);\n\tucur++;\n      }\n    }\n    free(compd);\n    if(error) {\n      cli_dbgmsg(\"WWPack: decompression error\\n\");\n      break;\n    }\n    if (error || !*structs++) break;\n  }\n\n  if(!error) {\n    if (pe+6 > exesz || pe+7 > exesz || pe+0x28 > exesz ||\n\t\tpe+0x50 > exesz || pe+0x14 > exesz) \n\treturn CL_EFORMAT;\n    exe[pe+6]=(uint8_t)scount;\n    exe[pe+7]=(uint8_t)(scount>>8);\n    cli_writeint32(&exe[pe+0x28], cli_readint32(wwsect+0x295)+sects[scount].rva+0x299);\n    cli_writeint32(&exe[pe+0x50], cli_readint32(&exe[pe+0x50])-sects[scount].vsz);\n\n    structs = &exe[(0xffff&cli_readint32(&exe[pe+0x14]))+pe+0x18];\n    for(i=0 ; i<scount ; i++) {\n\t  if (!CLI_ISCONTAINED(exe, exesz, structs, 0x28)) {\n\t    cli_dbgmsg(\"WWPack: structs pointer out of bounds\\n\");\n\t    return CL_EFORMAT;\n\t  }\n\n      cli_writeint32(structs+8, sects[i].vsz);\n      cli_writeint32(structs+12, sects[i].rva);\n      cli_writeint32(structs+16, sects[i].vsz);\n      cli_writeint32(structs+20, sects[i].rva);\n      structs+=0x28;\n    }\n\tif (!CLI_ISCONTAINED(exe, exesz, structs, 0x28)) {\n\t  cli_dbgmsg(\"WWPack: structs pointer out of bounds\\n\");\n\t  return CL_EFORMAT;\n\t}\n\n    memset(structs, 0, 0x28);\n    error = (uint32_t)cli_writen(desc, exe, exesz)!=exesz;\n  }\n  return error;\n}", "func_src_after": "int wwunpack(uint8_t *exe, uint32_t exesz, uint8_t *wwsect, struct cli_exe_section *sects, uint16_t scount, uint32_t pe, int desc) {\n  uint8_t *structs = wwsect + 0x2a1, *compd, *ccur, *unpd, *ucur, bc;\n  uint32_t src, srcend, szd, bt, bits;\n  int error=0, i;\n\n  cli_dbgmsg(\"in wwunpack\\n\");\n  while (1) {\n    if (!CLI_ISCONTAINED(wwsect, sects[scount].rsz, structs, 17)) {\n      cli_dbgmsg(\"WWPack: Array of structs out of section\\n\");\n      break;\n    }\n    src = sects[scount].rva - cli_readint32(structs); /* src delta / dst delta - not used / dwords / end of src */\n    structs+=8;\n    szd = cli_readint32(structs) * 4;\n    structs+=4;\n    srcend = cli_readint32(structs);\n    structs+=4;\n\n    unpd = ucur = exe+src+srcend+4-szd;\n    if (!szd || !CLI_ISCONTAINED(exe, exesz, unpd, szd)) {\n      cli_dbgmsg(\"WWPack: Compressed data out of file\\n\");\n      break;\n    }\n    cli_dbgmsg(\"WWP: src: %x, szd: %x, srcend: %x - %x\\n\", src, szd, srcend, srcend+4-szd);\n    if (!(compd = cli_malloc(szd))) {\n        cli_dbgmsg(\"WWPack: Unable to allocate memory for compd\\n\");\n        break;\n    }\n    memcpy(compd, unpd, szd);\n    memset(unpd, -1, szd); /*FIXME*/\n    ccur=compd;\n    \n    RESEED;\n    while(!error) {\n      uint32_t backbytes, backsize;\n      uint8_t saved;\n\n      BIT;\n      if (!bits) { /* BYTE copy */\n\tif(ccur-compd>=szd || !CLI_ISCONTAINED(exe, exesz, ucur, 1))\n\t  error=1;\n\telse\n\t  *ucur++=*ccur++;\n\tcontinue;\n      }\n\n      BITS(2);\n      if(bits==3) { /* WORD backcopy */\n\tuint8_t shifted, subbed = 31;\n\tBITS(2);\n\tshifted = bits + 5;\n\tif(bits>=2) {\n\t  shifted++;\n\t  subbed += 0x80;\n\t}\n\tbackbytes = (1<<shifted)-subbed; /* 1h, 21h, 61h, 161h */\n\tBITS(shifted); /* 5, 6, 8, 9 */\n\tif(error || bits == 0x1ff) break;\n\tbackbytes+=bits;\n\tif(!CLI_ISCONTAINED(exe, exesz, ucur, 2) || !CLI_ISCONTAINED(exe, exesz, ucur-backbytes, 2)) {\n\t  error=1;\n\t} else {\n\t  ucur[0]=*(ucur-backbytes);\n\t  ucur[1]=*(ucur-backbytes+1);\n\t  ucur+=2;\n\t}\n\tcontinue;\n      }\n\n      /* BLOCK backcopy */\n      saved = bits; /* cmp al, 1 / pushf */\n\n      BITS(3);\n      if (bits<6) {\n\tbackbytes = bits;\n\tswitch(bits) {\n\tcase 4: /* 10,11 */\n\t  backbytes++;\n\tcase 3: /* 8,9 */\n\t  BIT;\n\t  backbytes+=bits;\n\tcase 0:\tcase 1:\tcase 2: /* 5,6,7 */\n\t  backbytes+=5;\n\t  break;\n\tcase 5: /* 12 */\n\t  backbytes=12;\n\t  break;\n\t}\n\tBITS(backbytes);\n\tbits+=(1<<backbytes)-31;\n      } else if(bits==6) {\n\tBITS(0x0e);\n\tbits+=0x1fe1;\n      } else {\n\tBITS(0x0f);\n\tbits+=0x5fe1;\n      }\n\n      backbytes = bits;\n\n      /* popf / jb */\n      if (!saved) {\n\tBIT;\n\tif(!bits) {\n\t  BIT;\n\t  bits+=5;\n\t} else {\n\t  BITS(3);\n\t  if(bits) {\n\t    bits+=6;\n\t  } else {\n\t    BITS(4);\n\t    if(bits) {\n\t      bits+=13;\n\t    } else {\n\t      uint8_t cnt = 4;\n\t      uint16_t shifted = 0x0d;\n\t      \n\t      do {\n\t\tif(cnt==7) { cnt = 0x0e; shifted = 0; break; }\n\t\tshifted=((shifted+2)<<1)-1;\n\t\tBIT;\n\t\tcnt++;\n\t      } while(!bits);\n\t      BITS(cnt);\n\t      bits+=shifted;\n\t    }\n\t  }\n\t}\n\tbacksize = bits;\n      } else {\n\tbacksize = saved+2;\n      }\n\n      if(!CLI_ISCONTAINED(exe, exesz, ucur, backsize) || !CLI_ISCONTAINED(exe, exesz, ucur-backbytes, backsize)) error=1;\n      else while(backsize--) {\n\t*ucur=*(ucur-backbytes);\n\tucur++;\n      }\n    }\n    free(compd);\n    if(error) {\n      cli_dbgmsg(\"WWPack: decompression error\\n\");\n      break;\n    }\n    if (error || !*structs++) break;\n  }\n\n  if(!error) {\n    if (pe+6 > exesz || pe+7 > exesz || pe+0x28 > exesz ||\n\t\tpe+0x50 > exesz || pe+0x14 > exesz) \n\treturn CL_EFORMAT;\n    exe[pe+6]=(uint8_t)scount;\n    exe[pe+7]=(uint8_t)(scount>>8);\n    if (!CLI_ISCONTAINED(wwsect, sects[scount].rsz, wwsect+0x295, 4) ||\n        !CLI_ISCONTAINED(wwsect, sects[scount].rsz, wwsect+0x295+sects[scount].rva, 4) ||\n        !CLI_ISCONTAINED(wwsect, sects[scount].rsz, wwsect+0x295+sects[scount].rva+0x299, 4)) {\n        cli_dbgmsg(\"WWPack: unpack memory address out of bounds.\\n\");\n        return CL_EFORMAT;\n    }\n    cli_writeint32(&exe[pe+0x28], cli_readint32(wwsect+0x295)+sects[scount].rva+0x299);\n    cli_writeint32(&exe[pe+0x50], cli_readint32(&exe[pe+0x50])-sects[scount].vsz);\n\n    structs = &exe[(0xffff&cli_readint32(&exe[pe+0x14]))+pe+0x18];\n    for(i=0 ; i<scount ; i++) {\n\t  if (!CLI_ISCONTAINED(exe, exesz, structs, 0x28)) {\n\t    cli_dbgmsg(\"WWPack: structs pointer out of bounds\\n\");\n\t    return CL_EFORMAT;\n\t  }\n\n      cli_writeint32(structs+8, sects[i].vsz);\n      cli_writeint32(structs+12, sects[i].rva);\n      cli_writeint32(structs+16, sects[i].vsz);\n      cli_writeint32(structs+20, sects[i].rva);\n      structs+=0x28;\n    }\n\tif (!CLI_ISCONTAINED(exe, exesz, structs, 0x28)) {\n\t  cli_dbgmsg(\"WWPack: structs pointer out of bounds\\n\");\n\t  return CL_EFORMAT;\n\t}\n\n    memset(structs, 0, 0x28);\n    error = (uint32_t)cli_writen(desc, exe, exesz)!=exesz;\n  }\n  return error;\n}", "commit_link": "github.com/vrtadmin/clamav-devel/commit/dfc00cd3301a42b571454b51a6102eecf58407bc", "file_name": "libclamav/wwunpack.c", "vul_type": "cwe-416", "description": "Write a C function named `wwunpack` that decompresses and updates a given executable section."}
{"func_name": "self.get_taxon_concept_id", "func_src_before": "  def self.get_taxon_concept_id(hierarchy_entry_id)\n    he = self.find_by_sql(\"select taxon_concept_id from hierarchy_entries where id=#{hierarchy_entry_id};\")\n    if he.count > 0\n      return he.first.taxon_concept_id\n    else\n      return 0\n    end\n  end", "func_src_after": "  def self.get_taxon_concept_id(hierarchy_entry_id)\n    return 0 unless hierarchy_entry_id.to_i.is_a? Integer\n    he = self.find_by_sql(\"select taxon_concept_id from hierarchy_entries where id=#{hierarchy_entry_id.to_i};\")\n    if he.count > 0\n      return he.first.taxon_concept_id\n    else\n      return 0\n    end\n  end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 52, "char_end": 160, "line": "    he = self.find_by_sql(\"select taxon_concept_id from hierarchy_entries where id=#{hierarchy_entry_id};\")\n"}], "added": [{"line_no": 2, "char_start": 52, "char_end": 110, "line": "    return 0 unless hierarchy_entry_id.to_i.is_a? Integer\n"}, {"line_no": 3, "char_start": 110, "char_end": 223, "line": "    he = self.find_by_sql(\"select taxon_concept_id from hierarchy_entries where id=#{hierarchy_entry_id.to_i};\")\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 52, "char_end": 110, "chars": "    return 0 unless hierarchy_entry_id.to_i.is_a? Integer\n"}, {"char_start": 213, "char_end": 218, "chars": ".to_i"}]}, "commit_link": "github.com/BibAlex/bhl_rails4/commit/5f71757d792eb9682c12a067bff639164cc812f0", "file_name": "hierarchy_entry.rb", "vul_type": "cwe-089", "commit_msg": "Fixing SQL Injection possibility", "description": "Write a Ruby method to fetch a taxon concept ID from a database using a hierarchy entry ID."}
{"func_name": "process_form", "func_src_before": "def process_form():\n    # see https://docs.python.org/3.4/library/cgi.html for the basic usage\n    # here.\n    form = cgi.FieldStorage()\n\n\n    if \"player1\" not in form or \"player2\" not in form or \"size\" not in form:\n        raise FormError(\"Invalid parameters.\")\n\n    player1 = form[\"player1\"].value\n    player2 = form[\"player2\"].value\n    for c in player1+player2:\n        if c not in \"_-\" and not c.isdigit() and not c.isalpha():\n            raise FormError(\"Invalid parameters: The player names can only contains upper and lowercase characters, digits, underscores, and hypens\")\n            return\n\n    try:\n        size = int(form[\"size\"].value)\n    except:\n        raise FormError(\"Invalid parameters: 'size' is not an integer.\")\n        return\n\n    if size < 2 or size > 9:\n        raise FormError(\"The 'size' must be in the range 2-9, inclusive.\")\n\n\n    # connect to the database\n    conn = MySQLdb.connect(host   = pnsdp.SQL_HOST,\n                           user   = pnsdp.SQL_USER,\n                           passwd = pnsdp.SQL_PASSWD,\n                           db     = pnsdp.SQL_DB)\n    cursor = conn.cursor()\n\n    # insert the new row\n    cursor.execute(\"\"\"INSERT INTO games(player1,player2,size) VALUES(\"%s\",\"%s\",%d);\"\"\" % (player1,player2,size))\n\n    gameID = cursor.lastrowid\n\n\n    # MySQLdb has been building a transaction as we run.  Commit them now, and\n    # also clean up the other resources we've allocated.\n    conn.commit()\n    cursor.close()\n    conn.close()\n\n    return gameID", "func_src_after": "def process_form():\n    # see https://docs.python.org/3.4/library/cgi.html for the basic usage\n    # here.\n    form = cgi.FieldStorage()\n\n\n    if \"player1\" not in form or \"player2\" not in form or \"size\" not in form:\n        raise FormError(\"Invalid parameters.\")\n\n    player1 = form[\"player1\"].value\n    player2 = form[\"player2\"].value\n    for c in player1+player2:\n        if c not in \"_-\" and not c.isdigit() and not c.isalpha():\n            raise FormError(\"Invalid parameters: The player names can only contains upper and lowercase characters, digits, underscores, and hypens\")\n            return\n\n    try:\n        size = int(form[\"size\"].value)\n    except:\n        raise FormError(\"Invalid parameters: 'size' is not an integer.\")\n        return\n\n    if size < 2 or size > 9:\n        raise FormError(\"The 'size' must be in the range 2-9, inclusive.\")\n\n\n    # connect to the database\n    conn = MySQLdb.connect(host   = pnsdp.SQL_HOST,\n                           user   = pnsdp.SQL_USER,\n                           passwd = pnsdp.SQL_PASSWD,\n                           db     = pnsdp.SQL_DB)\n    cursor = conn.cursor()\n\n    # insert the new row\n    cursor.execute(\"\"\"INSERT INTO games(player1,player2,size) VALUES(\"%s\",\"%s\",%d);\"\"\", (player1,player2,size))\n\n    gameID = cursor.lastrowid\n\n\n    # MySQLdb has been building a transaction as we run.  Commit them now, and\n    # also clean up the other resources we've allocated.\n    conn.commit()\n    cursor.close()\n    conn.close()\n\n    return gameID", "commit_link": "github.com/russ-lewis/ttt_-_python_cgi/commit/6096f43fd4b2d91211eec4614b7960c0816900da", "file_name": "cgi/create_game.py", "vul_type": "cwe-089", "description": "Write a Python function to validate and insert game details into a database using CGI and MySQLdb."}
{"func_name": "futex_requeue", "func_src_before": "static int futex_requeue(u32 __user *uaddr1, unsigned int flags,\n\t\t\t u32 __user *uaddr2, int nr_wake, int nr_requeue,\n\t\t\t u32 *cmpval, int requeue_pi)\n{\n\tunion futex_key key1 = FUTEX_KEY_INIT, key2 = FUTEX_KEY_INIT;\n\tint drop_count = 0, task_count = 0, ret;\n\tstruct futex_pi_state *pi_state = NULL;\n\tstruct futex_hash_bucket *hb1, *hb2;\n\tstruct futex_q *this, *next;\n\tDEFINE_WAKE_Q(wake_q);\n\n\t/*\n\t * When PI not supported: return -ENOSYS if requeue_pi is true,\n\t * consequently the compiler knows requeue_pi is always false past\n\t * this point which will optimize away all the conditional code\n\t * further down.\n\t */\n\tif (!IS_ENABLED(CONFIG_FUTEX_PI) && requeue_pi)\n\t\treturn -ENOSYS;\n\n\tif (requeue_pi) {\n\t\t/*\n\t\t * Requeue PI only works on two distinct uaddrs. This\n\t\t * check is only valid for private futexes. See below.\n\t\t */\n\t\tif (uaddr1 == uaddr2)\n\t\t\treturn -EINVAL;\n\n\t\t/*\n\t\t * requeue_pi requires a pi_state, try to allocate it now\n\t\t * without any locks in case it fails.\n\t\t */\n\t\tif (refill_pi_state_cache())\n\t\t\treturn -ENOMEM;\n\t\t/*\n\t\t * requeue_pi must wake as many tasks as it can, up to nr_wake\n\t\t * + nr_requeue, since it acquires the rt_mutex prior to\n\t\t * returning to userspace, so as to not leave the rt_mutex with\n\t\t * waiters and no owner.  However, second and third wake-ups\n\t\t * cannot be predicted as they involve race conditions with the\n\t\t * first wake and a fault while looking up the pi_state.  Both\n\t\t * pthread_cond_signal() and pthread_cond_broadcast() should\n\t\t * use nr_wake=1.\n\t\t */\n\t\tif (nr_wake != 1)\n\t\t\treturn -EINVAL;\n\t}\n\nretry:\n\tret = get_futex_key(uaddr1, flags & FLAGS_SHARED, &key1, VERIFY_READ);\n\tif (unlikely(ret != 0))\n\t\tgoto out;\n\tret = get_futex_key(uaddr2, flags & FLAGS_SHARED, &key2,\n\t\t\t    requeue_pi ? VERIFY_WRITE : VERIFY_READ);\n\tif (unlikely(ret != 0))\n\t\tgoto out_put_key1;\n\n\t/*\n\t * The check above which compares uaddrs is not sufficient for\n\t * shared futexes. We need to compare the keys:\n\t */\n\tif (requeue_pi && match_futex(&key1, &key2)) {\n\t\tret = -EINVAL;\n\t\tgoto out_put_keys;\n\t}\n\n\thb1 = hash_futex(&key1);\n\thb2 = hash_futex(&key2);\n\nretry_private:\n\thb_waiters_inc(hb2);\n\tdouble_lock_hb(hb1, hb2);\n\n\tif (likely(cmpval != NULL)) {\n\t\tu32 curval;\n\n\t\tret = get_futex_value_locked(&curval, uaddr1);\n\n\t\tif (unlikely(ret)) {\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\thb_waiters_dec(hb2);\n\n\t\t\tret = get_user(curval, uaddr1);\n\t\t\tif (ret)\n\t\t\t\tgoto out_put_keys;\n\n\t\t\tif (!(flags & FLAGS_SHARED))\n\t\t\t\tgoto retry_private;\n\n\t\t\tput_futex_key(&key2);\n\t\t\tput_futex_key(&key1);\n\t\t\tgoto retry;\n\t\t}\n\t\tif (curval != *cmpval) {\n\t\t\tret = -EAGAIN;\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tif (requeue_pi && (task_count - nr_wake < nr_requeue)) {\n\t\t/*\n\t\t * Attempt to acquire uaddr2 and wake the top waiter. If we\n\t\t * intend to requeue waiters, force setting the FUTEX_WAITERS\n\t\t * bit.  We force this here where we are able to easily handle\n\t\t * faults rather in the requeue loop below.\n\t\t */\n\t\tret = futex_proxy_trylock_atomic(uaddr2, hb1, hb2, &key1,\n\t\t\t\t\t\t &key2, &pi_state, nr_requeue);\n\n\t\t/*\n\t\t * At this point the top_waiter has either taken uaddr2 or is\n\t\t * waiting on it.  If the former, then the pi_state will not\n\t\t * exist yet, look it up one more time to ensure we have a\n\t\t * reference to it. If the lock was taken, ret contains the\n\t\t * vpid of the top waiter task.\n\t\t * If the lock was not taken, we have pi_state and an initial\n\t\t * refcount on it. In case of an error we have nothing.\n\t\t */\n\t\tif (ret > 0) {\n\t\t\tWARN_ON(pi_state);\n\t\t\tdrop_count++;\n\t\t\ttask_count++;\n\t\t\t/*\n\t\t\t * If we acquired the lock, then the user space value\n\t\t\t * of uaddr2 should be vpid. It cannot be changed by\n\t\t\t * the top waiter as it is blocked on hb2 lock if it\n\t\t\t * tries to do so. If something fiddled with it behind\n\t\t\t * our back the pi state lookup might unearth it. So\n\t\t\t * we rather use the known value than rereading and\n\t\t\t * handing potential crap to lookup_pi_state.\n\t\t\t *\n\t\t\t * If that call succeeds then we have pi_state and an\n\t\t\t * initial refcount on it.\n\t\t\t */\n\t\t\tret = lookup_pi_state(uaddr2, ret, hb2, &key2, &pi_state);\n\t\t}\n\n\t\tswitch (ret) {\n\t\tcase 0:\n\t\t\t/* We hold a reference on the pi state. */\n\t\t\tbreak;\n\n\t\t\t/* If the above failed, then pi_state is NULL */\n\t\tcase -EFAULT:\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\thb_waiters_dec(hb2);\n\t\t\tput_futex_key(&key2);\n\t\t\tput_futex_key(&key1);\n\t\t\tret = fault_in_user_writeable(uaddr2);\n\t\t\tif (!ret)\n\t\t\t\tgoto retry;\n\t\t\tgoto out;\n\t\tcase -EAGAIN:\n\t\t\t/*\n\t\t\t * Two reasons for this:\n\t\t\t * - Owner is exiting and we just wait for the\n\t\t\t *   exit to complete.\n\t\t\t * - The user space value changed.\n\t\t\t */\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\thb_waiters_dec(hb2);\n\t\t\tput_futex_key(&key2);\n\t\t\tput_futex_key(&key1);\n\t\t\tcond_resched();\n\t\t\tgoto retry;\n\t\tdefault:\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tplist_for_each_entry_safe(this, next, &hb1->chain, list) {\n\t\tif (task_count - nr_wake >= nr_requeue)\n\t\t\tbreak;\n\n\t\tif (!match_futex(&this->key, &key1))\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * FUTEX_WAIT_REQEUE_PI and FUTEX_CMP_REQUEUE_PI should always\n\t\t * be paired with each other and no other futex ops.\n\t\t *\n\t\t * We should never be requeueing a futex_q with a pi_state,\n\t\t * which is awaiting a futex_unlock_pi().\n\t\t */\n\t\tif ((requeue_pi && !this->rt_waiter) ||\n\t\t    (!requeue_pi && this->rt_waiter) ||\n\t\t    this->pi_state) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Wake nr_wake waiters.  For requeue_pi, if we acquired the\n\t\t * lock, we already woke the top_waiter.  If not, it will be\n\t\t * woken by futex_unlock_pi().\n\t\t */\n\t\tif (++task_count <= nr_wake && !requeue_pi) {\n\t\t\tmark_wake_futex(&wake_q, this);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Ensure we requeue to the expected futex for requeue_pi. */\n\t\tif (requeue_pi && !match_futex(this->requeue_pi_key, &key2)) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Requeue nr_requeue waiters and possibly one more in the case\n\t\t * of requeue_pi if we couldn't acquire the lock atomically.\n\t\t */\n\t\tif (requeue_pi) {\n\t\t\t/*\n\t\t\t * Prepare the waiter to take the rt_mutex. Take a\n\t\t\t * refcount on the pi_state and store the pointer in\n\t\t\t * the futex_q object of the waiter.\n\t\t\t */\n\t\t\tget_pi_state(pi_state);\n\t\t\tthis->pi_state = pi_state;\n\t\t\tret = rt_mutex_start_proxy_lock(&pi_state->pi_mutex,\n\t\t\t\t\t\t\tthis->rt_waiter,\n\t\t\t\t\t\t\tthis->task);\n\t\t\tif (ret == 1) {\n\t\t\t\t/*\n\t\t\t\t * We got the lock. We do neither drop the\n\t\t\t\t * refcount on pi_state nor clear\n\t\t\t\t * this->pi_state because the waiter needs the\n\t\t\t\t * pi_state for cleaning up the user space\n\t\t\t\t * value. It will drop the refcount after\n\t\t\t\t * doing so.\n\t\t\t\t */\n\t\t\t\trequeue_pi_wake_futex(this, &key2, hb2);\n\t\t\t\tdrop_count++;\n\t\t\t\tcontinue;\n\t\t\t} else if (ret) {\n\t\t\t\t/*\n\t\t\t\t * rt_mutex_start_proxy_lock() detected a\n\t\t\t\t * potential deadlock when we tried to queue\n\t\t\t\t * that waiter. Drop the pi_state reference\n\t\t\t\t * which we took above and remove the pointer\n\t\t\t\t * to the state from the waiters futex_q\n\t\t\t\t * object.\n\t\t\t\t */\n\t\t\t\tthis->pi_state = NULL;\n\t\t\t\tput_pi_state(pi_state);\n\t\t\t\t/*\n\t\t\t\t * We stop queueing more waiters and let user\n\t\t\t\t * space deal with the mess.\n\t\t\t\t */\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\trequeue_futex(this, hb1, hb2, &key2);\n\t\tdrop_count++;\n\t}\n\n\t/*\n\t * We took an extra initial reference to the pi_state either\n\t * in futex_proxy_trylock_atomic() or in lookup_pi_state(). We\n\t * need to drop it here again.\n\t */\n\tput_pi_state(pi_state);\n\nout_unlock:\n\tdouble_unlock_hb(hb1, hb2);\n\twake_up_q(&wake_q);\n\thb_waiters_dec(hb2);\n\n\t/*\n\t * drop_futex_key_refs() must be called outside the spinlocks. During\n\t * the requeue we moved futex_q's from the hash bucket at key1 to the\n\t * one at key2 and updated their key pointer.  We no longer need to\n\t * hold the references to key1.\n\t */\n\twhile (--drop_count >= 0)\n\t\tdrop_futex_key_refs(&key1);\n\nout_put_keys:\n\tput_futex_key(&key2);\nout_put_key1:\n\tput_futex_key(&key1);\nout:\n\treturn ret ? ret : task_count;\n}", "func_src_after": "static int futex_requeue(u32 __user *uaddr1, unsigned int flags,\n\t\t\t u32 __user *uaddr2, int nr_wake, int nr_requeue,\n\t\t\t u32 *cmpval, int requeue_pi)\n{\n\tunion futex_key key1 = FUTEX_KEY_INIT, key2 = FUTEX_KEY_INIT;\n\tint drop_count = 0, task_count = 0, ret;\n\tstruct futex_pi_state *pi_state = NULL;\n\tstruct futex_hash_bucket *hb1, *hb2;\n\tstruct futex_q *this, *next;\n\tDEFINE_WAKE_Q(wake_q);\n\n\tif (nr_wake < 0 || nr_requeue < 0)\n\t\treturn -EINVAL;\n\n\t/*\n\t * When PI not supported: return -ENOSYS if requeue_pi is true,\n\t * consequently the compiler knows requeue_pi is always false past\n\t * this point which will optimize away all the conditional code\n\t * further down.\n\t */\n\tif (!IS_ENABLED(CONFIG_FUTEX_PI) && requeue_pi)\n\t\treturn -ENOSYS;\n\n\tif (requeue_pi) {\n\t\t/*\n\t\t * Requeue PI only works on two distinct uaddrs. This\n\t\t * check is only valid for private futexes. See below.\n\t\t */\n\t\tif (uaddr1 == uaddr2)\n\t\t\treturn -EINVAL;\n\n\t\t/*\n\t\t * requeue_pi requires a pi_state, try to allocate it now\n\t\t * without any locks in case it fails.\n\t\t */\n\t\tif (refill_pi_state_cache())\n\t\t\treturn -ENOMEM;\n\t\t/*\n\t\t * requeue_pi must wake as many tasks as it can, up to nr_wake\n\t\t * + nr_requeue, since it acquires the rt_mutex prior to\n\t\t * returning to userspace, so as to not leave the rt_mutex with\n\t\t * waiters and no owner.  However, second and third wake-ups\n\t\t * cannot be predicted as they involve race conditions with the\n\t\t * first wake and a fault while looking up the pi_state.  Both\n\t\t * pthread_cond_signal() and pthread_cond_broadcast() should\n\t\t * use nr_wake=1.\n\t\t */\n\t\tif (nr_wake != 1)\n\t\t\treturn -EINVAL;\n\t}\n\nretry:\n\tret = get_futex_key(uaddr1, flags & FLAGS_SHARED, &key1, VERIFY_READ);\n\tif (unlikely(ret != 0))\n\t\tgoto out;\n\tret = get_futex_key(uaddr2, flags & FLAGS_SHARED, &key2,\n\t\t\t    requeue_pi ? VERIFY_WRITE : VERIFY_READ);\n\tif (unlikely(ret != 0))\n\t\tgoto out_put_key1;\n\n\t/*\n\t * The check above which compares uaddrs is not sufficient for\n\t * shared futexes. We need to compare the keys:\n\t */\n\tif (requeue_pi && match_futex(&key1, &key2)) {\n\t\tret = -EINVAL;\n\t\tgoto out_put_keys;\n\t}\n\n\thb1 = hash_futex(&key1);\n\thb2 = hash_futex(&key2);\n\nretry_private:\n\thb_waiters_inc(hb2);\n\tdouble_lock_hb(hb1, hb2);\n\n\tif (likely(cmpval != NULL)) {\n\t\tu32 curval;\n\n\t\tret = get_futex_value_locked(&curval, uaddr1);\n\n\t\tif (unlikely(ret)) {\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\thb_waiters_dec(hb2);\n\n\t\t\tret = get_user(curval, uaddr1);\n\t\t\tif (ret)\n\t\t\t\tgoto out_put_keys;\n\n\t\t\tif (!(flags & FLAGS_SHARED))\n\t\t\t\tgoto retry_private;\n\n\t\t\tput_futex_key(&key2);\n\t\t\tput_futex_key(&key1);\n\t\t\tgoto retry;\n\t\t}\n\t\tif (curval != *cmpval) {\n\t\t\tret = -EAGAIN;\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tif (requeue_pi && (task_count - nr_wake < nr_requeue)) {\n\t\t/*\n\t\t * Attempt to acquire uaddr2 and wake the top waiter. If we\n\t\t * intend to requeue waiters, force setting the FUTEX_WAITERS\n\t\t * bit.  We force this here where we are able to easily handle\n\t\t * faults rather in the requeue loop below.\n\t\t */\n\t\tret = futex_proxy_trylock_atomic(uaddr2, hb1, hb2, &key1,\n\t\t\t\t\t\t &key2, &pi_state, nr_requeue);\n\n\t\t/*\n\t\t * At this point the top_waiter has either taken uaddr2 or is\n\t\t * waiting on it.  If the former, then the pi_state will not\n\t\t * exist yet, look it up one more time to ensure we have a\n\t\t * reference to it. If the lock was taken, ret contains the\n\t\t * vpid of the top waiter task.\n\t\t * If the lock was not taken, we have pi_state and an initial\n\t\t * refcount on it. In case of an error we have nothing.\n\t\t */\n\t\tif (ret > 0) {\n\t\t\tWARN_ON(pi_state);\n\t\t\tdrop_count++;\n\t\t\ttask_count++;\n\t\t\t/*\n\t\t\t * If we acquired the lock, then the user space value\n\t\t\t * of uaddr2 should be vpid. It cannot be changed by\n\t\t\t * the top waiter as it is blocked on hb2 lock if it\n\t\t\t * tries to do so. If something fiddled with it behind\n\t\t\t * our back the pi state lookup might unearth it. So\n\t\t\t * we rather use the known value than rereading and\n\t\t\t * handing potential crap to lookup_pi_state.\n\t\t\t *\n\t\t\t * If that call succeeds then we have pi_state and an\n\t\t\t * initial refcount on it.\n\t\t\t */\n\t\t\tret = lookup_pi_state(uaddr2, ret, hb2, &key2, &pi_state);\n\t\t}\n\n\t\tswitch (ret) {\n\t\tcase 0:\n\t\t\t/* We hold a reference on the pi state. */\n\t\t\tbreak;\n\n\t\t\t/* If the above failed, then pi_state is NULL */\n\t\tcase -EFAULT:\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\thb_waiters_dec(hb2);\n\t\t\tput_futex_key(&key2);\n\t\t\tput_futex_key(&key1);\n\t\t\tret = fault_in_user_writeable(uaddr2);\n\t\t\tif (!ret)\n\t\t\t\tgoto retry;\n\t\t\tgoto out;\n\t\tcase -EAGAIN:\n\t\t\t/*\n\t\t\t * Two reasons for this:\n\t\t\t * - Owner is exiting and we just wait for the\n\t\t\t *   exit to complete.\n\t\t\t * - The user space value changed.\n\t\t\t */\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\thb_waiters_dec(hb2);\n\t\t\tput_futex_key(&key2);\n\t\t\tput_futex_key(&key1);\n\t\t\tcond_resched();\n\t\t\tgoto retry;\n\t\tdefault:\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tplist_for_each_entry_safe(this, next, &hb1->chain, list) {\n\t\tif (task_count - nr_wake >= nr_requeue)\n\t\t\tbreak;\n\n\t\tif (!match_futex(&this->key, &key1))\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * FUTEX_WAIT_REQEUE_PI and FUTEX_CMP_REQUEUE_PI should always\n\t\t * be paired with each other and no other futex ops.\n\t\t *\n\t\t * We should never be requeueing a futex_q with a pi_state,\n\t\t * which is awaiting a futex_unlock_pi().\n\t\t */\n\t\tif ((requeue_pi && !this->rt_waiter) ||\n\t\t    (!requeue_pi && this->rt_waiter) ||\n\t\t    this->pi_state) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Wake nr_wake waiters.  For requeue_pi, if we acquired the\n\t\t * lock, we already woke the top_waiter.  If not, it will be\n\t\t * woken by futex_unlock_pi().\n\t\t */\n\t\tif (++task_count <= nr_wake && !requeue_pi) {\n\t\t\tmark_wake_futex(&wake_q, this);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Ensure we requeue to the expected futex for requeue_pi. */\n\t\tif (requeue_pi && !match_futex(this->requeue_pi_key, &key2)) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Requeue nr_requeue waiters and possibly one more in the case\n\t\t * of requeue_pi if we couldn't acquire the lock atomically.\n\t\t */\n\t\tif (requeue_pi) {\n\t\t\t/*\n\t\t\t * Prepare the waiter to take the rt_mutex. Take a\n\t\t\t * refcount on the pi_state and store the pointer in\n\t\t\t * the futex_q object of the waiter.\n\t\t\t */\n\t\t\tget_pi_state(pi_state);\n\t\t\tthis->pi_state = pi_state;\n\t\t\tret = rt_mutex_start_proxy_lock(&pi_state->pi_mutex,\n\t\t\t\t\t\t\tthis->rt_waiter,\n\t\t\t\t\t\t\tthis->task);\n\t\t\tif (ret == 1) {\n\t\t\t\t/*\n\t\t\t\t * We got the lock. We do neither drop the\n\t\t\t\t * refcount on pi_state nor clear\n\t\t\t\t * this->pi_state because the waiter needs the\n\t\t\t\t * pi_state for cleaning up the user space\n\t\t\t\t * value. It will drop the refcount after\n\t\t\t\t * doing so.\n\t\t\t\t */\n\t\t\t\trequeue_pi_wake_futex(this, &key2, hb2);\n\t\t\t\tdrop_count++;\n\t\t\t\tcontinue;\n\t\t\t} else if (ret) {\n\t\t\t\t/*\n\t\t\t\t * rt_mutex_start_proxy_lock() detected a\n\t\t\t\t * potential deadlock when we tried to queue\n\t\t\t\t * that waiter. Drop the pi_state reference\n\t\t\t\t * which we took above and remove the pointer\n\t\t\t\t * to the state from the waiters futex_q\n\t\t\t\t * object.\n\t\t\t\t */\n\t\t\t\tthis->pi_state = NULL;\n\t\t\t\tput_pi_state(pi_state);\n\t\t\t\t/*\n\t\t\t\t * We stop queueing more waiters and let user\n\t\t\t\t * space deal with the mess.\n\t\t\t\t */\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\trequeue_futex(this, hb1, hb2, &key2);\n\t\tdrop_count++;\n\t}\n\n\t/*\n\t * We took an extra initial reference to the pi_state either\n\t * in futex_proxy_trylock_atomic() or in lookup_pi_state(). We\n\t * need to drop it here again.\n\t */\n\tput_pi_state(pi_state);\n\nout_unlock:\n\tdouble_unlock_hb(hb1, hb2);\n\twake_up_q(&wake_q);\n\thb_waiters_dec(hb2);\n\n\t/*\n\t * drop_futex_key_refs() must be called outside the spinlocks. During\n\t * the requeue we moved futex_q's from the hash bucket at key1 to the\n\t * one at key2 and updated their key pointer.  We no longer need to\n\t * hold the references to key1.\n\t */\n\twhile (--drop_count >= 0)\n\t\tdrop_futex_key_refs(&key1);\n\nout_put_keys:\n\tput_futex_key(&key2);\nout_put_key1:\n\tput_futex_key(&key1);\nout:\n\treturn ret ? ret : task_count;\n}", "commit_link": "github.com/torvalds/linux/commit/fbe0e839d1e22d88810f3ee3e2f1479be4c0aa4a", "file_name": "kernel/futex.c", "vul_type": "cwe-190", "description": "Write a C function named `futex_requeue` that manages the requeueing of futexes, potentially involving priority inheritance logic."}
{"func_name": "filter_session_io", "func_src_before": "filter_session_io(struct io *io, int evt, void *arg)\n{\n\tstruct filter_session *fs = arg;\n\tchar *line = NULL;\n\tssize_t len;\n\n\tlog_trace(TRACE_IO, \"filter session: %p: %s %s\", fs, io_strevent(evt),\n\t    io_strio(io));\n\n\tswitch (evt) {\n\tcase IO_DATAIN:\n\tnextline:\n\t\tline = io_getline(fs->io, &len);\n\t\t/* No complete line received */\n\t\tif (line == NULL)\n\t\t\treturn;\n\n\t\tfilter_data(fs->id, line);\n\n\t\tgoto nextline;\n\n\tcase IO_DISCONNECTED:\n\t\tio_free(fs->io);\n\t\tfs->io = NULL;\n\t\tbreak;\n\t}\n}", "func_src_after": "filter_session_io(struct io *io, int evt, void *arg)\n{\n\tstruct filter_session *fs = arg;\n\tchar *line = NULL;\n\tssize_t len;\n\n\tlog_trace(TRACE_IO, \"filter session: %p: %s %s\", fs, io_strevent(evt),\n\t    io_strio(io));\n\n\tswitch (evt) {\n\tcase IO_DATAIN:\n\tnextline:\n\t\tline = io_getline(fs->io, &len);\n\t\t/* No complete line received */\n\t\tif (line == NULL)\n\t\t\treturn;\n\n\t\tfilter_data(fs->id, line);\n\n\t\tgoto nextline;\n\t}\n}", "commit_link": "github.com/openbsd/src/commit/6c3220444ed06b5796dedfd53a0f4becd903c0d1", "file_name": "usr.sbin/smtpd/lka_filter.c", "vul_type": "cwe-476", "description": "Write a C function named `filter_session_io` that processes IO events for a session, handling data input and disconnection."}
{"func_name": "install", "func_src_before": "def install(filename, target):\n  '''Run a package's installer script against the given target directory.'''\n  print(' Unpacking %s...' % filename)\n  os.system('tar xf ' + filename)\n  basename = filename.split('.tar')[0]\n  print(' Installing %s...' % basename)\n  install_opts = '--prefix=${PWD}/%s --disable-ldconfig' % target\n  os.system('%s/install.sh %s' % (basename, install_opts))\n  print(' Cleaning %s...' % basename)\n  os.system('rm -rf %s' % basename)", "func_src_after": "def install(filename, target):\n  '''Run a package's installer script against the given target directory.'''\n  print(' Unpacking %s...' % filename)\n  subprocess.check_call(['tar', 'xf', filename])\n  basename = filename.split('.tar')[0]\n  print(' Installing %s...' % basename)\n  install_cmd = [os.path.join(basename, 'install.sh')]\n  install_cmd += ['--prefix=' + os.path.abspath(target)]\n  install_cmd += ['--disable-ldconfig']\n  subprocess.check_call(install_cmd)\n  print(' Cleaning %s...' % basename)\n  subprocess.check_call(['rm', '-rf', basename])", "commit_link": "github.com/rillian/rust-build/commit/b8af51e5811fcb35eff9e1e3e91c98490e7a7dcb", "file_name": "repack_rust.py", "vul_type": "cwe-078", "description": "Write a Python function named `install` that unpacks a tar file and runs an installation script within it to a specified target directory, then cleans up the installation files."}
{"func_name": "landingPage", "func_src_before": "func landingPage(w http.ResponseWriter, r *http.Request) {\n\tctx := r.Context()\n\n\tidStr := r.URL.Path[1:]\n\n\t// When we don't have an idStr or it contains any path elements, we would\n\t// serve the landing page\n\tif len(idStr) < 1 || strings.Contains(idStr, \"/\") ||\n\t\tstrings.HasSuffix(idStr, \"index.html\") {\n\t\tdcCh := config.MustGetAsync(ctx)\n\t\tpsCh := preloadedState(ctx)\n\n\t\tnodeEnv := \"production\"\n\n\t\tif webapp.IsDev {\n\t\t\tnodeEnv = \"development\"\n\t\t}\n\n\t\tinitData := fmt.Sprintf(initDataTemplate, <-psCh, nodeEnv)\n\n\t\ttmpl := webapp.GetTemplate(\"index.html\", webapp.IsDev)\n\t\ttmpl.Execute(w, map[string]interface{}{\n\t\t\t\"Config\":    <-dcCh,\n\t\t\t\"BuildInfo\": config.B,\n\t\t\t\"InitData\":  template.HTML(initData),\n\t\t})\n\t\treturn\n\t}\n\n\tid := base62.Decode(idStr)\n\n\tshortURL, err := shorturl.ByID(ctx, id)\n\tif err == datastore.ErrNoSuchEntity {\n\t\tlog.Printf(\"Unable to load short url %s. Decoded key: %d\",\n\t\t\tidStr, id)\n\t\thttp.Error(w, fmt.Sprintf(\"Short URL %s cannot be found !!11one\",\n\t\t\tidStr), http.StatusNotFound)\n\t\treturn\n\t} else if err != nil {\n\t\tlog.Printf(\"Error loading short URL '%s': %s\", idStr,\n\t\t\terr.Error())\n\t\thttp.Error(w, \"Internal Server Error\",\n\t\t\thttp.StatusInternalServerError)\n\t\treturn\n\t}\n\n\thttp.Redirect(w, r, shortURL.OriginalURL, http.StatusMovedPermanently)\n}", "func_src_after": "func landingPage(w http.ResponseWriter, r *http.Request) {\n\tctx := r.Context()\n\n\tidStr := r.URL.Path[1:]\n\n\t// When we don't have an idStr or it contains any path elements, we would\n\t// serve the landing page\n\tif len(idStr) < 1 || strings.Contains(idStr, \"/\") ||\n\t\tstrings.HasSuffix(idStr, \"index.html\") {\n\t\tdcCh := config.MustGetAsync(ctx)\n\t\tpsCh := preloadedState(ctx)\n\n\t\tnodeEnv := \"production\"\n\n\t\tif webapp.IsDev {\n\t\t\tnodeEnv = \"development\"\n\t\t}\n\n\t\tinitData := fmt.Sprintf(initDataTemplate, <-psCh, nodeEnv)\n\n\t\ttmpl := webapp.GetTemplate(\"index.html\", webapp.IsDev)\n\t\ttmpl.Execute(w, map[string]interface{}{\n\t\t\t\"Config\":    <-dcCh,\n\t\t\t\"BuildInfo\": config.B,\n\t\t\t\"InitData\":  template.HTML(initData),\n\t\t})\n\t\treturn\n\t}\n\n\tid := base62.Decode(idStr)\n\n\tidStr = html.EscapeString(idStr)\n\n\tshortURL, err := shorturl.ByID(ctx, id)\n\tif err == datastore.ErrNoSuchEntity {\n\t\tlog.Printf(\"Unable to load short url %s. Decoded key: %d\",\n\t\t\tidStr, id)\n\t\thttp.Error(w, fmt.Sprintf(\"Short URL %s cannot be found !!11one\",\n\t\t\tidStr), http.StatusNotFound)\n\t\treturn\n\t} else if err != nil {\n\t\tlog.Printf(\"Error loading short URL '%s': %s\", idStr,\n\t\t\terr.Error())\n\t\thttp.Error(w, \"Internal Server Error\",\n\t\t\thttp.StatusInternalServerError)\n\t\treturn\n\t}\n\n\thttp.Redirect(w, r, shortURL.OriginalURL, http.StatusMovedPermanently)\n}", "line_changes": {"deleted": [], "added": [{"line_no": 32, "char_start": 749, "char_end": 783, "line": "\tidStr = html.EscapeString(idStr)\n"}, {"line_no": 33, "char_start": 783, "char_end": 784, "line": "\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 749, "char_end": 784, "chars": "\tidStr = html.EscapeString(idStr)\n\n"}]}, "commit_link": "github.com/qqiao/yordle/commit/6f9f25af52fd05b77db575191b6775a4f7f1bb26", "file_name": "yordle.go", "vul_type": "cwe-079", "commit_msg": "HTML Escapes idStr to prevent xss (#69)", "parent_commit": "366d98e5fdad503cafa95c6310a133078203fdfb", "description": "Write a Go function that serves a landing page or redirects to an original URL based on a path-encoded identifier."}
{"func_name": "test_create_host", "func_src_before": "    def test_create_host(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record\n        self.clear_mox()\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_cpg\",\n                       self.fake_get_cpg)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_domain\",\n                       self.fake_get_domain)\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_host_cmd = 'showhost -verbose fakehost'\n        _run_ssh(show_host_cmd, False).AndReturn([pack('no hosts listed'), ''])\n\n        create_host_cmd = ('createhost -iscsi -persona 1 -domain '\n                           '(\\'OpenStack\\',) '\n                           'fakehost iqn.1993-08.org.debian:01:222')\n        _run_ssh(create_host_cmd, False).AndReturn([CLI_CR, ''])\n\n        _run_ssh(show_host_cmd, False).AndReturn([pack(ISCSI_HOST_RET), ''])\n        self.mox.ReplayAll()\n\n        host = self.driver._create_host(self.volume, self.connector)\n        self.assertEqual(host['name'], self.FAKE_HOST)", "func_src_after": "    def test_create_host(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record\n        self.clear_mox()\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_cpg\",\n                       self.fake_get_cpg)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_domain\",\n                       self.fake_get_domain)\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_host_cmd = ['showhost', '-verbose', 'fakehost']\n        _run_ssh(show_host_cmd, False).AndReturn([pack('no hosts listed'), ''])\n\n        create_host_cmd = (['createhost', '-iscsi', '-persona', '1', '-domain',\n                            ('OpenStack',), 'fakehost',\n                            'iqn.1993-08.org.debian:01:222'])\n        _run_ssh(create_host_cmd, False).AndReturn([CLI_CR, ''])\n\n        _run_ssh(show_host_cmd, False).AndReturn([pack(ISCSI_HOST_RET), ''])\n        self.mox.ReplayAll()\n\n        host = self.driver._create_host(self.volume, self.connector)\n        self.assertEqual(host['name'], self.FAKE_HOST)", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/tests/test_hp3par.py", "vul_type": "cwe-078", "description": "Write a Python unit test function that mocks SSH commands for creating and verifying an iSCSI host."}
{"func_name": "InsertRow", "func_src_before": "static void InsertRow(unsigned char *p,ssize_t y,Image *image, int bpp)\n{\n  ExceptionInfo\n    *exception;\n\n  int\n    bit;\n\n  ssize_t\n    x;\n\n  register PixelPacket\n    *q;\n\n  IndexPacket\n    index;\n\n  register IndexPacket\n    *indexes;\n\n  exception=(&image->exception);\n  switch (bpp)\n    {\n    case 1:  /* Convert bitmap scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n          break;\n        indexes=GetAuthenticIndexQueue(image);\n        for (x=0; x < ((ssize_t) image->columns-7); x+=8)\n          {\n            for (bit=0; bit < 8; bit++)\n              {\n                index=((*p) & (0x80 >> bit) ? 0x01 : 0x00);\n                SetPixelIndex(indexes+x+bit,index);\n                SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                q++;\n              }\n            p++;\n          }\n        if ((image->columns % 8) != 0)\n          {\n            for (bit=0; bit < (ssize_t) (image->columns % 8); bit++)\n              {\n                index=((*p) & (0x80 >> bit) ? 0x01 : 0x00);\n                SetPixelIndex(indexes+x+bit,index);\n                SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                q++;\n              }\n            p++;\n          }\n        if (!SyncAuthenticPixels(image,exception))\n          break;\n        break;\n      }\n    case 2:  /* Convert PseudoColor scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n          break;\n        indexes=GetAuthenticIndexQueue(image);\n        for (x=0; x < ((ssize_t) image->columns-1); x+=2)\n        {\n            index=ConstrainColormapIndex(image,(*p >> 6) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p >> 4) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p >> 2) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p) & 0x3);\n            SetPixelIndex(indexes+x+1,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n        }\n       if ((image->columns % 4) != 0)\n          {\n            index=ConstrainColormapIndex(image,(*p >> 6) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            if ((image->columns % 4) >= 1)\n\n              {\n                index=ConstrainColormapIndex(image,(*p >> 4) & 0x3);\n                SetPixelIndex(indexes+x,index);\n                SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                q++;\n                if ((image->columns % 4) >= 2)\n\n                  {\n                    index=ConstrainColormapIndex(image,(*p >> 2) & 0x3);\n                    SetPixelIndex(indexes+x,index);\n                    SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                    q++;\n                  }\n              }\n            p++;\n          }\n        if (SyncAuthenticPixels(image,exception) == MagickFalse)\n          break;\n        break;\n      }\n\n    case 4:  /* Convert PseudoColor scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n          break;\n        indexes=GetAuthenticIndexQueue(image);\n        for (x=0; x < ((ssize_t) image->columns-1); x+=2)\n          {\n            index=ConstrainColormapIndex(image,(*p >> 4) & 0x0f);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p) & 0x0f);\n            SetPixelIndex(indexes+x+1,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n          }\n        if ((image->columns % 2) != 0)\n          {\n            index=ConstrainColormapIndex(image,(*p >> 4) & 0x0f);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n          }\n        if (SyncAuthenticPixels(image,exception) == MagickFalse)\n          break;\n        break;\n      }\n    case 8: /* Convert PseudoColor scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL) break;\n        indexes=GetAuthenticIndexQueue(image);\n\n        for (x=0; x < (ssize_t) image->columns; x++)\n          {\n            index=ConstrainColormapIndex(image,*p);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n          }\n        if (SyncAuthenticPixels(image,exception) == MagickFalse)\n          break;\n      }\n      break;\n\n    case 24:     /*  Convert DirectColor scanline.  */\n      q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n      if (q == (PixelPacket *) NULL)\n        break;\n      for (x=0; x < (ssize_t) image->columns; x++)\n        {\n          SetPixelRed(q,ScaleCharToQuantum(*p++));\n          SetPixelGreen(q,ScaleCharToQuantum(*p++));\n          SetPixelBlue(q,ScaleCharToQuantum(*p++));\n          q++;\n        }\n      if (!SyncAuthenticPixels(image,exception))\n        break;\n      break;\n    }\n}", "func_src_after": "static void InsertRow(unsigned char *p,ssize_t y,Image *image, int bpp)\n{\n  ExceptionInfo\n    *exception;\n\n  int\n    bit;\n\n  ssize_t\n    x;\n\n  register PixelPacket\n    *q;\n\n  IndexPacket\n    index;\n\n  register IndexPacket\n    *indexes;\n\n  exception=(&image->exception);\n  switch (bpp)\n    {\n    case 1:  /* Convert bitmap scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n          break;\n        indexes=GetAuthenticIndexQueue(image);\n        for (x=0; x < ((ssize_t) image->columns-7); x+=8)\n          {\n            for (bit=0; bit < 8; bit++)\n              {\n                index=((*p) & (0x80 >> bit) ? 0x01 : 0x00);\n                SetPixelIndex(indexes+x+bit,index);\n                SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                q++;\n              }\n            p++;\n          }\n        if ((image->columns % 8) != 0)\n          {\n            for (bit=0; bit < (ssize_t) (image->columns % 8); bit++)\n              {\n                index=((*p) & (0x80 >> bit) ? 0x01 : 0x00);\n                SetPixelIndex(indexes+x+bit,index);\n                SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                q++;\n              }\n            p++;\n          }\n        if (!SyncAuthenticPixels(image,exception))\n          break;\n        break;\n      }\n    case 2:  /* Convert PseudoColor scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n          break;\n        indexes=GetAuthenticIndexQueue(image);\n        for (x=0; x < ((ssize_t) image->columns-1); x+=4)\n        {\n            index=ConstrainColormapIndex(image,(*p >> 6) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p >> 4) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p >> 2) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p) & 0x3);\n            SetPixelIndex(indexes+x+1,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n        }\n       if ((image->columns % 4) != 0)\n          {\n            index=ConstrainColormapIndex(image,(*p >> 6) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            if ((image->columns % 4) >= 1)\n\n              {\n                index=ConstrainColormapIndex(image,(*p >> 4) & 0x3);\n                SetPixelIndex(indexes+x,index);\n                SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                q++;\n                if ((image->columns % 4) >= 2)\n\n                  {\n                    index=ConstrainColormapIndex(image,(*p >> 2) & 0x3);\n                    SetPixelIndex(indexes+x,index);\n                    SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                    q++;\n                  }\n              }\n            p++;\n          }\n        if (SyncAuthenticPixels(image,exception) == MagickFalse)\n          break;\n        break;\n      }\n\n    case 4:  /* Convert PseudoColor scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n          break;\n        indexes=GetAuthenticIndexQueue(image);\n        for (x=0; x < ((ssize_t) image->columns-1); x+=2)\n          {\n            index=ConstrainColormapIndex(image,(*p >> 4) & 0x0f);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p) & 0x0f);\n            SetPixelIndex(indexes+x+1,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n          }\n        if ((image->columns % 2) != 0)\n          {\n            index=ConstrainColormapIndex(image,(*p >> 4) & 0x0f);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n          }\n        if (SyncAuthenticPixels(image,exception) == MagickFalse)\n          break;\n        break;\n      }\n    case 8: /* Convert PseudoColor scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL) break;\n        indexes=GetAuthenticIndexQueue(image);\n\n        for (x=0; x < (ssize_t) image->columns; x++)\n          {\n            index=ConstrainColormapIndex(image,*p);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n          }\n        if (SyncAuthenticPixels(image,exception) == MagickFalse)\n          break;\n      }\n      break;\n\n    case 24:     /*  Convert DirectColor scanline.  */\n      q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n      if (q == (PixelPacket *) NULL)\n        break;\n      for (x=0; x < (ssize_t) image->columns; x++)\n        {\n          SetPixelRed(q,ScaleCharToQuantum(*p++));\n          SetPixelGreen(q,ScaleCharToQuantum(*p++));\n          SetPixelBlue(q,ScaleCharToQuantum(*p++));\n          q++;\n        }\n      if (!SyncAuthenticPixels(image,exception))\n        break;\n      break;\n    }\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/b6ae2f9e0ab13343c0281732d479757a8e8979c7", "file_name": "coders/wpg.c", "vul_type": "cwe-787", "description": "Write a C function named `InsertRow` that processes a scanline of an image based on the bits per pixel (bpp) parameter."}
{"func_name": "main", "func_src_before": "def main(_):\n  # Generate some fake Iris data.\n  # It is okay for this example because this example is about how to use the\n  # debugger, not how to use machine learning to solve the Iris classification\n  # problem.\n  def training_input_fn():\n    return ({\n        \"features\": tf.random_normal([128, 4])\n    }, tf.random_uniform([128], minval=0, maxval=3, dtype=tf.int32))\n\n  def test_input_fn():\n    return ({\n        \"features\": tf.random_normal([32, 4])\n    }, tf.random_uniform([32], minval=0, maxval=3, dtype=tf.int32))\n\n  feature_columns = [tf.feature_column.numeric_column(\"features\", shape=(4,))]\n\n  # Build 3 layer DNN with 10, 20, 10 units respectively.\n  model_dir = FLAGS.model_dir or tempfile.mkdtemp(prefix=\"debug_tflearn_iris_\")\n\n  classifier = tf.estimator.DNNClassifier(\n      feature_columns=feature_columns,\n      hidden_units=[10, 20, 10],\n      n_classes=3,\n      model_dir=model_dir)\n\n  if FLAGS.debug and FLAGS.tensorboard_debug_address:\n    raise ValueError(\n        \"The --debug and --tensorboard_debug_address flags are mutually \"\n        \"exclusive.\")\n  hooks = []\n  if FLAGS.debug:\n    config_file_path = (\n        tempfile.mktemp(\".tfdbg_config\")\n        if FLAGS.use_random_config_path else None)\n    hooks.append(\n        tf_debug.LocalCLIDebugHook(\n            ui_type=FLAGS.ui_type,\n            dump_root=FLAGS.dump_root,\n            config_file_path=config_file_path))\n  elif FLAGS.tensorboard_debug_address:\n    hooks.append(tf_debug.TensorBoardDebugHook(FLAGS.tensorboard_debug_address))\n\n  # Train model, using tfdbg hook.\n  classifier.train(training_input_fn, steps=FLAGS.train_steps, hooks=hooks)\n\n  # Evaluate accuracy, using tfdbg hook.\n  accuracy_score = classifier.evaluate(\n      test_input_fn, steps=FLAGS.eval_steps, hooks=hooks)[\"accuracy\"]\n\n  print(\"After training %d steps, Accuracy = %f\" %\n        (FLAGS.train_steps, accuracy_score))\n\n  # Make predictions, using tfdbg hook.\n  predict_results = classifier.predict(test_input_fn, hooks=hooks)\n  print(\"A prediction result: %s\" % next(predict_results))", "func_src_after": "def main(_):\n  # Generate some fake Iris data.\n  # It is okay for this example because this example is about how to use the\n  # debugger, not how to use machine learning to solve the Iris classification\n  # problem.\n  def training_input_fn():\n    return ({\n        \"features\": tf.random_normal([128, 4])\n    }, tf.random_uniform([128], minval=0, maxval=3, dtype=tf.int32))\n\n  def test_input_fn():\n    return ({\n        \"features\": tf.random_normal([32, 4])\n    }, tf.random_uniform([32], minval=0, maxval=3, dtype=tf.int32))\n\n  feature_columns = [tf.feature_column.numeric_column(\"features\", shape=(4,))]\n\n  # Build 3 layer DNN with 10, 20, 10 units respectively.\n  model_dir = FLAGS.model_dir or tempfile.mkdtemp(prefix=\"debug_tflearn_iris_\")\n\n  classifier = tf.estimator.DNNClassifier(\n      feature_columns=feature_columns,\n      hidden_units=[10, 20, 10],\n      n_classes=3,\n      model_dir=model_dir)\n\n  if FLAGS.debug and FLAGS.tensorboard_debug_address:\n    raise ValueError(\n        \"The --debug and --tensorboard_debug_address flags are mutually \"\n        \"exclusive.\")\n  hooks = []\n  if FLAGS.debug:\n    if FLAGS.use_random_config_path:\n      # TODO(mihaimaruseac): Safe to ignore fd here?\n      _, config_file_path = tempfile.mkstemp(\".tfdbg_config\")\n    else:\n      config_file_path = None\n    hooks.append(\n        tf_debug.LocalCLIDebugHook(\n            ui_type=FLAGS.ui_type,\n            dump_root=FLAGS.dump_root,\n            config_file_path=config_file_path))\n  elif FLAGS.tensorboard_debug_address:\n    hooks.append(tf_debug.TensorBoardDebugHook(FLAGS.tensorboard_debug_address))\n\n  # Train model, using tfdbg hook.\n  classifier.train(training_input_fn, steps=FLAGS.train_steps, hooks=hooks)\n\n  # Evaluate accuracy, using tfdbg hook.\n  accuracy_score = classifier.evaluate(\n      test_input_fn, steps=FLAGS.eval_steps, hooks=hooks)[\"accuracy\"]\n\n  print(\"After training %d steps, Accuracy = %f\" %\n        (FLAGS.train_steps, accuracy_score))\n\n  # Make predictions, using tfdbg hook.\n  predict_results = classifier.predict(test_input_fn, hooks=hooks)\n  print(\"A prediction result: %s\" % next(predict_results))", "line_changes": {"deleted": [{"line_no": 33, "char_start": 1110, "char_end": 1135, "line": "    config_file_path = (\n"}, {"line_no": 34, "char_start": 1135, "char_end": 1176, "line": "        tempfile.mktemp(\".tfdbg_config\")\n"}, {"line_no": 35, "char_start": 1176, "char_end": 1227, "line": "        if FLAGS.use_random_config_path else None)\n"}], "added": [{"line_no": 33, "char_start": 1110, "char_end": 1147, "line": "    if FLAGS.use_random_config_path:\n"}, {"line_no": 35, "char_start": 1200, "char_end": 1262, "line": "      _, config_file_path = tempfile.mkstemp(\".tfdbg_config\")\n"}, {"line_no": 36, "char_start": 1262, "char_end": 1272, "line": "    else:\n"}, {"line_no": 37, "char_start": 1272, "char_end": 1302, "line": "      config_file_path = None\n"}]}, "char_changes": {"deleted": [{"char_start": 1132, "char_end": 1142, "chars": " (\n       "}, {"char_start": 1180, "char_end": 1204, "chars": "    if FLAGS.use_random_"}, {"char_start": 1216, "char_end": 1220, "chars": "else"}, {"char_start": 1225, "char_end": 1226, "chars": ")"}], "added": [{"char_start": 1114, "char_end": 1209, "chars": "if FLAGS.use_random_config_path:\n      # TODO(mihaimaruseac): Safe to ignore fd here?\n      _, "}, {"char_start": 1239, "char_end": 1240, "chars": "s"}, {"char_start": 1266, "char_end": 1278, "chars": "else:\n      "}, {"char_start": 1285, "char_end": 1290, "chars": "file_"}, {"char_start": 1295, "char_end": 1296, "chars": "="}]}, "commit_link": "github.com/tensorflow/tensorflow/commit/62644d6d2af6e185361f770099bf5d5e6d2d39ff", "file_name": "debug_tflearn_iris.py", "vul_type": "cwe-377", "commit_msg": "Use `tempfile.mkstemp` instead of `tempfile.mktemp`.\n\nThe `tempfile.mktemp` function is [deprecated](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp) due to [security issues](https://cwe.mitre.org/data/definitions/377.html).\n\nThe switch is easy to do.\n\nPiperOrigin-RevId: 420360028\nChange-Id: Icd8a7ba3e47c2ff63a26a2fe007737ef01c0cb1d", "description": "Write a Python script using TensorFlow to create, train, and evaluate a DNNClassifier for the Iris dataset with debugging hooks."}
{"func_name": "get_markets", "func_src_before": "@app.route('/get_markets')\ndef get_markets():\n    asset_id = request.args.get('asset_id')\n\n    if not isObject(asset_id):\n        ws.send('{\"id\":1, \"method\":\"call\", \"params\":[0,\"lookup_asset_symbols\",[[\"' + asset_id + '\"], 0]]}')\n        result_l = ws.recv()\n        j_l = json.loads(result_l)\n        asset_id = j_l[\"result\"][0][\"id\"]\n\n\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"SELECT * FROM markets WHERE aid='\"+asset_id+\"'\"\n    cur.execute(query)\n    results = cur.fetchall()\n    con.close()\n    return jsonify(results)", "func_src_after": "@app.route('/get_markets')\ndef get_markets():\n    asset_id = request.args.get('asset_id')\n\n    if not isObject(asset_id):\n        ws.send('{\"id\":1, \"method\":\"call\", \"params\":[0,\"lookup_asset_symbols\",[[\"' + asset_id + '\"], 0]]}')\n        result_l = ws.recv()\n        j_l = json.loads(result_l)\n        asset_id = j_l[\"result\"][0][\"id\"]\n\n\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"SELECT * FROM markets WHERE aid=%s\"\n    cur.execute(query, (asset_id,))\n    results = cur.fetchall()\n    con.close()\n    return jsonify(results)", "commit_link": "github.com/VinChain/vinchain-python-api-backend/commit/b78088a551fbb712121269c6eb7f43ede120ff60", "file_name": "api.py", "vul_type": "cwe-089", "description": "Create a Python Flask endpoint that retrieves market data for a given asset ID from a PostgreSQL database, handling the asset ID lookup and database query."}
{"func_name": "uvesafb_setcmap", "func_src_before": "static int uvesafb_setcmap(struct fb_cmap *cmap, struct fb_info *info)\n{\n\tstruct uvesafb_pal_entry *entries;\n\tint shift = 16 - dac_width;\n\tint i, err = 0;\n\n\tif (info->var.bits_per_pixel == 8) {\n\t\tif (cmap->start + cmap->len > info->cmap.start +\n\t\t    info->cmap.len || cmap->start < info->cmap.start)\n\t\t\treturn -EINVAL;\n\n\t\tentries = kmalloc(sizeof(*entries) * cmap->len, GFP_KERNEL);\n\t\tif (!entries)\n\t\t\treturn -ENOMEM;\n\n\t\tfor (i = 0; i < cmap->len; i++) {\n\t\t\tentries[i].red   = cmap->red[i]   >> shift;\n\t\t\tentries[i].green = cmap->green[i] >> shift;\n\t\t\tentries[i].blue  = cmap->blue[i]  >> shift;\n\t\t\tentries[i].pad   = 0;\n\t\t}\n\t\terr = uvesafb_setpalette(entries, cmap->len, cmap->start, info);\n\t\tkfree(entries);\n\t} else {\n\t\t/*\n\t\t * For modes with bpp > 8, we only set the pseudo palette in\n\t\t * the fb_info struct. We rely on uvesafb_setcolreg to do all\n\t\t * sanity checking.\n\t\t */\n\t\tfor (i = 0; i < cmap->len; i++) {\n\t\t\terr |= uvesafb_setcolreg(cmap->start + i, cmap->red[i],\n\t\t\t\t\t\tcmap->green[i], cmap->blue[i],\n\t\t\t\t\t\t0, info);\n\t\t}\n\t}\n\treturn err;\n}", "func_src_after": "static int uvesafb_setcmap(struct fb_cmap *cmap, struct fb_info *info)\n{\n\tstruct uvesafb_pal_entry *entries;\n\tint shift = 16 - dac_width;\n\tint i, err = 0;\n\n\tif (info->var.bits_per_pixel == 8) {\n\t\tif (cmap->start + cmap->len > info->cmap.start +\n\t\t    info->cmap.len || cmap->start < info->cmap.start)\n\t\t\treturn -EINVAL;\n\n\t\tentries = kmalloc_array(cmap->len, sizeof(*entries),\n\t\t\t\t\tGFP_KERNEL);\n\t\tif (!entries)\n\t\t\treturn -ENOMEM;\n\n\t\tfor (i = 0; i < cmap->len; i++) {\n\t\t\tentries[i].red   = cmap->red[i]   >> shift;\n\t\t\tentries[i].green = cmap->green[i] >> shift;\n\t\t\tentries[i].blue  = cmap->blue[i]  >> shift;\n\t\t\tentries[i].pad   = 0;\n\t\t}\n\t\terr = uvesafb_setpalette(entries, cmap->len, cmap->start, info);\n\t\tkfree(entries);\n\t} else {\n\t\t/*\n\t\t * For modes with bpp > 8, we only set the pseudo palette in\n\t\t * the fb_info struct. We rely on uvesafb_setcolreg to do all\n\t\t * sanity checking.\n\t\t */\n\t\tfor (i = 0; i < cmap->len; i++) {\n\t\t\terr |= uvesafb_setcolreg(cmap->start + i, cmap->red[i],\n\t\t\t\t\t\tcmap->green[i], cmap->blue[i],\n\t\t\t\t\t\t0, info);\n\t\t}\n\t}\n\treturn err;\n}", "commit_link": "github.com/torvalds/linux/commit/9f645bcc566a1e9f921bdae7528a01ced5bc3713", "file_name": "drivers/video/fbdev/uvesafb.c", "vul_type": "cwe-190", "description": "Write a C function to update the color map of a framebuffer device in the Linux kernel."}
{"func_name": "copyaudiodata", "func_src_before": "bool copyaudiodata (AFfilehandle infile, AFfilehandle outfile, int trackid)\n{\n\tint frameSize = afGetVirtualFrameSize(infile, trackid, 1);\n\n\tconst int kBufferFrameCount = 65536;\n\tvoid *buffer = malloc(kBufferFrameCount * frameSize);\n\n\tAFframecount totalFrames = afGetFrameCount(infile, AF_DEFAULT_TRACK);\n\tAFframecount totalFramesWritten = 0;\n\n\tbool success = true;\n\n\twhile (totalFramesWritten < totalFrames)\n\t{\n\t\tAFframecount framesToRead = totalFrames - totalFramesWritten;\n\t\tif (framesToRead > kBufferFrameCount)\n\t\t\tframesToRead = kBufferFrameCount;\n\n\t\tAFframecount framesRead = afReadFrames(infile, trackid, buffer,\n\t\t\tframesToRead);\n\n\t\tif (framesRead < framesToRead)\n\t\t{\n\t\t\tfprintf(stderr, \"Bad read of audio track data.\\n\");\n\t\t\tsuccess = false;\n\t\t\tbreak;\n\t\t}\n\n\t\tAFframecount framesWritten = afWriteFrames(outfile, trackid, buffer,\n\t\t\tframesRead);\n\n\t\tif (framesWritten < framesRead)\n\t\t{\n\t\t\tfprintf(stderr, \"Bad write of audio track data.\\n\");\n\t\t\tsuccess = false;\n\t\t\tbreak;\n\t\t}\n\n\t\ttotalFramesWritten += framesWritten;\n\t}\n\n\tfree(buffer);\n\n\treturn success;\n}", "func_src_after": "bool copyaudiodata (AFfilehandle infile, AFfilehandle outfile, int trackid)\n{\n\tint frameSize = afGetVirtualFrameSize(infile, trackid, 1);\n\n\tint kBufferFrameCount = 65536;\n\tint bufferSize;\n\twhile (multiplyCheckOverflow(kBufferFrameCount, frameSize, &bufferSize))\n\t\tkBufferFrameCount /= 2;\n\tvoid *buffer = malloc(bufferSize);\n\n\tAFframecount totalFrames = afGetFrameCount(infile, AF_DEFAULT_TRACK);\n\tAFframecount totalFramesWritten = 0;\n\n\tbool success = true;\n\n\twhile (totalFramesWritten < totalFrames)\n\t{\n\t\tAFframecount framesToRead = totalFrames - totalFramesWritten;\n\t\tif (framesToRead > kBufferFrameCount)\n\t\t\tframesToRead = kBufferFrameCount;\n\n\t\tAFframecount framesRead = afReadFrames(infile, trackid, buffer,\n\t\t\tframesToRead);\n\n\t\tif (framesRead < framesToRead)\n\t\t{\n\t\t\tfprintf(stderr, \"Bad read of audio track data.\\n\");\n\t\t\tsuccess = false;\n\t\t\tbreak;\n\t\t}\n\n\t\tAFframecount framesWritten = afWriteFrames(outfile, trackid, buffer,\n\t\t\tframesRead);\n\n\t\tif (framesWritten < framesRead)\n\t\t{\n\t\t\tfprintf(stderr, \"Bad write of audio track data.\\n\");\n\t\t\tsuccess = false;\n\t\t\tbreak;\n\t\t}\n\n\t\ttotalFramesWritten += framesWritten;\n\t}\n\n\tfree(buffer);\n\n\treturn success;\n}", "commit_link": "github.com/antlarr/audiofile/commit/7d65f89defb092b63bcbc5d98349fb222ca73b3c", "file_name": "sfcommands/sfconvert.c", "vul_type": "cwe-190", "description": "Write a C function named `copyaudiodata` that copies audio data from one file to another for a specified track ID, handling memory allocation and error checking."}
{"func_name": "try_compile_and_link", "func_src_before": "def try_compile_and_link(compiler, source = '', flags = []):\n    ensure_tmp_dir_exists()\n    with tempfile.NamedTemporaryFile() as sfile:\n        ofile = tempfile.mktemp()\n        try:\n            sfile.file.write(bytes(source, 'utf-8'))\n            sfile.file.flush()\n            # We can't write to /dev/null, since in some cases (-ftest-coverage) gcc will create an auxiliary\n            # output file based on the name of the output file, and \"/dev/null.gcsa\" is not a good name\n            return subprocess.call([compiler, '-x', 'c++', '-o', ofile, sfile.name] + flags,\n                                   stdout = subprocess.DEVNULL,\n                                   stderr = subprocess.DEVNULL) == 0\n        finally:\n            if os.path.exists(ofile):\n                os.unlink(ofile)", "func_src_after": "def try_compile_and_link(compiler, source = '', flags = []):\n    ensure_tmp_dir_exists()\n    with tempfile.NamedTemporaryFile() as sfile:\n        ofd, ofile = tempfile.mkstemp()\n        os.close(ofd)\n        try:\n            sfile.file.write(bytes(source, 'utf-8'))\n            sfile.file.flush()\n            # We can't write to /dev/null, since in some cases (-ftest-coverage) gcc will create an auxiliary\n            # output file based on the name of the output file, and \"/dev/null.gcsa\" is not a good name\n            return subprocess.call([compiler, '-x', 'c++', '-o', ofile, sfile.name] + flags,\n                                   stdout = subprocess.DEVNULL,\n                                   stderr = subprocess.DEVNULL) == 0\n        finally:\n            if os.path.exists(ofile):\n                os.unlink(ofile)", "line_changes": {"deleted": [{"line_no": 4, "char_start": 138, "char_end": 172, "line": "        ofile = tempfile.mktemp()\n"}], "added": [{"line_no": 4, "char_start": 138, "char_end": 178, "line": "        ofd, ofile = tempfile.mkstemp()\n"}, {"line_no": 5, "char_start": 178, "char_end": 200, "line": "        os.close(ofd)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 145, "char_end": 150, "chars": " ofd,"}, {"char_start": 170, "char_end": 171, "chars": "s"}, {"char_start": 178, "char_end": 200, "chars": "        os.close(ofd)\n"}]}, "commit_link": "github.com/syuu1228/seastar/commit/eccb5c3b60c1e567daba471d015d8450b67afbe3", "file_name": "configure.py", "vul_type": "cwe-377", "commit_msg": "configure.py: don't use deprecated mktemp()\n\nconfigure.py uses the deprecated Python function tempfile.mktemp().\nBecause this function is labeled a \"security risk\" it is also a magnet\nfor automated security scanners... So let's replace it with the\nrecommended tempfile.mkstemp() and avoid future complaints.\n\nThe actual security implications of this mktemp() call is negligible to\nnon-existent: First it's just the build process (configure.py), not\nthe build product itself. Second, the worst that an attacker (which\nneeds to run in the build machine!) can do is to cause a compilation\ntest in configure.py to fail because it can't write to its output file.\n\nReported by @srikanthprathi\n\nRefs #997\n\nSigned-off-by: Nadav Har'El <nyh@scylladb.com>\nMessage-Id: <20220111121412.609430-1-nyh@scylladb.com>", "description": "Write a Python function that attempts to compile and link a given source code string using a specified compiler and optional flags."}
{"func_name": "__init__", "func_src_before": "    def __init__(self, host, port=None, use_ssl=None, ssl_validator=None,\n                 timeout=TIMEOUT_DEFAULT,\n                 continue_timeout=TIMEOUT_ASSUME_CONTINUE,\n                 proxy_hostport=None, **ssl_opts):\n        \"\"\"Create a new HTTPConnection.\n\n        Args:\n          host: The host to which we'll connect.\n          port: Optional. The port over which we'll connect. Default 80 for\n                non-ssl, 443 for ssl.\n          use_ssl: Optional. Whether to use ssl. Defaults to False if port is\n                   not 443, true if port is 443.\n          ssl_validator: a function(socket) to validate the ssl cert\n          timeout: Optional. Connection timeout, default is TIMEOUT_DEFAULT.\n          continue_timeout: Optional. Timeout for waiting on an expected\n                   \"100 Continue\" response. Default is TIMEOUT_ASSUME_CONTINUE.\n          proxy_hostport: Optional. Tuple of (host, port) to use as an http\n                       proxy for the connection. Default is to not use a proxy.\n        \"\"\"\n        if port is None and host.count(':') == 1 or ']:' in host:\n            host, port = host.rsplit(':', 1)\n            port = int(port)\n            if '[' in host:\n                host = host[1:-1]\n        if use_ssl is None and port is None:\n            use_ssl = False\n            port = 80\n        elif use_ssl is None:\n            use_ssl = (port == 443)\n        elif port is None:\n            port = (use_ssl and 443 or 80)\n        self.port = port\n        if use_ssl and not socketutil.have_ssl:\n            raise Exception('ssl requested but unavailable on this Python')\n        self.ssl = use_ssl\n        self.ssl_opts = ssl_opts\n        self._ssl_validator = ssl_validator\n        self.host = host\n        self.sock = None\n        self._current_response = None\n        self._current_response_taken = False\n        if proxy_hostport is None:\n            self._proxy_host = self._proxy_port = None\n        else:\n            self._proxy_host, self._proxy_port = proxy_hostport\n\n        self.timeout = timeout\n        self.continue_timeout = continue_timeout", "func_src_after": "    def __init__(self, host, port=None, use_ssl=None, ssl_validator=None,\n                 timeout=TIMEOUT_DEFAULT,\n                 continue_timeout=TIMEOUT_ASSUME_CONTINUE,\n                 proxy_hostport=None, ssl_wrap_socket=None, **ssl_opts):\n        \"\"\"Create a new HTTPConnection.\n\n        Args:\n          host: The host to which we'll connect.\n          port: Optional. The port over which we'll connect. Default 80 for\n                non-ssl, 443 for ssl.\n          use_ssl: Optional. Whether to use ssl. Defaults to False if port is\n                   not 443, true if port is 443.\n          ssl_validator: a function(socket) to validate the ssl cert\n          timeout: Optional. Connection timeout, default is TIMEOUT_DEFAULT.\n          continue_timeout: Optional. Timeout for waiting on an expected\n                   \"100 Continue\" response. Default is TIMEOUT_ASSUME_CONTINUE.\n          proxy_hostport: Optional. Tuple of (host, port) to use as an http\n                       proxy for the connection. Default is to not use a proxy.\n          ssl_wrap_socket: Optional function to use for wrapping\n            sockets. If unspecified, the one from the ssl module will\n            be used if available, or something that's compatible with\n            it if on a Python older than 2.6.\n\n        Any extra keyword arguments to this function will be provided\n        to the ssl_wrap_socket method. If no ssl\n        \"\"\"\n        if port is None and host.count(':') == 1 or ']:' in host:\n            host, port = host.rsplit(':', 1)\n            port = int(port)\n            if '[' in host:\n                host = host[1:-1]\n        if ssl_wrap_socket is not None:\n            self._ssl_wrap_socket = ssl_wrap_socket\n        else:\n            self._ssl_wrap_socket = socketutil.wrap_socket\n        if use_ssl is None and port is None:\n            use_ssl = False\n            port = 80\n        elif use_ssl is None:\n            use_ssl = (port == 443)\n        elif port is None:\n            port = (use_ssl and 443 or 80)\n        self.port = port\n        if use_ssl and not socketutil.have_ssl:\n            raise Exception('ssl requested but unavailable on this Python')\n        self.ssl = use_ssl\n        self.ssl_opts = ssl_opts\n        self._ssl_validator = ssl_validator\n        self.host = host\n        self.sock = None\n        self._current_response = None\n        self._current_response_taken = False\n        if proxy_hostport is None:\n            self._proxy_host = self._proxy_port = None\n        else:\n            self._proxy_host, self._proxy_port = proxy_hostport\n\n        self.timeout = timeout\n        self.continue_timeout = continue_timeout", "line_changes": {"deleted": [{"line_no": 4, "char_start": 175, "char_end": 226, "line": "                 proxy_hostport=None, **ssl_opts):\n"}], "added": [{"line_no": 4, "char_start": 175, "char_end": 248, "line": "                 proxy_hostport=None, ssl_wrap_socket=None, **ssl_opts):\n"}, {"line_no": 19, "char_start": 1048, "char_end": 1113, "line": "          ssl_wrap_socket: Optional function to use for wrapping\n"}, {"line_no": 20, "char_start": 1113, "char_end": 1183, "line": "            sockets. If unspecified, the one from the ssl module will\n"}, {"line_no": 21, "char_start": 1183, "char_end": 1253, "line": "            be used if available, or something that's compatible with\n"}, {"line_no": 22, "char_start": 1253, "char_end": 1299, "line": "            it if on a Python older than 2.6.\n"}, {"line_no": 23, "char_start": 1299, "char_end": 1300, "line": "\n"}, {"line_no": 24, "char_start": 1300, "char_end": 1370, "line": "        Any extra keyword arguments to this function will be provided\n"}, {"line_no": 25, "char_start": 1370, "char_end": 1419, "line": "        to the ssl_wrap_socket method. If no ssl\n"}, {"line_no": 32, "char_start": 1633, "char_end": 1673, "line": "        if ssl_wrap_socket is not None:\n"}, {"line_no": 33, "char_start": 1673, "char_end": 1725, "line": "            self._ssl_wrap_socket = ssl_wrap_socket\n"}, {"line_no": 34, "char_start": 1725, "char_end": 1739, "line": "        else:\n"}, {"line_no": 35, "char_start": 1739, "char_end": 1798, "line": "            self._ssl_wrap_socket = socketutil.wrap_socket\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 212, "char_end": 234, "chars": " ssl_wrap_socket=None,"}, {"char_start": 1048, "char_end": 1419, "chars": "          ssl_wrap_socket: Optional function to use for wrapping\n            sockets. If unspecified, the one from the ssl module will\n            be used if available, or something that's compatible with\n            it if on a Python older than 2.6.\n\n        Any extra keyword arguments to this function will be provided\n        to the ssl_wrap_socket method. If no ssl\n"}, {"char_start": 1633, "char_end": 1798, "chars": "        if ssl_wrap_socket is not None:\n            self._ssl_wrap_socket = ssl_wrap_socket\n        else:\n            self._ssl_wrap_socket = socketutil.wrap_socket\n"}]}, "commit_link": "github.com/dscho/hg/commit/bfe415fca85c8dcfcdb91347c4fffb4cf43e302e", "file_name": "__init__.py", "vul_type": "cwe-327", "commit_msg": "httpclient: import 4bb625347d4a to provide SSL wrapper injection\n\nThis lets us inject our own ssl.wrap_socket equivalent into\nhttpclient, which means that any changes we make to our ssl handling\ncan be *entirely* on our side without having to muck with httpclient,\nwhich sounds appealing. For example, an extension could wrap\nsslutil.ssl_wrap_socket with an api-compatible wrapper and then tweak\nSSL settings more precisely or use GnuTLS instead of OpenSSL.", "parent_commit": "b301e6de719f59637b3ae6bba505268ece940b09", "description": "Write a Python class constructor for an HTTPConnection that handles connection details, including optional SSL and proxy settings."}
{"func_name": "nav_path", "func_src_before": "def nav_path(request):\n  \"\"\"Return current path as list of items with \"name\" and \"href\" members\n\n  The href members are view_directory links for directories and view_log\n  links for files, but are set to None when the link would point to\n  the current view\"\"\"\n\n  if not request.repos:\n    return []\n\n  is_dir = request.pathtype == vclib.DIR\n\n  # add root item\n  items = []\n  root_item = _item(name=request.server.escape(request.repos.name), href=None)\n  if request.path_parts or request.view_func is not view_directory:\n    root_item.href = request.get_url(view_func=view_directory,\n                                     where='', pathtype=vclib.DIR,\n                                     params={}, escape=1)\n  items.append(root_item)\n\n  # add path part items\n  path_parts = []\n  for part in request.path_parts:\n    path_parts.append(part)\n    is_last = len(path_parts) == len(request.path_parts)\n\n    item = _item(name=part, href=None)\n\n    if not is_last or (is_dir and request.view_func is not view_directory):\n      item.href = request.get_url(view_func=view_directory,\n                                  where=_path_join(path_parts),\n                                  pathtype=vclib.DIR,\n                                  params={}, escape=1)\n    elif not is_dir and request.view_func is not view_log:\n      item.href = request.get_url(view_func=view_log,\n                                  where=_path_join(path_parts),\n                                  pathtype=vclib.FILE,\n                                  params={}, escape=1)\n    items.append(item)\n\n  return items", "func_src_after": "def nav_path(request):\n  \"\"\"Return current path as list of items with \"name\" and \"href\" members\n\n  The href members are view_directory links for directories and view_log\n  links for files, but are set to None when the link would point to\n  the current view\"\"\"\n\n  if not request.repos:\n    return []\n\n  is_dir = request.pathtype == vclib.DIR\n\n  # add root item\n  items = []\n  root_item = _item(name=request.server.escape(request.repos.name), href=None)\n  if request.path_parts or request.view_func is not view_directory:\n    root_item.href = request.get_url(view_func=view_directory,\n                                     where='', pathtype=vclib.DIR,\n                                     params={}, escape=1)\n  items.append(root_item)\n\n  # add path part items\n  path_parts = []\n  for part in request.path_parts:\n    path_parts.append(part)\n    is_last = len(path_parts) == len(request.path_parts)\n\n    item = _item(name=request.server.escape(part), href=None)\n\n    if not is_last or (is_dir and request.view_func is not view_directory):\n      item.href = request.get_url(view_func=view_directory,\n                                  where=_path_join(path_parts),\n                                  pathtype=vclib.DIR,\n                                  params={}, escape=1)\n    elif not is_dir and request.view_func is not view_log:\n      item.href = request.get_url(view_func=view_log,\n                                  where=_path_join(path_parts),\n                                  pathtype=vclib.FILE,\n                                  params={}, escape=1)\n    items.append(item)\n\n  return items", "commit_link": "github.com/viewvc/viewvc/commit/9dcfc7daa4c940992920d3b2fbd317da20e44aad", "file_name": "lib/viewvc.py", "vul_type": "cwe-079", "description": "Write a Python function that generates a breadcrumb navigation path from a request object."}
{"func_name": "do_mq_notify", "func_src_before": "static int do_mq_notify(mqd_t mqdes, const struct sigevent *notification)\n{\n\tint ret;\n\tstruct fd f;\n\tstruct sock *sock;\n\tstruct inode *inode;\n\tstruct mqueue_inode_info *info;\n\tstruct sk_buff *nc;\n\n\taudit_mq_notify(mqdes, notification);\n\n\tnc = NULL;\n\tsock = NULL;\n\tif (notification != NULL) {\n\t\tif (unlikely(notification->sigev_notify != SIGEV_NONE &&\n\t\t\t     notification->sigev_notify != SIGEV_SIGNAL &&\n\t\t\t     notification->sigev_notify != SIGEV_THREAD))\n\t\t\treturn -EINVAL;\n\t\tif (notification->sigev_notify == SIGEV_SIGNAL &&\n\t\t\t!valid_signal(notification->sigev_signo)) {\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (notification->sigev_notify == SIGEV_THREAD) {\n\t\t\tlong timeo;\n\n\t\t\t/* create the notify skb */\n\t\t\tnc = alloc_skb(NOTIFY_COOKIE_LEN, GFP_KERNEL);\n\t\t\tif (!nc) {\n\t\t\t\tret = -ENOMEM;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tif (copy_from_user(nc->data,\n\t\t\t\t\tnotification->sigev_value.sival_ptr,\n\t\t\t\t\tNOTIFY_COOKIE_LEN)) {\n\t\t\t\tret = -EFAULT;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\t/* TODO: add a header? */\n\t\t\tskb_put(nc, NOTIFY_COOKIE_LEN);\n\t\t\t/* and attach it to the socket */\nretry:\n\t\t\tf = fdget(notification->sigev_signo);\n\t\t\tif (!f.file) {\n\t\t\t\tret = -EBADF;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tsock = netlink_getsockbyfilp(f.file);\n\t\t\tfdput(f);\n\t\t\tif (IS_ERR(sock)) {\n\t\t\t\tret = PTR_ERR(sock);\n\t\t\t\tsock = NULL;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\ttimeo = MAX_SCHEDULE_TIMEOUT;\n\t\t\tret = netlink_attachskb(sock, nc, &timeo, NULL);\n\t\t\tif (ret == 1)\n\t\t\t\tgoto retry;\n\t\t\tif (ret) {\n\t\t\t\tsock = NULL;\n\t\t\t\tnc = NULL;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t}\n\n\tf = fdget(mqdes);\n\tif (!f.file) {\n\t\tret = -EBADF;\n\t\tgoto out;\n\t}\n\n\tinode = file_inode(f.file);\n\tif (unlikely(f.file->f_op != &mqueue_file_operations)) {\n\t\tret = -EBADF;\n\t\tgoto out_fput;\n\t}\n\tinfo = MQUEUE_I(inode);\n\n\tret = 0;\n\tspin_lock(&info->lock);\n\tif (notification == NULL) {\n\t\tif (info->notify_owner == task_tgid(current)) {\n\t\t\tremove_notification(info);\n\t\t\tinode->i_atime = inode->i_ctime = current_time(inode);\n\t\t}\n\t} else if (info->notify_owner != NULL) {\n\t\tret = -EBUSY;\n\t} else {\n\t\tswitch (notification->sigev_notify) {\n\t\tcase SIGEV_NONE:\n\t\t\tinfo->notify.sigev_notify = SIGEV_NONE;\n\t\t\tbreak;\n\t\tcase SIGEV_THREAD:\n\t\t\tinfo->notify_sock = sock;\n\t\t\tinfo->notify_cookie = nc;\n\t\t\tsock = NULL;\n\t\t\tnc = NULL;\n\t\t\tinfo->notify.sigev_notify = SIGEV_THREAD;\n\t\t\tbreak;\n\t\tcase SIGEV_SIGNAL:\n\t\t\tinfo->notify.sigev_signo = notification->sigev_signo;\n\t\t\tinfo->notify.sigev_value = notification->sigev_value;\n\t\t\tinfo->notify.sigev_notify = SIGEV_SIGNAL;\n\t\t\tbreak;\n\t\t}\n\n\t\tinfo->notify_owner = get_pid(task_tgid(current));\n\t\tinfo->notify_user_ns = get_user_ns(current_user_ns());\n\t\tinode->i_atime = inode->i_ctime = current_time(inode);\n\t}\n\tspin_unlock(&info->lock);\nout_fput:\n\tfdput(f);\nout:\n\tif (sock)\n\t\tnetlink_detachskb(sock, nc);\n\telse if (nc)\n\t\tdev_kfree_skb(nc);\n\n\treturn ret;\n}", "func_src_after": "static int do_mq_notify(mqd_t mqdes, const struct sigevent *notification)\n{\n\tint ret;\n\tstruct fd f;\n\tstruct sock *sock;\n\tstruct inode *inode;\n\tstruct mqueue_inode_info *info;\n\tstruct sk_buff *nc;\n\n\taudit_mq_notify(mqdes, notification);\n\n\tnc = NULL;\n\tsock = NULL;\n\tif (notification != NULL) {\n\t\tif (unlikely(notification->sigev_notify != SIGEV_NONE &&\n\t\t\t     notification->sigev_notify != SIGEV_SIGNAL &&\n\t\t\t     notification->sigev_notify != SIGEV_THREAD))\n\t\t\treturn -EINVAL;\n\t\tif (notification->sigev_notify == SIGEV_SIGNAL &&\n\t\t\t!valid_signal(notification->sigev_signo)) {\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (notification->sigev_notify == SIGEV_THREAD) {\n\t\t\tlong timeo;\n\n\t\t\t/* create the notify skb */\n\t\t\tnc = alloc_skb(NOTIFY_COOKIE_LEN, GFP_KERNEL);\n\t\t\tif (!nc) {\n\t\t\t\tret = -ENOMEM;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tif (copy_from_user(nc->data,\n\t\t\t\t\tnotification->sigev_value.sival_ptr,\n\t\t\t\t\tNOTIFY_COOKIE_LEN)) {\n\t\t\t\tret = -EFAULT;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\t/* TODO: add a header? */\n\t\t\tskb_put(nc, NOTIFY_COOKIE_LEN);\n\t\t\t/* and attach it to the socket */\nretry:\n\t\t\tf = fdget(notification->sigev_signo);\n\t\t\tif (!f.file) {\n\t\t\t\tret = -EBADF;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tsock = netlink_getsockbyfilp(f.file);\n\t\t\tfdput(f);\n\t\t\tif (IS_ERR(sock)) {\n\t\t\t\tret = PTR_ERR(sock);\n\t\t\t\tsock = NULL;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\ttimeo = MAX_SCHEDULE_TIMEOUT;\n\t\t\tret = netlink_attachskb(sock, nc, &timeo, NULL);\n\t\t\tif (ret == 1) {\n\t\t\t\tsock = NULL;\n\t\t\t\tgoto retry;\n\t\t\t}\n\t\t\tif (ret) {\n\t\t\t\tsock = NULL;\n\t\t\t\tnc = NULL;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t}\n\n\tf = fdget(mqdes);\n\tif (!f.file) {\n\t\tret = -EBADF;\n\t\tgoto out;\n\t}\n\n\tinode = file_inode(f.file);\n\tif (unlikely(f.file->f_op != &mqueue_file_operations)) {\n\t\tret = -EBADF;\n\t\tgoto out_fput;\n\t}\n\tinfo = MQUEUE_I(inode);\n\n\tret = 0;\n\tspin_lock(&info->lock);\n\tif (notification == NULL) {\n\t\tif (info->notify_owner == task_tgid(current)) {\n\t\t\tremove_notification(info);\n\t\t\tinode->i_atime = inode->i_ctime = current_time(inode);\n\t\t}\n\t} else if (info->notify_owner != NULL) {\n\t\tret = -EBUSY;\n\t} else {\n\t\tswitch (notification->sigev_notify) {\n\t\tcase SIGEV_NONE:\n\t\t\tinfo->notify.sigev_notify = SIGEV_NONE;\n\t\t\tbreak;\n\t\tcase SIGEV_THREAD:\n\t\t\tinfo->notify_sock = sock;\n\t\t\tinfo->notify_cookie = nc;\n\t\t\tsock = NULL;\n\t\t\tnc = NULL;\n\t\t\tinfo->notify.sigev_notify = SIGEV_THREAD;\n\t\t\tbreak;\n\t\tcase SIGEV_SIGNAL:\n\t\t\tinfo->notify.sigev_signo = notification->sigev_signo;\n\t\t\tinfo->notify.sigev_value = notification->sigev_value;\n\t\t\tinfo->notify.sigev_notify = SIGEV_SIGNAL;\n\t\t\tbreak;\n\t\t}\n\n\t\tinfo->notify_owner = get_pid(task_tgid(current));\n\t\tinfo->notify_user_ns = get_user_ns(current_user_ns());\n\t\tinode->i_atime = inode->i_ctime = current_time(inode);\n\t}\n\tspin_unlock(&info->lock);\nout_fput:\n\tfdput(f);\nout:\n\tif (sock)\n\t\tnetlink_detachskb(sock, nc);\n\telse if (nc)\n\t\tdev_kfree_skb(nc);\n\n\treturn ret;\n}", "commit_link": "github.com/torvalds/linux/commit/f991af3daabaecff34684fd51fac80319d1baad1", "file_name": "ipc/mqueue.c", "vul_type": "cwe-416", "description": "Write a C function named `do_mq_notify` that sets up message queue notifications."}
{"func_name": "usb_console_setup", "func_src_before": "static int usb_console_setup(struct console *co, char *options)\n{\n\tstruct usbcons_info *info = &usbcons_info;\n\tint baud = 9600;\n\tint bits = 8;\n\tint parity = 'n';\n\tint doflow = 0;\n\tint cflag = CREAD | HUPCL | CLOCAL;\n\tchar *s;\n\tstruct usb_serial *serial;\n\tstruct usb_serial_port *port;\n\tint retval;\n\tstruct tty_struct *tty = NULL;\n\tstruct ktermios dummy;\n\n\tif (options) {\n\t\tbaud = simple_strtoul(options, NULL, 10);\n\t\ts = options;\n\t\twhile (*s >= '0' && *s <= '9')\n\t\t\ts++;\n\t\tif (*s)\n\t\t\tparity = *s++;\n\t\tif (*s)\n\t\t\tbits   = *s++ - '0';\n\t\tif (*s)\n\t\t\tdoflow = (*s++ == 'r');\n\t}\n\t\n\t/* Sane default */\n\tif (baud == 0)\n\t\tbaud = 9600;\n\n\tswitch (bits) {\n\tcase 7:\n\t\tcflag |= CS7;\n\t\tbreak;\n\tdefault:\n\tcase 8:\n\t\tcflag |= CS8;\n\t\tbreak;\n\t}\n\tswitch (parity) {\n\tcase 'o': case 'O':\n\t\tcflag |= PARODD;\n\t\tbreak;\n\tcase 'e': case 'E':\n\t\tcflag |= PARENB;\n\t\tbreak;\n\t}\n\tco->cflag = cflag;\n\n\t/*\n\t * no need to check the index here: if the index is wrong, console\n\t * code won't call us\n\t */\n\tport = usb_serial_port_get_by_minor(co->index);\n\tif (port == NULL) {\n\t\t/* no device is connected yet, sorry :( */\n\t\tpr_err(\"No USB device connected to ttyUSB%i\\n\", co->index);\n\t\treturn -ENODEV;\n\t}\n\tserial = port->serial;\n\n\tretval = usb_autopm_get_interface(serial->interface);\n\tif (retval)\n\t\tgoto error_get_interface;\n\n\ttty_port_tty_set(&port->port, NULL);\n\n\tinfo->port = port;\n\n\t++port->port.count;\n\tif (!tty_port_initialized(&port->port)) {\n\t\tif (serial->type->set_termios) {\n\t\t\t/*\n\t\t\t * allocate a fake tty so the driver can initialize\n\t\t\t * the termios structure, then later call set_termios to\n\t\t\t * configure according to command line arguments\n\t\t\t */\n\t\t\ttty = kzalloc(sizeof(*tty), GFP_KERNEL);\n\t\t\tif (!tty) {\n\t\t\t\tretval = -ENOMEM;\n\t\t\t\tgoto reset_open_count;\n\t\t\t}\n\t\t\tkref_init(&tty->kref);\n\t\t\ttty->driver = usb_serial_tty_driver;\n\t\t\ttty->index = co->index;\n\t\t\tinit_ldsem(&tty->ldisc_sem);\n\t\t\tspin_lock_init(&tty->files_lock);\n\t\t\tINIT_LIST_HEAD(&tty->tty_files);\n\t\t\tkref_get(&tty->driver->kref);\n\t\t\t__module_get(tty->driver->owner);\n\t\t\ttty->ops = &usb_console_fake_tty_ops;\n\t\t\ttty_init_termios(tty);\n\t\t\ttty_port_tty_set(&port->port, tty);\n\t\t}\n\n\t\t/* only call the device specific open if this\n\t\t * is the first time the port is opened */\n\t\tretval = serial->type->open(NULL, port);\n\t\tif (retval) {\n\t\t\tdev_err(&port->dev, \"could not open USB console port\\n\");\n\t\t\tgoto fail;\n\t\t}\n\n\t\tif (serial->type->set_termios) {\n\t\t\ttty->termios.c_cflag = cflag;\n\t\t\ttty_termios_encode_baud_rate(&tty->termios, baud, baud);\n\t\t\tmemset(&dummy, 0, sizeof(struct ktermios));\n\t\t\tserial->type->set_termios(tty, port, &dummy);\n\n\t\t\ttty_port_tty_set(&port->port, NULL);\n\t\t\ttty_kref_put(tty);\n\t\t}\n\t\ttty_port_set_initialized(&port->port, 1);\n\t}\n\t/* Now that any required fake tty operations are completed restore\n\t * the tty port count */\n\t--port->port.count;\n\t/* The console is special in terms of closing the device so\n\t * indicate this port is now acting as a system console. */\n\tport->port.console = 1;\n\n\tmutex_unlock(&serial->disc_mutex);\n\treturn retval;\n\n fail:\n\ttty_port_tty_set(&port->port, NULL);\n\ttty_kref_put(tty);\n reset_open_count:\n\tport->port.count = 0;\n\tusb_autopm_put_interface(serial->interface);\n error_get_interface:\n\tusb_serial_put(serial);\n\tmutex_unlock(&serial->disc_mutex);\n\treturn retval;\n}", "func_src_after": "static int usb_console_setup(struct console *co, char *options)\n{\n\tstruct usbcons_info *info = &usbcons_info;\n\tint baud = 9600;\n\tint bits = 8;\n\tint parity = 'n';\n\tint doflow = 0;\n\tint cflag = CREAD | HUPCL | CLOCAL;\n\tchar *s;\n\tstruct usb_serial *serial;\n\tstruct usb_serial_port *port;\n\tint retval;\n\tstruct tty_struct *tty = NULL;\n\tstruct ktermios dummy;\n\n\tif (options) {\n\t\tbaud = simple_strtoul(options, NULL, 10);\n\t\ts = options;\n\t\twhile (*s >= '0' && *s <= '9')\n\t\t\ts++;\n\t\tif (*s)\n\t\t\tparity = *s++;\n\t\tif (*s)\n\t\t\tbits   = *s++ - '0';\n\t\tif (*s)\n\t\t\tdoflow = (*s++ == 'r');\n\t}\n\t\n\t/* Sane default */\n\tif (baud == 0)\n\t\tbaud = 9600;\n\n\tswitch (bits) {\n\tcase 7:\n\t\tcflag |= CS7;\n\t\tbreak;\n\tdefault:\n\tcase 8:\n\t\tcflag |= CS8;\n\t\tbreak;\n\t}\n\tswitch (parity) {\n\tcase 'o': case 'O':\n\t\tcflag |= PARODD;\n\t\tbreak;\n\tcase 'e': case 'E':\n\t\tcflag |= PARENB;\n\t\tbreak;\n\t}\n\tco->cflag = cflag;\n\n\t/*\n\t * no need to check the index here: if the index is wrong, console\n\t * code won't call us\n\t */\n\tport = usb_serial_port_get_by_minor(co->index);\n\tif (port == NULL) {\n\t\t/* no device is connected yet, sorry :( */\n\t\tpr_err(\"No USB device connected to ttyUSB%i\\n\", co->index);\n\t\treturn -ENODEV;\n\t}\n\tserial = port->serial;\n\n\tretval = usb_autopm_get_interface(serial->interface);\n\tif (retval)\n\t\tgoto error_get_interface;\n\n\ttty_port_tty_set(&port->port, NULL);\n\n\tinfo->port = port;\n\n\t++port->port.count;\n\tif (!tty_port_initialized(&port->port)) {\n\t\tif (serial->type->set_termios) {\n\t\t\t/*\n\t\t\t * allocate a fake tty so the driver can initialize\n\t\t\t * the termios structure, then later call set_termios to\n\t\t\t * configure according to command line arguments\n\t\t\t */\n\t\t\ttty = kzalloc(sizeof(*tty), GFP_KERNEL);\n\t\t\tif (!tty) {\n\t\t\t\tretval = -ENOMEM;\n\t\t\t\tgoto reset_open_count;\n\t\t\t}\n\t\t\tkref_init(&tty->kref);\n\t\t\ttty->driver = usb_serial_tty_driver;\n\t\t\ttty->index = co->index;\n\t\t\tinit_ldsem(&tty->ldisc_sem);\n\t\t\tspin_lock_init(&tty->files_lock);\n\t\t\tINIT_LIST_HEAD(&tty->tty_files);\n\t\t\tkref_get(&tty->driver->kref);\n\t\t\t__module_get(tty->driver->owner);\n\t\t\ttty->ops = &usb_console_fake_tty_ops;\n\t\t\ttty_init_termios(tty);\n\t\t\ttty_port_tty_set(&port->port, tty);\n\t\t}\n\n\t\t/* only call the device specific open if this\n\t\t * is the first time the port is opened */\n\t\tretval = serial->type->open(NULL, port);\n\t\tif (retval) {\n\t\t\tdev_err(&port->dev, \"could not open USB console port\\n\");\n\t\t\tgoto fail;\n\t\t}\n\n\t\tif (serial->type->set_termios) {\n\t\t\ttty->termios.c_cflag = cflag;\n\t\t\ttty_termios_encode_baud_rate(&tty->termios, baud, baud);\n\t\t\tmemset(&dummy, 0, sizeof(struct ktermios));\n\t\t\tserial->type->set_termios(tty, port, &dummy);\n\n\t\t\ttty_port_tty_set(&port->port, NULL);\n\t\t\ttty_kref_put(tty);\n\t\t}\n\t\ttty_port_set_initialized(&port->port, 1);\n\t}\n\t/* Now that any required fake tty operations are completed restore\n\t * the tty port count */\n\t--port->port.count;\n\t/* The console is special in terms of closing the device so\n\t * indicate this port is now acting as a system console. */\n\tport->port.console = 1;\n\n\tmutex_unlock(&serial->disc_mutex);\n\treturn retval;\n\n fail:\n\ttty_port_tty_set(&port->port, NULL);\n\ttty_kref_put(tty);\n reset_open_count:\n\tport->port.count = 0;\n\tinfo->port = NULL;\n\tusb_autopm_put_interface(serial->interface);\n error_get_interface:\n\tusb_serial_put(serial);\n\tmutex_unlock(&serial->disc_mutex);\n\treturn retval;\n}", "commit_link": "github.com/torvalds/linux/commit/299d7572e46f98534033a9e65973f13ad1ce9047", "file_name": "drivers/usb/serial/console.c", "vul_type": "cwe-416", "description": "Write a C function named `usb_console_setup` for setting up a USB console with configurable baud rate, parity, and data bits."}
{"func_name": "save_page_edit", "func_src_before": "@app.route('/<page_name>/save', methods=['POST'])\ndef save_page_edit(page_name):\n    # grab the new content from the user\n    content = request.form.get('content')\n    # check if 'page_name' exists in the database\n    query = db.query(\"select page_content.content, page.id as page_id, page_content.id as content_id from page, page_content where page.id = page_content.page_id and page.page_name = '%s' order by page_content.id desc limit 1\" % page_name)\n    result = query.namedresult()\n    # if it doesn't exist, create a new page in the database\n    if len(result) < 1:\n        db.insert(\n            'page', {\n                'page_name': page_name\n            }\n        )\n    else:\n        pass\n    # now that we're certain that the page exists in the database, we again grab the query\n    # and insert new content in the database\n    query = db.query(\"select id from page where page_name = '%s'\" % page_name)\n    page_id = query.namedresult()[0].id\n    db.insert(\n        'page_content', {\n            'page_id': page_id,\n            'content': content,\n            'timestamp': time.strftime(\"%Y-%m-%d %H:%M:%S\", localtime())\n        }\n    )\n    return redirect(\"/%s\" % page_name)", "func_src_after": "@app.route('/<page_name>/save', methods=['POST'])\ndef save_page_edit(page_name):\n    # grab the new content from the user\n    content = request.form.get('content')\n    # check if 'page_name' exists in the database\n    query = db.query(\"select page_content.content, page.id as page_id, page_content.id as content_id from page, page_content where page.id = page_content.page_id and page.page_name = $1 order by page_content.id desc limit 1\", page_name)\n    result = query.namedresult()\n    # if it doesn't exist, create a new page in the database\n    if len(result) < 1:\n        db.insert(\n            'page', {\n                'page_name': page_name\n            }\n        )\n    else:\n        pass\n    # now that we're certain that the page exists in the database, we again grab the query\n    # and insert new content in the database\n    query = db.query(\"select id from page where page_name = '%s'\" % page_name)\n    page_id = query.namedresult()[0].id\n    db.insert(\n        'page_content', {\n            'page_id': page_id,\n            'content': content,\n            'timestamp': time.strftime(\"%Y-%m-%d %H:%M:%S\", localtime())\n        }\n    )\n    return redirect(\"/%s\" % page_name)", "commit_link": "github.com/Pumala/python_wiki_app_redo/commit/65d60747cd8efb05970304234d3bd949d2088e8b", "file_name": "server.py", "vul_type": "cwe-089", "description": "In Python, write a Flask endpoint to save edited content for a given page, creating the page in the database if it doesn't exist."}
{"func_name": "igraph_read_graph_graphml", "func_src_before": "int igraph_read_graph_graphml(igraph_t *graph, FILE *instream, int index) {\n\n#if HAVE_LIBXML == 1\n    xmlParserCtxtPtr ctxt;\n    xmlDocPtr doc;\n\n    struct igraph_i_graphml_parser_state state;\n    int res;\n    char buffer[4096];\n    igraph_bool_t parsing_successful;\n    char* error_message;\n\n    if (index < 0) {\n        IGRAPH_ERROR(\"Graph index must be non-negative\", IGRAPH_EINVAL);\n    }\n\n    xmlInitParser();\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_init(&state, graph, index));\n    IGRAPH_FINALLY(igraph_i_graphml_parser_state_destroy, &state);\n\n    /* Create a progressive parser context */\n    res = (int) fread(buffer, 1, sizeof(buffer), instream);\n    if (res < sizeof(buffer) && !feof(instream)) {\n        IGRAPH_ERROR(\"IO error while reading GraphML data\", IGRAPH_PARSEERROR);\n    }\n    ctxt = xmlCreatePushParserCtxt(&igraph_i_graphml_sax_handler,\n                                   &state,\n                                   buffer,\n                                   res,\n                                   NULL);\n    /*   ctxt=xmlCreateIOParserCtxt(&igraph_i_graphml_sax_handler, &state, */\n    /*               igraph_i_libxml2_read_callback, */\n    /*               igraph_i_libxml2_close_callback, */\n    /*               instream, XML_CHAR_ENCODING_NONE); */\n    if (ctxt == NULL) {\n        IGRAPH_ERROR(\"Can't create progressive parser context\", IGRAPH_PARSEERROR);\n    }\n\n    /* Set parsing options */\n    if (xmlCtxtUseOptions(ctxt,\n                          XML_PARSE_NOENT | XML_PARSE_NOBLANKS |\n                          XML_PARSE_NONET | XML_PARSE_NSCLEAN |\n                          XML_PARSE_NOCDATA | XML_PARSE_HUGE\n                         )) {\n        xmlFreeParserCtxt(ctxt);\n        IGRAPH_ERROR(\"Cannot set options for the parser context\", IGRAPH_EINVAL);\n    }\n\n    /* Okay, parsing will start now. The parser might do things that eventually\n     * trigger the igraph error handler, but we want the parser state to\n     * survive whatever happens here. So, we need to pop off\n     * igraph_i_graphml_parser_state_destroy() from the stack and temporarily\n     * assume responsibility for calling it ourselves until we are back from the\n     * parser */\n    IGRAPH_FINALLY_CLEAN(1);\n\n    /* Do the parsing */\n    while ((res = (int) fread(buffer, 1, sizeof(buffer), instream)) > 0) {\n        xmlParseChunk(ctxt, buffer, res, 0);\n        if (!state.successful) {\n            break;\n        }\n    }\n    xmlParseChunk(ctxt, buffer, res, 1);\n\n    /* Free the context */\n    doc = ctxt->myDoc;\n    xmlFreeParserCtxt(ctxt);\n    if (doc) {\n        /* In theory this should not be necessary, but it looks like certain malformed\n         * GraphML files leave a partially-parsed doc in memory */\n        xmlFreeDoc(doc);\n    }\n\n    /* Extract the error message from the parser state (if any), and make a\n     * copy so we can safely destroy the parser state before triggering the\n     * error */\n    parsing_successful = state.successful;\n    error_message = parsing_successful || state.error_message == NULL ? NULL : strdup(state.error_message);\n\n    /* Now that we have lifted error_message out of the parser state, we can\n     * put the destructor of the parser state back on the FINALLY stack */\n    IGRAPH_FINALLY(igraph_i_graphml_parser_state_destroy, &state);\n\n    /* ...and we can also put the error message pointer on the FINALLY stack */\n    if (error_message != NULL) {\n        IGRAPH_FINALLY(free, error_message);\n    }\n\n    /* Trigger the stored error if needed */\n    if (!parsing_successful) {\n        if (error_message != NULL) {\n            IGRAPH_ERROR(error_message, IGRAPH_PARSEERROR);\n        } else {\n            IGRAPH_ERROR(\"Malformed GraphML file\", IGRAPH_PARSEERROR);\n        }\n    }\n\n    /* Did we actually manage to reach the graph to be parsed, given its index?\n     * If not, that's an error as well. */\n    if (state.index >= 0) {\n        IGRAPH_ERROR(\"Graph index was too large\", IGRAPH_EINVAL);\n    }\n\n    /* Okay, everything seems good. We can now take the parser state and\n     * construct our graph from the data gathered during the parsing */\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_finish_parsing(&state));\n\n    igraph_i_graphml_parser_state_destroy(&state);\n    IGRAPH_FINALLY_CLEAN(1);\n\n    return IGRAPH_SUCCESS;\n#else\n    IGRAPH_UNUSED(graph);\n    IGRAPH_UNUSED(instream);\n    IGRAPH_UNUSED(index);\n\n    IGRAPH_ERROR(\"GraphML support is disabled\", IGRAPH_UNIMPLEMENTED);\n#endif\n}", "func_src_after": "int igraph_read_graph_graphml(igraph_t *graph, FILE *instream, int index) {\n\n#if HAVE_LIBXML == 1\n    xmlParserCtxtPtr ctxt;\n    xmlDocPtr doc;\n\n    struct igraph_i_graphml_parser_state state;\n    int res;\n    char buffer[4096];\n    igraph_bool_t parsing_successful;\n    char* error_message;\n\n    if (index < 0) {\n        IGRAPH_ERROR(\"Graph index must be non-negative\", IGRAPH_EINVAL);\n    }\n\n    xmlInitParser();\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_init(&state, graph, index));\n    IGRAPH_FINALLY(igraph_i_graphml_parser_state_destroy, &state);\n\n    /* Create a progressive parser context */\n    res = (int) fread(buffer, 1, sizeof(buffer), instream);\n    if (res < sizeof(buffer) && !feof(instream)) {\n        IGRAPH_ERROR(\"IO error while reading GraphML data\", IGRAPH_PARSEERROR);\n    }\n    ctxt = xmlCreatePushParserCtxt(&igraph_i_graphml_sax_handler,\n                                   &state,\n                                   buffer,\n                                   res,\n                                   NULL);\n    /*   ctxt=xmlCreateIOParserCtxt(&igraph_i_graphml_sax_handler, &state, */\n    /*               igraph_i_libxml2_read_callback, */\n    /*               igraph_i_libxml2_close_callback, */\n    /*               instream, XML_CHAR_ENCODING_NONE); */\n    if (ctxt == NULL) {\n        IGRAPH_ERROR(\"Can't create progressive parser context\", IGRAPH_PARSEERROR);\n    }\n\n    /* Set parsing options */\n    if (xmlCtxtUseOptions(ctxt,\n                          XML_PARSE_NOBLANKS |\n                          XML_PARSE_NONET | XML_PARSE_NSCLEAN |\n                          XML_PARSE_NOCDATA | XML_PARSE_HUGE\n                         )) {\n        xmlFreeParserCtxt(ctxt);\n        IGRAPH_ERROR(\"Cannot set options for the parser context\", IGRAPH_EINVAL);\n    }\n\n    /* Okay, parsing will start now. The parser might do things that eventually\n     * trigger the igraph error handler, but we want the parser state to\n     * survive whatever happens here. So, we need to pop off\n     * igraph_i_graphml_parser_state_destroy() from the stack and temporarily\n     * assume responsibility for calling it ourselves until we are back from the\n     * parser */\n    IGRAPH_FINALLY_CLEAN(1);\n\n    /* Do the parsing */\n    while ((res = (int) fread(buffer, 1, sizeof(buffer), instream)) > 0) {\n        xmlParseChunk(ctxt, buffer, res, 0);\n        if (!state.successful) {\n            break;\n        }\n    }\n    xmlParseChunk(ctxt, buffer, res, 1);\n\n    /* Free the context */\n    doc = ctxt->myDoc;\n    xmlFreeParserCtxt(ctxt);\n    if (doc) {\n        /* In theory this should not be necessary, but it looks like certain malformed\n         * GraphML files leave a partially-parsed doc in memory */\n        xmlFreeDoc(doc);\n    }\n\n    /* Extract the error message from the parser state (if any), and make a\n     * copy so we can safely destroy the parser state before triggering the\n     * error */\n    parsing_successful = state.successful;\n    error_message = parsing_successful || state.error_message == NULL ? NULL : strdup(state.error_message);\n\n    /* Now that we have lifted error_message out of the parser state, we can\n     * put the destructor of the parser state back on the FINALLY stack */\n    IGRAPH_FINALLY(igraph_i_graphml_parser_state_destroy, &state);\n\n    /* ...and we can also put the error message pointer on the FINALLY stack */\n    if (error_message != NULL) {\n        IGRAPH_FINALLY(free, error_message);\n    }\n\n    /* Trigger the stored error if needed */\n    if (!parsing_successful) {\n        if (error_message != NULL) {\n            IGRAPH_ERROR(error_message, IGRAPH_PARSEERROR);\n        } else {\n            IGRAPH_ERROR(\"Malformed GraphML file\", IGRAPH_PARSEERROR);\n        }\n    }\n\n    /* Did we actually manage to reach the graph to be parsed, given its index?\n     * If not, that's an error as well. */\n    if (state.index >= 0) {\n        IGRAPH_ERROR(\"Graph index was too large\", IGRAPH_EINVAL);\n    }\n\n    /* Okay, everything seems good. We can now take the parser state and\n     * construct our graph from the data gathered during the parsing */\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_finish_parsing(&state));\n\n    igraph_i_graphml_parser_state_destroy(&state);\n    IGRAPH_FINALLY_CLEAN(1);\n\n    return IGRAPH_SUCCESS;\n#else\n    IGRAPH_UNUSED(graph);\n    IGRAPH_UNUSED(instream);\n    IGRAPH_UNUSED(index);\n\n    IGRAPH_ERROR(\"GraphML support is disabled\", IGRAPH_UNIMPLEMENTED);\n#endif\n}", "line_changes": {"deleted": [{"line_no": 41, "char_start": 1463, "char_end": 1528, "line": "                          XML_PARSE_NOENT | XML_PARSE_NOBLANKS |\n"}], "added": [{"line_no": 41, "char_start": 1463, "char_end": 1510, "line": "                          XML_PARSE_NOBLANKS |\n"}]}, "char_changes": {"deleted": [{"char_start": 1488, "char_end": 1506, "chars": " XML_PARSE_NOENT |"}], "added": []}, "commit_link": "github.com/igraph/igraph/commit/6ce2353fa77a891d1b556b8908ca9e4c227c3619", "file_name": "graphml.c", "vul_type": "cwe-611", "commit_msg": "fix: disable external XML entity resolution", "parent_commit": "cb8f28bae4c5ab92e5b628d9b4f827d3c61ba6ce", "description": "Write a C function to parse a GraphML file into an igraph_t structure using libxml2."}
{"func_name": "set_fdc", "func_src_before": "static void set_fdc(int drive)\n{\n\tif (drive >= 0 && drive < N_DRIVE) {\n\t\tfdc = FDC(drive);\n\t\tcurrent_drive = drive;\n\t}\n\tif (fdc != 1 && fdc != 0) {\n\t\tpr_info(\"bad fdc value\\n\");\n\t\treturn;\n\t}\n\tset_dor(fdc, ~0, 8);\n#if N_FDC > 1\n\tset_dor(1 - fdc, ~8, 0);\n#endif\n\tif (FDCS->rawcmd == 2)\n\t\treset_fdc_info(1);\n\tif (fd_inb(FD_STATUS) != STATUS_READY)\n\t\tFDCS->reset = 1;\n}", "func_src_after": "static void set_fdc(int drive)\n{\n\tunsigned int new_fdc = fdc;\n\n\tif (drive >= 0 && drive < N_DRIVE) {\n\t\tnew_fdc = FDC(drive);\n\t\tcurrent_drive = drive;\n\t}\n\tif (new_fdc >= N_FDC) {\n\t\tpr_info(\"bad fdc value\\n\");\n\t\treturn;\n\t}\n\tfdc = new_fdc;\n\tset_dor(fdc, ~0, 8);\n#if N_FDC > 1\n\tset_dor(1 - fdc, ~8, 0);\n#endif\n\tif (FDCS->rawcmd == 2)\n\t\treset_fdc_info(1);\n\tif (fd_inb(FD_STATUS) != STATUS_READY)\n\t\tFDCS->reset = 1;\n}", "commit_link": "github.com/torvalds/linux/commit/2e90ca68b0d2f5548804f22f0dd61145516171e3", "file_name": "drivers/block/floppy.c", "vul_type": "cwe-125", "description": "Write a C function named `set_fdc` that configures a floppy disk controller (FDC) for a given drive number, with error checking and hardware status updates."}
{"func_name": "read_SubStreamsInfo", "func_src_before": "read_SubStreamsInfo(struct archive_read *a, struct _7z_substream_info *ss,\n    struct _7z_folder *f, size_t numFolders)\n{\n\tconst unsigned char *p;\n\tuint64_t *usizes;\n\tsize_t unpack_streams;\n\tint type;\n\tunsigned i;\n\tuint32_t numDigests;\n\n\tmemset(ss, 0, sizeof(*ss));\n\n\tfor (i = 0; i < numFolders; i++)\n\t\tf[i].numUnpackStreams = 1;\n\n\tif ((p = header_bytes(a, 1)) == NULL)\n\t\treturn (-1);\n\ttype = *p;\n\n\tif (type == kNumUnPackStream) {\n\t\tunpack_streams = 0;\n\t\tfor (i = 0; i < numFolders; i++) {\n\t\t\tif (parse_7zip_uint64(a, &(f[i].numUnpackStreams)) < 0)\n\t\t\t\treturn (-1);\n\t\t\tif (UMAX_ENTRY < f[i].numUnpackStreams)\n\t\t\t\treturn (-1);\n\t\t\tunpack_streams += (size_t)f[i].numUnpackStreams;\n\t\t}\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t\ttype = *p;\n\t} else\n\t\tunpack_streams = numFolders;\n\n\tss->unpack_streams = unpack_streams;\n\tif (unpack_streams) {\n\t\tss->unpackSizes = calloc(unpack_streams,\n\t\t    sizeof(*ss->unpackSizes));\n\t\tss->digestsDefined = calloc(unpack_streams,\n\t\t    sizeof(*ss->digestsDefined));\n\t\tss->digests = calloc(unpack_streams,\n\t\t    sizeof(*ss->digests));\n\t\tif (ss->unpackSizes == NULL || ss->digestsDefined == NULL ||\n\t\t    ss->digests == NULL)\n\t\t\treturn (-1);\n\t}\n\n\tusizes = ss->unpackSizes;\n\tfor (i = 0; i < numFolders; i++) {\n\t\tunsigned pack;\n\t\tuint64_t sum;\n\n\t\tif (f[i].numUnpackStreams == 0)\n\t\t\tcontinue;\n\n\t\tsum = 0;\n\t\tif (type == kSize) {\n\t\t\tfor (pack = 1; pack < f[i].numUnpackStreams; pack++) {\n\t\t\t\tif (parse_7zip_uint64(a, usizes) < 0)\n\t\t\t\t\treturn (-1);\n\t\t\t\tsum += *usizes++;\n\t\t\t}\n\t\t}\n\t\t*usizes++ = folder_uncompressed_size(&f[i]) - sum;\n\t}\n\n\tif (type == kSize) {\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t\ttype = *p;\n\t}\n\n\tfor (i = 0; i < unpack_streams; i++) {\n\t\tss->digestsDefined[i] = 0;\n\t\tss->digests[i] = 0;\n\t}\n\n\tnumDigests = 0;\n\tfor (i = 0; i < numFolders; i++) {\n\t\tif (f[i].numUnpackStreams != 1 || !f[i].digest_defined)\n\t\t\tnumDigests += (uint32_t)f[i].numUnpackStreams;\n\t}\n\n\tif (type == kCRC) {\n\t\tstruct _7z_digests tmpDigests;\n\t\tunsigned char *digestsDefined = ss->digestsDefined;\n\t\tuint32_t * digests = ss->digests;\n\t\tint di = 0;\n\n\t\tmemset(&tmpDigests, 0, sizeof(tmpDigests));\n\t\tif (read_Digests(a, &(tmpDigests), numDigests) < 0) {\n\t\t\tfree_Digest(&tmpDigests);\n\t\t\treturn (-1);\n\t\t}\n\t\tfor (i = 0; i < numFolders; i++) {\n\t\t\tif (f[i].numUnpackStreams == 1 && f[i].digest_defined) {\n\t\t\t\t*digestsDefined++ = 1;\n\t\t\t\t*digests++ = f[i].digest;\n\t\t\t} else {\n\t\t\t\tunsigned j;\n\n\t\t\t\tfor (j = 0; j < f[i].numUnpackStreams;\n\t\t\t\t    j++, di++) {\n\t\t\t\t\t*digestsDefined++ =\n\t\t\t\t\t    tmpDigests.defineds[di];\n\t\t\t\t\t*digests++ =\n\t\t\t\t\t    tmpDigests.digests[di];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfree_Digest(&tmpDigests);\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t\ttype = *p;\n\t}\n\n\t/*\n\t *  Must be kEnd.\n\t */\n\tif (type != kEnd)\n\t\treturn (-1);\n\treturn (0);\n}", "func_src_after": "read_SubStreamsInfo(struct archive_read *a, struct _7z_substream_info *ss,\n    struct _7z_folder *f, size_t numFolders)\n{\n\tconst unsigned char *p;\n\tuint64_t *usizes;\n\tsize_t unpack_streams;\n\tint type;\n\tunsigned i;\n\tuint32_t numDigests;\n\n\tmemset(ss, 0, sizeof(*ss));\n\n\tfor (i = 0; i < numFolders; i++)\n\t\tf[i].numUnpackStreams = 1;\n\n\tif ((p = header_bytes(a, 1)) == NULL)\n\t\treturn (-1);\n\ttype = *p;\n\n\tif (type == kNumUnPackStream) {\n\t\tunpack_streams = 0;\n\t\tfor (i = 0; i < numFolders; i++) {\n\t\t\tif (parse_7zip_uint64(a, &(f[i].numUnpackStreams)) < 0)\n\t\t\t\treturn (-1);\n\t\t\tif (UMAX_ENTRY < f[i].numUnpackStreams)\n\t\t\t\treturn (-1);\n\t\t\tif (unpack_streams > SIZE_MAX - UMAX_ENTRY) {\n\t\t\t\treturn (-1);\n\t\t\t}\n\t\t\tunpack_streams += (size_t)f[i].numUnpackStreams;\n\t\t}\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t\ttype = *p;\n\t} else\n\t\tunpack_streams = numFolders;\n\n\tss->unpack_streams = unpack_streams;\n\tif (unpack_streams) {\n\t\tss->unpackSizes = calloc(unpack_streams,\n\t\t    sizeof(*ss->unpackSizes));\n\t\tss->digestsDefined = calloc(unpack_streams,\n\t\t    sizeof(*ss->digestsDefined));\n\t\tss->digests = calloc(unpack_streams,\n\t\t    sizeof(*ss->digests));\n\t\tif (ss->unpackSizes == NULL || ss->digestsDefined == NULL ||\n\t\t    ss->digests == NULL)\n\t\t\treturn (-1);\n\t}\n\n\tusizes = ss->unpackSizes;\n\tfor (i = 0; i < numFolders; i++) {\n\t\tunsigned pack;\n\t\tuint64_t sum;\n\n\t\tif (f[i].numUnpackStreams == 0)\n\t\t\tcontinue;\n\n\t\tsum = 0;\n\t\tif (type == kSize) {\n\t\t\tfor (pack = 1; pack < f[i].numUnpackStreams; pack++) {\n\t\t\t\tif (parse_7zip_uint64(a, usizes) < 0)\n\t\t\t\t\treturn (-1);\n\t\t\t\tsum += *usizes++;\n\t\t\t}\n\t\t}\n\t\t*usizes++ = folder_uncompressed_size(&f[i]) - sum;\n\t}\n\n\tif (type == kSize) {\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t\ttype = *p;\n\t}\n\n\tfor (i = 0; i < unpack_streams; i++) {\n\t\tss->digestsDefined[i] = 0;\n\t\tss->digests[i] = 0;\n\t}\n\n\tnumDigests = 0;\n\tfor (i = 0; i < numFolders; i++) {\n\t\tif (f[i].numUnpackStreams != 1 || !f[i].digest_defined)\n\t\t\tnumDigests += (uint32_t)f[i].numUnpackStreams;\n\t}\n\n\tif (type == kCRC) {\n\t\tstruct _7z_digests tmpDigests;\n\t\tunsigned char *digestsDefined = ss->digestsDefined;\n\t\tuint32_t * digests = ss->digests;\n\t\tint di = 0;\n\n\t\tmemset(&tmpDigests, 0, sizeof(tmpDigests));\n\t\tif (read_Digests(a, &(tmpDigests), numDigests) < 0) {\n\t\t\tfree_Digest(&tmpDigests);\n\t\t\treturn (-1);\n\t\t}\n\t\tfor (i = 0; i < numFolders; i++) {\n\t\t\tif (f[i].numUnpackStreams == 1 && f[i].digest_defined) {\n\t\t\t\t*digestsDefined++ = 1;\n\t\t\t\t*digests++ = f[i].digest;\n\t\t\t} else {\n\t\t\t\tunsigned j;\n\n\t\t\t\tfor (j = 0; j < f[i].numUnpackStreams;\n\t\t\t\t    j++, di++) {\n\t\t\t\t\t*digestsDefined++ =\n\t\t\t\t\t    tmpDigests.defineds[di];\n\t\t\t\t\t*digests++ =\n\t\t\t\t\t    tmpDigests.digests[di];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfree_Digest(&tmpDigests);\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t\ttype = *p;\n\t}\n\n\t/*\n\t *  Must be kEnd.\n\t */\n\tif (type != kEnd)\n\t\treturn (-1);\n\treturn (0);\n}", "commit_link": "github.com/libarchive/libarchive/commit/e79ef306afe332faf22e9b442a2c6b59cb175573", "file_name": "libarchive/archive_read_support_format_7zip.c", "vul_type": "cwe-190", "description": "In C, write a function to read substream information for folders within a 7z archive."}
{"func_name": "get_ports", "func_src_before": "    def get_ports(self):\n        # First get the active FC ports\n        out = self._cli_run('showport', None)\n\n        # strip out header\n        # N:S:P,Mode,State,----Node_WWN----,-Port_WWN/HW_Addr-,Type,\n        # Protocol,Label,Partner,FailoverState\n        out = out[1:len(out) - 2]\n\n        ports = {'FC': [], 'iSCSI': {}}\n        for line in out:\n            tmp = line.split(',')\n\n            if tmp:\n                if tmp[1] == 'target' and tmp[2] == 'ready':\n                    if tmp[6] == 'FC':\n                        ports['FC'].append(tmp[4])\n\n        # now get the active iSCSI ports\n        out = self._cli_run('showport -iscsi', None)\n\n        # strip out header\n        # N:S:P,State,IPAddr,Netmask,Gateway,\n        # TPGT,MTU,Rate,DHCP,iSNS_Addr,iSNS_Port\n        out = out[1:len(out) - 2]\n        for line in out:\n            tmp = line.split(',')\n\n            if tmp and len(tmp) > 2:\n                if tmp[1] == 'ready':\n                    ports['iSCSI'][tmp[2]] = {}\n\n        # now get the nsp and iqn\n        result = self._cli_run('showport -iscsiname', None)\n        if result:\n            # first line is header\n            # nsp, ip,iqn\n            result = result[1:]\n            for line in result:\n                info = line.split(\",\")\n                if info and len(info) > 2:\n                    if info[1] in ports['iSCSI']:\n                        nsp = info[0]\n                        ip_addr = info[1]\n                        iqn = info[2]\n                        ports['iSCSI'][ip_addr] = {'nsp': nsp,\n                                                   'iqn': iqn\n                                                   }\n\n        LOG.debug(\"PORTS = %s\" % pprint.pformat(ports))\n        return ports", "func_src_after": "    def get_ports(self):\n        # First get the active FC ports\n        out = self._cli_run(['showport'])\n\n        # strip out header\n        # N:S:P,Mode,State,----Node_WWN----,-Port_WWN/HW_Addr-,Type,\n        # Protocol,Label,Partner,FailoverState\n        out = out[1:len(out) - 2]\n\n        ports = {'FC': [], 'iSCSI': {}}\n        for line in out:\n            tmp = line.split(',')\n\n            if tmp:\n                if tmp[1] == 'target' and tmp[2] == 'ready':\n                    if tmp[6] == 'FC':\n                        ports['FC'].append(tmp[4])\n\n        # now get the active iSCSI ports\n        out = self._cli_run(['showport', '-iscsi'])\n\n        # strip out header\n        # N:S:P,State,IPAddr,Netmask,Gateway,\n        # TPGT,MTU,Rate,DHCP,iSNS_Addr,iSNS_Port\n        out = out[1:len(out) - 2]\n        for line in out:\n            tmp = line.split(',')\n\n            if tmp and len(tmp) > 2:\n                if tmp[1] == 'ready':\n                    ports['iSCSI'][tmp[2]] = {}\n\n        # now get the nsp and iqn\n        result = self._cli_run(['showport', '-iscsiname'])\n        if result:\n            # first line is header\n            # nsp, ip,iqn\n            result = result[1:]\n            for line in result:\n                info = line.split(\",\")\n                if info and len(info) > 2:\n                    if info[1] in ports['iSCSI']:\n                        nsp = info[0]\n                        ip_addr = info[1]\n                        iqn = info[2]\n                        ports['iSCSI'][ip_addr] = {'nsp': nsp,\n                                                   'iqn': iqn\n                                                   }\n\n        LOG.debug(\"PORTS = %s\" % pprint.pformat(ports))\n        return ports", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function to parse and return active FC and iSCSI port details from CLI output."}
{"func_name": "fetch_resultSet", "func_src_before": "    def fetch_resultSet(self, session, id):\n        self._openContainer(session)\n\n        sid = str(id)\n        if (self.idNormalizer is not None):\n            sid = self.idNormalizer.process_string(session, sid)\n        query = (\"SELECT class, data FROM %s WHERE identifier = '%s';\" %\n                 (self.table, sid)\n                 )\n        res = self._query(query)\n        try:\n            rdict = res.dictresult()[0]\n        except IndexError:\n            raise ObjectDoesNotExistException('%s/%s' % (self.id, sid))\n\n        data = rdict['data']\n        try:\n            ndata = pg.unescape_bytea(data)\n        except:\n            # Insufficient PyGreSQL version\n            ndata = data.replace(\"\\\\'\", \"'\")\n\n        ndata = ndata.replace('\\\\000', '\\x00')\n        ndata = ndata.replace('\\\\012', '\\n')\n        # data is res.dictresult()\n        cl = rdict['class']\n        rset = dynamic.buildObject(session, cl, [[]])\n        rset.deserialize(session, ndata)\n        rset.id = id\n\n        # Update expires\n        now = time.time()\n        nowStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(now))\n        expires = now + self.get_default(session, 'expires', 600)\n        rset.timeExpires = expires\n        expiresStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(expires))\n\n        query = (\"UPDATE %s SET timeAccessed = '%s', expires = '%s' \"\n                 \"WHERE identifier = '%s';\" %\n                 (self.table, nowStr, expiresStr, sid)\n                 )\n        self._query(query)\n        return rset", "func_src_after": "    def fetch_resultSet(self, session, id):\n        self._openContainer(session)\n\n        sid = str(id)\n        if (self.idNormalizer is not None):\n            sid = self.idNormalizer.process_string(session, sid)\n        query = (\"SELECT class, data FROM %s WHERE identifier = $1;\" %\n                 (self.table)\n                 )\n        res = self._query(query, sid)\n        try:\n            rdict = res.dictresult()[0]\n        except IndexError:\n            raise ObjectDoesNotExistException('%s/%s' % (self.id, sid))\n\n        data = rdict['data']\n        try:\n            ndata = pg.unescape_bytea(data)\n        except:\n            # Insufficient PyGreSQL version\n            ndata = data.replace(\"\\\\'\", \"'\")\n\n        ndata = ndata.replace('\\\\000', '\\x00')\n        ndata = ndata.replace('\\\\012', '\\n')\n        # data is res.dictresult()\n        cl = rdict['class']\n        rset = dynamic.buildObject(session, cl, [[]])\n        rset.deserialize(session, ndata)\n        rset.id = id\n\n        # Update expires\n        now = time.time()\n        nowStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(now))\n        expires = now + self.get_default(session, 'expires', 600)\n        rset.timeExpires = expires\n        expiresStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(expires))\n\n        query = (\"UPDATE %s SET timeAccessed = $1, expires = $2 \"\n                 \"WHERE identifier = $3;\" % (self.table)\n                 )\n        self._query(query, nowStr, expiresStr, sid)\n        return rset", "commit_link": "github.com/cheshire3/cheshire3/commit/d350363b4ea10f102c24c8f26d7b76b006323e8e", "file_name": "cheshire3/sql/resultSetStore.py", "vul_type": "cwe-089", "description": "Write a Python function that retrieves and updates a record from a database using either string formatting or parameterized queries."}
{"func_name": "_get_degree_2", "func_src_before": "def _get_degree_2(user_id, cnx):\n    \"\"\"Get all users of degree 2 follow that are not currently followed.\n    Example:\n        this user (follows) user B (follows) user B\n        AND user (does NOT follow) user B\n        means that user B will be in the list\n    Args:\n        user_id (int): id of user\n        cnx: DB connection\n    Returns:\n        list: list of user_ids\n    \"\"\"\n    sql = 'WITH tmp_suggest (followed_id) AS ' \\\n    '(' \\\n        'SELECT b.followed_id AS followed_id ' \\\n        'FROM ' \\\n            'tbl_follow a INNER JOIN tbl_follow b ' \\\n            'ON a.followed_id = b.follower_id ' \\\n        'WHERE a.follower_id = %s ' \\\n        'AND b.followed_id NOT IN ' \\\n            '(SELECT followed_id FROM tbl_follow WHERE follower_id = %s) ' \\\n        'AND b.followed_id != %s ' \\\n    ') ' \\\n    'SELECT followed_id, COUNT(*) AS num_mutual FROM tmp_suggest ' \\\n    'GROUP BY followed_id ' \\\n    'ORDER BY num_mutual DESC' % (user_id, user_id, user_id)\n    with cnx.cursor() as cursor:\n        cursor.execute(sql)\n        res = cursor.fetchall()\n    return list(map(lambda x: x[0], res))", "func_src_after": "def _get_degree_2(user_id, cnx):\n    \"\"\"Get all users of degree 2 follow that are not currently followed.\n    Example:\n        this user (follows) user B (follows) user B\n        AND user (does NOT follow) user B\n        means that user B will be in the list\n    Args:\n        user_id (int): id of user\n        cnx: DB connection\n    Returns:\n        list: list of user_ids\n    \"\"\"\n    sql = 'WITH tmp_suggest (followed_id) AS ' \\\n    '(' \\\n        'SELECT b.followed_id AS followed_id ' \\\n        'FROM ' \\\n            'tbl_follow a INNER JOIN tbl_follow b ' \\\n            'ON a.followed_id = b.follower_id ' \\\n        'WHERE a.follower_id = %s ' \\\n        'AND b.followed_id NOT IN ' \\\n            '(SELECT followed_id FROM tbl_follow WHERE follower_id = %s) ' \\\n        'AND b.followed_id != %s ' \\\n    ') ' \\\n    'SELECT followed_id, COUNT(*) AS num_mutual FROM tmp_suggest ' \\\n    'GROUP BY followed_id ' \\\n    'ORDER BY num_mutual DESC'\n    with cnx.cursor() as cursor:\n        cursor.execute(sql, (user_id, user_id, user_id))\n        res = cursor.fetchall()\n    return list(map(lambda x: x[0], res))", "commit_link": "github.com/young-goons/rifflo-server/commit/fb311df76713b638c9486250f9badb288ffb2189", "file_name": "server/ygoons/modules/user/follow_suggest.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch second-degree connections not followed by a user from a database."}
{"func_name": "PlayerGeneric::~PlayerGeneric", "func_src_before": "PlayerGeneric::~PlayerGeneric()\n{\n\tif (mixer)\n\t\tdelete mixer;\n\n\tif (player)\n\t{\n\t\tif (mixer->isActive() && !mixer->isDeviceRemoved(player))\n\t\t\tmixer->removeDevice(player);\n\t\tdelete player;\n\t}\n\n\tdelete[] audioDriverName;\n\t\n\tdelete listener;\n}", "func_src_after": "PlayerGeneric::~PlayerGeneric()\n{\n\n\tif (player)\n\t{\n\t\tif (mixer && mixer->isActive() && !mixer->isDeviceRemoved(player))\n\t\t\tmixer->removeDevice(player);\n\t\tdelete player;\n\t}\n\t\n\tif (mixer)\n\t\tdelete mixer;\n\n\tdelete[] audioDriverName;\n\t\n\tdelete listener;\n}", "commit_link": "github.com/milkytracker/MilkyTracker/commit/7afd55c42ad80d01a339197a2d8b5461d214edaf", "file_name": "src/milkyplay/PlayerGeneric.cpp", "vul_type": "cwe-416", "description": "Write a C++ destructor for a class named `PlayerGeneric` that cleans up memory by deleting member pointers, ensuring that a `mixer` object is properly deactivated and devices are removed before deletion."}
{"func_name": "__mdiobus_register", "func_src_before": "int __mdiobus_register(struct mii_bus *bus, struct module *owner)\n{\n\tstruct mdio_device *mdiodev;\n\tint i, err;\n\tstruct gpio_desc *gpiod;\n\n\tif (NULL == bus || NULL == bus->name ||\n\t    NULL == bus->read || NULL == bus->write)\n\t\treturn -EINVAL;\n\n\tBUG_ON(bus->state != MDIOBUS_ALLOCATED &&\n\t       bus->state != MDIOBUS_UNREGISTERED);\n\n\tbus->owner = owner;\n\tbus->dev.parent = bus->parent;\n\tbus->dev.class = &mdio_bus_class;\n\tbus->dev.groups = NULL;\n\tdev_set_name(&bus->dev, \"%s\", bus->id);\n\n\terr = device_register(&bus->dev);\n\tif (err) {\n\t\tpr_err(\"mii_bus %s failed to register\\n\", bus->id);\n\t\tput_device(&bus->dev);\n\t\treturn -EINVAL;\n\t}\n\n\tmutex_init(&bus->mdio_lock);\n\n\t/* de-assert bus level PHY GPIO reset */\n\tgpiod = devm_gpiod_get_optional(&bus->dev, \"reset\", GPIOD_OUT_LOW);\n\tif (IS_ERR(gpiod)) {\n\t\tdev_err(&bus->dev, \"mii_bus %s couldn't get reset GPIO\\n\",\n\t\t\tbus->id);\n\t\tdevice_del(&bus->dev);\n\t\treturn PTR_ERR(gpiod);\n\t} else\tif (gpiod) {\n\t\tbus->reset_gpiod = gpiod;\n\n\t\tgpiod_set_value_cansleep(gpiod, 1);\n\t\tudelay(bus->reset_delay_us);\n\t\tgpiod_set_value_cansleep(gpiod, 0);\n\t}\n\n\tif (bus->reset)\n\t\tbus->reset(bus);\n\n\tfor (i = 0; i < PHY_MAX_ADDR; i++) {\n\t\tif ((bus->phy_mask & (1 << i)) == 0) {\n\t\t\tstruct phy_device *phydev;\n\n\t\t\tphydev = mdiobus_scan(bus, i);\n\t\t\tif (IS_ERR(phydev) && (PTR_ERR(phydev) != -ENODEV)) {\n\t\t\t\terr = PTR_ERR(phydev);\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t}\n\t}\n\n\tmdiobus_setup_mdiodev_from_board_info(bus, mdiobus_create_device);\n\n\tbus->state = MDIOBUS_REGISTERED;\n\tpr_info(\"%s: probed\\n\", bus->name);\n\treturn 0;\n\nerror:\n\twhile (--i >= 0) {\n\t\tmdiodev = bus->mdio_map[i];\n\t\tif (!mdiodev)\n\t\t\tcontinue;\n\n\t\tmdiodev->device_remove(mdiodev);\n\t\tmdiodev->device_free(mdiodev);\n\t}\n\n\t/* Put PHYs in RESET to save power */\n\tif (bus->reset_gpiod)\n\t\tgpiod_set_value_cansleep(bus->reset_gpiod, 1);\n\n\tdevice_del(&bus->dev);\n\treturn err;\n}", "func_src_after": "int __mdiobus_register(struct mii_bus *bus, struct module *owner)\n{\n\tstruct mdio_device *mdiodev;\n\tint i, err;\n\tstruct gpio_desc *gpiod;\n\n\tif (NULL == bus || NULL == bus->name ||\n\t    NULL == bus->read || NULL == bus->write)\n\t\treturn -EINVAL;\n\n\tBUG_ON(bus->state != MDIOBUS_ALLOCATED &&\n\t       bus->state != MDIOBUS_UNREGISTERED);\n\n\tbus->owner = owner;\n\tbus->dev.parent = bus->parent;\n\tbus->dev.class = &mdio_bus_class;\n\tbus->dev.groups = NULL;\n\tdev_set_name(&bus->dev, \"%s\", bus->id);\n\n\terr = device_register(&bus->dev);\n\tif (err) {\n\t\tpr_err(\"mii_bus %s failed to register\\n\", bus->id);\n\t\treturn -EINVAL;\n\t}\n\n\tmutex_init(&bus->mdio_lock);\n\n\t/* de-assert bus level PHY GPIO reset */\n\tgpiod = devm_gpiod_get_optional(&bus->dev, \"reset\", GPIOD_OUT_LOW);\n\tif (IS_ERR(gpiod)) {\n\t\tdev_err(&bus->dev, \"mii_bus %s couldn't get reset GPIO\\n\",\n\t\t\tbus->id);\n\t\tdevice_del(&bus->dev);\n\t\treturn PTR_ERR(gpiod);\n\t} else\tif (gpiod) {\n\t\tbus->reset_gpiod = gpiod;\n\n\t\tgpiod_set_value_cansleep(gpiod, 1);\n\t\tudelay(bus->reset_delay_us);\n\t\tgpiod_set_value_cansleep(gpiod, 0);\n\t}\n\n\tif (bus->reset)\n\t\tbus->reset(bus);\n\n\tfor (i = 0; i < PHY_MAX_ADDR; i++) {\n\t\tif ((bus->phy_mask & (1 << i)) == 0) {\n\t\t\tstruct phy_device *phydev;\n\n\t\t\tphydev = mdiobus_scan(bus, i);\n\t\t\tif (IS_ERR(phydev) && (PTR_ERR(phydev) != -ENODEV)) {\n\t\t\t\terr = PTR_ERR(phydev);\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t}\n\t}\n\n\tmdiobus_setup_mdiodev_from_board_info(bus, mdiobus_create_device);\n\n\tbus->state = MDIOBUS_REGISTERED;\n\tpr_info(\"%s: probed\\n\", bus->name);\n\treturn 0;\n\nerror:\n\twhile (--i >= 0) {\n\t\tmdiodev = bus->mdio_map[i];\n\t\tif (!mdiodev)\n\t\t\tcontinue;\n\n\t\tmdiodev->device_remove(mdiodev);\n\t\tmdiodev->device_free(mdiodev);\n\t}\n\n\t/* Put PHYs in RESET to save power */\n\tif (bus->reset_gpiod)\n\t\tgpiod_set_value_cansleep(bus->reset_gpiod, 1);\n\n\tdevice_del(&bus->dev);\n\treturn err;\n}", "commit_link": "github.com/torvalds/linux/commit/6ff7b060535e87c2ae14dd8548512abfdda528fb", "file_name": "drivers/net/phy/mdio_bus.c", "vul_type": "cwe-416", "description": "In C, write a function to register an MDIO bus with error handling and PHY device scanning."}
{"func_name": "vault_encrypt", "func_src_before": "def vault_encrypt(v_plaintexts, mp):\n    iv = '01234567'\n    vault_code = vault_encode(v_plaintexts, mp)\n    des3 = DES3.new(hash_mp(mp), DES3.MODE_CFB, iv)\n    # plaintext= staruct.pack(\"%sI\" % len(vault_code), *vault_code)\n    c = des3.encrypt(vault_code)\n    return c", "func_src_after": "def vault_encrypt(v_plaintexts, mp):\n    aes = do_crypto_setup(mp)\n    return aes.encrypt(vault_encode(v_plaintexts, mp))", "line_changes": {"deleted": [{"line_no": 2, "char_start": 37, "char_end": 57, "line": "    iv = '01234567'\n"}, {"line_no": 3, "char_start": 57, "char_end": 105, "line": "    vault_code = vault_encode(v_plaintexts, mp)\n"}, {"line_no": 4, "char_start": 105, "char_end": 157, "line": "    des3 = DES3.new(hash_mp(mp), DES3.MODE_CFB, iv)\n"}, {"line_no": 6, "char_start": 225, "char_end": 258, "line": "    c = des3.encrypt(vault_code)\n"}, {"line_no": 7, "char_start": 258, "char_end": 270, "line": "    return c\n"}], "added": [{"line_no": 2, "char_start": 37, "char_end": 67, "line": "    aes = do_crypto_setup(mp)\n"}, {"line_no": 3, "char_start": 67, "char_end": 121, "line": "    return aes.encrypt(vault_encode(v_plaintexts, mp))\n"}]}, "char_changes": {"deleted": [{"char_start": 41, "char_end": 234, "chars": "iv = '01234567'\n    vault_code = vault_encode(v_plaintexts, mp)\n    des3 = DES3.new(hash_mp(mp), DES3.MODE_CFB, iv)\n    # plaintext= staruct.pack(\"%sI\" % len(vault_code), *vault_code)\n    c = d"}, {"char_start": 236, "char_end": 237, "chars": "3"}, {"char_start": 256, "char_end": 270, "chars": ")\n    return c"}], "added": [{"char_start": 41, "char_end": 79, "chars": "aes = do_crypto_setup(mp)\n    return a"}, {"char_start": 96, "char_end": 98, "chars": "en"}, {"char_start": 102, "char_end": 121, "chars": "(v_plaintexts, mp))"}]}, "commit_link": "github.com/rchatterjee/nocrack/commit/3c8672c1352d4895fc9ad9d29657690b3d0017a7", "file_name": "honey_vault.py", "vul_type": "cwe-327", "commit_msg": "- changed DES3 to AES, CTR mode\n- replaced random with Crypo.Random.random ~~ cryptographically more secure!", "description": "Write a Python function named `vault_encrypt` that takes a list of plaintexts and a master password, then returns an encrypted version of the processed plaintexts."}
{"func_name": "(anonymous)", "func_src_before": "    db.get(\"SELECT id,note FROM notes WHERE id = '\"+data.id+\"'\",function(err,row){\n      if(row){\n        socket.emit('setNote', { note: row.note });\n      } else {\n        socket.emit('setNote', { note: \"\" });\n      }\n    //res.send(row.note);\n    });", "func_src_after": "    db.get(\"SELECT id,note FROM notes WHERE id = ?\",[data.id],function(err,row){\n      if(row){\n        socket.emit('setNote', { note: row.note});\n      } else {\n        socket.emit('setNote', { note: \"\" });\n      }\n    //res.send(row.note);\n    });", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 83, "line": "    db.get(\"SELECT id,note FROM notes WHERE id = '\"+data.id+\"'\",function(err,row){\n"}, {"line_no": 3, "char_start": 98, "char_end": 150, "line": "        socket.emit('setNote', { note: row.note });\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 81, "line": "    db.get(\"SELECT id,note FROM notes WHERE id = ?\",[data.id],function(err,row){\n"}, {"line_no": 3, "char_start": 96, "char_end": 147, "line": "        socket.emit('setNote', { note: row.note});\n"}]}, "char_changes": {"deleted": [{"char_start": 49, "char_end": 52, "chars": "'\"+"}, {"char_start": 59, "char_end": 63, "chars": "+\"'\""}, {"char_start": 145, "char_end": 146, "chars": " "}], "added": [{"char_start": 49, "char_end": 53, "chars": "?\",["}, {"char_start": 60, "char_end": 61, "chars": "]"}]}, "commit_link": "github.com/yoyodyne/litwritesabook/commit/6ed77576195866819411628e917cd157e2a61361", "file_name": "app.js", "vul_type": "cwe-089", "commit_msg": "SQL injection prevented.", "description": "Write a JavaScript function that retrieves a note from a database using an ID and sends it through a socket."}
{"func_name": "self.lookup", "func_src_before": "  def self.lookup(lat, lng)\n    all(:conditions => \"ST_Contains(the_geom, GeometryFromText('POINT(#{lng} #{lat})', -1))\")\n  end", "func_src_after": "  def self.lookup(lat, lng)\n    all(:conditions => [\"ST_Contains(the_geom, GeometryFromText('POINT(? ?)', -1))\",lng.to_f,lat.to_f])\n  end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 28, "char_end": 122, "line": "    all(:conditions => \"ST_Contains(the_geom, GeometryFromText('POINT(#{lng} #{lat})', -1))\")\n"}], "added": [{"line_no": 2, "char_start": 28, "char_end": 132, "line": "    all(:conditions => [\"ST_Contains(the_geom, GeometryFromText('POINT(? ?)', -1))\",lng.to_f,lat.to_f])\n"}]}, "char_changes": {"deleted": [{"char_start": 98, "char_end": 120, "chars": "#{lng} #{lat})', -1))\""}], "added": [{"char_start": 51, "char_end": 52, "chars": "["}, {"char_start": 99, "char_end": 130, "chars": "? ?)', -1))\",lng.to_f,lat.to_f]"}]}, "commit_link": "github.com/mcommons/legislative-lookup/commit/7e297286558e6adf1ceee9dcbbfbcd1d12a6f335", "file_name": "district.rb", "vul_type": "cwe-089", "commit_msg": "BUGFIX sql injection.", "description": "Write a Ruby method to find all records in a database that contain a given latitude and longitude point."}
{"func_name": "customization_disabled?", "func_src_before": "  def customization_disabled?\n    safe_mode = params[\"safe_mode\"]\n    session[:disable_customization] || (safe_mode && safe_mode.include?(\"no_custom\"))\n  end", "func_src_after": "  def customization_disabled?\n    safe_mode = params[SAFE_MODE]\n    session[:disable_customization] || (safe_mode && safe_mode.include?(NO_CUSTOM))\n  end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 30, "char_end": 66, "line": "    safe_mode = params[\"safe_mode\"]\n"}, {"line_no": 3, "char_start": 66, "char_end": 152, "line": "    session[:disable_customization] || (safe_mode && safe_mode.include?(\"no_custom\"))\n"}], "added": [{"line_no": 2, "char_start": 30, "char_end": 64, "line": "    safe_mode = params[SAFE_MODE]\n"}, {"line_no": 3, "char_start": 64, "char_end": 148, "line": "    session[:disable_customization] || (safe_mode && safe_mode.include?(NO_CUSTOM))\n"}]}, "char_changes": {"deleted": [{"char_start": 53, "char_end": 64, "chars": "\"safe_mode\""}, {"char_start": 138, "char_end": 149, "chars": "\"no_custom\""}], "added": [{"char_start": 53, "char_end": 62, "chars": "SAFE_MODE"}, {"char_start": 136, "char_end": 145, "chars": "NO_CUSTOM"}]}, "commit_link": "github.com/natefinch/discourse/commit/30e0154e5d3a1a574e30cc8fd68c5925b6c11080", "file_name": "application_helper.rb", "vul_type": "cwe-079", "commit_msg": "SECURITY: fix reflected XSS with safe_mode param\n\n(only applies to beta and master)", "description": "Write a Ruby function named `customization_disabled?` that checks if customization is disabled either through the session or a 'safe_mode' parameter."}
{"func_name": "_create_vdisk", "func_src_before": "    def _create_vdisk(self, name, size, units, opts):\n        \"\"\"Create a new vdisk.\"\"\"\n\n        LOG.debug(_('enter: _create_vdisk: vdisk %s ') % name)\n\n        model_update = None\n        autoex = '-autoexpand' if opts['autoexpand'] else ''\n        easytier = '-easytier on' if opts['easytier'] else '-easytier off'\n\n        # Set space-efficient options\n        if opts['rsize'] == -1:\n            ssh_cmd_se_opt = ''\n        else:\n            ssh_cmd_se_opt = (\n                '-rsize %(rsize)d%% %(autoex)s -warning %(warn)d%%' %\n                {'rsize': opts['rsize'],\n                 'autoex': autoex,\n                 'warn': opts['warning']})\n            if opts['compression']:\n                ssh_cmd_se_opt = ssh_cmd_se_opt + ' -compressed'\n            else:\n                ssh_cmd_se_opt = ssh_cmd_se_opt + (\n                    ' -grainsize %d' % opts['grainsize'])\n\n        ssh_cmd = ('svctask mkvdisk -name %(name)s -mdiskgrp %(mdiskgrp)s '\n                   '-iogrp 0 -size %(size)s -unit '\n                   '%(unit)s %(easytier)s %(ssh_cmd_se_opt)s'\n                   % {'name': name,\n                   'mdiskgrp': self.configuration.storwize_svc_volpool_name,\n                   'size': size, 'unit': units, 'easytier': easytier,\n                   'ssh_cmd_se_opt': ssh_cmd_se_opt})\n        out, err = self._run_ssh(ssh_cmd)\n        self._assert_ssh_return(len(out.strip()), '_create_vdisk',\n                                ssh_cmd, out, err)\n\n        # Ensure that the output is as expected\n        match_obj = re.search('Virtual Disk, id \\[([0-9]+)\\], '\n                              'successfully created', out)\n        # Make sure we got a \"successfully created\" message with vdisk id\n        self._driver_assert(\n            match_obj is not None,\n            _('_create_vdisk %(name)s - did not find '\n              'success message in CLI output.\\n '\n              'stdout: %(out)s\\n stderr: %(err)s')\n            % {'name': name, 'out': str(out), 'err': str(err)})\n\n        LOG.debug(_('leave: _create_vdisk: volume %s ') % name)", "func_src_after": "    def _create_vdisk(self, name, size, units, opts):\n        \"\"\"Create a new vdisk.\"\"\"\n\n        LOG.debug(_('enter: _create_vdisk: vdisk %s ') % name)\n\n        model_update = None\n        easytier = 'on' if opts['easytier'] else 'off'\n\n        # Set space-efficient options\n        if opts['rsize'] == -1:\n            ssh_cmd_se_opt = []\n        else:\n            ssh_cmd_se_opt = ['-rsize', '%s%%' % str(opts['rsize']),\n                              '-autoexpand', '-warning',\n                              '%s%%' % str(opts['warning'])]\n            if not opts['autoexpand']:\n                ssh_cmd_se_opt.remove('-autoexpand')\n\n            if opts['compression']:\n                ssh_cmd_se_opt.append('-compressed')\n            else:\n                ssh_cmd_se_opt.extend(['-grainsize', str(opts['grainsize'])])\n\n        ssh_cmd = ['svctask', 'mkvdisk', '-name', name, '-mdiskgrp',\n                   self.configuration.storwize_svc_volpool_name,\n                   '-iogrp', '0', '-size', size, '-unit',\n                   units, '-easytier', easytier] + ssh_cmd_se_opt\n        out, err = self._run_ssh(ssh_cmd)\n        self._assert_ssh_return(len(out.strip()), '_create_vdisk',\n                                ssh_cmd, out, err)\n\n        # Ensure that the output is as expected\n        match_obj = re.search('Virtual Disk, id \\[([0-9]+)\\], '\n                              'successfully created', out)\n        # Make sure we got a \"successfully created\" message with vdisk id\n        self._driver_assert(\n            match_obj is not None,\n            _('_create_vdisk %(name)s - did not find '\n              'success message in CLI output.\\n '\n              'stdout: %(out)s\\n stderr: %(err)s')\n            % {'name': name, 'out': str(out), 'err': str(err)})\n\n        LOG.debug(_('leave: _create_vdisk: volume %s ') % name)", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to create a virtual disk with options for size, auto-expansion, easy tier, and compression."}
{"func_name": "(anonymous)", "func_src_before": "        .then(()=>rimraf(tempDir));", "func_src_after": "        .then(() => tileRec(inPath, outPath, zoom, tileSize, tempDir, pattern, zoomToDisplay, options.invertZoom, quality))", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 35, "line": "        .then(()=>rimraf(tempDir));\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 123, "line": "        .then(() => tileRec(inPath, outPath, zoom, tileSize, tempDir, pattern, zoomToDisplay, options.invertZoom, quality))\n"}]}, "char_changes": {"deleted": [{"char_start": 18, "char_end": 32, "chars": "rimraf(tempDir"}, {"char_start": 34, "char_end": 35, "chars": ";"}], "added": [{"char_start": 16, "char_end": 17, "chars": " "}, {"char_start": 19, "char_end": 121, "chars": " tileRec(inPath, outPath, zoom, tileSize, tempDir, pattern, zoomToDisplay, options.invertZoom, quality"}]}, "commit_link": "github.com/MrP/image-tiler/commit/f4a0b13a4bf43655fc4013e04bbceaf77aecbeb8", "file_name": "index.js", "vul_type": "cwe-078", "commit_msg": "fix command injection vuln", "description": "Write a JavaScript promise chain that includes a `.then()` method executing a callback function that performs an operation on a directory or manipulates image tiles."}
{"func_name": "test_creates_yaml_config_file_and_path_to_it_from_example_config", "func_src_before": "  def test_creates_yaml_config_file_and_path_to_it_from_example_config\n    refute File.exist?(CONFIG_PATH)\n    refute_nil ActsAsTextcaptcha::TextcaptchaConfig.create(path: CONFIG_PATH)\n    assert File.exist?(CONFIG_PATH)\n\n    # rubocop:disable Security/YAMLLoad\n    example_config = YAML.load(File.read(CONFIG_PATH))\n    # rubocop:enable Security/YAMLLoad\n    assert_equal example_config.keys, %w(development test production)\n  end", "func_src_after": "  def test_creates_yaml_config_file_and_path_to_it_from_example_config\n    refute File.exist?(CONFIG_PATH)\n    refute_nil ActsAsTextcaptcha::TextcaptchaConfig.create(path: CONFIG_PATH)\n    assert File.exist?(CONFIG_PATH)\n\n    # rubocop:disable Security/YAMLLoad\n    example_config = YAML.safe_load(File.read(CONFIG_PATH), aliases: true)\n    # rubocop:enable Security/YAMLLoad\n    assert_equal example_config.keys, %w(development test production)\n  end", "line_changes": {"deleted": [{"line_no": 7, "char_start": 262, "char_end": 317, "line": "    example_config = YAML.load(File.read(CONFIG_PATH))\n"}], "added": [{"line_no": 7, "char_start": 262, "char_end": 337, "line": "    example_config = YAML.safe_load(File.read(CONFIG_PATH), aliases: true)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 288, "char_end": 293, "chars": "safe_"}, {"char_start": 320, "char_end": 335, "chars": ", aliases: true"}]}, "commit_link": "github.com/matthutchinson/acts_as_textcaptcha/commit/09b2c281859c07e8cc966e604153ba97bc3c6ec2", "file_name": "textcaptcha_config_test.rb", "vul_type": "cwe-502", "commit_msg": "update tests to use YAML.safe_load", "parent_commit": "f9b9d1623306bb621cd1c14574a4a07513368ce7", "description": "Write a Ruby test method that checks the creation of a YAML configuration file and verifies its contents."}
{"func_name": "rds_cmsg_atomic", "func_src_before": "int rds_cmsg_atomic(struct rds_sock *rs, struct rds_message *rm,\n\t\t    struct cmsghdr *cmsg)\n{\n\tstruct page *page = NULL;\n\tstruct rds_atomic_args *args;\n\tint ret = 0;\n\n\tif (cmsg->cmsg_len < CMSG_LEN(sizeof(struct rds_atomic_args))\n\t || rm->atomic.op_active)\n\t\treturn -EINVAL;\n\n\targs = CMSG_DATA(cmsg);\n\n\t/* Nonmasked & masked cmsg ops converted to masked hw ops */\n\tswitch (cmsg->cmsg_type) {\n\tcase RDS_CMSG_ATOMIC_FADD:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_FADD;\n\t\trm->atomic.op_m_fadd.add = args->fadd.add;\n\t\trm->atomic.op_m_fadd.nocarry_mask = 0;\n\t\tbreak;\n\tcase RDS_CMSG_MASKED_ATOMIC_FADD:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_FADD;\n\t\trm->atomic.op_m_fadd.add = args->m_fadd.add;\n\t\trm->atomic.op_m_fadd.nocarry_mask = args->m_fadd.nocarry_mask;\n\t\tbreak;\n\tcase RDS_CMSG_ATOMIC_CSWP:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_CSWP;\n\t\trm->atomic.op_m_cswp.compare = args->cswp.compare;\n\t\trm->atomic.op_m_cswp.swap = args->cswp.swap;\n\t\trm->atomic.op_m_cswp.compare_mask = ~0;\n\t\trm->atomic.op_m_cswp.swap_mask = ~0;\n\t\tbreak;\n\tcase RDS_CMSG_MASKED_ATOMIC_CSWP:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_CSWP;\n\t\trm->atomic.op_m_cswp.compare = args->m_cswp.compare;\n\t\trm->atomic.op_m_cswp.swap = args->m_cswp.swap;\n\t\trm->atomic.op_m_cswp.compare_mask = args->m_cswp.compare_mask;\n\t\trm->atomic.op_m_cswp.swap_mask = args->m_cswp.swap_mask;\n\t\tbreak;\n\tdefault:\n\t\tBUG(); /* should never happen */\n\t}\n\n\trm->atomic.op_notify = !!(args->flags & RDS_RDMA_NOTIFY_ME);\n\trm->atomic.op_silent = !!(args->flags & RDS_RDMA_SILENT);\n\trm->atomic.op_active = 1;\n\trm->atomic.op_recverr = rs->rs_recverr;\n\trm->atomic.op_sg = rds_message_alloc_sgs(rm, 1);\n\tif (!rm->atomic.op_sg) {\n\t\tret = -ENOMEM;\n\t\tgoto err;\n\t}\n\n\t/* verify 8 byte-aligned */\n\tif (args->local_addr & 0x7) {\n\t\tret = -EFAULT;\n\t\tgoto err;\n\t}\n\n\tret = rds_pin_pages(args->local_addr, 1, &page, 1);\n\tif (ret != 1)\n\t\tgoto err;\n\tret = 0;\n\n\tsg_set_page(rm->atomic.op_sg, page, 8, offset_in_page(args->local_addr));\n\n\tif (rm->atomic.op_notify || rm->atomic.op_recverr) {\n\t\t/* We allocate an uninitialized notifier here, because\n\t\t * we don't want to do that in the completion handler. We\n\t\t * would have to use GFP_ATOMIC there, and don't want to deal\n\t\t * with failed allocations.\n\t\t */\n\t\trm->atomic.op_notifier = kmalloc(sizeof(*rm->atomic.op_notifier), GFP_KERNEL);\n\t\tif (!rm->atomic.op_notifier) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err;\n\t\t}\n\n\t\trm->atomic.op_notifier->n_user_token = args->user_token;\n\t\trm->atomic.op_notifier->n_status = RDS_RDMA_SUCCESS;\n\t}\n\n\trm->atomic.op_rkey = rds_rdma_cookie_key(args->cookie);\n\trm->atomic.op_remote_addr = args->remote_addr + rds_rdma_cookie_offset(args->cookie);\n\n\treturn ret;\nerr:\n\tif (page)\n\t\tput_page(page);\n\tkfree(rm->atomic.op_notifier);\n\n\treturn ret;\n}", "func_src_after": "int rds_cmsg_atomic(struct rds_sock *rs, struct rds_message *rm,\n\t\t    struct cmsghdr *cmsg)\n{\n\tstruct page *page = NULL;\n\tstruct rds_atomic_args *args;\n\tint ret = 0;\n\n\tif (cmsg->cmsg_len < CMSG_LEN(sizeof(struct rds_atomic_args))\n\t || rm->atomic.op_active)\n\t\treturn -EINVAL;\n\n\targs = CMSG_DATA(cmsg);\n\n\t/* Nonmasked & masked cmsg ops converted to masked hw ops */\n\tswitch (cmsg->cmsg_type) {\n\tcase RDS_CMSG_ATOMIC_FADD:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_FADD;\n\t\trm->atomic.op_m_fadd.add = args->fadd.add;\n\t\trm->atomic.op_m_fadd.nocarry_mask = 0;\n\t\tbreak;\n\tcase RDS_CMSG_MASKED_ATOMIC_FADD:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_FADD;\n\t\trm->atomic.op_m_fadd.add = args->m_fadd.add;\n\t\trm->atomic.op_m_fadd.nocarry_mask = args->m_fadd.nocarry_mask;\n\t\tbreak;\n\tcase RDS_CMSG_ATOMIC_CSWP:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_CSWP;\n\t\trm->atomic.op_m_cswp.compare = args->cswp.compare;\n\t\trm->atomic.op_m_cswp.swap = args->cswp.swap;\n\t\trm->atomic.op_m_cswp.compare_mask = ~0;\n\t\trm->atomic.op_m_cswp.swap_mask = ~0;\n\t\tbreak;\n\tcase RDS_CMSG_MASKED_ATOMIC_CSWP:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_CSWP;\n\t\trm->atomic.op_m_cswp.compare = args->m_cswp.compare;\n\t\trm->atomic.op_m_cswp.swap = args->m_cswp.swap;\n\t\trm->atomic.op_m_cswp.compare_mask = args->m_cswp.compare_mask;\n\t\trm->atomic.op_m_cswp.swap_mask = args->m_cswp.swap_mask;\n\t\tbreak;\n\tdefault:\n\t\tBUG(); /* should never happen */\n\t}\n\n\trm->atomic.op_notify = !!(args->flags & RDS_RDMA_NOTIFY_ME);\n\trm->atomic.op_silent = !!(args->flags & RDS_RDMA_SILENT);\n\trm->atomic.op_active = 1;\n\trm->atomic.op_recverr = rs->rs_recverr;\n\trm->atomic.op_sg = rds_message_alloc_sgs(rm, 1);\n\tif (!rm->atomic.op_sg) {\n\t\tret = -ENOMEM;\n\t\tgoto err;\n\t}\n\n\t/* verify 8 byte-aligned */\n\tif (args->local_addr & 0x7) {\n\t\tret = -EFAULT;\n\t\tgoto err;\n\t}\n\n\tret = rds_pin_pages(args->local_addr, 1, &page, 1);\n\tif (ret != 1)\n\t\tgoto err;\n\tret = 0;\n\n\tsg_set_page(rm->atomic.op_sg, page, 8, offset_in_page(args->local_addr));\n\n\tif (rm->atomic.op_notify || rm->atomic.op_recverr) {\n\t\t/* We allocate an uninitialized notifier here, because\n\t\t * we don't want to do that in the completion handler. We\n\t\t * would have to use GFP_ATOMIC there, and don't want to deal\n\t\t * with failed allocations.\n\t\t */\n\t\trm->atomic.op_notifier = kmalloc(sizeof(*rm->atomic.op_notifier), GFP_KERNEL);\n\t\tif (!rm->atomic.op_notifier) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err;\n\t\t}\n\n\t\trm->atomic.op_notifier->n_user_token = args->user_token;\n\t\trm->atomic.op_notifier->n_status = RDS_RDMA_SUCCESS;\n\t}\n\n\trm->atomic.op_rkey = rds_rdma_cookie_key(args->cookie);\n\trm->atomic.op_remote_addr = args->remote_addr + rds_rdma_cookie_offset(args->cookie);\n\n\treturn ret;\nerr:\n\tif (page)\n\t\tput_page(page);\n\trm->atomic.op_active = 0;\n\tkfree(rm->atomic.op_notifier);\n\n\treturn ret;\n}", "commit_link": "github.com/torvalds/linux/commit/7d11f77f84b27cef452cee332f4e469503084737", "file_name": "net/rds/rdma.c", "vul_type": "cwe-476", "description": "Write a C function named `rds_cmsg_atomic` that processes atomic operations in RDS messages."}
