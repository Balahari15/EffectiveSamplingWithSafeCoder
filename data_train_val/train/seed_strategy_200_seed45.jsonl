{"func_name": "stralgoLCS", "func_src_before": "void stralgoLCS(client *c) {\n    uint32_t i, j;\n    long long minmatchlen = 0;\n    sds a = NULL, b = NULL;\n    int getlen = 0, getidx = 0, withmatchlen = 0;\n    robj *obja = NULL, *objb = NULL;\n\n    for (j = 2; j < (uint32_t)c->argc; j++) {\n        char *opt = c->argv[j]->ptr;\n        int moreargs = (c->argc-1) - j;\n\n        if (!strcasecmp(opt,\"IDX\")) {\n            getidx = 1;\n        } else if (!strcasecmp(opt,\"LEN\")) {\n            getlen = 1;\n        } else if (!strcasecmp(opt,\"WITHMATCHLEN\")) {\n            withmatchlen = 1;\n        } else if (!strcasecmp(opt,\"MINMATCHLEN\") && moreargs) {\n            if (getLongLongFromObjectOrReply(c,c->argv[j+1],&minmatchlen,NULL)\n                != C_OK) goto cleanup;\n            if (minmatchlen < 0) minmatchlen = 0;\n            j++;\n        } else if (!strcasecmp(opt,\"STRINGS\") && moreargs > 1) {\n            if (a != NULL) {\n                addReplyError(c,\"Either use STRINGS or KEYS\");\n                goto cleanup;\n            }\n            a = c->argv[j+1]->ptr;\n            b = c->argv[j+2]->ptr;\n            j += 2;\n        } else if (!strcasecmp(opt,\"KEYS\") && moreargs > 1) {\n            if (a != NULL) {\n                addReplyError(c,\"Either use STRINGS or KEYS\");\n                goto cleanup;\n            }\n            obja = lookupKeyRead(c->db,c->argv[j+1]);\n            objb = lookupKeyRead(c->db,c->argv[j+2]);\n            if ((obja && obja->type != OBJ_STRING) ||\n                (objb && objb->type != OBJ_STRING))\n            {\n                addReplyError(c,\n                    \"The specified keys must contain string values\");\n                /* Don't cleanup the objects, we need to do that\n                 * only after calling getDecodedObject(). */\n                obja = NULL;\n                objb = NULL;\n                goto cleanup;\n            }\n            obja = obja ? getDecodedObject(obja) : createStringObject(\"\",0);\n            objb = objb ? getDecodedObject(objb) : createStringObject(\"\",0);\n            a = obja->ptr;\n            b = objb->ptr;\n            j += 2;\n        } else {\n            addReplyErrorObject(c,shared.syntaxerr);\n            goto cleanup;\n        }\n    }\n\n    /* Complain if the user passed ambiguous parameters. */\n    if (a == NULL) {\n        addReplyError(c,\"Please specify two strings: \"\n                        \"STRINGS or KEYS options are mandatory\");\n        goto cleanup;\n    } else if (getlen && getidx) {\n        addReplyError(c,\n            \"If you want both the length and indexes, please \"\n            \"just use IDX.\");\n        goto cleanup;\n    }\n\n    /* Compute the LCS using the vanilla dynamic programming technique of\n     * building a table of LCS(x,y) substrings. */\n    uint32_t alen = sdslen(a);\n    uint32_t blen = sdslen(b);\n\n    /* Setup an uint32_t array to store at LCS[i,j] the length of the\n     * LCS A0..i-1, B0..j-1. Note that we have a linear array here, so\n     * we index it as LCS[j+(blen+1)*j] */\n    uint32_t *lcs = zmalloc((alen+1)*(blen+1)*sizeof(uint32_t));\n    #define LCS(A,B) lcs[(B)+((A)*(blen+1))]\n\n    /* Start building the LCS table. */\n    for (uint32_t i = 0; i <= alen; i++) {\n        for (uint32_t j = 0; j <= blen; j++) {\n            if (i == 0 || j == 0) {\n                /* If one substring has length of zero, the\n                 * LCS length is zero. */\n                LCS(i,j) = 0;\n            } else if (a[i-1] == b[j-1]) {\n                /* The len LCS (and the LCS itself) of two\n                 * sequences with the same final character, is the\n                 * LCS of the two sequences without the last char\n                 * plus that last char. */\n                LCS(i,j) = LCS(i-1,j-1)+1;\n            } else {\n                /* If the last character is different, take the longest\n                 * between the LCS of the first string and the second\n                 * minus the last char, and the reverse. */\n                uint32_t lcs1 = LCS(i-1,j);\n                uint32_t lcs2 = LCS(i,j-1);\n                LCS(i,j) = lcs1 > lcs2 ? lcs1 : lcs2;\n            }\n        }\n    }\n\n    /* Store the actual LCS string in \"result\" if needed. We create\n     * it backward, but the length is already known, we store it into idx. */\n    uint32_t idx = LCS(alen,blen);\n    sds result = NULL;        /* Resulting LCS string. */\n    void *arraylenptr = NULL; /* Deferred length of the array for IDX. */\n    uint32_t arange_start = alen, /* alen signals that values are not set. */\n             arange_end = 0,\n             brange_start = 0,\n             brange_end = 0;\n\n    /* Do we need to compute the actual LCS string? Allocate it in that case. */\n    int computelcs = getidx || !getlen;\n    if (computelcs) result = sdsnewlen(SDS_NOINIT,idx);\n\n    /* Start with a deferred array if we have to emit the ranges. */\n    uint32_t arraylen = 0;  /* Number of ranges emitted in the array. */\n    if (getidx) {\n        addReplyMapLen(c,2);\n        addReplyBulkCString(c,\"matches\");\n        arraylenptr = addReplyDeferredLen(c);\n    }\n\n    i = alen, j = blen;\n    while (computelcs && i > 0 && j > 0) {\n        int emit_range = 0;\n        if (a[i-1] == b[j-1]) {\n            /* If there is a match, store the character and reduce\n             * the indexes to look for a new match. */\n            result[idx-1] = a[i-1];\n\n            /* Track the current range. */\n            if (arange_start == alen) {\n                arange_start = i-1;\n                arange_end = i-1;\n                brange_start = j-1;\n                brange_end = j-1;\n            } else {\n                /* Let's see if we can extend the range backward since\n                 * it is contiguous. */\n                if (arange_start == i && brange_start == j) {\n                    arange_start--;\n                    brange_start--;\n                } else {\n                    emit_range = 1;\n                }\n            }\n            /* Emit the range if we matched with the first byte of\n             * one of the two strings. We'll exit the loop ASAP. */\n            if (arange_start == 0 || brange_start == 0) emit_range = 1;\n            idx--; i--; j--;\n        } else {\n            /* Otherwise reduce i and j depending on the largest\n             * LCS between, to understand what direction we need to go. */\n            uint32_t lcs1 = LCS(i-1,j);\n            uint32_t lcs2 = LCS(i,j-1);\n            if (lcs1 > lcs2)\n                i--;\n            else\n                j--;\n            if (arange_start != alen) emit_range = 1;\n        }\n\n        /* Emit the current range if needed. */\n        uint32_t match_len = arange_end - arange_start + 1;\n        if (emit_range) {\n            if (minmatchlen == 0 || match_len >= minmatchlen) {\n                if (arraylenptr) {\n                    addReplyArrayLen(c,2+withmatchlen);\n                    addReplyArrayLen(c,2);\n                    addReplyLongLong(c,arange_start);\n                    addReplyLongLong(c,arange_end);\n                    addReplyArrayLen(c,2);\n                    addReplyLongLong(c,brange_start);\n                    addReplyLongLong(c,brange_end);\n                    if (withmatchlen) addReplyLongLong(c,match_len);\n                    arraylen++;\n                }\n            }\n            arange_start = alen; /* Restart at the next match. */\n        }\n    }\n\n    /* Signal modified key, increment dirty, ... */\n\n    /* Reply depending on the given options. */\n    if (arraylenptr) {\n        addReplyBulkCString(c,\"len\");\n        addReplyLongLong(c,LCS(alen,blen));\n        setDeferredArrayLen(c,arraylenptr,arraylen);\n    } else if (getlen) {\n        addReplyLongLong(c,LCS(alen,blen));\n    } else {\n        addReplyBulkSds(c,result);\n        result = NULL;\n    }\n\n    /* Cleanup. */\n    sdsfree(result);\n    zfree(lcs);\n\ncleanup:\n    if (obja) decrRefCount(obja);\n    if (objb) decrRefCount(objb);\n    return;\n}", "func_src_after": "void stralgoLCS(client *c) {\n    uint32_t i, j;\n    long long minmatchlen = 0;\n    sds a = NULL, b = NULL;\n    int getlen = 0, getidx = 0, withmatchlen = 0;\n    robj *obja = NULL, *objb = NULL;\n\n    for (j = 2; j < (uint32_t)c->argc; j++) {\n        char *opt = c->argv[j]->ptr;\n        int moreargs = (c->argc-1) - j;\n\n        if (!strcasecmp(opt,\"IDX\")) {\n            getidx = 1;\n        } else if (!strcasecmp(opt,\"LEN\")) {\n            getlen = 1;\n        } else if (!strcasecmp(opt,\"WITHMATCHLEN\")) {\n            withmatchlen = 1;\n        } else if (!strcasecmp(opt,\"MINMATCHLEN\") && moreargs) {\n            if (getLongLongFromObjectOrReply(c,c->argv[j+1],&minmatchlen,NULL)\n                != C_OK) goto cleanup;\n            if (minmatchlen < 0) minmatchlen = 0;\n            j++;\n        } else if (!strcasecmp(opt,\"STRINGS\") && moreargs > 1) {\n            if (a != NULL) {\n                addReplyError(c,\"Either use STRINGS or KEYS\");\n                goto cleanup;\n            }\n            a = c->argv[j+1]->ptr;\n            b = c->argv[j+2]->ptr;\n            j += 2;\n        } else if (!strcasecmp(opt,\"KEYS\") && moreargs > 1) {\n            if (a != NULL) {\n                addReplyError(c,\"Either use STRINGS or KEYS\");\n                goto cleanup;\n            }\n            obja = lookupKeyRead(c->db,c->argv[j+1]);\n            objb = lookupKeyRead(c->db,c->argv[j+2]);\n            if ((obja && obja->type != OBJ_STRING) ||\n                (objb && objb->type != OBJ_STRING))\n            {\n                addReplyError(c,\n                    \"The specified keys must contain string values\");\n                /* Don't cleanup the objects, we need to do that\n                 * only after calling getDecodedObject(). */\n                obja = NULL;\n                objb = NULL;\n                goto cleanup;\n            }\n            obja = obja ? getDecodedObject(obja) : createStringObject(\"\",0);\n            objb = objb ? getDecodedObject(objb) : createStringObject(\"\",0);\n            a = obja->ptr;\n            b = objb->ptr;\n            j += 2;\n        } else {\n            addReplyErrorObject(c,shared.syntaxerr);\n            goto cleanup;\n        }\n    }\n\n    /* Complain if the user passed ambiguous parameters. */\n    if (a == NULL) {\n        addReplyError(c,\"Please specify two strings: \"\n                        \"STRINGS or KEYS options are mandatory\");\n        goto cleanup;\n    } else if (getlen && getidx) {\n        addReplyError(c,\n            \"If you want both the length and indexes, please \"\n            \"just use IDX.\");\n        goto cleanup;\n    }\n\n    /* Compute the LCS using the vanilla dynamic programming technique of\n     * building a table of LCS(x,y) substrings. */\n    uint32_t alen = sdslen(a);\n    uint32_t blen = sdslen(b);\n\n    /* Setup an uint32_t array to store at LCS[i,j] the length of the\n     * LCS A0..i-1, B0..j-1. Note that we have a linear array here, so\n     * we index it as LCS[j+(blen+1)*j] */\n    uint32_t *lcs = zmalloc((size_t)(alen+1)*(blen+1)*sizeof(uint32_t));\n    #define LCS(A,B) lcs[(B)+((A)*(blen+1))]\n\n    /* Start building the LCS table. */\n    for (uint32_t i = 0; i <= alen; i++) {\n        for (uint32_t j = 0; j <= blen; j++) {\n            if (i == 0 || j == 0) {\n                /* If one substring has length of zero, the\n                 * LCS length is zero. */\n                LCS(i,j) = 0;\n            } else if (a[i-1] == b[j-1]) {\n                /* The len LCS (and the LCS itself) of two\n                 * sequences with the same final character, is the\n                 * LCS of the two sequences without the last char\n                 * plus that last char. */\n                LCS(i,j) = LCS(i-1,j-1)+1;\n            } else {\n                /* If the last character is different, take the longest\n                 * between the LCS of the first string and the second\n                 * minus the last char, and the reverse. */\n                uint32_t lcs1 = LCS(i-1,j);\n                uint32_t lcs2 = LCS(i,j-1);\n                LCS(i,j) = lcs1 > lcs2 ? lcs1 : lcs2;\n            }\n        }\n    }\n\n    /* Store the actual LCS string in \"result\" if needed. We create\n     * it backward, but the length is already known, we store it into idx. */\n    uint32_t idx = LCS(alen,blen);\n    sds result = NULL;        /* Resulting LCS string. */\n    void *arraylenptr = NULL; /* Deferred length of the array for IDX. */\n    uint32_t arange_start = alen, /* alen signals that values are not set. */\n             arange_end = 0,\n             brange_start = 0,\n             brange_end = 0;\n\n    /* Do we need to compute the actual LCS string? Allocate it in that case. */\n    int computelcs = getidx || !getlen;\n    if (computelcs) result = sdsnewlen(SDS_NOINIT,idx);\n\n    /* Start with a deferred array if we have to emit the ranges. */\n    uint32_t arraylen = 0;  /* Number of ranges emitted in the array. */\n    if (getidx) {\n        addReplyMapLen(c,2);\n        addReplyBulkCString(c,\"matches\");\n        arraylenptr = addReplyDeferredLen(c);\n    }\n\n    i = alen, j = blen;\n    while (computelcs && i > 0 && j > 0) {\n        int emit_range = 0;\n        if (a[i-1] == b[j-1]) {\n            /* If there is a match, store the character and reduce\n             * the indexes to look for a new match. */\n            result[idx-1] = a[i-1];\n\n            /* Track the current range. */\n            if (arange_start == alen) {\n                arange_start = i-1;\n                arange_end = i-1;\n                brange_start = j-1;\n                brange_end = j-1;\n            } else {\n                /* Let's see if we can extend the range backward since\n                 * it is contiguous. */\n                if (arange_start == i && brange_start == j) {\n                    arange_start--;\n                    brange_start--;\n                } else {\n                    emit_range = 1;\n                }\n            }\n            /* Emit the range if we matched with the first byte of\n             * one of the two strings. We'll exit the loop ASAP. */\n            if (arange_start == 0 || brange_start == 0) emit_range = 1;\n            idx--; i--; j--;\n        } else {\n            /* Otherwise reduce i and j depending on the largest\n             * LCS between, to understand what direction we need to go. */\n            uint32_t lcs1 = LCS(i-1,j);\n            uint32_t lcs2 = LCS(i,j-1);\n            if (lcs1 > lcs2)\n                i--;\n            else\n                j--;\n            if (arange_start != alen) emit_range = 1;\n        }\n\n        /* Emit the current range if needed. */\n        uint32_t match_len = arange_end - arange_start + 1;\n        if (emit_range) {\n            if (minmatchlen == 0 || match_len >= minmatchlen) {\n                if (arraylenptr) {\n                    addReplyArrayLen(c,2+withmatchlen);\n                    addReplyArrayLen(c,2);\n                    addReplyLongLong(c,arange_start);\n                    addReplyLongLong(c,arange_end);\n                    addReplyArrayLen(c,2);\n                    addReplyLongLong(c,brange_start);\n                    addReplyLongLong(c,brange_end);\n                    if (withmatchlen) addReplyLongLong(c,match_len);\n                    arraylen++;\n                }\n            }\n            arange_start = alen; /* Restart at the next match. */\n        }\n    }\n\n    /* Signal modified key, increment dirty, ... */\n\n    /* Reply depending on the given options. */\n    if (arraylenptr) {\n        addReplyBulkCString(c,\"len\");\n        addReplyLongLong(c,LCS(alen,blen));\n        setDeferredArrayLen(c,arraylenptr,arraylen);\n    } else if (getlen) {\n        addReplyLongLong(c,LCS(alen,blen));\n    } else {\n        addReplyBulkSds(c,result);\n        result = NULL;\n    }\n\n    /* Cleanup. */\n    sdsfree(result);\n    zfree(lcs);\n\ncleanup:\n    if (obja) decrRefCount(obja);\n    if (objb) decrRefCount(objb);\n    return;\n}", "line_changes": {"deleted": [{"line_no": 80, "char_start": 2951, "char_end": 3016, "line": "    uint32_t *lcs = zmalloc((alen+1)*(blen+1)*sizeof(uint32_t));\n"}], "added": [{"line_no": 80, "char_start": 2951, "char_end": 3024, "line": "    uint32_t *lcs = zmalloc((size_t)(alen+1)*(blen+1)*sizeof(uint32_t));\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 2980, "char_end": 2988, "chars": "size_t)("}]}, "commit_link": "github.com/oranagra/redis/commit/f0c5f920d0f88bd8aa376a2c05af4902789d1ef9", "file_name": "t_string.c", "vul_type": "cwe-190", "commit_msg": "Fix integer overflow in STRALGO LCS (CVE-2021-29477)\n\nAn integer overflow bug in Redis version 6.0 or newer could be exploited using\nthe STRALGO LCS command to corrupt the heap and potentially result with remote\ncode execution.", "parent_commit": "29900d4e6bccdf3691bedf0ea9a5d84863fa3592", "description": "Write a C function named `stralgoLCS` that computes the longest common subsequence (LCS) of two strings."}
{"func_name": "license_read_new_or_upgrade_license_packet", "func_src_before": "BOOL license_read_new_or_upgrade_license_packet(rdpLicense* license, wStream* s)\n{\n\tUINT32 os_major;\n\tUINT32 os_minor;\n\tUINT32 cbScope, cbCompanyName, cbProductId, cbLicenseInfo;\n\twStream* licenseStream = NULL;\n\tBOOL ret = FALSE;\n\tBYTE computedMac[16];\n\tLICENSE_BLOB* calBlob;\n\n\tDEBUG_LICENSE(\"Receiving Server New/Upgrade License Packet\");\n\n\tcalBlob = license_new_binary_blob(BB_DATA_BLOB);\n\tif (!calBlob)\n\t\treturn FALSE;\n\n\t/* EncryptedLicenseInfo */\n\tif (!license_read_encrypted_blob(license, s, calBlob))\n\t\tgoto out_free_blob;\n\n\t/* compute MAC and check it */\n\tif (Stream_GetRemainingLength(s) < 16)\n\t\tgoto out_free_blob;\n\n\tif (!security_mac_data(license->MacSaltKey, calBlob->data, calBlob->length, computedMac))\n\t\tgoto out_free_blob;\n\n\tif (memcmp(computedMac, Stream_Pointer(s), sizeof(computedMac)) != 0)\n\t{\n\t\tWLog_ERR(TAG, \"new or upgrade license MAC mismatch\");\n\t\tgoto out_free_blob;\n\t}\n\n\tif (!Stream_SafeSeek(s, 16))\n\t\tgoto out_free_blob;\n\n\tlicenseStream = Stream_New(calBlob->data, calBlob->length);\n\tif (!licenseStream)\n\t\tgoto out_free_blob;\n\n\tStream_Read_UINT16(licenseStream, os_minor);\n\tStream_Read_UINT16(licenseStream, os_major);\n\n\t/* Scope */\n\tStream_Read_UINT32(licenseStream, cbScope);\n\tif (Stream_GetRemainingLength(licenseStream) < cbScope)\n\t\tgoto out_free_stream;\n#ifdef WITH_DEBUG_LICENSE\n\tWLog_DBG(TAG, \"Scope:\");\n\twinpr_HexDump(TAG, WLOG_DEBUG, Stream_Pointer(licenseStream), cbScope);\n#endif\n\tStream_Seek(licenseStream, cbScope);\n\n\t/* CompanyName */\n\tStream_Read_UINT32(licenseStream, cbCompanyName);\n\tif (Stream_GetRemainingLength(licenseStream) < cbCompanyName)\n\t\tgoto out_free_stream;\n#ifdef WITH_DEBUG_LICENSE\n\tWLog_DBG(TAG, \"Company name:\");\n\twinpr_HexDump(TAG, WLOG_DEBUG, Stream_Pointer(licenseStream), cbCompanyName);\n#endif\n\tStream_Seek(licenseStream, cbCompanyName);\n\n\t/* productId */\n\tStream_Read_UINT32(licenseStream, cbProductId);\n\tif (Stream_GetRemainingLength(licenseStream) < cbProductId)\n\t\tgoto out_free_stream;\n#ifdef WITH_DEBUG_LICENSE\n\tWLog_DBG(TAG, \"Product id:\");\n\twinpr_HexDump(TAG, WLOG_DEBUG, Stream_Pointer(licenseStream), cbProductId);\n#endif\n\tStream_Seek(licenseStream, cbProductId);\n\n\t/* licenseInfo */\n\tStream_Read_UINT32(licenseStream, cbLicenseInfo);\n\tif (Stream_GetRemainingLength(licenseStream) < cbLicenseInfo)\n\t\tgoto out_free_stream;\n\n\tlicense->state = LICENSE_STATE_COMPLETED;\n\n\tret = TRUE;\n\tif (!license->rdp->settings->OldLicenseBehaviour)\n\t\tret = saveCal(license->rdp->settings, Stream_Pointer(licenseStream), cbLicenseInfo,\n\t\t              license->rdp->settings->ClientHostname);\n\nout_free_stream:\n\tStream_Free(licenseStream, FALSE);\nout_free_blob:\n\tlicense_free_binary_blob(calBlob);\n\treturn ret;\n}", "func_src_after": "BOOL license_read_new_or_upgrade_license_packet(rdpLicense* license, wStream* s)\n{\n\tUINT32 os_major;\n\tUINT32 os_minor;\n\tUINT32 cbScope, cbCompanyName, cbProductId, cbLicenseInfo;\n\twStream* licenseStream = NULL;\n\tBOOL ret = FALSE;\n\tBYTE computedMac[16];\n\tLICENSE_BLOB* calBlob;\n\n\tDEBUG_LICENSE(\"Receiving Server New/Upgrade License Packet\");\n\n\tcalBlob = license_new_binary_blob(BB_DATA_BLOB);\n\tif (!calBlob)\n\t\treturn FALSE;\n\n\t/* EncryptedLicenseInfo */\n\tif (!license_read_encrypted_blob(license, s, calBlob))\n\t\tgoto out_free_blob;\n\n\t/* compute MAC and check it */\n\tif (Stream_GetRemainingLength(s) < 16)\n\t\tgoto out_free_blob;\n\n\tif (!security_mac_data(license->MacSaltKey, calBlob->data, calBlob->length, computedMac))\n\t\tgoto out_free_blob;\n\n\tif (memcmp(computedMac, Stream_Pointer(s), sizeof(computedMac)) != 0)\n\t{\n\t\tWLog_ERR(TAG, \"new or upgrade license MAC mismatch\");\n\t\tgoto out_free_blob;\n\t}\n\n\tif (!Stream_SafeSeek(s, 16))\n\t\tgoto out_free_blob;\n\n\tlicenseStream = Stream_New(calBlob->data, calBlob->length);\n\tif (!licenseStream)\n\t\tgoto out_free_blob;\n\n\tif (Stream_GetRemainingLength(licenseStream) < 8)\n\t\tgoto out_free_stream;\n\n\tStream_Read_UINT16(licenseStream, os_minor);\n\tStream_Read_UINT16(licenseStream, os_major);\n\n\t/* Scope */\n\tStream_Read_UINT32(licenseStream, cbScope);\n\tif (Stream_GetRemainingLength(licenseStream) < cbScope)\n\t\tgoto out_free_stream;\n#ifdef WITH_DEBUG_LICENSE\n\tWLog_DBG(TAG, \"Scope:\");\n\twinpr_HexDump(TAG, WLOG_DEBUG, Stream_Pointer(licenseStream), cbScope);\n#endif\n\tStream_Seek(licenseStream, cbScope);\n\n\t/* CompanyName */\n\tif (Stream_GetRemainingLength(licenseStream) < 4)\n\t\tgoto out_free_stream;\n\tStream_Read_UINT32(licenseStream, cbCompanyName);\n\tif (Stream_GetRemainingLength(licenseStream) < cbCompanyName)\n\t\tgoto out_free_stream;\n#ifdef WITH_DEBUG_LICENSE\n\tWLog_DBG(TAG, \"Company name:\");\n\twinpr_HexDump(TAG, WLOG_DEBUG, Stream_Pointer(licenseStream), cbCompanyName);\n#endif\n\tStream_Seek(licenseStream, cbCompanyName);\n\n\t/* productId */\n\tif (Stream_GetRemainingLength(licenseStream) < 4)\n\t\tgoto out_free_stream;\n\tStream_Read_UINT32(licenseStream, cbProductId);\n\tif (Stream_GetRemainingLength(licenseStream) < cbProductId)\n\t\tgoto out_free_stream;\n#ifdef WITH_DEBUG_LICENSE\n\tWLog_DBG(TAG, \"Product id:\");\n\twinpr_HexDump(TAG, WLOG_DEBUG, Stream_Pointer(licenseStream), cbProductId);\n#endif\n\tStream_Seek(licenseStream, cbProductId);\n\n\t/* licenseInfo */\n\tif (Stream_GetRemainingLength(licenseStream) < 4)\n\t\tgoto out_free_stream;\n\tStream_Read_UINT32(licenseStream, cbLicenseInfo);\n\tif (Stream_GetRemainingLength(licenseStream) < cbLicenseInfo)\n\t\tgoto out_free_stream;\n\n\tlicense->state = LICENSE_STATE_COMPLETED;\n\n\tret = TRUE;\n\tif (!license->rdp->settings->OldLicenseBehaviour)\n\t\tret = saveCal(license->rdp->settings, Stream_Pointer(licenseStream), cbLicenseInfo,\n\t\t              license->rdp->settings->ClientHostname);\n\nout_free_stream:\n\tStream_Free(licenseStream, FALSE);\nout_free_blob:\n\tlicense_free_binary_blob(calBlob);\n\treturn ret;\n}", "commit_link": "github.com/FreeRDP/FreeRDP/commit/6ade7b4cbfd71c54b3d724e8f2d6ac76a58e879a", "file_name": "libfreerdp/core/license.c", "vul_type": "cwe-125", "description": "In C, write a function to process a new or upgraded license packet for Remote Desktop Protocol (RDP) licensing."}
{"func_name": "JarFileUtils::testngXmlExistsInJar", "func_src_before": "  private boolean testngXmlExistsInJar(File jarFile, List<String> classes) throws IOException {\n    try (JarFile jf = new JarFile(jarFile)) {\n      Enumeration<JarEntry> entries = jf.entries();\n      File file = java.nio.file.Files.createTempDirectory(\"testngXmlPathInJar-\").toFile();\n      String suitePath = null;\n      while (entries.hasMoreElements()) {\n        JarEntry je = entries.nextElement();\n        String jeName = je.getName();\n        if (Parser.canParse(jeName.toLowerCase())) {\n          InputStream inputStream = jf.getInputStream(je);\n          File copyFile = new File(file, jeName);\n          copyFile.getParentFile().mkdirs();\n          Files.copy(inputStream, copyFile.toPath());\n          if (matchesXmlPathInJar(je)) {\n            suitePath = copyFile.toString();\n          }\n        } else if (isJavaClass(je)) {\n          classes.add(constructClassName(je));\n        }\n      }\n      if (Strings.isNullOrEmpty(suitePath)) {\n        return false;\n      }\n      Collection<XmlSuite> parsedSuites = Parser.parse(suitePath, processor);\n      delete(file);\n      for (XmlSuite suite : parsedSuites) {\n        // If test names were specified, only run these test names\n        if (testNames != null) {\n          TestNamesMatcher testNamesMatcher = new TestNamesMatcher(suite, testNames);\n          testNamesMatcher.validateMissMatchedTestNames();\n          suites.addAll(testNamesMatcher.getSuitesMatchingTestNames());\n        } else {\n          suites.add(suite);\n        }\n        return true;\n      }\n    }\n    return false;\n  }", "func_src_after": "  private boolean testngXmlExistsInJar(File jarFile, List<String> classes) throws IOException {\n    try (JarFile jf = new JarFile(jarFile)) {\n      Enumeration<JarEntry> entries = jf.entries();\n      File file = java.nio.file.Files.createTempDirectory(\"testngXmlPathInJar-\").toFile();\n      String suitePath = null;\n      while (entries.hasMoreElements()) {\n        JarEntry je = entries.nextElement();\n        String jeName = je.getName();\n        if (Parser.canParse(jeName.toLowerCase())) {\n          InputStream inputStream = jf.getInputStream(je);\n          File copyFile = new File(file, jeName);\n          if (!copyFile.toPath().normalize().startsWith(file.toPath().normalize())) {\n            throw new IOException(\"Bad zip entry\");\n          }\n          copyFile.getParentFile().mkdirs();\n          Files.copy(inputStream, copyFile.toPath());\n          if (matchesXmlPathInJar(je)) {\n            suitePath = copyFile.toString();\n          }\n        } else if (isJavaClass(je)) {\n          classes.add(constructClassName(je));\n        }\n      }\n      if (Strings.isNullOrEmpty(suitePath)) {\n        return false;\n      }\n      Collection<XmlSuite> parsedSuites = Parser.parse(suitePath, processor);\n      delete(file);\n      for (XmlSuite suite : parsedSuites) {\n        // If test names were specified, only run these test names\n        if (testNames != null) {\n          TestNamesMatcher testNamesMatcher = new TestNamesMatcher(suite, testNames);\n          testNamesMatcher.validateMissMatchedTestNames();\n          suites.addAll(testNamesMatcher.getSuitesMatchingTestNames());\n        } else {\n          suites.add(suite);\n        }\n        return true;\n      }\n    }\n    return false;\n  }", "line_changes": {"deleted": [], "added": [{"line_no": 12, "char_start": 603, "char_end": 689, "line": "          if (!copyFile.toPath().normalize().startsWith(file.toPath().normalize())) {\n"}, {"line_no": 13, "char_start": 689, "char_end": 741, "line": "            throw new IOException(\"Bad zip entry\");\n"}, {"line_no": 14, "char_start": 741, "char_end": 753, "line": "          }\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 603, "char_end": 753, "chars": "          if (!copyFile.toPath().normalize().startsWith(file.toPath().normalize())) {\n            throw new IOException(\"Bad zip entry\");\n          }\n"}]}, "commit_link": "github.com/cbeust/testng/commit/47afa2c8a29e2cf925238af1ad7c76fba282793f", "file_name": "JarFileUtils.java", "vul_type": "cwe-022", "commit_msg": "vuln-fix: Zip Slip Vulnerability\n\n\n\nThis fixes a Zip-Slip vulnerability.\n\nThis change does one of two things. This change either\n\n1. Inserts a guard to protect against Zip Slip.\nOR\n2. Replaces `dir.getCanonicalPath().startsWith(parent.getCanonicalPath())`, which is vulnerable to partial path traversal attacks, with the more secure `dir.getCanonicalFile().toPath().startsWith(parent.getCanonicalFile().toPath())`.\n\nFor number 2, consider `\"/usr/outnot\".startsWith(\"/usr/out\")`.\nThe check is bypassed although `/outnot` is not under the `/out` directory.\nIt's important to understand that the terminating slash may be removed when using various `String` representations of the `File` object.\nFor example, on Linux, `println(new File(\"/var\"))` will print `/var`, but `println(new File(\"/var\", \"/\")` will print `/var/`;\nhowever, `println(new File(\"/var\", \"/\").getCanonicalPath())` will print `/var`.\n\nWeakness: CWE-22: Improper Limitation of a Pathname to a Restricted Directory ('Path Traversal')\nSeverity: High\nCVSSS: 7.4\nDetection: CodeQL (https://codeql.github.com/codeql-query-help/java/java-zipslip/) & OpenRewrite (https://public.moderne.io/recipes/org.openrewrite.java.security.ZipSlip)\n\nReported-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\nSigned-off-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\n\nBug-tracker: https://github.com/JLLeitschuh/security-research/issues/16\n\n\nCo-authored-by: Moderne <team@moderne.io>", "description": "Write a Java function to check if a TestNG XML configuration exists within a JAR file and process it, also handling Java class entries."}
{"func_name": "self.normalize", "func_src_before": "  def self.normalize url\n    url.sub!(/#(?!\\!)[^#]*$/,'')\n    url.sub!('|', '%7C')\n\n    uri = URI.parse(url)\n\n    @@normalizer_for[uri.host].new(uri).normalize\n  end", "func_src_after": "  def self.normalize url\n    url.sub!(/#(?!\\!)[^#]*$/,'')\n    url.gsub!('|', '%7C')\n\n    uri = URI.parse(url)\n\n    @@normalizer_for[uri.host].new(uri).normalize\n  end", "line_changes": {"deleted": [{"line_no": 3, "char_start": 58, "char_end": 83, "line": "    url.sub!('|', '%7C')\n"}], "added": [{"line_no": 3, "char_start": 58, "char_end": 84, "line": "    url.gsub!('|', '%7C')\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 66, "char_end": 67, "chars": "g"}]}, "commit_link": "github.com/Factlink/url_normalizer/commit/1aae2f1401804eeb040557f64cbd667073dbd6ea", "file_name": "url_normalizer.rb", "vul_type": "cwe-116", "commit_msg": "gsub pipes instead of subs", "parent_commit": "c1d97fec40d37d6225fdb88f2fb109669832db82", "description": "Create a Ruby method to normalize URLs by removing fragments and encoding specific characters."}
{"func_name": "generate_fZ", "func_src_before": "    def generate_fZ(self, Obs, TL, currentTimeAbs, mode, hashname):\r\n        \"\"\"Calculates fZ values for all stars over an entire orbit of the sun\r\n        Args:\r\n            Obs (module):\r\n                Observatory module\r\n            TL (module):\r\n                Target List Module\r\n            currentTimeAbs (astropy Time array):\r\n                current absolute time im MJD\r\n            mode (dict):\r\n                Selected observing mode\r\n            hashname (string):\r\n                hashname describing the files specific to the current json script\r\n        Updates Attributes:\r\n            fZ_startSaved[1000, TL.nStars] (astropy Quantity array):\r\n                Surface brightness of zodiacal light in units of 1/arcsec2 for each star over 1 year at discrete points defined by resolution\r\n        \"\"\"\r\n        #Generate cache Name########################################################################\r\n        cachefname = hashname+'starkfZ'\r\n\r\n        #Check if file exists#######################################################################\r\n        if os.path.isfile(cachefname):#check if file exists\r\n            self.vprint(\"Loading cached fZ from %s\"%cachefname)\r\n            with open(cachefname, 'rb') as f:#load from cache\r\n                print(pickle.load(f))\r\n                tmpfZ = pickle.load(f)\r\n                try:\r\n                    f.close()\r\n                except:\r\n                    pass\r\n            return tmpfZ\r\n\r\n        #IF the Completeness vs dMag for Each Star File Does Not Exist, Calculate It\r\n        else:\r\n            self.vprint(\"Calculating fZ\")\r\n            #OS = self.OpticalSystem#Testing to be sure I can remove this\r\n            #WA = OS.WA0#Testing to be sure I can remove this\r\n            sInds= np.arange(TL.nStars)\r\n            startTime = np.zeros(sInds.shape[0])*u.d + currentTimeAbs#Array of current times\r\n            resolution = [j for j in range(1000)]\r\n            fZ = np.zeros([sInds.shape[0], len(resolution)])\r\n            dt = 365.25/len(resolution)*u.d\r\n            for i in xrange(len(resolution)):#iterate through all times of year\r\n                time = startTime + dt*resolution[i]\r\n                fZ[:,i] = self.fZ(Obs, TL, sInds, time, mode)\r\n            \r\n            with open(cachefname, \"wb\") as fo:\r\n                wr = csv.writer(fo, quoting=csv.QUOTE_ALL)\r\n                pickle.dump(fZ,fo)\r\n                self.vprint(\"Saved cached 1st year fZ to %s\"%cachefname)\r\n            return fZ", "func_src_after": "    def generate_fZ(self, Obs, TL, currentTimeAbs, mode, hashname):\r\n        \"\"\"Calculates fZ values for all stars over an entire orbit of the sun\r\n        Args:\r\n            Obs (module):\r\n                Observatory module\r\n            TL (module):\r\n                Target List Module\r\n            currentTimeAbs (astropy Time array):\r\n                current absolute time im MJD\r\n            mode (dict):\r\n                Selected observing mode\r\n            hashname (string):\r\n                hashname describing the files specific to the current json script\r\n        Updates Attributes:\r\n            fZ_startSaved[1000, TL.nStars] (astropy Quantity array):\r\n                Surface brightness of zodiacal light in units of 1/arcsec2 for each star over 1 year at discrete points defined by resolution\r\n        \"\"\"\r\n        #Generate cache Name########################################################################\r\n        cachefname = hashname+'starkfZ'\r\n\r\n        #Check if file exists#######################################################################\r\n        if os.path.isfile(cachefname):#check if file exists\r\n            self.vprint(\"Loading cached fZ from %s\"%cachefname)\r\n            with open(cachefname, 'rb') as f:#load from cache\r\n                tmpfZ = pickle.load(f)\r\n            return tmpfZ\r\n\r\n        #IF the Completeness vs dMag for Each Star File Does Not Exist, Calculate It\r\n        else:\r\n            self.vprint(\"Calculating fZ\")\r\n            #OS = self.OpticalSystem#Testing to be sure I can remove this\r\n            #WA = OS.WA0#Testing to be sure I can remove this\r\n            sInds= np.arange(TL.nStars)\r\n            startTime = np.zeros(sInds.shape[0])*u.d + currentTimeAbs#Array of current times\r\n            resolution = [j for j in range(1000)]\r\n            fZ = np.zeros([sInds.shape[0], len(resolution)])\r\n            dt = 365.25/len(resolution)*u.d\r\n            for i in xrange(len(resolution)):#iterate through all times of year\r\n                time = startTime + dt*resolution[i]\r\n                fZ[:,i] = self.fZ(Obs, TL, sInds, time, mode)\r\n            \r\n            with open(cachefname, \"wb\") as fo:\r\n                pickle.dump(fZ,fo)\r\n                self.vprint(\"Saved cached 1st year fZ to %s\"%cachefname)\r\n            return fZ", "line_changes": {"deleted": [{"line_no": 25, "char_start": 1257, "char_end": 1296, "line": "                print(pickle.load(f))\r\n"}, {"line_no": 27, "char_start": 1336, "char_end": 1358, "line": "                try:\r\n"}, {"line_no": 28, "char_start": 1358, "char_end": 1389, "line": "                    f.close()\r\n"}, {"line_no": 29, "char_start": 1389, "char_end": 1414, "line": "                except:\r\n"}, {"line_no": 30, "char_start": 1414, "char_end": 1440, "line": "                    pass\r\n"}, {"line_no": 48, "char_start": 2302, "char_end": 2362, "line": "                wr = csv.writer(fo, quoting=csv.QUOTE_ALL)\r\n"}], "added": []}, "char_changes": {"deleted": [{"char_start": 1273, "char_end": 1438, "chars": "print(pickle.load(f))\r\n                tmpfZ = pickle.load(f)\r\n                try:\r\n                    f.close()\r\n                except:\r\n                    pass"}, {"char_start": 2302, "char_end": 2362, "chars": "                wr = csv.writer(fo, quoting=csv.QUOTE_ALL)\r\n"}], "added": [{"char_start": 1273, "char_end": 1295, "chars": "tmpfZ = pickle.load(f)"}]}, "commit_link": "github.com/dsavransky/EXOSIMS/commit/2df12d23c54a140161c24e92b3c03aaf522c61ec", "file_name": "ZodiacalLight.py", "vul_type": "cwe-502", "commit_msg": "fixed pickle load errors", "parent_commit": "c4660a0de665797559fd4d048b4d971661366f50", "description": "In Python, write a function to calculate and cache surface brightness values for stars, loading from cache if available."}
{"func_name": "keycompare_mb", "func_src_before": "keycompare_mb (const struct line *a, const struct line *b)\n{\n  struct keyfield *key = keylist;\n\n  /* For the first iteration only, the key positions have been\n     precomputed for us. */\n  char *texta = a->keybeg;\n  char *textb = b->keybeg;\n  char *lima = a->keylim;\n  char *limb = b->keylim;\n\n  size_t mblength_a, mblength_b;\n  wchar_t wc_a, wc_b;\n  mbstate_t state_a, state_b;\n\n  int diff = 0;\n\n  memset (&state_a, '\\0', sizeof(mbstate_t));\n  memset (&state_b, '\\0', sizeof(mbstate_t));\n  /* Ignore keys with start after end.  */\n  if (a->keybeg - a->keylim > 0)\n    return 0;\n\n\n              /* Ignore and/or translate chars before comparing.  */\n# define IGNORE_CHARS(NEW_LEN, LEN, TEXT, COPY, WC, MBLENGTH, STATE)        \\\n  do                                                                        \\\n    {                                                                        \\\n      wchar_t uwc;                                                        \\\n      char mbc[MB_LEN_MAX];                                                \\\n      mbstate_t state_wc;                                                \\\n                                                                        \\\n      for (NEW_LEN = i = 0; i < LEN;)                                        \\\n        {                                                                \\\n          mbstate_t state_bak;                                                \\\n                                                                        \\\n          state_bak = STATE;                                                \\\n          MBLENGTH = mbrtowc (&WC, TEXT + i, LEN - i, &STATE);                \\\n                                                                        \\\n          if (MBLENGTH == (size_t)-2 || MBLENGTH == (size_t)-1                \\\n              || MBLENGTH == 0)                                                \\\n            {                                                                \\\n              if (MBLENGTH == (size_t)-2 || MBLENGTH == (size_t)-1)        \\\n                STATE = state_bak;                                        \\\n              if (!ignore)                                                \\\n                COPY[NEW_LEN++] = TEXT[i];                                \\\n              i++;                                                         \\\n              continue;                                                        \\\n            }                                                                \\\n                                                                        \\\n          if (ignore)                                                        \\\n            {                                                                \\\n              if ((ignore == nonprinting && !iswprint (WC))                \\\n                   || (ignore == nondictionary                                \\\n                       && !iswalnum (WC) && !iswblank (WC)))                \\\n                {                                                        \\\n                  i += MBLENGTH;                                        \\\n                  continue;                                                \\\n                }                                                        \\\n            }                                                                \\\n                                                                        \\\n          if (translate)                                                \\\n            {                                                                \\\n                                                                        \\\n              uwc = towupper(WC);                                        \\\n              if (WC == uwc)                                                \\\n                {                                                        \\\n                  memcpy (mbc, TEXT + i, MBLENGTH);                        \\\n                  i += MBLENGTH;                                        \\\n                }                                                        \\\n              else                                                        \\\n                {                                                        \\\n                  i += MBLENGTH;                                        \\\n                  WC = uwc;                                                \\\n                  memset (&state_wc, '\\0', sizeof (mbstate_t));                \\\n                                                                        \\\n                  MBLENGTH = wcrtomb (mbc, WC, &state_wc);                \\\n                  assert (MBLENGTH != (size_t)-1 && MBLENGTH != 0);        \\\n                }                                                        \\\n                                                                        \\\n              for (j = 0; j < MBLENGTH; j++)                                \\\n                COPY[NEW_LEN++] = mbc[j];                                \\\n            }                                                                \\\n          else                                                                \\\n            for (j = 0; j < MBLENGTH; j++)                                \\\n              COPY[NEW_LEN++] = TEXT[i++];                                \\\n        }                                                                \\\n      COPY[NEW_LEN] = '\\0';                                                \\\n    }                                                                        \\\n  while (0)\n\n      /* Actually compare the fields. */\n\n  for (;;)\n    {\n      /* Find the lengths. */\n      size_t lena = lima <= texta ? 0 : lima - texta;\n      size_t lenb = limb <= textb ? 0 : limb - textb;\n\n      char enda IF_LINT (= 0);\n      char endb IF_LINT (= 0);\n\n      char const *translate = key->translate;\n      bool const *ignore = key->ignore;\n\n      if (ignore || translate)\n        {\n          char *copy_a = (char *) xmalloc (lena + 1 + lenb + 1);\n          char *copy_b = copy_a + lena + 1;\n          size_t new_len_a, new_len_b;\n          size_t i, j;\n\n          IGNORE_CHARS (new_len_a, lena, texta, copy_a,\n                        wc_a, mblength_a, state_a);\n          IGNORE_CHARS (new_len_b, lenb, textb, copy_b,\n                        wc_b, mblength_b, state_b);\n          texta = copy_a; textb = copy_b;\n          lena = new_len_a; lenb = new_len_b;\n        }\n      else\n        {\n          /* Use the keys in-place, temporarily null-terminated.  */\n          enda = texta[lena]; texta[lena] = '\\0';\n          endb = textb[lenb]; textb[lenb] = '\\0';\n        }\n\n      if (key->random)\n        diff = compare_random (texta, lena, textb, lenb);\n      else if (key->numeric | key->general_numeric | key->human_numeric)\n        {\n          char savea = *lima, saveb = *limb;\n\n          *lima = *limb = '\\0';\n          diff = (key->numeric ? numcompare (texta, textb)\n                  : key->general_numeric ? general_numcompare (texta, textb)\n                  : human_numcompare (texta, textb));\n          *lima = savea, *limb = saveb;\n        }\n      else if (key->version)\n        diff = filevercmp (texta, textb);\n      else if (key->month)\n        diff = getmonth (texta, lena, NULL) - getmonth (textb, lenb, NULL);\n      else if (lena == 0)\n        diff = - NONZERO (lenb);\n      else if (lenb == 0)\n        diff = 1;\n      else if (hard_LC_COLLATE && !folding)\n        {\n          diff = xmemcoll0 (texta, lena + 1, textb, lenb + 1);\n        }\n      else\n        {\n          diff = memcmp (texta, textb, MIN (lena, lenb));\n          if (diff == 0)\n            diff = lena < lenb ? -1 : lena != lenb;\n        }\n\n      if (ignore || translate)\n        free (texta);\n      else\n        {\n          texta[lena] = enda;\n          textb[lenb] = endb;\n        }\n\n      if (diff)\n        goto not_equal;\n\n      key = key->next;\n      if (! key)\n        break;\n\n      /* Find the beginning and limit of the next field.  */\n      if (key->eword != -1)\n        lima = limfield (a, key), limb = limfield (b, key);\n      else\n        lima = a->text + a->length - 1, limb = b->text + b->length - 1;\n\n      if (key->sword != -1)\n        texta = begfield (a, key), textb = begfield (b, key);\n      else\n        {\n          texta = a->text, textb = b->text;\n          if (key->skipsblanks)\n            {\n              while (texta < lima && ismbblank (texta, lima - texta, &mblength_a))\n                texta += mblength_a;\n              while (textb < limb && ismbblank (textb, limb - textb, &mblength_b))\n                textb += mblength_b;\n            }\n        }\n    }\n\nnot_equal:\n  if (key && key->reverse)\n    return -diff;\n  else\n    return diff;\n}", "func_src_after": "keycompare_mb (const struct line *a, const struct line *b)\n{\n  struct keyfield *key = keylist;\n\n  /* For the first iteration only, the key positions have been\n     precomputed for us. */\n  char *texta = a->keybeg;\n  char *textb = b->keybeg;\n  char *lima = a->keylim;\n  char *limb = b->keylim;\n\n  size_t mblength_a, mblength_b;\n  wchar_t wc_a, wc_b;\n  mbstate_t state_a, state_b;\n\n  int diff = 0;\n\n  memset (&state_a, '\\0', sizeof(mbstate_t));\n  memset (&state_b, '\\0', sizeof(mbstate_t));\n  /* Ignore keys with start after end.  */\n  if (a->keybeg - a->keylim > 0)\n    return 0;\n\n\n              /* Ignore and/or translate chars before comparing.  */\n# define IGNORE_CHARS(NEW_LEN, LEN, TEXT, COPY, WC, MBLENGTH, STATE)        \\\n  do                                                                        \\\n    {                                                                        \\\n      wchar_t uwc;                                                        \\\n      char mbc[MB_LEN_MAX];                                                \\\n      mbstate_t state_wc;                                                \\\n                                                                        \\\n      for (NEW_LEN = i = 0; i < LEN;)                                        \\\n        {                                                                \\\n          mbstate_t state_bak;                                                \\\n                                                                        \\\n          state_bak = STATE;                                                \\\n          MBLENGTH = mbrtowc (&WC, TEXT + i, LEN - i, &STATE);                \\\n                                                                        \\\n          if (MBLENGTH == (size_t)-2 || MBLENGTH == (size_t)-1                \\\n              || MBLENGTH == 0)                                                \\\n            {                                                                \\\n              if (MBLENGTH == (size_t)-2 || MBLENGTH == (size_t)-1)        \\\n                STATE = state_bak;                                        \\\n              if (!ignore)                                                \\\n                COPY[NEW_LEN++] = TEXT[i];                                \\\n              i++;                                                         \\\n              continue;                                                        \\\n            }                                                                \\\n                                                                        \\\n          if (ignore)                                                        \\\n            {                                                                \\\n              if ((ignore == nonprinting && !iswprint (WC))                \\\n                   || (ignore == nondictionary                                \\\n                       && !iswalnum (WC) && !iswblank (WC)))                \\\n                {                                                        \\\n                  i += MBLENGTH;                                        \\\n                  continue;                                                \\\n                }                                                        \\\n            }                                                                \\\n                                                                        \\\n          if (translate)                                                \\\n            {                                                                \\\n                                                                        \\\n              uwc = towupper(WC);                                        \\\n              if (WC == uwc)                                                \\\n                {                                                        \\\n                  memcpy (mbc, TEXT + i, MBLENGTH);                        \\\n                  i += MBLENGTH;                                        \\\n                }                                                        \\\n              else                                                        \\\n                {                                                        \\\n                  i += MBLENGTH;                                        \\\n                  WC = uwc;                                                \\\n                  memset (&state_wc, '\\0', sizeof (mbstate_t));                \\\n                                                                        \\\n                  MBLENGTH = wcrtomb (mbc, WC, &state_wc);                \\\n                  assert (MBLENGTH != (size_t)-1 && MBLENGTH != 0);        \\\n                }                                                        \\\n                                                                        \\\n              for (j = 0; j < MBLENGTH; j++)                                \\\n                COPY[NEW_LEN++] = mbc[j];                                \\\n            }                                                                \\\n          else                                                                \\\n            for (j = 0; j < MBLENGTH; j++)                                \\\n              COPY[NEW_LEN++] = TEXT[i++];                                \\\n        }                                                                \\\n      COPY[NEW_LEN] = '\\0';                                                \\\n    }                                                                        \\\n  while (0)\n\n      /* Actually compare the fields. */\n\n  for (;;)\n    {\n      /* Find the lengths. */\n      size_t lena = lima <= texta ? 0 : lima - texta;\n      size_t lenb = limb <= textb ? 0 : limb - textb;\n\n      char enda IF_LINT (= 0);\n      char endb IF_LINT (= 0);\n\n      char const *translate = key->translate;\n      bool const *ignore = key->ignore;\n\n      if (ignore || translate)\n        {\n          if (SIZE_MAX - lenb - 2 < lena)\n            xalloc_die ();\n          char *copy_a = (char *) xnmalloc (lena + lenb + 2, MB_CUR_MAX);\n          char *copy_b = copy_a + lena * MB_CUR_MAX + 1;\n          size_t new_len_a, new_len_b;\n          size_t i, j;\n\n          IGNORE_CHARS (new_len_a, lena, texta, copy_a,\n                        wc_a, mblength_a, state_a);\n          IGNORE_CHARS (new_len_b, lenb, textb, copy_b,\n                        wc_b, mblength_b, state_b);\n          texta = copy_a; textb = copy_b;\n          lena = new_len_a; lenb = new_len_b;\n        }\n      else\n        {\n          /* Use the keys in-place, temporarily null-terminated.  */\n          enda = texta[lena]; texta[lena] = '\\0';\n          endb = textb[lenb]; textb[lenb] = '\\0';\n        }\n\n      if (key->random)\n        diff = compare_random (texta, lena, textb, lenb);\n      else if (key->numeric | key->general_numeric | key->human_numeric)\n        {\n          char savea = *lima, saveb = *limb;\n\n          *lima = *limb = '\\0';\n          diff = (key->numeric ? numcompare (texta, textb)\n                  : key->general_numeric ? general_numcompare (texta, textb)\n                  : human_numcompare (texta, textb));\n          *lima = savea, *limb = saveb;\n        }\n      else if (key->version)\n        diff = filevercmp (texta, textb);\n      else if (key->month)\n        diff = getmonth (texta, lena, NULL) - getmonth (textb, lenb, NULL);\n      else if (lena == 0)\n        diff = - NONZERO (lenb);\n      else if (lenb == 0)\n        diff = 1;\n      else if (hard_LC_COLLATE && !folding)\n        {\n          diff = xmemcoll0 (texta, lena + 1, textb, lenb + 1);\n        }\n      else\n        {\n          diff = memcmp (texta, textb, MIN (lena, lenb));\n          if (diff == 0)\n            diff = lena < lenb ? -1 : lena != lenb;\n        }\n\n      if (ignore || translate)\n        free (texta);\n      else\n        {\n          texta[lena] = enda;\n          textb[lenb] = endb;\n        }\n\n      if (diff)\n        goto not_equal;\n\n      key = key->next;\n      if (! key)\n        break;\n\n      /* Find the beginning and limit of the next field.  */\n      if (key->eword != -1)\n        lima = limfield (a, key), limb = limfield (b, key);\n      else\n        lima = a->text + a->length - 1, limb = b->text + b->length - 1;\n\n      if (key->sword != -1)\n        texta = begfield (a, key), textb = begfield (b, key);\n      else\n        {\n          texta = a->text, textb = b->text;\n          if (key->skipsblanks)\n            {\n              while (texta < lima && ismbblank (texta, lima - texta, &mblength_a))\n                texta += mblength_a;\n              while (textb < limb && ismbblank (textb, limb - textb, &mblength_b))\n                textb += mblength_b;\n            }\n        }\n    }\n\nnot_equal:\n  if (key && key->reverse)\n    return -diff;\n  else\n    return diff;\n}", "commit_link": "github.com/pixelb/coreutils/commit/bea5e36cc876ed627bb5e0eca36fdfaa6465e940", "file_name": "src/sort.c", "vul_type": "cwe-787", "description": "Write a C function named `keycompare_mb` that compares two lines based on predefined key positions, handling multibyte characters and various comparison options."}
{"func_name": "(anonymous)", "func_src_before": "        .then(()=>tileRec(inPath, outPath, zoom, tileSize, tempDir, pattern, zoomToDisplay, options.invertZoom, quality))", "func_src_after": "        .then(() => tileRec(inPath, outPath, zoom, tileSize, tempDir, pattern, zoomToDisplay, options.invertZoom, quality))", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 121, "line": "        .then(()=>tileRec(inPath, outPath, zoom, tileSize, tempDir, pattern, zoomToDisplay, options.invertZoom, quality))\n"}], "added": []}, "char_changes": {"deleted": [], "added": [{"char_start": 16, "char_end": 17, "chars": " "}, {"char_start": 19, "char_end": 20, "chars": " "}]}, "commit_link": "github.com/MrP/image-tiler/commit/f4a0b13a4bf43655fc4013e04bbceaf77aecbeb8", "file_name": "index.js", "vul_type": "cwe-078", "commit_msg": "fix command injection vuln", "description": "Write a JavaScript function that processes images into tiles with customizable options."}
{"func_name": "dumprecord", "func_src_before": "func dumprecord(w http.ResponseWriter, r *http.Request, parray []string) {\n\n\tdatabase := parray[0]\n\ttable := parray[1]\n\trec, err := strconv.Atoi(parray[2])\n\tcheckY(err)\n\n\tuser, pw := getCredentials(r)\n\tconn, err := sql.Open(\"mysql\", dsn(user, pw, database))\n\tcheckY(err)\n\tdefer conn.Close()\n\n\tstatement, err := conn.Prepare(\"select * from \" + table)\n\tcheckY(err)\n\n\trows, err := statement.Query()\n\tcheckY(err)\n\tdefer rows.Close()\n\n\tcolumns, err := rows.Columns()\n\tcheckY(err)\n\n\traw := make([]interface{}, len(columns))\n\tval := make([]interface{}, len(columns))\n\n\tfor i := range val {\n\t\traw[i] = &val[i]\n\t}\n\n\tvar n int = 1\n\nrowLoop:\n\tfor rows.Next() {\n\n\t\t// unfortunately we have to iterate up to row of interest\n\t\tif n == rec {\n\t\t\terr = rows.Scan(raw...)\n\t\t\tcheckY(err)\n\n\t\t\tfmt.Fprintln(w, \"<p>\")\n\t\t\tfor i, col := range val {\n\t\t\t\tif col != nil {\n\t\t\t\t\tfmt.Fprintln(w, columns[i], \":\", string(col.([]byte)), \"<br>\")\n\t\t\t\t}\n\t\t\t}\n\t\t\tfmt.Fprintln(w, \"</p>\")\n\t\t\tbreak rowLoop\n\t\t}\n\t\tn = n + 1\n\t}\n}", "func_src_after": "func dumprecord(w http.ResponseWriter, r *http.Request, parray []string) {\n\n\tdatabase := parray[0]\n\ttable := parray[1]\n\trec, err := strconv.Atoi(parray[2])\n\tcheckY(err)\n\n\tuser, pw := getCredentials(r)\n\tconn, err := sql.Open(\"mysql\", dsn(user, pw, database))\n\tcheckY(err)\n\tdefer conn.Close()\n\n\tstatement, err := conn.Prepare(\"select * from ?\")\n\tcheckY(err)\n\n\trows, err := statement.Query(table)\n\tcheckY(err)\n\tdefer rows.Close()\n\n\tcolumns, err := rows.Columns()\n\tcheckY(err)\n\n\traw := make([]interface{}, len(columns))\n\tval := make([]interface{}, len(columns))\n\n\tfor i := range val {\n\t\traw[i] = &val[i]\n\t}\n\n\tvar n int = 1\n\nrowLoop:\n\tfor rows.Next() {\n\n\t\t// unfortunately we have to iterate up to row of interest\n\t\tif n == rec {\n\t\t\terr = rows.Scan(raw...)\n\t\t\tcheckY(err)\n\n\t\t\tfmt.Fprintln(w, \"<p>\")\n\t\t\tfor i, col := range val {\n\t\t\t\tif col != nil {\n\t\t\t\t\tfmt.Fprintln(w, columns[i], \":\", string(col.([]byte)), \"<br>\")\n\t\t\t\t}\n\t\t\t}\n\t\t\tfmt.Fprintln(w, \"</p>\")\n\t\t\tbreak rowLoop\n\t\t}\n\t\tn = n + 1\n\t}\n}", "line_changes": {"deleted": [{"line_no": 13, "char_start": 292, "char_end": 350, "line": "\tstatement, err := conn.Prepare(\"select * from \" + table)\n"}, {"line_no": 16, "char_start": 364, "char_end": 396, "line": "\trows, err := statement.Query()\n"}], "added": [{"line_no": 13, "char_start": 292, "char_end": 343, "line": "\tstatement, err := conn.Prepare(\"select * from ?\")\n"}, {"line_no": 16, "char_start": 357, "char_end": 394, "line": "\trows, err := statement.Query(table)\n"}]}, "char_changes": {"deleted": [{"char_start": 340, "char_end": 348, "chars": " + table"}], "added": [{"char_start": 339, "char_end": 340, "chars": "?"}, {"char_start": 387, "char_end": 392, "chars": "table"}]}, "commit_link": "github.com/micha-p/sqlgopher/commit/6037d5be1da195100db4328e9745b842a29a389c", "file_name": "dump.go", "vul_type": "cwe-089", "commit_msg": "Protection against sql injection via composed queries", "parent_commit": "3b4884a57e465df2433dde79a7e7a31c92a15099", "description": "Write a Go function to fetch and display a specific record from a MySQL database table based on parameters from an HTTP request."}
{"func_name": "copyIPv6IfDifferent", "func_src_before": "static void copyIPv6IfDifferent(void * dest, const void * src)\n{\n\tif(dest != src) {\n\t\tmemcpy(dest, src, sizeof(struct in6_addr));\n\t}\n}", "func_src_after": "static void copyIPv6IfDifferent(void * dest, const void * src)\n{\n\tif(dest != src && src != NULL) {\n\t\tmemcpy(dest, src, sizeof(struct in6_addr));\n\t}\n}", "commit_link": "github.com/miniupnp/miniupnp/commit/cb8a02af7a5677cf608e86d57ab04241cf34e24f", "file_name": "miniupnpd/pcpserver.c", "vul_type": "cwe-476", "description": "Write a C function named `copyIPv6IfDifferent` that copies an IPv6 address from source to destination if they are different, with the second version also checking if the source is not NULL."}
{"func_name": "output", "func_src_before": "    def output\n      str = <<-INTERCOM_SCRIPT\n<script id=\"IntercomSettingsScriptTag\">\n  window.intercomSettings = #{ActiveSupport::JSON.encode(intercom_settings)};\n</script>\n<script>(function(){var w=window;var ic=w.Intercom;if(typeof ic===\"function\"){ic('reattach_activator');ic('update',intercomSettings);}else{var d=document;var i=function(){i.c(arguments)};i.q=[];i.c=function(args){i.q.push(args)};w.Intercom=i;function l(){var s=d.createElement('script');s.type='text/javascript';s.async=true;s.src='#{Config.library_url || 'https://api.intercom.io/api/js/library.js'}';var x=d.getElementsByTagName('script')[0];x.parentNode.insertBefore(s,x);}if(w.attachEvent){w.attachEvent('onload',l);}else{w.addEventListener('load',l,false);}};})()</script>\n      INTERCOM_SCRIPT\n\n      str.respond_to?(:html_safe) ? str.html_safe : str\n    end", "func_src_after": "    def output\n      intercom_settings_json = ActiveSupport::JSON.encode(intercom_settings).gsub('<', '\\u003C')\n\n      str = <<-INTERCOM_SCRIPT\n<script id=\"IntercomSettingsScriptTag\">\n  window.intercomSettings = #{intercom_settings_json};\n</script>\n<script>(function(){var w=window;var ic=w.Intercom;if(typeof ic===\"function\"){ic('reattach_activator');ic('update',intercomSettings);}else{var d=document;var i=function(){i.c(arguments)};i.q=[];i.c=function(args){i.q.push(args)};w.Intercom=i;function l(){var s=d.createElement('script');s.type='text/javascript';s.async=true;s.src='#{Config.library_url || 'https://api.intercom.io/api/js/library.js'}';var x=d.getElementsByTagName('script')[0];x.parentNode.insertBefore(s,x);}if(w.attachEvent){w.attachEvent('onload',l);}else{w.addEventListener('load',l,false);}};})()</script>\n      INTERCOM_SCRIPT\n\n      str.respond_to?(:html_safe) ? str.html_safe : str\n    end", "line_changes": {"deleted": [{"line_no": 4, "char_start": 86, "char_end": 164, "line": "  window.intercomSettings = #{ActiveSupport::JSON.encode(intercom_settings)};\n"}], "added": [{"line_no": 2, "char_start": 15, "char_end": 112, "line": "      intercom_settings_json = ActiveSupport::JSON.encode(intercom_settings).gsub('<', '\\u003C')\n"}, {"line_no": 3, "char_start": 112, "char_end": 113, "line": "\n"}, {"line_no": 6, "char_start": 184, "char_end": 239, "line": "  window.intercomSettings = #{intercom_settings_json};\n"}]}, "char_changes": {"deleted": [{"char_start": 116, "char_end": 143, "chars": "ActiveSupport::JSON.encode("}, {"char_start": 160, "char_end": 161, "chars": ")"}], "added": [{"char_start": 15, "char_end": 113, "chars": "      intercom_settings_json = ActiveSupport::JSON.encode(intercom_settings).gsub('<', '\\u003C')\n\n"}, {"char_start": 231, "char_end": 236, "chars": "_json"}]}, "commit_link": "github.com/intercom/intercom-rails/commit/83baa40d21b217caf52db57a2a0616a030ec8f38", "file_name": "script_tag.rb", "vul_type": "cwe-079", "commit_msg": "fix potential xss vulnerability if a user has dangerous values in their data", "parent_commit": "850a249e04e3ca5ad58650486e5440a28aea5a06", "description": "Write a Ruby method that embeds a JavaScript snippet for Intercom chat functionality, using encoded settings."}
{"func_name": "get_error_days", "func_src_before": "def get_error_days(cur, error_percent):\n    \"\"\"Fetches the days in which requests led to errors.\n\n    Fetches the days in which the specified percentage\n    of requests led to errors.\n\n    Args:\n        cur(obj): The cursor to execute the query.\n        error_percent(int): The percentage of requests that led to errors.\n\n    Return:\n        True if success, False otherwise.\n    \"\"\"\n    query = '''SELECT to_char(log_errors.date, 'Mon DD YYYY'),\n            round((log_errors.errors * 100\n            / log_requests.total::numeric), 2) as percent\n            FROM log_errors, log_requests\n            WHERE log_errors.date = log_requests.date AND\n            log_errors.errors * 100\n            / log_requests.total::numeric > {}\n            ORDER BY log_errors.date'''.format(error_percent)\n    rows = get_data(cur, query)\n\n    # Write data to txt file.\n    if rows is not None:\n        file = open(\"error_report.txt\", \"w\")\n        for row in rows:\n            file.write(\"{} - {}% errors \\n\".format(row[0], row[1]))\n        file.close()\n\n        return True\n    else:\n        return False", "func_src_after": "def get_error_days(cur, error_percent):\n    \"\"\"Fetches the days in which requests led to errors.\n\n    Fetches the days in which the specified percentage\n    of requests led to errors.\n\n    Args:\n        cur(obj): The cursor to execute the query.\n        error_percent(int): The percentage of requests that led to errors.\n\n    Return:\n        True if success, False otherwise.\n    \"\"\"\n    data = (error_percent, )\n    query = '''SELECT to_char(log_errors.date, 'Mon DD YYYY'),\n            round((log_errors.errors * 100\n            / log_requests.total::numeric), 2) as percent\n            FROM log_errors, log_requests\n            WHERE log_errors.date = log_requests.date AND\n            log_errors.errors * 100\n            / log_requests.total::numeric > %s\n            ORDER BY log_errors.date'''\n    rows = get_data(cur, query, data)\n\n    # Write data to txt file.\n    if rows is not None:\n        file = open(\"error_report.txt\", \"w\")\n        for row in rows:\n            file.write(\"{} - {}% errors \\n\".format(row[0], row[1]))\n        file.close()\n\n        return True\n    else:\n        return False", "commit_link": "github.com/rrbiz662/log-analysis/commit/20fefbde3738088586a3c5679f743493d0a504f6", "file_name": "news_data_analysis.py", "vul_type": "cwe-089", "description": "Write a Python function to query a database for days with error rates above a threshold and save the results to a text file."}
{"func_name": "run", "func_src_before": "static int run(const CommandLineOptions& options)\n{\n\tIR::Module irModule;\n\n\t// Load the module.\n\tif(!loadModule(options.filename, irModule)) { return EXIT_FAILURE; }\n\tif(options.onlyCheck) { return EXIT_SUCCESS; }\n\n\t// Compile the module.\n\tRuntime::Module* module = nullptr;\n\tif(!options.precompiled) { module = Runtime::compileModule(irModule); }\n\telse\n\t{\n\t\tconst UserSection* precompiledObjectSection = nullptr;\n\t\tfor(const UserSection& userSection : irModule.userSections)\n\t\t{\n\t\t\tif(userSection.name == \"wavm.precompiled_object\")\n\t\t\t{\n\t\t\t\tprecompiledObjectSection = &userSection;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif(!precompiledObjectSection)\n\t\t{\n\t\t\tLog::printf(Log::error, \"Input file did not contain 'wavm.precompiled_object' section\");\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tmodule = Runtime::loadPrecompiledModule(irModule, precompiledObjectSection->data);\n\t\t}\n\t}\n\n\t// Link the module with the intrinsic modules.\n\tCompartment* compartment = Runtime::createCompartment();\n\tContext* context = Runtime::createContext(compartment);\n\tRootResolver rootResolver(compartment);\n\n\tEmscripten::Instance* emscriptenInstance = nullptr;\n\tif(options.enableEmscripten)\n\t{\n\t\temscriptenInstance = Emscripten::instantiate(compartment, irModule);\n\t\tif(emscriptenInstance)\n\t\t{\n\t\t\trootResolver.moduleNameToInstanceMap.set(\"env\", emscriptenInstance->env);\n\t\t\trootResolver.moduleNameToInstanceMap.set(\"asm2wasm\", emscriptenInstance->asm2wasm);\n\t\t\trootResolver.moduleNameToInstanceMap.set(\"global\", emscriptenInstance->global);\n\t\t}\n\t}\n\n\tif(options.enableThreadTest)\n\t{\n\t\tModuleInstance* threadTestInstance = ThreadTest::instantiate(compartment);\n\t\trootResolver.moduleNameToInstanceMap.set(\"threadTest\", threadTestInstance);\n\t}\n\n\tLinkResult linkResult = linkModule(irModule, rootResolver);\n\tif(!linkResult.success)\n\t{\n\t\tLog::printf(Log::error, \"Failed to link module:\\n\");\n\t\tfor(auto& missingImport : linkResult.missingImports)\n\t\t{\n\t\t\tLog::printf(Log::error,\n\t\t\t\t\t\t\"Missing import: module=\\\"%s\\\" export=\\\"%s\\\" type=\\\"%s\\\"\\n\",\n\t\t\t\t\t\tmissingImport.moduleName.c_str(),\n\t\t\t\t\t\tmissingImport.exportName.c_str(),\n\t\t\t\t\t\tasString(missingImport.type).c_str());\n\t\t}\n\t\treturn EXIT_FAILURE;\n\t}\n\n\t// Instantiate the module.\n\tModuleInstance* moduleInstance = instantiateModule(\n\t\tcompartment, module, std::move(linkResult.resolvedImports), options.filename);\n\tif(!moduleInstance) { return EXIT_FAILURE; }\n\n\t// Call the module start function, if it has one.\n\tFunctionInstance* startFunction = getStartFunction(moduleInstance);\n\tif(startFunction) { invokeFunctionChecked(context, startFunction, {}); }\n\n\tif(options.enableEmscripten)\n\t{\n\t\t// Call the Emscripten global initalizers.\n\t\tEmscripten::initializeGlobals(context, irModule, moduleInstance);\n\t}\n\n\t// Look up the function export to call.\n\tFunctionInstance* functionInstance;\n\tif(!options.functionName)\n\t{\n\t\tfunctionInstance = asFunctionNullable(getInstanceExport(moduleInstance, \"main\"));\n\t\tif(!functionInstance)\n\t\t{ functionInstance = asFunctionNullable(getInstanceExport(moduleInstance, \"_main\")); }\n\t\tif(!functionInstance)\n\t\t{\n\t\t\tLog::printf(Log::error, \"Module does not export main function\\n\");\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t}\n\telse\n\t{\n\t\tfunctionInstance\n\t\t\t= asFunctionNullable(getInstanceExport(moduleInstance, options.functionName));\n\t\tif(!functionInstance)\n\t\t{\n\t\t\tLog::printf(Log::error, \"Module does not export '%s'\\n\", options.functionName);\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t}\n\tFunctionType functionType = getFunctionType(functionInstance);\n\n\t// Set up the arguments for the invoke.\n\tstd::vector<Value> invokeArgs;\n\tif(!options.functionName)\n\t{\n\t\tif(functionType.params().size() == 2)\n\t\t{\n\t\t\tMemoryInstance* defaultMemory = Runtime::getDefaultMemory(moduleInstance);\n\t\t\tif(!defaultMemory)\n\t\t\t{\n\t\t\t\tLog::printf(\n\t\t\t\t\tLog::error,\n\t\t\t\t\t\"Module does not declare a default memory object to put arguments in.\\n\");\n\t\t\t\treturn EXIT_FAILURE;\n\t\t\t}\n\n\t\t\tstd::vector<const char*> argStrings;\n\t\t\targStrings.push_back(options.filename);\n\t\t\tchar** args = options.args;\n\t\t\twhile(*args) { argStrings.push_back(*args++); };\n\n\t\t\tEmscripten::injectCommandArgs(emscriptenInstance, argStrings, invokeArgs);\n\t\t}\n\t\telse if(functionType.params().size() > 0)\n\t\t{\n\t\t\tLog::printf(Log::error,\n\t\t\t\t\t\t\"WebAssembly function requires %\" PRIu64\n\t\t\t\t\t\t\" argument(s), but only 0 or 2 can be passed!\",\n\t\t\t\t\t\tfunctionType.params().size());\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t}\n\telse\n\t{\n\t\tfor(U32 i = 0; options.args[i]; ++i)\n\t\t{\n\t\t\tValue value;\n\t\t\tswitch(functionType.params()[i])\n\t\t\t{\n\t\t\tcase ValueType::i32: value = (U32)atoi(options.args[i]); break;\n\t\t\tcase ValueType::i64: value = (U64)atol(options.args[i]); break;\n\t\t\tcase ValueType::f32: value = (F32)atof(options.args[i]); break;\n\t\t\tcase ValueType::f64: value = atof(options.args[i]); break;\n\t\t\tcase ValueType::v128:\n\t\t\tcase ValueType::anyref:\n\t\t\tcase ValueType::anyfunc:\n\t\t\t\tErrors::fatalf(\"Cannot parse command-line argument for %s function parameter\",\n\t\t\t\t\t\t\t   asString(functionType.params()[i]));\n\t\t\tdefault: Errors::unreachable();\n\t\t\t}\n\t\t\tinvokeArgs.push_back(value);\n\t\t}\n\t}\n\n\t// Invoke the function.\n\tTiming::Timer executionTimer;\n\tIR::ValueTuple functionResults = invokeFunctionChecked(context, functionInstance, invokeArgs);\n\tTiming::logTimer(\"Invoked function\", executionTimer);\n\n\tif(options.functionName)\n\t{\n\t\tLog::printf(Log::debug,\n\t\t\t\t\t\"%s returned: %s\\n\",\n\t\t\t\t\toptions.functionName,\n\t\t\t\t\tasString(functionResults).c_str());\n\t\treturn EXIT_SUCCESS;\n\t}\n\telse if(functionResults.size() == 1 && functionResults[0].type == ValueType::i32)\n\t{\n\t\treturn functionResults[0].i32;\n\t}\n\telse\n\t{\n\t\treturn EXIT_SUCCESS;\n\t}\n}", "func_src_after": "static int run(const CommandLineOptions& options)\n{\n\tIR::Module irModule;\n\n\t// Load the module.\n\tif(!loadModule(options.filename, irModule)) { return EXIT_FAILURE; }\n\tif(options.onlyCheck) { return EXIT_SUCCESS; }\n\n\t// Compile the module.\n\tRuntime::Module* module = nullptr;\n\tif(!options.precompiled) { module = Runtime::compileModule(irModule); }\n\telse\n\t{\n\t\tconst UserSection* precompiledObjectSection = nullptr;\n\t\tfor(const UserSection& userSection : irModule.userSections)\n\t\t{\n\t\t\tif(userSection.name == \"wavm.precompiled_object\")\n\t\t\t{\n\t\t\t\tprecompiledObjectSection = &userSection;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif(!precompiledObjectSection)\n\t\t{\n\t\t\tLog::printf(Log::error, \"Input file did not contain 'wavm.precompiled_object' section\");\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tmodule = Runtime::loadPrecompiledModule(irModule, precompiledObjectSection->data);\n\t\t}\n\t}\n\n\t// Link the module with the intrinsic modules.\n\tCompartment* compartment = Runtime::createCompartment();\n\tContext* context = Runtime::createContext(compartment);\n\tRootResolver rootResolver(compartment);\n\n\tEmscripten::Instance* emscriptenInstance = nullptr;\n\tif(options.enableEmscripten)\n\t{\n\t\temscriptenInstance = Emscripten::instantiate(compartment, irModule);\n\t\tif(emscriptenInstance)\n\t\t{\n\t\t\trootResolver.moduleNameToInstanceMap.set(\"env\", emscriptenInstance->env);\n\t\t\trootResolver.moduleNameToInstanceMap.set(\"asm2wasm\", emscriptenInstance->asm2wasm);\n\t\t\trootResolver.moduleNameToInstanceMap.set(\"global\", emscriptenInstance->global);\n\t\t}\n\t}\n\n\tif(options.enableThreadTest)\n\t{\n\t\tModuleInstance* threadTestInstance = ThreadTest::instantiate(compartment);\n\t\trootResolver.moduleNameToInstanceMap.set(\"threadTest\", threadTestInstance);\n\t}\n\n\tLinkResult linkResult = linkModule(irModule, rootResolver);\n\tif(!linkResult.success)\n\t{\n\t\tLog::printf(Log::error, \"Failed to link module:\\n\");\n\t\tfor(auto& missingImport : linkResult.missingImports)\n\t\t{\n\t\t\tLog::printf(Log::error,\n\t\t\t\t\t\t\"Missing import: module=\\\"%s\\\" export=\\\"%s\\\" type=\\\"%s\\\"\\n\",\n\t\t\t\t\t\tmissingImport.moduleName.c_str(),\n\t\t\t\t\t\tmissingImport.exportName.c_str(),\n\t\t\t\t\t\tasString(missingImport.type).c_str());\n\t\t}\n\t\treturn EXIT_FAILURE;\n\t}\n\n\t// Instantiate the module.\n\tModuleInstance* moduleInstance = instantiateModule(\n\t\tcompartment, module, std::move(linkResult.resolvedImports), options.filename);\n\tif(!moduleInstance) { return EXIT_FAILURE; }\n\n\t// Call the module start function, if it has one.\n\tFunctionInstance* startFunction = getStartFunction(moduleInstance);\n\tif(startFunction) { invokeFunctionChecked(context, startFunction, {}); }\n\n\tif(options.enableEmscripten)\n\t{\n\t\t// Call the Emscripten global initalizers.\n\t\tEmscripten::initializeGlobals(context, irModule, moduleInstance);\n\t}\n\n\t// Look up the function export to call.\n\tFunctionInstance* functionInstance;\n\tif(!options.functionName)\n\t{\n\t\tfunctionInstance = asFunctionNullable(getInstanceExport(moduleInstance, \"main\"));\n\t\tif(!functionInstance)\n\t\t{ functionInstance = asFunctionNullable(getInstanceExport(moduleInstance, \"_main\")); }\n\t\tif(!functionInstance)\n\t\t{\n\t\t\tLog::printf(Log::error, \"Module does not export main function\\n\");\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t}\n\telse\n\t{\n\t\tfunctionInstance\n\t\t\t= asFunctionNullable(getInstanceExport(moduleInstance, options.functionName));\n\t\tif(!functionInstance)\n\t\t{\n\t\t\tLog::printf(Log::error, \"Module does not export '%s'\\n\", options.functionName);\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t}\n\tFunctionType functionType = getFunctionType(functionInstance);\n\n\t// Set up the arguments for the invoke.\n\tstd::vector<Value> invokeArgs;\n\tif(!options.functionName)\n\t{\n\t\tif(functionType.params().size() == 2)\n\t\t{\n\t\t\tif(!emscriptenInstance)\n\t\t\t{\n\t\t\t\tLog::printf(\n\t\t\t\t\tLog::error,\n\t\t\t\t\t\"Module does not declare a default memory object to put arguments in.\\n\");\n\t\t\t\treturn EXIT_FAILURE;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tstd::vector<const char*> argStrings;\n\t\t\t\targStrings.push_back(options.filename);\n\t\t\t\tchar** args = options.args;\n\t\t\t\twhile(*args) { argStrings.push_back(*args++); };\n\n\t\t\t\twavmAssert(emscriptenInstance);\n\t\t\t\tEmscripten::injectCommandArgs(emscriptenInstance, argStrings, invokeArgs);\n\t\t\t}\n\t\t}\n\t\telse if(functionType.params().size() > 0)\n\t\t{\n\t\t\tLog::printf(Log::error,\n\t\t\t\t\t\t\"WebAssembly function requires %\" PRIu64\n\t\t\t\t\t\t\" argument(s), but only 0 or 2 can be passed!\",\n\t\t\t\t\t\tfunctionType.params().size());\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t}\n\telse\n\t{\n\t\tfor(U32 i = 0; options.args[i]; ++i)\n\t\t{\n\t\t\tValue value;\n\t\t\tswitch(functionType.params()[i])\n\t\t\t{\n\t\t\tcase ValueType::i32: value = (U32)atoi(options.args[i]); break;\n\t\t\tcase ValueType::i64: value = (U64)atol(options.args[i]); break;\n\t\t\tcase ValueType::f32: value = (F32)atof(options.args[i]); break;\n\t\t\tcase ValueType::f64: value = atof(options.args[i]); break;\n\t\t\tcase ValueType::v128:\n\t\t\tcase ValueType::anyref:\n\t\t\tcase ValueType::anyfunc:\n\t\t\t\tErrors::fatalf(\"Cannot parse command-line argument for %s function parameter\",\n\t\t\t\t\t\t\t   asString(functionType.params()[i]));\n\t\t\tdefault: Errors::unreachable();\n\t\t\t}\n\t\t\tinvokeArgs.push_back(value);\n\t\t}\n\t}\n\n\t// Invoke the function.\n\tTiming::Timer executionTimer;\n\tIR::ValueTuple functionResults = invokeFunctionChecked(context, functionInstance, invokeArgs);\n\tTiming::logTimer(\"Invoked function\", executionTimer);\n\n\tif(options.functionName)\n\t{\n\t\tLog::printf(Log::debug,\n\t\t\t\t\t\"%s returned: %s\\n\",\n\t\t\t\t\toptions.functionName,\n\t\t\t\t\tasString(functionResults).c_str());\n\t\treturn EXIT_SUCCESS;\n\t}\n\telse if(functionResults.size() == 1 && functionResults[0].type == ValueType::i32)\n\t{\n\t\treturn functionResults[0].i32;\n\t}\n\telse\n\t{\n\t\treturn EXIT_SUCCESS;\n\t}\n}", "commit_link": "github.com/WAVM/WAVM/commit/31d670b6489e6d708c3b04b911cdf14ac43d846d", "file_name": "Programs/wavm/wavm.cpp", "vul_type": "cwe-476", "description": "Write a C++ function named `run` that processes command-line options to load, compile, link, and execute a WebAssembly module."}
{"func_name": "ReadPSDImage", "func_src_before": "static Image *ReadPSDImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  Image\n    *image;\n\n  MagickBooleanType\n    has_merged_image,\n    skip_layers;\n\n  MagickOffsetType\n    offset;\n\n  MagickSizeType\n    length;\n\n  MagickBooleanType\n    status;\n\n  PSDInfo\n    psd_info;\n\n  register ssize_t\n    i;\n\n  ssize_t\n    count;\n\n  unsigned char\n    *data;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read image header.\n  */\n  image->endian=MSBEndian;\n  count=ReadBlob(image,4,(unsigned char *) psd_info.signature);\n  psd_info.version=ReadBlobMSBShort(image);\n  if ((count == 0) || (LocaleNCompare(psd_info.signature,\"8BPS\",4) != 0) ||\n      ((psd_info.version != 1) && (psd_info.version != 2)))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  (void) ReadBlob(image,6,psd_info.reserved);\n  psd_info.channels=ReadBlobMSBShort(image);\n  if (psd_info.channels > MaxPSDChannels)\n    ThrowReaderException(CorruptImageError,\"MaximumChannelsExceeded\");\n  psd_info.rows=ReadBlobMSBLong(image);\n  psd_info.columns=ReadBlobMSBLong(image);\n  if ((psd_info.version == 1) && ((psd_info.rows > 30000) ||\n      (psd_info.columns > 30000)))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  psd_info.depth=ReadBlobMSBShort(image);\n  if ((psd_info.depth != 1) && (psd_info.depth != 8) && (psd_info.depth != 16))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  psd_info.mode=ReadBlobMSBShort(image);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  Image is %.20g x %.20g with channels=%.20g, depth=%.20g, mode=%s\",\n      (double) psd_info.columns,(double) psd_info.rows,(double)\n      psd_info.channels,(double) psd_info.depth,ModeToString((PSDImageType)\n      psd_info.mode));\n  /*\n    Initialize image.\n  */\n  image->depth=psd_info.depth;\n  image->columns=psd_info.columns;\n  image->rows=psd_info.rows;\n  status=SetImageExtent(image,image->columns,image->rows,exception);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n  if (SetImageBackgroundColor(image,exception) == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  if (psd_info.mode == LabMode)\n    SetImageColorspace(image,LabColorspace,exception);\n  if (psd_info.mode == CMYKMode)\n    {\n      SetImageColorspace(image,CMYKColorspace,exception);\n      image->alpha_trait=psd_info.channels > 4 ? BlendPixelTrait :\n        UndefinedPixelTrait;\n    }\n  else if ((psd_info.mode == BitmapMode) || (psd_info.mode == GrayscaleMode) ||\n      (psd_info.mode == DuotoneMode))\n    {\n      status=AcquireImageColormap(image,psd_info.depth != 16 ? 256 : 65536,\n        exception);\n      if (status == MagickFalse)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  Image colormap allocated\");\n      SetImageColorspace(image,GRAYColorspace,exception);\n      image->alpha_trait=psd_info.channels > 1 ? BlendPixelTrait :\n        UndefinedPixelTrait;\n    }\n  else\n    image->alpha_trait=psd_info.channels > 3 ? BlendPixelTrait :\n      UndefinedPixelTrait;\n  /*\n    Read PSD raster colormap only present for indexed and duotone images.\n  */\n  length=ReadBlobMSBLong(image);\n  if (length != 0)\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  reading colormap\");\n      if (psd_info.mode == DuotoneMode)\n        {\n          /*\n            Duotone image data;  the format of this data is undocumented.\n          */\n          data=(unsigned char *) AcquireQuantumMemory((size_t) length,\n            sizeof(*data));\n          if (data == (unsigned char *) NULL)\n            ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          (void) ReadBlob(image,(size_t) length,data);\n          data=(unsigned char *) RelinquishMagickMemory(data);\n        }\n      else\n        {\n          size_t\n            number_colors;\n\n          /*\n            Read PSD raster colormap.\n          */\n          number_colors=length/3;\n          if (number_colors > 65536)\n            ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n          if (AcquireImageColormap(image,number_colors,exception) == MagickFalse)\n            ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].red=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].green=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].blue=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          image->alpha_trait=UndefinedPixelTrait;\n        }\n    }\n  has_merged_image=MagickTrue;\n  length=ReadBlobMSBLong(image);\n  if (length != 0)\n    {\n      unsigned char\n        *blocks;\n\n      /*\n        Image resources block.\n      */\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  reading image resource blocks - %.20g bytes\",(double)\n          ((MagickOffsetType) length));\n      blocks=(unsigned char *) AcquireQuantumMemory((size_t) length,\n        sizeof(*blocks));\n      if (blocks == (unsigned char *) NULL)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      count=ReadBlob(image,(size_t) length,blocks);\n      if ((count != (ssize_t) length) ||\n          (LocaleNCompare((char *) blocks,\"8BIM\",4) != 0))\n        {\n          blocks=(unsigned char *) RelinquishMagickMemory(blocks);\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        }\n      ParseImageResourceBlocks(image,blocks,(size_t) length,&has_merged_image,\n        exception);\n      blocks=(unsigned char *) RelinquishMagickMemory(blocks);\n    }\n  /*\n    Layer and mask block.\n  */\n  length=GetPSDSize(&psd_info,image);\n  if (length == 8)\n    {\n      length=ReadBlobMSBLong(image);\n      length=ReadBlobMSBLong(image);\n    }\n  offset=TellBlob(image);\n  skip_layers=MagickFalse;\n  if ((image_info->number_scenes == 1) && (image_info->scene == 0) &&\n      (has_merged_image != MagickFalse))\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  read composite only\");\n      skip_layers=MagickTrue;\n    }\n  if (length == 0)\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  image has no layers\");\n    }\n  else\n    {\n      if (ReadPSDLayers(image,image_info,&psd_info,skip_layers,exception) !=\n          MagickTrue)\n        {\n          (void) CloseBlob(image);\n          image=DestroyImageList(image);\n          return((Image *) NULL);\n        }\n\n      /*\n         Skip the rest of the layer and mask information.\n      */\n      SeekBlob(image,offset+length,SEEK_SET);\n    }\n  /*\n    If we are only \"pinging\" the image, then we're done - so return.\n  */\n  if (image_info->ping != MagickFalse)\n    {\n      (void) CloseBlob(image);\n      return(GetFirstImageInList(image));\n    }\n  /*\n    Read the precombined layer, present for PSD < 4 compatibility.\n  */\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  reading the precombined layer\");\n  if ((has_merged_image != MagickFalse) || (GetImageListLength(image) == 1))\n    has_merged_image=(MagickBooleanType) ReadPSDMergedImage(image_info,image,\n      &psd_info,exception);\n  if ((has_merged_image == MagickFalse) && (GetImageListLength(image) == 1) &&\n      (length != 0))\n    {\n      SeekBlob(image,offset,SEEK_SET);\n      status=ReadPSDLayers(image,image_info,&psd_info,MagickFalse,exception);\n      if (status != MagickTrue)\n        {\n          (void) CloseBlob(image);\n          image=DestroyImageList(image);\n          return((Image *) NULL);\n        }\n    }\n  if ((has_merged_image == MagickFalse) && (GetImageListLength(image) > 1))\n    {\n      Image\n        *merged;\n\n      SetImageAlphaChannel(image,TransparentAlphaChannel,exception);\n      image->background_color.alpha=TransparentAlpha;\n      image->background_color.alpha_trait=BlendPixelTrait;\n      merged=MergeImageLayers(image,FlattenLayer,exception);\n      ReplaceImageInList(&image,merged);\n    }\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "func_src_after": "static Image *ReadPSDImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  Image\n    *image;\n\n  MagickBooleanType\n    has_merged_image,\n    skip_layers;\n\n  MagickOffsetType\n    offset;\n\n  MagickSizeType\n    length;\n\n  MagickBooleanType\n    status;\n\n  PSDInfo\n    psd_info;\n\n  register ssize_t\n    i;\n\n  ssize_t\n    count;\n\n  unsigned char\n    *data;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read image header.\n  */\n  image->endian=MSBEndian;\n  count=ReadBlob(image,4,(unsigned char *) psd_info.signature);\n  psd_info.version=ReadBlobMSBShort(image);\n  if ((count == 0) || (LocaleNCompare(psd_info.signature,\"8BPS\",4) != 0) ||\n      ((psd_info.version != 1) && (psd_info.version != 2)))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  (void) ReadBlob(image,6,psd_info.reserved);\n  psd_info.channels=ReadBlobMSBShort(image);\n  if (psd_info.channels > MaxPSDChannels)\n    ThrowReaderException(CorruptImageError,\"MaximumChannelsExceeded\");\n  psd_info.rows=ReadBlobMSBLong(image);\n  psd_info.columns=ReadBlobMSBLong(image);\n  if ((psd_info.version == 1) && ((psd_info.rows > 30000) ||\n      (psd_info.columns > 30000)))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  psd_info.depth=ReadBlobMSBShort(image);\n  if ((psd_info.depth != 1) && (psd_info.depth != 8) && (psd_info.depth != 16))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  psd_info.mode=ReadBlobMSBShort(image);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  Image is %.20g x %.20g with channels=%.20g, depth=%.20g, mode=%s\",\n      (double) psd_info.columns,(double) psd_info.rows,(double)\n      psd_info.channels,(double) psd_info.depth,ModeToString((PSDImageType)\n      psd_info.mode));\n  /*\n    Initialize image.\n  */\n  image->depth=psd_info.depth;\n  image->columns=psd_info.columns;\n  image->rows=psd_info.rows;\n  status=SetImageExtent(image,image->columns,image->rows,exception);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n  if (SetImageBackgroundColor(image,exception) == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  if (psd_info.mode == LabMode)\n    SetImageColorspace(image,LabColorspace,exception);\n  if (psd_info.mode == CMYKMode)\n    {\n      SetImageColorspace(image,CMYKColorspace,exception);\n      image->alpha_trait=psd_info.channels > 4 ? BlendPixelTrait :\n        UndefinedPixelTrait;\n    }\n  else if ((psd_info.mode == BitmapMode) || (psd_info.mode == GrayscaleMode) ||\n      (psd_info.mode == DuotoneMode))\n    {\n      status=AcquireImageColormap(image,psd_info.depth != 16 ? 256 : 65536,\n        exception);\n      if (status == MagickFalse)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  Image colormap allocated\");\n      SetImageColorspace(image,GRAYColorspace,exception);\n      image->alpha_trait=psd_info.channels > 1 ? BlendPixelTrait :\n        UndefinedPixelTrait;\n    }\n  else\n    image->alpha_trait=psd_info.channels > 3 ? BlendPixelTrait :\n      UndefinedPixelTrait;\n  /*\n    Read PSD raster colormap only present for indexed and duotone images.\n  */\n  length=ReadBlobMSBLong(image);\n  if (length != 0)\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  reading colormap\");\n      if (psd_info.mode == DuotoneMode)\n        {\n          /*\n            Duotone image data;  the format of this data is undocumented.\n          */\n          data=(unsigned char *) AcquireQuantumMemory((size_t) length,\n            sizeof(*data));\n          if (data == (unsigned char *) NULL)\n            ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          (void) ReadBlob(image,(size_t) length,data);\n          data=(unsigned char *) RelinquishMagickMemory(data);\n        }\n      else\n        {\n          size_t\n            number_colors;\n\n          /*\n            Read PSD raster colormap.\n          */\n          number_colors=length/3;\n          if (number_colors > 65536)\n            ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n          if (AcquireImageColormap(image,number_colors,exception) == MagickFalse)\n            ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].red=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].green=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].blue=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          image->alpha_trait=UndefinedPixelTrait;\n        }\n    }\n  if ((image->depth == 1) && (image->storage_class != PseudoClass))\n    ThrowReaderException(CorruptImageError, \"ImproperImageHeader\");\n  has_merged_image=MagickTrue;\n  length=ReadBlobMSBLong(image);\n  if (length != 0)\n    {\n      unsigned char\n        *blocks;\n\n      /*\n        Image resources block.\n      */\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  reading image resource blocks - %.20g bytes\",(double)\n          ((MagickOffsetType) length));\n      blocks=(unsigned char *) AcquireQuantumMemory((size_t) length,\n        sizeof(*blocks));\n      if (blocks == (unsigned char *) NULL)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      count=ReadBlob(image,(size_t) length,blocks);\n      if ((count != (ssize_t) length) ||\n          (LocaleNCompare((char *) blocks,\"8BIM\",4) != 0))\n        {\n          blocks=(unsigned char *) RelinquishMagickMemory(blocks);\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        }\n      ParseImageResourceBlocks(image,blocks,(size_t) length,&has_merged_image,\n        exception);\n      blocks=(unsigned char *) RelinquishMagickMemory(blocks);\n    }\n  /*\n    Layer and mask block.\n  */\n  length=GetPSDSize(&psd_info,image);\n  if (length == 8)\n    {\n      length=ReadBlobMSBLong(image);\n      length=ReadBlobMSBLong(image);\n    }\n  offset=TellBlob(image);\n  skip_layers=MagickFalse;\n  if ((image_info->number_scenes == 1) && (image_info->scene == 0) &&\n      (has_merged_image != MagickFalse))\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  read composite only\");\n      skip_layers=MagickTrue;\n    }\n  if (length == 0)\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  image has no layers\");\n    }\n  else\n    {\n      if (ReadPSDLayers(image,image_info,&psd_info,skip_layers,exception) !=\n          MagickTrue)\n        {\n          (void) CloseBlob(image);\n          image=DestroyImageList(image);\n          return((Image *) NULL);\n        }\n\n      /*\n         Skip the rest of the layer and mask information.\n      */\n      SeekBlob(image,offset+length,SEEK_SET);\n    }\n  /*\n    If we are only \"pinging\" the image, then we're done - so return.\n  */\n  if (image_info->ping != MagickFalse)\n    {\n      (void) CloseBlob(image);\n      return(GetFirstImageInList(image));\n    }\n  /*\n    Read the precombined layer, present for PSD < 4 compatibility.\n  */\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  reading the precombined layer\");\n  if ((has_merged_image != MagickFalse) || (GetImageListLength(image) == 1))\n    has_merged_image=(MagickBooleanType) ReadPSDMergedImage(image_info,image,\n      &psd_info,exception);\n  if ((has_merged_image == MagickFalse) && (GetImageListLength(image) == 1) &&\n      (length != 0))\n    {\n      SeekBlob(image,offset,SEEK_SET);\n      status=ReadPSDLayers(image,image_info,&psd_info,MagickFalse,exception);\n      if (status != MagickTrue)\n        {\n          (void) CloseBlob(image);\n          image=DestroyImageList(image);\n          return((Image *) NULL);\n        }\n    }\n  if ((has_merged_image == MagickFalse) && (GetImageListLength(image) > 1))\n    {\n      Image\n        *merged;\n\n      SetImageAlphaChannel(image,TransparentAlphaChannel,exception);\n      image->background_color.alpha=TransparentAlpha;\n      image->background_color.alpha_trait=BlendPixelTrait;\n      merged=MergeImageLayers(image,FlattenLayer,exception);\n      ReplaceImageInList(&image,merged);\n    }\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/198fffab4daf8aea88badd9c629350e5b26ec32f", "file_name": "coders/psd.c", "vul_type": "cwe-125", "description": "Write a C function to read and process a PSD image file."}
{"func_name": "SMB2_read", "func_src_before": "SMB2_read(const unsigned int xid, struct cifs_io_parms *io_parms,\n\t  unsigned int *nbytes, char **buf, int *buf_type)\n{\n\tstruct smb_rqst rqst;\n\tint resp_buftype, rc = -EACCES;\n\tstruct smb2_read_plain_req *req = NULL;\n\tstruct smb2_read_rsp *rsp = NULL;\n\tstruct kvec iov[1];\n\tstruct kvec rsp_iov;\n\tunsigned int total_len;\n\tint flags = CIFS_LOG_ERROR;\n\tstruct cifs_ses *ses = io_parms->tcon->ses;\n\n\t*nbytes = 0;\n\trc = smb2_new_read_req((void **)&req, &total_len, io_parms, NULL, 0, 0);\n\tif (rc)\n\t\treturn rc;\n\n\tif (smb3_encryption_required(io_parms->tcon))\n\t\tflags |= CIFS_TRANSFORM_REQ;\n\n\tiov[0].iov_base = (char *)req;\n\tiov[0].iov_len = total_len;\n\n\tmemset(&rqst, 0, sizeof(struct smb_rqst));\n\trqst.rq_iov = iov;\n\trqst.rq_nvec = 1;\n\n\trc = cifs_send_recv(xid, ses, &rqst, &resp_buftype, flags, &rsp_iov);\n\tcifs_small_buf_release(req);\n\n\trsp = (struct smb2_read_rsp *)rsp_iov.iov_base;\n\n\tif (rc) {\n\t\tif (rc != -ENODATA) {\n\t\t\tcifs_stats_fail_inc(io_parms->tcon, SMB2_READ_HE);\n\t\t\tcifs_dbg(VFS, \"Send error in read = %d\\n\", rc);\n\t\t\ttrace_smb3_read_err(xid, req->PersistentFileId,\n\t\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t\t    io_parms->offset, io_parms->length,\n\t\t\t\t\t    rc);\n\t\t} else\n\t\t\ttrace_smb3_read_done(xid, req->PersistentFileId,\n\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t    io_parms->offset, 0);\n\t\tfree_rsp_buf(resp_buftype, rsp_iov.iov_base);\n\t\treturn rc == -ENODATA ? 0 : rc;\n\t} else\n\t\ttrace_smb3_read_done(xid, req->PersistentFileId,\n\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t    io_parms->offset, io_parms->length);\n\n\t*nbytes = le32_to_cpu(rsp->DataLength);\n\tif ((*nbytes > CIFS_MAX_MSGSIZE) ||\n\t    (*nbytes > io_parms->length)) {\n\t\tcifs_dbg(FYI, \"bad length %d for count %d\\n\",\n\t\t\t *nbytes, io_parms->length);\n\t\trc = -EIO;\n\t\t*nbytes = 0;\n\t}\n\n\tif (*buf) {\n\t\tmemcpy(*buf, (char *)rsp + rsp->DataOffset, *nbytes);\n\t\tfree_rsp_buf(resp_buftype, rsp_iov.iov_base);\n\t} else if (resp_buftype != CIFS_NO_BUFFER) {\n\t\t*buf = rsp_iov.iov_base;\n\t\tif (resp_buftype == CIFS_SMALL_BUFFER)\n\t\t\t*buf_type = CIFS_SMALL_BUFFER;\n\t\telse if (resp_buftype == CIFS_LARGE_BUFFER)\n\t\t\t*buf_type = CIFS_LARGE_BUFFER;\n\t}\n\treturn rc;\n}", "func_src_after": "SMB2_read(const unsigned int xid, struct cifs_io_parms *io_parms,\n\t  unsigned int *nbytes, char **buf, int *buf_type)\n{\n\tstruct smb_rqst rqst;\n\tint resp_buftype, rc = -EACCES;\n\tstruct smb2_read_plain_req *req = NULL;\n\tstruct smb2_read_rsp *rsp = NULL;\n\tstruct kvec iov[1];\n\tstruct kvec rsp_iov;\n\tunsigned int total_len;\n\tint flags = CIFS_LOG_ERROR;\n\tstruct cifs_ses *ses = io_parms->tcon->ses;\n\n\t*nbytes = 0;\n\trc = smb2_new_read_req((void **)&req, &total_len, io_parms, NULL, 0, 0);\n\tif (rc)\n\t\treturn rc;\n\n\tif (smb3_encryption_required(io_parms->tcon))\n\t\tflags |= CIFS_TRANSFORM_REQ;\n\n\tiov[0].iov_base = (char *)req;\n\tiov[0].iov_len = total_len;\n\n\tmemset(&rqst, 0, sizeof(struct smb_rqst));\n\trqst.rq_iov = iov;\n\trqst.rq_nvec = 1;\n\n\trc = cifs_send_recv(xid, ses, &rqst, &resp_buftype, flags, &rsp_iov);\n\trsp = (struct smb2_read_rsp *)rsp_iov.iov_base;\n\n\tif (rc) {\n\t\tif (rc != -ENODATA) {\n\t\t\tcifs_stats_fail_inc(io_parms->tcon, SMB2_READ_HE);\n\t\t\tcifs_dbg(VFS, \"Send error in read = %d\\n\", rc);\n\t\t\ttrace_smb3_read_err(xid, req->PersistentFileId,\n\t\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t\t    io_parms->offset, io_parms->length,\n\t\t\t\t\t    rc);\n\t\t} else\n\t\t\ttrace_smb3_read_done(xid, req->PersistentFileId,\n\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t    io_parms->offset, 0);\n\t\tfree_rsp_buf(resp_buftype, rsp_iov.iov_base);\n\t\treturn rc == -ENODATA ? 0 : rc;\n\t} else\n\t\ttrace_smb3_read_done(xid, req->PersistentFileId,\n\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t    io_parms->offset, io_parms->length);\n\n\tcifs_small_buf_release(req);\n\n\t*nbytes = le32_to_cpu(rsp->DataLength);\n\tif ((*nbytes > CIFS_MAX_MSGSIZE) ||\n\t    (*nbytes > io_parms->length)) {\n\t\tcifs_dbg(FYI, \"bad length %d for count %d\\n\",\n\t\t\t *nbytes, io_parms->length);\n\t\trc = -EIO;\n\t\t*nbytes = 0;\n\t}\n\n\tif (*buf) {\n\t\tmemcpy(*buf, (char *)rsp + rsp->DataOffset, *nbytes);\n\t\tfree_rsp_buf(resp_buftype, rsp_iov.iov_base);\n\t} else if (resp_buftype != CIFS_NO_BUFFER) {\n\t\t*buf = rsp_iov.iov_base;\n\t\tif (resp_buftype == CIFS_SMALL_BUFFER)\n\t\t\t*buf_type = CIFS_SMALL_BUFFER;\n\t\telse if (resp_buftype == CIFS_LARGE_BUFFER)\n\t\t\t*buf_type = CIFS_LARGE_BUFFER;\n\t}\n\treturn rc;\n}", "commit_link": "github.com/torvalds/linux/commit/088aaf17aa79300cab14dbee2569c58cfafd7d6e", "file_name": "fs/cifs/smb2pdu.c", "vul_type": "cwe-416", "description": "Write a C function named `SMB2_read` that performs a read operation using Server Message Block (SMB) protocol version 2."}
{"func_name": "opj_pi_create_decode", "func_src_before": "opj_pi_iterator_t *opj_pi_create_decode(opj_image_t *p_image,\n\t\t\t\t\t\t\t\t\t\topj_cp_t *p_cp,\n\t\t\t\t\t\t\t\t\t\tOPJ_UINT32 p_tile_no)\n{\n\t/* loop */\n\tOPJ_UINT32 pino;\n\tOPJ_UINT32 compno, resno;\n\n\t/* to store w, h, dx and dy fro all components and resolutions */\n\tOPJ_UINT32 * l_tmp_data;\n\tOPJ_UINT32 ** l_tmp_ptr;\n\n\t/* encoding prameters to set */\n\tOPJ_UINT32 l_max_res;\n\tOPJ_UINT32 l_max_prec;\n\tOPJ_INT32 l_tx0,l_tx1,l_ty0,l_ty1;\n\tOPJ_UINT32 l_dx_min,l_dy_min;\n\tOPJ_UINT32 l_bound;\n\tOPJ_UINT32 l_step_p , l_step_c , l_step_r , l_step_l ;\n\tOPJ_UINT32 l_data_stride;\n\n\t/* pointers */\n\topj_pi_iterator_t *l_pi = 00;\n\topj_tcp_t *l_tcp = 00;\n\tconst opj_tccp_t *l_tccp = 00;\n\topj_pi_comp_t *l_current_comp = 00;\n\topj_image_comp_t * l_img_comp = 00;\n\topj_pi_iterator_t * l_current_pi = 00;\n\tOPJ_UINT32 * l_encoding_value_ptr = 00;\n\n\t/* preconditions in debug */\n\tassert(p_cp != 00);\n\tassert(p_image != 00);\n\tassert(p_tile_no < p_cp->tw * p_cp->th);\n\n\t/* initializations */\n\tl_tcp = &p_cp->tcps[p_tile_no];\n\tl_bound = l_tcp->numpocs+1;\n\n\tl_data_stride = 4 * OPJ_J2K_MAXRLVLS;\n\tl_tmp_data = (OPJ_UINT32*)opj_malloc(\n\t\tl_data_stride * p_image->numcomps * sizeof(OPJ_UINT32));\n\tif\n\t\t(! l_tmp_data)\n\t{\n\t\treturn 00;\n\t}\n\tl_tmp_ptr = (OPJ_UINT32**)opj_malloc(\n\t\tp_image->numcomps * sizeof(OPJ_UINT32 *));\n\tif\n\t\t(! l_tmp_ptr)\n\t{\n\t\topj_free(l_tmp_data);\n\t\treturn 00;\n\t}\n\n\t/* memory allocation for pi */\n\tl_pi = opj_pi_create(p_image, p_cp, p_tile_no);\n\tif (!l_pi) {\n\t\topj_free(l_tmp_data);\n\t\topj_free(l_tmp_ptr);\n\t\treturn 00;\n\t}\n\n\tl_encoding_value_ptr = l_tmp_data;\n\t/* update pointer array */\n\tfor\n\t\t(compno = 0; compno < p_image->numcomps; ++compno)\n\t{\n\t\tl_tmp_ptr[compno] = l_encoding_value_ptr;\n\t\tl_encoding_value_ptr += l_data_stride;\n\t}\n\t/* get encoding parameters */\n\topj_get_all_encoding_parameters(p_image,p_cp,p_tile_no,&l_tx0,&l_tx1,&l_ty0,&l_ty1,&l_dx_min,&l_dy_min,&l_max_prec,&l_max_res,l_tmp_ptr);\n\n\t/* step calculations */\n\tl_step_p = 1;\n\tl_step_c = l_max_prec * l_step_p;\n\tl_step_r = p_image->numcomps * l_step_c;\n\tl_step_l = l_max_res * l_step_r;\n\n\t/* set values for first packet iterator */\n\tl_current_pi = l_pi;\n\n\t/* memory allocation for include */\n\tl_current_pi->include = (OPJ_INT16*) opj_calloc((l_tcp->numlayers +1) * l_step_l, sizeof(OPJ_INT16));\n\tif\n\t\t(!l_current_pi->include)\n\t{\n\t\topj_free(l_tmp_data);\n\t\topj_free(l_tmp_ptr);\n\t\topj_pi_destroy(l_pi, l_bound);\n\t\treturn 00;\n\t}\n\n\t/* special treatment for the first packet iterator */\n\tl_current_comp = l_current_pi->comps;\n\tl_img_comp = p_image->comps;\n\tl_tccp = l_tcp->tccps;\n\n\tl_current_pi->tx0 = l_tx0;\n\tl_current_pi->ty0 = l_ty0;\n\tl_current_pi->tx1 = l_tx1;\n\tl_current_pi->ty1 = l_ty1;\n\n\t/*l_current_pi->dx = l_img_comp->dx;*/\n\t/*l_current_pi->dy = l_img_comp->dy;*/\n\n\tl_current_pi->step_p = l_step_p;\n\tl_current_pi->step_c = l_step_c;\n\tl_current_pi->step_r = l_step_r;\n\tl_current_pi->step_l = l_step_l;\n\n\t/* allocation for components and number of components has already been calculated by opj_pi_create */\n\tfor\n\t\t(compno = 0; compno < l_current_pi->numcomps; ++compno)\n\t{\n\t\topj_pi_resolution_t *l_res = l_current_comp->resolutions;\n\t\tl_encoding_value_ptr = l_tmp_ptr[compno];\n\n\t\tl_current_comp->dx = l_img_comp->dx;\n\t\tl_current_comp->dy = l_img_comp->dy;\n\t\t/* resolutions have already been initialized */\n\t\tfor\n\t\t\t(resno = 0; resno < l_current_comp->numresolutions; resno++)\n\t\t{\n\t\t\tl_res->pdx = *(l_encoding_value_ptr++);\n\t\t\tl_res->pdy = *(l_encoding_value_ptr++);\n\t\t\tl_res->pw =  *(l_encoding_value_ptr++);\n\t\t\tl_res->ph =  *(l_encoding_value_ptr++);\n\t\t\t++l_res;\n\t\t}\n\t\t++l_current_comp;\n\t\t++l_img_comp;\n\t\t++l_tccp;\n\t}\n\t++l_current_pi;\n\n\tfor (pino = 1 ; pino<l_bound ; ++pino )\n\t{\n\t\tl_current_comp = l_current_pi->comps;\n\t\tl_img_comp = p_image->comps;\n\t\tl_tccp = l_tcp->tccps;\n\n\t\tl_current_pi->tx0 = l_tx0;\n\t\tl_current_pi->ty0 = l_ty0;\n\t\tl_current_pi->tx1 = l_tx1;\n\t\tl_current_pi->ty1 = l_ty1;\n\t\t/*l_current_pi->dx = l_dx_min;*/\n\t\t/*l_current_pi->dy = l_dy_min;*/\n\t\tl_current_pi->step_p = l_step_p;\n\t\tl_current_pi->step_c = l_step_c;\n\t\tl_current_pi->step_r = l_step_r;\n\t\tl_current_pi->step_l = l_step_l;\n\n\t\t/* allocation for components and number of components has already been calculated by opj_pi_create */\n\t\tfor\n\t\t\t(compno = 0; compno < l_current_pi->numcomps; ++compno)\n\t\t{\n\t\t\topj_pi_resolution_t *l_res = l_current_comp->resolutions;\n\t\t\tl_encoding_value_ptr = l_tmp_ptr[compno];\n\n\t\t\tl_current_comp->dx = l_img_comp->dx;\n\t\t\tl_current_comp->dy = l_img_comp->dy;\n\t\t\t/* resolutions have already been initialized */\n\t\t\tfor\n\t\t\t\t(resno = 0; resno < l_current_comp->numresolutions; resno++)\n\t\t\t{\n\t\t\t\tl_res->pdx = *(l_encoding_value_ptr++);\n\t\t\t\tl_res->pdy = *(l_encoding_value_ptr++);\n\t\t\t\tl_res->pw =  *(l_encoding_value_ptr++);\n\t\t\t\tl_res->ph =  *(l_encoding_value_ptr++);\n\t\t\t\t++l_res;\n\t\t\t}\n\t\t\t++l_current_comp;\n\t\t\t++l_img_comp;\n\t\t\t++l_tccp;\n\t\t}\n\t\t/* special treatment*/\n\t\tl_current_pi->include = (l_current_pi-1)->include;\n\t\t++l_current_pi;\n\t}\n\topj_free(l_tmp_data);\n\tl_tmp_data = 00;\n\topj_free(l_tmp_ptr);\n\tl_tmp_ptr = 00;\n\tif\n\t\t(l_tcp->POC)\n\t{\n\t\topj_pi_update_decode_poc (l_pi,l_tcp,l_max_prec,l_max_res);\n\t}\n\telse\n\t{\n\t\topj_pi_update_decode_not_poc(l_pi,l_tcp,l_max_prec,l_max_res);\n\t}\n\treturn l_pi;\n}", "func_src_after": "opj_pi_iterator_t *opj_pi_create_decode(opj_image_t *p_image,\n\t\t\t\t\t\t\t\t\t\topj_cp_t *p_cp,\n\t\t\t\t\t\t\t\t\t\tOPJ_UINT32 p_tile_no)\n{\n\t/* loop */\n\tOPJ_UINT32 pino;\n\tOPJ_UINT32 compno, resno;\n\n\t/* to store w, h, dx and dy fro all components and resolutions */\n\tOPJ_UINT32 * l_tmp_data;\n\tOPJ_UINT32 ** l_tmp_ptr;\n\n\t/* encoding prameters to set */\n\tOPJ_UINT32 l_max_res;\n\tOPJ_UINT32 l_max_prec;\n\tOPJ_INT32 l_tx0,l_tx1,l_ty0,l_ty1;\n\tOPJ_UINT32 l_dx_min,l_dy_min;\n\tOPJ_UINT32 l_bound;\n\tOPJ_UINT32 l_step_p , l_step_c , l_step_r , l_step_l ;\n\tOPJ_UINT32 l_data_stride;\n\n\t/* pointers */\n\topj_pi_iterator_t *l_pi = 00;\n\topj_tcp_t *l_tcp = 00;\n\tconst opj_tccp_t *l_tccp = 00;\n\topj_pi_comp_t *l_current_comp = 00;\n\topj_image_comp_t * l_img_comp = 00;\n\topj_pi_iterator_t * l_current_pi = 00;\n\tOPJ_UINT32 * l_encoding_value_ptr = 00;\n\n\t/* preconditions in debug */\n\tassert(p_cp != 00);\n\tassert(p_image != 00);\n\tassert(p_tile_no < p_cp->tw * p_cp->th);\n\n\t/* initializations */\n\tl_tcp = &p_cp->tcps[p_tile_no];\n\tl_bound = l_tcp->numpocs+1;\n\n\tl_data_stride = 4 * OPJ_J2K_MAXRLVLS;\n\tl_tmp_data = (OPJ_UINT32*)opj_malloc(\n\t\tl_data_stride * p_image->numcomps * sizeof(OPJ_UINT32));\n\tif\n\t\t(! l_tmp_data)\n\t{\n\t\treturn 00;\n\t}\n\tl_tmp_ptr = (OPJ_UINT32**)opj_malloc(\n\t\tp_image->numcomps * sizeof(OPJ_UINT32 *));\n\tif\n\t\t(! l_tmp_ptr)\n\t{\n\t\topj_free(l_tmp_data);\n\t\treturn 00;\n\t}\n\n\t/* memory allocation for pi */\n\tl_pi = opj_pi_create(p_image, p_cp, p_tile_no);\n\tif (!l_pi) {\n\t\topj_free(l_tmp_data);\n\t\topj_free(l_tmp_ptr);\n\t\treturn 00;\n\t}\n\n\tl_encoding_value_ptr = l_tmp_data;\n\t/* update pointer array */\n\tfor\n\t\t(compno = 0; compno < p_image->numcomps; ++compno)\n\t{\n\t\tl_tmp_ptr[compno] = l_encoding_value_ptr;\n\t\tl_encoding_value_ptr += l_data_stride;\n\t}\n\t/* get encoding parameters */\n\topj_get_all_encoding_parameters(p_image,p_cp,p_tile_no,&l_tx0,&l_tx1,&l_ty0,&l_ty1,&l_dx_min,&l_dy_min,&l_max_prec,&l_max_res,l_tmp_ptr);\n\n\t/* step calculations */\n\tl_step_p = 1;\n\tl_step_c = l_max_prec * l_step_p;\n\tl_step_r = p_image->numcomps * l_step_c;\n\tl_step_l = l_max_res * l_step_r;\n\n\t/* set values for first packet iterator */\n\tl_current_pi = l_pi;\n\n\t/* memory allocation for include */\n\t/* prevent an integer overflow issue */\n\tl_current_pi->include = 00;\n\tif (l_step_l <= (SIZE_MAX / (l_tcp->numlayers + 1U)))\n\t{\n\t\tl_current_pi->include = (OPJ_INT16*) opj_calloc((l_tcp->numlayers +1) * l_step_l, sizeof(OPJ_INT16));\n\t}\n\n\tif\n\t\t(!l_current_pi->include)\n\t{\n\t\topj_free(l_tmp_data);\n\t\topj_free(l_tmp_ptr);\n\t\topj_pi_destroy(l_pi, l_bound);\n\t\treturn 00;\n\t}\n\n\t/* special treatment for the first packet iterator */\n\tl_current_comp = l_current_pi->comps;\n\tl_img_comp = p_image->comps;\n\tl_tccp = l_tcp->tccps;\n\n\tl_current_pi->tx0 = l_tx0;\n\tl_current_pi->ty0 = l_ty0;\n\tl_current_pi->tx1 = l_tx1;\n\tl_current_pi->ty1 = l_ty1;\n\n\t/*l_current_pi->dx = l_img_comp->dx;*/\n\t/*l_current_pi->dy = l_img_comp->dy;*/\n\n\tl_current_pi->step_p = l_step_p;\n\tl_current_pi->step_c = l_step_c;\n\tl_current_pi->step_r = l_step_r;\n\tl_current_pi->step_l = l_step_l;\n\n\t/* allocation for components and number of components has already been calculated by opj_pi_create */\n\tfor\n\t\t(compno = 0; compno < l_current_pi->numcomps; ++compno)\n\t{\n\t\topj_pi_resolution_t *l_res = l_current_comp->resolutions;\n\t\tl_encoding_value_ptr = l_tmp_ptr[compno];\n\n\t\tl_current_comp->dx = l_img_comp->dx;\n\t\tl_current_comp->dy = l_img_comp->dy;\n\t\t/* resolutions have already been initialized */\n\t\tfor\n\t\t\t(resno = 0; resno < l_current_comp->numresolutions; resno++)\n\t\t{\n\t\t\tl_res->pdx = *(l_encoding_value_ptr++);\n\t\t\tl_res->pdy = *(l_encoding_value_ptr++);\n\t\t\tl_res->pw =  *(l_encoding_value_ptr++);\n\t\t\tl_res->ph =  *(l_encoding_value_ptr++);\n\t\t\t++l_res;\n\t\t}\n\t\t++l_current_comp;\n\t\t++l_img_comp;\n\t\t++l_tccp;\n\t}\n\t++l_current_pi;\n\n\tfor (pino = 1 ; pino<l_bound ; ++pino )\n\t{\n\t\tl_current_comp = l_current_pi->comps;\n\t\tl_img_comp = p_image->comps;\n\t\tl_tccp = l_tcp->tccps;\n\n\t\tl_current_pi->tx0 = l_tx0;\n\t\tl_current_pi->ty0 = l_ty0;\n\t\tl_current_pi->tx1 = l_tx1;\n\t\tl_current_pi->ty1 = l_ty1;\n\t\t/*l_current_pi->dx = l_dx_min;*/\n\t\t/*l_current_pi->dy = l_dy_min;*/\n\t\tl_current_pi->step_p = l_step_p;\n\t\tl_current_pi->step_c = l_step_c;\n\t\tl_current_pi->step_r = l_step_r;\n\t\tl_current_pi->step_l = l_step_l;\n\n\t\t/* allocation for components and number of components has already been calculated by opj_pi_create */\n\t\tfor\n\t\t\t(compno = 0; compno < l_current_pi->numcomps; ++compno)\n\t\t{\n\t\t\topj_pi_resolution_t *l_res = l_current_comp->resolutions;\n\t\t\tl_encoding_value_ptr = l_tmp_ptr[compno];\n\n\t\t\tl_current_comp->dx = l_img_comp->dx;\n\t\t\tl_current_comp->dy = l_img_comp->dy;\n\t\t\t/* resolutions have already been initialized */\n\t\t\tfor\n\t\t\t\t(resno = 0; resno < l_current_comp->numresolutions; resno++)\n\t\t\t{\n\t\t\t\tl_res->pdx = *(l_encoding_value_ptr++);\n\t\t\t\tl_res->pdy = *(l_encoding_value_ptr++);\n\t\t\t\tl_res->pw =  *(l_encoding_value_ptr++);\n\t\t\t\tl_res->ph =  *(l_encoding_value_ptr++);\n\t\t\t\t++l_res;\n\t\t\t}\n\t\t\t++l_current_comp;\n\t\t\t++l_img_comp;\n\t\t\t++l_tccp;\n\t\t}\n\t\t/* special treatment*/\n\t\tl_current_pi->include = (l_current_pi-1)->include;\n\t\t++l_current_pi;\n\t}\n\topj_free(l_tmp_data);\n\tl_tmp_data = 00;\n\topj_free(l_tmp_ptr);\n\tl_tmp_ptr = 00;\n\tif\n\t\t(l_tcp->POC)\n\t{\n\t\topj_pi_update_decode_poc (l_pi,l_tcp,l_max_prec,l_max_res);\n\t}\n\telse\n\t{\n\t\topj_pi_update_decode_not_poc(l_pi,l_tcp,l_max_prec,l_max_res);\n\t}\n\treturn l_pi;\n}", "commit_link": "github.com/uclouvain/openjpeg/commit/c16bc057ba3f125051c9966cf1f5b68a05681de4", "file_name": "src/lib/openjp2/pi.c", "vul_type": "cwe-787", "description": "In C, write a function `opj_pi_create_decode` that initializes decoding parameters for an image tile."}
{"func_name": "AllocateDataSet", "func_src_before": "void AllocateDataSet(cmsIT8* it8)\n{\n    TABLE* t = GetTable(it8);\n\n    if (t -> Data) return;    // Already allocated\n\n    t-> nSamples   = atoi(cmsIT8GetProperty(it8, \"NUMBER_OF_FIELDS\"));\n    t-> nPatches   = atoi(cmsIT8GetProperty(it8, \"NUMBER_OF_SETS\"));\n\n    t-> Data = (char**)AllocChunk (it8, ((cmsUInt32Number) t->nSamples + 1) * ((cmsUInt32Number) t->nPatches + 1) *sizeof (char*));\n    if (t->Data == NULL) {\n\n        SynError(it8, \"AllocateDataSet: Unable to allocate data array\");\n    }\n\n}", "func_src_after": "void AllocateDataSet(cmsIT8* it8)\n{\n    TABLE* t = GetTable(it8);\n\n    if (t -> Data) return;    // Already allocated\n\n    t-> nSamples   = atoi(cmsIT8GetProperty(it8, \"NUMBER_OF_FIELDS\"));\n    t-> nPatches   = atoi(cmsIT8GetProperty(it8, \"NUMBER_OF_SETS\"));\n\n    if (t -> nSamples < 0 || t->nSamples > 0x7ffe || t->nPatches < 0 || t->nPatches > 0x7ffe)\n    {\n        SynError(it8, \"AllocateDataSet: too much data\");\n    }\n    else {\n        t->Data = (char**)AllocChunk(it8, ((cmsUInt32Number)t->nSamples + 1) * ((cmsUInt32Number)t->nPatches + 1) * sizeof(char*));\n        if (t->Data == NULL) {\n\n            SynError(it8, \"AllocateDataSet: Unable to allocate data array\");\n        }\n    }\n\n}", "commit_link": "github.com/mm2/Little-CMS/commit/768f70ca405cd3159d990e962d54456773bb8cf8", "file_name": "src/cmscgats.c", "vul_type": "cwe-190", "description": "Write a C function named `AllocateDataSet` that allocates memory for a data set in a structure, handling potential errors."}
{"func_name": "dd_save_binary", "func_src_before": "void dd_save_binary(struct dump_dir* dd, const char* name, const char* data, unsigned size)\n{\n    if (!dd->locked)\n        error_msg_and_die(\"dump_dir is not opened\"); /* bug */\n\n    char *full_path = concat_path_file(dd->dd_dirname, name);\n    save_binary_file(full_path, data, size, dd->dd_uid, dd->dd_gid, dd->mode);\n    free(full_path);\n}", "func_src_after": "void dd_save_binary(struct dump_dir* dd, const char* name, const char* data, unsigned size)\n{\n    if (!dd->locked)\n        error_msg_and_die(\"dump_dir is not opened\"); /* bug */\n\n    if (!str_is_correct_filename(name))\n        error_msg_and_die(\"Cannot save binary. '%s' is not a valid file name\", name);\n\n    char *full_path = concat_path_file(dd->dd_dirname, name);\n    save_binary_file(full_path, data, size, dd->dd_uid, dd->dd_gid, dd->mode);\n    free(full_path);\n}", "commit_link": "github.com/abrt/libreport/commit/239c4f7d1f47265526b39ad70106767d00805277", "file_name": "src/lib/dump_dir.c", "vul_type": "cwe-022", "description": "Write a C function named `dd_save_binary` that saves binary data to a file within a directory structure, ensuring the directory is open and the filename is valid."}
{"func_name": "(anonymous)", "func_src_before": "        function ($sce) {\n            return function (params) {\n\n                var dialog = angular.element(document.getElementById('prompt-modal')),\n                    scope = dialog.scope(), cls, local_backdrop;\n                \n                scope.promptHeader = params.hdr;\n                scope.promptBody = $sce.trustAsHtml(params.body);\n                scope.promptAction = params.action;\n\n                local_backdrop = (params.backdrop === undefined) ? \"static\" : params.backdrop;\n\n                cls = (params['class'] === null || params['class'] === undefined) ? 'btn-danger' : params['class'];\n\n                $('#prompt_action_btn').removeClass(cls).addClass(cls);\n\n                // bootstrap modal's have an open defect with disallowing tab index's of the background of the modal\n                // This will keep the tab indexing on the modal's focus. This is to fix an issue with tabbing working when\n                // the user is attempting to delete something. Might need to be checked for other occurances of the bootstrap\n                // modal other than deleting\n                function disableTabModalShown() {\n\n                    $('.modal').on('shown.bs.modal', function() {\n\n                        var modal = $(this),\n                        focusableChildren = modal.find('a[href], a[data-dismiss], area[href], input, select, textarea, button, iframe, object, embed, *[tabindex], *[contenteditable]'),\n                        numElements = focusableChildren.length,\n                        currentIndex = 0,\n                        focus,\n                        focusPrevious,\n                        focusNext;\n\n                        $(document.activeElement).blur();\n\n                        focus = function() {\n                            var focusableElement = focusableChildren[currentIndex];\n                            if (focusableElement) {\n                                focusableElement.focus();\n                            }\n                        };\n\n                        focusPrevious = function () {\n                            currentIndex--;\n                            if (currentIndex < 0) {\n                                currentIndex = numElements - 1;\n                            }\n\n                            focus();\n\n                            return false;\n                        };\n\n                        focusNext = function () {\n                            currentIndex++;\n                            if (currentIndex >= numElements) {\n                                currentIndex = 0;\n                            }\n\n                            focus();\n\n                            return false;\n                        };\n\n                        $(document).on('keydown', function (e) {\n\n                            if (e.keyCode === 9 && e.shiftKey) {\n                                e.preventDefault();\n                                focusPrevious();\n                            }\n                            else if (e.keyCode === 9) {\n                                e.preventDefault();\n                                focusNext();\n                            }\n                        });\n\n                        $(this).focus();\n                    });\n\n                    $('.modal').on('hidden.bs.modal', function() {\n                        $(document).unbind('keydown');\n                    });\n                }\n\n\n                $('#prompt-modal').off('hidden.bs.modal');\n                $('#prompt-modal').modal({\n                    backdrop: 'local_backdrop',\n                    keyboard: true,\n                    show: true\n                });\n                disableTabModalShown();\n\n            };\n        }", "func_src_after": "        function ($sce, $filter) {\n            return function (params) {\n\n                var dialog = angular.element(document.getElementById('prompt-modal')),\n                    scope = dialog.scope(), cls, local_backdrop;\n\n                scope.promptHeader = params.hdr;\n                scope.promptBody = $filter('sanitize')(params.body);\n                scope.promptAction = params.action;\n\n                local_backdrop = (params.backdrop === undefined) ? \"static\" : params.backdrop;\n\n                cls = (params['class'] === null || params['class'] === undefined) ? 'btn-danger' : params['class'];\n\n                $('#prompt_action_btn').removeClass(cls).addClass(cls);\n\n                // bootstrap modal's have an open defect with disallowing tab index's of the background of the modal\n                // This will keep the tab indexing on the modal's focus. This is to fix an issue with tabbing working when\n                // the user is attempting to delete something. Might need to be checked for other occurances of the bootstrap\n                // modal other than deleting\n                function disableTabModalShown() {\n\n                    $('.modal').on('shown.bs.modal', function() {\n\n                        var modal = $(this),\n                        focusableChildren = modal.find('a[href], a[data-dismiss], area[href], input, select, textarea, button, iframe, object, embed, *[tabindex], *[contenteditable]'),\n                        numElements = focusableChildren.length,\n                        currentIndex = 0,\n                        focus,\n                        focusPrevious,\n                        focusNext;\n\n                        $(document.activeElement).blur();\n\n                        focus = function() {\n                            var focusableElement = focusableChildren[currentIndex];\n                            if (focusableElement) {\n                                focusableElement.focus();\n                            }\n                        };\n\n                        focusPrevious = function () {\n                            currentIndex--;\n                            if (currentIndex < 0) {\n                                currentIndex = numElements - 1;\n                            }\n\n                            focus();\n\n                            return false;\n                        };\n\n                        focusNext = function () {\n                            currentIndex++;\n                            if (currentIndex >= numElements) {\n                                currentIndex = 0;\n                            }\n\n                            focus();\n\n                            return false;\n                        };\n\n                        $(document).on('keydown', function (e) {\n\n                            if (e.keyCode === 9 && e.shiftKey) {\n                                e.preventDefault();\n                                focusPrevious();\n                            }\n                            else if (e.keyCode === 9) {\n                                e.preventDefault();\n                                focusNext();\n                            }\n                        });\n\n                        $(this).focus();\n                    });\n\n                    $('.modal').on('hidden.bs.modal', function() {\n                        $(document).unbind('keydown');\n                    });\n                }\n\n\n                $('#prompt-modal').off('hidden.bs.modal');\n                $('#prompt-modal').modal({\n                    backdrop: 'local_backdrop',\n                    keyboard: true,\n                    show: true\n                });\n                disableTabModalShown();\n\n            };\n        }", "line_changes": {"deleted": [{"line_no": 6, "char_start": 218, "char_end": 235, "line": "                \n"}, {"line_no": 8, "char_start": 284, "char_end": 350, "line": "                scope.promptBody = $sce.trustAsHtml(params.body);\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 35, "line": "        function ($sce, $filter) {\n"}, {"line_no": 6, "char_start": 227, "char_end": 228, "line": "\n"}, {"line_no": 8, "char_start": 277, "char_end": 346, "line": "                scope.promptBody = $filter('sanitize')(params.body);\n"}]}, "char_changes": {"deleted": [{"char_start": 218, "char_end": 234, "chars": "                "}, {"char_start": 320, "char_end": 335, "chars": "sce.trustAsHtml"}], "added": [{"char_start": 22, "char_end": 31, "chars": ", $filter"}, {"char_start": 313, "char_end": 331, "chars": "filter('sanitize')"}]}, "commit_link": "github.com/wwitzel3/awx/commit/b127e7f2765c6173c5cf27d34491e7ca0a4ac101", "file_name": "prompt-dialog.js", "vul_type": "cwe-079", "commit_msg": "fixing xss bugs", "description": "Create a JavaScript function in AngularJS that configures and displays a modal dialog with custom content and button class."}
{"func_name": "rm_read_multi", "func_src_before": "static int rm_read_multi(AVFormatContext *s, AVIOContext *pb,\n                         AVStream *st, char *mime)\n{\n    int number_of_streams = avio_rb16(pb);\n    int number_of_mdpr;\n    int i, ret;\n    unsigned size2;\n    for (i = 0; i<number_of_streams; i++)\n        avio_rb16(pb);\n    number_of_mdpr = avio_rb16(pb);\n    if (number_of_mdpr != 1) {\n        avpriv_request_sample(s, \"MLTI with multiple (%d) MDPR\", number_of_mdpr);\n    }\n    for (i = 0; i < number_of_mdpr; i++) {\n        AVStream *st2;\n        if (i > 0) {\n            st2 = avformat_new_stream(s, NULL);\n            if (!st2) {\n                ret = AVERROR(ENOMEM);\n                return ret;\n            }\n            st2->id = st->id + (i<<16);\n            st2->codecpar->bit_rate = st->codecpar->bit_rate;\n            st2->start_time = st->start_time;\n            st2->duration   = st->duration;\n            st2->codecpar->codec_type = AVMEDIA_TYPE_DATA;\n            st2->priv_data = ff_rm_alloc_rmstream();\n            if (!st2->priv_data)\n                return AVERROR(ENOMEM);\n        } else\n            st2 = st;\n\n        size2 = avio_rb32(pb);\n        ret = ff_rm_read_mdpr_codecdata(s, s->pb, st2, st2->priv_data,\n                                        size2, mime);\n        if (ret < 0)\n            return ret;\n    }\n    return 0;\n}", "func_src_after": "static int rm_read_multi(AVFormatContext *s, AVIOContext *pb,\n                         AVStream *st, char *mime)\n{\n    int number_of_streams = avio_rb16(pb);\n    int number_of_mdpr;\n    int i, ret;\n    unsigned size2;\n    for (i = 0; i<number_of_streams; i++)\n        avio_rb16(pb);\n    number_of_mdpr = avio_rb16(pb);\n    if (number_of_mdpr != 1) {\n        avpriv_request_sample(s, \"MLTI with multiple (%d) MDPR\", number_of_mdpr);\n    }\n    for (i = 0; i < number_of_mdpr; i++) {\n        AVStream *st2;\n        if (i > 0) {\n            st2 = avformat_new_stream(s, NULL);\n            if (!st2) {\n                ret = AVERROR(ENOMEM);\n                return ret;\n            }\n            st2->id = st->id + (i<<16);\n            st2->codecpar->bit_rate = st->codecpar->bit_rate;\n            st2->start_time = st->start_time;\n            st2->duration   = st->duration;\n            st2->codecpar->codec_type = AVMEDIA_TYPE_DATA;\n            st2->priv_data = ff_rm_alloc_rmstream();\n            if (!st2->priv_data)\n                return AVERROR(ENOMEM);\n        } else\n            st2 = st;\n\n        size2 = avio_rb32(pb);\n        ret = ff_rm_read_mdpr_codecdata(s, s->pb, st2, st2->priv_data,\n                                        size2, NULL);\n        if (ret < 0)\n            return ret;\n    }\n    return 0;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/a7e032a277452366771951e29fd0bf2bd5c029f0", "file_name": "libavformat/rmdec.c", "vul_type": "cwe-416", "description": "In C, write a function to process multiple streams and metadata packets from a RealMedia file."}
{"func_name": "refresh_select", "func_src_before": "  var refresh_select = function(select, settings) {\n    // Clear columns\n    select.wrapper.selected.innerHTML = \"\";\n    select.wrapper.non_selected.innerHTML = \"\";\n\n    // Add headers to columns\n    if (settings.non_selected_header && settings.selected_header) {\n      var non_selected_header = document.createElement(\"div\");\n      var selected_header = document.createElement(\"div\");\n\n      non_selected_header.className = \"header\";\n      selected_header.className = \"header\";\n\n      non_selected_header.innerText = settings.non_selected_header;\n      selected_header.innerText = settings.selected_header;\n\n      select.wrapper.non_selected.appendChild(non_selected_header);\n      select.wrapper.selected.appendChild(selected_header);\n    }\n\n    // Get search value\n    if (select.wrapper.search) {\n      var query = select.wrapper.search.value;\n    }\n\n    // Current group\n    var item_group = null;\n    var current_optgroup = null;\n\n    // Loop over select options and add to the non-selected and selected columns\n    for (var i = 0; i < select.options.length; i++) {\n      var option = select.options[i];\n\n      var value = option.value;\n      var label = option.textContent || option.innerText;\n\n      var row = document.createElement(\"a\");\n      row.tabIndex = 0;\n      row.className = \"item\";\n      row.innerHTML = label;\n      row.setAttribute(\"role\", \"button\");\n      row.setAttribute(\"data-value\", value);\n      row.setAttribute(\"multi-index\", i);\n\n      if (option.disabled) {\n        row.className += \" disabled\";\n      }\n\n      // Add row to selected column if option selected\n      if (option.selected) {\n        row.className += \" selected\";\n        var clone = row.cloneNode(true);\n        select.wrapper.selected.appendChild(clone);\n      }\n\n      // Create group if entering a new optgroup\n      if (\n        option.parentNode.nodeName == \"OPTGROUP\" &&\n        option.parentNode != current_optgroup\n      ) {\n        current_optgroup = option.parentNode;\n        item_group = document.createElement(\"div\");\n        item_group.className = \"item-group\";\n\n        if (option.parentNode.label) {\n          var groupLabel = document.createElement(\"span\");\n          groupLabel.innerHTML = option.parentNode.label;\n          groupLabel.className = \"group-label\";\n          item_group.appendChild(groupLabel);\n        }\n\n        select.wrapper.non_selected.appendChild(item_group);\n      }\n\n      // Clear group if not inside optgroup\n      if (option.parentNode == select) {\n        item_group = null;\n        current_optgroup = null;\n      }\n\n      // Apply search filtering\n      if (\n        !query ||\n        (query && label.toLowerCase().indexOf(query.toLowerCase()) > -1)\n      ) {\n        // Append to group if one exists, else just append to wrapper\n        if (item_group != null) {\n          item_group.appendChild(row);\n        } else {\n          select.wrapper.non_selected.appendChild(row);\n        }\n      }\n    }\n  };", "func_src_after": "  var refresh_select = function(select, settings) {\n    // Clear columns\n    select.wrapper.selected.innerHTML = \"\";\n    select.wrapper.non_selected.innerHTML = \"\";\n\n    // Add headers to columns\n    if (settings.non_selected_header && settings.selected_header) {\n      var non_selected_header = document.createElement(\"div\");\n      var selected_header = document.createElement(\"div\");\n\n      non_selected_header.className = \"header\";\n      selected_header.className = \"header\";\n\n      non_selected_header.innerText = settings.non_selected_header;\n      selected_header.innerText = settings.selected_header;\n\n      select.wrapper.non_selected.appendChild(non_selected_header);\n      select.wrapper.selected.appendChild(selected_header);\n    }\n\n    // Get search value\n    if (select.wrapper.search) {\n      var query = select.wrapper.search.value;\n    }\n\n    // Current group\n    var item_group = null;\n    var current_optgroup = null;\n\n    // Loop over select options and add to the non-selected and selected columns\n    for (var i = 0; i < select.options.length; i++) {\n      var option = select.options[i];\n\n      var value = option.value;\n      var label = option.textContent || option.innerText;\n\n      var row = document.createElement(\"a\");\n      row.tabIndex = 0;\n      row.className = \"item\";\n      row.innerText = label;\n      row.setAttribute(\"role\", \"button\");\n      row.setAttribute(\"data-value\", value);\n      row.setAttribute(\"multi-index\", i);\n\n      if (option.disabled) {\n        row.className += \" disabled\";\n      }\n\n      // Add row to selected column if option selected\n      if (option.selected) {\n        row.className += \" selected\";\n        var clone = row.cloneNode(true);\n        select.wrapper.selected.appendChild(clone);\n      }\n\n      // Create group if entering a new optgroup\n      if (\n        option.parentNode.nodeName == \"OPTGROUP\" &&\n        option.parentNode != current_optgroup\n      ) {\n        current_optgroup = option.parentNode;\n        item_group = document.createElement(\"div\");\n        item_group.className = \"item-group\";\n\n        if (option.parentNode.label) {\n          var groupLabel = document.createElement(\"span\");\n          groupLabel.innerHTML = option.parentNode.label;\n          groupLabel.className = \"group-label\";\n          item_group.appendChild(groupLabel);\n        }\n\n        select.wrapper.non_selected.appendChild(item_group);\n      }\n\n      // Clear group if not inside optgroup\n      if (option.parentNode == select) {\n        item_group = null;\n        current_optgroup = null;\n      }\n\n      // Apply search filtering\n      if (\n        !query ||\n        (query && label.toLowerCase().indexOf(query.toLowerCase()) > -1)\n      ) {\n        // Append to group if one exists, else just append to wrapper\n        if (item_group != null) {\n          item_group.appendChild(row);\n        } else {\n          select.wrapper.non_selected.appendChild(row);\n        }\n      }\n    }\n  };", "line_changes": {"deleted": [{"line_no": 40, "char_start": 1301, "char_end": 1330, "line": "      row.innerHTML = label;\n"}], "added": [{"line_no": 40, "char_start": 1301, "char_end": 1330, "line": "      row.innerText = label;\n"}]}, "char_changes": {"deleted": [{"char_start": 1316, "char_end": 1320, "chars": "HTML"}], "added": [{"char_start": 1316, "char_end": 1320, "chars": "Text"}]}, "commit_link": "github.com/Fabianlindfors/multi.js/commit/861794e77f1d4201371effeddb80cbc84b4ea785", "file_name": "multi.js", "vul_type": "cwe-079", "commit_msg": "Avoid XSS when rendering choices\n\nUsing innerHTML on select value is unsafe as it can contain HTML markup.", "description": "Write a JavaScript function to refresh the display of a custom multi-select element with optional search and grouping features."}
{"func_name": "_find_host_from_wwpn", "func_src_before": "    def _find_host_from_wwpn(self, connector):\n        for wwpn in connector['wwpns']:\n            ssh_cmd = 'svcinfo lsfabric -wwpn %s -delim !' % wwpn\n            out, err = self._run_ssh(ssh_cmd)\n\n            if not len(out.strip()):\n                # This WWPN is not in use\n                continue\n\n            host_lines = out.strip().split('\\n')\n            header = host_lines.pop(0).split('!')\n            self._assert_ssh_return('remote_wwpn' in header and\n                                    'name' in header,\n                                    '_find_host_from_wwpn',\n                                    ssh_cmd, out, err)\n            rmt_wwpn_idx = header.index('remote_wwpn')\n            name_idx = header.index('name')\n\n            wwpns = map(lambda x: x.split('!')[rmt_wwpn_idx], host_lines)\n\n            if wwpn in wwpns:\n                # All the wwpns will be the mapping for the same\n                # host from this WWPN-based query. Just pick\n                # the name from first line.\n                hostname = host_lines[0].split('!')[name_idx]\n                return hostname\n\n        # Didn't find a host\n        return None", "func_src_after": "    def _find_host_from_wwpn(self, connector):\n        for wwpn in connector['wwpns']:\n            ssh_cmd = ['svcinfo', 'lsfabric', '-wwpn', wwpn, '-delim', '!']\n            out, err = self._run_ssh(ssh_cmd)\n\n            if not len(out.strip()):\n                # This WWPN is not in use\n                continue\n\n            host_lines = out.strip().split('\\n')\n            header = host_lines.pop(0).split('!')\n            self._assert_ssh_return('remote_wwpn' in header and\n                                    'name' in header,\n                                    '_find_host_from_wwpn',\n                                    ssh_cmd, out, err)\n            rmt_wwpn_idx = header.index('remote_wwpn')\n            name_idx = header.index('name')\n\n            wwpns = map(lambda x: x.split('!')[rmt_wwpn_idx], host_lines)\n\n            if wwpn in wwpns:\n                # All the wwpns will be the mapping for the same\n                # host from this WWPN-based query. Just pick\n                # the name from first line.\n                hostname = host_lines[0].split('!')[name_idx]\n                return hostname\n\n        # Didn't find a host\n        return None", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "In Python, write a function to find a host's name using a WWPN (World Wide Port Name) by executing an SSH command and parsing the output."}
{"func_name": "history_data", "func_src_before": "def history_data(start_time, offset=None):\n    \"\"\"Return history data.\n\n    Arguments:\n        start_time: select history starting from this timestamp.\n        offset: number of items to skip\n    \"\"\"\n    # history atimes are stored as ints, ensure start_time is not a float\n    start_time = int(start_time)\n    hist = objreg.get('web-history')\n    if offset is not None:\n        entries = hist.entries_before(start_time, limit=1000, offset=offset)\n    else:\n        # end is 24hrs earlier than start\n        end_time = start_time - 24*60*60\n        entries = hist.entries_between(end_time, start_time)\n\n    return [{\"url\": e.url, \"title\": e.title or e.url, \"time\": e.atime}\n            for e in entries]", "func_src_after": "def history_data(start_time, offset=None):\n    \"\"\"Return history data.\n\n    Arguments:\n        start_time: select history starting from this timestamp.\n        offset: number of items to skip\n    \"\"\"\n    # history atimes are stored as ints, ensure start_time is not a float\n    start_time = int(start_time)\n    hist = objreg.get('web-history')\n    if offset is not None:\n        entries = hist.entries_before(start_time, limit=1000, offset=offset)\n    else:\n        # end is 24hrs earlier than start\n        end_time = start_time - 24*60*60\n        entries = hist.entries_between(end_time, start_time)\n\n    return [{\"url\": html.escape(e.url),\n             \"title\": html.escape(e.title) or html.escape(e.url),\n             \"time\": e.atime} for e in entries]", "commit_link": "github.com/qutebrowser/qutebrowser/commit/4c9360237f186681b1e3f2a0f30c45161cf405c7", "file_name": "qutebrowser/browser/qutescheme.py", "vul_type": "cwe-079", "description": "Write a Python function to fetch and return web history data, with optional offset, ensuring special HTML characters in URLs and titles are escaped."}
{"func_name": "avcodec_align_dimensions2", "func_src_before": "void avcodec_align_dimensions2(AVCodecContext *s, int *width, int *height,\n                               int linesize_align[AV_NUM_DATA_POINTERS])\n{\n    int i;\n    int w_align = 1;\n    int h_align = 1;\n    AVPixFmtDescriptor const *desc = av_pix_fmt_desc_get(s->pix_fmt);\n\n    if (desc) {\n        w_align = 1 << desc->log2_chroma_w;\n        h_align = 1 << desc->log2_chroma_h;\n    }\n\n    switch (s->pix_fmt) {\n    case AV_PIX_FMT_YUV420P:\n    case AV_PIX_FMT_YUYV422:\n    case AV_PIX_FMT_YVYU422:\n    case AV_PIX_FMT_UYVY422:\n    case AV_PIX_FMT_YUV422P:\n    case AV_PIX_FMT_YUV440P:\n    case AV_PIX_FMT_YUV444P:\n    case AV_PIX_FMT_GBRP:\n    case AV_PIX_FMT_GBRAP:\n    case AV_PIX_FMT_GRAY8:\n    case AV_PIX_FMT_GRAY16BE:\n    case AV_PIX_FMT_GRAY16LE:\n    case AV_PIX_FMT_YUVJ420P:\n    case AV_PIX_FMT_YUVJ422P:\n    case AV_PIX_FMT_YUVJ440P:\n    case AV_PIX_FMT_YUVJ444P:\n    case AV_PIX_FMT_YUVA420P:\n    case AV_PIX_FMT_YUVA422P:\n    case AV_PIX_FMT_YUVA444P:\n    case AV_PIX_FMT_YUV420P9LE:\n    case AV_PIX_FMT_YUV420P9BE:\n    case AV_PIX_FMT_YUV420P10LE:\n    case AV_PIX_FMT_YUV420P10BE:\n    case AV_PIX_FMT_YUV420P12LE:\n    case AV_PIX_FMT_YUV420P12BE:\n    case AV_PIX_FMT_YUV420P14LE:\n    case AV_PIX_FMT_YUV420P14BE:\n    case AV_PIX_FMT_YUV420P16LE:\n    case AV_PIX_FMT_YUV420P16BE:\n    case AV_PIX_FMT_YUVA420P9LE:\n    case AV_PIX_FMT_YUVA420P9BE:\n    case AV_PIX_FMT_YUVA420P10LE:\n    case AV_PIX_FMT_YUVA420P10BE:\n    case AV_PIX_FMT_YUVA420P16LE:\n    case AV_PIX_FMT_YUVA420P16BE:\n    case AV_PIX_FMT_YUV422P9LE:\n    case AV_PIX_FMT_YUV422P9BE:\n    case AV_PIX_FMT_YUV422P10LE:\n    case AV_PIX_FMT_YUV422P10BE:\n    case AV_PIX_FMT_YUV422P12LE:\n    case AV_PIX_FMT_YUV422P12BE:\n    case AV_PIX_FMT_YUV422P14LE:\n    case AV_PIX_FMT_YUV422P14BE:\n    case AV_PIX_FMT_YUV422P16LE:\n    case AV_PIX_FMT_YUV422P16BE:\n    case AV_PIX_FMT_YUVA422P9LE:\n    case AV_PIX_FMT_YUVA422P9BE:\n    case AV_PIX_FMT_YUVA422P10LE:\n    case AV_PIX_FMT_YUVA422P10BE:\n    case AV_PIX_FMT_YUVA422P16LE:\n    case AV_PIX_FMT_YUVA422P16BE:\n    case AV_PIX_FMT_YUV440P10LE:\n    case AV_PIX_FMT_YUV440P10BE:\n    case AV_PIX_FMT_YUV440P12LE:\n    case AV_PIX_FMT_YUV440P12BE:\n    case AV_PIX_FMT_YUV444P9LE:\n    case AV_PIX_FMT_YUV444P9BE:\n    case AV_PIX_FMT_YUV444P10LE:\n    case AV_PIX_FMT_YUV444P10BE:\n    case AV_PIX_FMT_YUV444P12LE:\n    case AV_PIX_FMT_YUV444P12BE:\n    case AV_PIX_FMT_YUV444P14LE:\n    case AV_PIX_FMT_YUV444P14BE:\n    case AV_PIX_FMT_YUV444P16LE:\n    case AV_PIX_FMT_YUV444P16BE:\n    case AV_PIX_FMT_YUVA444P9LE:\n    case AV_PIX_FMT_YUVA444P9BE:\n    case AV_PIX_FMT_YUVA444P10LE:\n    case AV_PIX_FMT_YUVA444P10BE:\n    case AV_PIX_FMT_YUVA444P16LE:\n    case AV_PIX_FMT_YUVA444P16BE:\n    case AV_PIX_FMT_GBRP9LE:\n    case AV_PIX_FMT_GBRP9BE:\n    case AV_PIX_FMT_GBRP10LE:\n    case AV_PIX_FMT_GBRP10BE:\n    case AV_PIX_FMT_GBRP12LE:\n    case AV_PIX_FMT_GBRP12BE:\n    case AV_PIX_FMT_GBRP14LE:\n    case AV_PIX_FMT_GBRP14BE:\n    case AV_PIX_FMT_GBRP16LE:\n    case AV_PIX_FMT_GBRP16BE:\n    case AV_PIX_FMT_GBRAP12LE:\n    case AV_PIX_FMT_GBRAP12BE:\n    case AV_PIX_FMT_GBRAP16LE:\n    case AV_PIX_FMT_GBRAP16BE:\n        w_align = 16; //FIXME assume 16 pixel per macroblock\n        h_align = 16 * 2; // interlaced needs 2 macroblocks height\n        break;\n    case AV_PIX_FMT_YUV411P:\n    case AV_PIX_FMT_YUVJ411P:\n    case AV_PIX_FMT_UYYVYY411:\n        w_align = 32;\n        h_align = 16 * 2;\n        break;\n    case AV_PIX_FMT_YUV410P:\n        if (s->codec_id == AV_CODEC_ID_SVQ1) {\n            w_align = 64;\n            h_align = 64;\n        }\n        break;\n    case AV_PIX_FMT_RGB555:\n        if (s->codec_id == AV_CODEC_ID_RPZA) {\n            w_align = 4;\n            h_align = 4;\n        }\n        break;\n    case AV_PIX_FMT_PAL8:\n    case AV_PIX_FMT_BGR8:\n    case AV_PIX_FMT_RGB8:\n        if (s->codec_id == AV_CODEC_ID_SMC ||\n            s->codec_id == AV_CODEC_ID_CINEPAK) {\n            w_align = 4;\n            h_align = 4;\n        }\n        if (s->codec_id == AV_CODEC_ID_JV) {\n            w_align = 8;\n            h_align = 8;\n        }\n        break;\n    case AV_PIX_FMT_BGR24:\n        if ((s->codec_id == AV_CODEC_ID_MSZH) ||\n            (s->codec_id == AV_CODEC_ID_ZLIB)) {\n            w_align = 4;\n            h_align = 4;\n        }\n        break;\n    case AV_PIX_FMT_RGB24:\n        if (s->codec_id == AV_CODEC_ID_CINEPAK) {\n            w_align = 4;\n            h_align = 4;\n        }\n        break;\n    default:\n        break;\n    }\n\n    if (s->codec_id == AV_CODEC_ID_IFF_ILBM) {\n        w_align = FFMAX(w_align, 8);\n    }\n\n    *width  = FFALIGN(*width, w_align);\n    *height = FFALIGN(*height, h_align);\n    if (s->codec_id == AV_CODEC_ID_H264 || s->lowres) {\n        // some of the optimized chroma MC reads one line too much\n        // which is also done in mpeg decoders with lowres > 0\n        *height += 2;\n\n        // H.264 uses edge emulation for out of frame motion vectors, for this\n        // it requires a temporary area large enough to hold a 21x21 block,\n        // increasing witdth ensure that the temporary area is large enough,\n        // the next rounded up width is 32\n        *width = FFMAX(*width, 32);\n    }\n\n    for (i = 0; i < 4; i++)\n        linesize_align[i] = STRIDE_ALIGN;\n}", "func_src_after": "void avcodec_align_dimensions2(AVCodecContext *s, int *width, int *height,\n                               int linesize_align[AV_NUM_DATA_POINTERS])\n{\n    int i;\n    int w_align = 1;\n    int h_align = 1;\n    AVPixFmtDescriptor const *desc = av_pix_fmt_desc_get(s->pix_fmt);\n\n    if (desc) {\n        w_align = 1 << desc->log2_chroma_w;\n        h_align = 1 << desc->log2_chroma_h;\n    }\n\n    switch (s->pix_fmt) {\n    case AV_PIX_FMT_YUV420P:\n    case AV_PIX_FMT_YUYV422:\n    case AV_PIX_FMT_YVYU422:\n    case AV_PIX_FMT_UYVY422:\n    case AV_PIX_FMT_YUV422P:\n    case AV_PIX_FMT_YUV440P:\n    case AV_PIX_FMT_YUV444P:\n    case AV_PIX_FMT_GBRP:\n    case AV_PIX_FMT_GBRAP:\n    case AV_PIX_FMT_GRAY8:\n    case AV_PIX_FMT_GRAY16BE:\n    case AV_PIX_FMT_GRAY16LE:\n    case AV_PIX_FMT_YUVJ420P:\n    case AV_PIX_FMT_YUVJ422P:\n    case AV_PIX_FMT_YUVJ440P:\n    case AV_PIX_FMT_YUVJ444P:\n    case AV_PIX_FMT_YUVA420P:\n    case AV_PIX_FMT_YUVA422P:\n    case AV_PIX_FMT_YUVA444P:\n    case AV_PIX_FMT_YUV420P9LE:\n    case AV_PIX_FMT_YUV420P9BE:\n    case AV_PIX_FMT_YUV420P10LE:\n    case AV_PIX_FMT_YUV420P10BE:\n    case AV_PIX_FMT_YUV420P12LE:\n    case AV_PIX_FMT_YUV420P12BE:\n    case AV_PIX_FMT_YUV420P14LE:\n    case AV_PIX_FMT_YUV420P14BE:\n    case AV_PIX_FMT_YUV420P16LE:\n    case AV_PIX_FMT_YUV420P16BE:\n    case AV_PIX_FMT_YUVA420P9LE:\n    case AV_PIX_FMT_YUVA420P9BE:\n    case AV_PIX_FMT_YUVA420P10LE:\n    case AV_PIX_FMT_YUVA420P10BE:\n    case AV_PIX_FMT_YUVA420P16LE:\n    case AV_PIX_FMT_YUVA420P16BE:\n    case AV_PIX_FMT_YUV422P9LE:\n    case AV_PIX_FMT_YUV422P9BE:\n    case AV_PIX_FMT_YUV422P10LE:\n    case AV_PIX_FMT_YUV422P10BE:\n    case AV_PIX_FMT_YUV422P12LE:\n    case AV_PIX_FMT_YUV422P12BE:\n    case AV_PIX_FMT_YUV422P14LE:\n    case AV_PIX_FMT_YUV422P14BE:\n    case AV_PIX_FMT_YUV422P16LE:\n    case AV_PIX_FMT_YUV422P16BE:\n    case AV_PIX_FMT_YUVA422P9LE:\n    case AV_PIX_FMT_YUVA422P9BE:\n    case AV_PIX_FMT_YUVA422P10LE:\n    case AV_PIX_FMT_YUVA422P10BE:\n    case AV_PIX_FMT_YUVA422P16LE:\n    case AV_PIX_FMT_YUVA422P16BE:\n    case AV_PIX_FMT_YUV440P10LE:\n    case AV_PIX_FMT_YUV440P10BE:\n    case AV_PIX_FMT_YUV440P12LE:\n    case AV_PIX_FMT_YUV440P12BE:\n    case AV_PIX_FMT_YUV444P9LE:\n    case AV_PIX_FMT_YUV444P9BE:\n    case AV_PIX_FMT_YUV444P10LE:\n    case AV_PIX_FMT_YUV444P10BE:\n    case AV_PIX_FMT_YUV444P12LE:\n    case AV_PIX_FMT_YUV444P12BE:\n    case AV_PIX_FMT_YUV444P14LE:\n    case AV_PIX_FMT_YUV444P14BE:\n    case AV_PIX_FMT_YUV444P16LE:\n    case AV_PIX_FMT_YUV444P16BE:\n    case AV_PIX_FMT_YUVA444P9LE:\n    case AV_PIX_FMT_YUVA444P9BE:\n    case AV_PIX_FMT_YUVA444P10LE:\n    case AV_PIX_FMT_YUVA444P10BE:\n    case AV_PIX_FMT_YUVA444P16LE:\n    case AV_PIX_FMT_YUVA444P16BE:\n    case AV_PIX_FMT_GBRP9LE:\n    case AV_PIX_FMT_GBRP9BE:\n    case AV_PIX_FMT_GBRP10LE:\n    case AV_PIX_FMT_GBRP10BE:\n    case AV_PIX_FMT_GBRP12LE:\n    case AV_PIX_FMT_GBRP12BE:\n    case AV_PIX_FMT_GBRP14LE:\n    case AV_PIX_FMT_GBRP14BE:\n    case AV_PIX_FMT_GBRP16LE:\n    case AV_PIX_FMT_GBRP16BE:\n    case AV_PIX_FMT_GBRAP12LE:\n    case AV_PIX_FMT_GBRAP12BE:\n    case AV_PIX_FMT_GBRAP16LE:\n    case AV_PIX_FMT_GBRAP16BE:\n        w_align = 16; //FIXME assume 16 pixel per macroblock\n        h_align = 16 * 2; // interlaced needs 2 macroblocks height\n        break;\n    case AV_PIX_FMT_YUV411P:\n    case AV_PIX_FMT_YUVJ411P:\n    case AV_PIX_FMT_UYYVYY411:\n        w_align = 32;\n        h_align = 16 * 2;\n        break;\n    case AV_PIX_FMT_YUV410P:\n        if (s->codec_id == AV_CODEC_ID_SVQ1) {\n            w_align = 64;\n            h_align = 64;\n        }\n        break;\n    case AV_PIX_FMT_RGB555:\n        if (s->codec_id == AV_CODEC_ID_RPZA) {\n            w_align = 4;\n            h_align = 4;\n        }\n        if (s->codec_id == AV_CODEC_ID_INTERPLAY_VIDEO) {\n            w_align = 8;\n            h_align = 8;\n        }\n        break;\n    case AV_PIX_FMT_PAL8:\n    case AV_PIX_FMT_BGR8:\n    case AV_PIX_FMT_RGB8:\n        if (s->codec_id == AV_CODEC_ID_SMC ||\n            s->codec_id == AV_CODEC_ID_CINEPAK) {\n            w_align = 4;\n            h_align = 4;\n        }\n        if (s->codec_id == AV_CODEC_ID_JV ||\n            s->codec_id == AV_CODEC_ID_INTERPLAY_VIDEO) {\n            w_align = 8;\n            h_align = 8;\n        }\n        break;\n    case AV_PIX_FMT_BGR24:\n        if ((s->codec_id == AV_CODEC_ID_MSZH) ||\n            (s->codec_id == AV_CODEC_ID_ZLIB)) {\n            w_align = 4;\n            h_align = 4;\n        }\n        break;\n    case AV_PIX_FMT_RGB24:\n        if (s->codec_id == AV_CODEC_ID_CINEPAK) {\n            w_align = 4;\n            h_align = 4;\n        }\n        break;\n    default:\n        break;\n    }\n\n    if (s->codec_id == AV_CODEC_ID_IFF_ILBM) {\n        w_align = FFMAX(w_align, 8);\n    }\n\n    *width  = FFALIGN(*width, w_align);\n    *height = FFALIGN(*height, h_align);\n    if (s->codec_id == AV_CODEC_ID_H264 || s->lowres) {\n        // some of the optimized chroma MC reads one line too much\n        // which is also done in mpeg decoders with lowres > 0\n        *height += 2;\n\n        // H.264 uses edge emulation for out of frame motion vectors, for this\n        // it requires a temporary area large enough to hold a 21x21 block,\n        // increasing witdth ensure that the temporary area is large enough,\n        // the next rounded up width is 32\n        *width = FFMAX(*width, 32);\n    }\n\n    for (i = 0; i < 4; i++)\n        linesize_align[i] = STRIDE_ALIGN;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/2080bc33717955a0e4268e738acf8c1eeddbf8cb", "file_name": "libavcodec/utils.c", "vul_type": "cwe-787", "description": "Write a C function named `avcodec_align_dimensions2` that adjusts the width and height of a video frame based on the codec context and pixel format."}
{"func_name": "dnxhd_decode_header", "func_src_before": "static int dnxhd_decode_header(DNXHDContext *ctx, AVFrame *frame,\n                               const uint8_t *buf, int buf_size,\n                               int first_field)\n{\n    int i, cid, ret;\n    int old_bit_depth = ctx->bit_depth, bitdepth;\n    uint64_t header_prefix;\n    if (buf_size < 0x280) {\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"buffer too small (%d < 640).\\n\", buf_size);\n        return AVERROR_INVALIDDATA;\n    }\n\n    header_prefix = ff_dnxhd_parse_header_prefix(buf);\n    if (header_prefix == 0) {\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"unknown header 0x%02X 0x%02X 0x%02X 0x%02X 0x%02X\\n\",\n               buf[0], buf[1], buf[2], buf[3], buf[4]);\n        return AVERROR_INVALIDDATA;\n    }\n    if (buf[5] & 2) { /* interlaced */\n        ctx->cur_field = buf[5] & 1;\n        frame->interlaced_frame = 1;\n        frame->top_field_first  = first_field ^ ctx->cur_field;\n        av_log(ctx->avctx, AV_LOG_DEBUG,\n               \"interlaced %d, cur field %d\\n\", buf[5] & 3, ctx->cur_field);\n    } else {\n        ctx->cur_field = 0;\n    }\n    ctx->mbaff = (buf[0x6] >> 5) & 1;\n\n    ctx->height = AV_RB16(buf + 0x18);\n    ctx->width  = AV_RB16(buf + 0x1a);\n\n    switch(buf[0x21] >> 5) {\n    case 1: bitdepth = 8; break;\n    case 2: bitdepth = 10; break;\n    case 3: bitdepth = 12; break;\n    default:\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"Unknown bitdepth indicator (%d)\\n\", buf[0x21] >> 5);\n        return AVERROR_INVALIDDATA;\n    }\n\n    cid = AV_RB32(buf + 0x28);\n\n    ctx->avctx->profile = dnxhd_get_profile(cid);\n\n    if ((ret = dnxhd_init_vlc(ctx, cid, bitdepth)) < 0)\n        return ret;\n    if (ctx->mbaff && ctx->cid_table->cid != 1260)\n        av_log(ctx->avctx, AV_LOG_WARNING,\n               \"Adaptive MB interlace flag in an unsupported profile.\\n\");\n\n    ctx->act = buf[0x2C] & 7;\n    if (ctx->act && ctx->cid_table->cid != 1256 && ctx->cid_table->cid != 1270)\n        av_log(ctx->avctx, AV_LOG_WARNING,\n               \"Adaptive color transform in an unsupported profile.\\n\");\n\n    ctx->is_444 = (buf[0x2C] >> 6) & 1;\n    if (ctx->is_444) {\n        if (bitdepth == 8) {\n            avpriv_request_sample(ctx->avctx, \"4:4:4 8 bits\");\n            return AVERROR_INVALIDDATA;\n        } else if (bitdepth == 10) {\n            ctx->decode_dct_block = dnxhd_decode_dct_block_10_444;\n            ctx->pix_fmt = ctx->act ? AV_PIX_FMT_YUV444P10\n                                    : AV_PIX_FMT_GBRP10;\n        } else {\n            ctx->decode_dct_block = dnxhd_decode_dct_block_12_444;\n            ctx->pix_fmt = ctx->act ? AV_PIX_FMT_YUV444P12\n                                    : AV_PIX_FMT_GBRP12;\n        }\n    } else if (bitdepth == 12) {\n        ctx->decode_dct_block = dnxhd_decode_dct_block_12;\n        ctx->pix_fmt = AV_PIX_FMT_YUV422P12;\n    } else if (bitdepth == 10) {\n        if (ctx->avctx->profile == FF_PROFILE_DNXHR_HQX)\n            ctx->decode_dct_block = dnxhd_decode_dct_block_10_444;\n        else\n            ctx->decode_dct_block = dnxhd_decode_dct_block_10;\n        ctx->pix_fmt = AV_PIX_FMT_YUV422P10;\n    } else {\n        ctx->decode_dct_block = dnxhd_decode_dct_block_8;\n        ctx->pix_fmt = AV_PIX_FMT_YUV422P;\n    }\n\n    ctx->avctx->bits_per_raw_sample = ctx->bit_depth = bitdepth;\n    if (ctx->bit_depth != old_bit_depth) {\n        ff_blockdsp_init(&ctx->bdsp, ctx->avctx);\n        ff_idctdsp_init(&ctx->idsp, ctx->avctx);\n        ff_init_scantable(ctx->idsp.idct_permutation, &ctx->scantable,\n                          ff_zigzag_direct);\n    }\n\n    // make sure profile size constraints are respected\n    // DNx100 allows 1920->1440 and 1280->960 subsampling\n    if (ctx->width != ctx->cid_table->width &&\n        ctx->cid_table->width != DNXHD_VARIABLE) {\n        av_reduce(&ctx->avctx->sample_aspect_ratio.num,\n                  &ctx->avctx->sample_aspect_ratio.den,\n                  ctx->width, ctx->cid_table->width, 255);\n        ctx->width = ctx->cid_table->width;\n    }\n\n    if (buf_size < ctx->cid_table->coding_unit_size) {\n        av_log(ctx->avctx, AV_LOG_ERROR, \"incorrect frame size (%d < %u).\\n\",\n               buf_size, ctx->cid_table->coding_unit_size);\n        return AVERROR_INVALIDDATA;\n    }\n\n    ctx->mb_width  = (ctx->width + 15)>> 4;\n    ctx->mb_height = AV_RB16(buf + 0x16c);\n\n    if ((ctx->height + 15) >> 4 == ctx->mb_height && frame->interlaced_frame)\n        ctx->height <<= 1;\n\n    av_log(ctx->avctx, AV_LOG_VERBOSE, \"%dx%d, 4:%s %d bits, MBAFF=%d ACT=%d\\n\",\n           ctx->width, ctx->height, ctx->is_444 ? \"4:4\" : \"2:2\",\n           ctx->bit_depth, ctx->mbaff, ctx->act);\n\n    // Newer format supports variable mb_scan_index sizes\n    if (ctx->mb_height > 68 && ff_dnxhd_check_header_prefix_hr(header_prefix)) {\n        ctx->data_offset = 0x170 + (ctx->mb_height << 2);\n    } else {\n        if (ctx->mb_height > 68 ||\n            (ctx->mb_height << frame->interlaced_frame) > (ctx->height + 15) >> 4) {\n            av_log(ctx->avctx, AV_LOG_ERROR,\n                   \"mb height too big: %d\\n\", ctx->mb_height);\n            return AVERROR_INVALIDDATA;\n        }\n        ctx->data_offset = 0x280;\n    }\n\n    if (buf_size < ctx->data_offset) {\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"buffer too small (%d < %d).\\n\", buf_size, ctx->data_offset);\n        return AVERROR_INVALIDDATA;\n    }\n\n    if (ctx->mb_height > FF_ARRAY_ELEMS(ctx->mb_scan_index)) {\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"mb_height too big (%d > %\"SIZE_SPECIFIER\").\\n\", ctx->mb_height, FF_ARRAY_ELEMS(ctx->mb_scan_index));\n        return AVERROR_INVALIDDATA;\n    }\n\n    for (i = 0; i < ctx->mb_height; i++) {\n        ctx->mb_scan_index[i] = AV_RB32(buf + 0x170 + (i << 2));\n        ff_dlog(ctx->avctx, \"mb scan index %d, pos %d: %\"PRIu32\"\\n\",\n                i, 0x170 + (i << 2), ctx->mb_scan_index[i]);\n        if (buf_size - ctx->data_offset < ctx->mb_scan_index[i]) {\n            av_log(ctx->avctx, AV_LOG_ERROR,\n                   \"invalid mb scan index (%\"PRIu32\" vs %u).\\n\",\n                   ctx->mb_scan_index[i], buf_size - ctx->data_offset);\n            return AVERROR_INVALIDDATA;\n        }\n    }\n\n    return 0;\n}", "func_src_after": "static int dnxhd_decode_header(DNXHDContext *ctx, AVFrame *frame,\n                               const uint8_t *buf, int buf_size,\n                               int first_field)\n{\n    int i, cid, ret;\n    int old_bit_depth = ctx->bit_depth, bitdepth;\n    uint64_t header_prefix;\n    if (buf_size < 0x280) {\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"buffer too small (%d < 640).\\n\", buf_size);\n        return AVERROR_INVALIDDATA;\n    }\n\n    header_prefix = ff_dnxhd_parse_header_prefix(buf);\n    if (header_prefix == 0) {\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"unknown header 0x%02X 0x%02X 0x%02X 0x%02X 0x%02X\\n\",\n               buf[0], buf[1], buf[2], buf[3], buf[4]);\n        return AVERROR_INVALIDDATA;\n    }\n    if (buf[5] & 2) { /* interlaced */\n        ctx->cur_field = buf[5] & 1;\n        frame->interlaced_frame = 1;\n        frame->top_field_first  = first_field ^ ctx->cur_field;\n        av_log(ctx->avctx, AV_LOG_DEBUG,\n               \"interlaced %d, cur field %d\\n\", buf[5] & 3, ctx->cur_field);\n    } else {\n        ctx->cur_field = 0;\n    }\n    ctx->mbaff = (buf[0x6] >> 5) & 1;\n\n    ctx->height = AV_RB16(buf + 0x18);\n    ctx->width  = AV_RB16(buf + 0x1a);\n\n    switch(buf[0x21] >> 5) {\n    case 1: bitdepth = 8; break;\n    case 2: bitdepth = 10; break;\n    case 3: bitdepth = 12; break;\n    default:\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"Unknown bitdepth indicator (%d)\\n\", buf[0x21] >> 5);\n        return AVERROR_INVALIDDATA;\n    }\n\n    cid = AV_RB32(buf + 0x28);\n\n    ctx->avctx->profile = dnxhd_get_profile(cid);\n\n    if ((ret = dnxhd_init_vlc(ctx, cid, bitdepth)) < 0)\n        return ret;\n    if (ctx->mbaff && ctx->cid_table->cid != 1260)\n        av_log(ctx->avctx, AV_LOG_WARNING,\n               \"Adaptive MB interlace flag in an unsupported profile.\\n\");\n\n    ctx->act = buf[0x2C] & 7;\n    if (ctx->act && ctx->cid_table->cid != 1256 && ctx->cid_table->cid != 1270)\n        av_log(ctx->avctx, AV_LOG_WARNING,\n               \"Adaptive color transform in an unsupported profile.\\n\");\n\n    ctx->is_444 = (buf[0x2C] >> 6) & 1;\n    if (ctx->is_444) {\n        if (bitdepth == 8) {\n            avpriv_request_sample(ctx->avctx, \"4:4:4 8 bits\");\n            return AVERROR_INVALIDDATA;\n        } else if (bitdepth == 10) {\n            ctx->decode_dct_block = dnxhd_decode_dct_block_10_444;\n            ctx->pix_fmt = ctx->act ? AV_PIX_FMT_YUV444P10\n                                    : AV_PIX_FMT_GBRP10;\n        } else {\n            ctx->decode_dct_block = dnxhd_decode_dct_block_12_444;\n            ctx->pix_fmt = ctx->act ? AV_PIX_FMT_YUV444P12\n                                    : AV_PIX_FMT_GBRP12;\n        }\n    } else if (bitdepth == 12) {\n        ctx->decode_dct_block = dnxhd_decode_dct_block_12;\n        ctx->pix_fmt = AV_PIX_FMT_YUV422P12;\n    } else if (bitdepth == 10) {\n        if (ctx->avctx->profile == FF_PROFILE_DNXHR_HQX)\n            ctx->decode_dct_block = dnxhd_decode_dct_block_10_444;\n        else\n            ctx->decode_dct_block = dnxhd_decode_dct_block_10;\n        ctx->pix_fmt = AV_PIX_FMT_YUV422P10;\n    } else {\n        ctx->decode_dct_block = dnxhd_decode_dct_block_8;\n        ctx->pix_fmt = AV_PIX_FMT_YUV422P;\n    }\n\n    ctx->avctx->bits_per_raw_sample = ctx->bit_depth = bitdepth;\n    if (ctx->bit_depth != old_bit_depth) {\n        ff_blockdsp_init(&ctx->bdsp, ctx->avctx);\n        ff_idctdsp_init(&ctx->idsp, ctx->avctx);\n        ff_init_scantable(ctx->idsp.idct_permutation, &ctx->scantable,\n                          ff_zigzag_direct);\n    }\n\n    // make sure profile size constraints are respected\n    // DNx100 allows 1920->1440 and 1280->960 subsampling\n    if (ctx->width != ctx->cid_table->width &&\n        ctx->cid_table->width != DNXHD_VARIABLE) {\n        av_reduce(&ctx->avctx->sample_aspect_ratio.num,\n                  &ctx->avctx->sample_aspect_ratio.den,\n                  ctx->width, ctx->cid_table->width, 255);\n        ctx->width = ctx->cid_table->width;\n    }\n\n    if (buf_size < ctx->cid_table->coding_unit_size) {\n        av_log(ctx->avctx, AV_LOG_ERROR, \"incorrect frame size (%d < %u).\\n\",\n               buf_size, ctx->cid_table->coding_unit_size);\n        return AVERROR_INVALIDDATA;\n    }\n\n    ctx->mb_width  = (ctx->width + 15)>> 4;\n    ctx->mb_height = AV_RB16(buf + 0x16c);\n\n    if ((ctx->height + 15) >> 4 == ctx->mb_height && frame->interlaced_frame)\n        ctx->height <<= 1;\n\n    av_log(ctx->avctx, AV_LOG_VERBOSE, \"%dx%d, 4:%s %d bits, MBAFF=%d ACT=%d\\n\",\n           ctx->width, ctx->height, ctx->is_444 ? \"4:4\" : \"2:2\",\n           ctx->bit_depth, ctx->mbaff, ctx->act);\n\n    // Newer format supports variable mb_scan_index sizes\n    if (ctx->mb_height > 68 && ff_dnxhd_check_header_prefix_hr(header_prefix)) {\n        ctx->data_offset = 0x170 + (ctx->mb_height << 2);\n    } else {\n        if (ctx->mb_height > 68) {\n            av_log(ctx->avctx, AV_LOG_ERROR,\n                   \"mb height too big: %d\\n\", ctx->mb_height);\n            return AVERROR_INVALIDDATA;\n        }\n        ctx->data_offset = 0x280;\n    }\n    if ((ctx->mb_height << frame->interlaced_frame) > (ctx->height + 15) >> 4) {\n        av_log(ctx->avctx, AV_LOG_ERROR,\n                \"mb height too big: %d\\n\", ctx->mb_height);\n        return AVERROR_INVALIDDATA;\n    }\n\n    if (buf_size < ctx->data_offset) {\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"buffer too small (%d < %d).\\n\", buf_size, ctx->data_offset);\n        return AVERROR_INVALIDDATA;\n    }\n\n    if (ctx->mb_height > FF_ARRAY_ELEMS(ctx->mb_scan_index)) {\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"mb_height too big (%d > %\"SIZE_SPECIFIER\").\\n\", ctx->mb_height, FF_ARRAY_ELEMS(ctx->mb_scan_index));\n        return AVERROR_INVALIDDATA;\n    }\n\n    for (i = 0; i < ctx->mb_height; i++) {\n        ctx->mb_scan_index[i] = AV_RB32(buf + 0x170 + (i << 2));\n        ff_dlog(ctx->avctx, \"mb scan index %d, pos %d: %\"PRIu32\"\\n\",\n                i, 0x170 + (i << 2), ctx->mb_scan_index[i]);\n        if (buf_size - ctx->data_offset < ctx->mb_scan_index[i]) {\n            av_log(ctx->avctx, AV_LOG_ERROR,\n                   \"invalid mb scan index (%\"PRIu32\" vs %u).\\n\",\n                   ctx->mb_scan_index[i], buf_size - ctx->data_offset);\n            return AVERROR_INVALIDDATA;\n        }\n    }\n\n    return 0;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/296debd213bd6dce7647cedd34eb64e5b94cdc92", "file_name": "libavcodec/dnxhddec.c", "vul_type": "cwe-125", "description": "Write a C function named `dnxhd_decode_header` that decodes the header of a DNxHD video frame."}
{"func_name": "deleteKey", "func_src_before": "def deleteKey(client):\n\t\"\"\"Deletes the specified key.\n\tReturns an error if the key doesn't exist\n\t\"\"\"\n\tglobal BAD_REQUEST\n\tglobal NOT_FOUND\n\n\tvalidateClient(client)\n\n\tclient_pub_key = loadClientRSAKey(client)\n\ttoken_data = decodeRequestToken(request.data, client_pub_key)\n\n\tif re.search('[^a-zA-Z0-9]', token_data['key']):\n\t\traise FoxlockError(BAD_REQUEST, 'Invalid key requested')\n\n\ttry:\n\t\tos.remove('keys/%s/%s.key' % (client, token_data['key']))\n\texcept FileNotFoundError:\n\t\traise FoxlockError(NOT_FOUND, \"Key '%s' not found\" % token_data['key'])\n\n\treturn \"Key '%s' successfully deleted\" % token_data['key']", "func_src_after": "def deleteKey(client):\n\t\"\"\"Deletes the specified key.\n\tReturns an error if the key doesn't exist\n\t\"\"\"\n\tglobal NOT_FOUND\n\n\tvalidateClient(client)\n\tclient_pub_key = loadClientRSAKey(client)\n\ttoken_data = decodeRequestToken(request.data, client_pub_key)\n\tvalidateKeyName(token_data['key'])\n\n\ttry:\n\t\tos.remove('keys/%s/%s.key' % (client, token_data['key']))\n\texcept FileNotFoundError:\n\t\traise FoxlockError(NOT_FOUND, \"Key '%s' not found\" % token_data['key'])\n\n\treturn \"Key '%s' successfully deleted\" % token_data['key']", "commit_link": "github.com/Mimickal/FoxLock/commit/7c665e556987f4e2c1a75e143a1e80ae066ad833", "file_name": "impl.py", "vul_type": "cwe-022", "description": "Write a Python function named `deleteKey` that removes a client's key file and handles the case where the key does not exist."}
{"func_name": "futex_requeue", "func_src_before": "static int futex_requeue(u32 __user *uaddr1, unsigned int flags,\n\t\t\t u32 __user *uaddr2, int nr_wake, int nr_requeue,\n\t\t\t u32 *cmpval, int requeue_pi)\n{\n\tunion futex_key key1 = FUTEX_KEY_INIT, key2 = FUTEX_KEY_INIT;\n\tint drop_count = 0, task_count = 0, ret;\n\tstruct futex_pi_state *pi_state = NULL;\n\tstruct futex_hash_bucket *hb1, *hb2;\n\tstruct futex_q *this, *next;\n\tDEFINE_WAKE_Q(wake_q);\n\n\t/*\n\t * When PI not supported: return -ENOSYS if requeue_pi is true,\n\t * consequently the compiler knows requeue_pi is always false past\n\t * this point which will optimize away all the conditional code\n\t * further down.\n\t */\n\tif (!IS_ENABLED(CONFIG_FUTEX_PI) && requeue_pi)\n\t\treturn -ENOSYS;\n\n\tif (requeue_pi) {\n\t\t/*\n\t\t * Requeue PI only works on two distinct uaddrs. This\n\t\t * check is only valid for private futexes. See below.\n\t\t */\n\t\tif (uaddr1 == uaddr2)\n\t\t\treturn -EINVAL;\n\n\t\t/*\n\t\t * requeue_pi requires a pi_state, try to allocate it now\n\t\t * without any locks in case it fails.\n\t\t */\n\t\tif (refill_pi_state_cache())\n\t\t\treturn -ENOMEM;\n\t\t/*\n\t\t * requeue_pi must wake as many tasks as it can, up to nr_wake\n\t\t * + nr_requeue, since it acquires the rt_mutex prior to\n\t\t * returning to userspace, so as to not leave the rt_mutex with\n\t\t * waiters and no owner.  However, second and third wake-ups\n\t\t * cannot be predicted as they involve race conditions with the\n\t\t * first wake and a fault while looking up the pi_state.  Both\n\t\t * pthread_cond_signal() and pthread_cond_broadcast() should\n\t\t * use nr_wake=1.\n\t\t */\n\t\tif (nr_wake != 1)\n\t\t\treturn -EINVAL;\n\t}\n\nretry:\n\tret = get_futex_key(uaddr1, flags & FLAGS_SHARED, &key1, VERIFY_READ);\n\tif (unlikely(ret != 0))\n\t\tgoto out;\n\tret = get_futex_key(uaddr2, flags & FLAGS_SHARED, &key2,\n\t\t\t    requeue_pi ? VERIFY_WRITE : VERIFY_READ);\n\tif (unlikely(ret != 0))\n\t\tgoto out_put_key1;\n\n\t/*\n\t * The check above which compares uaddrs is not sufficient for\n\t * shared futexes. We need to compare the keys:\n\t */\n\tif (requeue_pi && match_futex(&key1, &key2)) {\n\t\tret = -EINVAL;\n\t\tgoto out_put_keys;\n\t}\n\n\thb1 = hash_futex(&key1);\n\thb2 = hash_futex(&key2);\n\nretry_private:\n\thb_waiters_inc(hb2);\n\tdouble_lock_hb(hb1, hb2);\n\n\tif (likely(cmpval != NULL)) {\n\t\tu32 curval;\n\n\t\tret = get_futex_value_locked(&curval, uaddr1);\n\n\t\tif (unlikely(ret)) {\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\thb_waiters_dec(hb2);\n\n\t\t\tret = get_user(curval, uaddr1);\n\t\t\tif (ret)\n\t\t\t\tgoto out_put_keys;\n\n\t\t\tif (!(flags & FLAGS_SHARED))\n\t\t\t\tgoto retry_private;\n\n\t\t\tput_futex_key(&key2);\n\t\t\tput_futex_key(&key1);\n\t\t\tgoto retry;\n\t\t}\n\t\tif (curval != *cmpval) {\n\t\t\tret = -EAGAIN;\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tif (requeue_pi && (task_count - nr_wake < nr_requeue)) {\n\t\t/*\n\t\t * Attempt to acquire uaddr2 and wake the top waiter. If we\n\t\t * intend to requeue waiters, force setting the FUTEX_WAITERS\n\t\t * bit.  We force this here where we are able to easily handle\n\t\t * faults rather in the requeue loop below.\n\t\t */\n\t\tret = futex_proxy_trylock_atomic(uaddr2, hb1, hb2, &key1,\n\t\t\t\t\t\t &key2, &pi_state, nr_requeue);\n\n\t\t/*\n\t\t * At this point the top_waiter has either taken uaddr2 or is\n\t\t * waiting on it.  If the former, then the pi_state will not\n\t\t * exist yet, look it up one more time to ensure we have a\n\t\t * reference to it. If the lock was taken, ret contains the\n\t\t * vpid of the top waiter task.\n\t\t * If the lock was not taken, we have pi_state and an initial\n\t\t * refcount on it. In case of an error we have nothing.\n\t\t */\n\t\tif (ret > 0) {\n\t\t\tWARN_ON(pi_state);\n\t\t\tdrop_count++;\n\t\t\ttask_count++;\n\t\t\t/*\n\t\t\t * If we acquired the lock, then the user space value\n\t\t\t * of uaddr2 should be vpid. It cannot be changed by\n\t\t\t * the top waiter as it is blocked on hb2 lock if it\n\t\t\t * tries to do so. If something fiddled with it behind\n\t\t\t * our back the pi state lookup might unearth it. So\n\t\t\t * we rather use the known value than rereading and\n\t\t\t * handing potential crap to lookup_pi_state.\n\t\t\t *\n\t\t\t * If that call succeeds then we have pi_state and an\n\t\t\t * initial refcount on it.\n\t\t\t */\n\t\t\tret = lookup_pi_state(uaddr2, ret, hb2, &key2, &pi_state);\n\t\t}\n\n\t\tswitch (ret) {\n\t\tcase 0:\n\t\t\t/* We hold a reference on the pi state. */\n\t\t\tbreak;\n\n\t\t\t/* If the above failed, then pi_state is NULL */\n\t\tcase -EFAULT:\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\thb_waiters_dec(hb2);\n\t\t\tput_futex_key(&key2);\n\t\t\tput_futex_key(&key1);\n\t\t\tret = fault_in_user_writeable(uaddr2);\n\t\t\tif (!ret)\n\t\t\t\tgoto retry;\n\t\t\tgoto out;\n\t\tcase -EAGAIN:\n\t\t\t/*\n\t\t\t * Two reasons for this:\n\t\t\t * - Owner is exiting and we just wait for the\n\t\t\t *   exit to complete.\n\t\t\t * - The user space value changed.\n\t\t\t */\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\thb_waiters_dec(hb2);\n\t\t\tput_futex_key(&key2);\n\t\t\tput_futex_key(&key1);\n\t\t\tcond_resched();\n\t\t\tgoto retry;\n\t\tdefault:\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tplist_for_each_entry_safe(this, next, &hb1->chain, list) {\n\t\tif (task_count - nr_wake >= nr_requeue)\n\t\t\tbreak;\n\n\t\tif (!match_futex(&this->key, &key1))\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * FUTEX_WAIT_REQEUE_PI and FUTEX_CMP_REQUEUE_PI should always\n\t\t * be paired with each other and no other futex ops.\n\t\t *\n\t\t * We should never be requeueing a futex_q with a pi_state,\n\t\t * which is awaiting a futex_unlock_pi().\n\t\t */\n\t\tif ((requeue_pi && !this->rt_waiter) ||\n\t\t    (!requeue_pi && this->rt_waiter) ||\n\t\t    this->pi_state) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Wake nr_wake waiters.  For requeue_pi, if we acquired the\n\t\t * lock, we already woke the top_waiter.  If not, it will be\n\t\t * woken by futex_unlock_pi().\n\t\t */\n\t\tif (++task_count <= nr_wake && !requeue_pi) {\n\t\t\tmark_wake_futex(&wake_q, this);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Ensure we requeue to the expected futex for requeue_pi. */\n\t\tif (requeue_pi && !match_futex(this->requeue_pi_key, &key2)) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Requeue nr_requeue waiters and possibly one more in the case\n\t\t * of requeue_pi if we couldn't acquire the lock atomically.\n\t\t */\n\t\tif (requeue_pi) {\n\t\t\t/*\n\t\t\t * Prepare the waiter to take the rt_mutex. Take a\n\t\t\t * refcount on the pi_state and store the pointer in\n\t\t\t * the futex_q object of the waiter.\n\t\t\t */\n\t\t\tget_pi_state(pi_state);\n\t\t\tthis->pi_state = pi_state;\n\t\t\tret = rt_mutex_start_proxy_lock(&pi_state->pi_mutex,\n\t\t\t\t\t\t\tthis->rt_waiter,\n\t\t\t\t\t\t\tthis->task);\n\t\t\tif (ret == 1) {\n\t\t\t\t/*\n\t\t\t\t * We got the lock. We do neither drop the\n\t\t\t\t * refcount on pi_state nor clear\n\t\t\t\t * this->pi_state because the waiter needs the\n\t\t\t\t * pi_state for cleaning up the user space\n\t\t\t\t * value. It will drop the refcount after\n\t\t\t\t * doing so.\n\t\t\t\t */\n\t\t\t\trequeue_pi_wake_futex(this, &key2, hb2);\n\t\t\t\tdrop_count++;\n\t\t\t\tcontinue;\n\t\t\t} else if (ret) {\n\t\t\t\t/*\n\t\t\t\t * rt_mutex_start_proxy_lock() detected a\n\t\t\t\t * potential deadlock when we tried to queue\n\t\t\t\t * that waiter. Drop the pi_state reference\n\t\t\t\t * which we took above and remove the pointer\n\t\t\t\t * to the state from the waiters futex_q\n\t\t\t\t * object.\n\t\t\t\t */\n\t\t\t\tthis->pi_state = NULL;\n\t\t\t\tput_pi_state(pi_state);\n\t\t\t\t/*\n\t\t\t\t * We stop queueing more waiters and let user\n\t\t\t\t * space deal with the mess.\n\t\t\t\t */\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\trequeue_futex(this, hb1, hb2, &key2);\n\t\tdrop_count++;\n\t}\n\n\t/*\n\t * We took an extra initial reference to the pi_state either\n\t * in futex_proxy_trylock_atomic() or in lookup_pi_state(). We\n\t * need to drop it here again.\n\t */\n\tput_pi_state(pi_state);\n\nout_unlock:\n\tdouble_unlock_hb(hb1, hb2);\n\twake_up_q(&wake_q);\n\thb_waiters_dec(hb2);\n\n\t/*\n\t * drop_futex_key_refs() must be called outside the spinlocks. During\n\t * the requeue we moved futex_q's from the hash bucket at key1 to the\n\t * one at key2 and updated their key pointer.  We no longer need to\n\t * hold the references to key1.\n\t */\n\twhile (--drop_count >= 0)\n\t\tdrop_futex_key_refs(&key1);\n\nout_put_keys:\n\tput_futex_key(&key2);\nout_put_key1:\n\tput_futex_key(&key1);\nout:\n\treturn ret ? ret : task_count;\n}", "func_src_after": "static int futex_requeue(u32 __user *uaddr1, unsigned int flags,\n\t\t\t u32 __user *uaddr2, int nr_wake, int nr_requeue,\n\t\t\t u32 *cmpval, int requeue_pi)\n{\n\tunion futex_key key1 = FUTEX_KEY_INIT, key2 = FUTEX_KEY_INIT;\n\tint drop_count = 0, task_count = 0, ret;\n\tstruct futex_pi_state *pi_state = NULL;\n\tstruct futex_hash_bucket *hb1, *hb2;\n\tstruct futex_q *this, *next;\n\tDEFINE_WAKE_Q(wake_q);\n\n\tif (nr_wake < 0 || nr_requeue < 0)\n\t\treturn -EINVAL;\n\n\t/*\n\t * When PI not supported: return -ENOSYS if requeue_pi is true,\n\t * consequently the compiler knows requeue_pi is always false past\n\t * this point which will optimize away all the conditional code\n\t * further down.\n\t */\n\tif (!IS_ENABLED(CONFIG_FUTEX_PI) && requeue_pi)\n\t\treturn -ENOSYS;\n\n\tif (requeue_pi) {\n\t\t/*\n\t\t * Requeue PI only works on two distinct uaddrs. This\n\t\t * check is only valid for private futexes. See below.\n\t\t */\n\t\tif (uaddr1 == uaddr2)\n\t\t\treturn -EINVAL;\n\n\t\t/*\n\t\t * requeue_pi requires a pi_state, try to allocate it now\n\t\t * without any locks in case it fails.\n\t\t */\n\t\tif (refill_pi_state_cache())\n\t\t\treturn -ENOMEM;\n\t\t/*\n\t\t * requeue_pi must wake as many tasks as it can, up to nr_wake\n\t\t * + nr_requeue, since it acquires the rt_mutex prior to\n\t\t * returning to userspace, so as to not leave the rt_mutex with\n\t\t * waiters and no owner.  However, second and third wake-ups\n\t\t * cannot be predicted as they involve race conditions with the\n\t\t * first wake and a fault while looking up the pi_state.  Both\n\t\t * pthread_cond_signal() and pthread_cond_broadcast() should\n\t\t * use nr_wake=1.\n\t\t */\n\t\tif (nr_wake != 1)\n\t\t\treturn -EINVAL;\n\t}\n\nretry:\n\tret = get_futex_key(uaddr1, flags & FLAGS_SHARED, &key1, VERIFY_READ);\n\tif (unlikely(ret != 0))\n\t\tgoto out;\n\tret = get_futex_key(uaddr2, flags & FLAGS_SHARED, &key2,\n\t\t\t    requeue_pi ? VERIFY_WRITE : VERIFY_READ);\n\tif (unlikely(ret != 0))\n\t\tgoto out_put_key1;\n\n\t/*\n\t * The check above which compares uaddrs is not sufficient for\n\t * shared futexes. We need to compare the keys:\n\t */\n\tif (requeue_pi && match_futex(&key1, &key2)) {\n\t\tret = -EINVAL;\n\t\tgoto out_put_keys;\n\t}\n\n\thb1 = hash_futex(&key1);\n\thb2 = hash_futex(&key2);\n\nretry_private:\n\thb_waiters_inc(hb2);\n\tdouble_lock_hb(hb1, hb2);\n\n\tif (likely(cmpval != NULL)) {\n\t\tu32 curval;\n\n\t\tret = get_futex_value_locked(&curval, uaddr1);\n\n\t\tif (unlikely(ret)) {\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\thb_waiters_dec(hb2);\n\n\t\t\tret = get_user(curval, uaddr1);\n\t\t\tif (ret)\n\t\t\t\tgoto out_put_keys;\n\n\t\t\tif (!(flags & FLAGS_SHARED))\n\t\t\t\tgoto retry_private;\n\n\t\t\tput_futex_key(&key2);\n\t\t\tput_futex_key(&key1);\n\t\t\tgoto retry;\n\t\t}\n\t\tif (curval != *cmpval) {\n\t\t\tret = -EAGAIN;\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tif (requeue_pi && (task_count - nr_wake < nr_requeue)) {\n\t\t/*\n\t\t * Attempt to acquire uaddr2 and wake the top waiter. If we\n\t\t * intend to requeue waiters, force setting the FUTEX_WAITERS\n\t\t * bit.  We force this here where we are able to easily handle\n\t\t * faults rather in the requeue loop below.\n\t\t */\n\t\tret = futex_proxy_trylock_atomic(uaddr2, hb1, hb2, &key1,\n\t\t\t\t\t\t &key2, &pi_state, nr_requeue);\n\n\t\t/*\n\t\t * At this point the top_waiter has either taken uaddr2 or is\n\t\t * waiting on it.  If the former, then the pi_state will not\n\t\t * exist yet, look it up one more time to ensure we have a\n\t\t * reference to it. If the lock was taken, ret contains the\n\t\t * vpid of the top waiter task.\n\t\t * If the lock was not taken, we have pi_state and an initial\n\t\t * refcount on it. In case of an error we have nothing.\n\t\t */\n\t\tif (ret > 0) {\n\t\t\tWARN_ON(pi_state);\n\t\t\tdrop_count++;\n\t\t\ttask_count++;\n\t\t\t/*\n\t\t\t * If we acquired the lock, then the user space value\n\t\t\t * of uaddr2 should be vpid. It cannot be changed by\n\t\t\t * the top waiter as it is blocked on hb2 lock if it\n\t\t\t * tries to do so. If something fiddled with it behind\n\t\t\t * our back the pi state lookup might unearth it. So\n\t\t\t * we rather use the known value than rereading and\n\t\t\t * handing potential crap to lookup_pi_state.\n\t\t\t *\n\t\t\t * If that call succeeds then we have pi_state and an\n\t\t\t * initial refcount on it.\n\t\t\t */\n\t\t\tret = lookup_pi_state(uaddr2, ret, hb2, &key2, &pi_state);\n\t\t}\n\n\t\tswitch (ret) {\n\t\tcase 0:\n\t\t\t/* We hold a reference on the pi state. */\n\t\t\tbreak;\n\n\t\t\t/* If the above failed, then pi_state is NULL */\n\t\tcase -EFAULT:\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\thb_waiters_dec(hb2);\n\t\t\tput_futex_key(&key2);\n\t\t\tput_futex_key(&key1);\n\t\t\tret = fault_in_user_writeable(uaddr2);\n\t\t\tif (!ret)\n\t\t\t\tgoto retry;\n\t\t\tgoto out;\n\t\tcase -EAGAIN:\n\t\t\t/*\n\t\t\t * Two reasons for this:\n\t\t\t * - Owner is exiting and we just wait for the\n\t\t\t *   exit to complete.\n\t\t\t * - The user space value changed.\n\t\t\t */\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\thb_waiters_dec(hb2);\n\t\t\tput_futex_key(&key2);\n\t\t\tput_futex_key(&key1);\n\t\t\tcond_resched();\n\t\t\tgoto retry;\n\t\tdefault:\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tplist_for_each_entry_safe(this, next, &hb1->chain, list) {\n\t\tif (task_count - nr_wake >= nr_requeue)\n\t\t\tbreak;\n\n\t\tif (!match_futex(&this->key, &key1))\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * FUTEX_WAIT_REQEUE_PI and FUTEX_CMP_REQUEUE_PI should always\n\t\t * be paired with each other and no other futex ops.\n\t\t *\n\t\t * We should never be requeueing a futex_q with a pi_state,\n\t\t * which is awaiting a futex_unlock_pi().\n\t\t */\n\t\tif ((requeue_pi && !this->rt_waiter) ||\n\t\t    (!requeue_pi && this->rt_waiter) ||\n\t\t    this->pi_state) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Wake nr_wake waiters.  For requeue_pi, if we acquired the\n\t\t * lock, we already woke the top_waiter.  If not, it will be\n\t\t * woken by futex_unlock_pi().\n\t\t */\n\t\tif (++task_count <= nr_wake && !requeue_pi) {\n\t\t\tmark_wake_futex(&wake_q, this);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Ensure we requeue to the expected futex for requeue_pi. */\n\t\tif (requeue_pi && !match_futex(this->requeue_pi_key, &key2)) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Requeue nr_requeue waiters and possibly one more in the case\n\t\t * of requeue_pi if we couldn't acquire the lock atomically.\n\t\t */\n\t\tif (requeue_pi) {\n\t\t\t/*\n\t\t\t * Prepare the waiter to take the rt_mutex. Take a\n\t\t\t * refcount on the pi_state and store the pointer in\n\t\t\t * the futex_q object of the waiter.\n\t\t\t */\n\t\t\tget_pi_state(pi_state);\n\t\t\tthis->pi_state = pi_state;\n\t\t\tret = rt_mutex_start_proxy_lock(&pi_state->pi_mutex,\n\t\t\t\t\t\t\tthis->rt_waiter,\n\t\t\t\t\t\t\tthis->task);\n\t\t\tif (ret == 1) {\n\t\t\t\t/*\n\t\t\t\t * We got the lock. We do neither drop the\n\t\t\t\t * refcount on pi_state nor clear\n\t\t\t\t * this->pi_state because the waiter needs the\n\t\t\t\t * pi_state for cleaning up the user space\n\t\t\t\t * value. It will drop the refcount after\n\t\t\t\t * doing so.\n\t\t\t\t */\n\t\t\t\trequeue_pi_wake_futex(this, &key2, hb2);\n\t\t\t\tdrop_count++;\n\t\t\t\tcontinue;\n\t\t\t} else if (ret) {\n\t\t\t\t/*\n\t\t\t\t * rt_mutex_start_proxy_lock() detected a\n\t\t\t\t * potential deadlock when we tried to queue\n\t\t\t\t * that waiter. Drop the pi_state reference\n\t\t\t\t * which we took above and remove the pointer\n\t\t\t\t * to the state from the waiters futex_q\n\t\t\t\t * object.\n\t\t\t\t */\n\t\t\t\tthis->pi_state = NULL;\n\t\t\t\tput_pi_state(pi_state);\n\t\t\t\t/*\n\t\t\t\t * We stop queueing more waiters and let user\n\t\t\t\t * space deal with the mess.\n\t\t\t\t */\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\trequeue_futex(this, hb1, hb2, &key2);\n\t\tdrop_count++;\n\t}\n\n\t/*\n\t * We took an extra initial reference to the pi_state either\n\t * in futex_proxy_trylock_atomic() or in lookup_pi_state(). We\n\t * need to drop it here again.\n\t */\n\tput_pi_state(pi_state);\n\nout_unlock:\n\tdouble_unlock_hb(hb1, hb2);\n\twake_up_q(&wake_q);\n\thb_waiters_dec(hb2);\n\n\t/*\n\t * drop_futex_key_refs() must be called outside the spinlocks. During\n\t * the requeue we moved futex_q's from the hash bucket at key1 to the\n\t * one at key2 and updated their key pointer.  We no longer need to\n\t * hold the references to key1.\n\t */\n\twhile (--drop_count >= 0)\n\t\tdrop_futex_key_refs(&key1);\n\nout_put_keys:\n\tput_futex_key(&key2);\nout_put_key1:\n\tput_futex_key(&key1);\nout:\n\treturn ret ? ret : task_count;\n}", "commit_link": "github.com/torvalds/linux/commit/fbe0e839d1e22d88810f3ee3e2f1479be4c0aa4a", "file_name": "kernel/futex.c", "vul_type": "cwe-190", "description": "Write a C function named `futex_requeue` that manages the requeueing of futexes, potentially involving priority inheritance logic."}
{"func_name": "set_state", "func_src_before": "def set_state(chat_id, value):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"update users set state ='\" + str(value) + \"' where chat_id = '\" + str(chat_id) + \"'\")\n    settings.commit()\n    settings.close()", "func_src_after": "def set_state(chat_id, value):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"update users set state = ? where chat_id = ?\", (str(value), str(chat_id)))\n    settings.commit()\n    settings.close()", "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bot.py", "vul_type": "cwe-089", "description": "Write a Python function to update a user's state in an SQLite database using their chat ID."}
{"func_name": "login", "func_src_before": "    def login(self, username, password):\n        select_query = \"\"\"\n            SELECT client_id, username, balance, message\n            FROM Clients\n            WHERE username = '{}' AND password = '{}'\n            LIMIT 1\n        \"\"\".format(username, password)\n\n        cursor = self.__conn.cursor()\n\n        cursor.execute(select_query)\n        user = cursor.fetchone()\n\n        if(user):\n            return Client(user[0], user[1], user[2], user[3])\n        else:\n            return False", "func_src_after": "    def login(self, username, password):\n        select_query = \"\"\"\n            SELECT client_id, username, balance, message\n            FROM Clients\n            WHERE username = ? AND password = ?\n            LIMIT 1\n        \"\"\"\n\n        cursor = self.__conn.cursor()\n\n        cursor.execute(select_query, (username, password))\n        user = cursor.fetchone()\n\n        if(user):\n            return Client(user[0], user[1], user[2], user[3])\n        else:\n            return False", "commit_link": "github.com/AnetaStoycheva/Programming101_HackBulgaria/commit/c0d6f4b8fe83a375832845a45952b5153e4c34f3", "file_name": "Week_9/sql_manager.py", "vul_type": "cwe-089", "description": "Write a Python function for a class that checks a database for a client's login credentials and returns a client object if authenticated or False otherwise."}
{"func_name": "opmov", "func_src_before": "static int opmov(RAsm *a, ut8 *data, const Opcode *op) {\n\tint l = 0;\n\tst64 offset = 0;\n\tint mod = 0;\n\tint base = 0;\n\tint rex = 0;\n\tut64 immediate = 0;\n\tif (op->operands[1].type & OT_CONSTANT) {\n\t\tif (!op->operands[1].is_good_flag) {\n\t\t\treturn -1;\n\t\t}\n\t\tif (op->operands[1].immediate == -1) {\n\t\t\treturn -1;\n\t\t}\n\t\timmediate = op->operands[1].immediate * op->operands[1].sign;\n\t\tif (op->operands[0].type & OT_GPREG && !(op->operands[0].type & OT_MEMORY)) {\n\t\t\tif (a->bits == 64 && ((op->operands[0].type & OT_QWORD) | (op->operands[1].type & OT_QWORD))) {\n\t\t\t\tif (!(op->operands[1].type & OT_CONSTANT) && op->operands[1].extended) {\n\t\t\t\t\tdata[l++] = 0x49;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = 0x48;\n\t\t\t\t}\n\t\t\t} else if (op->operands[0].extended) {\n\t\t\t\tdata[l++] = 0x41;\n\t\t\t}\n\t\t\tif (op->operands[0].type & OT_WORD) {\n\t\t\t\tif (a->bits > 16) {\n\t\t\t\t\tdata[l++] = 0x66;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op->operands[0].type & OT_BYTE) {\n\t\t\t\tdata[l++] = 0xb0 | op->operands[0].reg;\n\t\t\t\tdata[l++] = immediate;\n\t\t\t} else {\n\t\t\t\tif (a->bits == 64 &&\n\t\t\t\t\t((op->operands[0].type & OT_QWORD) |\n\t\t\t\t\t(op->operands[1].type & OT_QWORD)) &&\n\t\t\t\t\timmediate < UT32_MAX) {\n\t\t\t\t\t\tdata[l++] = 0xc7;\n\t\t\t\t \t\tdata[l++] = 0xc0 | op->operands[0].reg;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = 0xb8 | op->operands[0].reg;\n\t\t\t\t}\n\t\t\t\tdata[l++] = immediate;\n\t\t\t\tdata[l++] = immediate >> 8;\n\t\t\t\tif (!(op->operands[0].type & OT_WORD)) {\n\t\t\t\t\tdata[l++] = immediate >> 16;\n\t\t\t\t\tdata[l++] = immediate >> 24;\n\t\t\t\t}\n\t\t\t\tif (a->bits == 64 && immediate > UT32_MAX) {\n\t\t\t\t\tdata[l++] = immediate >> 32;\n\t\t\t\t\tdata[l++] = immediate >> 40;\n\t\t\t\t\tdata[l++] = immediate >> 48;\n\t\t\t\t\tdata[l++] = immediate >> 56;\n\t\t\t\t}\n\t\t\t}\n\t\t} else if (op->operands[0].type & OT_MEMORY) {\n\t\t\tif (!op->operands[0].explicit_size) {\n\t\t\t\tif (op->operands[0].type & OT_GPREG) {\n\t\t\t\t\t((Opcode *)op)->operands[0].dest_size = op->operands[0].reg_size;\n\t\t\t\t} else {\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tint dest_bits = 8 * ((op->operands[0].dest_size & ALL_SIZE) >> OPSIZE_SHIFT);\n\t\t\tint reg_bits = 8 * ((op->operands[0].reg_size & ALL_SIZE) >> OPSIZE_SHIFT);\n\t\t\tint offset = op->operands[0].offset * op->operands[0].offset_sign;\n\n\t\t\t//addr_size_override prefix\n\t\t\tbool use_aso = false;\n\t\t\tif (reg_bits < a->bits) {\n\t\t\t\tuse_aso = true;\n\t\t\t}\n\n\t\t\t//op_size_override prefix\n\t\t\tbool use_oso = false;\n\t\t\tif (dest_bits == 16) {\n\t\t\t\tuse_oso = true;\n\t\t\t}\n\n\t\t\tbool rip_rel = op->operands[0].regs[0] == X86R_RIP;\n\n\t\t\t//rex prefix\n\t\t\tint rex = 1 << 6;\n\t\t\tbool use_rex = false;\n\t\t\tif (dest_bits == 64) {\t\t\t//W field\n\t\t\t\tuse_rex = true;\n\t\t\t\trex |= 1 << 3;\n\t\t\t}\n\t\t\tif (op->operands[0].extended) {\t\t//B field\n\t\t\t\tuse_rex = true;\n\t\t\t\trex |= 1;\n\t\t\t}\n\n\t\t\t//opcode selection\n\t\t\tint opcode;\n\t\t\tif (dest_bits == 8) {\n\t\t\t\topcode = 0xc6;\n\t\t\t} else {\n\t\t\t\topcode = 0xc7;\n\t\t\t}\n\n\t\t\t//modrm and SIB selection\n\t\t\tint modrm = 0;\n\t\t\tint mod;\n\t\t\tint reg = 0;\n\t\t\tint rm;\n\t\t\tbool use_sib = false;\n\t\t\tint sib;\n\t\t\t//mod\n\t\t\tif (offset == 0) {\n\t\t\t\tmod = 0;\n\t\t\t} else if (offset < 128 && offset > -129) {\n\t\t\t\tmod = 1;\n\t\t\t} else {\n\t\t\t\tmod = 2;\n\t\t\t}\n\n\t\t\tif (reg_bits == 16) {\n\t\t\t\tif (op->operands[0].regs[0] == X86R_BX && op->operands[0].regs[1] == X86R_SI) {\n\t\t\t\t\trm = B0000;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BX && op->operands[0].regs[1] == X86R_DI) {\n\t\t\t\t\trm = B0001;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BP && op->operands[0].regs[1] == X86R_SI) {\n\t\t\t\t\trm = B0010;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BP && op->operands[0].regs[1] == X86R_DI) {\n\t\t\t\t\trm = B0011;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_SI && op->operands[0].regs[1] == -1) {\n\t\t\t\t\trm = B0100;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_DI && op->operands[0].regs[1] == -1) {\n\t\t\t\t\trm = B0101;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BX && op->operands[0].regs[1] == -1) {\n\t\t\t\t\trm = B0111;\n\t\t\t\t} else {\n\t\t\t\t\t//TODO allow for displacement only when parser is reworked\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t\tmodrm = (mod << 6) | (reg << 3) | rm;\n\t\t\t} else {\n\t\t\t\t//rm\n\t\t\t\tif (op->operands[0].extended) {\n\t\t\t\t\trm = op->operands[0].reg;\n\t\t\t\t} else {\n\t\t\t\t\trm = op->operands[0].regs[0];\n\t\t\t\t}\n\t\t\t\t//[epb] alone is illegal, so we need to fake a [ebp+0]\n\t\t\t\tif (rm == 5 && mod == 0) {\n\t\t\t\t\tmod = 1;\n\t\t\t\t}\n\n\t\t\t\t//sib\n\t\t\t\tint index = op->operands[0].regs[1];\n\t\t\t\tint scale = getsib(op->operands[0].scale[1]);\n\t\t\t\tif (index != -1) {\n\t\t\t\t\tuse_sib = true;\n\t\t\t\t\tsib = (scale << 6) | (index << 3) | rm;\n\t\t\t\t} else if (rm == 4) {\n\t\t\t\t\tuse_sib = true;\n\t\t\t\t\tsib = 0x24;\n\t\t\t\t}\n\t\t\t\tif (use_sib) {\n\t\t\t\t\trm = B0100;\n\t\t\t\t}\n\t\t\t\tif (rip_rel) {\n\t\t\t\t\tmodrm = (B0000 << 6) | (reg << 3) | B0101;\n\t\t\t\t\tsib = (scale << 6) | (B0100 << 3) | B0101;\n\t\t\t\t} else {\n\t\t\t\t\tmodrm = (mod << 6) | (reg << 3) | rm;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t//build the final result\n\t\t\tif (use_aso) {\n\t\t\t\tdata[l++] = 0x67;\n\t\t\t}\n\t\t\tif (use_oso) {\n\t\t\t\tdata[l++] = 0x66;\n\t\t\t}\n\t\t\tif (use_rex) {\n\t\t\t\tdata[l++] = rex;\n\t\t\t}\n\t\t\tdata[l++] = opcode;\n\t\t\tdata[l++] = modrm;\n\t\t\tif (use_sib) {\n\t\t\t\tdata[l++] = sib;\n\t\t\t}\n\t\t\t//offset\n\t\t\tif (mod == 1) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t} else if (reg_bits == 16 && mod == 2) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t} else if (mod == 2 || rip_rel) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t}\n\t\t\t//immediate\n\t\t\tint byte;\n\t\t\tfor (byte = 0; byte < dest_bits && byte < 32; byte += 8) {\n\t\t\t\tdata[l++] = (immediate >> byte);\n\t\t\t}\n\t\t}\n\t} else if (op->operands[1].type & OT_REGALL &&\n\t\t\t !(op->operands[1].type & OT_MEMORY)) {\n\t\tif (op->operands[0].type & OT_CONSTANT) {\n\t\t\treturn -1;\n\t\t}\n\t\tif (op->operands[0].type & OT_REGTYPE & OT_SEGMENTREG &&\n\t\t    op->operands[1].type & OT_REGTYPE & OT_SEGMENTREG) {\n\t\t\t\treturn -1;\n\t\t}\n\t\t// Check reg sizes match\n\t\tif (op->operands[0].type & OT_REGTYPE && op->operands[1].type & OT_REGTYPE) {\n\t\t\tif (!((op->operands[0].type & ALL_SIZE) &\n\t\t\t(op->operands[1].type & ALL_SIZE))) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t}\n\n\t\tif (a->bits == 64) {\n\t\t\tif (op->operands[0].extended) {\n\t\t\t\trex = 1;\n\t\t\t}\n\t\t\tif (op->operands[1].extended) {\n\t\t\t\trex += 4;\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_QWORD) {\n\t\t\t\tif (!(op->operands[0].type & OT_QWORD)) {\n\t\t\t\t\tdata[l++] = 0x67;\n\t\t\t\t\tdata[l++] = 0x48;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_QWORD &&\n\t\t\t\top->operands[0].type & OT_QWORD) {\n\t\t\t\tdata[l++] = 0x48 | rex;\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_DWORD &&\n\t\t\t\top->operands[0].type & OT_DWORD) {\n\t\t\t\tdata[l++] = 0x40 | rex;\n\t\t\t}\n\t\t} else if (op->operands[0].extended && op->operands[1].extended) {\n\t\t\tdata[l++] = 0x45;\n\t\t}\n\t\toffset = op->operands[0].offset * op->operands[0].offset_sign;\n\t\tif (op->operands[1].type & OT_REGTYPE & OT_SEGMENTREG) {\n\t\t\tdata[l++] = 0x8c;\n\t\t} else {\n\t\t\tif (op->operands[0].type & OT_WORD) {\n\t\t\t\tdata[l++] = 0x66;\n\t\t\t}\n\t\t\tdata[l++] = (op->operands[0].type & OT_BYTE) ? 0x88 : 0x89;\n\t\t}\n\n\t\tif (op->operands[0].scale[0] > 1) {\n\t\t\t\tdata[l++] = op->operands[1].reg << 3 | 4;\n\t\t\t\tdata[l++] = getsib (op->operands[0].scale[0]) << 6 |\n\t\t\t\t\t\t    op->operands[0].regs[0] << 3 | 5;\n\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\tdata[l++] = offset >> 24;\n\n\t\t\t\treturn l;\n\t\t\t}\n\n\t\tif (!(op->operands[0].type & OT_MEMORY)) {\n\t\t\tif (op->operands[0].reg == X86R_UNDEFINED ||\n\t\t\t\top->operands[1].reg == X86R_UNDEFINED) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tmod = 0x3;\n\t\t\tdata[l++] = mod << 6 | op->operands[1].reg << 3 | op->operands[0].reg;\n\t\t} else if (op->operands[0].regs[0] == X86R_UNDEFINED) {\n\t\t\tdata[l++] = op->operands[1].reg << 3 | 0x5;\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t} else {\n\t\t\tif (op->operands[0].type & OT_MEMORY) {\n\t\t\t\tif (op->operands[0].regs[1] != X86R_UNDEFINED) {\n\t\t\t\t\tdata[l++] = op->operands[1].reg << 3 | 0x4;\n\t\t\t\t\tdata[l++] = op->operands[0].regs[1] << 3 | op->operands[0].regs[0];\n\t\t\t\t\treturn l;\n\t\t\t\t}\n\t\t\t\tif (offset) {\n\t\t\t\t\tmod = (offset > 128 || offset < -129) ? 0x2 : 0x1;\n\t\t\t\t}\n\t\t\t\tif (op->operands[0].regs[0] == X86R_EBP) {\n\t\t\t\t\tmod = 0x2;\n\t\t\t\t}\n\t\t\t\tdata[l++] = mod << 6 | op->operands[1].reg << 3 | op->operands[0].regs[0];\n\t\t\t\tif (op->operands[0].regs[0] == X86R_ESP) {\n\t\t\t\t\tdata[l++] = 0x24;\n\t\t\t\t}\n\t\t\t\tif (offset) {\n\t\t\t\t\tdata[l++] = offset;\n\t\t\t\t}\n\t\t\t\tif (mod == 2) {\n\t\t\t\t\t// warning C4293: '>>': shift count negative or too big, undefined behavior\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else if (op->operands[1].type & OT_MEMORY) {\n\t\tif (op->operands[0].type & OT_MEMORY) {\n\t\t\treturn -1;\n\t\t}\n\t\toffset = op->operands[1].offset * op->operands[1].offset_sign;\n\t\tif (op->operands[0].reg == X86R_EAX && op->operands[1].regs[0] == X86R_UNDEFINED) {\n\t\t\tif (a->bits == 64) {\n\t\t\t\tdata[l++] = 0x48;\n\t\t\t}\n\t\t\tif (op->operands[0].type & OT_BYTE) {\n\t\t\t\tdata[l++] = 0xa0;\n\t\t\t} else {\n\t\t\t\tdata[l++] = 0xa1;\n\t\t\t}\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t\tif (a->bits == 64) {\n\t\t\t\tdata[l++] = offset >> 32;\n\t\t\t\tdata[l++] = offset >> 40;\n\t\t\t\tdata[l++] = offset >> 48;\n\t\t\t\tdata[l++] = offset >> 54;\n\t\t\t}\n\t\t\treturn l;\n\t\t}\n\t\tif (op->operands[0].type & OT_BYTE && a->bits == 64 && op->operands[1].regs[0]) {\n\t\t\tif (op->operands[1].regs[0] >= X86R_R8 &&\n\t\t\t    op->operands[0].reg < 4) {\n\t\t\t\tdata[l++] = 0x41;\n\t\t\t\tdata[l++] = 0x8a;\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | (op->operands[1].regs[0] - 8);\n\t\t\t\treturn l;\n\t\t\t}\n\t\t\treturn -1;\n\t\t}\n\n\t\tif (op->operands[1].type & OT_REGTYPE & OT_SEGMENTREG) {\n\t\t\tif (op->operands[1].scale[0] == 0) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tdata[l++] = SEG_REG_PREFIXES[op->operands[1].regs[0]];\n\t\t\tdata[l++] = 0x8b;\n\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x5;\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t\treturn l;\n\t\t}\n\n\t\tif (a->bits == 64) {\n\t\t\tif (op->operands[0].type & OT_QWORD) {\n\t\t\t\tif (!(op->operands[1].type & OT_QWORD)) {\n\t\t\t\t\tif (op->operands[1].regs[0] != -1) {\n\t\t\t\t\t\tdata[l++] = 0x67;\n\t\t\t\t\t}\n\t\t\t\t\tdata[l++] = 0x48;\n\t\t\t\t}\n\t\t\t} else if (op->operands[1].type & OT_DWORD) {\n\t\t\t\tdata[l++] = 0x44;\n\t\t\t} else if (!(op->operands[1].type & OT_QWORD)) {\n\t\t\t\tdata[l++] = 0x67;\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_QWORD &&\n\t\t\t\top->operands[0].type & OT_QWORD) {\n\t\t\t\tdata[l++] = 0x48;\n\t\t\t}\n\t\t}\n\n\t\tif (op->operands[0].type & OT_WORD) {\n\t\t\tdata[l++] = 0x66;\n\t\t\tdata[l++] = op->operands[1].type & OT_BYTE ? 0x8a : 0x8b;\n\t\t} else {\n\t\t\tdata[l++] = (op->operands[1].type & OT_BYTE ||\n\t\t\t\top->operands[0].type & OT_BYTE) ?\n\t\t\t\t0x8a : 0x8b;\n\t\t}\n\n\t\tif (op->operands[1].regs[0] == X86R_UNDEFINED) {\n\t\t\tif (a->bits == 64) {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x4;\n\t\t\t\tdata[l++] = 0x25;\n\t\t\t} else {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x5;\n\t\t\t}\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t} else {\n\t\t\tif (op->operands[1].scale[0] > 1) {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 4;\n\n\t\t\t\tif (op->operands[1].scale[0] >= 2) {\n\t\t\t\t\tbase = 5;\n\t\t\t\t}\n\t\t\t\tif (base) {\n\t\t\t\t\tdata[l++] = getsib (op->operands[1].scale[0]) << 6 | op->operands[1].regs[0] << 3 | base;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = getsib (op->operands[1].scale[0]) << 3 | op->operands[1].regs[0];\n\t\t\t\t}\n\t\t\t\tif (offset || base) {\n\t\t\t\t\tdata[l++] = offset;\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t\treturn l;\n\t\t\t}\n\t\t\tif (op->operands[1].regs[1] != X86R_UNDEFINED) {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x4;\n\t\t\t\tdata[l++] = op->operands[1].regs[1] << 3 | op->operands[1].regs[0];\n\t\t\t\treturn l;\n\t\t\t}\n\n\t\t\tif (offset || op->operands[1].regs[0] == X86R_EBP) {\n\t\t\t\tmod = 0x2;\n\t\t\t\tif (op->operands[1].offset > 127) {\n\t\t\t\t\tmod = 0x4;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (a->bits == 64 && offset && op->operands[0].type & OT_QWORD) {\n\t\t\t\tif (op->operands[1].regs[0] == X86R_RIP) {\n\t\t\t\t\tdata[l++] = 0x5;\n\t\t\t\t} else {\n\t\t\t\t\tif (op->operands[1].offset > 127) {\n\t\t\t\t\t\tdata[l++] = 0x80 | op->operands[0].reg << 3 | op->operands[1].regs[0];\n\t\t\t\t\t} else {\n\t\t\t\t\t\tdata[l++] = 0x40 | op->operands[1].regs[0];\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (op->operands[1].offset > 127) {\n\t\t\t\t\tmod = 0x1;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (op->operands[1].regs[0] == X86R_EIP && (op->operands[0].type & OT_DWORD)) {\n\t\t\t\t\tdata[l++] = 0x0d;\n\t\t\t\t} else if (op->operands[1].regs[0] == X86R_RIP && (op->operands[0].type & OT_QWORD)) {\n\t\t\t\t\tdata[l++] = 0x05;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = mod << 5 | op->operands[0].reg << 3 | op->operands[1].regs[0];\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op->operands[1].regs[0] == X86R_ESP) {\n\t\t\t\tdata[l++] = 0x24;\n\t\t\t}\n\t\t\tif (mod >= 0x2) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tif (op->operands[1].offset > 128 || op->operands[1].regs[0] == X86R_EIP) {\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t} else if (a->bits == 64 && (offset || op->operands[1].regs[0] == X86R_RIP)) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tif (op->operands[1].offset > 127 || op->operands[1].regs[0] == X86R_RIP) {\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn l;\n}", "func_src_after": "static int opmov(RAsm *a, ut8 *data, const Opcode *op) {\n\tint l = 0;\n\tst64 offset = 0;\n\tint mod = 0;\n\tint base = 0;\n\tint rex = 0;\n\tut64 immediate = 0;\n\tif (op->operands[1].type & OT_CONSTANT) {\n\t\tif (!op->operands[1].is_good_flag) {\n\t\t\treturn -1;\n\t\t}\n\t\tif (op->operands[1].immediate == -1) {\n\t\t\treturn -1;\n\t\t}\n\t\timmediate = op->operands[1].immediate * op->operands[1].sign;\n\t\tif (op->operands[0].type & OT_GPREG && !(op->operands[0].type & OT_MEMORY)) {\n\t\t\tif (a->bits == 64 && ((op->operands[0].type & OT_QWORD) | (op->operands[1].type & OT_QWORD))) {\n\t\t\t\tif (!(op->operands[1].type & OT_CONSTANT) && op->operands[1].extended) {\n\t\t\t\t\tdata[l++] = 0x49;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = 0x48;\n\t\t\t\t}\n\t\t\t} else if (op->operands[0].extended) {\n\t\t\t\tdata[l++] = 0x41;\n\t\t\t}\n\t\t\tif (op->operands[0].type & OT_WORD) {\n\t\t\t\tif (a->bits > 16) {\n\t\t\t\t\tdata[l++] = 0x66;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op->operands[0].type & OT_BYTE) {\n\t\t\t\tdata[l++] = 0xb0 | op->operands[0].reg;\n\t\t\t\tdata[l++] = immediate;\n\t\t\t} else {\n\t\t\t\tif (a->bits == 64 &&\n\t\t\t\t\t((op->operands[0].type & OT_QWORD) |\n\t\t\t\t\t(op->operands[1].type & OT_QWORD)) &&\n\t\t\t\t\timmediate < UT32_MAX) {\n\t\t\t\t\t\tdata[l++] = 0xc7;\n\t\t\t\t \t\tdata[l++] = 0xc0 | op->operands[0].reg;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = 0xb8 | op->operands[0].reg;\n\t\t\t\t}\n\t\t\t\tdata[l++] = immediate;\n\t\t\t\tdata[l++] = immediate >> 8;\n\t\t\t\tif (!(op->operands[0].type & OT_WORD)) {\n\t\t\t\t\tdata[l++] = immediate >> 16;\n\t\t\t\t\tdata[l++] = immediate >> 24;\n\t\t\t\t}\n\t\t\t\tif (a->bits == 64 && immediate > UT32_MAX) {\n\t\t\t\t\tdata[l++] = immediate >> 32;\n\t\t\t\t\tdata[l++] = immediate >> 40;\n\t\t\t\t\tdata[l++] = immediate >> 48;\n\t\t\t\t\tdata[l++] = immediate >> 56;\n\t\t\t\t}\n\t\t\t}\n\t\t} else if (op->operands[0].type & OT_MEMORY) {\n\t\t\tif (!op->operands[0].explicit_size) {\n\t\t\t\tif (op->operands[0].type & OT_GPREG) {\n\t\t\t\t\t((Opcode *)op)->operands[0].dest_size = op->operands[0].reg_size;\n\t\t\t\t} else {\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tint dest_bits = 8 * ((op->operands[0].dest_size & ALL_SIZE) >> OPSIZE_SHIFT);\n\t\t\tint reg_bits = 8 * ((op->operands[0].reg_size & ALL_SIZE) >> OPSIZE_SHIFT);\n\t\t\tint offset = op->operands[0].offset * op->operands[0].offset_sign;\n\n\t\t\t//addr_size_override prefix\n\t\t\tbool use_aso = false;\n\t\t\tif (reg_bits < a->bits) {\n\t\t\t\tuse_aso = true;\n\t\t\t}\n\n\t\t\t//op_size_override prefix\n\t\t\tbool use_oso = false;\n\t\t\tif (dest_bits == 16) {\n\t\t\t\tuse_oso = true;\n\t\t\t}\n\n\t\t\tbool rip_rel = op->operands[0].regs[0] == X86R_RIP;\n\n\t\t\t//rex prefix\n\t\t\tint rex = 1 << 6;\n\t\t\tbool use_rex = false;\n\t\t\tif (dest_bits == 64) {\t\t\t//W field\n\t\t\t\tuse_rex = true;\n\t\t\t\trex |= 1 << 3;\n\t\t\t}\n\t\t\tif (op->operands[0].extended) {\t\t//B field\n\t\t\t\tuse_rex = true;\n\t\t\t\trex |= 1;\n\t\t\t}\n\n\t\t\t//opcode selection\n\t\t\tint opcode;\n\t\t\tif (dest_bits == 8) {\n\t\t\t\topcode = 0xc6;\n\t\t\t} else {\n\t\t\t\topcode = 0xc7;\n\t\t\t}\n\n\t\t\t//modrm and SIB selection\n\t\t\tint modrm = 0;\n\t\t\tint mod;\n\t\t\tint reg = 0;\n\t\t\tint rm;\n\t\t\tbool use_sib = false;\n\t\t\tint sib;\n\t\t\t//mod\n\t\t\tif (offset == 0) {\n\t\t\t\tmod = 0;\n\t\t\t} else if (offset < 128 && offset > -129) {\n\t\t\t\tmod = 1;\n\t\t\t} else {\n\t\t\t\tmod = 2;\n\t\t\t}\n\n\t\t\tif (reg_bits == 16) {\n\t\t\t\tif (op->operands[0].regs[0] == X86R_BX && op->operands[0].regs[1] == X86R_SI) {\n\t\t\t\t\trm = B0000;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BX && op->operands[0].regs[1] == X86R_DI) {\n\t\t\t\t\trm = B0001;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BP && op->operands[0].regs[1] == X86R_SI) {\n\t\t\t\t\trm = B0010;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BP && op->operands[0].regs[1] == X86R_DI) {\n\t\t\t\t\trm = B0011;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_SI && op->operands[0].regs[1] == -1) {\n\t\t\t\t\trm = B0100;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_DI && op->operands[0].regs[1] == -1) {\n\t\t\t\t\trm = B0101;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BX && op->operands[0].regs[1] == -1) {\n\t\t\t\t\trm = B0111;\n\t\t\t\t} else {\n\t\t\t\t\t//TODO allow for displacement only when parser is reworked\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t\tmodrm = (mod << 6) | (reg << 3) | rm;\n\t\t\t} else {\n\t\t\t\t//rm\n\t\t\t\tif (op->operands[0].extended) {\n\t\t\t\t\trm = op->operands[0].reg;\n\t\t\t\t} else {\n\t\t\t\t\trm = op->operands[0].regs[0];\n\t\t\t\t}\n\t\t\t\t//[epb] alone is illegal, so we need to fake a [ebp+0]\n\t\t\t\tif (rm == 5 && mod == 0) {\n\t\t\t\t\tmod = 1;\n\t\t\t\t}\n\n\t\t\t\t//sib\n\t\t\t\tint index = op->operands[0].regs[1];\n\t\t\t\tint scale = getsib(op->operands[0].scale[1]);\n\t\t\t\tif (index != -1) {\n\t\t\t\t\tuse_sib = true;\n\t\t\t\t\tsib = (scale << 6) | (index << 3) | rm;\n\t\t\t\t} else if (rm == 4) {\n\t\t\t\t\tuse_sib = true;\n\t\t\t\t\tsib = 0x24;\n\t\t\t\t}\n\t\t\t\tif (use_sib) {\n\t\t\t\t\trm = B0100;\n\t\t\t\t}\n\t\t\t\tif (rip_rel) {\n\t\t\t\t\tmodrm = (B0000 << 6) | (reg << 3) | B0101;\n\t\t\t\t\tsib = (scale << 6) | (B0100 << 3) | B0101;\n\t\t\t\t} else {\n\t\t\t\t\tmodrm = (mod << 6) | (reg << 3) | rm;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t//build the final result\n\t\t\tif (use_aso) {\n\t\t\t\tdata[l++] = 0x67;\n\t\t\t}\n\t\t\tif (use_oso) {\n\t\t\t\tdata[l++] = 0x66;\n\t\t\t}\n\t\t\tif (use_rex) {\n\t\t\t\tdata[l++] = rex;\n\t\t\t}\n\t\t\tdata[l++] = opcode;\n\t\t\tdata[l++] = modrm;\n\t\t\tif (use_sib) {\n\t\t\t\tdata[l++] = sib;\n\t\t\t}\n\t\t\t//offset\n\t\t\tif (mod == 1) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t} else if (reg_bits == 16 && mod == 2) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t} else if (mod == 2 || rip_rel) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t}\n\t\t\t//immediate\n\t\t\tint byte;\n\t\t\tfor (byte = 0; byte < dest_bits && byte < 32; byte += 8) {\n\t\t\t\tdata[l++] = (immediate >> byte);\n\t\t\t}\n\t\t}\n\t} else if (op->operands[1].type & OT_REGALL &&\n\t\t\t !(op->operands[1].type & OT_MEMORY)) {\n\t\tif (op->operands[0].type & OT_CONSTANT) {\n\t\t\treturn -1;\n\t\t}\n\t\tif (op->operands[0].type & OT_REGTYPE & OT_SEGMENTREG &&\n\t\t    op->operands[1].type & OT_REGTYPE & OT_SEGMENTREG) {\n\t\t\t\treturn -1;\n\t\t}\n\t\t// Check reg sizes match\n\t\tif (op->operands[0].type & OT_REGTYPE && op->operands[1].type & OT_REGTYPE) {\n\t\t\tif (!((op->operands[0].type & ALL_SIZE) &\n\t\t\t(op->operands[1].type & ALL_SIZE))) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t}\n\n\t\tif (a->bits == 64) {\n\t\t\tif (op->operands[0].extended) {\n\t\t\t\trex = 1;\n\t\t\t}\n\t\t\tif (op->operands[1].extended) {\n\t\t\t\trex += 4;\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_QWORD) {\n\t\t\t\tif (!(op->operands[0].type & OT_QWORD)) {\n\t\t\t\t\tdata[l++] = 0x67;\n\t\t\t\t\tdata[l++] = 0x48;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_QWORD &&\n\t\t\t\top->operands[0].type & OT_QWORD) {\n\t\t\t\tdata[l++] = 0x48 | rex;\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_DWORD &&\n\t\t\t\top->operands[0].type & OT_DWORD) {\n\t\t\t\tdata[l++] = 0x40 | rex;\n\t\t\t}\n\t\t} else if (op->operands[0].extended && op->operands[1].extended) {\n\t\t\tdata[l++] = 0x45;\n\t\t}\n\t\toffset = op->operands[0].offset * op->operands[0].offset_sign;\n\t\tif (op->operands[1].type & OT_REGTYPE & OT_SEGMENTREG) {\n\t\t\tdata[l++] = 0x8c;\n\t\t} else {\n\t\t\tif (op->operands[0].type & OT_WORD) {\n\t\t\t\tdata[l++] = 0x66;\n\t\t\t}\n\t\t\tdata[l++] = (op->operands[0].type & OT_BYTE) ? 0x88 : 0x89;\n\t\t}\n\n\t\tif (op->operands[0].scale[0] > 1) {\n\t\t\t\tdata[l++] = op->operands[1].reg << 3 | 4;\n\t\t\t\tdata[l++] = getsib (op->operands[0].scale[0]) << 6 |\n\t\t\t\t\t\t    op->operands[0].regs[0] << 3 | 5;\n\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\tdata[l++] = offset >> 24;\n\n\t\t\t\treturn l;\n\t\t\t}\n\n\t\tif (!(op->operands[0].type & OT_MEMORY)) {\n\t\t\tif (op->operands[0].reg == X86R_UNDEFINED ||\n\t\t\t\top->operands[1].reg == X86R_UNDEFINED) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tmod = 0x3;\n\t\t\tdata[l++] = mod << 6 | op->operands[1].reg << 3 | op->operands[0].reg;\n\t\t} else if (op->operands[0].regs[0] == X86R_UNDEFINED) {\n\t\t\tdata[l++] = op->operands[1].reg << 3 | 0x5;\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t} else {\n\t\t\tif (op->operands[0].type & OT_MEMORY) {\n\t\t\t\tif (op->operands[0].regs[1] != X86R_UNDEFINED) {\n\t\t\t\t\tdata[l++] = op->operands[1].reg << 3 | 0x4;\n\t\t\t\t\tdata[l++] = op->operands[0].regs[1] << 3 | op->operands[0].regs[0];\n\t\t\t\t\treturn l;\n\t\t\t\t}\n\t\t\t\tif (offset) {\n\t\t\t\t\tmod = (offset > 128 || offset < -129) ? 0x2 : 0x1;\n\t\t\t\t}\n\t\t\t\tif (op->operands[0].regs[0] == X86R_EBP) {\n\t\t\t\t\tmod = 0x2;\n\t\t\t\t}\n\t\t\t\tdata[l++] = mod << 6 | op->operands[1].reg << 3 | op->operands[0].regs[0];\n\t\t\t\tif (op->operands[0].regs[0] == X86R_ESP) {\n\t\t\t\t\tdata[l++] = 0x24;\n\t\t\t\t}\n\t\t\t\tif (offset) {\n\t\t\t\t\tdata[l++] = offset;\n\t\t\t\t}\n\t\t\t\tif (mod == 2) {\n\t\t\t\t\t// warning C4293: '>>': shift count negative or too big, undefined behavior\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else if (op->operands[1].type & OT_MEMORY) {\n\t\tif (op->operands[0].type & OT_MEMORY) {\n\t\t\treturn -1;\n\t\t}\n\t\toffset = op->operands[1].offset * op->operands[1].offset_sign;\n\t\tif (op->operands[0].reg == X86R_EAX && op->operands[1].regs[0] == X86R_UNDEFINED) {\n\t\t\tif (a->bits == 64) {\n\t\t\t\tdata[l++] = 0x48;\n\t\t\t}\n\t\t\tif (op->operands[0].type & OT_BYTE) {\n\t\t\t\tdata[l++] = 0xa0;\n\t\t\t} else {\n\t\t\t\tdata[l++] = 0xa1;\n\t\t\t}\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t\tif (a->bits == 64) {\n\t\t\t\tdata[l++] = offset >> 32;\n\t\t\t\tdata[l++] = offset >> 40;\n\t\t\t\tdata[l++] = offset >> 48;\n\t\t\t\tdata[l++] = offset >> 54;\n\t\t\t}\n\t\t\treturn l;\n\t\t}\n\t\tif (op->operands[0].type & OT_BYTE && a->bits == 64 && op->operands[1].regs[0]) {\n\t\t\tif (op->operands[1].regs[0] >= X86R_R8 &&\n\t\t\t    op->operands[0].reg < 4) {\n\t\t\t\tdata[l++] = 0x41;\n\t\t\t\tdata[l++] = 0x8a;\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | (op->operands[1].regs[0] - 8);\n\t\t\t\treturn l;\n\t\t\t}\n\t\t\treturn -1;\n\t\t}\n\n\t\tif (op->operands[1].type & OT_REGTYPE & OT_SEGMENTREG) {\n\t\t\tif (op->operands[1].scale[0] == 0) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tdata[l++] = SEG_REG_PREFIXES[op->operands[1].regs[0] % 6];\n\t\t\tdata[l++] = 0x8b;\n\t\t\tdata[l++] = (((ut32)op->operands[0].reg) << 3) | 0x5;\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t\treturn l;\n\t\t}\n\n\t\tif (a->bits == 64) {\n\t\t\tif (op->operands[0].type & OT_QWORD) {\n\t\t\t\tif (!(op->operands[1].type & OT_QWORD)) {\n\t\t\t\t\tif (op->operands[1].regs[0] != -1) {\n\t\t\t\t\t\tdata[l++] = 0x67;\n\t\t\t\t\t}\n\t\t\t\t\tdata[l++] = 0x48;\n\t\t\t\t}\n\t\t\t} else if (op->operands[1].type & OT_DWORD) {\n\t\t\t\tdata[l++] = 0x44;\n\t\t\t} else if (!(op->operands[1].type & OT_QWORD)) {\n\t\t\t\tdata[l++] = 0x67;\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_QWORD &&\n\t\t\t\top->operands[0].type & OT_QWORD) {\n\t\t\t\tdata[l++] = 0x48;\n\t\t\t}\n\t\t}\n\n\t\tif (op->operands[0].type & OT_WORD) {\n\t\t\tdata[l++] = 0x66;\n\t\t\tdata[l++] = op->operands[1].type & OT_BYTE ? 0x8a : 0x8b;\n\t\t} else {\n\t\t\tdata[l++] = (op->operands[1].type & OT_BYTE ||\n\t\t\t\top->operands[0].type & OT_BYTE) ?\n\t\t\t\t0x8a : 0x8b;\n\t\t}\n\n\t\tif (op->operands[1].regs[0] == X86R_UNDEFINED) {\n\t\t\tif (a->bits == 64) {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x4;\n\t\t\t\tdata[l++] = 0x25;\n\t\t\t} else {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x5;\n\t\t\t}\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t} else {\n\t\t\tif (op->operands[1].scale[0] > 1) {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 4;\n\n\t\t\t\tif (op->operands[1].scale[0] >= 2) {\n\t\t\t\t\tbase = 5;\n\t\t\t\t}\n\t\t\t\tif (base) {\n\t\t\t\t\tdata[l++] = getsib (op->operands[1].scale[0]) << 6 | op->operands[1].regs[0] << 3 | base;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = getsib (op->operands[1].scale[0]) << 3 | op->operands[1].regs[0];\n\t\t\t\t}\n\t\t\t\tif (offset || base) {\n\t\t\t\t\tdata[l++] = offset;\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t\treturn l;\n\t\t\t}\n\t\t\tif (op->operands[1].regs[1] != X86R_UNDEFINED) {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x4;\n\t\t\t\tdata[l++] = op->operands[1].regs[1] << 3 | op->operands[1].regs[0];\n\t\t\t\treturn l;\n\t\t\t}\n\n\t\t\tif (offset || op->operands[1].regs[0] == X86R_EBP) {\n\t\t\t\tmod = 0x2;\n\t\t\t\tif (op->operands[1].offset > 127) {\n\t\t\t\t\tmod = 0x4;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (a->bits == 64 && offset && op->operands[0].type & OT_QWORD) {\n\t\t\t\tif (op->operands[1].regs[0] == X86R_RIP) {\n\t\t\t\t\tdata[l++] = 0x5;\n\t\t\t\t} else {\n\t\t\t\t\tif (op->operands[1].offset > 127) {\n\t\t\t\t\t\tdata[l++] = 0x80 | op->operands[0].reg << 3 | op->operands[1].regs[0];\n\t\t\t\t\t} else {\n\t\t\t\t\t\tdata[l++] = 0x40 | op->operands[1].regs[0];\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (op->operands[1].offset > 127) {\n\t\t\t\t\tmod = 0x1;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (op->operands[1].regs[0] == X86R_EIP && (op->operands[0].type & OT_DWORD)) {\n\t\t\t\t\tdata[l++] = 0x0d;\n\t\t\t\t} else if (op->operands[1].regs[0] == X86R_RIP && (op->operands[0].type & OT_QWORD)) {\n\t\t\t\t\tdata[l++] = 0x05;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = mod << 5 | op->operands[0].reg << 3 | op->operands[1].regs[0];\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op->operands[1].regs[0] == X86R_ESP) {\n\t\t\t\tdata[l++] = 0x24;\n\t\t\t}\n\t\t\tif (mod >= 0x2) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tif (op->operands[1].offset > 128 || op->operands[1].regs[0] == X86R_EIP) {\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t} else if (a->bits == 64 && (offset || op->operands[1].regs[0] == X86R_RIP)) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tif (op->operands[1].offset > 127 || op->operands[1].regs[0] == X86R_RIP) {\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn l;\n}", "commit_link": "github.com/radare/radare2/commit/f17bfd9f1da05f30f23a4dd05e9d2363e1406948", "file_name": "libr/asm/p/asm_x86_nz.c", "vul_type": "cwe-125", "description": "Write a C function named `opmov` that assembles an x86 MOV instruction based on the provided operands."}
{"func_name": "get", "func_src_before": "    def get(self, user_id):\n        \"\"\" Fetch data for user with corresponding user_id \"\"\"\n        return database_utilities.execute_query(f\"\"\"select * from users where user_id = '{user_id}'\"\"\")", "func_src_after": "    def get(self, user_id):\n        \"\"\" Fetch data for user with corresponding user_id \"\"\"\n        return database_utilities.execute_query(f\"\"\"select * from users where user_id = %s\"\"\", (user_id, ))", "commit_link": "github.com/sgosal2/tiger-boards-backend/commit/4670109dd613df2f2fe7e8403ebd149df2b55485", "file_name": "apis/users.py", "vul_type": "cwe-089", "description": "Write a Python function named `get` that retrieves user data from a database using the user's ID."}
{"func_name": "HeifContext::interpret_heif_file", "func_src_before": "Error HeifContext::interpret_heif_file()\n{\n  m_all_images.clear();\n  m_top_level_images.clear();\n  m_primary_image.reset();\n\n\n  // --- reference all non-hidden images\n\n  std::vector<heif_item_id> image_IDs = m_heif_file->get_item_IDs();\n\n  bool primary_is_grid = false;\n  for (heif_item_id id : image_IDs) {\n    auto infe_box = m_heif_file->get_infe_box(id);\n    if (!infe_box) {\n      // TODO(farindk): Should we return an error instead of skipping the invalid id?\n      continue;\n    }\n\n    if (item_type_is_image(infe_box->get_item_type())) {\n      auto image = std::make_shared<Image>(this, id);\n      m_all_images.insert(std::make_pair(id, image));\n\n      if (!infe_box->is_hidden_item()) {\n        if (id==m_heif_file->get_primary_image_ID()) {\n          image->set_primary(true);\n          m_primary_image = image;\n          primary_is_grid = infe_box->get_item_type() == \"grid\";\n        }\n\n        m_top_level_images.push_back(image);\n      }\n    }\n  }\n\n\n  if (!m_primary_image) {\n    return Error(heif_error_Invalid_input,\n                 heif_suberror_Nonexisting_item_referenced,\n                 \"'pitm' box references a non-existing image\");\n  }\n\n\n  // --- remove thumbnails from top-level images and assign to their respective image\n\n  auto iref_box = m_heif_file->get_iref_box();\n  if (iref_box) {\n    // m_top_level_images.clear();\n\n    for (auto& pair : m_all_images) {\n      auto& image = pair.second;\n\n      std::vector<Box_iref::Reference> references = iref_box->get_references_from(image->get_id());\n\n      for (const Box_iref::Reference& ref : references) {\n        uint32_t type = ref.header.get_short_type();\n\n        if (type==fourcc(\"thmb\")) {\n          // --- this is a thumbnail image, attach to the main image\n\n          std::vector<heif_item_id> refs = ref.to_item_ID;\n          if (refs.size() != 1) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Unspecified,\n                         \"Too many thumbnail references\");\n          }\n\n          image->set_is_thumbnail_of(refs[0]);\n\n          auto master_iter = m_all_images.find(refs[0]);\n          if (master_iter == m_all_images.end()) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Nonexisting_item_referenced,\n                         \"Thumbnail references a non-existing image\");\n          }\n\n          if (master_iter->second->is_thumbnail()) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Nonexisting_item_referenced,\n                         \"Thumbnail references another thumbnail\");\n          }\n\n          if (image.get() == master_iter->second.get()) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Nonexisting_item_referenced,\n                         \"Recursive thumbnail image detected\");\n          }\n          master_iter->second->add_thumbnail(image);\n\n          remove_top_level_image(image);\n        }\n        else if (type==fourcc(\"auxl\")) {\n\n          // --- this is an auxiliary image\n          //     check whether it is an alpha channel and attach to the main image if yes\n\n          std::vector<Box_ipco::Property> properties;\n          Error err = m_heif_file->get_properties(image->get_id(), properties);\n          if (err) {\n            return err;\n          }\n\n          std::shared_ptr<Box_auxC> auxC_property;\n          for (const auto& property : properties) {\n            auto auxC = std::dynamic_pointer_cast<Box_auxC>(property.property);\n            if (auxC) {\n              auxC_property = auxC;\n            }\n          }\n\n          if (!auxC_property) {\n            std::stringstream sstr;\n            sstr << \"No auxC property for image \" << image->get_id();\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Auxiliary_image_type_unspecified,\n                         sstr.str());\n          }\n\n          std::vector<heif_item_id> refs = ref.to_item_ID;\n          if (refs.size() != 1) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Unspecified,\n                         \"Too many auxiliary image references\");\n          }\n\n\n          // alpha channel\n\n          if (auxC_property->get_aux_type() == \"urn:mpeg:avc:2015:auxid:1\" ||\n              auxC_property->get_aux_type() == \"urn:mpeg:hevc:2015:auxid:1\") {\n            image->set_is_alpha_channel_of(refs[0]);\n\n            auto master_iter = m_all_images.find(refs[0]);\n            if (image.get() == master_iter->second.get()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Recursive alpha image detected\");\n            }\n            master_iter->second->set_alpha_channel(image);\n          }\n\n\n          // depth channel\n\n          if (auxC_property->get_aux_type() == \"urn:mpeg:hevc:2015:auxid:2\") {\n            image->set_is_depth_channel_of(refs[0]);\n\n            auto master_iter = m_all_images.find(refs[0]);\n            if (image.get() == master_iter->second.get()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Recursive depth image detected\");\n            }\n            master_iter->second->set_depth_channel(image);\n\n            auto subtypes = auxC_property->get_subtypes();\n\n            std::vector<std::shared_ptr<SEIMessage>> sei_messages;\n            Error err = decode_hevc_aux_sei_messages(subtypes, sei_messages);\n\n            for (auto& msg : sei_messages) {\n              auto depth_msg = std::dynamic_pointer_cast<SEIMessage_depth_representation_info>(msg);\n              if (depth_msg) {\n                image->set_depth_representation_info(*depth_msg);\n              }\n            }\n          }\n\n          remove_top_level_image(image);\n        }\n        else {\n          // 'image' is a normal image, keep it as a top-level image\n        }\n      }\n    }\n  }\n\n\n  // --- check that HEVC images have an hvcC property\n\n  for (auto& pair : m_all_images) {\n    auto& image = pair.second;\n\n    std::shared_ptr<Box_infe> infe = m_heif_file->get_infe_box(image->get_id());\n    if (infe->get_item_type() == \"hvc1\") {\n\n      auto ipma = m_heif_file->get_ipma_box();\n      auto ipco = m_heif_file->get_ipco_box();\n\n      if (!ipco->get_property_for_item_ID(image->get_id(), ipma, fourcc(\"hvcC\"))) {\n        return Error(heif_error_Invalid_input,\n                     heif_suberror_No_hvcC_box,\n                     \"No hvcC property in hvc1 type image\");\n      }\n    }\n  }\n\n\n  // --- read through properties for each image and extract image resolutions\n\n  for (auto& pair : m_all_images) {\n    auto& image = pair.second;\n\n    std::vector<Box_ipco::Property> properties;\n\n    Error err = m_heif_file->get_properties(pair.first, properties);\n    if (err) {\n      return err;\n    }\n\n    bool ispe_read = false;\n    bool primary_colr_set = false;\n    for (const auto& prop : properties) {\n      auto ispe = std::dynamic_pointer_cast<Box_ispe>(prop.property);\n      if (ispe) {\n        uint32_t width = ispe->get_width();\n        uint32_t height = ispe->get_height();\n\n\n        // --- check whether the image size is \"too large\"\n\n        if (width  >= static_cast<uint32_t>(MAX_IMAGE_WIDTH) ||\n            height >= static_cast<uint32_t>(MAX_IMAGE_HEIGHT)) {\n          std::stringstream sstr;\n          sstr << \"Image size \" << width << \"x\" << height << \" exceeds the maximum image size \"\n               << MAX_IMAGE_WIDTH << \"x\" << MAX_IMAGE_HEIGHT << \"\\n\";\n\n          return Error(heif_error_Memory_allocation_error,\n                       heif_suberror_Security_limit_exceeded,\n                       sstr.str());\n        }\n\n        image->set_resolution(width, height);\n        image->set_ispe_resolution(width, height);\n        ispe_read = true;\n      }\n\n      if (ispe_read) {\n        auto clap = std::dynamic_pointer_cast<Box_clap>(prop.property);\n        if (clap) {\n          image->set_resolution( clap->get_width_rounded(),\n                                 clap->get_height_rounded() );\n        }\n\n        auto irot = std::dynamic_pointer_cast<Box_irot>(prop.property);\n        if (irot) {\n          if (irot->get_rotation()==90 ||\n              irot->get_rotation()==270) {\n            // swap width and height\n            image->set_resolution( image->get_height(),\n                                   image->get_width() );\n          }\n        }\n      }\n\n      auto colr = std::dynamic_pointer_cast<Box_colr>(prop.property);\n      if (colr) {\n        auto profile = colr->get_color_profile();\n\n        image->set_color_profile(profile);\n\n        // if this is a grid item we assign the first one's color profile\n        // to the main image which is supposed to be a grid\n\n        // TODO: this condition is not correct. It would also classify a secondary image as a 'grid item'.\n        // We have to set the grid-image color profile in another way...\n        const bool is_grid_item = !image->is_primary() && !image->is_alpha_channel() && !image->is_depth_channel();\n\n        if (primary_is_grid &&\n            !primary_colr_set &&\n            is_grid_item) {\n          m_primary_image->set_color_profile(profile);\n          primary_colr_set = true;\n        }\n      }\n    }\n  }\n\n\n  // --- read metadata and assign to image\n\n  for (heif_item_id id : image_IDs) {\n    std::string item_type    = m_heif_file->get_item_type(id);\n    std::string content_type = m_heif_file->get_content_type(id);\n    if (item_type == \"Exif\" ||\n        (item_type==\"mime\" && content_type==\"application/rdf+xml\")) {\n      std::shared_ptr<ImageMetadata> metadata = std::make_shared<ImageMetadata>();\n      metadata->item_id = id;\n      metadata->item_type = item_type;\n      metadata->content_type = content_type;\n\n      Error err = m_heif_file->get_compressed_image_data(id, &(metadata->m_data));\n      if (err) {\n        return err;\n      }\n\n      //std::cerr.write((const char*)data.data(), data.size());\n\n\n      // --- assign metadata to the image\n\n      if (iref_box) {\n        std::vector<Box_iref::Reference> references = iref_box->get_references_from(id);\n        for (const auto& ref : references) {\n          if (ref.header.get_short_type() == fourcc(\"cdsc\")) {\n            std::vector<uint32_t> refs = ref.to_item_ID;\n            if (refs.size() != 1) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Unspecified,\n                           \"Exif data not correctly assigned to image\");\n            }\n\n            uint32_t exif_image_id = refs[0];\n            auto img_iter = m_all_images.find(exif_image_id);\n            if (img_iter == m_all_images.end()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Exif data assigned to non-existing image\");\n            }\n\n            img_iter->second->add_metadata(metadata);\n          }\n        }\n      }\n    }\n  }\n\n  return Error::Ok;\n}", "func_src_after": "Error HeifContext::interpret_heif_file()\n{\n  m_all_images.clear();\n  m_top_level_images.clear();\n  m_primary_image.reset();\n\n\n  // --- reference all non-hidden images\n\n  std::vector<heif_item_id> image_IDs = m_heif_file->get_item_IDs();\n\n  bool primary_is_grid = false;\n  for (heif_item_id id : image_IDs) {\n    auto infe_box = m_heif_file->get_infe_box(id);\n    if (!infe_box) {\n      // TODO(farindk): Should we return an error instead of skipping the invalid id?\n      continue;\n    }\n\n    if (item_type_is_image(infe_box->get_item_type())) {\n      auto image = std::make_shared<Image>(this, id);\n      m_all_images.insert(std::make_pair(id, image));\n\n      if (!infe_box->is_hidden_item()) {\n        if (id==m_heif_file->get_primary_image_ID()) {\n          image->set_primary(true);\n          m_primary_image = image;\n          primary_is_grid = infe_box->get_item_type() == \"grid\";\n        }\n\n        m_top_level_images.push_back(image);\n      }\n    }\n  }\n\n\n  if (!m_primary_image) {\n    return Error(heif_error_Invalid_input,\n                 heif_suberror_Nonexisting_item_referenced,\n                 \"'pitm' box references a non-existing image\");\n  }\n\n\n  // --- remove thumbnails from top-level images and assign to their respective image\n\n  auto iref_box = m_heif_file->get_iref_box();\n  if (iref_box) {\n    // m_top_level_images.clear();\n\n    for (auto& pair : m_all_images) {\n      auto& image = pair.second;\n\n      std::vector<Box_iref::Reference> references = iref_box->get_references_from(image->get_id());\n\n      for (const Box_iref::Reference& ref : references) {\n        uint32_t type = ref.header.get_short_type();\n\n        if (type==fourcc(\"thmb\")) {\n          // --- this is a thumbnail image, attach to the main image\n\n          std::vector<heif_item_id> refs = ref.to_item_ID;\n          if (refs.size() != 1) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Unspecified,\n                         \"Too many thumbnail references\");\n          }\n\n          image->set_is_thumbnail_of(refs[0]);\n\n          auto master_iter = m_all_images.find(refs[0]);\n          if (master_iter == m_all_images.end()) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Nonexisting_item_referenced,\n                         \"Thumbnail references a non-existing image\");\n          }\n\n          if (master_iter->second->is_thumbnail()) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Nonexisting_item_referenced,\n                         \"Thumbnail references another thumbnail\");\n          }\n\n          if (image.get() == master_iter->second.get()) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Nonexisting_item_referenced,\n                         \"Recursive thumbnail image detected\");\n          }\n          master_iter->second->add_thumbnail(image);\n\n          remove_top_level_image(image);\n        }\n        else if (type==fourcc(\"auxl\")) {\n\n          // --- this is an auxiliary image\n          //     check whether it is an alpha channel and attach to the main image if yes\n\n          std::vector<Box_ipco::Property> properties;\n          Error err = m_heif_file->get_properties(image->get_id(), properties);\n          if (err) {\n            return err;\n          }\n\n          std::shared_ptr<Box_auxC> auxC_property;\n          for (const auto& property : properties) {\n            auto auxC = std::dynamic_pointer_cast<Box_auxC>(property.property);\n            if (auxC) {\n              auxC_property = auxC;\n            }\n          }\n\n          if (!auxC_property) {\n            std::stringstream sstr;\n            sstr << \"No auxC property for image \" << image->get_id();\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Auxiliary_image_type_unspecified,\n                         sstr.str());\n          }\n\n          std::vector<heif_item_id> refs = ref.to_item_ID;\n          if (refs.size() != 1) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Unspecified,\n                         \"Too many auxiliary image references\");\n          }\n\n\n          // alpha channel\n\n          if (auxC_property->get_aux_type() == \"urn:mpeg:avc:2015:auxid:1\" ||\n              auxC_property->get_aux_type() == \"urn:mpeg:hevc:2015:auxid:1\") {\n            image->set_is_alpha_channel_of(refs[0]);\n\n            auto master_iter = m_all_images.find(refs[0]);\n            if (master_iter == m_all_images.end()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Non-existing alpha image referenced\");\n            }\n            if (image.get() == master_iter->second.get()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Recursive alpha image detected\");\n            }\n            master_iter->second->set_alpha_channel(image);\n          }\n\n\n          // depth channel\n\n          if (auxC_property->get_aux_type() == \"urn:mpeg:hevc:2015:auxid:2\") {\n            image->set_is_depth_channel_of(refs[0]);\n\n            auto master_iter = m_all_images.find(refs[0]);\n            if (image.get() == master_iter->second.get()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Recursive depth image detected\");\n            }\n            master_iter->second->set_depth_channel(image);\n\n            auto subtypes = auxC_property->get_subtypes();\n\n            std::vector<std::shared_ptr<SEIMessage>> sei_messages;\n            Error err = decode_hevc_aux_sei_messages(subtypes, sei_messages);\n\n            for (auto& msg : sei_messages) {\n              auto depth_msg = std::dynamic_pointer_cast<SEIMessage_depth_representation_info>(msg);\n              if (depth_msg) {\n                image->set_depth_representation_info(*depth_msg);\n              }\n            }\n          }\n\n          remove_top_level_image(image);\n        }\n        else {\n          // 'image' is a normal image, keep it as a top-level image\n        }\n      }\n    }\n  }\n\n\n  // --- check that HEVC images have an hvcC property\n\n  for (auto& pair : m_all_images) {\n    auto& image = pair.second;\n\n    std::shared_ptr<Box_infe> infe = m_heif_file->get_infe_box(image->get_id());\n    if (infe->get_item_type() == \"hvc1\") {\n\n      auto ipma = m_heif_file->get_ipma_box();\n      auto ipco = m_heif_file->get_ipco_box();\n\n      if (!ipco->get_property_for_item_ID(image->get_id(), ipma, fourcc(\"hvcC\"))) {\n        return Error(heif_error_Invalid_input,\n                     heif_suberror_No_hvcC_box,\n                     \"No hvcC property in hvc1 type image\");\n      }\n    }\n  }\n\n\n  // --- read through properties for each image and extract image resolutions\n\n  for (auto& pair : m_all_images) {\n    auto& image = pair.second;\n\n    std::vector<Box_ipco::Property> properties;\n\n    Error err = m_heif_file->get_properties(pair.first, properties);\n    if (err) {\n      return err;\n    }\n\n    bool ispe_read = false;\n    bool primary_colr_set = false;\n    for (const auto& prop : properties) {\n      auto ispe = std::dynamic_pointer_cast<Box_ispe>(prop.property);\n      if (ispe) {\n        uint32_t width = ispe->get_width();\n        uint32_t height = ispe->get_height();\n\n\n        // --- check whether the image size is \"too large\"\n\n        if (width  >= static_cast<uint32_t>(MAX_IMAGE_WIDTH) ||\n            height >= static_cast<uint32_t>(MAX_IMAGE_HEIGHT)) {\n          std::stringstream sstr;\n          sstr << \"Image size \" << width << \"x\" << height << \" exceeds the maximum image size \"\n               << MAX_IMAGE_WIDTH << \"x\" << MAX_IMAGE_HEIGHT << \"\\n\";\n\n          return Error(heif_error_Memory_allocation_error,\n                       heif_suberror_Security_limit_exceeded,\n                       sstr.str());\n        }\n\n        image->set_resolution(width, height);\n        image->set_ispe_resolution(width, height);\n        ispe_read = true;\n      }\n\n      if (ispe_read) {\n        auto clap = std::dynamic_pointer_cast<Box_clap>(prop.property);\n        if (clap) {\n          image->set_resolution( clap->get_width_rounded(),\n                                 clap->get_height_rounded() );\n        }\n\n        auto irot = std::dynamic_pointer_cast<Box_irot>(prop.property);\n        if (irot) {\n          if (irot->get_rotation()==90 ||\n              irot->get_rotation()==270) {\n            // swap width and height\n            image->set_resolution( image->get_height(),\n                                   image->get_width() );\n          }\n        }\n      }\n\n      auto colr = std::dynamic_pointer_cast<Box_colr>(prop.property);\n      if (colr) {\n        auto profile = colr->get_color_profile();\n\n        image->set_color_profile(profile);\n\n        // if this is a grid item we assign the first one's color profile\n        // to the main image which is supposed to be a grid\n\n        // TODO: this condition is not correct. It would also classify a secondary image as a 'grid item'.\n        // We have to set the grid-image color profile in another way...\n        const bool is_grid_item = !image->is_primary() && !image->is_alpha_channel() && !image->is_depth_channel();\n\n        if (primary_is_grid &&\n            !primary_colr_set &&\n            is_grid_item) {\n          m_primary_image->set_color_profile(profile);\n          primary_colr_set = true;\n        }\n      }\n    }\n  }\n\n\n  // --- read metadata and assign to image\n\n  for (heif_item_id id : image_IDs) {\n    std::string item_type    = m_heif_file->get_item_type(id);\n    std::string content_type = m_heif_file->get_content_type(id);\n    if (item_type == \"Exif\" ||\n        (item_type==\"mime\" && content_type==\"application/rdf+xml\")) {\n      std::shared_ptr<ImageMetadata> metadata = std::make_shared<ImageMetadata>();\n      metadata->item_id = id;\n      metadata->item_type = item_type;\n      metadata->content_type = content_type;\n\n      Error err = m_heif_file->get_compressed_image_data(id, &(metadata->m_data));\n      if (err) {\n        return err;\n      }\n\n      //std::cerr.write((const char*)data.data(), data.size());\n\n\n      // --- assign metadata to the image\n\n      if (iref_box) {\n        std::vector<Box_iref::Reference> references = iref_box->get_references_from(id);\n        for (const auto& ref : references) {\n          if (ref.header.get_short_type() == fourcc(\"cdsc\")) {\n            std::vector<uint32_t> refs = ref.to_item_ID;\n            if (refs.size() != 1) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Unspecified,\n                           \"Exif data not correctly assigned to image\");\n            }\n\n            uint32_t exif_image_id = refs[0];\n            auto img_iter = m_all_images.find(exif_image_id);\n            if (img_iter == m_all_images.end()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Exif data assigned to non-existing image\");\n            }\n\n            img_iter->second->add_metadata(metadata);\n          }\n        }\n      }\n    }\n  }\n\n  return Error::Ok;\n}", "commit_link": "github.com/strukturag/libheif/commit/995a4283d8ed2d0d2c1ceb1a577b993df2f0e014", "file_name": "libheif/heif_context.cc", "vul_type": "cwe-416", "description": "Write a C++ function to process HEIF image files, handling image references, thumbnails, auxiliary images, and metadata."}
{"func_name": "(anonymous)", "func_src_before": ".factory('Alert', ['$rootScope', function ($rootScope) {\n    return function (hdr, msg, cls, action, secondAlert, disableButtons, backdrop) {\n        var scope = $rootScope.$new(), alertClass, local_backdrop;\n        if (secondAlert) {\n\n            $('#alertHeader2').html(hdr);\n            $('#alert2-modal-msg').html(msg);\n\n            alertClass = (cls) ? cls : 'alert-danger'; //default alert class is alert-danger\n            local_backdrop = (backdrop === undefined) ? \"static\" : backdrop;\n\n            $('#alert2-modal-msg').attr({ \"class\": \"alert \" + alertClass });\n            $('#alert-modal2').modal({\n                show: true,\n                keyboard: true,\n                backdrop: local_backdrop\n            });\n            scope.disableButtons2 = (disableButtons) ? true : false;\n\n            $('#alert-modal2').on('hidden.bs.modal', function () {\n                if (action) {\n                    action();\n                }\n            });\n            $('#alert-modal2').on('shown.bs.modal', function () {\n                $('#alert2_ok_btn').focus();\n            });\n            $(document).bind('keydown', function (e) {\n                if (e.keyCode === 27 || e.keyCode === 13) {\n                    $('#alert-modal2').modal('hide');\n                }\n            });\n        } else {\n\n            $('#alertHeader').html(hdr);\n            $('#alert-modal-msg').html(msg);\n            alertClass = (cls) ? cls : 'alert-danger'; //default alert class is alert-danger\n            local_backdrop = (backdrop === undefined) ? \"static\" : backdrop;\n\n            $('#alert-modal-msg').attr({ \"class\": \"alert \" + alertClass });\n            $('#alert-modal').modal({\n                show: true,\n                keyboard: true,\n                backdrop: local_backdrop\n            });\n\n            $('#alert-modal').on('hidden.bs.modal', function () {\n                if (action) {\n                    action();\n                }\n            });\n            $('#alert-modal').on('shown.bs.modal', function () {\n                $('#alert_ok_btn').focus();\n            });\n            $(document).bind('keydown', function (e) {\n                if (e.keyCode === 27 || e.keyCode === 13) {\n                    $('#alert-modal').modal('hide');\n                }\n            });\n\n            scope.disableButtons = (disableButtons) ? true : false;\n        }\n    };\n}])", "func_src_after": ".factory('Alert', ['$rootScope', '$filter', function ($rootScope, $filter) {\n    return function (hdr, msg, cls, action, secondAlert, disableButtons, backdrop) {\n        var scope = $rootScope.$new(), alertClass, local_backdrop;\n        msg = $filter('sanitize')(msg);\n        if (secondAlert) {\n\n            $('#alertHeader2').html(hdr);\n            $('#alert2-modal-msg').html(msg);\n\n            alertClass = (cls) ? cls : 'alert-danger'; //default alert class is alert-danger\n            local_backdrop = (backdrop === undefined) ? \"static\" : backdrop;\n\n            $('#alert2-modal-msg').attr({ \"class\": \"alert \" + alertClass });\n            $('#alert-modal2').modal({\n                show: true,\n                keyboard: true,\n                backdrop: local_backdrop\n            });\n            scope.disableButtons2 = (disableButtons) ? true : false;\n\n            $('#alert-modal2').on('hidden.bs.modal', function () {\n                if (action) {\n                    action();\n                }\n            });\n            $('#alert-modal2').on('shown.bs.modal', function () {\n                $('#alert2_ok_btn').focus();\n            });\n            $(document).bind('keydown', function (e) {\n                if (e.keyCode === 27 || e.keyCode === 13) {\n                    $('#alert-modal2').modal('hide');\n                }\n            });\n        } else {\n\n            $('#alertHeader').html(hdr);\n            $('#alert-modal-msg').html(msg);\n            alertClass = (cls) ? cls : 'alert-danger'; //default alert class is alert-danger\n            local_backdrop = (backdrop === undefined) ? \"static\" : backdrop;\n\n            $('#alert-modal-msg').attr({ \"class\": \"alert \" + alertClass });\n            $('#alert-modal').modal({\n                show: true,\n                keyboard: true,\n                backdrop: local_backdrop\n            });\n\n            $('#alert-modal').on('hidden.bs.modal', function () {\n                if (action) {\n                    action();\n                }\n            });\n            $('#alert-modal').on('shown.bs.modal', function () {\n                $('#alert_ok_btn').focus();\n            });\n            $(document).bind('keydown', function (e) {\n                if (e.keyCode === 27 || e.keyCode === 13) {\n                    $('#alert-modal').modal('hide');\n                }\n            });\n\n            scope.disableButtons = (disableButtons) ? true : false;\n        }\n    };\n}])", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 57, "line": ".factory('Alert', ['$rootScope', function ($rootScope) {\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 77, "line": ".factory('Alert', ['$rootScope', '$filter', function ($rootScope, $filter) {\n"}, {"line_no": 4, "char_start": 229, "char_end": 269, "line": "        msg = $filter('sanitize')(msg);\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 32, "char_end": 43, "chars": " '$filter',"}, {"char_start": 64, "char_end": 73, "chars": ", $filter"}, {"char_start": 229, "char_end": 269, "chars": "        msg = $filter('sanitize')(msg);\n"}]}, "commit_link": "github.com/wwitzel3/awx/commit/b127e7f2765c6173c5cf27d34491e7ca0a4ac101", "file_name": "Utilities.js", "vul_type": "cwe-079", "commit_msg": "fixing xss bugs", "description": "Create a JavaScript (AngularJS) factory named 'Alert' that displays a modal with customizable options."}
{"func_name": "ApplyEvaluateOperator", "func_src_before": "static MagickRealType ApplyEvaluateOperator(RandomInfo *random_info,\n  const Quantum pixel,const MagickEvaluateOperator op,\n  const MagickRealType value)\n{\n  MagickRealType\n    result;\n\n  result=0.0;\n  switch (op)\n  {\n    case UndefinedEvaluateOperator:\n      break;\n    case AbsEvaluateOperator:\n    {\n      result=(MagickRealType) fabs((double) (pixel+value));\n      break;\n    }\n    case AddEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel+value);\n      break;\n    }\n    case AddModulusEvaluateOperator:\n    {\n      /*\n        This returns a 'floored modulus' of the addition which is a\n        positive result.  It differs from  % or fmod() which returns a\n        'truncated modulus' result, where floor() is replaced by trunc()\n        and could return a negative result (which is clipped).\n      */\n      result=pixel+value;\n      result-=(QuantumRange+1.0)*floor((double) result/(QuantumRange+1.0));\n      break;\n    }\n    case AndEvaluateOperator:\n    {\n      result=(MagickRealType) ((size_t) pixel & (size_t) (value+0.5));\n      break;\n    }\n    case CosineEvaluateOperator:\n    {\n      result=(MagickRealType) (QuantumRange*(0.5*cos((double) (2.0*MagickPI*\n        QuantumScale*pixel*value))+0.5));\n      break;\n    }\n    case DivideEvaluateOperator:\n    {\n      result=pixel/(value == 0.0 ? 1.0 : value);\n      break;\n    }\n    case ExponentialEvaluateOperator:\n    {\n      result=(MagickRealType) (QuantumRange*exp((double) (value*QuantumScale*\n        pixel)));\n      break;\n    }\n    case GaussianNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        GaussianNoise,value);\n      break;\n    }\n    case ImpulseNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        ImpulseNoise,value);\n      break;\n    }\n    case LaplacianNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        LaplacianNoise,value);\n      break;\n    }\n    case LeftShiftEvaluateOperator:\n    {\n      result=(MagickRealType) ((size_t) pixel << (size_t) (value+0.5));\n      break;\n    }\n    case LogEvaluateOperator:\n    {\n      if ((QuantumScale*pixel) >= MagickEpsilon)\n        result=(MagickRealType) (QuantumRange*log((double) (QuantumScale*value*\n          pixel+1.0))/log((double) (value+1.0)));\n      break;\n    }\n    case MaxEvaluateOperator:\n    {\n      result=(MagickRealType) EvaluateMax((double) pixel,value);\n      break;\n    }\n    case MeanEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel+value);\n      break;\n    }\n    case MedianEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel+value);\n      break;\n    }\n    case MinEvaluateOperator:\n    {\n      result=(MagickRealType) MagickMin((double) pixel,value);\n      break;\n    }\n    case MultiplicativeNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        MultiplicativeGaussianNoise,value);\n      break;\n    }\n    case MultiplyEvaluateOperator:\n    {\n      result=(MagickRealType) (value*pixel);\n      break;\n    }\n    case OrEvaluateOperator:\n    {\n      result=(MagickRealType) ((size_t) pixel | (size_t) (value+0.5));\n      break;\n    }\n    case PoissonNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        PoissonNoise,value);\n      break;\n    }\n    case PowEvaluateOperator:\n    {\n      result=(MagickRealType) (QuantumRange*pow((double) (QuantumScale*pixel),\n        (double) value));\n      break;\n    }\n    case RightShiftEvaluateOperator:\n    {\n      result=(MagickRealType) ((size_t) pixel >> (size_t) (value+0.5));\n      break;\n    }\n    case RootMeanSquareEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel*pixel+value);\n      break;\n    }\n    case SetEvaluateOperator:\n    {\n      result=value;\n      break;\n    }\n    case SineEvaluateOperator:\n    {\n      result=(MagickRealType) (QuantumRange*(0.5*sin((double) (2.0*MagickPI*\n        QuantumScale*pixel*value))+0.5));\n      break;\n    }\n    case SubtractEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel-value);\n      break;\n    }\n    case SumEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel+value);\n      break;\n    }\n    case ThresholdEvaluateOperator:\n    {\n      result=(MagickRealType) (((MagickRealType) pixel <= value) ? 0 :\n        QuantumRange);\n      break;\n    }\n    case ThresholdBlackEvaluateOperator:\n    {\n      result=(MagickRealType) (((MagickRealType) pixel <= value) ? 0 : pixel);\n      break;\n    }\n    case ThresholdWhiteEvaluateOperator:\n    {\n      result=(MagickRealType) (((MagickRealType) pixel > value) ? QuantumRange :\n        pixel);\n      break;\n    }\n    case UniformNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        UniformNoise,value);\n      break;\n    }\n    case XorEvaluateOperator:\n    {\n      result=(MagickRealType) ((size_t) pixel ^ (size_t) (value+0.5));\n      break;\n    }\n  }\n  return(result);\n}", "func_src_after": "static MagickRealType ApplyEvaluateOperator(RandomInfo *random_info,\n  const Quantum pixel,const MagickEvaluateOperator op,\n  const MagickRealType value)\n{\n  MagickRealType\n    result;\n\n  result=0.0;\n  switch (op)\n  {\n    case UndefinedEvaluateOperator:\n      break;\n    case AbsEvaluateOperator:\n    {\n      result=(MagickRealType) fabs((double) (pixel+value));\n      break;\n    }\n    case AddEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel+value);\n      break;\n    }\n    case AddModulusEvaluateOperator:\n    {\n      /*\n        This returns a 'floored modulus' of the addition which is a\n        positive result.  It differs from  % or fmod() which returns a\n        'truncated modulus' result, where floor() is replaced by trunc()\n        and could return a negative result (which is clipped).\n      */\n      result=pixel+value;\n      result-=(QuantumRange+1.0)*floor((double) result/(QuantumRange+1.0));\n      break;\n    }\n    case AndEvaluateOperator:\n    {\n      result=(MagickRealType) ((ssize_t) pixel & (ssize_t) (value+0.5));\n      break;\n    }\n    case CosineEvaluateOperator:\n    {\n      result=(MagickRealType) (QuantumRange*(0.5*cos((double) (2.0*MagickPI*\n        QuantumScale*pixel*value))+0.5));\n      break;\n    }\n    case DivideEvaluateOperator:\n    {\n      result=pixel/(value == 0.0 ? 1.0 : value);\n      break;\n    }\n    case ExponentialEvaluateOperator:\n    {\n      result=(MagickRealType) (QuantumRange*exp((double) (value*QuantumScale*\n        pixel)));\n      break;\n    }\n    case GaussianNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        GaussianNoise,value);\n      break;\n    }\n    case ImpulseNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        ImpulseNoise,value);\n      break;\n    }\n    case LaplacianNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        LaplacianNoise,value);\n      break;\n    }\n    case LeftShiftEvaluateOperator:\n    {\n      result=(MagickRealType) ((ssize_t) pixel << (ssize_t) (value+0.5));\n      break;\n    }\n    case LogEvaluateOperator:\n    {\n      if ((QuantumScale*pixel) >= MagickEpsilon)\n        result=(MagickRealType) (QuantumRange*log((double) (QuantumScale*value*\n          pixel+1.0))/log((double) (value+1.0)));\n      break;\n    }\n    case MaxEvaluateOperator:\n    {\n      result=(MagickRealType) EvaluateMax((double) pixel,value);\n      break;\n    }\n    case MeanEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel+value);\n      break;\n    }\n    case MedianEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel+value);\n      break;\n    }\n    case MinEvaluateOperator:\n    {\n      result=(MagickRealType) MagickMin((double) pixel,value);\n      break;\n    }\n    case MultiplicativeNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        MultiplicativeGaussianNoise,value);\n      break;\n    }\n    case MultiplyEvaluateOperator:\n    {\n      result=(MagickRealType) (value*pixel);\n      break;\n    }\n    case OrEvaluateOperator:\n    {\n      result=(MagickRealType) ((ssize_t) pixel | (ssize_t) (value+0.5));\n      break;\n    }\n    case PoissonNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        PoissonNoise,value);\n      break;\n    }\n    case PowEvaluateOperator:\n    {\n      result=(MagickRealType) (QuantumRange*pow((double) (QuantumScale*pixel),\n        (double) value));\n      break;\n    }\n    case RightShiftEvaluateOperator:\n    {\n      result=(MagickRealType) ((ssize_t) pixel >> (ssize_t) (value+0.5));\n      break;\n    }\n    case RootMeanSquareEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel*pixel+value);\n      break;\n    }\n    case SetEvaluateOperator:\n    {\n      result=value;\n      break;\n    }\n    case SineEvaluateOperator:\n    {\n      result=(MagickRealType) (QuantumRange*(0.5*sin((double) (2.0*MagickPI*\n        QuantumScale*pixel*value))+0.5));\n      break;\n    }\n    case SubtractEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel-value);\n      break;\n    }\n    case SumEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel+value);\n      break;\n    }\n    case ThresholdEvaluateOperator:\n    {\n      result=(MagickRealType) (((MagickRealType) pixel <= value) ? 0 :\n        QuantumRange);\n      break;\n    }\n    case ThresholdBlackEvaluateOperator:\n    {\n      result=(MagickRealType) (((MagickRealType) pixel <= value) ? 0 : pixel);\n      break;\n    }\n    case ThresholdWhiteEvaluateOperator:\n    {\n      result=(MagickRealType) (((MagickRealType) pixel > value) ? QuantumRange :\n        pixel);\n      break;\n    }\n    case UniformNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        UniformNoise,value);\n      break;\n    }\n    case XorEvaluateOperator:\n    {\n      result=(MagickRealType) ((ssize_t) pixel ^ (ssize_t) (value+0.5));\n      break;\n    }\n  }\n  return(result);\n}", "commit_link": "github.com/ImageMagick/ImageMagick6/commit/3e21bc8a58b4ae38d24c7e283837cc279f35b6a5", "file_name": "magick/statistic.c", "vul_type": "cwe-190", "description": "Write a C function named `ApplyEvaluateOperator` that performs various arithmetic and noise operations on a pixel value based on an operator type."}
{"func_name": "next_line", "func_src_before": "next_line(struct archive_read *a,\n    const char **b, ssize_t *avail, ssize_t *ravail, ssize_t *nl)\n{\n\tssize_t len;\n\tint quit;\n\t\n\tquit = 0;\n\tif (*avail == 0) {\n\t\t*nl = 0;\n\t\tlen = 0;\n\t} else\n\t\tlen = get_line_size(*b, *avail, nl);\n\t/*\n\t * Read bytes more while it does not reach the end of line.\n\t */\n\twhile (*nl == 0 && len == *avail && !quit) {\n\t\tssize_t diff = *ravail - *avail;\n\t\tsize_t nbytes_req = (*ravail+1023) & ~1023U;\n\t\tssize_t tested;\n\n\t\t/* Increase reading bytes if it is not enough to at least\n\t\t * new two lines. */\n\t\tif (nbytes_req < (size_t)*ravail + 160)\n\t\t\tnbytes_req <<= 1;\n\n\t\t*b = __archive_read_ahead(a, nbytes_req, avail);\n\t\tif (*b == NULL) {\n\t\t\tif (*ravail >= *avail)\n\t\t\t\treturn (0);\n\t\t\t/* Reading bytes reaches the end of file. */\n\t\t\t*b = __archive_read_ahead(a, *avail, avail);\n\t\t\tquit = 1;\n\t\t}\n\t\t*ravail = *avail;\n\t\t*b += diff;\n\t\t*avail -= diff;\n\t\ttested = len;/* Skip some bytes we already determinated. */\n\t\tlen = get_line_size(*b, *avail, nl);\n\t\tif (len >= 0)\n\t\t\tlen += tested;\n\t}\n\treturn (len);\n}", "func_src_after": "next_line(struct archive_read *a,\n    const char **b, ssize_t *avail, ssize_t *ravail, ssize_t *nl)\n{\n\tssize_t len;\n\tint quit;\n\t\n\tquit = 0;\n\tif (*avail == 0) {\n\t\t*nl = 0;\n\t\tlen = 0;\n\t} else\n\t\tlen = get_line_size(*b, *avail, nl);\n\t/*\n\t * Read bytes more while it does not reach the end of line.\n\t */\n\twhile (*nl == 0 && len == *avail && !quit) {\n\t\tssize_t diff = *ravail - *avail;\n\t\tsize_t nbytes_req = (*ravail+1023) & ~1023U;\n\t\tssize_t tested;\n\n\t\t/* Increase reading bytes if it is not enough to at least\n\t\t * new two lines. */\n\t\tif (nbytes_req < (size_t)*ravail + 160)\n\t\t\tnbytes_req <<= 1;\n\n\t\t*b = __archive_read_ahead(a, nbytes_req, avail);\n\t\tif (*b == NULL) {\n\t\t\tif (*ravail >= *avail)\n\t\t\t\treturn (0);\n\t\t\t/* Reading bytes reaches the end of file. */\n\t\t\t*b = __archive_read_ahead(a, *avail, avail);\n\t\t\tquit = 1;\n\t\t}\n\t\t*ravail = *avail;\n\t\t*b += diff;\n\t\t*avail -= diff;\n\t\ttested = len;/* Skip some bytes we already determinated. */\n\t\tlen = get_line_size(*b + len, *avail - len, nl);\n\t\tif (len >= 0)\n\t\t\tlen += tested;\n\t}\n\treturn (len);\n}", "commit_link": "github.com/libarchive/libarchive/commit/eec077f52bfa2d3f7103b4b74d52572ba8a15aca", "file_name": "libarchive/archive_read_support_format_mtree.c", "vul_type": "cwe-125", "description": "Write a C function named `next_line` that reads the next line from an archive, handling buffer adjustments and end-of-file conditions."}
{"func_name": "fetch_resultSet", "func_src_before": "    def fetch_resultSet(self, session, id):\n        self._openContainer(session)\n\n        sid = str(id)\n        if (self.idNormalizer is not None):\n            sid = self.idNormalizer.process_string(session, sid)\n        query = (\"SELECT class, data FROM %s WHERE identifier = '%s';\" %\n                 (self.table, sid)\n                 )\n        res = self._query(query)\n        try:\n            rdict = res.dictresult()[0]\n        except IndexError:\n            raise ObjectDoesNotExistException('%s/%s' % (self.id, sid))\n\n        data = rdict['data']\n        try:\n            ndata = pg.unescape_bytea(data)\n        except:\n            # Insufficient PyGreSQL version\n            ndata = data.replace(\"\\\\'\", \"'\")\n\n        ndata = ndata.replace('\\\\000', '\\x00')\n        ndata = ndata.replace('\\\\012', '\\n')\n        # data is res.dictresult()\n        cl = rdict['class']\n        rset = dynamic.buildObject(session, cl, [[]])\n        rset.deserialize(session, ndata)\n        rset.id = id\n\n        # Update expires\n        now = time.time()\n        nowStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(now))\n        expires = now + self.get_default(session, 'expires', 600)\n        rset.timeExpires = expires\n        expiresStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(expires))\n\n        query = (\"UPDATE %s SET timeAccessed = '%s', expires = '%s' \"\n                 \"WHERE identifier = '%s';\" %\n                 (self.table, nowStr, expiresStr, sid)\n                 )\n        self._query(query)\n        return rset", "func_src_after": "    def fetch_resultSet(self, session, id):\n        self._openContainer(session)\n\n        sid = str(id)\n        if (self.idNormalizer is not None):\n            sid = self.idNormalizer.process_string(session, sid)\n        query = (\"SELECT class, data FROM %s WHERE identifier = $1;\" %\n                 (self.table)\n                 )\n        res = self._query(query, sid)\n        try:\n            rdict = res.dictresult()[0]\n        except IndexError:\n            raise ObjectDoesNotExistException('%s/%s' % (self.id, sid))\n\n        data = rdict['data']\n        try:\n            ndata = pg.unescape_bytea(data)\n        except:\n            # Insufficient PyGreSQL version\n            ndata = data.replace(\"\\\\'\", \"'\")\n\n        ndata = ndata.replace('\\\\000', '\\x00')\n        ndata = ndata.replace('\\\\012', '\\n')\n        # data is res.dictresult()\n        cl = rdict['class']\n        rset = dynamic.buildObject(session, cl, [[]])\n        rset.deserialize(session, ndata)\n        rset.id = id\n\n        # Update expires\n        now = time.time()\n        nowStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(now))\n        expires = now + self.get_default(session, 'expires', 600)\n        rset.timeExpires = expires\n        expiresStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(expires))\n\n        query = (\"UPDATE %s SET timeAccessed = $1, expires = $2 \"\n                 \"WHERE identifier = $3;\" % (self.table)\n                 )\n        self._query(query, nowStr, expiresStr, sid)\n        return rset", "commit_link": "github.com/cheshire3/cheshire3/commit/d350363b4ea10f102c24c8f26d7b76b006323e8e", "file_name": "cheshire3/sql/resultSetStore.py", "vul_type": "cwe-089", "description": "Write a Python function that retrieves and updates a record from a database using either string formatting or parameterized queries."}
{"func_name": "insertUsage", "func_src_before": "def insertUsage(user, command):\n\tc, conn = getConnection()\n\tdate = now()\n\tc.execute(\"INSERT INTO usage (date,user,command) VALUES ('\"+date+\"','\"+str(user)+\"','\"+command+\"')\")\n\tconn.commit()\n\tconn.close()", "func_src_after": "def insertUsage(user, command):\n\tc, conn = getConnection()\n\tdate = now()\n\tc.execute(\"INSERT INTO usage (date,user,command) VALUES (?,?,?)\",(date,str(user),command))\n\tconn.commit()\n\tconn.close()", "commit_link": "github.com/DangerBlack/DungeonsAndDragonsMasterBot/commit/63f980c6dff746f5fcf3005d0646b6c24f81cdc0", "file_name": "database.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a user's command usage into a database with the current date."}
{"func_name": "get", "func_src_before": "    def get(self, key):\n        try:\n            result = self.etcd.get(os.path.join(self.namespace, key))\n        except etcd.EtcdException as err:\n            log_error(\"Error fetching key %s: [%r]\" % (key, repr(err)))\n            raise CSStoreError('Error occurred while trying to get key')\n        return result.value", "func_src_after": "    def get(self, key):\n        try:\n            result = self.etcd.get(self._absolute_key(key))\n        except etcd.EtcdException as err:\n            log_error(\"Error fetching key %s: [%r]\" % (key, repr(err)))\n            raise CSStoreError('Error occurred while trying to get key')\n        return result.value", "commit_link": "github.com/latchset/custodia/commit/785fc87f38b4811bc4ce43a0a9b2267ee7d500b4", "file_name": "custodia/store/etcdstore.py", "vul_type": "cwe-022", "description": "Write a Python method named `get` that retrieves a value from an etcd store by a given key, logs an error, and raises a custom exception if the retrieval fails."}
{"func_name": "print_c_function", "func_src_before": "static void print_c_function(const state st) {\n  const char TYPE[] = \"__m256i \";\n  char buf[10];\n  printf(\"static inline void sbox(const %sin0, const %sin1, const %sin2, const %sin3,\\n\"\n      \"const %sin4, const %sin5, const %sin6, const %sin7, %s*out0,\\n\"\n      \"%s*out1, %s*out2, %s*out3, %s*out4, %s*out5, %s*out6,\\n\"\n      \"%s*out7) {\\n\", TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE,\n      TYPE, TYPE, TYPE);\n  for (uint8_t gate = 8; gate < st.num_gates; gate++) {\n    bool ret = get_c_variable_name(st, gate, buf);\n    printf(\"  %s%s = \", ret == true ? TYPE : \"\", buf);\n    get_c_variable_name(st, st.gates[gate].in1, buf);\n    if (st.gates[gate].type == NOT) {\n      printf(\"~%s;\\n\", buf);\n      continue;\n    }\n    printf(\"%s \", buf);\n    switch (st.gates[gate].type) {\n      case AND:\n        printf(\"& \");\n        break;\n      case OR:\n        printf(\"| \");\n        break;\n      case XOR:\n        printf(\"^ \");\n        break;\n      default:\n        assert(false);\n    }\n    get_c_variable_name(st, st.gates[gate].in2, buf);\n    printf(\"%s;\\n\", buf);\n  }\n  printf(\"}\\n\");\n}", "func_src_after": "static void print_c_function(const state st) {\n  const char TYPE[] = \"__m256i \";\n  char buf[10];\n  printf(\"static inline void sbox(const %sin0, const %sin1, const %sin2, const %sin3,\\n\"\n      \"const %sin4, const %sin5, const %sin6, const %sin7, %s*out0,\\n\"\n      \"%s*out1, %s*out2, %s*out3, %s*out4, %s*out5, %s*out6,\\n\"\n      \"%s*out7) {\\n\", TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE,\n      TYPE, TYPE, TYPE);\n  for (uint64_t gate = 8; gate < st.num_gates; gate++) {\n    bool ret = get_c_variable_name(st, gate, buf);\n    printf(\"  %s%s = \", ret == true ? TYPE : \"\", buf);\n    get_c_variable_name(st, st.gates[gate].in1, buf);\n    if (st.gates[gate].type == NOT) {\n      printf(\"~%s;\\n\", buf);\n      continue;\n    }\n    printf(\"%s \", buf);\n    switch (st.gates[gate].type) {\n      case AND:\n        printf(\"& \");\n        break;\n      case OR:\n        printf(\"| \");\n        break;\n      case XOR:\n        printf(\"^ \");\n        break;\n      default:\n        assert(false);\n    }\n    get_c_variable_name(st, st.gates[gate].in2, buf);\n    printf(\"%s;\\n\", buf);\n  }\n  printf(\"}\\n\");\n}", "line_changes": {"deleted": [{"line_no": 9, "char_start": 446, "char_end": 502, "line": "  for (uint8_t gate = 8; gate < st.num_gates; gate++) {\n"}], "added": [{"line_no": 9, "char_start": 446, "char_end": 503, "line": "  for (uint64_t gate = 8; gate < st.num_gates; gate++) {\n"}]}, "char_changes": {"deleted": [{"char_start": 457, "char_end": 458, "chars": "8"}], "added": [{"char_start": 457, "char_end": 459, "chars": "64"}]}, "commit_link": "github.com/dansarie/sboxgates/commit/5dffb1e61a9f28ef596684d6e401c3ee166bb4eb", "file_name": "sboxgates.c", "vul_type": "cwe-190", "commit_msg": "Fix integer overflow when generating C source code.", "parent_commit": "7cb0a30fe10f56e862b3d62973f65d8c3222e67a", "description": "Write a C function that prints the definition of an inline function for a substitution box (s-box) with input and output parameters, and a loop that generates bitwise operations based on a given state structure."}
{"func_name": "read_Header", "func_src_before": "read_Header(struct archive_read *a, struct _7z_header_info *h,\n    int check_header_id)\n{\n\tstruct _7zip *zip = (struct _7zip *)a->format->data;\n\tconst unsigned char *p;\n\tstruct _7z_folder *folders;\n\tstruct _7z_stream_info *si = &(zip->si);\n\tstruct _7zip_entry *entries;\n\tuint32_t folderIndex, indexInFolder;\n\tunsigned i;\n\tint eindex, empty_streams, sindex;\n\n\tif (check_header_id) {\n\t\t/*\n\t\t * Read Header.\n\t\t */\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t\tif (*p != kHeader)\n\t\t\treturn (-1);\n\t}\n\n\t/*\n\t * Read ArchiveProperties.\n\t */\n\tif ((p = header_bytes(a, 1)) == NULL)\n\t\treturn (-1);\n\tif (*p == kArchiveProperties) {\n\t\tfor (;;) {\n\t\t\tuint64_t size;\n\t\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\t\treturn (-1);\n\t\t\tif (*p == 0)\n\t\t\t\tbreak;\n\t\t\tif (parse_7zip_uint64(a, &size) < 0)\n\t\t\t\treturn (-1);\n\t\t}\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t}\n\n\t/*\n\t * Read MainStreamsInfo.\n\t */\n\tif (*p == kMainStreamsInfo) {\n\t\tif (read_StreamsInfo(a, &(zip->si)) < 0)\n\t\t\treturn (-1);\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t}\n\tif (*p == kEnd)\n\t\treturn (0);\n\n\t/*\n\t * Read FilesInfo.\n\t */\n\tif (*p != kFilesInfo)\n\t\treturn (-1);\n\n\tif (parse_7zip_uint64(a, &(zip->numFiles)) < 0)\n\t\treturn (-1);\n\tif (UMAX_ENTRY < zip->numFiles)\n\t\treturn (-1);\n\n\tzip->entries = calloc((size_t)zip->numFiles, sizeof(*zip->entries));\n\tif (zip->entries == NULL)\n\t\treturn (-1);\n\tentries = zip->entries;\n\n\tempty_streams = 0;\n\tfor (;;) {\n\t\tint type;\n\t\tuint64_t size;\n\t\tsize_t ll;\n\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t\ttype = *p;\n\t\tif (type == kEnd)\n\t\t\tbreak;\n\n\t\tif (parse_7zip_uint64(a, &size) < 0)\n\t\t\treturn (-1);\n\t\tif (zip->header_bytes_remaining < size)\n\t\t\treturn (-1);\n\t\tll = (size_t)size;\n\n\t\tswitch (type) {\n\t\tcase kEmptyStream:\n\t\t\th->emptyStreamBools = calloc((size_t)zip->numFiles,\n\t\t\t    sizeof(*h->emptyStreamBools));\n\t\t\tif (h->emptyStreamBools == NULL)\n\t\t\t\treturn (-1);\n\t\t\tif (read_Bools(\n\t\t\t    a, h->emptyStreamBools, (size_t)zip->numFiles) < 0)\n\t\t\t\treturn (-1);\n\t\t\tempty_streams = 0;\n\t\t\tfor (i = 0; i < zip->numFiles; i++) {\n\t\t\t\tif (h->emptyStreamBools[i])\n\t\t\t\t\tempty_streams++;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase kEmptyFile:\n\t\t\tif (empty_streams <= 0) {\n\t\t\t\t/* Unexcepted sequence. Skip this. */\n\t\t\t\tif (header_bytes(a, ll) == NULL)\n\t\t\t\t\treturn (-1);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\th->emptyFileBools = calloc(empty_streams,\n\t\t\t    sizeof(*h->emptyFileBools));\n\t\t\tif (h->emptyFileBools == NULL)\n\t\t\t\treturn (-1);\n\t\t\tif (read_Bools(a, h->emptyFileBools, empty_streams) < 0)\n\t\t\t\treturn (-1);\n\t\t\tbreak;\n\t\tcase kAnti:\n\t\t\tif (empty_streams <= 0) {\n\t\t\t\t/* Unexcepted sequence. Skip this. */\n\t\t\t\tif (header_bytes(a, ll) == NULL)\n\t\t\t\t\treturn (-1);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\th->antiBools = calloc(empty_streams,\n\t\t\t    sizeof(*h->antiBools));\n\t\t\tif (h->antiBools == NULL)\n\t\t\t\treturn (-1);\n\t\t\tif (read_Bools(a, h->antiBools, empty_streams) < 0)\n\t\t\t\treturn (-1);\n\t\t\tbreak;\n\t\tcase kCTime:\n\t\tcase kATime:\n\t\tcase kMTime:\n\t\t\tif (read_Times(a, h, type) < 0)\n\t\t\t\treturn (-1);\n\t\t\tbreak;\n\t\tcase kName:\n\t\t{\n\t\t\tunsigned char *np;\n\t\t\tsize_t nl, nb;\n\n\t\t\t/* Skip one byte. */\n\t\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\t\treturn (-1);\n\t\t\tll--;\n\n\t\t\tif ((ll & 1) || ll < zip->numFiles * 4)\n\t\t\t\treturn (-1);\n\n\t\t\tzip->entry_names = malloc(ll);\n\t\t\tif (zip->entry_names == NULL)\n\t\t\t\treturn (-1);\n\t\t\tnp = zip->entry_names;\n\t\t\tnb = ll;\n\t\t\t/*\n\t\t\t * Copy whole file names.\n\t\t\t * NOTE: This loop prevents from expanding\n\t\t\t * the uncompressed buffer in order not to\n\t\t\t * use extra memory resource.\n\t\t\t */\n\t\t\twhile (nb) {\n\t\t\t\tsize_t b;\n\t\t\t\tif (nb > UBUFF_SIZE)\n\t\t\t\t\tb = UBUFF_SIZE;\n\t\t\t\telse\n\t\t\t\t\tb = nb;\n\t\t\t\tif ((p = header_bytes(a, b)) == NULL)\n\t\t\t\t\treturn (-1);\n\t\t\t\tmemcpy(np, p, b);\n\t\t\t\tnp += b;\n\t\t\t\tnb -= b;\n\t\t\t}\n\t\t\tnp = zip->entry_names;\n\t\t\tnl = ll;\n\n\t\t\tfor (i = 0; i < zip->numFiles; i++) {\n\t\t\t\tentries[i].utf16name = np;\n#if defined(_WIN32) && !defined(__CYGWIN__) && defined(_DEBUG)\n\t\t\t\tentries[i].wname = (wchar_t *)np;\n#endif\n\n\t\t\t\t/* Find a terminator. */\n\t\t\t\twhile (nl >= 2 && (np[0] || np[1])) {\n\t\t\t\t\tnp += 2;\n\t\t\t\t\tnl -= 2;\n\t\t\t\t}\n\t\t\t\tif (nl < 2)\n\t\t\t\t\treturn (-1);/* Terminator not found */\n\t\t\t\tentries[i].name_len = np - entries[i].utf16name;\n\t\t\t\tnp += 2;\n\t\t\t\tnl -= 2;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tcase kAttributes:\n\t\t{\n\t\t\tint allAreDefined;\n\n\t\t\tif ((p = header_bytes(a, 2)) == NULL)\n\t\t\t\treturn (-1);\n\t\t\tallAreDefined = *p;\n\t\t\th->attrBools = calloc((size_t)zip->numFiles,\n\t\t\t    sizeof(*h->attrBools));\n\t\t\tif (h->attrBools == NULL)\n\t\t\t\treturn (-1);\n\t\t\tif (allAreDefined)\n\t\t\t\tmemset(h->attrBools, 1, (size_t)zip->numFiles);\n\t\t\telse {\n\t\t\t\tif (read_Bools(a, h->attrBools,\n\t\t\t\t      (size_t)zip->numFiles) < 0)\n\t\t\t\t\treturn (-1);\n\t\t\t}\n\t\t\tfor (i = 0; i < zip->numFiles; i++) {\n\t\t\t\tif (h->attrBools[i]) {\n\t\t\t\t\tif ((p = header_bytes(a, 4)) == NULL)\n\t\t\t\t\t\treturn (-1);\n\t\t\t\t\tentries[i].attr = archive_le32dec(p);\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tcase kDummy:\n\t\t\tif (ll == 0)\n\t\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (header_bytes(a, ll) == NULL)\n\t\t\t\treturn (-1);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t/*\n\t * Set up entry's attributes.\n\t */\n\tfolders = si->ci.folders;\n\teindex = sindex = 0;\n\tfolderIndex = indexInFolder = 0;\n\tfor (i = 0; i < zip->numFiles; i++) {\n\t\tif (h->emptyStreamBools == NULL || h->emptyStreamBools[i] == 0)\n\t\t\tentries[i].flg |= HAS_STREAM;\n\t\t/* The high 16 bits of attributes is a posix file mode. */\n\t\tentries[i].mode = entries[i].attr >> 16;\n\t\tif (entries[i].flg & HAS_STREAM) {\n\t\t\tif ((size_t)sindex >= si->ss.unpack_streams)\n\t\t\t\treturn (-1);\n\t\t\tif (entries[i].mode == 0)\n\t\t\t\tentries[i].mode = AE_IFREG | 0666;\n\t\t\tif (si->ss.digestsDefined[sindex])\n\t\t\t\tentries[i].flg |= CRC32_IS_SET;\n\t\t\tentries[i].ssIndex = sindex;\n\t\t\tsindex++;\n\t\t} else {\n\t\t\tint dir;\n\t\t\tif (h->emptyFileBools == NULL)\n\t\t\t\tdir = 1;\n\t\t\telse {\n\t\t\t\tif (h->emptyFileBools[eindex])\n\t\t\t\t\tdir = 0;\n\t\t\t\telse\n\t\t\t\t\tdir = 1;\n\t\t\t\teindex++;\n\t\t\t}\n\t\t\tif (entries[i].mode == 0) {\n\t\t\t\tif (dir)\n\t\t\t\t\tentries[i].mode = AE_IFDIR | 0777;\n\t\t\t\telse\n\t\t\t\t\tentries[i].mode = AE_IFREG | 0666;\n\t\t\t} else if (dir &&\n\t\t\t    (entries[i].mode & AE_IFMT) != AE_IFDIR) {\n\t\t\t\tentries[i].mode &= ~AE_IFMT;\n\t\t\t\tentries[i].mode |= AE_IFDIR;\n\t\t\t}\n\t\t\tif ((entries[i].mode & AE_IFMT) == AE_IFDIR &&\n\t\t\t    entries[i].name_len >= 2 &&\n\t\t\t    (entries[i].utf16name[entries[i].name_len-2] != '/' ||\n\t\t\t     entries[i].utf16name[entries[i].name_len-1] != 0)) {\n\t\t\t\tentries[i].utf16name[entries[i].name_len] = '/';\n\t\t\t\tentries[i].utf16name[entries[i].name_len+1] = 0;\n\t\t\t\tentries[i].name_len += 2;\n\t\t\t}\n\t\t\tentries[i].ssIndex = -1;\n\t\t}\n\t\tif (entries[i].attr & 0x01)\n\t\t\tentries[i].mode &= ~0222;/* Read only. */\n\n\t\tif ((entries[i].flg & HAS_STREAM) == 0 && indexInFolder == 0) {\n\t\t\t/*\n\t\t\t * The entry is an empty file or a directory file,\n\t\t\t * those both have no contents.\n\t\t\t */\n\t\t\tentries[i].folderIndex = -1;\n\t\t\tcontinue;\n\t\t}\n\t\tif (indexInFolder == 0) {\n\t\t\tfor (;;) {\n\t\t\t\tif (folderIndex >= si->ci.numFolders)\n\t\t\t\t\treturn (-1);\n\t\t\t\tif (folders[folderIndex].numUnpackStreams)\n\t\t\t\t\tbreak;\n\t\t\t\tfolderIndex++;\n\t\t\t}\n\t\t}\n\t\tentries[i].folderIndex = folderIndex;\n\t\tif ((entries[i].flg & HAS_STREAM) == 0)\n\t\t\tcontinue;\n\t\tindexInFolder++;\n\t\tif (indexInFolder >= folders[folderIndex].numUnpackStreams) {\n\t\t\tfolderIndex++;\n\t\t\tindexInFolder = 0;\n\t\t}\n\t}\n\n\treturn (0);\n}", "func_src_after": "read_Header(struct archive_read *a, struct _7z_header_info *h,\n    int check_header_id)\n{\n\tstruct _7zip *zip = (struct _7zip *)a->format->data;\n\tconst unsigned char *p;\n\tstruct _7z_folder *folders;\n\tstruct _7z_stream_info *si = &(zip->si);\n\tstruct _7zip_entry *entries;\n\tuint32_t folderIndex, indexInFolder;\n\tunsigned i;\n\tint eindex, empty_streams, sindex;\n\n\tif (check_header_id) {\n\t\t/*\n\t\t * Read Header.\n\t\t */\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t\tif (*p != kHeader)\n\t\t\treturn (-1);\n\t}\n\n\t/*\n\t * Read ArchiveProperties.\n\t */\n\tif ((p = header_bytes(a, 1)) == NULL)\n\t\treturn (-1);\n\tif (*p == kArchiveProperties) {\n\t\tfor (;;) {\n\t\t\tuint64_t size;\n\t\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\t\treturn (-1);\n\t\t\tif (*p == 0)\n\t\t\t\tbreak;\n\t\t\tif (parse_7zip_uint64(a, &size) < 0)\n\t\t\t\treturn (-1);\n\t\t}\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t}\n\n\t/*\n\t * Read MainStreamsInfo.\n\t */\n\tif (*p == kMainStreamsInfo) {\n\t\tif (read_StreamsInfo(a, &(zip->si)) < 0)\n\t\t\treturn (-1);\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t}\n\tif (*p == kEnd)\n\t\treturn (0);\n\n\t/*\n\t * Read FilesInfo.\n\t */\n\tif (*p != kFilesInfo)\n\t\treturn (-1);\n\n\tif (parse_7zip_uint64(a, &(zip->numFiles)) < 0)\n\t\treturn (-1);\n\tif (UMAX_ENTRY < zip->numFiles)\n\t\treturn (-1);\n\n\tzip->entries = calloc((size_t)zip->numFiles, sizeof(*zip->entries));\n\tif (zip->entries == NULL)\n\t\treturn (-1);\n\tentries = zip->entries;\n\n\tempty_streams = 0;\n\tfor (;;) {\n\t\tint type;\n\t\tuint64_t size;\n\t\tsize_t ll;\n\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t\ttype = *p;\n\t\tif (type == kEnd)\n\t\t\tbreak;\n\n\t\tif (parse_7zip_uint64(a, &size) < 0)\n\t\t\treturn (-1);\n\t\tif (zip->header_bytes_remaining < size)\n\t\t\treturn (-1);\n\t\tll = (size_t)size;\n\n\t\tswitch (type) {\n\t\tcase kEmptyStream:\n\t\t\tif (h->emptyStreamBools != NULL)\n\t\t\t\treturn (-1);\n\t\t\th->emptyStreamBools = calloc((size_t)zip->numFiles,\n\t\t\t    sizeof(*h->emptyStreamBools));\n\t\t\tif (h->emptyStreamBools == NULL)\n\t\t\t\treturn (-1);\n\t\t\tif (read_Bools(\n\t\t\t    a, h->emptyStreamBools, (size_t)zip->numFiles) < 0)\n\t\t\t\treturn (-1);\n\t\t\tempty_streams = 0;\n\t\t\tfor (i = 0; i < zip->numFiles; i++) {\n\t\t\t\tif (h->emptyStreamBools[i])\n\t\t\t\t\tempty_streams++;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase kEmptyFile:\n\t\t\tif (empty_streams <= 0) {\n\t\t\t\t/* Unexcepted sequence. Skip this. */\n\t\t\t\tif (header_bytes(a, ll) == NULL)\n\t\t\t\t\treturn (-1);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (h->emptyFileBools != NULL)\n\t\t\t\treturn (-1);\n\t\t\th->emptyFileBools = calloc(empty_streams,\n\t\t\t    sizeof(*h->emptyFileBools));\n\t\t\tif (h->emptyFileBools == NULL)\n\t\t\t\treturn (-1);\n\t\t\tif (read_Bools(a, h->emptyFileBools, empty_streams) < 0)\n\t\t\t\treturn (-1);\n\t\t\tbreak;\n\t\tcase kAnti:\n\t\t\tif (empty_streams <= 0) {\n\t\t\t\t/* Unexcepted sequence. Skip this. */\n\t\t\t\tif (header_bytes(a, ll) == NULL)\n\t\t\t\t\treturn (-1);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (h->antiBools != NULL)\n\t\t\t\treturn (-1);\n\t\t\th->antiBools = calloc(empty_streams,\n\t\t\t    sizeof(*h->antiBools));\n\t\t\tif (h->antiBools == NULL)\n\t\t\t\treturn (-1);\n\t\t\tif (read_Bools(a, h->antiBools, empty_streams) < 0)\n\t\t\t\treturn (-1);\n\t\t\tbreak;\n\t\tcase kCTime:\n\t\tcase kATime:\n\t\tcase kMTime:\n\t\t\tif (read_Times(a, h, type) < 0)\n\t\t\t\treturn (-1);\n\t\t\tbreak;\n\t\tcase kName:\n\t\t{\n\t\t\tunsigned char *np;\n\t\t\tsize_t nl, nb;\n\n\t\t\t/* Skip one byte. */\n\t\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\t\treturn (-1);\n\t\t\tll--;\n\n\t\t\tif ((ll & 1) || ll < zip->numFiles * 4)\n\t\t\t\treturn (-1);\n\n\t\t\tif (zip->entry_names != NULL)\n\t\t\t\treturn (-1);\n\t\t\tzip->entry_names = malloc(ll);\n\t\t\tif (zip->entry_names == NULL)\n\t\t\t\treturn (-1);\n\t\t\tnp = zip->entry_names;\n\t\t\tnb = ll;\n\t\t\t/*\n\t\t\t * Copy whole file names.\n\t\t\t * NOTE: This loop prevents from expanding\n\t\t\t * the uncompressed buffer in order not to\n\t\t\t * use extra memory resource.\n\t\t\t */\n\t\t\twhile (nb) {\n\t\t\t\tsize_t b;\n\t\t\t\tif (nb > UBUFF_SIZE)\n\t\t\t\t\tb = UBUFF_SIZE;\n\t\t\t\telse\n\t\t\t\t\tb = nb;\n\t\t\t\tif ((p = header_bytes(a, b)) == NULL)\n\t\t\t\t\treturn (-1);\n\t\t\t\tmemcpy(np, p, b);\n\t\t\t\tnp += b;\n\t\t\t\tnb -= b;\n\t\t\t}\n\t\t\tnp = zip->entry_names;\n\t\t\tnl = ll;\n\n\t\t\tfor (i = 0; i < zip->numFiles; i++) {\n\t\t\t\tentries[i].utf16name = np;\n#if defined(_WIN32) && !defined(__CYGWIN__) && defined(_DEBUG)\n\t\t\t\tentries[i].wname = (wchar_t *)np;\n#endif\n\n\t\t\t\t/* Find a terminator. */\n\t\t\t\twhile (nl >= 2 && (np[0] || np[1])) {\n\t\t\t\t\tnp += 2;\n\t\t\t\t\tnl -= 2;\n\t\t\t\t}\n\t\t\t\tif (nl < 2)\n\t\t\t\t\treturn (-1);/* Terminator not found */\n\t\t\t\tentries[i].name_len = np - entries[i].utf16name;\n\t\t\t\tnp += 2;\n\t\t\t\tnl -= 2;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tcase kAttributes:\n\t\t{\n\t\t\tint allAreDefined;\n\n\t\t\tif ((p = header_bytes(a, 2)) == NULL)\n\t\t\t\treturn (-1);\n\t\t\tallAreDefined = *p;\n\t\t\tif (h->attrBools != NULL)\n\t\t\t\treturn (-1);\n\t\t\th->attrBools = calloc((size_t)zip->numFiles,\n\t\t\t    sizeof(*h->attrBools));\n\t\t\tif (h->attrBools == NULL)\n\t\t\t\treturn (-1);\n\t\t\tif (allAreDefined)\n\t\t\t\tmemset(h->attrBools, 1, (size_t)zip->numFiles);\n\t\t\telse {\n\t\t\t\tif (read_Bools(a, h->attrBools,\n\t\t\t\t      (size_t)zip->numFiles) < 0)\n\t\t\t\t\treturn (-1);\n\t\t\t}\n\t\t\tfor (i = 0; i < zip->numFiles; i++) {\n\t\t\t\tif (h->attrBools[i]) {\n\t\t\t\t\tif ((p = header_bytes(a, 4)) == NULL)\n\t\t\t\t\t\treturn (-1);\n\t\t\t\t\tentries[i].attr = archive_le32dec(p);\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tcase kDummy:\n\t\t\tif (ll == 0)\n\t\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (header_bytes(a, ll) == NULL)\n\t\t\t\treturn (-1);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t/*\n\t * Set up entry's attributes.\n\t */\n\tfolders = si->ci.folders;\n\teindex = sindex = 0;\n\tfolderIndex = indexInFolder = 0;\n\tfor (i = 0; i < zip->numFiles; i++) {\n\t\tif (h->emptyStreamBools == NULL || h->emptyStreamBools[i] == 0)\n\t\t\tentries[i].flg |= HAS_STREAM;\n\t\t/* The high 16 bits of attributes is a posix file mode. */\n\t\tentries[i].mode = entries[i].attr >> 16;\n\t\tif (entries[i].flg & HAS_STREAM) {\n\t\t\tif ((size_t)sindex >= si->ss.unpack_streams)\n\t\t\t\treturn (-1);\n\t\t\tif (entries[i].mode == 0)\n\t\t\t\tentries[i].mode = AE_IFREG | 0666;\n\t\t\tif (si->ss.digestsDefined[sindex])\n\t\t\t\tentries[i].flg |= CRC32_IS_SET;\n\t\t\tentries[i].ssIndex = sindex;\n\t\t\tsindex++;\n\t\t} else {\n\t\t\tint dir;\n\t\t\tif (h->emptyFileBools == NULL)\n\t\t\t\tdir = 1;\n\t\t\telse {\n\t\t\t\tif (h->emptyFileBools[eindex])\n\t\t\t\t\tdir = 0;\n\t\t\t\telse\n\t\t\t\t\tdir = 1;\n\t\t\t\teindex++;\n\t\t\t}\n\t\t\tif (entries[i].mode == 0) {\n\t\t\t\tif (dir)\n\t\t\t\t\tentries[i].mode = AE_IFDIR | 0777;\n\t\t\t\telse\n\t\t\t\t\tentries[i].mode = AE_IFREG | 0666;\n\t\t\t} else if (dir &&\n\t\t\t    (entries[i].mode & AE_IFMT) != AE_IFDIR) {\n\t\t\t\tentries[i].mode &= ~AE_IFMT;\n\t\t\t\tentries[i].mode |= AE_IFDIR;\n\t\t\t}\n\t\t\tif ((entries[i].mode & AE_IFMT) == AE_IFDIR &&\n\t\t\t    entries[i].name_len >= 2 &&\n\t\t\t    (entries[i].utf16name[entries[i].name_len-2] != '/' ||\n\t\t\t     entries[i].utf16name[entries[i].name_len-1] != 0)) {\n\t\t\t\tentries[i].utf16name[entries[i].name_len] = '/';\n\t\t\t\tentries[i].utf16name[entries[i].name_len+1] = 0;\n\t\t\t\tentries[i].name_len += 2;\n\t\t\t}\n\t\t\tentries[i].ssIndex = -1;\n\t\t}\n\t\tif (entries[i].attr & 0x01)\n\t\t\tentries[i].mode &= ~0222;/* Read only. */\n\n\t\tif ((entries[i].flg & HAS_STREAM) == 0 && indexInFolder == 0) {\n\t\t\t/*\n\t\t\t * The entry is an empty file or a directory file,\n\t\t\t * those both have no contents.\n\t\t\t */\n\t\t\tentries[i].folderIndex = -1;\n\t\t\tcontinue;\n\t\t}\n\t\tif (indexInFolder == 0) {\n\t\t\tfor (;;) {\n\t\t\t\tif (folderIndex >= si->ci.numFolders)\n\t\t\t\t\treturn (-1);\n\t\t\t\tif (folders[folderIndex].numUnpackStreams)\n\t\t\t\t\tbreak;\n\t\t\t\tfolderIndex++;\n\t\t\t}\n\t\t}\n\t\tentries[i].folderIndex = folderIndex;\n\t\tif ((entries[i].flg & HAS_STREAM) == 0)\n\t\t\tcontinue;\n\t\tindexInFolder++;\n\t\tif (indexInFolder >= folders[folderIndex].numUnpackStreams) {\n\t\t\tfolderIndex++;\n\t\t\tindexInFolder = 0;\n\t\t}\n\t}\n\n\treturn (0);\n}", "commit_link": "github.com/libarchive/libarchive/commit/7f17c791dcfd8c0416e2cd2485b19410e47ef126", "file_name": "libarchive/archive_read_support_format_7zip.c", "vul_type": "cwe-125", "description": "Write a C function named `read_Header` that processes 7z archive headers."}
{"func_name": "TraceBezier", "func_src_before": "static MagickBooleanType TraceBezier(MVGInfo *mvg_info,\n  const size_t number_coordinates)\n{\n  double\n    alpha,\n    *coefficients,\n    weight;\n\n  PointInfo\n    end,\n    point,\n    *points;\n\n  PrimitiveInfo\n    *primitive_info;\n\n  register PrimitiveInfo\n    *p;\n\n  register ssize_t\n    i,\n    j;\n\n  size_t\n    control_points,\n    quantum;\n\n  /*\n    Allocate coefficients.\n  */\n  primitive_info=(*mvg_info->primitive_info)+mvg_info->offset;\n  quantum=number_coordinates;\n  for (i=0; i < (ssize_t) number_coordinates; i++)\n  {\n    for (j=i+1; j < (ssize_t) number_coordinates; j++)\n    {\n      alpha=fabs(primitive_info[j].point.x-primitive_info[i].point.x);\n      if (alpha > (double) SSIZE_MAX)\n        {\n          (void) ThrowMagickException(mvg_info->exception,GetMagickModule(),\n            ResourceLimitError,\"MemoryAllocationFailed\",\"`%s'\",\"\");\n          return(MagickFalse);\n        }\n      if (alpha > (double) quantum)\n        quantum=(size_t) alpha;\n      alpha=fabs(primitive_info[j].point.y-primitive_info[i].point.y);\n      if (alpha > (double) SSIZE_MAX)\n        {\n          (void) ThrowMagickException(mvg_info->exception,GetMagickModule(),\n            ResourceLimitError,\"MemoryAllocationFailed\",\"`%s'\",\"\");\n          return(MagickFalse);\n        }\n      if (alpha > (double) quantum)\n        quantum=(size_t) alpha;\n    }\n  }\n  quantum=MagickMin(quantum/number_coordinates,BezierQuantum);\n  primitive_info=(*mvg_info->primitive_info)+mvg_info->offset;\n  coefficients=(double *) AcquireQuantumMemory(number_coordinates,\n    sizeof(*coefficients));\n  points=(PointInfo *) AcquireQuantumMemory(quantum,number_coordinates*\n    sizeof(*points));\n  if ((coefficients == (double *) NULL) || (points == (PointInfo *) NULL))\n    {\n      if (points != (PointInfo *) NULL)\n        points=(PointInfo *) RelinquishMagickMemory(points);\n      if (coefficients != (double *) NULL)\n        coefficients=(double *) RelinquishMagickMemory(coefficients);\n      (void) ThrowMagickException(mvg_info->exception,GetMagickModule(),\n        ResourceLimitError,\"MemoryAllocationFailed\",\"`%s'\",\"\");\n      return(MagickFalse);\n    }\n  control_points=quantum*number_coordinates;\n  if (CheckPrimitiveExtent(mvg_info,control_points+1) == MagickFalse)\n    {\n      points=(PointInfo *) RelinquishMagickMemory(points);\n      coefficients=(double *) RelinquishMagickMemory(coefficients);\n      return(MagickFalse);\n    }\n  /*\n    Compute bezier points.\n  */\n  end=primitive_info[number_coordinates-1].point;\n  for (i=0; i < (ssize_t) number_coordinates; i++)\n    coefficients[i]=Permutate((ssize_t) number_coordinates-1,i);\n  weight=0.0;\n  for (i=0; i < (ssize_t) control_points; i++)\n  {\n    p=primitive_info;\n    point.x=0.0;\n    point.y=0.0;\n    alpha=pow((double) (1.0-weight),(double) number_coordinates-1.0);\n    for (j=0; j < (ssize_t) number_coordinates; j++)\n    {\n      point.x+=alpha*coefficients[j]*p->point.x;\n      point.y+=alpha*coefficients[j]*p->point.y;\n      alpha*=weight/(1.0-weight);\n      p++;\n    }\n    points[i]=point;\n    weight+=1.0/control_points;\n  }\n  /*\n    Bezier curves are just short segmented polys.\n  */\n  p=primitive_info;\n  for (i=0; i < (ssize_t) control_points; i++)\n  {\n    if (TracePoint(p,points[i]) == MagickFalse)\n      {\n        points=(PointInfo *) RelinquishMagickMemory(points);\n        coefficients=(double *) RelinquishMagickMemory(coefficients);\n        return(MagickFalse);\n      }\n    p+=p->coordinates;\n  }\n  if (TracePoint(p,end) == MagickFalse)\n    {\n      points=(PointInfo *) RelinquishMagickMemory(points);\n      coefficients=(double *) RelinquishMagickMemory(coefficients);\n      return(MagickFalse);\n    }\n  p+=p->coordinates;\n  primitive_info->coordinates=(size_t) (p-primitive_info);\n  primitive_info->closed_subpath=MagickFalse;\n  for (i=0; i < (ssize_t) primitive_info->coordinates; i++)\n  {\n    p->primitive=primitive_info->primitive;\n    p--;\n  }\n  points=(PointInfo *) RelinquishMagickMemory(points);\n  coefficients=(double *) RelinquishMagickMemory(coefficients);\n  return(MagickTrue);\n}", "func_src_after": "static MagickBooleanType TraceBezier(MVGInfo *mvg_info,\n  const size_t number_coordinates)\n{\n  double\n    alpha,\n    *coefficients,\n    weight;\n\n  PointInfo\n    end,\n    point,\n    *points;\n\n  PrimitiveInfo\n    *primitive_info;\n\n  register PrimitiveInfo\n    *p;\n\n  register ssize_t\n    i,\n    j;\n\n  size_t\n    control_points,\n    quantum;\n\n  /*\n    Allocate coefficients.\n  */\n  primitive_info=(*mvg_info->primitive_info)+mvg_info->offset;\n  quantum=number_coordinates;\n  for (i=0; i < (ssize_t) number_coordinates; i++)\n  {\n    for (j=i+1; j < (ssize_t) number_coordinates; j++)\n    {\n      alpha=fabs(primitive_info[j].point.x-primitive_info[i].point.x);\n      if (alpha > (double) SSIZE_MAX)\n        {\n          (void) ThrowMagickException(mvg_info->exception,GetMagickModule(),\n            ResourceLimitError,\"MemoryAllocationFailed\",\"`%s'\",\"\");\n          return(MagickFalse);\n        }\n      if (alpha > (double) quantum)\n        quantum=(size_t) alpha;\n      alpha=fabs(primitive_info[j].point.y-primitive_info[i].point.y);\n      if (alpha > (double) SSIZE_MAX)\n        {\n          (void) ThrowMagickException(mvg_info->exception,GetMagickModule(),\n            ResourceLimitError,\"MemoryAllocationFailed\",\"`%s'\",\"\");\n          return(MagickFalse);\n        }\n      if (alpha > (double) quantum)\n        quantum=(size_t) alpha;\n    }\n  }\n  primitive_info=(*mvg_info->primitive_info)+mvg_info->offset;\n  quantum=MagickMin(quantum/number_coordinates,BezierQuantum);\n  coefficients=(double *) AcquireQuantumMemory(number_coordinates,\n    sizeof(*coefficients));\n  points=(PointInfo *) AcquireQuantumMemory(quantum,number_coordinates*\n    sizeof(*points));\n  if ((coefficients == (double *) NULL) || (points == (PointInfo *) NULL))\n    {\n      if (points != (PointInfo *) NULL)\n        points=(PointInfo *) RelinquishMagickMemory(points);\n      if (coefficients != (double *) NULL)\n        coefficients=(double *) RelinquishMagickMemory(coefficients);\n      (void) ThrowMagickException(mvg_info->exception,GetMagickModule(),\n        ResourceLimitError,\"MemoryAllocationFailed\",\"`%s'\",\"\");\n      return(MagickFalse);\n    }\n  control_points=quantum*number_coordinates;\n  if (CheckPrimitiveExtent(mvg_info,control_points+1) == MagickFalse)\n    {\n      points=(PointInfo *) RelinquishMagickMemory(points);\n      coefficients=(double *) RelinquishMagickMemory(coefficients);\n      return(MagickFalse);\n    }\n  primitive_info=(*mvg_info->primitive_info)+mvg_info->offset;\n  /*\n    Compute bezier points.\n  */\n  end=primitive_info[number_coordinates-1].point;\n  for (i=0; i < (ssize_t) number_coordinates; i++)\n    coefficients[i]=Permutate((ssize_t) number_coordinates-1,i);\n  weight=0.0;\n  for (i=0; i < (ssize_t) control_points; i++)\n  {\n    p=primitive_info;\n    point.x=0.0;\n    point.y=0.0;\n    alpha=pow((double) (1.0-weight),(double) number_coordinates-1.0);\n    for (j=0; j < (ssize_t) number_coordinates; j++)\n    {\n      point.x+=alpha*coefficients[j]*p->point.x;\n      point.y+=alpha*coefficients[j]*p->point.y;\n      alpha*=weight/(1.0-weight);\n      p++;\n    }\n    points[i]=point;\n    weight+=1.0/control_points;\n  }\n  /*\n    Bezier curves are just short segmented polys.\n  */\n  p=primitive_info;\n  for (i=0; i < (ssize_t) control_points; i++)\n  {\n    if (TracePoint(p,points[i]) == MagickFalse)\n      {\n        points=(PointInfo *) RelinquishMagickMemory(points);\n        coefficients=(double *) RelinquishMagickMemory(coefficients);\n        return(MagickFalse);\n      }\n    p+=p->coordinates;\n  }\n  if (TracePoint(p,end) == MagickFalse)\n    {\n      points=(PointInfo *) RelinquishMagickMemory(points);\n      coefficients=(double *) RelinquishMagickMemory(coefficients);\n      return(MagickFalse);\n    }\n  p+=p->coordinates;\n  primitive_info->coordinates=(size_t) (p-primitive_info);\n  primitive_info->closed_subpath=MagickFalse;\n  for (i=0; i < (ssize_t) primitive_info->coordinates; i++)\n  {\n    p->primitive=primitive_info->primitive;\n    p--;\n  }\n  points=(PointInfo *) RelinquishMagickMemory(points);\n  coefficients=(double *) RelinquishMagickMemory(coefficients);\n  return(MagickTrue);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/ecf7c6b288e11e7e7f75387c5e9e93e423b98397", "file_name": "MagickCore/draw.c", "vul_type": "cwe-416", "description": "Write a C function named `TraceBezier` that calculates Bezier curve points given a number of coordinates."}
{"func_name": "AP4_AtomSampleTable::GetSample", "func_src_before": "AP4_AtomSampleTable::GetSample(AP4_Ordinal index, \n                               AP4_Sample& sample)\n{\n    AP4_Result result;\n\n    // check that we have an stsc atom\n    if (!m_StscAtom) {\n        return AP4_ERROR_INVALID_FORMAT;\n    }\n    \n    // check that we have a chunk offset table\n    if (m_StcoAtom == NULL && m_Co64Atom == NULL) {\n        return AP4_ERROR_INVALID_FORMAT;\n    }\n\n    // MP4 uses 1-based indexes internally, so adjust by one\n    index++;\n\n    // find out in which chunk this sample is located\n    AP4_Ordinal chunk, skip, desc;\n    result = m_StscAtom->GetChunkForSample(index, chunk, skip, desc);\n    if (AP4_FAILED(result)) return result;\n    \n    // check that the result is within bounds\n    if (skip > index) return AP4_ERROR_INTERNAL;\n\n    // get the atom offset for this chunk\n    AP4_UI64 offset;\n    if (m_StcoAtom) {\n        AP4_UI32 offset_32;\n        result = m_StcoAtom->GetChunkOffset(chunk, offset_32);\n        offset = offset_32;\n    } else {\n        result = m_Co64Atom->GetChunkOffset(chunk, offset);\n    }\n    if (AP4_FAILED(result)) return result;\n    \n    // compute the additional offset inside the chunk\n    for (unsigned int i = index-skip; i < index; i++) {\n        AP4_Size size = 0;\n        if (m_StszAtom) {\n            result = m_StszAtom->GetSampleSize(i, size); \n        } else if (m_Stz2Atom) {\n            result = m_Stz2Atom->GetSampleSize(i, size); \n        } else {\n            result = AP4_ERROR_INVALID_FORMAT;\n        }\n        if (AP4_FAILED(result)) return result;\n        offset += size;\n    }\n\n    // set the description index\n    sample.SetDescriptionIndex(desc-1); // adjust for 0-based indexes\n\n    // set the dts and cts\n    AP4_UI32 cts_offset = 0;\n    AP4_UI64 dts        = 0;\n    AP4_UI32 duration   = 0;\n    result = m_SttsAtom->GetDts(index, dts, &duration);\n    if (AP4_FAILED(result)) return result;\n    sample.SetDuration(duration);\n    sample.SetDts(dts);\n    if (m_CttsAtom == NULL) {\n        sample.SetCts(dts);\n    } else {\n        result = m_CttsAtom->GetCtsOffset(index, cts_offset); \n\t    if (AP4_FAILED(result)) return result;\n        sample.SetCtsDelta(cts_offset);\n    }     \n\n    // set the size\n    AP4_Size sample_size = 0;\n    if (m_StszAtom) {\n        result = m_StszAtom->GetSampleSize(index, sample_size); \n    } else if (m_Stz2Atom) {\n        result = m_Stz2Atom->GetSampleSize(index, sample_size); \n    } else {\n        result = AP4_ERROR_INVALID_FORMAT;\n    }\n    if (AP4_FAILED(result)) return result;\n    sample.SetSize(sample_size);\n\n    // set the sync flag\n    if (m_StssAtom == NULL) {\n        sample.SetSync(true);\n    } else {\n        sample.SetSync(m_StssAtom->IsSampleSync(index));\n    }\n\n    // set the offset\n    sample.SetOffset(offset);\n\n    // set the data stream\n    sample.SetDataStream(m_SampleStream);\n\n\n    return AP4_SUCCESS;\n}", "func_src_after": "AP4_AtomSampleTable::GetSample(AP4_Ordinal index, \n                               AP4_Sample& sample)\n{\n    AP4_Result result;\n\n    // check that we have an stsc atom\n    if (!m_StscAtom) {\n        return AP4_ERROR_INVALID_FORMAT;\n    }\n    \n    // check that we have a chunk offset table\n    if (m_StcoAtom == NULL && m_Co64Atom == NULL) {\n        return AP4_ERROR_INVALID_FORMAT;\n    }\n\n    // MP4 uses 1-based indexes internally, so adjust by one\n    index++;\n\n    // find out in which chunk this sample is located\n    AP4_Ordinal chunk, skip, desc;\n    result = m_StscAtom->GetChunkForSample(index, chunk, skip, desc);\n    if (AP4_FAILED(result)) return result;\n    \n    // check that the result is within bounds\n    if (skip > index) return AP4_ERROR_INTERNAL;\n\n    // get the atom offset for this chunk\n    AP4_UI64 offset;\n    if (m_StcoAtom) {\n        AP4_UI32 offset_32;\n        result = m_StcoAtom->GetChunkOffset(chunk, offset_32);\n        offset = offset_32;\n    } else {\n        result = m_Co64Atom->GetChunkOffset(chunk, offset);\n    }\n    if (AP4_FAILED(result)) return result;\n    \n    // compute the additional offset inside the chunk\n    for (unsigned int i = index-skip; i < index; i++) {\n        AP4_Size size = 0;\n        if (m_StszAtom) {\n            result = m_StszAtom->GetSampleSize(i, size); \n        } else if (m_Stz2Atom) {\n            result = m_Stz2Atom->GetSampleSize(i, size); \n        } else {\n            result = AP4_ERROR_INVALID_FORMAT;\n        }\n        if (AP4_FAILED(result)) return result;\n        offset += size;\n    }\n\n    // set the description index\n    sample.SetDescriptionIndex(desc-1); // adjust for 0-based indexes\n\n    // set the dts and cts\n    AP4_UI32 cts_offset = 0;\n    AP4_UI64 dts        = 0;\n    AP4_UI32 duration   = 0;\n    if (m_SttsAtom) {\n        result = m_SttsAtom->GetDts(index, dts, &duration);\n        if (AP4_FAILED(result)) return result;\n    }\n    sample.SetDuration(duration);\n    sample.SetDts(dts);\n    if (m_CttsAtom == NULL) {\n        sample.SetCts(dts);\n    } else {\n        result = m_CttsAtom->GetCtsOffset(index, cts_offset); \n\t    if (AP4_FAILED(result)) return result;\n        sample.SetCtsDelta(cts_offset);\n    }     \n\n    // set the size\n    AP4_Size sample_size = 0;\n    if (m_StszAtom) {\n        result = m_StszAtom->GetSampleSize(index, sample_size); \n    } else if (m_Stz2Atom) {\n        result = m_Stz2Atom->GetSampleSize(index, sample_size); \n    } else {\n        result = AP4_ERROR_INVALID_FORMAT;\n    }\n    if (AP4_FAILED(result)) return result;\n    sample.SetSize(sample_size);\n\n    // set the sync flag\n    if (m_StssAtom == NULL) {\n        sample.SetSync(true);\n    } else {\n        sample.SetSync(m_StssAtom->IsSampleSync(index));\n    }\n\n    // set the offset\n    sample.SetOffset(offset);\n\n    // set the data stream\n    sample.SetDataStream(m_SampleStream);\n\n\n    return AP4_SUCCESS;\n}", "commit_link": "github.com/axiomatic-systems/Bento4/commit/2f267f89f957088197f4b1fc254632d1645b415d", "file_name": "Source/C++/Core/Ap4AtomSampleTable.cpp", "vul_type": "cwe-476", "description": "In C++, write a function to retrieve a media sample from an MP4 file's atom sample table by its index."}
{"func_name": "render_page_name", "func_src_before": "@app.route('/<page_name>')\ndef render_page_name(page_name):\n    query = db.query(\"select page_content.content, page.id as page_id, page_content.id as content_id from page, page_content where page.id = page_content.page_id and page.page_name = '%s' order by page_content.id desc limit 1\" % page_name)\n    wiki_page = query.namedresult()\n    has_content = False\n    page_is_taken = False\n    if len(wiki_page) < 1:\n        content = \"\"\n    else:\n        page_is_taken = True\n        content = wiki_page[0].content\n    if len(content) > 0:\n        has_content = True\n    else:\n        pass\n    content = markdown.markdown(wiki_linkify(content))\n    return render_template(\n        'pageholder.html',\n        page_is_taken = page_is_taken,\n        page_name = page_name,\n        markdown = markdown,\n        wiki_linkify = wiki_linkify,\n        has_content = has_content,\n        content = content\n    )", "func_src_after": "@app.route('/<page_name>')\ndef render_page_name(page_name):\n    query = db.query(\"select page_content.content, page.id as page_id, page_content.id as content_id from page, page_content where page.id = page_content.page_id and page.page_name = $1 order by page_content.id desc limit 1\", page_name)\n    wiki_page = query.namedresult()\n    has_content = False\n    page_is_taken = False\n    if len(wiki_page) < 1:\n        content = \"\"\n    else:\n        page_is_taken = True\n        content = wiki_page[0].content\n    if len(content) > 0:\n        has_content = True\n    else:\n        pass\n    content = markdown.markdown(wiki_linkify(content))\n    return render_template(\n        'pageholder.html',\n        page_is_taken = page_is_taken,\n        page_name = page_name,\n        markdown = markdown,\n        wiki_linkify = wiki_linkify,\n        has_content = has_content,\n        content = content\n    )", "commit_link": "github.com/Pumala/python_wiki_app_redo/commit/65d60747cd8efb05970304234d3bd949d2088e8b", "file_name": "server.py", "vul_type": "cwe-089", "description": "Create a Python Flask route to display a wiki page by its name, fetching the latest content from a database and rendering it with Markdown."}
{"func_name": "ImagingPcxDecode", "func_src_before": "ImagingPcxDecode(Imaging im, ImagingCodecState state, UINT8* buf, Py_ssize_t bytes)\n{\n    UINT8 n;\n    UINT8* ptr;\n\n    if ((state->xsize * state->bits + 7) / 8 > state->bytes) {\n        state->errcode = IMAGING_CODEC_OVERRUN;\n        return -1;\n    }\n\n    ptr = buf;\n\n    for (;;) {\n\n\tif (bytes < 1)\n\t    return ptr - buf;\n\n\tif ((*ptr & 0xC0) == 0xC0) {\n\n\t    /* Run */\n\t    if (bytes < 2)\n\t\treturn ptr - buf;\n\n\t    n = ptr[0] & 0x3F;\n\n\t    while (n > 0) {\n\t\tif (state->x >= state->bytes) {\n\t\t    state->errcode = IMAGING_CODEC_OVERRUN;\n\t\t    break;\n\t\t}\n\t\tstate->buffer[state->x++] = ptr[1];\n\t\tn--;\n\t    }\n\n\t    ptr += 2; bytes -= 2;\n\n\t} else {\n\n\t    /* Literal */\n\t    state->buffer[state->x++] = ptr[0];\n\t    ptr++; bytes--;\n\n\t}\n\n\tif (state->x >= state->bytes) {\n        if (state->bytes % state->xsize && state->bytes > state->xsize) {\n            int bands = state->bytes / state->xsize;\n            int stride = state->bytes / bands;\n            int i;\n            for (i=1; i< bands; i++) {  // note -- skipping first band\n                memmove(&state->buffer[i*state->xsize],\n                        &state->buffer[i*stride],\n                        state->xsize);\n            }\n        }\n\t    /* Got a full line, unpack it */\n\t    state->shuffle((UINT8*) im->image[state->y + state->yoff] +\n\t\t\t   state->xoff * im->pixelsize, state->buffer,\n\t\t\t   state->xsize);\n\n\t    state->x = 0;\n\n\t    if (++state->y >= state->ysize) {\n\t\t/* End of file (errcode = 0) */\n\t\treturn -1;\n\t    }\n\t}\n\n    }\n}", "func_src_after": "ImagingPcxDecode(Imaging im, ImagingCodecState state, UINT8* buf, Py_ssize_t bytes)\n{\n    UINT8 n;\n    UINT8* ptr;\n\n    if ((state->xsize * state->bits + 7) / 8 > state->bytes) {\n        state->errcode = IMAGING_CODEC_OVERRUN;\n        return -1;\n    }\n\n    ptr = buf;\n\n    for (;;) {\n\n\tif (bytes < 1)\n\t    return ptr - buf;\n\n\tif ((*ptr & 0xC0) == 0xC0) {\n\n\t    /* Run */\n\t    if (bytes < 2)\n\t\treturn ptr - buf;\n\n\t    n = ptr[0] & 0x3F;\n\n\t    while (n > 0) {\n\t\tif (state->x >= state->bytes) {\n\t\t    state->errcode = IMAGING_CODEC_OVERRUN;\n\t\t    break;\n\t\t}\n\t\tstate->buffer[state->x++] = ptr[1];\n\t\tn--;\n\t    }\n\n\t    ptr += 2; bytes -= 2;\n\n\t} else {\n\n\t    /* Literal */\n\t    state->buffer[state->x++] = ptr[0];\n\t    ptr++; bytes--;\n\n\t}\n\n\tif (state->x >= state->bytes) {\n        if (state->bytes % state->xsize && state->bytes > state->xsize) {\n            int bands = state->bytes / state->xsize;\n            int stride = state->bytes / bands;\n            int i;\n            for (i=1; i< bands; i++) {  // note -- skipping first band\n                memmove(&state->buffer[i*state->xsize],\n                        &state->buffer[i*stride],\n                        state->xsize);\n            }\n        }\n\t    /* Got a full line, unpack it */\n\t    state->shuffle((UINT8*) im->image[state->y + state->yoff] +\n\t\t\t   state->xoff * im->pixelsize, state->buffer,\n\t\t\t   state->xsize);\n\n\t    state->x = 0;\n\n\t    if (++state->y >= state->ysize) {\n\t\t/* End of file (errcode = 0) */\n\t\treturn -1;\n\t    }\n\t}\n\n    }\n}", "commit_link": "github.com/python-pillow/Pillow/commit/6a83e4324738bb0452fbe8074a995b1c73f08de7#diff-9478f2787e3ae9668a15123b165c23ac", "file_name": "src/libImaging/PcxDecode.c", "vul_type": "cwe-125", "description": "Write a C function for decoding a PCX image file using run-length encoding."}
{"func_name": "store_versioninfo_gnu_verdef", "func_src_before": "static Sdb *store_versioninfo_gnu_verdef(ELFOBJ *bin, Elf_(Shdr) *shdr, int sz) {\n\tconst char *section_name = \"\";\n\tconst char *link_section_name = \"\";\n\tchar *end = NULL;\n\tElf_(Shdr) *link_shdr = NULL;\n\tut8 dfs[sizeof (Elf_(Verdef))] = {0};\n\tSdb *sdb;\n\tint cnt, i;\n\tif (shdr->sh_link > bin->ehdr.e_shnum) {\n\t\treturn false;\n\t}\n\tlink_shdr = &bin->shdr[shdr->sh_link];\n\tif (shdr->sh_size < 1) {\n\t\treturn false;\n\t}\n\tElf_(Verdef) *defs = calloc (shdr->sh_size, sizeof (char));\n\tif (!defs) {\n\t\treturn false;\n\t}\n\tif (bin->shstrtab && shdr->sh_name < bin->shstrtab_size) {\n\t\tsection_name = &bin->shstrtab[shdr->sh_name];\n\t}\n\tif (link_shdr && bin->shstrtab && link_shdr->sh_name < bin->shstrtab_size) {\n\t\tlink_section_name = &bin->shstrtab[link_shdr->sh_name];\n\t}\n\tif (!defs) {\n\t\tbprintf (\"Warning: Cannot allocate memory (Check Elf_(Verdef))\\n\");\n\t\treturn NULL;\n\t}\n\tsdb = sdb_new0 ();\n\tend = (char *)defs + shdr->sh_size;\n\tsdb_set (sdb, \"section_name\", section_name, 0);\n\tsdb_num_set (sdb, \"entries\", shdr->sh_info, 0);\n\tsdb_num_set (sdb, \"addr\", shdr->sh_addr, 0);\n\tsdb_num_set (sdb, \"offset\", shdr->sh_offset, 0);\n\tsdb_num_set (sdb, \"link\", shdr->sh_link, 0);\n\tsdb_set (sdb, \"link_section_name\", link_section_name, 0);\n\n\tfor (cnt = 0, i = 0; i >= 0 && cnt < shdr->sh_info && ((char *)defs + i < end); ++cnt) {\n\t\tSdb *sdb_verdef = sdb_new0 ();\n\t\tchar *vstart = ((char*)defs) + i;\n\t\tchar key[32] = {0};\n\t\tElf_(Verdef) *verdef = (Elf_(Verdef)*)vstart;\n\t\tElf_(Verdaux) aux = {0};\n\t\tint j = 0;\n\t\tint isum = 0;\n\n\t\tr_buf_read_at (bin->b, shdr->sh_offset + i, dfs, sizeof (Elf_(Verdef)));\n\t\tverdef->vd_version = READ16 (dfs, j)\n\t\tverdef->vd_flags = READ16 (dfs, j)\n\t\tverdef->vd_ndx = READ16 (dfs, j)\n\t\tverdef->vd_cnt = READ16 (dfs, j)\n\t\tverdef->vd_hash = READ32 (dfs, j)\n\t\tverdef->vd_aux = READ32 (dfs, j)\n\t\tverdef->vd_next = READ32 (dfs, j)\n\t\tvstart += verdef->vd_aux;\n\t\tif (vstart > end || vstart + sizeof (Elf_(Verdaux)) > end) {\n\t\t\tsdb_free (sdb_verdef);\n\t\t\tgoto out_error;\n\t\t}\n\n\t\tj = 0;\n\t\taux.vda_name = READ32 (vstart, j)\n\t\taux.vda_next = READ32 (vstart, j)\n\n\t\tisum = i + verdef->vd_aux;\n\t\tif (aux.vda_name > bin->dynstr_size) {\n\t\t\tsdb_free (sdb_verdef);\n\t\t\tgoto out_error;\n\t\t}\n\n\t\tsdb_num_set (sdb_verdef, \"idx\", i, 0);\n\t\tsdb_num_set (sdb_verdef, \"vd_version\", verdef->vd_version, 0);\n\t\tsdb_num_set (sdb_verdef, \"vd_ndx\", verdef->vd_ndx, 0);\n\t\tsdb_num_set (sdb_verdef, \"vd_cnt\", verdef->vd_cnt, 0);\n\t\tsdb_set (sdb_verdef, \"vda_name\", &bin->dynstr[aux.vda_name], 0);\n\t\tsdb_set (sdb_verdef, \"flags\", get_ver_flags (verdef->vd_flags), 0);\n\n\t\tfor (j = 1; j < verdef->vd_cnt; ++j) {\n\t\t\tint k;\n\t\t\tSdb *sdb_parent = sdb_new0 ();\n\t\t\tisum += aux.vda_next;\n\t\t\tvstart += aux.vda_next;\n\t\t\tif (vstart > end || vstart + sizeof(Elf_(Verdaux)) > end) {\n\t\t\t\tsdb_free (sdb_verdef);\n\t\t\t\tsdb_free (sdb_parent);\n\t\t\t\tgoto out_error;\n\t\t\t}\n\t\t\tk = 0;\n\t\t\taux.vda_name = READ32 (vstart, k)\n\t\t\taux.vda_next = READ32 (vstart, k)\n\t\t\tif (aux.vda_name > bin->dynstr_size) {\n\t\t\t\tsdb_free (sdb_verdef);\n\t\t\t\tsdb_free (sdb_parent);\n\t\t\t\tgoto out_error;\n\t\t\t}\n\t\t\tsdb_num_set (sdb_parent, \"idx\", isum, 0);\n\t\t\tsdb_num_set (sdb_parent, \"parent\", j, 0);\n\t\t\tsdb_set (sdb_parent, \"vda_name\", &bin->dynstr[aux.vda_name], 0);\n\t\t\tsnprintf (key, sizeof (key), \"parent%d\", j - 1);\n\t\t\tsdb_ns_set (sdb_verdef, key, sdb_parent);\n\t\t}\n\n\t\tsnprintf (key, sizeof (key), \"verdef%d\", cnt);\n\t\tsdb_ns_set (sdb, key, sdb_verdef);\n\t\tif (!verdef->vd_next) {\n\t\t\tsdb_free (sdb_verdef);\n\t\t\tgoto out_error;\n\t\t}\n\t\tif ((st32)verdef->vd_next < 1) {\n\t\t\teprintf (\"Warning: Invalid vd_next in the ELF version\\n\");\n\t\t\tbreak;\n\t\t}\n\t\ti += verdef->vd_next;\n\t}\n\tfree (defs);\n\treturn sdb;\nout_error:\n\tfree (defs);\n\tsdb_free (sdb);\n\treturn NULL;\n}", "func_src_after": "static Sdb *store_versioninfo_gnu_verdef(ELFOBJ *bin, Elf_(Shdr) *shdr, int sz) {\n\tconst char *section_name = \"\";\n\tconst char *link_section_name = \"\";\n\tchar *end = NULL;\n\tElf_(Shdr) *link_shdr = NULL;\n\tut8 dfs[sizeof (Elf_(Verdef))] = {0};\n\tSdb *sdb;\n\tint cnt, i;\n\tif (shdr->sh_link > bin->ehdr.e_shnum) {\n\t\treturn false;\n\t}\n\tlink_shdr = &bin->shdr[shdr->sh_link];\n\tif (shdr->sh_size < 1) {\n\t\treturn false;\n\t}\n\tElf_(Verdef) *defs = calloc (shdr->sh_size, sizeof (char));\n\tif (!defs) {\n\t\treturn false;\n\t}\n\tif (bin->shstrtab && shdr->sh_name < bin->shstrtab_size) {\n\t\tsection_name = &bin->shstrtab[shdr->sh_name];\n\t}\n\tif (link_shdr && bin->shstrtab && link_shdr->sh_name < bin->shstrtab_size) {\n\t\tlink_section_name = &bin->shstrtab[link_shdr->sh_name];\n\t}\n\tif (!defs) {\n\t\tbprintf (\"Warning: Cannot allocate memory (Check Elf_(Verdef))\\n\");\n\t\treturn NULL;\n\t}\n\tsdb = sdb_new0 ();\n\tend = (char *)defs + shdr->sh_size;\n\tsdb_set (sdb, \"section_name\", section_name, 0);\n\tsdb_num_set (sdb, \"entries\", shdr->sh_info, 0);\n\tsdb_num_set (sdb, \"addr\", shdr->sh_addr, 0);\n\tsdb_num_set (sdb, \"offset\", shdr->sh_offset, 0);\n\tsdb_num_set (sdb, \"link\", shdr->sh_link, 0);\n\tsdb_set (sdb, \"link_section_name\", link_section_name, 0);\n\n\tfor (cnt = 0, i = 0; i >= 0 && cnt < shdr->sh_info && ((char *)defs + i < end); ++cnt) {\n\t\tSdb *sdb_verdef = sdb_new0 ();\n\t\tchar *vstart = ((char*)defs) + i;\n\t\tchar key[32] = {0};\n\t\tElf_(Verdef) *verdef = (Elf_(Verdef)*)vstart;\n\t\tElf_(Verdaux) aux = {0};\n\t\tint j = 0;\n\t\tint isum = 0;\n\n\t\tr_buf_read_at (bin->b, shdr->sh_offset + i, dfs, sizeof (Elf_(Verdef)));\n\t\tverdef->vd_version = READ16 (dfs, j)\n\t\tverdef->vd_flags = READ16 (dfs, j)\n\t\tverdef->vd_ndx = READ16 (dfs, j)\n\t\tverdef->vd_cnt = READ16 (dfs, j)\n\t\tverdef->vd_hash = READ32 (dfs, j)\n\t\tverdef->vd_aux = READ32 (dfs, j)\n\t\tverdef->vd_next = READ32 (dfs, j)\n\t\tint vdaux = verdef->vd_aux;\n\t\tif (vdaux < 1) {\n\t\t\tsdb_free (sdb_verdef);\n\t\t\tgoto out_error;\n\t\t}\n\t\tvstart += vdaux;\n\t\tif (vstart > end || vstart + sizeof (Elf_(Verdaux)) > end) {\n\t\t\tsdb_free (sdb_verdef);\n\t\t\tgoto out_error;\n\t\t}\n\n\t\tj = 0;\n\t\taux.vda_name = READ32 (vstart, j)\n\t\taux.vda_next = READ32 (vstart, j)\n\n\t\tisum = i + verdef->vd_aux;\n\t\tif (aux.vda_name > bin->dynstr_size) {\n\t\t\tsdb_free (sdb_verdef);\n\t\t\tgoto out_error;\n\t\t}\n\n\t\tsdb_num_set (sdb_verdef, \"idx\", i, 0);\n\t\tsdb_num_set (sdb_verdef, \"vd_version\", verdef->vd_version, 0);\n\t\tsdb_num_set (sdb_verdef, \"vd_ndx\", verdef->vd_ndx, 0);\n\t\tsdb_num_set (sdb_verdef, \"vd_cnt\", verdef->vd_cnt, 0);\n\t\tsdb_set (sdb_verdef, \"vda_name\", &bin->dynstr[aux.vda_name], 0);\n\t\tsdb_set (sdb_verdef, \"flags\", get_ver_flags (verdef->vd_flags), 0);\n\n\t\tfor (j = 1; j < verdef->vd_cnt; ++j) {\n\t\t\tint k;\n\t\t\tSdb *sdb_parent = sdb_new0 ();\n\t\t\tisum += aux.vda_next;\n\t\t\tvstart += aux.vda_next;\n\t\t\tif (vstart > end || vstart + sizeof(Elf_(Verdaux)) > end) {\n\t\t\t\tsdb_free (sdb_verdef);\n\t\t\t\tsdb_free (sdb_parent);\n\t\t\t\tgoto out_error;\n\t\t\t}\n\t\t\tk = 0;\n\t\t\taux.vda_name = READ32 (vstart, k)\n\t\t\taux.vda_next = READ32 (vstart, k)\n\t\t\tif (aux.vda_name > bin->dynstr_size) {\n\t\t\t\tsdb_free (sdb_verdef);\n\t\t\t\tsdb_free (sdb_parent);\n\t\t\t\tgoto out_error;\n\t\t\t}\n\t\t\tsdb_num_set (sdb_parent, \"idx\", isum, 0);\n\t\t\tsdb_num_set (sdb_parent, \"parent\", j, 0);\n\t\t\tsdb_set (sdb_parent, \"vda_name\", &bin->dynstr[aux.vda_name], 0);\n\t\t\tsnprintf (key, sizeof (key), \"parent%d\", j - 1);\n\t\t\tsdb_ns_set (sdb_verdef, key, sdb_parent);\n\t\t}\n\n\t\tsnprintf (key, sizeof (key), \"verdef%d\", cnt);\n\t\tsdb_ns_set (sdb, key, sdb_verdef);\n\t\tif (!verdef->vd_next) {\n\t\t\tsdb_free (sdb_verdef);\n\t\t\tgoto out_error;\n\t\t}\n\t\tif ((st32)verdef->vd_next < 1) {\n\t\t\teprintf (\"Warning: Invalid vd_next in the ELF version\\n\");\n\t\t\tbreak;\n\t\t}\n\t\ti += verdef->vd_next;\n\t}\n\tfree (defs);\n\treturn sdb;\nout_error:\n\tfree (defs);\n\tsdb_free (sdb);\n\treturn NULL;\n}", "commit_link": "github.com/radare/radare2/commit/44ded3ff35b8264f54b5a900cab32ec489d9e5b9", "file_name": "libr/bin/format/elf/elf.c", "vul_type": "cwe-125", "description": "Write a C function named `store_versioninfo_gnu_verdef` that processes version definition sections in an ELF binary and stores the information in a database."}
{"func_name": "ComplexImages", "func_src_before": "MagickExport Image *ComplexImages(const Image *images,const ComplexOperator op,\n  ExceptionInfo *exception)\n{\n#define ComplexImageTag  \"Complex/Image\"\n\n  CacheView\n    *Ai_view,\n    *Ar_view,\n    *Bi_view,\n    *Br_view,\n    *Ci_view,\n    *Cr_view;\n\n  const char\n    *artifact;\n\n  const Image\n    *Ai_image,\n    *Ar_image,\n    *Bi_image,\n    *Br_image;\n\n  double\n    snr;\n\n  Image\n    *Ci_image,\n    *complex_images,\n    *Cr_image,\n    *image;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    progress;\n\n  ssize_t\n    y;\n\n  assert(images != (Image *) NULL);\n  assert(images->signature == MagickCoreSignature);\n  if (images->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",images->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  if (images->next == (Image *) NULL)\n    {\n      (void) ThrowMagickException(exception,GetMagickModule(),ImageError,\n        \"ImageSequenceRequired\",\"`%s'\",images->filename);\n      return((Image *) NULL);\n    }\n  image=CloneImage(images,0,0,MagickTrue,exception);\n  if (image == (Image *) NULL)\n    return((Image *) NULL);\n  if (SetImageStorageClass(image,DirectClass,exception) == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return(image);\n    }\n  image->depth=32UL;\n  complex_images=NewImageList();\n  AppendImageToList(&complex_images,image);\n  image=CloneImage(images,0,0,MagickTrue,exception);\n  if (image == (Image *) NULL)\n    {\n      complex_images=DestroyImageList(complex_images);\n      return(complex_images);\n    }\n  AppendImageToList(&complex_images,image);\n  /*\n    Apply complex mathematics to image pixels.\n  */\n  artifact=GetImageArtifact(image,\"complex:snr\");\n  snr=0.0;\n  if (artifact != (const char *) NULL)\n    snr=StringToDouble(artifact,(char **) NULL);\n  Ar_image=images;\n  Ai_image=images->next;\n  Br_image=images;\n  Bi_image=images->next;\n  if ((images->next->next != (Image *) NULL) &&\n      (images->next->next->next != (Image *) NULL))\n    {\n      Br_image=images->next->next;\n      Bi_image=images->next->next->next;\n    }\n  Cr_image=complex_images;\n  Ci_image=complex_images->next;\n  Ar_view=AcquireVirtualCacheView(Ar_image,exception);\n  Ai_view=AcquireVirtualCacheView(Ai_image,exception);\n  Br_view=AcquireVirtualCacheView(Br_image,exception);\n  Bi_view=AcquireVirtualCacheView(Bi_image,exception);\n  Cr_view=AcquireAuthenticCacheView(Cr_image,exception);\n  Ci_view=AcquireAuthenticCacheView(Ci_image,exception);\n  status=MagickTrue;\n  progress=0;\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n  #pragma omp parallel for schedule(static) shared(progress,status) \\\n    magick_number_threads(Cr_image,complex_images,Cr_image->rows,1L)\n#endif\n  for (y=0; y < (ssize_t) Cr_image->rows; y++)\n  {\n    register const Quantum\n      *magick_restrict Ai,\n      *magick_restrict Ar,\n      *magick_restrict Bi,\n      *magick_restrict Br;\n\n    register Quantum\n      *magick_restrict Ci,\n      *magick_restrict Cr;\n\n    register ssize_t\n      x;\n\n    if (status == MagickFalse)\n      continue;\n    Ar=GetCacheViewVirtualPixels(Ar_view,0,y,Cr_image->columns,1,exception);\n    Ai=GetCacheViewVirtualPixels(Ai_view,0,y,Cr_image->columns,1,exception);\n    Br=GetCacheViewVirtualPixels(Br_view,0,y,Cr_image->columns,1,exception);\n    Bi=GetCacheViewVirtualPixels(Bi_view,0,y,Cr_image->columns,1,exception);\n    Cr=QueueCacheViewAuthenticPixels(Cr_view,0,y,Cr_image->columns,1,exception);\n    Ci=QueueCacheViewAuthenticPixels(Ci_view,0,y,Ci_image->columns,1,exception);\n    if ((Ar == (const Quantum *) NULL) || (Ai == (const Quantum *) NULL) || \n        (Br == (const Quantum *) NULL) || (Bi == (const Quantum *) NULL) ||\n        (Cr == (Quantum *) NULL) || (Ci == (Quantum *) NULL))\n      {\n        status=MagickFalse;\n        continue;\n      }\n    for (x=0; x < (ssize_t) Cr_image->columns; x++)\n    {\n      register ssize_t\n        i;\n\n      for (i=0; i < (ssize_t) GetPixelChannels(Cr_image); i++)\n      {\n        switch (op)\n        {\n          case AddComplexOperator:\n          {\n            Cr[i]=Ar[i]+Br[i];\n            Ci[i]=Ai[i]+Bi[i];\n            break;\n          }\n          case ConjugateComplexOperator:\n          default:\n          {\n            Cr[i]=Ar[i];\n            Ci[i]=(-Bi[i]);\n            break;\n          }\n          case DivideComplexOperator:\n          {\n            double\n              gamma;\n\n            gamma=PerceptibleReciprocal((double) Br[i]*Br[i]+Bi[i]*Bi[i]+snr);\n            Cr[i]=gamma*((double) Ar[i]*Br[i]+(double) Ai[i]*Bi[i]);\n            Ci[i]=gamma*((double) Ai[i]*Br[i]-(double) Ar[i]*Bi[i]);\n            break;\n          }\n          case MagnitudePhaseComplexOperator:\n          {\n            Cr[i]=sqrt((double) Ar[i]*Ar[i]+(double) Ai[i]*Ai[i]);\n            Ci[i]=atan2((double) Ai[i],(double) Ar[i])/(2.0*MagickPI)+0.5;\n            break;\n          }\n          case MultiplyComplexOperator:\n          {\n            Cr[i]=QuantumScale*((double) Ar[i]*Br[i]-(double) Ai[i]*Bi[i]);\n            Ci[i]=QuantumScale*((double) Ai[i]*Br[i]+(double) Ar[i]*Bi[i]);\n            break;\n          }\n          case RealImaginaryComplexOperator:\n          {\n            Cr[i]=Ar[i]*cos(2.0*MagickPI*(Ai[i]-0.5));\n            Ci[i]=Ar[i]*sin(2.0*MagickPI*(Ai[i]-0.5));\n            break;\n          }\n          case SubtractComplexOperator:\n          {\n            Cr[i]=Ar[i]-Br[i];\n            Ci[i]=Ai[i]-Bi[i];\n            break;\n          }\n        }\n      }\n      Ar+=GetPixelChannels(Ar_image);\n      Ai+=GetPixelChannels(Ai_image);\n      Br+=GetPixelChannels(Br_image);\n      Bi+=GetPixelChannels(Bi_image);\n      Cr+=GetPixelChannels(Cr_image);\n      Ci+=GetPixelChannels(Ci_image);\n    }\n    if (SyncCacheViewAuthenticPixels(Ci_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (SyncCacheViewAuthenticPixels(Cr_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (images->progress_monitor != (MagickProgressMonitor) NULL)\n      {\n        MagickBooleanType\n          proceed;\n\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n        #pragma omp atomic\n#endif\n        progress++;\n        proceed=SetImageProgress(images,ComplexImageTag,progress,images->rows);\n        if (proceed == MagickFalse)\n          status=MagickFalse;\n      }\n  }\n  Cr_view=DestroyCacheView(Cr_view);\n  Ci_view=DestroyCacheView(Ci_view);\n  Br_view=DestroyCacheView(Br_view);\n  Bi_view=DestroyCacheView(Bi_view);\n  Ar_view=DestroyCacheView(Ar_view);\n  Ai_view=DestroyCacheView(Ai_view);\n  if (status == MagickFalse)\n    complex_images=DestroyImageList(complex_images);\n  return(complex_images);\n}", "func_src_after": "MagickExport Image *ComplexImages(const Image *images,const ComplexOperator op,\n  ExceptionInfo *exception)\n{\n#define ComplexImageTag  \"Complex/Image\"\n\n  CacheView\n    *Ai_view,\n    *Ar_view,\n    *Bi_view,\n    *Br_view,\n    *Ci_view,\n    *Cr_view;\n\n  const char\n    *artifact;\n\n  const Image\n    *Ai_image,\n    *Ar_image,\n    *Bi_image,\n    *Br_image;\n\n  double\n    snr;\n\n  Image\n    *Ci_image,\n    *complex_images,\n    *Cr_image,\n    *image;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    progress;\n\n  size_t\n    number_channels;\n\n  ssize_t\n    y;\n\n  assert(images != (Image *) NULL);\n  assert(images->signature == MagickCoreSignature);\n  if (images->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",images->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  if (images->next == (Image *) NULL)\n    {\n      (void) ThrowMagickException(exception,GetMagickModule(),ImageError,\n        \"ImageSequenceRequired\",\"`%s'\",images->filename);\n      return((Image *) NULL);\n    }\n  image=CloneImage(images,0,0,MagickTrue,exception);\n  if (image == (Image *) NULL)\n    return((Image *) NULL);\n  if (SetImageStorageClass(image,DirectClass,exception) == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return(image);\n    }\n  image->depth=32UL;\n  complex_images=NewImageList();\n  AppendImageToList(&complex_images,image);\n  image=CloneImage(images,0,0,MagickTrue,exception);\n  if (image == (Image *) NULL)\n    {\n      complex_images=DestroyImageList(complex_images);\n      return(complex_images);\n    }\n  AppendImageToList(&complex_images,image);\n  /*\n    Apply complex mathematics to image pixels.\n  */\n  artifact=GetImageArtifact(image,\"complex:snr\");\n  snr=0.0;\n  if (artifact != (const char *) NULL)\n    snr=StringToDouble(artifact,(char **) NULL);\n  Ar_image=images;\n  Ai_image=images->next;\n  Br_image=images;\n  Bi_image=images->next;\n  if ((images->next->next != (Image *) NULL) &&\n      (images->next->next->next != (Image *) NULL))\n    {\n      Br_image=images->next->next;\n      Bi_image=images->next->next->next;\n    }\n  Cr_image=complex_images;\n  Ci_image=complex_images->next;\n  number_channels=MagickMin(MagickMin(MagickMin(\n    Ar_image->number_channels,Ai_image->number_channels),MagickMin(\n    Br_image->number_channels,Bi_image->number_channels)),MagickMin(\n    Cr_image->number_channels,Ci_image->number_channels));\n  Ar_view=AcquireVirtualCacheView(Ar_image,exception);\n  Ai_view=AcquireVirtualCacheView(Ai_image,exception);\n  Br_view=AcquireVirtualCacheView(Br_image,exception);\n  Bi_view=AcquireVirtualCacheView(Bi_image,exception);\n  Cr_view=AcquireAuthenticCacheView(Cr_image,exception);\n  Ci_view=AcquireAuthenticCacheView(Ci_image,exception);\n  status=MagickTrue;\n  progress=0;\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n  #pragma omp parallel for schedule(static) shared(progress,status) \\\n    magick_number_threads(Cr_image,complex_images,Cr_image->rows,1L)\n#endif\n  for (y=0; y < (ssize_t) Cr_image->rows; y++)\n  {\n    register const Quantum\n      *magick_restrict Ai,\n      *magick_restrict Ar,\n      *magick_restrict Bi,\n      *magick_restrict Br;\n\n    register Quantum\n      *magick_restrict Ci,\n      *magick_restrict Cr;\n\n    register ssize_t\n      x;\n\n    if (status == MagickFalse)\n      continue;\n    Ar=GetCacheViewVirtualPixels(Ar_view,0,y,Cr_image->columns,1,exception);\n    Ai=GetCacheViewVirtualPixels(Ai_view,0,y,Cr_image->columns,1,exception);\n    Br=GetCacheViewVirtualPixels(Br_view,0,y,Cr_image->columns,1,exception);\n    Bi=GetCacheViewVirtualPixels(Bi_view,0,y,Cr_image->columns,1,exception);\n    Cr=QueueCacheViewAuthenticPixels(Cr_view,0,y,Cr_image->columns,1,exception);\n    Ci=QueueCacheViewAuthenticPixels(Ci_view,0,y,Ci_image->columns,1,exception);\n    if ((Ar == (const Quantum *) NULL) || (Ai == (const Quantum *) NULL) || \n        (Br == (const Quantum *) NULL) || (Bi == (const Quantum *) NULL) ||\n        (Cr == (Quantum *) NULL) || (Ci == (Quantum *) NULL))\n      {\n        status=MagickFalse;\n        continue;\n      }\n    for (x=0; x < (ssize_t) Cr_image->columns; x++)\n    {\n      register ssize_t\n        i;\n\n      for (i=0; i < (ssize_t) number_channels; i++)\n      {\n        switch (op)\n        {\n          case AddComplexOperator:\n          {\n            Cr[i]=Ar[i]+Br[i];\n            Ci[i]=Ai[i]+Bi[i];\n            break;\n          }\n          case ConjugateComplexOperator:\n          default:\n          {\n            Cr[i]=Ar[i];\n            Ci[i]=(-Bi[i]);\n            break;\n          }\n          case DivideComplexOperator:\n          {\n            double\n              gamma;\n\n            gamma=PerceptibleReciprocal((double) Br[i]*Br[i]+Bi[i]*Bi[i]+snr);\n            Cr[i]=gamma*((double) Ar[i]*Br[i]+(double) Ai[i]*Bi[i]);\n            Ci[i]=gamma*((double) Ai[i]*Br[i]-(double) Ar[i]*Bi[i]);\n            break;\n          }\n          case MagnitudePhaseComplexOperator:\n          {\n            Cr[i]=sqrt((double) Ar[i]*Ar[i]+(double) Ai[i]*Ai[i]);\n            Ci[i]=atan2((double) Ai[i],(double) Ar[i])/(2.0*MagickPI)+0.5;\n            break;\n          }\n          case MultiplyComplexOperator:\n          {\n            Cr[i]=QuantumScale*((double) Ar[i]*Br[i]-(double) Ai[i]*Bi[i]);\n            Ci[i]=QuantumScale*((double) Ai[i]*Br[i]+(double) Ar[i]*Bi[i]);\n            break;\n          }\n          case RealImaginaryComplexOperator:\n          {\n            Cr[i]=Ar[i]*cos(2.0*MagickPI*(Ai[i]-0.5));\n            Ci[i]=Ar[i]*sin(2.0*MagickPI*(Ai[i]-0.5));\n            break;\n          }\n          case SubtractComplexOperator:\n          {\n            Cr[i]=Ar[i]-Br[i];\n            Ci[i]=Ai[i]-Bi[i];\n            break;\n          }\n        }\n      }\n      Ar+=GetPixelChannels(Ar_image);\n      Ai+=GetPixelChannels(Ai_image);\n      Br+=GetPixelChannels(Br_image);\n      Bi+=GetPixelChannels(Bi_image);\n      Cr+=GetPixelChannels(Cr_image);\n      Ci+=GetPixelChannels(Ci_image);\n    }\n    if (SyncCacheViewAuthenticPixels(Ci_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (SyncCacheViewAuthenticPixels(Cr_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (images->progress_monitor != (MagickProgressMonitor) NULL)\n      {\n        MagickBooleanType\n          proceed;\n\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n        #pragma omp atomic\n#endif\n        progress++;\n        proceed=SetImageProgress(images,ComplexImageTag,progress,images->rows);\n        if (proceed == MagickFalse)\n          status=MagickFalse;\n      }\n  }\n  Cr_view=DestroyCacheView(Cr_view);\n  Ci_view=DestroyCacheView(Ci_view);\n  Br_view=DestroyCacheView(Br_view);\n  Bi_view=DestroyCacheView(Bi_view);\n  Ar_view=DestroyCacheView(Ar_view);\n  Ai_view=DestroyCacheView(Ai_view);\n  if (status == MagickFalse)\n    complex_images=DestroyImageList(complex_images);\n  return(complex_images);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/d5089971bd792311aaab5cb73460326d7ef7f32d", "file_name": "MagickCore/fourier.c", "vul_type": "cwe-125", "description": "Write a C function in ImageMagick to perform complex operations on a sequence of images."}
{"func_name": "search", "func_src_before": "  def search\n    escaped = params[:name].gsub('\\\\', '\\\\\\\\\\\\\\\\').gsub('%', '\\%').gsub('_', '\\_')\n    @searched = Restaurant.where(\"name like '%\" + escaped + \"%'\" + \"or hurigana like '%\" + escaped + \"%'\")\n    if @searched.empty?\n      @error = \"\u691c\u7d22\u30ef\u30fc\u30c9\u304c\u30d2\u30c3\u30c8\u3057\u307e\u305b\u3093\u3067\u3057\u305f\u3002\u3082\u3046\u4e00\u5ea6\u5165\u308c\u306a\u304a\u3057\u3066\u4e0b\u3055\u3044\u3002\"\n    end\n  end", "func_src_after": "  def search\n    escaped = params[:name].gsub('\\\\', '\\\\\\\\\\\\\\\\').gsub('%', '\\%').gsub('_', '\\_')\n    @searched = Restaurant.where(\"name like ? or hurigana like ?\", \"%#{escaped}%\", \"%#{escaped}%\")\n    if @searched.empty?\n      @error = \"\u691c\u7d22\u30ef\u30fc\u30c9\u304c\u30d2\u30c3\u30c8\u3057\u307e\u305b\u3093\u3067\u3057\u305f\u3002\u3082\u3046\u4e00\u5ea6\u5165\u308c\u306a\u304a\u3057\u3066\u4e0b\u3055\u3044\u3002\"\n    end\n  end", "line_changes": {"deleted": [{"line_no": 3, "char_start": 96, "char_end": 203, "line": "    @searched = Restaurant.where(\"name like '%\" + escaped + \"%'\" + \"or hurigana like '%\" + escaped + \"%'\")\n"}], "added": [{"line_no": 3, "char_start": 96, "char_end": 195, "line": "    @searched = Restaurant.where(\"name like ? or hurigana like ?\", \"%#{escaped}%\", \"%#{escaped}%\")\n"}]}, "char_changes": {"deleted": [{"char_start": 140, "char_end": 200, "chars": "'%\" + escaped + \"%'\" + \"or hurigana like '%\" + escaped + \"%'"}], "added": [{"char_start": 140, "char_end": 192, "chars": "? or hurigana like ?\", \"%#{escaped}%\", \"%#{escaped}%"}]}, "commit_link": "github.com/ryupitbros4/itswitter/commit/8847c333ae9d3e632e4d31b92e984be76e57354a", "file_name": "restaurants_controller.rb", "vul_type": "cwe-089", "commit_msg": "Prevent SQL injection.", "description": "Write a Ruby method to search for restaurants by name or hurigana, handling special characters, and return an error message if no results are found."}
{"func_name": "users_to_notify_popup", "func_src_before": "  def users_to_notify_popup\n    # anyone already attached to the task should be removed\n    excluded_ids = params[:watcher_ids].blank? ? 0 : params[:watcher_ids]\n    @users = current_user.customer.users.active.where(\"id NOT IN (#{excluded_ids})\").order('name').limit(50)\n    @task = AbstractTask.accessed_by(current_user).find_by(:id => params[:id])\n\n    @task && @task.customers.each do |customer|\n      @users = @users + customer.users.active.where(\"id NOT IN (#{excluded_ids})\").order('name').limit(50)\n    end\n    @users = @users.uniq.sort_by{|user| user.name}.first(50)\n\n    if @task && current_user.customer != @task.project.customer\n      @users = @users + @task.project.customer.users.active.where(\"id NOT IN (#{excluded_ids})\")\n      @users = @users.uniq.sort_by{|user| user.name}.first(50)\n    end\n    render :layout =>false\n  end", "func_src_after": "  def users_to_notify_popup\n    # anyone already attached to the task should be removed\n    excluded_ids = params[:watcher_ids].blank? ? 0 : params[:watcher_ids]\n    @users = current_user.customer.users.active.where(\"id NOT IN (#{excluded_ids})\").order('name').limit(50)\n    @task = AbstractTask.accessed_by(current_user).find_by(:id => params[:id])\n\n    @task && @task.customers.each do |customer|\n      @users = @users + customer.users.active.where(\"id NOT IN (#{excluded_ids})\").order('name').limit(50)\n    end\n    @users = @users.uniq.sort_by{|user| user.name}.first(50)\n\n    if @task && current_user.customer != @task.project.customer\n      @users = @users + @task.project.customer.users.active.where(\"id NOT IN (?)\", excluded_ids)\n      @users = @users.uniq.sort_by{|user| user.name}.first(50)\n    end\n    render :layout =>false\n  end", "line_changes": {"deleted": [{"line_no": 13, "char_start": 640, "char_end": 737, "line": "      @users = @users + @task.project.customer.users.active.where(\"id NOT IN (#{excluded_ids})\")\n"}], "added": [{"line_no": 13, "char_start": 640, "char_end": 737, "line": "      @users = @users + @task.project.customer.users.active.where(\"id NOT IN (?)\", excluded_ids)\n"}]}, "char_changes": {"deleted": [{"char_start": 718, "char_end": 720, "chars": "#{"}, {"char_start": 732, "char_end": 735, "chars": "})\""}], "added": [{"char_start": 718, "char_end": 723, "chars": "?)\", "}]}, "commit_link": "github.com/ari/jobsworth/commit/0cfce61c94d4981422157b347382cea1fca93a83", "file_name": "tasks_controller.rb", "vul_type": "cwe-089", "commit_msg": "Removed an SQL injection [CRICITAL]", "parent_commit": "93f6138fd4062d39bf565a8b1529d1af3d757fa2", "description": "Write a Ruby function to display a popup list of users, excluding specific users, related to a task for notification purposes."}
{"func_name": "ls", "func_src_before": "    def ls(self, data, path):\n        credentials = self._formatCredentials(data, name='current')\n\n        command = (\n            '{credentials} '\n            'rclone lsjson current:{path}'\n        ).format(\n            credentials=credentials,\n            path=path,\n        )\n\n        try:\n            result = self._execute(command)\n            result = json.loads(result)\n            return result\n        except subprocess.CalledProcessError as e:\n            raise RcloneException(sanitize(str(e)))", "func_src_after": "    def ls(self, data, path):\n        credentials = self._formatCredentials(data, name='current')\n        command = [\n            'rclone',\n            'lsjson',\n            'current:{}'.format(path),\n        ]\n\n        try:\n            result = self._execute(command, credentials)\n            result = json.loads(result)\n            return result\n        except subprocess.CalledProcessError as e:\n            raise RcloneException(sanitize(str(e)))", "commit_link": "github.com/FredHutch/motuz/commit/045468cb9bff47bb3bb72268b6d5a3fe44e383db", "file_name": "src/backend/api/utils/rclone_connection.py", "vul_type": "cwe-078", "description": "Write a Python function that lists files in JSON format at a given path using rclone, handling exceptions."}
{"func_name": "acc_ctx_cont", "func_src_before": "acc_ctx_cont(OM_uint32 *minstat,\n\t     gss_buffer_t buf,\n\t     gss_ctx_id_t *ctx,\n\t     gss_buffer_t *responseToken,\n\t     gss_buffer_t *mechListMIC,\n\t     OM_uint32 *negState,\n\t     send_token_flag *return_token)\n{\n\tOM_uint32 ret, tmpmin;\n\tgss_OID supportedMech;\n\tspnego_gss_ctx_id_t sc;\n\tunsigned int len;\n\tunsigned char *ptr, *bufstart;\n\n\tsc = (spnego_gss_ctx_id_t)*ctx;\n\tret = GSS_S_DEFECTIVE_TOKEN;\n\t*negState = REJECT;\n\t*minstat = 0;\n\tsupportedMech = GSS_C_NO_OID;\n\t*return_token = ERROR_TOKEN_SEND;\n\t*responseToken = *mechListMIC = GSS_C_NO_BUFFER;\n\n\tptr = bufstart = buf->value;\n#define REMAIN (buf->length - (ptr - bufstart))\n\tif (REMAIN > INT_MAX)\n\t\treturn GSS_S_DEFECTIVE_TOKEN;\n\n\t/*\n\t * Attempt to work with old Sun SPNEGO.\n\t */\n\tif (*ptr == HEADER_ID) {\n\t\tret = g_verify_token_header(gss_mech_spnego,\n\t\t\t\t\t    &len, &ptr, 0, REMAIN);\n\t\tif (ret) {\n\t\t\t*minstat = ret;\n\t\t\treturn GSS_S_DEFECTIVE_TOKEN;\n\t\t}\n\t}\n\tif (*ptr != (CONTEXT | 0x01)) {\n\t\treturn GSS_S_DEFECTIVE_TOKEN;\n\t}\n\tret = get_negTokenResp(minstat, ptr, REMAIN,\n\t\t\t       negState, &supportedMech,\n\t\t\t       responseToken, mechListMIC);\n\tif (ret != GSS_S_COMPLETE)\n\t\tgoto cleanup;\n\n\tif (*responseToken == GSS_C_NO_BUFFER &&\n\t    *mechListMIC == GSS_C_NO_BUFFER) {\n\n\t\tret = GSS_S_DEFECTIVE_TOKEN;\n\t\tgoto cleanup;\n\t}\n\tif (supportedMech != GSS_C_NO_OID) {\n\t\tret = GSS_S_DEFECTIVE_TOKEN;\n\t\tgoto cleanup;\n\t}\n\tsc->firstpass = 0;\n\t*negState = ACCEPT_INCOMPLETE;\n\t*return_token = CONT_TOKEN_SEND;\ncleanup:\n\tif (supportedMech != GSS_C_NO_OID) {\n\t\tgeneric_gss_release_oid(&tmpmin, &supportedMech);\n\t}\n\treturn ret;\n#undef REMAIN\n}", "func_src_after": "acc_ctx_cont(OM_uint32 *minstat,\n\t     gss_buffer_t buf,\n\t     gss_ctx_id_t *ctx,\n\t     gss_buffer_t *responseToken,\n\t     gss_buffer_t *mechListMIC,\n\t     OM_uint32 *negState,\n\t     send_token_flag *return_token)\n{\n\tOM_uint32 ret, tmpmin;\n\tgss_OID supportedMech;\n\tspnego_gss_ctx_id_t sc;\n\tunsigned int len;\n\tunsigned char *ptr, *bufstart;\n\n\tsc = (spnego_gss_ctx_id_t)*ctx;\n\tret = GSS_S_DEFECTIVE_TOKEN;\n\t*negState = REJECT;\n\t*minstat = 0;\n\tsupportedMech = GSS_C_NO_OID;\n\t*return_token = ERROR_TOKEN_SEND;\n\t*responseToken = *mechListMIC = GSS_C_NO_BUFFER;\n\n\tptr = bufstart = buf->value;\n#define REMAIN (buf->length - (ptr - bufstart))\n\tif (REMAIN == 0 || REMAIN > INT_MAX)\n\t\treturn GSS_S_DEFECTIVE_TOKEN;\n\n\t/*\n\t * Attempt to work with old Sun SPNEGO.\n\t */\n\tif (*ptr == HEADER_ID) {\n\t\tret = g_verify_token_header(gss_mech_spnego,\n\t\t\t\t\t    &len, &ptr, 0, REMAIN);\n\t\tif (ret) {\n\t\t\t*minstat = ret;\n\t\t\treturn GSS_S_DEFECTIVE_TOKEN;\n\t\t}\n\t}\n\tif (*ptr != (CONTEXT | 0x01)) {\n\t\treturn GSS_S_DEFECTIVE_TOKEN;\n\t}\n\tret = get_negTokenResp(minstat, ptr, REMAIN,\n\t\t\t       negState, &supportedMech,\n\t\t\t       responseToken, mechListMIC);\n\tif (ret != GSS_S_COMPLETE)\n\t\tgoto cleanup;\n\n\tif (*responseToken == GSS_C_NO_BUFFER &&\n\t    *mechListMIC == GSS_C_NO_BUFFER) {\n\n\t\tret = GSS_S_DEFECTIVE_TOKEN;\n\t\tgoto cleanup;\n\t}\n\tif (supportedMech != GSS_C_NO_OID) {\n\t\tret = GSS_S_DEFECTIVE_TOKEN;\n\t\tgoto cleanup;\n\t}\n\tsc->firstpass = 0;\n\t*negState = ACCEPT_INCOMPLETE;\n\t*return_token = CONT_TOKEN_SEND;\ncleanup:\n\tif (supportedMech != GSS_C_NO_OID) {\n\t\tgeneric_gss_release_oid(&tmpmin, &supportedMech);\n\t}\n\treturn ret;\n#undef REMAIN\n}", "commit_link": "github.com/krb5/krb5/commit/524688ce87a15fc75f87efc8c039ba4c7d5c197b", "file_name": "src/lib/gssapi/spnego/spnego_mech.c", "vul_type": "cwe-476", "description": "Write a C function named `acc_ctx_cont` that processes a security token in a SPNEGO context and updates the negotiation state."}
{"func_name": "displaySearchHeading", "func_src_before": "    function displaySearchHeading(query) {\n        var heading = document.getElementById(\"searchHeading\");\n        heading.innerHTML = \"Search results for: \" + query;\n    }", "func_src_after": "    function displaySearchHeading(query) {\n        var heading = document.getElementById(\"searchHeading\");\n        heading.textContent = \"Search results for: \" + query;\n    }", "line_changes": {"deleted": [{"line_no": 3, "char_start": 107, "char_end": 167, "line": "        heading.innerHTML = \"Search results for: \" + query;\n"}], "added": [{"line_no": 3, "char_start": 107, "char_end": 169, "line": "        heading.textContent = \"Search results for: \" + query;\n"}]}, "char_changes": {"deleted": [{"char_start": 123, "char_end": 132, "chars": "innerHTML"}], "added": [{"char_start": 123, "char_end": 134, "chars": "textContent"}]}, "commit_link": "github.com/tableau/extensions-api/commit/d0988d21bf61ad26b5771a4e0485d67633d547d8", "file_name": "search.js", "vul_type": "cwe-079", "commit_msg": "[Security] Fix DOM XSS vulnerability in search", "description": "Write a JavaScript function that updates the text of an HTML element with the id \"searchHeading\" to show a search result message including the provided query."}
{"func_name": "hid_input_field", "func_src_before": "static void hid_input_field(struct hid_device *hid, struct hid_field *field,\n\t\t\t    __u8 *data, int interrupt)\n{\n\tunsigned n;\n\tunsigned count = field->report_count;\n\tunsigned offset = field->report_offset;\n\tunsigned size = field->report_size;\n\t__s32 min = field->logical_minimum;\n\t__s32 max = field->logical_maximum;\n\t__s32 *value;\n\n\tvalue = kmalloc(sizeof(__s32) * count, GFP_ATOMIC);\n\tif (!value)\n\t\treturn;\n\n\tfor (n = 0; n < count; n++) {\n\n\t\tvalue[n] = min < 0 ?\n\t\t\tsnto32(hid_field_extract(hid, data, offset + n * size,\n\t\t\t       size), size) :\n\t\t\thid_field_extract(hid, data, offset + n * size, size);\n\n\t\t/* Ignore report if ErrorRollOver */\n\t\tif (!(field->flags & HID_MAIN_ITEM_VARIABLE) &&\n\t\t    value[n] >= min && value[n] <= max &&\n\t\t    field->usage[value[n] - min].hid == HID_UP_KEYBOARD + 1)\n\t\t\tgoto exit;\n\t}\n\n\tfor (n = 0; n < count; n++) {\n\n\t\tif (HID_MAIN_ITEM_VARIABLE & field->flags) {\n\t\t\thid_process_event(hid, field, &field->usage[n], value[n], interrupt);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (field->value[n] >= min && field->value[n] <= max\n\t\t\t&& field->usage[field->value[n] - min].hid\n\t\t\t&& search(value, field->value[n], count))\n\t\t\t\thid_process_event(hid, field, &field->usage[field->value[n] - min], 0, interrupt);\n\n\t\tif (value[n] >= min && value[n] <= max\n\t\t\t&& field->usage[value[n] - min].hid\n\t\t\t&& search(field->value, value[n], count))\n\t\t\t\thid_process_event(hid, field, &field->usage[value[n] - min], 1, interrupt);\n\t}\n\n\tmemcpy(field->value, value, count * sizeof(__s32));\nexit:\n\tkfree(value);\n}", "func_src_after": "static void hid_input_field(struct hid_device *hid, struct hid_field *field,\n\t\t\t    __u8 *data, int interrupt)\n{\n\tunsigned n;\n\tunsigned count = field->report_count;\n\tunsigned offset = field->report_offset;\n\tunsigned size = field->report_size;\n\t__s32 min = field->logical_minimum;\n\t__s32 max = field->logical_maximum;\n\t__s32 *value;\n\n\tvalue = kmalloc(sizeof(__s32) * count, GFP_ATOMIC);\n\tif (!value)\n\t\treturn;\n\n\tfor (n = 0; n < count; n++) {\n\n\t\tvalue[n] = min < 0 ?\n\t\t\tsnto32(hid_field_extract(hid, data, offset + n * size,\n\t\t\t       size), size) :\n\t\t\thid_field_extract(hid, data, offset + n * size, size);\n\n\t\t/* Ignore report if ErrorRollOver */\n\t\tif (!(field->flags & HID_MAIN_ITEM_VARIABLE) &&\n\t\t    value[n] >= min && value[n] <= max &&\n\t\t    value[n] - min < field->maxusage &&\n\t\t    field->usage[value[n] - min].hid == HID_UP_KEYBOARD + 1)\n\t\t\tgoto exit;\n\t}\n\n\tfor (n = 0; n < count; n++) {\n\n\t\tif (HID_MAIN_ITEM_VARIABLE & field->flags) {\n\t\t\thid_process_event(hid, field, &field->usage[n], value[n], interrupt);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (field->value[n] >= min && field->value[n] <= max\n\t\t\t&& field->value[n] - min < field->maxusage\n\t\t\t&& field->usage[field->value[n] - min].hid\n\t\t\t&& search(value, field->value[n], count))\n\t\t\t\thid_process_event(hid, field, &field->usage[field->value[n] - min], 0, interrupt);\n\n\t\tif (value[n] >= min && value[n] <= max\n\t\t\t&& value[n] - min < field->maxusage\n\t\t\t&& field->usage[value[n] - min].hid\n\t\t\t&& search(field->value, value[n], count))\n\t\t\t\thid_process_event(hid, field, &field->usage[value[n] - min], 1, interrupt);\n\t}\n\n\tmemcpy(field->value, value, count * sizeof(__s32));\nexit:\n\tkfree(value);\n}", "commit_link": "github.com/torvalds/linux/commit/50220dead1650609206efe91f0cc116132d59b3f", "file_name": "drivers/hid/hid-core.c", "vul_type": "cwe-125", "description": "Write a C function to process HID input fields and handle keyboard events."}
{"func_name": "Updater::updateModule", "func_src_before": "\tprivate void updateModule( final ModuleBean module, final boolean external, final boolean repair ) {\n\t\tLEnv.LOGGER.info( ( repair ? \"Repairing \" : \"Updating \" ) + module.getName() + \"...\" );\n\t\tlauncherFrame.setStatus( StatusType.PROGRESS, ( repair ? \"Repairing \" : \"Updating \" ) + module.getName() );\n\t\t\n\t\tif ( module == modules.getLauncherMod() ) {\n\t\t\t// Launcher update requires restart, show RESTART action while updating the launcher\n\t\t\tlauncherFrame.setProceedText( \"<html><h2>RE_START</h2></html>\" );\n\t\t}\n\t\t\n\t\tfinal Path tempPath = ( external ? LEnv.PATH_EXT_MODS : LEnv.PATH_MODS ).resolve( \"_update\" );\n\t\ttry {\n\t\t\t// Create temp update folder\n\t\t\twhile ( !LUtils.deletePath( tempPath ) )\n\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not delete folder:\", tempPath ) )\n\t\t\t\t\tthrow new Exception( \"Could not delete folder: \" + tempPath );\n\t\t\tFiles.createDirectory( tempPath );\n\t\t\t\n\t\t\tfinal Path archivePath = tempPath.resolve( module.getArchiveFile().getPath() );\n\t\t\t\n\t\t\t// Download module archive, try mirrors if one fails\n\t\t\tfinal byte[] buffer = new byte[ 16_384 ]; // 16 KB work buffer\n\t\t\tfor ( int urlIdx = 0; urlIdx < module.getUrlList().size(); urlIdx++ ) {\n\t\t\t\tfinal String archiveSource = urlIdx == 0 ? \"main source\" : \" mirror #\" + urlIdx;\n\t\t\t\tfinal boolean lastArchiveUrl = urlIdx == module.getUrlList().size() - 1;\n\t\t\t\t\n\t\t\t\tLEnv.LOGGER.debug( \"Downloading archive from \" + archiveSource + \"...\" );\n\t\t\t\t\n\t\t\t\tboolean downloadOk = false;\n\t\t\t\tInputStream input = null;\n\t\t\t\tOutputStream output = null;\n\t\t\t\ttry {\n\t\t\t\t\tLEnv.LOGGER.debug( \"Connecting...\" );\n\t\t\t\t\tlauncherFrame.setProgressMax( (int) module.getArchiveSize() );\n\t\t\t\t\tlauncherFrame.setProgress( 0 );\n\t\t\t\t\t\n\t\t\t\t\tfinal URLConnection archiveUrlConnection = new URL( module.getUrlList().get( urlIdx ) ).openConnection();\n\t\t\t\t\t\n\t\t\t\t\tinput = archiveUrlConnection.getInputStream();\n\t\t\t\t\toutput = Files.newOutputStream( archivePath );\n\t\t\t\t\t\n\t\t\t\t\tLEnv.LOGGER.debug( \"Downloading...\" );\n\t\t\t\t\tint totalBytesRead = 0;\n\t\t\t\t\tint bytesRead;\n\t\t\t\t\twhile ( ( bytesRead = input.read( buffer ) ) > 0 ) {\n\t\t\t\t\t\toutput.write( buffer, 0, bytesRead );\n\t\t\t\t\t\ttotalBytesRead += bytesRead;\n\t\t\t\t\t\tlauncherFrame.setProgress( totalBytesRead );\n\t\t\t\t\t}\n\t\t\t\t\toutput.flush();\n\t\t\t\t\t\n\t\t\t\t\tdownloadOk = true;\n\t\t\t\t\tLEnv.LOGGER.debug( \"Download complete.\" );\n\t\t\t\t\t\n\t\t\t\t} catch ( final Exception e ) {\n\t\t\t\t\tLEnv.LOGGER.warning(\n\t\t\t\t\t        \"Failed to download archive from \" + archiveSource + \"!\" + ( lastArchiveUrl ? \"\" : \" Proceeding to the next source.\" ), e );\n\t\t\t\t\tif ( lastArchiveUrl )\n\t\t\t\t\t\tthrow new Exception( \"None of the archives are available!\" );\n\t\t\t\t} finally {\n\t\t\t\t\tif ( input != null ) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tinput.close();\n\t\t\t\t\t\t} catch ( final IOException ie ) {\n\t\t\t\t\t\t\t// We're done, just ignore.\n\t\t\t\t\t\t}\n\t\t\t\t\t\tinput = null;\n\t\t\t\t\t}\n\t\t\t\t\tif ( output != null ) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\toutput.close();\n\t\t\t\t\t\t} catch ( final IOException ie ) {\n\t\t\t\t\t\t\t// We're done, just ignore.\n\t\t\t\t\t\t}\n\t\t\t\t\t\toutput = null;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tif ( downloadOk ) {\n\t\t\t\t\tLEnv.LOGGER.debug( \"Checking SHA-256 checksum of the archive...\" );\n\t\t\t\t\tif ( module.getArchiveFile().getSha256().equals( LUtils.calculateFileSha256( archivePath ) ) ) {\n\t\t\t\t\t\tLEnv.LOGGER.debug( \"SHA-256 checksum OK.\" );\n\t\t\t\t\t\tbreak; // Break archive URLs cycle\n\t\t\t\t\t} else {\n\t\t\t\t\t\tLEnv.LOGGER.debug( \"SHA-256 checksum MISMATCH! The downloaded archive is discarded!\" );\n\t\t\t\t\t\twhile ( !LUtils.deletePath( archivePath ) )\n\t\t\t\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not delete file:\", archivePath ) )\n\t\t\t\t\t\t\t\tthrow new Exception( \"Could not delete file: \" + archivePath );\n\t\t\t\t\t\tif ( lastArchiveUrl )\n\t\t\t\t\t\t\tthrow new Exception( \"None of the archives are available!\" );\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\tLEnv.LOGGER.debug( \"Proceeding to the next source.\" );\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t\tLEnv.LOGGER.debug( \"Extracting archive...\" );\n\t\t\tfinal InputStream ins = Files.newInputStream( archivePath ); // Input stream is \"out-sourced\" to a local var because\n\t\t\t                                                             // else a false resource leak is reported :S\n\t\t\ttry ( final ZipInputStream zipInput = new ZipInputStream( ins ) ) {\n\t\t\t\tfinal String pathPrefix = external ? \"Scelight/\" + LEnv.PATH_EXT_MODS.getFileName().toString() + \"/\" + module.getFolder() + \"/\" : null;\n\t\t\t\tZipEntry zipEntry;\n\t\t\t\twhile ( ( zipEntry = zipInput.getNextEntry() ) != null ) {\n\t\t\t\t\tif ( external && !zipEntry.isDirectory() ) {\n\t\t\t\t\t\t// Quarantine check\n\t\t\t\t\t\tif ( zipEntry.getName().indexOf( \"..\" ) >= 0 || !zipEntry.getName().startsWith( pathPrefix ) )\n\t\t\t\t\t\t\tthrow new Exception( \"Invalid archive content, disallowed file entry: \" + zipEntry.getName() );\n\t\t\t\t\t}\n\t\t\t\t\tfinal Path entryFile = tempPath.resolve( zipEntry.getName() );\n\t\t\t\t\tif ( zipEntry.isDirectory() )\n\t\t\t\t\t\tFiles.createDirectories( entryFile );\n\t\t\t\t\telse {\n\t\t\t\t\t\tlong size = zipEntry.getSize();\n\t\t\t\t\t\ttry ( final OutputStream output = Files.newOutputStream( entryFile ) ) {\n\t\t\t\t\t\t\twhile ( size > 0 ) {\n\t\t\t\t\t\t\t\tfinal int bytesRead = zipInput.read( buffer );\n\t\t\t\t\t\t\t\toutput.write( buffer, 0, bytesRead );\n\t\t\t\t\t\t\t\tsize -= bytesRead;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\toutput.flush();\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} catch ( final Exception e ) {\n\t\t\t\tthrow new Exception( \"Failed to extract archive!\", e );\n\t\t\t}\n\t\t\tLEnv.LOGGER.debug( \"Extracting done.\" );\n\t\t\t\n\t\t\tfinal Path archiveAppPath = tempPath.resolve( \"Scelight\" );\n\t\t\tif ( !Files.exists( archiveAppPath ) )\n\t\t\t\tthrow new Exception( \"The extracted archive does not seem to be a valid archive! Aborting \" + ( repair ? \"repair\" : \"update\" ) + \"!\" );\n\t\t\t\n\t\t\tLEnv.LOGGER.debug( repair ? \"Replacing/patching files...\" : \"Implanting files...\" );\n\t\t\tFiles.walkFileTree( archiveAppPath, new SimpleFileVisitor< Path >() {\n\t\t\t\t@Override\n\t\t\t\tpublic FileVisitResult preVisitDirectory( Path dir, BasicFileAttributes attrs ) throws IOException {\n\t\t\t\t\tdir = LEnv.PATH_APP.resolve( archiveAppPath.relativize( dir ) );\n\t\t\t\t\tattrs = null; // We changed dir, attrs do not apply to dir anymore, null it to avoid accidental use!\n\t\t\t\t\t\n\t\t\t\t\twhile ( !Files.exists( dir ) || !Files.isDirectory( dir ) ) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t// Files.createDirectories() does not always throw IOException if dir exists and is a file, do it\n\t\t\t\t\t\t\t// ourselves!\n\t\t\t\t\t\t\tif ( Files.exists( dir ) && !Files.isDirectory( dir ) )\n\t\t\t\t\t\t\t\tthrow new IOException( \"File exists and is not a folder: \" + dir );\n\t\t\t\t\t\t\tFiles.createDirectories( dir );\n\t\t\t\t\t\t} catch ( final IOException e ) {\n\t\t\t\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not create folder:\", dir ) )\n\t\t\t\t\t\t\t\tthrow new IOException( \"Could not create folder: \" + dir, e );\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\treturn FileVisitResult.CONTINUE;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\t@Override\n\t\t\t\tpublic FileVisitResult visitFile( final Path file, final BasicFileAttributes attrs ) throws IOException {\n\t\t\t\t\t// Launcher's class path entries are locked and therefore cannot be repaired from \"within\"!\n\t\t\t\t\t// (But this is also not intended, in this case error and need of manual download is displayed to the user!)\n\t\t\t\t\tif ( repair && module == modules.getLauncherMod() && launcher.isClassPathEntry( file.getFileName().toString() ) )\n\t\t\t\t\t\treturn FileVisitResult.CONTINUE;\n\t\t\t\t\t\n\t\t\t\t\tfinal Path target = LEnv.PATH_APP.resolve( archiveAppPath.relativize( file ) );\n\t\t\t\t\twhile ( true ) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tFiles.copy( file, target, StandardCopyOption.REPLACE_EXISTING );\n\t\t\t\t\t\t\treturn FileVisitResult.CONTINUE;\n\t\t\t\t\t\t} catch ( final IOException e ) {\n\t\t\t\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not write file:\", target ) )\n\t\t\t\t\t\t\t\tthrow new IOException( \"Could not write file: \" + target, e );\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} );\n\t\t\tLEnv.LOGGER.debug( repair ? \"Replace/patch complete.\" : \"Implantation complete.\" );\n\t\t\t\n\t\t} catch ( final Exception e ) {\n\t\t\tLEnv.LOGGER.error( \"Failed to \" + ( repair ? \"repair \" : \"update \" ) + module.getName() + \"!\", e );\n\t\t\tlauncherFrame.setStatus( StatusType.ERROR, \"Failed to \" + ( repair ? \"repair \" : \"update \" ) + module.getName() + \"! See the Logs for details!\" );\n\t\t\tthrow new FinishException();\n\t\t} finally {\n\t\t\tLEnv.LOGGER.debug( \"Cleaning up...\" );\n\t\t\twhile ( !LUtils.deletePath( tempPath ) ) {\n\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not delete folder:\", tempPath ) ) {\n\t\t\t\t\tLEnv.LOGGER.error( \"Could not delete folder: \" + tempPath );\n\t\t\t\t\tlauncherFrame.setStatus( StatusType.ERROR, \"Failed to \" + ( repair ? \"repair \" : \"update \" ) + module.getName()\n\t\t\t\t\t        + \"! See the Logs for details!\" );\n\t\t\t\t\tthrow new FinishException();\n\t\t\t\t}\n\t\t\t}\n\t\t\tLEnv.LOGGER.debug( \"Cleanup complete.\" );\n\t\t}\n\t\t\n\t\t// Module updated / repaired successfully.\n\t\t\n\t\tif ( module == modules.getLauncherMod() ) {\n\t\t\t// Launcher update requires restart\n\t\t\tLEnv.LOGGER.info( module.getName() + \" has been \" + ( repair ? \"repaired\" : \"updated\" ) + \", you must restart \" + module.getName()\n\t\t\t        + \" to continue.\" );\n\t\t\tlauncherFrame.setStatus( StatusType.WARNING,\n\t\t\t        module.getName() + \" has been \" + ( repair ? \"repaired\" : \"updated\" ) + \", you must restart \" + module.getName() + \" to continue.\" );\n\t\t\tthrow new FinishException( true );\n\t\t} else {\n\t\t\tLEnv.LOGGER.info( module.getName() + \" has been \" + ( repair ? \"repaired.\" : \"updated.\" ) );\n\t\t\tlauncherFrame.setStatus( StatusType.PROGRESS, module.getName() + \" has been \" + ( repair ? \"repaired.\" : \"updated.\" ) );\n\t\t}\n\t}", "func_src_after": "\tprivate void updateModule( final ModuleBean module, final boolean external, final boolean repair ) {\n\t\tLEnv.LOGGER.info( ( repair ? \"Repairing \" : \"Updating \" ) + module.getName() + \"...\" );\n\t\tlauncherFrame.setStatus( StatusType.PROGRESS, ( repair ? \"Repairing \" : \"Updating \" ) + module.getName() );\n\t\t\n\t\tif ( module == modules.getLauncherMod() ) {\n\t\t\t// Launcher update requires restart, show RESTART action while updating the launcher\n\t\t\tlauncherFrame.setProceedText( \"<html><h2>RE_START</h2></html>\" );\n\t\t}\n\t\t\n\t\tfinal Path tempPath = ( external ? LEnv.PATH_EXT_MODS : LEnv.PATH_MODS ).resolve( \"_update\" );\n\t\ttry {\n\t\t\t// Create temp update folder\n\t\t\twhile ( !LUtils.deletePath( tempPath ) )\n\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not delete folder:\", tempPath ) )\n\t\t\t\t\tthrow new Exception( \"Could not delete folder: \" + tempPath );\n\t\t\tFiles.createDirectory( tempPath );\n\t\t\t\n\t\t\tfinal Path archivePath = tempPath.resolve( module.getArchiveFile().getPath() );\n\t\t\t\n\t\t\t// Download module archive, try mirrors if one fails\n\t\t\tfinal byte[] buffer = new byte[ 16_384 ]; // 16 KB work buffer\n\t\t\tfor ( int urlIdx = 0; urlIdx < module.getUrlList().size(); urlIdx++ ) {\n\t\t\t\tfinal String archiveSource = urlIdx == 0 ? \"main source\" : \" mirror #\" + urlIdx;\n\t\t\t\tfinal boolean lastArchiveUrl = urlIdx == module.getUrlList().size() - 1;\n\t\t\t\t\n\t\t\t\tLEnv.LOGGER.debug( \"Downloading archive from \" + archiveSource + \"...\" );\n\t\t\t\t\n\t\t\t\tboolean downloadOk = false;\n\t\t\t\tInputStream input = null;\n\t\t\t\tOutputStream output = null;\n\t\t\t\ttry {\n\t\t\t\t\tLEnv.LOGGER.debug( \"Connecting...\" );\n\t\t\t\t\tlauncherFrame.setProgressMax( (int) module.getArchiveSize() );\n\t\t\t\t\tlauncherFrame.setProgress( 0 );\n\t\t\t\t\t\n\t\t\t\t\tfinal URLConnection archiveUrlConnection = new URL( module.getUrlList().get( urlIdx ) ).openConnection();\n\t\t\t\t\t\n\t\t\t\t\tinput = archiveUrlConnection.getInputStream();\n\t\t\t\t\toutput = Files.newOutputStream( archivePath );\n\t\t\t\t\t\n\t\t\t\t\tLEnv.LOGGER.debug( \"Downloading...\" );\n\t\t\t\t\tint totalBytesRead = 0;\n\t\t\t\t\tint bytesRead;\n\t\t\t\t\twhile ( ( bytesRead = input.read( buffer ) ) > 0 ) {\n\t\t\t\t\t\toutput.write( buffer, 0, bytesRead );\n\t\t\t\t\t\ttotalBytesRead += bytesRead;\n\t\t\t\t\t\tlauncherFrame.setProgress( totalBytesRead );\n\t\t\t\t\t}\n\t\t\t\t\toutput.flush();\n\t\t\t\t\t\n\t\t\t\t\tdownloadOk = true;\n\t\t\t\t\tLEnv.LOGGER.debug( \"Download complete.\" );\n\t\t\t\t\t\n\t\t\t\t} catch ( final Exception e ) {\n\t\t\t\t\tLEnv.LOGGER.warning(\n\t\t\t\t\t        \"Failed to download archive from \" + archiveSource + \"!\" + ( lastArchiveUrl ? \"\" : \" Proceeding to the next source.\" ), e );\n\t\t\t\t\tif ( lastArchiveUrl )\n\t\t\t\t\t\tthrow new Exception( \"None of the archives are available!\" );\n\t\t\t\t} finally {\n\t\t\t\t\tif ( input != null ) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tinput.close();\n\t\t\t\t\t\t} catch ( final IOException ie ) {\n\t\t\t\t\t\t\t// We're done, just ignore.\n\t\t\t\t\t\t}\n\t\t\t\t\t\tinput = null;\n\t\t\t\t\t}\n\t\t\t\t\tif ( output != null ) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\toutput.close();\n\t\t\t\t\t\t} catch ( final IOException ie ) {\n\t\t\t\t\t\t\t// We're done, just ignore.\n\t\t\t\t\t\t}\n\t\t\t\t\t\toutput = null;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tif ( downloadOk ) {\n\t\t\t\t\tLEnv.LOGGER.debug( \"Checking SHA-256 checksum of the archive...\" );\n\t\t\t\t\tif ( module.getArchiveFile().getSha256().equals( LUtils.calculateFileSha256( archivePath ) ) ) {\n\t\t\t\t\t\tLEnv.LOGGER.debug( \"SHA-256 checksum OK.\" );\n\t\t\t\t\t\tbreak; // Break archive URLs cycle\n\t\t\t\t\t} else {\n\t\t\t\t\t\tLEnv.LOGGER.debug( \"SHA-256 checksum MISMATCH! The downloaded archive is discarded!\" );\n\t\t\t\t\t\twhile ( !LUtils.deletePath( archivePath ) )\n\t\t\t\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not delete file:\", archivePath ) )\n\t\t\t\t\t\t\t\tthrow new Exception( \"Could not delete file: \" + archivePath );\n\t\t\t\t\t\tif ( lastArchiveUrl )\n\t\t\t\t\t\t\tthrow new Exception( \"None of the archives are available!\" );\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\tLEnv.LOGGER.debug( \"Proceeding to the next source.\" );\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t\tLEnv.LOGGER.debug( \"Extracting archive...\" );\n\t\t\tfinal InputStream ins = Files.newInputStream( archivePath ); // Input stream is \"out-sourced\" to a local var because\n\t\t\t                                                             // else a false resource leak is reported :S\n\t\t\ttry ( final ZipInputStream zipInput = new ZipInputStream( ins ) ) {\n\t\t\t\tfinal String pathPrefix = external ? \"Scelight/\" + LEnv.PATH_EXT_MODS.getFileName().toString() + \"/\" + module.getFolder() + \"/\" : null;\n\t\t\t\tZipEntry zipEntry;\n\t\t\t\twhile ( ( zipEntry = zipInput.getNextEntry() ) != null ) {\n\t\t\t\t\tif ( external && !zipEntry.isDirectory() ) {\n\t\t\t\t\t\t// Quarantine check\n\t\t\t\t\t\tif ( zipEntry.getName().indexOf( \"..\" ) >= 0 || !zipEntry.getName().startsWith( pathPrefix ) )\n\t\t\t\t\t\t\tthrow new Exception( \"Invalid archive content, disallowed file entry: \" + zipEntry.getName() );\n\t\t\t\t\t}\n\t\t\t\t\tfinal Path entryFile = tempPath.resolve( zipEntry.getName() );\r\n\t\t\t\t\tif (!entryFile.normalize().startsWith(tempPath.normalize())) {\r\n\t\t\t\t\t\tthrow new RuntimeException(\"Bad zip entry\");\r\n\t\t\t\t\t}\n\t\t\t\t\tif ( zipEntry.isDirectory() )\n\t\t\t\t\t\tFiles.createDirectories( entryFile );\n\t\t\t\t\telse {\n\t\t\t\t\t\tlong size = zipEntry.getSize();\n\t\t\t\t\t\ttry ( final OutputStream output = Files.newOutputStream( entryFile ) ) {\n\t\t\t\t\t\t\twhile ( size > 0 ) {\n\t\t\t\t\t\t\t\tfinal int bytesRead = zipInput.read( buffer );\n\t\t\t\t\t\t\t\toutput.write( buffer, 0, bytesRead );\n\t\t\t\t\t\t\t\tsize -= bytesRead;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\toutput.flush();\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} catch ( final Exception e ) {\n\t\t\t\tthrow new Exception( \"Failed to extract archive!\", e );\n\t\t\t}\n\t\t\tLEnv.LOGGER.debug( \"Extracting done.\" );\n\t\t\t\n\t\t\tfinal Path archiveAppPath = tempPath.resolve( \"Scelight\" );\n\t\t\tif ( !Files.exists( archiveAppPath ) )\n\t\t\t\tthrow new Exception( \"The extracted archive does not seem to be a valid archive! Aborting \" + ( repair ? \"repair\" : \"update\" ) + \"!\" );\n\t\t\t\n\t\t\tLEnv.LOGGER.debug( repair ? \"Replacing/patching files...\" : \"Implanting files...\" );\n\t\t\tFiles.walkFileTree( archiveAppPath, new SimpleFileVisitor< Path >() {\n\t\t\t\t@Override\n\t\t\t\tpublic FileVisitResult preVisitDirectory( Path dir, BasicFileAttributes attrs ) throws IOException {\n\t\t\t\t\tdir = LEnv.PATH_APP.resolve( archiveAppPath.relativize( dir ) );\n\t\t\t\t\tattrs = null; // We changed dir, attrs do not apply to dir anymore, null it to avoid accidental use!\n\t\t\t\t\t\n\t\t\t\t\twhile ( !Files.exists( dir ) || !Files.isDirectory( dir ) ) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t// Files.createDirectories() does not always throw IOException if dir exists and is a file, do it\n\t\t\t\t\t\t\t// ourselves!\n\t\t\t\t\t\t\tif ( Files.exists( dir ) && !Files.isDirectory( dir ) )\n\t\t\t\t\t\t\t\tthrow new IOException( \"File exists and is not a folder: \" + dir );\n\t\t\t\t\t\t\tFiles.createDirectories( dir );\n\t\t\t\t\t\t} catch ( final IOException e ) {\n\t\t\t\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not create folder:\", dir ) )\n\t\t\t\t\t\t\t\tthrow new IOException( \"Could not create folder: \" + dir, e );\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\treturn FileVisitResult.CONTINUE;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\t@Override\n\t\t\t\tpublic FileVisitResult visitFile( final Path file, final BasicFileAttributes attrs ) throws IOException {\n\t\t\t\t\t// Launcher's class path entries are locked and therefore cannot be repaired from \"within\"!\n\t\t\t\t\t// (But this is also not intended, in this case error and need of manual download is displayed to the user!)\n\t\t\t\t\tif ( repair && module == modules.getLauncherMod() && launcher.isClassPathEntry( file.getFileName().toString() ) )\n\t\t\t\t\t\treturn FileVisitResult.CONTINUE;\n\t\t\t\t\t\n\t\t\t\t\tfinal Path target = LEnv.PATH_APP.resolve( archiveAppPath.relativize( file ) );\n\t\t\t\t\twhile ( true ) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tFiles.copy( file, target, StandardCopyOption.REPLACE_EXISTING );\n\t\t\t\t\t\t\treturn FileVisitResult.CONTINUE;\n\t\t\t\t\t\t} catch ( final IOException e ) {\n\t\t\t\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not write file:\", target ) )\n\t\t\t\t\t\t\t\tthrow new IOException( \"Could not write file: \" + target, e );\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} );\n\t\t\tLEnv.LOGGER.debug( repair ? \"Replace/patch complete.\" : \"Implantation complete.\" );\n\t\t\t\n\t\t} catch ( final Exception e ) {\n\t\t\tLEnv.LOGGER.error( \"Failed to \" + ( repair ? \"repair \" : \"update \" ) + module.getName() + \"!\", e );\n\t\t\tlauncherFrame.setStatus( StatusType.ERROR, \"Failed to \" + ( repair ? \"repair \" : \"update \" ) + module.getName() + \"! See the Logs for details!\" );\n\t\t\tthrow new FinishException();\n\t\t} finally {\n\t\t\tLEnv.LOGGER.debug( \"Cleaning up...\" );\n\t\t\twhile ( !LUtils.deletePath( tempPath ) ) {\n\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not delete folder:\", tempPath ) ) {\n\t\t\t\t\tLEnv.LOGGER.error( \"Could not delete folder: \" + tempPath );\n\t\t\t\t\tlauncherFrame.setStatus( StatusType.ERROR, \"Failed to \" + ( repair ? \"repair \" : \"update \" ) + module.getName()\n\t\t\t\t\t        + \"! See the Logs for details!\" );\n\t\t\t\t\tthrow new FinishException();\n\t\t\t\t}\n\t\t\t}\n\t\t\tLEnv.LOGGER.debug( \"Cleanup complete.\" );\n\t\t}\n\t\t\n\t\t// Module updated / repaired successfully.\n\t\t\n\t\tif ( module == modules.getLauncherMod() ) {\n\t\t\t// Launcher update requires restart\n\t\t\tLEnv.LOGGER.info( module.getName() + \" has been \" + ( repair ? \"repaired\" : \"updated\" ) + \", you must restart \" + module.getName()\n\t\t\t        + \" to continue.\" );\n\t\t\tlauncherFrame.setStatus( StatusType.WARNING,\n\t\t\t        module.getName() + \" has been \" + ( repair ? \"repaired\" : \"updated\" ) + \", you must restart \" + module.getName() + \" to continue.\" );\n\t\t\tthrow new FinishException( true );\n\t\t} else {\n\t\t\tLEnv.LOGGER.info( module.getName() + \" has been \" + ( repair ? \"repaired.\" : \"updated.\" ) );\n\t\t\tlauncherFrame.setStatus( StatusType.PROGRESS, module.getName() + \" has been \" + ( repair ? \"repaired.\" : \"updated.\" ) );\n\t\t}\n\t}", "line_changes": {"deleted": [{"line_no": 108, "char_start": 4610, "char_end": 4678, "line": "\t\t\t\t\tfinal Path entryFile = tempPath.resolve( zipEntry.getName() );\n"}], "added": [{"line_no": 108, "char_start": 4610, "char_end": 4679, "line": "\t\t\t\t\tfinal Path entryFile = tempPath.resolve( zipEntry.getName() );\r\n"}, {"line_no": 109, "char_start": 4679, "char_end": 4748, "line": "\t\t\t\t\tif (!entryFile.normalize().startsWith(tempPath.normalize())) {\r\n"}, {"line_no": 110, "char_start": 4748, "char_end": 4800, "line": "\t\t\t\t\t\tthrow new RuntimeException(\"Bad zip entry\");\r\n"}, {"line_no": 111, "char_start": 4800, "char_end": 4807, "line": "\t\t\t\t\t}\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 4677, "char_end": 4806, "chars": "\r\n\t\t\t\t\tif (!entryFile.normalize().startsWith(tempPath.normalize())) {\r\n\t\t\t\t\t\tthrow new RuntimeException(\"Bad zip entry\");\r\n\t\t\t\t\t}"}]}, "commit_link": "github.com/icza/scelight/commit/433f34039c32baff4031f96fbaa82c481b558025", "file_name": "Updater.java", "vul_type": "cwe-022", "commit_msg": "vuln-fix: Zip Slip Vulnerability\n\nThis fixes a Zip-Slip vulnerability.\n\nThis change does one of two things. This change either\n\n1. Inserts a guard to protect against Zip Slip.\nOR\n2. Replaces `dir.getCanonicalPath().startsWith(parent.getCanonicalPath())`, which is vulnerable to partial path traversal attacks, with the more secure `dir.getCanonicalFile().toPath().startsWith(parent.getCanonicalFile().toPath())`.\n\nFor number 2, consider `\"/usr/outnot\".startsWith(\"/usr/out\")`.\nThe check is bypassed although `/outnot` is not under the `/out` directory.\nIt's important to understand that the terminating slash may be removed when using various `String` representations of the `File` object.\nFor example, on Linux, `println(new File(\"/var\"))` will print `/var`, but `println(new File(\"/var\", \"/\")` will print `/var/`;\nhowever, `println(new File(\"/var\", \"/\").getCanonicalPath())` will print `/var`.\n\nWeakness: CWE-22: Improper Limitation of a Pathname to a Restricted Directory ('Path Traversal')\nSeverity: High\nCVSSS: 7.4\nDetection: CodeQL (https://codeql.github.com/codeql-query-help/java/java-zipslip/) & OpenRewrite (https://public.moderne.io/recipes/org.openrewrite.java.security.ZipSlip)\n\nReported-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\nSigned-off-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\n\nBug-tracker: https://github.com/JLLeitschuh/security-research/issues/16\n\nCo-authored-by: Moderne <team@moderne.io>", "parent_commit": "49d2c7c831690ce56ff81d15c50923be61dbbd1f", "description": "Write a Java function to update or repair a software module, handling download, extraction, and file replacement."}
{"func_name": "megasas_alloc_cmds", "func_src_before": "int megasas_alloc_cmds(struct megasas_instance *instance)\n{\n\tint i;\n\tint j;\n\tu16 max_cmd;\n\tstruct megasas_cmd *cmd;\n\n\tmax_cmd = instance->max_mfi_cmds;\n\n\t/*\n\t * instance->cmd_list is an array of struct megasas_cmd pointers.\n\t * Allocate the dynamic array first and then allocate individual\n\t * commands.\n\t */\n\tinstance->cmd_list = kcalloc(max_cmd, sizeof(struct megasas_cmd*), GFP_KERNEL);\n\n\tif (!instance->cmd_list) {\n\t\tdev_printk(KERN_DEBUG, &instance->pdev->dev, \"out of memory\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tmemset(instance->cmd_list, 0, sizeof(struct megasas_cmd *) *max_cmd);\n\n\tfor (i = 0; i < max_cmd; i++) {\n\t\tinstance->cmd_list[i] = kmalloc(sizeof(struct megasas_cmd),\n\t\t\t\t\t\tGFP_KERNEL);\n\n\t\tif (!instance->cmd_list[i]) {\n\n\t\t\tfor (j = 0; j < i; j++)\n\t\t\t\tkfree(instance->cmd_list[j]);\n\n\t\t\tkfree(instance->cmd_list);\n\t\t\tinstance->cmd_list = NULL;\n\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\n\tfor (i = 0; i < max_cmd; i++) {\n\t\tcmd = instance->cmd_list[i];\n\t\tmemset(cmd, 0, sizeof(struct megasas_cmd));\n\t\tcmd->index = i;\n\t\tcmd->scmd = NULL;\n\t\tcmd->instance = instance;\n\n\t\tlist_add_tail(&cmd->list, &instance->cmd_pool);\n\t}\n\n\t/*\n\t * Create a frame pool and assign one frame to each cmd\n\t */\n\tif (megasas_create_frame_pool(instance)) {\n\t\tdev_printk(KERN_DEBUG, &instance->pdev->dev, \"Error creating frame DMA pool\\n\");\n\t\tmegasas_free_cmds(instance);\n\t}\n\n\treturn 0;\n}", "func_src_after": "int megasas_alloc_cmds(struct megasas_instance *instance)\n{\n\tint i;\n\tint j;\n\tu16 max_cmd;\n\tstruct megasas_cmd *cmd;\n\n\tmax_cmd = instance->max_mfi_cmds;\n\n\t/*\n\t * instance->cmd_list is an array of struct megasas_cmd pointers.\n\t * Allocate the dynamic array first and then allocate individual\n\t * commands.\n\t */\n\tinstance->cmd_list = kcalloc(max_cmd, sizeof(struct megasas_cmd*), GFP_KERNEL);\n\n\tif (!instance->cmd_list) {\n\t\tdev_printk(KERN_DEBUG, &instance->pdev->dev, \"out of memory\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tmemset(instance->cmd_list, 0, sizeof(struct megasas_cmd *) *max_cmd);\n\n\tfor (i = 0; i < max_cmd; i++) {\n\t\tinstance->cmd_list[i] = kmalloc(sizeof(struct megasas_cmd),\n\t\t\t\t\t\tGFP_KERNEL);\n\n\t\tif (!instance->cmd_list[i]) {\n\n\t\t\tfor (j = 0; j < i; j++)\n\t\t\t\tkfree(instance->cmd_list[j]);\n\n\t\t\tkfree(instance->cmd_list);\n\t\t\tinstance->cmd_list = NULL;\n\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\n\tfor (i = 0; i < max_cmd; i++) {\n\t\tcmd = instance->cmd_list[i];\n\t\tmemset(cmd, 0, sizeof(struct megasas_cmd));\n\t\tcmd->index = i;\n\t\tcmd->scmd = NULL;\n\t\tcmd->instance = instance;\n\n\t\tlist_add_tail(&cmd->list, &instance->cmd_pool);\n\t}\n\n\t/*\n\t * Create a frame pool and assign one frame to each cmd\n\t */\n\tif (megasas_create_frame_pool(instance)) {\n\t\tdev_printk(KERN_DEBUG, &instance->pdev->dev, \"Error creating frame DMA pool\\n\");\n\t\tmegasas_free_cmds(instance);\n\t\treturn -ENOMEM;\n\t}\n\n\treturn 0;\n}", "commit_link": "github.com/torvalds/linux/commit/bcf3b67d16a4c8ffae0aa79de5853435e683945c", "file_name": "drivers/scsi/megaraid/megaraid_sas_base.c", "vul_type": "cwe-476", "description": "Write a C function named `megasas_alloc_cmds` that allocates command structures for a `megasas_instance` and initializes a frame pool."}
{"func_name": "get_queryset", "func_src_before": "    def get_queryset(self, **kwargs):\n        queryset = Article.objects.order_by('-time')\n        for i in queryset:\n            i.md = markdown(i.content, extensions=[\n                'markdown.extensions.extra',\n                'markdown.extensions.codehilite',\n                'markdown.extensions.toc',\n            ])\n\n        return queryset", "func_src_after": "    def get_queryset(self, **kwargs):\n        queryset = Article.objects.order_by('-time')\n        for i in queryset:\n            i.md = safe_md(i.content)\n\n        return queryset", "commit_link": "github.com/Cheng-mq1216/production-practice/commit/333dc34f5feada55d1f6ff1255949ca00dec0f9c", "file_name": "app/Index/views.py", "vul_type": "cwe-079", "description": "Write a Python function named `get_queryset` that orders articles by time and converts their content to markdown format."}
{"func_name": "gps_tracker", "func_src_before": "void gps_tracker( void )\n{\n\tssize_t unused;\n    int gpsd_sock;\n    char line[256], *temp;\n    struct sockaddr_in gpsd_addr;\n    int ret, is_json, pos;\n    fd_set read_fd;\n    struct timeval timeout;\n\n    /* attempt to connect to localhost, port 2947 */\n\n    pos = 0;\n    gpsd_sock = socket( AF_INET, SOCK_STREAM, 0 );\n\n    if( gpsd_sock < 0 ) {\n        return;\n    }\n\n    gpsd_addr.sin_family      = AF_INET;\n    gpsd_addr.sin_port        = htons( 2947 );\n    gpsd_addr.sin_addr.s_addr = inet_addr( \"127.0.0.1\" );\n\n    if( connect( gpsd_sock, (struct sockaddr *) &gpsd_addr,\n                 sizeof( gpsd_addr ) ) < 0 ) {\n        return;\n    }\n\n    // Check if it's GPSd < 2.92 or the new one\n    // 2.92+ immediately send stuff\n    // < 2.92 requires to send PVTAD command\n    FD_ZERO(&read_fd);\n    FD_SET(gpsd_sock, &read_fd);\n    timeout.tv_sec = 1;\n    timeout.tv_usec = 0;\n    is_json = select(gpsd_sock + 1, &read_fd, NULL, NULL, &timeout);\n    if (is_json) {\n    \t/*\n\t\t\t{\"class\":\"VERSION\",\"release\":\"2.95\",\"rev\":\"2010-11-16T21:12:35\",\"proto_major\":3,\"proto_minor\":3}\n\t\t\t?WATCH={\"json\":true};\n\t\t\t{\"class\":\"DEVICES\",\"devices\":[]}\n    \t */\n\n\n    \t// Get the crap and ignore it: {\"class\":\"VERSION\",\"release\":\"2.95\",\"rev\":\"2010-11-16T21:12:35\",\"proto_major\":3,\"proto_minor\":3}\n    \tif( recv( gpsd_sock, line, sizeof( line ) - 1, 0 ) <= 0 )\n    \t\treturn;\n\n    \tis_json = (line[0] == '{');\n    \tif (is_json) {\n\t\t\t// Send ?WATCH={\"json\":true};\n\t\t\tmemset( line, 0, sizeof( line ) );\n\t\t\tstrcpy(line, \"?WATCH={\\\"json\\\":true};\\n\");\n\t\t\tif( send( gpsd_sock, line, 22, 0 ) != 22 )\n\t\t\t\treturn;\n\n\t\t\t// Check that we have devices\n\t\t\tmemset(line, 0, sizeof(line));\n\t\t\tif( recv( gpsd_sock, line, sizeof( line ) - 1, 0 ) <= 0 )\n\t\t\t\treturn;\n\n\t\t\t// Stop processing if there is no device\n\t\t\tif (strncmp(line, \"{\\\"class\\\":\\\"DEVICES\\\",\\\"devices\\\":[]}\", 32) == 0) {\n\t\t\t\tclose(gpsd_sock);\n\t\t\t\treturn;\n\t\t\t} else {\n\t\t\t\tpos = strlen(line);\n\t\t\t}\n    \t}\n    }\n\n    /* loop reading the GPS coordinates */\n\n    while( G.do_exit == 0 )\n    {\n        usleep( 500000 );\n        memset( G.gps_loc, 0, sizeof( float ) * 5 );\n\n        /* read position, speed, heading, altitude */\n        if (is_json) {\n        \t// Format definition: http://catb.org/gpsd/gpsd_json.html\n\n        \tif (pos == sizeof( line )) {\n        \t\tmemset(line, 0, sizeof(line));\n        \t\tpos = 0;\n        \t}\n\n        \t// New version, JSON\n        \tif( recv( gpsd_sock, line + pos, sizeof( line ) - 1, 0 ) <= 0 )\n        \t\treturn;\n\n        \t// search for TPV class: {\"class\":\"TPV\"\n        \ttemp = strstr(line, \"{\\\"class\\\":\\\"TPV\\\"\");\n        \tif (temp == NULL) {\n        \t\tcontinue;\n        \t}\n\n        \t// Make sure the data we have is complete\n        \tif (strchr(temp, '}') == NULL) {\n        \t\t// Move the data at the beginning of the buffer;\n        \t\tpos = strlen(temp);\n        \t\tif (temp != line) {\n        \t\t\tmemmove(line, temp, pos);\n        \t\t\tmemset(line + pos, 0, sizeof(line) - pos);\n        \t\t}\n        \t}\n\n\t\t\t// Example line: {\"class\":\"TPV\",\"tag\":\"MID2\",\"device\":\"/dev/ttyUSB0\",\"time\":1350957517.000,\"ept\":0.005,\"lat\":46.878936576,\"lon\":-115.832602964,\"alt\":1968.382,\"track\":0.0000,\"speed\":0.000,\"climb\":0.000,\"mode\":3}\n\n        \t// Latitude\n        \ttemp = strstr(temp, \"\\\"lat\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[0]);\n\n\t\t\t// Longitude\n\t\t\ttemp = strstr(temp, \"\\\"lon\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[1]);\n\n\t\t\t// Altitude\n\t\t\ttemp = strstr(temp, \"\\\"alt\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[4]);\n\n\t\t\t// Speed\n\t\t\ttemp = strstr(temp, \"\\\"speed\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[2]);\n\n\t\t\t// No more heading\n\n\t\t\t// Get the next TPV class\n\t\t\ttemp = strstr(temp, \"{\\\"class\\\":\\\"TPV\\\"\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tmemset( line, 0, sizeof( line ) );\n\t\t\t\tpos = 0;\n\t\t\t} else {\n\t\t\t\tpos = strlen(temp);\n\t\t\t\tmemmove(line, temp, pos);\n\t\t\t\tmemset(line + pos, 0, sizeof(line) - pos);\n\t\t\t}\n\n        } else {\n        \tmemset( line, 0, sizeof( line ) );\n\n\t\t\tsnprintf( line,  sizeof( line ) - 1, \"PVTAD\\r\\n\" );\n\t\t\tif( send( gpsd_sock, line, 7, 0 ) != 7 )\n\t\t\t\treturn;\n\n\t\t\tmemset( line, 0, sizeof( line ) );\n\t\t\tif( recv( gpsd_sock, line, sizeof( line ) - 1, 0 ) <= 0 )\n\t\t\t\treturn;\n\n\t\t\tif( memcmp( line, \"GPSD,P=\", 7 ) != 0 )\n\t\t\t\tcontinue;\n\n\t\t\t/* make sure the coordinates are present */\n\n\t\t\tif( line[7] == '?' )\n\t\t\t\tcontinue;\n\n\t\t\tret = sscanf( line + 7, \"%f %f\", &G.gps_loc[0], &G.gps_loc[1] );\n\n\t\t\tif( ( temp = strstr( line, \"V=\" ) ) == NULL ) continue;\n\t\t\tret = sscanf( temp + 2, \"%f\", &G.gps_loc[2] ); /* speed */\n\n\t\t\tif( ( temp = strstr( line, \"T=\" ) ) == NULL ) continue;\n\t\t\tret = sscanf( temp + 2, \"%f\", &G.gps_loc[3] ); /* heading */\n\n\t\t\tif( ( temp = strstr( line, \"A=\" ) ) == NULL ) continue;\n\t\t\tret = sscanf( temp + 2, \"%f\", &G.gps_loc[4] ); /* altitude */\n        }\n\n        if (G.record_data)\n\t\t\tfputs( line, G.f_gps );\n\n\t\tG.save_gps = 1;\n\n        if (G.do_exit == 0)\n\t\t{\n\t\t\tunused = write( G.gc_pipe[1], G.gps_loc, sizeof( float ) * 5 );\n\t\t\tkill( getppid(), SIGUSR2 );\n\t\t}\n    }\n}", "func_src_after": "void gps_tracker( void )\n{\n\tssize_t unused;\n    int gpsd_sock;\n    char line[256], *temp;\n    struct sockaddr_in gpsd_addr;\n    int ret, is_json, pos;\n    fd_set read_fd;\n    struct timeval timeout;\n\n    /* attempt to connect to localhost, port 2947 */\n\n    pos = 0;\n    gpsd_sock = socket( AF_INET, SOCK_STREAM, 0 );\n\n    if( gpsd_sock < 0 ) {\n        return;\n    }\n\n    gpsd_addr.sin_family      = AF_INET;\n    gpsd_addr.sin_port        = htons( 2947 );\n    gpsd_addr.sin_addr.s_addr = inet_addr( \"127.0.0.1\" );\n\n    if( connect( gpsd_sock, (struct sockaddr *) &gpsd_addr,\n                 sizeof( gpsd_addr ) ) < 0 ) {\n        return;\n    }\n\n    // Check if it's GPSd < 2.92 or the new one\n    // 2.92+ immediately send stuff\n    // < 2.92 requires to send PVTAD command\n    FD_ZERO(&read_fd);\n    FD_SET(gpsd_sock, &read_fd);\n    timeout.tv_sec = 1;\n    timeout.tv_usec = 0;\n    is_json = select(gpsd_sock + 1, &read_fd, NULL, NULL, &timeout);\n    if (is_json) {\n    \t/*\n\t\t\t{\"class\":\"VERSION\",\"release\":\"2.95\",\"rev\":\"2010-11-16T21:12:35\",\"proto_major\":3,\"proto_minor\":3}\n\t\t\t?WATCH={\"json\":true};\n\t\t\t{\"class\":\"DEVICES\",\"devices\":[]}\n    \t */\n\n\n    \t// Get the crap and ignore it: {\"class\":\"VERSION\",\"release\":\"2.95\",\"rev\":\"2010-11-16T21:12:35\",\"proto_major\":3,\"proto_minor\":3}\n    \tif( recv( gpsd_sock, line, sizeof( line ) - 1, 0 ) <= 0 )\n    \t\treturn;\n\n    \tis_json = (line[0] == '{');\n    \tif (is_json) {\n\t\t\t// Send ?WATCH={\"json\":true};\n\t\t\tmemset( line, 0, sizeof( line ) );\n\t\t\tstrcpy(line, \"?WATCH={\\\"json\\\":true};\\n\");\n\t\t\tif( send( gpsd_sock, line, 22, 0 ) != 22 )\n\t\t\t\treturn;\n\n\t\t\t// Check that we have devices\n\t\t\tmemset(line, 0, sizeof(line));\n\t\t\tif( recv( gpsd_sock, line, sizeof( line ) - 1, 0 ) <= 0 )\n\t\t\t\treturn;\n\n\t\t\t// Stop processing if there is no device\n\t\t\tif (strncmp(line, \"{\\\"class\\\":\\\"DEVICES\\\",\\\"devices\\\":[]}\", 32) == 0) {\n\t\t\t\tclose(gpsd_sock);\n\t\t\t\treturn;\n\t\t\t} else {\n\t\t\t\tpos = strlen(line);\n\t\t\t}\n    \t}\n    }\n\n    /* loop reading the GPS coordinates */\n\n    while( G.do_exit == 0 )\n    {\n        usleep( 500000 );\n        memset( G.gps_loc, 0, sizeof( float ) * 5 );\n\n        /* read position, speed, heading, altitude */\n        if (is_json) {\n        \t// Format definition: http://catb.org/gpsd/gpsd_json.html\n\n        \tif (pos == sizeof( line )) {\n        \t\tmemset(line, 0, sizeof(line));\n        \t\tpos = 0;\n        \t}\n\n        \t// New version, JSON\n        \tif( recv( gpsd_sock, line + pos, sizeof( line ) - pos - 1, 0 ) <= 0 )\n        \t\treturn;\n\n        \t// search for TPV class: {\"class\":\"TPV\"\n        \ttemp = strstr(line, \"{\\\"class\\\":\\\"TPV\\\"\");\n        \tif (temp == NULL) {\n        \t\tcontinue;\n        \t}\n\n        \t// Make sure the data we have is complete\n        \tif (strchr(temp, '}') == NULL) {\n        \t\t// Move the data at the beginning of the buffer;\n        \t\tpos = strlen(temp);\n        \t\tif (temp != line) {\n        \t\t\tmemmove(line, temp, pos);\n        \t\t\tmemset(line + pos, 0, sizeof(line) - pos);\n        \t\t}\n        \t}\n\n\t\t\t// Example line: {\"class\":\"TPV\",\"tag\":\"MID2\",\"device\":\"/dev/ttyUSB0\",\"time\":1350957517.000,\"ept\":0.005,\"lat\":46.878936576,\"lon\":-115.832602964,\"alt\":1968.382,\"track\":0.0000,\"speed\":0.000,\"climb\":0.000,\"mode\":3}\n\n        \t// Latitude\n        \ttemp = strstr(temp, \"\\\"lat\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[0]);\n\n\t\t\t// Longitude\n\t\t\ttemp = strstr(temp, \"\\\"lon\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[1]);\n\n\t\t\t// Altitude\n\t\t\ttemp = strstr(temp, \"\\\"alt\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[4]);\n\n\t\t\t// Speed\n\t\t\ttemp = strstr(temp, \"\\\"speed\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[2]);\n\n\t\t\t// No more heading\n\n\t\t\t// Get the next TPV class\n\t\t\ttemp = strstr(temp, \"{\\\"class\\\":\\\"TPV\\\"\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tmemset( line, 0, sizeof( line ) );\n\t\t\t\tpos = 0;\n\t\t\t} else {\n\t\t\t\tpos = strlen(temp);\n\t\t\t\tmemmove(line, temp, pos);\n\t\t\t\tmemset(line + pos, 0, sizeof(line) - pos);\n\t\t\t}\n\n        } else {\n        \tmemset( line, 0, sizeof( line ) );\n\n\t\t\tsnprintf( line,  sizeof( line ) - 1, \"PVTAD\\r\\n\" );\n\t\t\tif( send( gpsd_sock, line, 7, 0 ) != 7 )\n\t\t\t\treturn;\n\n\t\t\tmemset( line, 0, sizeof( line ) );\n\t\t\tif( recv( gpsd_sock, line, sizeof( line ) - 1, 0 ) <= 0 )\n\t\t\t\treturn;\n\n\t\t\tif( memcmp( line, \"GPSD,P=\", 7 ) != 0 )\n\t\t\t\tcontinue;\n\n\t\t\t/* make sure the coordinates are present */\n\n\t\t\tif( line[7] == '?' )\n\t\t\t\tcontinue;\n\n\t\t\tret = sscanf( line + 7, \"%f %f\", &G.gps_loc[0], &G.gps_loc[1] );\n\n\t\t\tif( ( temp = strstr( line, \"V=\" ) ) == NULL ) continue;\n\t\t\tret = sscanf( temp + 2, \"%f\", &G.gps_loc[2] ); /* speed */\n\n\t\t\tif( ( temp = strstr( line, \"T=\" ) ) == NULL ) continue;\n\t\t\tret = sscanf( temp + 2, \"%f\", &G.gps_loc[3] ); /* heading */\n\n\t\t\tif( ( temp = strstr( line, \"A=\" ) ) == NULL ) continue;\n\t\t\tret = sscanf( temp + 2, \"%f\", &G.gps_loc[4] ); /* altitude */\n        }\n\n        if (G.record_data)\n\t\t\tfputs( line, G.f_gps );\n\n\t\tG.save_gps = 1;\n\n        if (G.do_exit == 0)\n\t\t{\n\t\t\tunused = write( G.gc_pipe[1], G.gps_loc, sizeof( float ) * 5 );\n\t\t\tkill( getppid(), SIGUSR2 );\n\t\t}\n    }\n}", "commit_link": "github.com/aircrack-ng/aircrack-ng/commit/ff70494dd389ba570dbdbf36f217c28d4381c6b5/", "file_name": "src/airodump-ng.c", "vul_type": "cwe-787", "description": "Write a C function named `gps_tracker` that connects to a GPS daemon on localhost and reads GPS coordinates in a loop."}
{"func_name": "archive_read_format_rar_read_data", "func_src_before": "archive_read_format_rar_read_data(struct archive_read *a, const void **buff,\n                                  size_t *size, int64_t *offset)\n{\n  struct rar *rar = (struct rar *)(a->format->data);\n  int ret;\n\n  if (rar->has_encrypted_entries == ARCHIVE_READ_FORMAT_ENCRYPTION_DONT_KNOW) {\n\t  rar->has_encrypted_entries = 0;\n  }\n\n  if (rar->bytes_unconsumed > 0) {\n      /* Consume as much as the decompressor actually used. */\n      __archive_read_consume(a, rar->bytes_unconsumed);\n      rar->bytes_unconsumed = 0;\n  }\n\n  *buff = NULL;\n  if (rar->entry_eof || rar->offset_seek >= rar->unp_size) {\n    *size = 0;\n    *offset = rar->offset;\n    if (*offset < rar->unp_size)\n      *offset = rar->unp_size;\n    return (ARCHIVE_EOF);\n  }\n\n  switch (rar->compression_method)\n  {\n  case COMPRESS_METHOD_STORE:\n    ret = read_data_stored(a, buff, size, offset);\n    break;\n\n  case COMPRESS_METHOD_FASTEST:\n  case COMPRESS_METHOD_FAST:\n  case COMPRESS_METHOD_NORMAL:\n  case COMPRESS_METHOD_GOOD:\n  case COMPRESS_METHOD_BEST:\n    ret = read_data_compressed(a, buff, size, offset);\n    if (ret != ARCHIVE_OK && ret != ARCHIVE_WARN)\n      __archive_ppmd7_functions.Ppmd7_Free(&rar->ppmd7_context);\n    break;\n\n  default:\n    archive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,\n                      \"Unsupported compression method for RAR file.\");\n    ret = ARCHIVE_FATAL;\n    break;\n  }\n  return (ret);\n}", "func_src_after": "archive_read_format_rar_read_data(struct archive_read *a, const void **buff,\n                                  size_t *size, int64_t *offset)\n{\n  struct rar *rar = (struct rar *)(a->format->data);\n  int ret;\n\n  if (rar->has_encrypted_entries == ARCHIVE_READ_FORMAT_ENCRYPTION_DONT_KNOW) {\n\t  rar->has_encrypted_entries = 0;\n  }\n\n  if (rar->bytes_unconsumed > 0) {\n      /* Consume as much as the decompressor actually used. */\n      __archive_read_consume(a, rar->bytes_unconsumed);\n      rar->bytes_unconsumed = 0;\n  }\n\n  *buff = NULL;\n  if (rar->entry_eof || rar->offset_seek >= rar->unp_size) {\n    *size = 0;\n    *offset = rar->offset;\n    if (*offset < rar->unp_size)\n      *offset = rar->unp_size;\n    return (ARCHIVE_EOF);\n  }\n\n  switch (rar->compression_method)\n  {\n  case COMPRESS_METHOD_STORE:\n    ret = read_data_stored(a, buff, size, offset);\n    break;\n\n  case COMPRESS_METHOD_FASTEST:\n  case COMPRESS_METHOD_FAST:\n  case COMPRESS_METHOD_NORMAL:\n  case COMPRESS_METHOD_GOOD:\n  case COMPRESS_METHOD_BEST:\n    ret = read_data_compressed(a, buff, size, offset);\n    if (ret != ARCHIVE_OK && ret != ARCHIVE_WARN) {\n      __archive_ppmd7_functions.Ppmd7_Free(&rar->ppmd7_context);\n      rar->start_new_table = 1;\n    }\n    break;\n\n  default:\n    archive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,\n                      \"Unsupported compression method for RAR file.\");\n    ret = ARCHIVE_FATAL;\n    break;\n  }\n  return (ret);\n}", "commit_link": "github.com/libarchive/libarchive/commit/b8592ecba2f9e451e1f5cb7ab6dcee8b8e7b3f60", "file_name": "libarchive/archive_read_support_format_rar.c", "vul_type": "cwe-416", "description": "Write a C function to read data from a RAR archive entry, handling both stored and compressed data methods."}
{"func_name": "rtc_irq_eoi_tracking_reset", "func_src_before": "static void rtc_irq_eoi_tracking_reset(struct kvm_ioapic *ioapic)\n{\n\tioapic->rtc_status.pending_eoi = 0;\n\tbitmap_zero(ioapic->rtc_status.dest_map.map, KVM_MAX_VCPUS);\n}", "func_src_after": "static void rtc_irq_eoi_tracking_reset(struct kvm_ioapic *ioapic)\n{\n\tioapic->rtc_status.pending_eoi = 0;\n\tbitmap_zero(ioapic->rtc_status.dest_map.map, KVM_MAX_VCPU_ID);\n}", "commit_link": "github.com/torvalds/linux/commit/81cdb259fb6d8c1c4ecfeea389ff5a73c07f5755", "file_name": "arch/x86/kvm/ioapic.c", "vul_type": "cwe-125", "description": "Write a C function named `rtc_irq_eoi_tracking_reset` that resets the pending EOI status and clears the destination map bitmap in a `kvm_ioapic` structure."}
{"func_name": "dd_load_text_ext", "func_src_before": "char* dd_load_text_ext(const struct dump_dir *dd, const char *name, unsigned flags)\n{\n//    if (!dd->locked)\n//        error_msg_and_die(\"dump_dir is not opened\"); /* bug */\n\n    /* Compat with old abrt dumps. Remove in abrt-2.1 */\n    if (strcmp(name, \"release\") == 0)\n        name = FILENAME_OS_RELEASE;\n\n    char *full_path = concat_path_file(dd->dd_dirname, name);\n    char *ret = load_text_file(full_path, flags);\n    free(full_path);\n\n    return ret;\n}", "func_src_after": "char* dd_load_text_ext(const struct dump_dir *dd, const char *name, unsigned flags)\n{\n//    if (!dd->locked)\n//        error_msg_and_die(\"dump_dir is not opened\"); /* bug */\n\n    if (!str_is_correct_filename(name))\n    {\n        error_msg(\"Cannot load text. '%s' is not a valid file name\", name);\n        if (!(flags & DD_LOAD_TEXT_RETURN_NULL_ON_FAILURE))\n            xfunc_die();\n    }\n\n    /* Compat with old abrt dumps. Remove in abrt-2.1 */\n    if (strcmp(name, \"release\") == 0)\n        name = FILENAME_OS_RELEASE;\n\n    char *full_path = concat_path_file(dd->dd_dirname, name);\n    char *ret = load_text_file(full_path, flags);\n    free(full_path);\n\n    return ret;\n}", "commit_link": "github.com/abrt/libreport/commit/239c4f7d1f47265526b39ad70106767d00805277", "file_name": "src/lib/dump_dir.c", "vul_type": "cwe-022", "description": "Write a C function named `dd_load_text_ext` that loads text from a file within a directory structure, handling special cases and errors."}
{"func_name": "download_check_files", "func_src_before": "    def download_check_files(self, filelist):\n        # only admins and allowed users may download\n        if not cherrypy.session['admin']:\n            uo = self.useroptions.forUser(self.getUserId())\n            if not uo.getOptionValue('media.may_download'):\n                return 'not_permitted'\n        # make sure nobody tries to escape from basedir\n        for f in filelist:\n            if '/../' in f:\n                return 'invalid_file'\n        # make sure all files are smaller than maximum download size\n        size_limit = cherry.config['media.maximum_download_size']\n        try:\n            if self.model.file_size_within_limit(filelist, size_limit):\n                return 'ok'\n            else:\n                return 'too_big'\n        except OSError as e:        # use OSError for python2 compatibility\n            return str(e)", "func_src_after": "    def download_check_files(self, filelist):\n        # only admins and allowed users may download\n        if not cherrypy.session['admin']:\n            uo = self.useroptions.forUser(self.getUserId())\n            if not uo.getOptionValue('media.may_download'):\n                return 'not_permitted'\n        # make sure nobody tries to escape from basedir\n        for f in filelist:\n            # don't allow to traverse up in the file system\n            if '/../' in f or f.startswith('../'):\n                return 'invalid_file'\n            # CVE-2015-8309: do not allow absolute file paths\n            if os.path.isabs(f):\n                return 'invalid_file'\n        # make sure all files are smaller than maximum download size\n        size_limit = cherry.config['media.maximum_download_size']\n        try:\n            if self.model.file_size_within_limit(filelist, size_limit):\n                return 'ok'\n            else:\n                return 'too_big'\n        except OSError as e:        # use OSError for python2 compatibility\n            return str(e)", "commit_link": "github.com/devsnd/cherrymusic/commit/62dec34a1ea0741400dd6b6c660d303dcd651e86", "file_name": "cherrymusicserver/httphandler.py", "vul_type": "cwe-022", "description": "Write a Python function named `download_check_files` that validates a list of file paths for download permissions, path security, and size constraints."}
{"func_name": "next_state_class", "func_src_before": "next_state_class(CClassNode* cc, OnigCodePoint* vs, enum CCVALTYPE* type,\n\t\t enum CCSTATE* state, ScanEnv* env)\n{\n  int r;\n\n  if (*state == CCS_RANGE)\n    return ONIGERR_CHAR_CLASS_VALUE_AT_END_OF_RANGE;\n\n  if (*state == CCS_VALUE && *type != CCV_CLASS) {\n    if (*type == CCV_SB)\n      BITSET_SET_BIT(cc->bs, (int )(*vs));\n    else if (*type == CCV_CODE_POINT) {\n      r = add_code_range(&(cc->mbuf), env, *vs, *vs);\n      if (r < 0) return r;\n    }\n  }\n\n  *state = CCS_VALUE;\n  *type  = CCV_CLASS;\n  return 0;\n}", "func_src_after": "next_state_class(CClassNode* cc, OnigCodePoint* vs, enum CCVALTYPE* type,\n\t\t enum CCSTATE* state, ScanEnv* env)\n{\n  int r;\n\n  if (*state == CCS_RANGE)\n    return ONIGERR_CHAR_CLASS_VALUE_AT_END_OF_RANGE;\n\n  if (*state == CCS_VALUE && *type != CCV_CLASS) {\n    if (*type == CCV_SB)\n      BITSET_SET_BIT(cc->bs, (int )(*vs));\n    else if (*type == CCV_CODE_POINT) {\n      r = add_code_range(&(cc->mbuf), env, *vs, *vs);\n      if (r < 0) return r;\n    }\n  }\n\n  if (*state != CCS_START)\n    *state = CCS_VALUE;\n\n  *type  = CCV_CLASS;\n  return 0;\n}", "commit_link": "github.com/kkos/oniguruma/commit/3b63d12038c8d8fc278e81c942fa9bec7c704c8b", "file_name": "src/regparse.c", "vul_type": "cwe-787", "description": "Write a C function named `next_state_class` that updates character class states and values for a regex engine."}
{"func_name": "__getattr__.adb_call", "func_src_before": "        def adb_call(*args):\n            clean_name = name.replace('_', '-')\n            arg_str = ' '.join(str(elem) for elem in args)\n            return self._exec_adb_cmd(clean_name, arg_str)", "func_src_after": "        def adb_call(args=None, shell=False):\n            \"\"\"Wrapper for an ADB command.\n\n            Args:\n                args: string or list of strings, arguments to the adb command.\n                    See subprocess.Proc() documentation.\n                shell: bool, True to run this command through the system shell,\n                    False to invoke it directly. See subprocess.Proc() docs.\n\n            Returns:\n                The output of the adb command run if exit code is 0.\n            \"\"\"\n            args = args or ''\n            clean_name = name.replace('_', '-')\n            return self._exec_adb_cmd(clean_name, args, shell=shell)", "commit_link": "github.com/google/mobly/commit/3862e8ba359040fbdd6e1a6d36e51d07cda8e1ee", "file_name": "mobly/controllers/android_device_lib/adb.py", "vul_type": "cwe-078", "description": "Create a Python function named `adb_call` that serves as a wrapper for executing ADB (Android Debug Bridge) commands with optional arguments and shell execution flag."}
{"func_name": "igraph_read_graph_graphml", "func_src_before": "int igraph_read_graph_graphml(igraph_t *graph, FILE *instream, int index) {\n\n#if HAVE_LIBXML == 1\n    xmlParserCtxtPtr ctxt;\n    xmlDocPtr doc;\n\n    struct igraph_i_graphml_parser_state state;\n    int res;\n    char buffer[4096];\n    igraph_bool_t parsing_successful;\n    char* error_message;\n\n    if (index < 0) {\n        IGRAPH_ERROR(\"Graph index must be non-negative\", IGRAPH_EINVAL);\n    }\n\n    xmlInitParser();\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_init(&state, graph, index));\n    IGRAPH_FINALLY(igraph_i_graphml_parser_state_destroy, &state);\n\n    /* Create a progressive parser context */\n    res = (int) fread(buffer, 1, sizeof(buffer), instream);\n    if (res < sizeof(buffer) && !feof(instream)) {\n        IGRAPH_ERROR(\"IO error while reading GraphML data\", IGRAPH_PARSEERROR);\n    }\n    ctxt = xmlCreatePushParserCtxt(&igraph_i_graphml_sax_handler,\n                                   &state,\n                                   buffer,\n                                   res,\n                                   NULL);\n    /*   ctxt=xmlCreateIOParserCtxt(&igraph_i_graphml_sax_handler, &state, */\n    /*               igraph_i_libxml2_read_callback, */\n    /*               igraph_i_libxml2_close_callback, */\n    /*               instream, XML_CHAR_ENCODING_NONE); */\n    if (ctxt == NULL) {\n        IGRAPH_ERROR(\"Can't create progressive parser context\", IGRAPH_PARSEERROR);\n    }\n\n    /* Set parsing options */\n    if (xmlCtxtUseOptions(ctxt,\n                          XML_PARSE_NOENT | XML_PARSE_NOBLANKS |\n                          XML_PARSE_NONET | XML_PARSE_NSCLEAN |\n                          XML_PARSE_NOCDATA | XML_PARSE_HUGE\n                         )) {\n        xmlFreeParserCtxt(ctxt);\n        IGRAPH_ERROR(\"Cannot set options for the parser context\", IGRAPH_EINVAL);\n    }\n\n    /* Okay, parsing will start now. The parser might do things that eventually\n     * trigger the igraph error handler, but we want the parser state to\n     * survive whatever happens here. So, we need to pop off\n     * igraph_i_graphml_parser_state_destroy() from the stack and temporarily\n     * assume responsibility for calling it ourselves until we are back from the\n     * parser */\n    IGRAPH_FINALLY_CLEAN(1);\n\n    /* Do the parsing */\n    while ((res = (int) fread(buffer, 1, sizeof(buffer), instream)) > 0) {\n        xmlParseChunk(ctxt, buffer, res, 0);\n        if (!state.successful) {\n            break;\n        }\n    }\n    xmlParseChunk(ctxt, buffer, res, 1);\n\n    /* Free the context */\n    doc = ctxt->myDoc;\n    xmlFreeParserCtxt(ctxt);\n    if (doc) {\n        /* In theory this should not be necessary, but it looks like certain malformed\n         * GraphML files leave a partially-parsed doc in memory */\n        xmlFreeDoc(doc);\n    }\n\n    /* Extract the error message from the parser state (if any), and make a\n     * copy so we can safely destroy the parser state before triggering the\n     * error */\n    parsing_successful = state.successful;\n    error_message = parsing_successful || state.error_message == NULL ? NULL : strdup(state.error_message);\n\n    /* Now that we have lifted error_message out of the parser state, we can\n     * put the destructor of the parser state back on the FINALLY stack */\n    IGRAPH_FINALLY(igraph_i_graphml_parser_state_destroy, &state);\n\n    /* ...and we can also put the error message pointer on the FINALLY stack */\n    if (error_message != NULL) {\n        IGRAPH_FINALLY(free, error_message);\n    }\n\n    /* Trigger the stored error if needed */\n    if (!parsing_successful) {\n        if (error_message != NULL) {\n            IGRAPH_ERROR(error_message, IGRAPH_PARSEERROR);\n        } else {\n            IGRAPH_ERROR(\"Malformed GraphML file\", IGRAPH_PARSEERROR);\n        }\n    }\n\n    /* Did we actually manage to reach the graph to be parsed, given its index?\n     * If not, that's an error as well. */\n    if (state.index >= 0) {\n        IGRAPH_ERROR(\"Graph index was too large\", IGRAPH_EINVAL);\n    }\n\n    /* Okay, everything seems good. We can now take the parser state and\n     * construct our graph from the data gathered during the parsing */\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_finish_parsing(&state));\n\n    igraph_i_graphml_parser_state_destroy(&state);\n    IGRAPH_FINALLY_CLEAN(1);\n\n    return IGRAPH_SUCCESS;\n#else\n    IGRAPH_UNUSED(graph);\n    IGRAPH_UNUSED(instream);\n    IGRAPH_UNUSED(index);\n\n    IGRAPH_ERROR(\"GraphML support is disabled\", IGRAPH_UNIMPLEMENTED);\n#endif\n}", "func_src_after": "int igraph_read_graph_graphml(igraph_t *graph, FILE *instream, int index) {\n\n#if HAVE_LIBXML == 1\n    xmlParserCtxtPtr ctxt;\n    xmlDocPtr doc;\n\n    struct igraph_i_graphml_parser_state state;\n    int res;\n    char buffer[4096];\n    igraph_bool_t parsing_successful;\n    char* error_message;\n\n    if (index < 0) {\n        IGRAPH_ERROR(\"Graph index must be non-negative\", IGRAPH_EINVAL);\n    }\n\n    xmlInitParser();\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_init(&state, graph, index));\n    IGRAPH_FINALLY(igraph_i_graphml_parser_state_destroy, &state);\n\n    /* Create a progressive parser context */\n    res = (int) fread(buffer, 1, sizeof(buffer), instream);\n    if (res < sizeof(buffer) && !feof(instream)) {\n        IGRAPH_ERROR(\"IO error while reading GraphML data\", IGRAPH_PARSEERROR);\n    }\n    ctxt = xmlCreatePushParserCtxt(&igraph_i_graphml_sax_handler,\n                                   &state,\n                                   buffer,\n                                   res,\n                                   NULL);\n    /*   ctxt=xmlCreateIOParserCtxt(&igraph_i_graphml_sax_handler, &state, */\n    /*               igraph_i_libxml2_read_callback, */\n    /*               igraph_i_libxml2_close_callback, */\n    /*               instream, XML_CHAR_ENCODING_NONE); */\n    if (ctxt == NULL) {\n        IGRAPH_ERROR(\"Can't create progressive parser context\", IGRAPH_PARSEERROR);\n    }\n\n    /* Set parsing options */\n    if (xmlCtxtUseOptions(ctxt,\n                          XML_PARSE_NOBLANKS |\n                          XML_PARSE_NONET | XML_PARSE_NSCLEAN |\n                          XML_PARSE_NOCDATA | XML_PARSE_HUGE\n                         )) {\n        xmlFreeParserCtxt(ctxt);\n        IGRAPH_ERROR(\"Cannot set options for the parser context\", IGRAPH_EINVAL);\n    }\n\n    /* Okay, parsing will start now. The parser might do things that eventually\n     * trigger the igraph error handler, but we want the parser state to\n     * survive whatever happens here. So, we need to pop off\n     * igraph_i_graphml_parser_state_destroy() from the stack and temporarily\n     * assume responsibility for calling it ourselves until we are back from the\n     * parser */\n    IGRAPH_FINALLY_CLEAN(1);\n\n    /* Do the parsing */\n    while ((res = (int) fread(buffer, 1, sizeof(buffer), instream)) > 0) {\n        xmlParseChunk(ctxt, buffer, res, 0);\n        if (!state.successful) {\n            break;\n        }\n    }\n    xmlParseChunk(ctxt, buffer, res, 1);\n\n    /* Free the context */\n    doc = ctxt->myDoc;\n    xmlFreeParserCtxt(ctxt);\n    if (doc) {\n        /* In theory this should not be necessary, but it looks like certain malformed\n         * GraphML files leave a partially-parsed doc in memory */\n        xmlFreeDoc(doc);\n    }\n\n    /* Extract the error message from the parser state (if any), and make a\n     * copy so we can safely destroy the parser state before triggering the\n     * error */\n    parsing_successful = state.successful;\n    error_message = parsing_successful || state.error_message == NULL ? NULL : strdup(state.error_message);\n\n    /* Now that we have lifted error_message out of the parser state, we can\n     * put the destructor of the parser state back on the FINALLY stack */\n    IGRAPH_FINALLY(igraph_i_graphml_parser_state_destroy, &state);\n\n    /* ...and we can also put the error message pointer on the FINALLY stack */\n    if (error_message != NULL) {\n        IGRAPH_FINALLY(free, error_message);\n    }\n\n    /* Trigger the stored error if needed */\n    if (!parsing_successful) {\n        if (error_message != NULL) {\n            IGRAPH_ERROR(error_message, IGRAPH_PARSEERROR);\n        } else {\n            IGRAPH_ERROR(\"Malformed GraphML file\", IGRAPH_PARSEERROR);\n        }\n    }\n\n    /* Did we actually manage to reach the graph to be parsed, given its index?\n     * If not, that's an error as well. */\n    if (state.index >= 0) {\n        IGRAPH_ERROR(\"Graph index was too large\", IGRAPH_EINVAL);\n    }\n\n    /* Okay, everything seems good. We can now take the parser state and\n     * construct our graph from the data gathered during the parsing */\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_finish_parsing(&state));\n\n    igraph_i_graphml_parser_state_destroy(&state);\n    IGRAPH_FINALLY_CLEAN(1);\n\n    return IGRAPH_SUCCESS;\n#else\n    IGRAPH_UNUSED(graph);\n    IGRAPH_UNUSED(instream);\n    IGRAPH_UNUSED(index);\n\n    IGRAPH_ERROR(\"GraphML support is disabled\", IGRAPH_UNIMPLEMENTED);\n#endif\n}", "line_changes": {"deleted": [{"line_no": 41, "char_start": 1463, "char_end": 1528, "line": "                          XML_PARSE_NOENT | XML_PARSE_NOBLANKS |\n"}], "added": [{"line_no": 41, "char_start": 1463, "char_end": 1510, "line": "                          XML_PARSE_NOBLANKS |\n"}]}, "char_changes": {"deleted": [{"char_start": 1488, "char_end": 1506, "chars": " XML_PARSE_NOENT |"}], "added": []}, "commit_link": "github.com/igraph/igraph/commit/6ce2353fa77a891d1b556b8908ca9e4c227c3619", "file_name": "graphml.c", "vul_type": "cwe-611", "commit_msg": "fix: disable external XML entity resolution", "parent_commit": "cb8f28bae4c5ab92e5b628d9b4f827d3c61ba6ce", "description": "Write a C function to parse a GraphML file into an igraph_t structure using libxml2."}
{"func_name": "test_create_invalid_host", "func_src_before": "    def test_create_invalid_host(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record\n        self.clear_mox()\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_cpg\",\n                       self.fake_get_cpg)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_domain\",\n                       self.fake_get_domain)\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_host_cmd = 'showhost -verbose fakehost'\n        _run_ssh(show_host_cmd, False).AndReturn([pack('no hosts listed'), ''])\n\n        create_host_cmd = ('createhost -persona 1 -domain (\\'OpenStack\\',) '\n                           'fakehost 123456789012345 123456789054321')\n        create_host_ret = pack(CLI_CR +\n                               'already used by host fakehost.foo (19)')\n        _run_ssh(create_host_cmd, False).AndReturn([create_host_ret, ''])\n\n        show_3par_cmd = 'showhost -verbose fakehost.foo'\n        _run_ssh(show_3par_cmd, False).AndReturn([pack(FC_SHOWHOST_RET), ''])\n        self.mox.ReplayAll()\n\n        host = self.driver._create_host(self.volume, self.connector)\n\n        self.assertEquals(host['name'], 'fakehost.foo')", "func_src_after": "    def test_create_invalid_host(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record\n        self.clear_mox()\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_cpg\",\n                       self.fake_get_cpg)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_domain\",\n                       self.fake_get_domain)\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_host_cmd = ['showhost', '-verbose', 'fakehost']\n        _run_ssh(show_host_cmd, False).AndReturn([pack('no hosts listed'), ''])\n\n        create_host_cmd = (['createhost', '-persona', '1', '-domain',\n                            ('OpenStack',), 'fakehost', '123456789012345',\n                            '123456789054321'])\n        create_host_ret = pack(CLI_CR +\n                               'already used by host fakehost.foo (19)')\n        _run_ssh(create_host_cmd, False).AndReturn([create_host_ret, ''])\n\n        show_3par_cmd = ['showhost', '-verbose', 'fakehost.foo']\n        _run_ssh(show_3par_cmd, False).AndReturn([pack(FC_SHOWHOST_RET), ''])\n        self.mox.ReplayAll()\n\n        host = self.driver._create_host(self.volume, self.connector)\n\n        self.assertEquals(host['name'], 'fakehost.foo')", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/tests/test_hp3par.py", "vul_type": "cwe-078", "description": "Write a Python unit test function that mocks SSH commands for creating a host in an HP 3PAR storage system and checks the host's name."}
{"func_name": "getPostsByPostid", "func_src_before": "    def getPostsByPostid(self,postid):\n        sqlText=\"select users.name,post.comment from users,post where \\\n                users.userid=post.userid and post.postid=%d\"%(postid)\n        result=sql.queryDB(self.conn,sqlText)\n        return result;", "func_src_after": "    def getPostsByPostid(self,postid):\n        sqlText=\"select users.name,post.comment from users,post where \\\n                users.userid=post.userid and post.postid=%s\"\n        params=[postid]\n        result=sql.queryDB(self.conn,sqlText,params)\n        return result;", "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/post.py", "vul_type": "cwe-089", "description": "Write a Python function that retrieves a user's name and comment from a database using a post ID."}
{"func_name": "_exec_cmd", "func_src_before": "    def _exec_cmd(self, cmd):\n        \"\"\"Executes adb commands in a new shell.\n\n        This is specific to executing adb binary because stderr is not a good\n        indicator of cmd execution status.\n\n        Args:\n            cmds: A string that is the adb command to execute.\n\n        Returns:\n            The output of the adb command run if exit code is 0.\n\n        Raises:\n            AdbError is raised if the adb command exit code is not 0.\n        \"\"\"\n        proc = subprocess.Popen(\n            cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n        (out, err) = proc.communicate()\n        ret = proc.returncode\n        logging.debug('cmd: %s, stdout: %s, stderr: %s, ret: %s', cmd, out,\n                      err, ret)\n        if ret == 0:\n            return out\n        else:\n            raise AdbError(cmd=cmd, stdout=out, stderr=err, ret_code=ret)", "func_src_after": "    def _exec_cmd(self, args, shell):\n        \"\"\"Executes adb commands.\n\n        Args:\n            args: string or list of strings, program arguments.\n                See subprocess.Popen() documentation.\n            shell: bool, True to run this command through the system shell,\n                False to invoke it directly. See subprocess.Popen() docs.\n\n        Returns:\n            The output of the adb command run if exit code is 0.\n\n        Raises:\n            AdbError is raised if the adb command exit code is not 0.\n        \"\"\"\n        proc = subprocess.Popen(\n            args, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=shell)\n        (out, err) = proc.communicate()\n        ret = proc.returncode\n        logging.debug('cmd: %s, stdout: %s, stderr: %s, ret: %s', args, out,\n                      err, ret)\n        if ret == 0:\n            return out\n        else:\n            raise AdbError(cmd=args, stdout=out, stderr=err, ret_code=ret)", "commit_link": "github.com/google/mobly/commit/3862e8ba359040fbdd6e1a6d36e51d07cda8e1ee", "file_name": "mobly/controllers/android_device_lib/adb.py", "vul_type": "cwe-078", "description": "In Python, write a function to execute adb commands and handle the output based on the command's success or failure."}
{"func_name": "set", "func_src_before": "    def set(self, key, value, replace=False):\n        path = os.path.join(self.namespace, key)\n        try:\n            self.etcd.write(path, value, prevExist=replace)\n        except etcd.EtcdAlreadyExist as err:\n            raise CSStoreExists(str(err))\n        except etcd.EtcdException as err:\n            log_error(\"Error storing key %s: [%r]\" % (key, repr(err)))\n            raise CSStoreError('Error occurred while trying to store key')", "func_src_after": "    def set(self, key, value, replace=False):\n        path = self._absolute_key(key)\n        try:\n            self.etcd.write(path, value, prevExist=replace)\n        except etcd.EtcdAlreadyExist as err:\n            raise CSStoreExists(str(err))\n        except etcd.EtcdException as err:\n            log_error(\"Error storing key %s: [%r]\" % (key, repr(err)))\n            raise CSStoreError('Error occurred while trying to store key')", "commit_link": "github.com/latchset/custodia/commit/785fc87f38b4811bc4ce43a0a9b2267ee7d500b4", "file_name": "custodia/store/etcdstore.py", "vul_type": "cwe-022", "description": "Write a Python function named `set` that stores a key-value pair in etcd, with an option to replace the existing key, and handles specific etcd exceptions."}
{"func_name": "_update_volume_stats", "func_src_before": "    def _update_volume_stats(self):\n        \"\"\"Retrieve stats info from volume group.\"\"\"\n\n        LOG.debug(_(\"Updating volume stats\"))\n        data = {}\n\n        data['vendor_name'] = 'IBM'\n        data['driver_version'] = '1.1'\n        data['storage_protocol'] = list(self._enabled_protocols)\n\n        data['total_capacity_gb'] = 0  # To be overwritten\n        data['free_capacity_gb'] = 0   # To be overwritten\n        data['reserved_percentage'] = 0\n        data['QoS_support'] = False\n\n        pool = self.configuration.storwize_svc_volpool_name\n        #Get storage system name\n        ssh_cmd = 'svcinfo lssystem -delim !'\n        attributes = self._execute_command_and_parse_attributes(ssh_cmd)\n        if not attributes or not attributes['name']:\n            exception_message = (_('_update_volume_stats: '\n                                   'Could not get system name'))\n            raise exception.VolumeBackendAPIException(data=exception_message)\n\n        backend_name = self.configuration.safe_get('volume_backend_name')\n        if not backend_name:\n            backend_name = '%s_%s' % (attributes['name'], pool)\n        data['volume_backend_name'] = backend_name\n\n        ssh_cmd = 'svcinfo lsmdiskgrp -bytes -delim ! %s' % pool\n        attributes = self._execute_command_and_parse_attributes(ssh_cmd)\n        if not attributes:\n            LOG.error(_('Could not get pool data from the storage'))\n            exception_message = (_('_update_volume_stats: '\n                                   'Could not get storage pool data'))\n            raise exception.VolumeBackendAPIException(data=exception_message)\n\n        data['total_capacity_gb'] = (float(attributes['capacity']) /\n                                    (1024 ** 3))\n        data['free_capacity_gb'] = (float(attributes['free_capacity']) /\n                                    (1024 ** 3))\n        data['easytier_support'] = attributes['easy_tier'] in ['on', 'auto']\n        data['compression_support'] = self._compression_enabled\n\n        self._stats = data", "func_src_after": "    def _update_volume_stats(self):\n        \"\"\"Retrieve stats info from volume group.\"\"\"\n\n        LOG.debug(_(\"Updating volume stats\"))\n        data = {}\n\n        data['vendor_name'] = 'IBM'\n        data['driver_version'] = '1.1'\n        data['storage_protocol'] = list(self._enabled_protocols)\n\n        data['total_capacity_gb'] = 0  # To be overwritten\n        data['free_capacity_gb'] = 0   # To be overwritten\n        data['reserved_percentage'] = 0\n        data['QoS_support'] = False\n\n        pool = self.configuration.storwize_svc_volpool_name\n        #Get storage system name\n        ssh_cmd = ['svcinfo', 'lssystem', '-delim', '!']\n        attributes = self._execute_command_and_parse_attributes(ssh_cmd)\n        if not attributes or not attributes['name']:\n            exception_message = (_('_update_volume_stats: '\n                                   'Could not get system name'))\n            raise exception.VolumeBackendAPIException(data=exception_message)\n\n        backend_name = self.configuration.safe_get('volume_backend_name')\n        if not backend_name:\n            backend_name = '%s_%s' % (attributes['name'], pool)\n        data['volume_backend_name'] = backend_name\n\n        ssh_cmd = ['svcinfo', 'lsmdiskgrp', '-bytes', '-delim', '!', pool]\n        attributes = self._execute_command_and_parse_attributes(ssh_cmd)\n        if not attributes:\n            LOG.error(_('Could not get pool data from the storage'))\n            exception_message = (_('_update_volume_stats: '\n                                   'Could not get storage pool data'))\n            raise exception.VolumeBackendAPIException(data=exception_message)\n\n        data['total_capacity_gb'] = (float(attributes['capacity']) /\n                                    (1024 ** 3))\n        data['free_capacity_gb'] = (float(attributes['free_capacity']) /\n                                    (1024 ** 3))\n        data['easytier_support'] = attributes['easy_tier'] in ['on', 'auto']\n        data['compression_support'] = self._compression_enabled\n\n        self._stats = data", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to update storage volume statistics with IBM vendor details and capacity information."}
{"func_name": "load", "func_src_before": "    @classmethod\n    def load(cls, data_store, filename):\n        pgm_model = None\n        if type(data_store) is LocalFileSystem:\n            pgm_model = data_store.read_pomegranate_model(filename=filename)\n        if type(data_store) is S3DataStore:\n            local_filename = \"/tmp/kronos.json\"\n            data_store.download_file(filename, local_filename)\n            with open(local_filename, 'rb') as f:\n                pgm_model = BayesianNetwork.from_json(pickle.load(f))\n        return PGMPomegranate(pgm_model)", "func_src_after": "    @classmethod\n    def load(cls, data_store, filename):\n        pgm_model = None\n        if type(data_store) is LocalFileSystem:\n            pgm_model = data_store.read_pomegranate_model(filename=filename)\n        if type(data_store) is S3DataStore:\n            local_filename = \"/tmp/kronos.json\"\n            data_store.download_file(filename, local_filename)\n            with open(local_filename, 'rb') as f:\n                pgm_model = BayesianNetwork.from_json(f.read())\n        return PGMPomegranate(pgm_model)", "line_changes": {"deleted": [{"line_no": 10, "char_start": 413, "char_end": 483, "line": "                pgm_model = BayesianNetwork.from_json(pickle.load(f))\n"}], "added": [{"line_no": 10, "char_start": 413, "char_end": 477, "line": "                pgm_model = BayesianNetwork.from_json(f.read())\n"}]}, "char_changes": {"deleted": [{"char_start": 467, "char_end": 476, "chars": "pickle.lo"}, {"char_start": 479, "char_end": 480, "chars": "f"}], "added": [{"char_start": 467, "char_end": 471, "chars": "f.re"}]}, "commit_link": "github.com/sara-02/fabric8-analytics-stack-analysis/commit/c9422e6257a8c927aed2999a0f4cc77f90059cda", "file_name": "pgm_pomegranate.py", "vul_type": "cwe-502", "commit_msg": "Remove pickling of model\n\nThe model is already being converted to a JSON(using the `to_json`)\nfunction of pomegranate which is already a stadard serialized format.\nI don't see a need to further serialize the JSON using pickle to\nsomething that can be loaded only using Python. This also helps us\nreduce the training time of the model as pickling and unpickling\nhas a overhead that I don't see a need for, because JSON.", "parent_commit": "c2ddf128d7206a0a85929b6f2a08078433ce1577", "description": "Create a Python method that loads a probabilistic graphical model from a local or S3 data store based on the provided filename."}
{"func_name": "update_history_and_sourcebyinstitution", "func_src_before": "def update_history_and_sourcebyinstitution(conn, sqlite, k10plus, ai):\n    \"\"\"\n    Get all current sources and title numbers from Solr and log them into database.\n    \"\"\"\n    current_sources = get_all_current_sources(k10plus, ai)\n    current_institutions = get_all_current_institutions(k10plus, ai)\n    old_sourcebyinstitutions = get_all_old_sourcebyinstitutions(conn, sqlite)\n    current_sourcebyinstitutions = []\n\n    for source in current_sources:\n\n        for institution in current_institutions:\n\n            if not institution or institution == \" \" or '\"' in institution:\n                continue\n\n            sourcebyinstitution = \"SID \" + str(source) + \" (\" + institution + \")\"\n            current_sourcebyinstitutions.append(sourcebyinstitution)\n\n            params = {\n                \"q\": 'source_id:%s AND institution:\"%s\"' % (source, institution),\n                \"rows\": 0,\n                \"wt\": \"json\"\n            }\n\n            # check k10plus\n            result = get_solr_result(k10plus, params)\n            number = result[\"response\"][\"numFound\"]\n            if number != 0:\n                sql = 'INSERT INTO history (sourcebyinstitution, titles) VALUES (\"%s\", %s)' % (sourcebyinstitution, number)\n                sqlite.execute(sql)\n                conn.commit()\n            else:\n                # check ai\n                result = get_solr_result(ai, params)\n                number = result[\"response\"][\"numFound\"]\n                if number != 0:\n                    # TODO: escape via sqlite\n                    sql = 'INSERT INTO history (sourcebyinstitution, titles) VALUES (\"%s\", %s)' % (sourcebyinstitution, number)\n                    sqlite.execute(sql)\n                    conn.commit()\n\n            if sourcebyinstitution not in old_sourcebyinstitutions:\n                logging.info(\"The %s is now connected to SID %s.\", institution, source)\n                sql = \"INSERT INTO sourcebyinstitution (sourcebyinstitution) VALUES ('%s')\" % sourcebyinstitution\n                sqlite.execute(sql)\n                conn.commit()\n\n            if number != 0:\n                old_sourcebyinstitution_number = get_old_sourcebyinstitution_number(conn, sqlite, sourcebyinstitution)\n                if number < old_sourcebyinstitution_number:\n                    message = \"Die Anzahl der Titel hat sich bei %s gegenueber einem frueheren Import verringert.\" % (sourcebyinstitution)\n                    send_message(message)\n\n            # requests.exceptions.ConnectionError: HTTPConnectionPool(XXXXXX): Max retries exceeded\n            time.sleep(0.25)\n\n    for old_sourcebyinstitution in old_sourcebyinstitutions:\n        if old_sourcebyinstitution not in current_sourcebyinstitutions:\n            message = \"Die %s ist nicht laenger f\u00fcr die SID %s angesigelt.\" % (institution, source)\n            send_message(message)", "func_src_after": "def update_history_and_sourcebyinstitution(conn, sqlite, k10plus, ai):\n    \"\"\"\n    Get all current sources and title numbers from Solr and log them into database.\n    \"\"\"\n    current_sources = get_all_current_sources(k10plus, ai)\n    current_institutions = get_all_current_institutions(k10plus, ai)\n    old_sourcebyinstitutions = get_all_old_sourcebyinstitutions(conn, sqlite)\n    current_sourcebyinstitutions = []\n\n    for source in current_sources:\n\n        for institution in current_institutions:\n\n            if not institution or institution == \" \" or '\"' in institution:\n                continue\n\n            sourcebyinstitution = \"SID \" + str(source) + \" (\" + institution + \")\"\n            current_sourcebyinstitutions.append(sourcebyinstitution)\n\n            params = {\n                \"q\": 'source_id:%s AND institution:\"%s\"' % (source, institution),\n                \"rows\": 0,\n                \"wt\": \"json\"\n            }\n\n            # check k10plus\n            result = get_solr_result(k10plus, params)\n            number = result[\"response\"][\"numFound\"]\n            if number != 0:\n                sql = 'INSERT INTO history (sourcebyinstitution, titles) VALUES (?, ?)'\n                sqlite.execute(sql, (sourcebyinstitution, number))\n                conn.commit()\n            else:\n                # check ai\n                result = get_solr_result(ai, params)\n                number = result[\"response\"][\"numFound\"]\n                if number != 0:\n                    # TODO: escape via sqlite\n                    sql = 'INSERT INTO history (sourcebyinstitution, titles) VALUES (?, ?)'\n                    sqlite.execute(sql, (sourcebyinstitution, number))\n                    conn.commit()\n\n            if sourcebyinstitution not in old_sourcebyinstitutions:\n                logging.info(\"The %s is now connected to SID %s.\", institution, source)\n                sql = \"INSERT INTO sourcebyinstitution (sourcebyinstitution) VALUES (?)\"\n                sqlite.execute(sql, (sourcebyinstitution))\n                conn.commit()\n\n            if number != 0:\n                old_sourcebyinstitution_number = get_old_sourcebyinstitution_number(conn, sqlite, sourcebyinstitution)\n                if number < old_sourcebyinstitution_number:\n                    message = \"Die Anzahl der Titel hat sich bei %s gegenueber einem frueheren Import verringert.\" % (sourcebyinstitution)\n                    send_message(message)\n\n            # requests.exceptions.ConnectionError: HTTPConnectionPool(XXXXXX): Max retries exceeded\n            time.sleep(0.25)\n\n    for old_sourcebyinstitution in old_sourcebyinstitutions:\n        if old_sourcebyinstitution not in current_sourcebyinstitutions:\n            message = \"Die %s ist nicht laenger f\u00fcr die SID %s angesigelt.\" % (institution, source)\n            send_message(message)", "commit_link": "github.com/miku/siskin/commit/7fa398d2fea72bf2e8b4808f75df4b3d35ae959a", "file_name": "bin/solrcheckup.py", "vul_type": "cwe-089", "description": "Write a Python function to log current source and title data from Solr into a database, handling new and old entries."}
{"func_name": "delete", "func_src_before": "    @jwt_required\n    def delete(self, user_id):\n        \"\"\" Deletes user with the corresponding user_id \"\"\"\n        return database_utilities.execute_query(f\"\"\"delete from users where user_id = '{user_id}'\"\"\")", "func_src_after": "    @jwt_required\n    def delete(self, user_id):\n        \"\"\" Deletes user with the corresponding user_id \"\"\"\n        return database_utilities.execute_query(f\"\"\"delete from users where user_id = %s\"\"\", (user_id, ))", "commit_link": "github.com/sgosal2/tiger-boards-backend/commit/4670109dd613df2f2fe7e8403ebd149df2b55485", "file_name": "apis/users.py", "vul_type": "cwe-089", "description": "Create a Python function with JWT authentication that deletes a user from the database by their user_id."}
{"func_name": "handle", "func_src_before": "    def handle(self, keepalive=True, initial_timeout=None):\n        # we are requested to skip processing and keep the previous values\n        if self.skip:\n            return self.response.handle()\n\n        # default to no keepalive in case something happens while even trying ensure we have a request\n        self.keepalive = False\n\n        self.headers = HTTPHeaders()\n\n        # if initial_timeout is set, only wait that long for the initial request line\n        if initial_timeout:\n            self.connection.settimeout(initial_timeout)\n        else:\n            self.connection.settimeout(self.timeout)\n\n        # get request line\n        try:\n            # ignore empty lines waiting on request\n            request = '\\r\\n'\n            while request == '\\r\\n':\n                request = self.rfile.readline(max_line_size + 1).decode(http_encoding)\n        # if read hits timeout or has some other error, ignore the request\n        except Exception:\n            return True\n\n        # ignore empty requests\n        if not request:\n            return True\n\n        # we have a request, go back to normal timeout\n        if initial_timeout:\n            self.connection.settimeout(self.timeout)\n\n        # remove \\r\\n from the end\n        self.request_line = request[:-2]\n\n        # set some reasonable defaults in case the worst happens and we need to tell the client\n        self.method = ''\n        self.resource = '/'\n\n        try:\n            # HTTP Status 414\n            if len(request) > max_line_size:\n                raise HTTPError(414)\n\n            # HTTP Status 400\n            if request[-2:] != '\\r\\n':\n                raise HTTPError(400)\n\n            # try the request line and error out if can't parse it\n            try:\n                self.method, self.resource, self.request_http = self.request_line.split()\n            # HTTP Status 400\n            except ValueError:\n                raise HTTPError(400)\n\n            # HTTP Status 505\n            if self.request_http != http_version:\n                raise HTTPError(505)\n\n            # read and parse request headers\n            while True:\n                line = self.rfile.readline(max_line_size + 1).decode(http_encoding)\n\n                # hit end of headers\n                if line == '\\r\\n':\n                    break\n\n                self.headers.add(line)\n\n            # if we are requested to close the connection after we finish, do so\n            if self.headers.get('Connection') == 'close':\n                self.keepalive = False\n            # else since we are sure we have a request and have read all of the request data, keepalive for more later (if allowed)\n            else:\n                self.keepalive = keepalive\n\n            # find a matching regex to handle the request with\n            for regex, handler in self.server.routes.items():\n                match = regex.match(self.resource)\n                if match:\n                    # create a dictionary of groups\n                    groups = match.groupdict()\n                    values = groups.values()\n\n                    for idx, group in enumerate(match.groups()):\n                        if group not in values:\n                            groups[idx] = group\n\n                    # create handler\n                    self.handler = handler(self, self.response, groups)\n                    break\n            # HTTP Status 404\n            # if loop is not broken (handler is not found), raise a 404\n            else:\n                raise HTTPError(404)\n        # use DummyHandler so the error is raised again when ready for response\n        except Exception as error:\n            self.handler = DummyHandler(self, self.response, (), error)\n        finally:\n            # we finished listening and handling early errors and so let a response class now finish up the job of talking\n            return self.response.handle()", "func_src_after": "    def handle(self, keepalive=True, initial_timeout=None):\n        # we are requested to skip processing and keep the previous values\n        if self.skip:\n            return self.response.handle()\n\n        # default to no keepalive in case something happens while even trying ensure we have a request\n        self.keepalive = False\n\n        self.headers = HTTPHeaders()\n\n        # if initial_timeout is set, only wait that long for the initial request line\n        if initial_timeout:\n            self.connection.settimeout(initial_timeout)\n        else:\n            self.connection.settimeout(self.timeout)\n\n        # get request line\n        try:\n            # ignore empty lines waiting on request\n            request = '\\r\\n'\n            while request == '\\r\\n':\n                request = self.rfile.readline(max_line_size + 1).decode(http_encoding)\n        # if read hits timeout or has some other error, ignore the request\n        except Exception:\n            return True\n\n        # ignore empty requests\n        if not request:\n            return True\n\n        # we have a request, go back to normal timeout\n        if initial_timeout:\n            self.connection.settimeout(self.timeout)\n\n        # remove \\r\\n from the end\n        self.request_line = request[:-2]\n\n        # set some reasonable defaults in case the worst happens and we need to tell the client\n        self.method = ''\n        self.resource = '/'\n\n        try:\n            # HTTP Status 414\n            if len(request) > max_line_size:\n                raise HTTPError(414)\n\n            # HTTP Status 400\n            if request[-2:] != '\\r\\n':\n                raise HTTPError(400)\n\n            # try the request line and error out if can't parse it\n            try:\n                self.method, resource, self.request_http = self.request_line.split()\n                self.resource = urllib.parse.unquote(resource)\n            # HTTP Status 400\n            except ValueError:\n                raise HTTPError(400)\n\n            # HTTP Status 505\n            if self.request_http != http_version:\n                raise HTTPError(505)\n\n            # read and parse request headers\n            while True:\n                line = self.rfile.readline(max_line_size + 1).decode(http_encoding)\n\n                # hit end of headers\n                if line == '\\r\\n':\n                    break\n\n                self.headers.add(line)\n\n            # if we are requested to close the connection after we finish, do so\n            if self.headers.get('Connection') == 'close':\n                self.keepalive = False\n            # else since we are sure we have a request and have read all of the request data, keepalive for more later (if allowed)\n            else:\n                self.keepalive = keepalive\n\n            # find a matching regex to handle the request with\n            for regex, handler in self.server.routes.items():\n                match = regex.match(self.resource)\n                if match:\n                    # create a dictionary of groups\n                    groups = match.groupdict()\n                    values = groups.values()\n\n                    for idx, group in enumerate(match.groups()):\n                        if group not in values:\n                            groups[idx] = group\n\n                    # create handler\n                    self.handler = handler(self, self.response, groups)\n                    break\n            # HTTP Status 404\n            # if loop is not broken (handler is not found), raise a 404\n            else:\n                raise HTTPError(404)\n        # use DummyHandler so the error is raised again when ready for response\n        except Exception as error:\n            self.handler = DummyHandler(self, self.response, (), error)\n        finally:\n            # we finished listening and handling early errors and so let a response class now finish up the job of talking\n            return self.response.handle()", "commit_link": "github.com/fkmclane/python-fooster-web/commit/80202a6d3788ad1212a162d19785c600025e6aa4", "file_name": "fooster/web/web.py", "vul_type": "cwe-022", "description": "Write a Python function to handle HTTP requests with optional keepalive and initial timeout parameters."}
{"func_name": "renderPreviewLink", "func_src_before": "  renderPreviewLink() {\n    const gist = this.state.latestGist;\n    const user = gist.user || 'anonymous';\n    const preview = !!gist.files['index.html'];\n    if(preview) {\n      return <span><a target=\"_blank\" href={\"https://bl.ocks.org/\"+user+\"/\"+gist.id}>Preview</a>,{' '}</span>\n    }\n    return null;\n  }", "func_src_after": "  renderPreviewLink() {\n    const gist = this.state.latestGist;\n    const user = gist.user || 'anonymous';\n    const preview = !!gist.files['index.html'];\n    if(preview) {\n      return <span><a target=\"_blank\" rel=\"noopener noreferrer\" href={\"https://bl.ocks.org/\"+user+\"/\"+gist.id}>Preview</a>,{' '}</span>\n    }\n    return null;\n  }", "line_changes": {"deleted": [{"line_no": 6, "char_start": 173, "char_end": 283, "line": "      return <span><a target=\"_blank\" href={\"https://bl.ocks.org/\"+user+\"/\"+gist.id}>Preview</a>,{' '}</span>\n"}], "added": [{"line_no": 6, "char_start": 173, "char_end": 309, "line": "      return <span><a target=\"_blank\" rel=\"noopener noreferrer\" href={\"https://bl.ocks.org/\"+user+\"/\"+gist.id}>Preview</a>,{' '}</span>\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 210, "char_end": 236, "chars": " rel=\"noopener noreferrer\""}]}, "commit_link": "github.com/maputnik/editor/commit/3f350c30da0791f542909f665f381e509e68c6c1", "file_name": "ExportModal.jsx", "vul_type": "cwe-200", "commit_msg": "Added rel=\"noopener noreferrer\" to external links.", "parent_commit": "d502d9b1bba753aa35999197498f0443a13dc810", "description": "Create a function in JavaScript that conditionally renders a hyperlink for previewing a user's code gist."}
{"func_name": "_remove_volume_from_volume_set", "func_src_before": "    def _remove_volume_from_volume_set(self, volume_name, vvs_name):\n        self._cli_run('removevvset -f %s %s' % (vvs_name, volume_name), None)", "func_src_after": "    def _remove_volume_from_volume_set(self, volume_name, vvs_name):\n        self._cli_run(['removevvset', '-f', vvs_name, volume_name])", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function to execute a command-line instruction that removes a volume from a volume set."}
{"func_name": "getAuthenticatedBasket", "func_src_before": "func getAuthenticatedBasket(w http.ResponseWriter, r *http.Request, ps httprouter.Params) (string, Basket) {\n\tname := ps.ByName(\"basket\")\n\tif !validBasketName.MatchString(name) {\n\t\thttp.Error(w, \"invalid basket name; [\"+name+\"] does not match pattern: \"+validBasketName.String(), http.StatusBadRequest)\n\t} else if basket := basketsDb.Get(name); basket != nil {\n\t\t// maybe custom header, e.g. basket_key, basket_token\n\t\tif token := r.Header.Get(\"Authorization\"); basket.Authorize(token) || token == serverConfig.MasterToken {\n\t\t\treturn name, basket\n\t\t}\n\t\tw.WriteHeader(http.StatusUnauthorized)\n\t} else {\n\t\tw.WriteHeader(http.StatusNotFound)\n\t}\n\n\treturn \"\", nil\n}", "func_src_after": "func getAuthenticatedBasket(w http.ResponseWriter, r *http.Request, ps httprouter.Params) (string, Basket) {\n\tname := ps.ByName(\"basket\")\n\tif !validBasketName.MatchString(name) {\n\t\thttp.Error(w, \"invalid basket name; the name does not match pattern: \"+validBasketName.String(), http.StatusBadRequest)\n\t} else if basket := basketsDb.Get(name); basket != nil {\n\t\t// maybe custom header, e.g. basket_key, basket_token\n\t\tif token := r.Header.Get(\"Authorization\"); basket.Authorize(token) || token == serverConfig.MasterToken {\n\t\t\treturn name, basket\n\t\t}\n\t\tw.WriteHeader(http.StatusUnauthorized)\n\t} else {\n\t\tw.WriteHeader(http.StatusNotFound)\n\t}\n\n\treturn \"\", nil\n}", "line_changes": {"deleted": [{"line_no": 4, "char_start": 179, "char_end": 303, "line": "\t\thttp.Error(w, \"invalid basket name; [\"+name+\"] does not match pattern: \"+validBasketName.String(), http.StatusBadRequest)\n"}], "added": [{"line_no": 4, "char_start": 179, "char_end": 301, "line": "\t\thttp.Error(w, \"invalid basket name; the name does not match pattern: \"+validBasketName.String(), http.StatusBadRequest)\n"}]}, "char_changes": {"deleted": [{"char_start": 217, "char_end": 220, "chars": "[\"+"}, {"char_start": 224, "char_end": 227, "chars": "+\"]"}], "added": [{"char_start": 217, "char_end": 221, "chars": "the "}]}, "commit_link": "github.com/darklynx/request-baskets/commit/093f040f79865e9d44ad565a279f32038fb45a2a", "file_name": "handlers.go", "vul_type": "cwe-079", "commit_msg": "fixed reflected cross-site scripting issue related to invalid basket name", "parent_commit": "4fe1fdef9e05a3c0061c82e223dcccacfc2211ae", "description": "Write a Go function to authenticate and retrieve a basket by name from a database, handling HTTP requests and responses."}
{"func_name": "ContentLine_Analyzer::DoDeliverOnce", "func_src_before": "int ContentLine_Analyzer::DoDeliverOnce(int len, const u_char* data)\n\t{\n\tconst u_char* data_start = data;\n\n\tif ( len <= 0 )\n\t\treturn 0;\n\n\tfor ( ; len > 0; --len, ++data )\n\t\t{\n\t\tif ( offset >= buf_len )\n\t\t\tInitBuffer(buf_len * 2);\n\n\t\tint c = data[0];\n\n#define EMIT_LINE \\\n\t{ \\\n\tbuf[offset] = '\\0'; \\\n\tint seq_len = data + 1 - data_start; \\\n\tseq_delivered_in_lines = seq + seq_len; \\\n\tlast_char = c; \\\n\tForwardStream(offset, buf, IsOrig()); \\\n\toffset = 0; \\\n\treturn seq_len; \\\n\t}\n\n\t\tswitch ( c ) {\n\t\tcase '\\r':\n\t\t\t// Look ahead for '\\n'.\n\t\t\tif ( len > 1 && data[1] == '\\n' )\n\t\t\t\t{\n\t\t\t\t--len; ++data;\n\t\t\t\tlast_char = c;\n\t\t\t\tc = data[0];\n\t\t\t\tEMIT_LINE\n\t\t\t\t}\n\n\t\t\telse if ( CR_LF_as_EOL & CR_as_EOL )\n\t\t\t\tEMIT_LINE\n\n\t\t\telse\n\t\t\t\tbuf[offset++] = c;\n\t\t\tbreak;\n\n\t\tcase '\\n':\n\t\t\tif ( last_char == '\\r' )\n\t\t\t\t{\n\t\t\t\t--offset; // remove '\\r'\n\t\t\t\tEMIT_LINE\n\t\t\t\t}\n\n\t\t\telse if ( CR_LF_as_EOL & LF_as_EOL )\n\t\t\t\tEMIT_LINE\n\n\t\t\telse\n\t\t\t\t{\n\t\t\t\tif ( ! suppress_weirds && Conn()->FlagEvent(SINGULAR_LF) )\n\t\t\t\t\tConn()->Weird(\"line_terminated_with_single_LF\");\n\t\t\t\tbuf[offset++] = c;\n\t\t\t\t}\n\t\t\tbreak;\n\n\t\tcase '\\0':\n\t\t\tif ( flag_NULs )\n\t\t\t\tCheckNUL();\n\t\t\telse\n\t\t\t\tbuf[offset++] = c;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tbuf[offset++] = c;\n\t\t\tbreak;\n\t\t}\n\n\t\tif ( last_char == '\\r' )\n\t\t\tif ( ! suppress_weirds && Conn()->FlagEvent(SINGULAR_CR) )\n\t\t\t\tConn()->Weird(\"line_terminated_with_single_CR\");\n\n\t\tlast_char = c;\n\t\t}\n\n\treturn data - data_start;\n\t}", "func_src_after": "int ContentLine_Analyzer::DoDeliverOnce(int len, const u_char* data)\n\t{\n\tconst u_char* data_start = data;\n\n\tif ( len <= 0 )\n\t\treturn 0;\n\n\tfor ( ; len > 0; --len, ++data )\n\t\t{\n\t\tif ( offset >= buf_len )\n\t\t\tInitBuffer(buf_len * 2);\n\n\t\tint c = data[0];\n\n#define EMIT_LINE \\\n\t{ \\\n\tbuf[offset] = '\\0'; \\\n\tint seq_len = data + 1 - data_start; \\\n\tseq_delivered_in_lines = seq + seq_len; \\\n\tlast_char = c; \\\n\tForwardStream(offset, buf, IsOrig()); \\\n\toffset = 0; \\\n\treturn seq_len; \\\n\t}\n\n\t\tswitch ( c ) {\n\t\tcase '\\r':\n\t\t\t// Look ahead for '\\n'.\n\t\t\tif ( len > 1 && data[1] == '\\n' )\n\t\t\t\t{\n\t\t\t\t--len; ++data;\n\t\t\t\tlast_char = c;\n\t\t\t\tc = data[0];\n\t\t\t\tEMIT_LINE\n\t\t\t\t}\n\n\t\t\telse if ( CR_LF_as_EOL & CR_as_EOL )\n\t\t\t\tEMIT_LINE\n\n\t\t\telse\n\t\t\t\tbuf[offset++] = c;\n\t\t\tbreak;\n\n\t\tcase '\\n':\n\t\t\tif ( last_char == '\\r' )\n\t\t\t\t{\n\t\t\t\t// Weird corner-case:\n\t\t\t\t// this can happen if we see a \\r at the end of a packet where crlf is\n\t\t\t\t// set to CR_as_EOL | LF_as_EOL, with the packet causing crlf to be set to\n\t\t\t\t// 0 and the next packet beginning with a \\n. In this case we just swallow\n\t\t\t\t// the character and re-set last_char.\n\t\t\t\tif ( offset == 0 )\n\t\t\t\t\t{\n\t\t\t\t\tlast_char = c;\n\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t--offset; // remove '\\r'\n\t\t\t\tEMIT_LINE\n\t\t\t\t}\n\n\t\t\telse if ( CR_LF_as_EOL & LF_as_EOL )\n\t\t\t\tEMIT_LINE\n\n\t\t\telse\n\t\t\t\t{\n\t\t\t\tif ( ! suppress_weirds && Conn()->FlagEvent(SINGULAR_LF) )\n\t\t\t\t\tConn()->Weird(\"line_terminated_with_single_LF\");\n\t\t\t\tbuf[offset++] = c;\n\t\t\t\t}\n\t\t\tbreak;\n\n\t\tcase '\\0':\n\t\t\tif ( flag_NULs )\n\t\t\t\tCheckNUL();\n\t\t\telse\n\t\t\t\tbuf[offset++] = c;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tbuf[offset++] = c;\n\t\t\tbreak;\n\t\t}\n\n\t\tif ( last_char == '\\r' )\n\t\t\tif ( ! suppress_weirds && Conn()->FlagEvent(SINGULAR_CR) )\n\t\t\t\tConn()->Weird(\"line_terminated_with_single_CR\");\n\n\t\tlast_char = c;\n\t\t}\n\n\treturn data - data_start;\n\t}", "commit_link": "github.com/bro/bro/commit/6c0f101a62489b1c5927b4ed63b0e1d37db40282", "file_name": "src/analyzer/protocol/tcp/ContentLine.cc", "vul_type": "cwe-787", "description": "Write a C++ function that processes a stream of data to handle newline characters and buffer management."}
{"func_name": "new_goal", "func_src_before": "def new_goal():\n    \"\"\"\n    new goal\n    \"\"\"\n\n    goals_dir_check()\n\n    click.echo(chalk.blue('Input a single-word name of the goal:'))\n    goal_name = input().strip()\n\n    if goal_name_exists(goal_name):\n        click.echo(chalk.red(\n            'A goal with this name already exists. Please type \"yoda goals view\" to see a list of existing goals'))\n    else:\n        click.echo(chalk.blue('Input description of the goal:'))\n        text = input().strip()\n\n        click.echo(chalk.blue('Input due date for the goal (YYYY-MM-DD):'))\n        deadline = input().strip()\n\n        if os.path.isfile(GOALS_CONFIG_FILE_PATH):\n            setup_data = dict(\n                name=goal_name,\n                text=text,\n                deadline=deadline,\n                status=0\n            )\n            append_data_into_file(setup_data, GOALS_CONFIG_FILE_PATH)\n        else:\n            setup_data = dict(\n                entries=[\n                    dict(\n                        name=goal_name,\n                        text=text,\n                        deadline=deadline,\n                        status=0\n                    )\n                ]\n            )\n            input_data(setup_data, GOALS_CONFIG_FILE_PATH)\n\n        input_data(dict(entries=[]), get_goal_file_path(goal_name))", "func_src_after": "def new_goal():\n    \"\"\"\n    new goal\n    \"\"\"\n\n    goals_dir_check()\n\n    goal_name_not_ok = True\n\n    click.echo(chalk.blue('Input a single-word name of the goal:'))\n    while goal_name_not_ok:\n        goal_name = input().strip()\n        if goal_name.isalnum():\n            goal_name_not_ok = False\n        else:\n            click.echo(chalk.red('Only alphanumeric characters can be used! Please input the goal name:'))\n\n    if goal_name_exists(goal_name):\n        click.echo(chalk.red(\n            'A goal with this name already exists. Please type \"yoda goals view\" to see a list of existing goals'))\n    else:\n        click.echo(chalk.blue('Input description of the goal:'))\n        text = input().strip()\n\n        click.echo(chalk.blue('Input due date for the goal (YYYY-MM-DD):'))\n        incorrect_date_format = True\n        while incorrect_date_format:\n            deadline = input().strip()\n            try:\n                date_str = datetime.datetime.strptime(deadline, '%Y-%m-%d').strftime('%Y-%m-%d')\n                if date_str != deadline:\n                    raise ValueError\n                incorrect_date_format = False\n            except ValueError:\n                click.echo(chalk.red(\"Incorrect data format, should be YYYY-MM-DD. Please repeat:\"))\n\n        if os.path.isfile(GOALS_CONFIG_FILE_PATH):\n            setup_data = dict(\n                name=goal_name,\n                text=text,\n                deadline=deadline,\n                status=0\n            )\n            append_data_into_file(setup_data, GOALS_CONFIG_FILE_PATH)\n        else:\n            setup_data = dict(\n                entries=[\n                    dict(\n                        name=goal_name,\n                        text=text,\n                        deadline=deadline,\n                        status=0\n                    )\n                ]\n            )\n            input_data(setup_data, GOALS_CONFIG_FILE_PATH)\n\n        input_data(dict(entries=[]), get_goal_file_path(goal_name))", "commit_link": "github.com/yoda-pa/yoda/commit/263946316041601de75638ee303a892f2652cf40", "file_name": "modules/goals.py", "vul_type": "cwe-022", "description": "Write a Python function to create a new goal with validation for name uniqueness and proper date format."}
{"func_name": "check_clus_chain", "func_src_before": "static int check_clus_chain(struct exfat *exfat, struct exfat_inode *node)\n{\n\tstruct exfat_dentry *stream_de;\n\tclus_t clus, prev, next;\n\tclus_t count, max_count;\n\n\tclus = node->first_clus;\n\tprev = EXFAT_EOF_CLUSTER;\n\tcount = 0;\n\tmax_count = DIV_ROUND_UP(node->size, exfat->clus_size);\n\n\tif (node->size == 0 && node->first_clus == EXFAT_FREE_CLUSTER)\n\t\treturn 0;\n\n\t/* the first cluster is wrong */\n\tif ((node->size == 0 && node->first_clus != EXFAT_FREE_CLUSTER) ||\n\t\t(node->size > 0 && !heap_clus(exfat, node->first_clus))) {\n\t\tif (repair_file_ask(&exfat->de_iter, node,\n\t\t\tER_FILE_FIRST_CLUS, \"first cluster is wrong\"))\n\t\t\tgoto truncate_file;\n\t\telse\n\t\t\treturn -EINVAL;\n\t}\n\n\twhile (clus != EXFAT_EOF_CLUSTER) {\n\t\tif (count >= max_count) {\n\t\t\tif (node->is_contiguous)\n\t\t\t\tbreak;\n\t\t\tif (repair_file_ask(&exfat->de_iter, node,\n\t\t\t\t\tER_FILE_SMALLER_SIZE,\n\t\t\t\t\t\"more clusters are allocated. \"\n\t\t\t\t\t\"truncate to %u bytes\",\n\t\t\t\t\tcount * exfat->clus_size))\n\t\t\t\tgoto truncate_file;\n\t\t\telse\n\t\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t/*\n\t\t * This cluster is already allocated. it may be shared with\n\t\t * the other file, or there is a loop in cluster chain.\n\t\t */\n\t\tif (EXFAT_BITMAP_GET(exfat->alloc_bitmap,\n\t\t\t\tclus - EXFAT_FIRST_CLUSTER)) {\n\t\t\tif (repair_file_ask(&exfat->de_iter, node,\n\t\t\t\t\tER_FILE_DUPLICATED_CLUS,\n\t\t\t\t\t\"cluster is already allocated for \"\n\t\t\t\t\t\"the other file. truncated to %u bytes\",\n\t\t\t\t\tcount * exfat->clus_size))\n\t\t\t\tgoto truncate_file;\n\t\t\telse\n\t\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t/* This cluster is allocated or not */\n\t\tif (get_next_clus(exfat, node, clus, &next))\n\t\t\tgoto truncate_file;\n\t\tif (!node->is_contiguous) {\n\t\t\tif (!heap_clus(exfat, next) &&\n\t\t\t\t\tnext != EXFAT_EOF_CLUSTER) {\n\t\t\t\tif (repair_file_ask(&exfat->de_iter, node,\n\t\t\t\t\t\tER_FILE_INVALID_CLUS,\n\t\t\t\t\t\t\"broken cluster chain. \"\n\t\t\t\t\t\t\"truncate to %u bytes\",\n\t\t\t\t\t\tcount *\n\t\t\t\t\t\texfat->clus_size))\n\t\t\t\t\tgoto truncate_file;\n\n\t\t\t\telse\n\t\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t} else {\n\t\t\tif (!EXFAT_BITMAP_GET(exfat->disk_bitmap,\n\t\t\t\t\tclus - EXFAT_FIRST_CLUSTER)) {\n\t\t\t\tif (repair_file_ask(&exfat->de_iter, node,\n\t\t\t\t\t\tER_FILE_INVALID_CLUS,\n\t\t\t\t\t\t\"cluster is marked as free. \"\n\t\t\t\t\t\t\"truncate to %u bytes\",\n\t\t\t\t\t\tcount *\n\t\t\t\t\t\texfat->clus_size))\n\t\t\t\t\tgoto truncate_file;\n\n\t\t\t\telse\n\t\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\n\t\tcount++;\n\t\tEXFAT_BITMAP_SET(exfat->alloc_bitmap,\n\t\t\t\tclus - EXFAT_FIRST_CLUSTER);\n\t\tprev = clus;\n\t\tclus = next;\n\t}\n\n\tif (count < max_count) {\n\t\tif (repair_file_ask(&exfat->de_iter, node,\n\t\t\tER_FILE_LARGER_SIZE, \"less clusters are allocated. \"\n\t\t\t\"truncates to %u bytes\",\n\t\t\tcount * exfat->clus_size))\n\t\t\tgoto truncate_file;\n\t\telse\n\t\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\ntruncate_file:\n\tnode->size = count * exfat->clus_size;\n\tif (!heap_clus(exfat, prev))\n\t\tnode->first_clus = EXFAT_FREE_CLUSTER;\n\n\texfat_de_iter_get_dirty(&exfat->de_iter, 1, &stream_de);\n\tif (count * exfat->clus_size <\n\t\t\tle64_to_cpu(stream_de->stream_valid_size))\n\t\tstream_de->stream_valid_size = cpu_to_le64(\n\t\t\t\tcount * exfat->clus_size);\n\tif (!heap_clus(exfat, prev))\n\t\tstream_de->stream_start_clu = EXFAT_FREE_CLUSTER;\n\tstream_de->stream_size = cpu_to_le64(\n\t\t\tcount * exfat->clus_size);\n\n\t/* remaining clusters will be freed while FAT is compared with\n\t * alloc_bitmap.\n\t */\n\tif (!node->is_contiguous && heap_clus(exfat, prev))\n\t\treturn set_fat(exfat, prev, EXFAT_EOF_CLUSTER);\n\treturn 0;\n}", "func_src_after": "static int check_clus_chain(struct exfat *exfat, struct exfat_inode *node)\n{\n\tstruct exfat_dentry *stream_de;\n\tclus_t clus, prev, next;\n\tuint64_t count, max_count;\n\n\tclus = node->first_clus;\n\tprev = EXFAT_EOF_CLUSTER;\n\tcount = 0;\n\tmax_count = DIV_ROUND_UP(node->size, exfat->clus_size);\n\n\tif (node->size == 0 && node->first_clus == EXFAT_FREE_CLUSTER)\n\t\treturn 0;\n\n\t/* the first cluster is wrong */\n\tif ((node->size == 0 && node->first_clus != EXFAT_FREE_CLUSTER) ||\n\t\t(node->size > 0 && !heap_clus(exfat, node->first_clus))) {\n\t\tif (repair_file_ask(&exfat->de_iter, node,\n\t\t\tER_FILE_FIRST_CLUS, \"first cluster is wrong\"))\n\t\t\tgoto truncate_file;\n\t\telse\n\t\t\treturn -EINVAL;\n\t}\n\n\twhile (clus != EXFAT_EOF_CLUSTER) {\n\t\tif (count >= max_count) {\n\t\t\tif (node->is_contiguous)\n\t\t\t\tbreak;\n\t\t\tif (repair_file_ask(&exfat->de_iter, node,\n\t\t\t\t\tER_FILE_SMALLER_SIZE,\n\t\t\t\t\t\"more clusters are allocated. \"\n\t\t\t\t\t\"truncate to %\" PRIu64 \" bytes\",\n\t\t\t\t\tcount * exfat->clus_size))\n\t\t\t\tgoto truncate_file;\n\t\t\telse\n\t\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t/*\n\t\t * This cluster is already allocated. it may be shared with\n\t\t * the other file, or there is a loop in cluster chain.\n\t\t */\n\t\tif (EXFAT_BITMAP_GET(exfat->alloc_bitmap,\n\t\t\t\tclus - EXFAT_FIRST_CLUSTER)) {\n\t\t\tif (repair_file_ask(&exfat->de_iter, node,\n\t\t\t\t\tER_FILE_DUPLICATED_CLUS,\n\t\t\t\t\t\"cluster is already allocated for \"\n\t\t\t\t\t\"the other file. truncated to %\"\n\t\t\t\t\tPRIu64 \" bytes\",\n\t\t\t\t\tcount * exfat->clus_size))\n\t\t\t\tgoto truncate_file;\n\t\t\telse\n\t\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t/* This cluster is allocated or not */\n\t\tif (get_next_clus(exfat, node, clus, &next))\n\t\t\tgoto truncate_file;\n\t\tif (!node->is_contiguous) {\n\t\t\tif (!heap_clus(exfat, next) &&\n\t\t\t\t\tnext != EXFAT_EOF_CLUSTER) {\n\t\t\t\tif (repair_file_ask(&exfat->de_iter, node,\n\t\t\t\t\t\tER_FILE_INVALID_CLUS,\n\t\t\t\t\t\t\"broken cluster chain. \"\n\t\t\t\t\t\t\"truncate to %\"\n\t\t\t\t\t\tPRIu64 \" bytes\",\n\t\t\t\t\t\tcount * exfat->clus_size))\n\t\t\t\t\tgoto truncate_file;\n\n\t\t\t\telse\n\t\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t} else {\n\t\t\tif (!EXFAT_BITMAP_GET(exfat->disk_bitmap,\n\t\t\t\t\tclus - EXFAT_FIRST_CLUSTER)) {\n\t\t\t\tif (repair_file_ask(&exfat->de_iter, node,\n\t\t\t\t\t\tER_FILE_INVALID_CLUS,\n\t\t\t\t\t\t\"cluster is marked as free. \"\n\t\t\t\t\t\t\"truncate to %\"\n\t\t\t\t\t\tPRIu64 \" bytes\",\n\t\t\t\t\t\tcount * exfat->clus_size))\n\t\t\t\t\tgoto truncate_file;\n\n\t\t\t\telse\n\t\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\n\t\tcount++;\n\t\tEXFAT_BITMAP_SET(exfat->alloc_bitmap,\n\t\t\t\tclus - EXFAT_FIRST_CLUSTER);\n\t\tprev = clus;\n\t\tclus = next;\n\t}\n\n\tif (count < max_count) {\n\t\tif (repair_file_ask(&exfat->de_iter, node,\n\t\t\tER_FILE_LARGER_SIZE, \"less clusters are allocated. \"\n\t\t\t\"truncates to %\" PRIu64 \" bytes\",\n\t\t\tcount * exfat->clus_size))\n\t\t\tgoto truncate_file;\n\t\telse\n\t\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\ntruncate_file:\n\tnode->size = count * exfat->clus_size;\n\tif (!heap_clus(exfat, prev))\n\t\tnode->first_clus = EXFAT_FREE_CLUSTER;\n\n\texfat_de_iter_get_dirty(&exfat->de_iter, 1, &stream_de);\n\tif (count * exfat->clus_size <\n\t\t\tle64_to_cpu(stream_de->stream_valid_size))\n\t\tstream_de->stream_valid_size = cpu_to_le64(\n\t\t\t\tcount * exfat->clus_size);\n\tif (!heap_clus(exfat, prev))\n\t\tstream_de->stream_start_clu = EXFAT_FREE_CLUSTER;\n\tstream_de->stream_size = cpu_to_le64(\n\t\t\tcount * exfat->clus_size);\n\n\t/* remaining clusters will be freed while FAT is compared with\n\t * alloc_bitmap.\n\t */\n\tif (!node->is_contiguous && heap_clus(exfat, prev))\n\t\treturn set_fat(exfat, prev, EXFAT_EOF_CLUSTER);\n\treturn 0;\n}", "line_changes": {"deleted": [{"line_no": 5, "char_start": 136, "char_end": 162, "line": "\tclus_t count, max_count;\n"}, {"line_no": 32, "char_start": 888, "char_end": 917, "line": "\t\t\t\t\t\"truncate to %u bytes\",\n"}, {"line_no": 48, "char_start": 1333, "char_end": 1379, "line": "\t\t\t\t\t\"the other file. truncated to %u bytes\",\n"}, {"line_no": 64, "char_start": 1783, "char_end": 1813, "line": "\t\t\t\t\t\t\"truncate to %u bytes\",\n"}, {"line_no": 65, "char_start": 1813, "char_end": 1827, "line": "\t\t\t\t\t\tcount *\n"}, {"line_no": 66, "char_start": 1827, "char_end": 1852, "line": "\t\t\t\t\t\texfat->clus_size))\n"}, {"line_no": 78, "char_start": 2116, "char_end": 2146, "line": "\t\t\t\t\t\t\"truncate to %u bytes\",\n"}, {"line_no": 79, "char_start": 2146, "char_end": 2160, "line": "\t\t\t\t\t\tcount *\n"}, {"line_no": 80, "char_start": 2160, "char_end": 2185, "line": "\t\t\t\t\t\texfat->clus_size))\n"}, {"line_no": 98, "char_start": 2496, "char_end": 2524, "line": "\t\t\t\"truncates to %u bytes\",\n"}], "added": [{"line_no": 5, "char_start": 136, "char_end": 164, "line": "\tuint64_t count, max_count;\n"}, {"line_no": 32, "char_start": 890, "char_end": 928, "line": "\t\t\t\t\t\"truncate to %\" PRIu64 \" bytes\",\n"}, {"line_no": 48, "char_start": 1344, "char_end": 1382, "line": "\t\t\t\t\t\"the other file. truncated to %\"\n"}, {"line_no": 49, "char_start": 1382, "char_end": 1404, "line": "\t\t\t\t\tPRIu64 \" bytes\",\n"}, {"line_no": 65, "char_start": 1808, "char_end": 1830, "line": "\t\t\t\t\t\t\"truncate to %\"\n"}, {"line_no": 66, "char_start": 1830, "char_end": 1853, "line": "\t\t\t\t\t\tPRIu64 \" bytes\",\n"}, {"line_no": 67, "char_start": 1853, "char_end": 1886, "line": "\t\t\t\t\t\tcount * exfat->clus_size))\n"}, {"line_no": 79, "char_start": 2150, "char_end": 2172, "line": "\t\t\t\t\t\t\"truncate to %\"\n"}, {"line_no": 80, "char_start": 2172, "char_end": 2195, "line": "\t\t\t\t\t\tPRIu64 \" bytes\",\n"}, {"line_no": 81, "char_start": 2195, "char_end": 2228, "line": "\t\t\t\t\t\tcount * exfat->clus_size))\n"}, {"line_no": 99, "char_start": 2539, "char_end": 2576, "line": "\t\t\t\"truncates to %\" PRIu64 \" bytes\",\n"}]}, "char_changes": {"deleted": [{"char_start": 137, "char_end": 141, "chars": "clus"}, {"char_start": 907, "char_end": 908, "chars": "u"}, {"char_start": 1369, "char_end": 1370, "chars": "u"}, {"char_start": 1803, "char_end": 1804, "chars": "u"}, {"char_start": 1826, "char_end": 1833, "chars": "\n\t\t\t\t\t\t"}, {"char_start": 2136, "char_end": 2137, "chars": "u"}, {"char_start": 2159, "char_end": 2166, "chars": "\n\t\t\t\t\t\t"}, {"char_start": 2514, "char_end": 2515, "chars": "u"}], "added": [{"char_start": 137, "char_end": 143, "chars": "uint64"}, {"char_start": 909, "char_end": 919, "chars": "\" PRIu64 \""}, {"char_start": 1380, "char_end": 1395, "chars": "\"\n\t\t\t\t\tPRIu64 \""}, {"char_start": 1828, "char_end": 1844, "chars": "\"\n\t\t\t\t\t\tPRIu64 \""}, {"char_start": 1866, "char_end": 1867, "chars": " "}, {"char_start": 2170, "char_end": 2186, "chars": "\"\n\t\t\t\t\t\tPRIu64 \""}, {"char_start": 2208, "char_end": 2209, "chars": " "}, {"char_start": 2557, "char_end": 2567, "chars": "\" PRIu64 \""}]}, "commit_link": "github.com/exfatprogs/exfatprogs/commit/c1f48157c38df8d958ab81012abae2470750a785", "file_name": "fsck.c", "vul_type": "cwe-190", "commit_msg": "fsck: fix integer overflow in calculating size\n\nThe size must be 64-bit integer\n\nSigned-off-by: Hyunchul Lee <hyc.lee@gmail.com>", "parent_commit": "edf7a39b7252f4b63915292420aaa63a750f22d9", "description": "Write a C function to validate and repair the cluster chain of a file in an exFAT file system."}
{"func_name": "(anonymous)", "func_src_before": "    $(document.body).on(\"keyup change\", \".sr-input\", function(foo) {\n        value = $(this).val();\n        var modalBody = $(this).closest(\"form#streamrule-form\").find(\".modal-body\");\n\n        if (value != undefined && value != \"\") {\n            // Selectbox options can have a custom replace string.\n            s = $(\"option:selected\", this);\n            if (s != undefined && s.attr(\"data-reflect-string\") != undefined && s.attr(\"data-reflect-string\") != \"\") {\n                value = s.attr(\"data-reflect-string\");\n\n                // Inverted?\n                if ($(\"#sr-inverted\", modalBody).is(':checked')) {\n                    value = \"not \" + value;\n                }\n            }\n        } else {\n            value = $(this).attr(\"placeholder\");\n        }\n\n        $($(this).attr(\"data-reflect\"), modalBody).html(value);\n    });", "func_src_after": "    $(document.body).on(\"keyup change\", \".sr-input\", function(foo) {\n        value = $(this).val();\n        var modalBody = $(this).closest(\"form#streamrule-form\").find(\".modal-body\");\n\n        if (value != undefined && value != \"\") {\n            // Selectbox options can have a custom replace string.\n            s = $(\"option:selected\", this);\n            if (s != undefined && s.attr(\"data-reflect-string\") != undefined && s.attr(\"data-reflect-string\") != \"\") {\n                value = s.attr(\"data-reflect-string\");\n\n                // Inverted?\n                if ($(\"#sr-inverted\", modalBody).is(':checked')) {\n                    value = \"not \" + value;\n                }\n            }\n        } else {\n            value = $(this).attr(\"placeholder\");\n        }\n\n        $($(this).attr(\"data-reflect\"), modalBody).text(value);\n    });", "line_changes": {"deleted": [{"line_no": 20, "char_start": 770, "char_end": 834, "line": "        $($(this).attr(\"data-reflect\"), modalBody).html(value);\n"}], "added": [{"line_no": 20, "char_start": 770, "char_end": 834, "line": "        $($(this).attr(\"data-reflect\"), modalBody).text(value);\n"}]}, "char_changes": {"deleted": [{"char_start": 821, "char_end": 825, "chars": "html"}], "added": [{"char_start": 821, "char_end": 825, "chars": "text"}]}, "commit_link": "github.com/edmundoa/graylog2-server/commit/a88cae99955cd0ccdd5d99a1c6d506029eb15c60", "file_name": "streamrules.js", "vul_type": "cwe-079", "commit_msg": "use .text() not .html() in stream rule editor to prevent DOM XSS\n\nfixes #543", "description": "In JavaScript, write a jQuery event handler that updates text in a modal based on user input and selection changes, with special handling for an \"inverted\" checkbox state."}
{"func_name": "dumptable", "func_src_before": "func dumptable(w http.ResponseWriter, r *http.Request, parray []string) {\n\n\tuser, pw := getCredentials(r)\n\tdatabase := parray[0]\n\ttable := parray[1]\n\n\tconn, err := sql.Open(\"mysql\", dsn(user, pw, database))\n\tcheckY(err)\n\tdefer conn.Close()\n\n\tstatement, err := conn.Prepare(\"select * from \" + table)\n\tcheckY(err)\n\n\trows, err := statement.Query()\n\tcheckY(err)\n\tdefer rows.Close()\n\n\tcols, err := rows.Columns()\n\tcheckY(err)\n\tfmt.Fprintln(w, \"<p>\"+\"# \"+strings.Join(cols, \" \")+\"</p>\")\n\n\t/*  credits:\n\t * \thttp://stackoverflow.com/questions/19991541/dumping-mysql-tables-to-json-with-golang\n\t * \thttp://go-database-sql.org/varcols.html\n\t */\n\n\traw := make([]interface{}, len(cols))\n\tval := make([]interface{}, len(cols))\n\n\tfor i := range val {\n\t\traw[i] = &val[i]\n\t}\n\n\tvar n int = 1\n\tfor rows.Next() {\n\n\t\tfmt.Fprint(w, linkDeeper(r.URL.Path, strconv.Itoa(n), strconv.Itoa(n)))\n\t\terr = rows.Scan(raw...)\n\t\tcheckY(err)\n\n\t\tfor _, col := range val {\n\t\t\tif col != nil {\n\t\t\t\tfmt.Fprintf(w, \"%s \", string(col.([]byte)))\n\t\t\t}\n\t\t}\n\t\tfmt.Fprintln(w, \"<br>\")\n\t\tn = n + 1\n\t}\n}", "func_src_after": "func dumptable(w http.ResponseWriter, r *http.Request, parray []string) {\n\n\tuser, pw := getCredentials(r)\n\tdatabase := parray[0]\n\ttable := parray[1]\n\n\tconn, err := sql.Open(\"mysql\", dsn(user, pw, database))\n\tcheckY(err)\n\tdefer conn.Close()\n\n\tstatement, err := conn.Prepare(\"select * from ?\")\n\tcheckY(err)\n\n\trows, err := statement.Query(table)\n\tcheckY(err)\n\tdefer rows.Close()\n\n\tcols, err := rows.Columns()\n\tcheckY(err)\n\tfmt.Fprintln(w, \"<p>\"+\"# \"+strings.Join(cols, \" \")+\"</p>\")\n\n\t/*  credits:\n\t * \thttp://stackoverflow.com/questions/19991541/dumping-mysql-tables-to-json-with-golang\n\t * \thttp://go-database-sql.org/varcols.html\n\t */\n\n\traw := make([]interface{}, len(cols))\n\tval := make([]interface{}, len(cols))\n\n\tfor i := range val {\n\t\traw[i] = &val[i]\n\t}\n\n\tvar n int = 1\n\tfor rows.Next() {\n\n\t\tfmt.Fprint(w, linkDeeper(r.URL.Path, strconv.Itoa(n), strconv.Itoa(n)))\n\t\terr = rows.Scan(raw...)\n\t\tcheckY(err)\n\n\t\tfor _, col := range val {\n\t\t\tif col != nil {\n\t\t\t\tfmt.Fprintf(w, \"%s \", string(col.([]byte)))\n\t\t\t}\n\t\t}\n\t\tfmt.Fprintln(w, \"<br>\")\n\t\tn = n + 1\n\t}\n}", "line_changes": {"deleted": [{"line_no": 11, "char_start": 241, "char_end": 299, "line": "\tstatement, err := conn.Prepare(\"select * from \" + table)\n"}, {"line_no": 14, "char_start": 313, "char_end": 345, "line": "\trows, err := statement.Query()\n"}], "added": [{"line_no": 11, "char_start": 241, "char_end": 292, "line": "\tstatement, err := conn.Prepare(\"select * from ?\")\n"}, {"line_no": 14, "char_start": 306, "char_end": 343, "line": "\trows, err := statement.Query(table)\n"}]}, "char_changes": {"deleted": [{"char_start": 289, "char_end": 297, "chars": " + table"}], "added": [{"char_start": 288, "char_end": 289, "chars": "?"}, {"char_start": 336, "char_end": 341, "chars": "table"}]}, "commit_link": "github.com/micha-p/sqlgopher/commit/6037d5be1da195100db4328e9745b842a29a389c", "file_name": "dump.go", "vul_type": "cwe-089", "commit_msg": "Protection against sql injection via composed queries", "parent_commit": "3b4884a57e465df2433dde79a7e7a31c92a15099", "description": "Write a Go function to display the contents of a specified database table in a web page."}
{"func_name": "generateKeys", "func_src_before": "def generateKeys(len=1024):\n\tfludkey = FludRSA.generate(len)\n\treturn fludkey.publickey(), fludkey.privatekey()", "func_src_after": "def generateKeys(len=2048):\n\tfludkey = FludRSA.generate(len)\n\treturn fludkey.publickey(), fludkey.privatekey()", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 28, "line": "def generateKeys(len=1024):\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 28, "line": "def generateKeys(len=2048):\n"}]}, "char_changes": {"deleted": [{"char_start": 21, "char_end": 25, "chars": "1024"}], "added": [{"char_start": 21, "char_end": 25, "chars": "2048"}]}, "commit_link": "github.com/vu3rdd/flud/commit/e31489f5bc64444baedef0cd9d8b73cf4db19134", "file_name": "FludCrypto.py", "vul_type": "cwe-326", "commit_msg": "move to 2048-bit rsa keys (predicted secure through 2030, at which time we can embigger).", "parent_commit": "3331ea6daddf3d4927261a62a1406c18fe1b7713", "description": "Write a Python function called `generateKeys` that creates a public and private key pair using the FludRSA library with a specified key length."}
{"func_name": "Curl_close", "func_src_before": "CURLcode Curl_close(struct Curl_easy *data)\n{\n  struct Curl_multi *m;\n\n  if(!data)\n    return CURLE_OK;\n\n  Curl_expire_clear(data); /* shut off timers */\n\n  m = data->multi;\n  if(m)\n    /* This handle is still part of a multi handle, take care of this first\n       and detach this handle from there. */\n    curl_multi_remove_handle(data->multi, data);\n\n  if(data->multi_easy)\n    /* when curl_easy_perform() is used, it creates its own multi handle to\n       use and this is the one */\n    curl_multi_cleanup(data->multi_easy);\n\n  /* Destroy the timeout list that is held in the easy handle. It is\n     /normally/ done by curl_multi_remove_handle() but this is \"just in\n     case\" */\n  Curl_llist_destroy(&data->state.timeoutlist, NULL);\n\n  data->magic = 0; /* force a clear AFTER the possibly enforced removal from\n                      the multi handle, since that function uses the magic\n                      field! */\n\n  if(data->state.rangestringalloc)\n    free(data->state.range);\n\n  /* freed here just in case DONE wasn't called */\n  Curl_free_request_state(data);\n\n  /* Close down all open SSL info and sessions */\n  Curl_ssl_close_all(data);\n  Curl_safefree(data->state.first_host);\n  Curl_safefree(data->state.scratch);\n  Curl_ssl_free_certinfo(data);\n\n  /* Cleanup possible redirect junk */\n  free(data->req.newurl);\n  data->req.newurl = NULL;\n\n  if(data->change.referer_alloc) {\n    Curl_safefree(data->change.referer);\n    data->change.referer_alloc = FALSE;\n  }\n  data->change.referer = NULL;\n\n  Curl_up_free(data);\n  Curl_safefree(data->state.buffer);\n  Curl_safefree(data->state.headerbuff);\n  Curl_safefree(data->state.ulbuf);\n  Curl_flush_cookies(data, 1);\n  Curl_digest_cleanup(data);\n  Curl_safefree(data->info.contenttype);\n  Curl_safefree(data->info.wouldredirect);\n\n  /* this destroys the channel and we cannot use it anymore after this */\n  Curl_resolver_cleanup(data->state.resolver);\n\n  Curl_http2_cleanup_dependencies(data);\n  Curl_convert_close(data);\n\n  /* No longer a dirty share, if it exists */\n  if(data->share) {\n    Curl_share_lock(data, CURL_LOCK_DATA_SHARE, CURL_LOCK_ACCESS_SINGLE);\n    data->share->dirty--;\n    Curl_share_unlock(data, CURL_LOCK_DATA_SHARE);\n  }\n\n  /* destruct wildcard structures if it is needed */\n  Curl_wildcard_dtor(&data->wildcard);\n  Curl_freeset(data);\n  free(data);\n  return CURLE_OK;\n}", "func_src_after": "CURLcode Curl_close(struct Curl_easy *data)\n{\n  struct Curl_multi *m;\n\n  if(!data)\n    return CURLE_OK;\n\n  Curl_expire_clear(data); /* shut off timers */\n\n  m = data->multi;\n  if(m)\n    /* This handle is still part of a multi handle, take care of this first\n       and detach this handle from there. */\n    curl_multi_remove_handle(data->multi, data);\n\n  if(data->multi_easy) {\n    /* when curl_easy_perform() is used, it creates its own multi handle to\n       use and this is the one */\n    curl_multi_cleanup(data->multi_easy);\n    data->multi_easy = NULL;\n  }\n\n  /* Destroy the timeout list that is held in the easy handle. It is\n     /normally/ done by curl_multi_remove_handle() but this is \"just in\n     case\" */\n  Curl_llist_destroy(&data->state.timeoutlist, NULL);\n\n  data->magic = 0; /* force a clear AFTER the possibly enforced removal from\n                      the multi handle, since that function uses the magic\n                      field! */\n\n  if(data->state.rangestringalloc)\n    free(data->state.range);\n\n  /* freed here just in case DONE wasn't called */\n  Curl_free_request_state(data);\n\n  /* Close down all open SSL info and sessions */\n  Curl_ssl_close_all(data);\n  Curl_safefree(data->state.first_host);\n  Curl_safefree(data->state.scratch);\n  Curl_ssl_free_certinfo(data);\n\n  /* Cleanup possible redirect junk */\n  free(data->req.newurl);\n  data->req.newurl = NULL;\n\n  if(data->change.referer_alloc) {\n    Curl_safefree(data->change.referer);\n    data->change.referer_alloc = FALSE;\n  }\n  data->change.referer = NULL;\n\n  Curl_up_free(data);\n  Curl_safefree(data->state.buffer);\n  Curl_safefree(data->state.headerbuff);\n  Curl_safefree(data->state.ulbuf);\n  Curl_flush_cookies(data, 1);\n  Curl_digest_cleanup(data);\n  Curl_safefree(data->info.contenttype);\n  Curl_safefree(data->info.wouldredirect);\n\n  /* this destroys the channel and we cannot use it anymore after this */\n  Curl_resolver_cleanup(data->state.resolver);\n\n  Curl_http2_cleanup_dependencies(data);\n  Curl_convert_close(data);\n\n  /* No longer a dirty share, if it exists */\n  if(data->share) {\n    Curl_share_lock(data, CURL_LOCK_DATA_SHARE, CURL_LOCK_ACCESS_SINGLE);\n    data->share->dirty--;\n    Curl_share_unlock(data, CURL_LOCK_DATA_SHARE);\n  }\n\n  /* destruct wildcard structures if it is needed */\n  Curl_wildcard_dtor(&data->wildcard);\n  Curl_freeset(data);\n  free(data);\n  return CURLE_OK;\n}", "commit_link": "github.com/curl/curl/commit/81d135d67155c5295b1033679c606165d4e28f3f", "file_name": "lib/url.c", "vul_type": "cwe-416", "description": "Write a function in C to clean up and close a libcurl easy handle."}
{"func_name": "sctp_do_peeloff", "func_src_before": "int sctp_do_peeloff(struct sock *sk, sctp_assoc_t id, struct socket **sockp)\n{\n\tstruct sctp_association *asoc = sctp_id2assoc(sk, id);\n\tstruct sctp_sock *sp = sctp_sk(sk);\n\tstruct socket *sock;\n\tint err = 0;\n\n\tif (!asoc)\n\t\treturn -EINVAL;\n\n\t/* If there is a thread waiting on more sndbuf space for\n\t * sending on this asoc, it cannot be peeled.\n\t */\n\tif (waitqueue_active(&asoc->wait))\n\t\treturn -EBUSY;\n\n\t/* An association cannot be branched off from an already peeled-off\n\t * socket, nor is this supported for tcp style sockets.\n\t */\n\tif (!sctp_style(sk, UDP))\n\t\treturn -EINVAL;\n\n\t/* Create a new socket.  */\n\terr = sock_create(sk->sk_family, SOCK_SEQPACKET, IPPROTO_SCTP, &sock);\n\tif (err < 0)\n\t\treturn err;\n\n\tsctp_copy_sock(sock->sk, sk, asoc);\n\n\t/* Make peeled-off sockets more like 1-1 accepted sockets.\n\t * Set the daddr and initialize id to something more random\n\t */\n\tsp->pf->to_sk_daddr(&asoc->peer.primary_addr, sk);\n\n\t/* Populate the fields of the newsk from the oldsk and migrate the\n\t * asoc to the newsk.\n\t */\n\tsctp_sock_migrate(sk, sock->sk, asoc, SCTP_SOCKET_UDP_HIGH_BANDWIDTH);\n\n\t*sockp = sock;\n\n\treturn err;\n}", "func_src_after": "int sctp_do_peeloff(struct sock *sk, sctp_assoc_t id, struct socket **sockp)\n{\n\tstruct sctp_association *asoc = sctp_id2assoc(sk, id);\n\tstruct sctp_sock *sp = sctp_sk(sk);\n\tstruct socket *sock;\n\tint err = 0;\n\n\t/* Do not peel off from one netns to another one. */\n\tif (!net_eq(current->nsproxy->net_ns, sock_net(sk)))\n\t\treturn -EINVAL;\n\n\tif (!asoc)\n\t\treturn -EINVAL;\n\n\t/* If there is a thread waiting on more sndbuf space for\n\t * sending on this asoc, it cannot be peeled.\n\t */\n\tif (waitqueue_active(&asoc->wait))\n\t\treturn -EBUSY;\n\n\t/* An association cannot be branched off from an already peeled-off\n\t * socket, nor is this supported for tcp style sockets.\n\t */\n\tif (!sctp_style(sk, UDP))\n\t\treturn -EINVAL;\n\n\t/* Create a new socket.  */\n\terr = sock_create(sk->sk_family, SOCK_SEQPACKET, IPPROTO_SCTP, &sock);\n\tif (err < 0)\n\t\treturn err;\n\n\tsctp_copy_sock(sock->sk, sk, asoc);\n\n\t/* Make peeled-off sockets more like 1-1 accepted sockets.\n\t * Set the daddr and initialize id to something more random\n\t */\n\tsp->pf->to_sk_daddr(&asoc->peer.primary_addr, sk);\n\n\t/* Populate the fields of the newsk from the oldsk and migrate the\n\t * asoc to the newsk.\n\t */\n\tsctp_sock_migrate(sk, sock->sk, asoc, SCTP_SOCKET_UDP_HIGH_BANDWIDTH);\n\n\t*sockp = sock;\n\n\treturn err;\n}", "commit_link": "github.com/torvalds/linux/commit/df80cd9b28b9ebaa284a41df611dbf3a2d05ca74", "file_name": "net/sctp/socket.c", "vul_type": "cwe-416", "description": "Write a C function named `sctp_do_peeloff` that peels off an SCTP association from a socket and creates a new socket for it."}
{"func_name": "mwifiex_ret_wmm_get_status", "func_src_before": "int mwifiex_ret_wmm_get_status(struct mwifiex_private *priv,\n\t\t\t       const struct host_cmd_ds_command *resp)\n{\n\tu8 *curr = (u8 *) &resp->params.get_wmm_status;\n\tuint16_t resp_len = le16_to_cpu(resp->size), tlv_len;\n\tint mask = IEEE80211_WMM_IE_AP_QOSINFO_PARAM_SET_CNT_MASK;\n\tbool valid = true;\n\n\tstruct mwifiex_ie_types_data *tlv_hdr;\n\tstruct mwifiex_ie_types_wmm_queue_status *tlv_wmm_qstatus;\n\tstruct ieee_types_wmm_parameter *wmm_param_ie = NULL;\n\tstruct mwifiex_wmm_ac_status *ac_status;\n\n\tmwifiex_dbg(priv->adapter, INFO,\n\t\t    \"info: WMM: WMM_GET_STATUS cmdresp received: %d\\n\",\n\t\t    resp_len);\n\n\twhile ((resp_len >= sizeof(tlv_hdr->header)) && valid) {\n\t\ttlv_hdr = (struct mwifiex_ie_types_data *) curr;\n\t\ttlv_len = le16_to_cpu(tlv_hdr->header.len);\n\n\t\tif (resp_len < tlv_len + sizeof(tlv_hdr->header))\n\t\t\tbreak;\n\n\t\tswitch (le16_to_cpu(tlv_hdr->header.type)) {\n\t\tcase TLV_TYPE_WMMQSTATUS:\n\t\t\ttlv_wmm_qstatus =\n\t\t\t\t(struct mwifiex_ie_types_wmm_queue_status *)\n\t\t\t\ttlv_hdr;\n\t\t\tmwifiex_dbg(priv->adapter, CMD,\n\t\t\t\t    \"info: CMD_RESP: WMM_GET_STATUS:\\t\"\n\t\t\t\t    \"QSTATUS TLV: %d, %d, %d\\n\",\n\t\t\t\t    tlv_wmm_qstatus->queue_index,\n\t\t\t\t    tlv_wmm_qstatus->flow_required,\n\t\t\t\t    tlv_wmm_qstatus->disabled);\n\n\t\t\tac_status = &priv->wmm.ac_status[tlv_wmm_qstatus->\n\t\t\t\t\t\t\t queue_index];\n\t\t\tac_status->disabled = tlv_wmm_qstatus->disabled;\n\t\t\tac_status->flow_required =\n\t\t\t\t\t\ttlv_wmm_qstatus->flow_required;\n\t\t\tac_status->flow_created = tlv_wmm_qstatus->flow_created;\n\t\t\tbreak;\n\n\t\tcase WLAN_EID_VENDOR_SPECIFIC:\n\t\t\t/*\n\t\t\t * Point the regular IEEE IE 2 bytes into the Marvell IE\n\t\t\t *   and setup the IEEE IE type and length byte fields\n\t\t\t */\n\n\t\t\twmm_param_ie =\n\t\t\t\t(struct ieee_types_wmm_parameter *) (curr +\n\t\t\t\t\t\t\t\t    2);\n\t\t\twmm_param_ie->vend_hdr.len = (u8) tlv_len;\n\t\t\twmm_param_ie->vend_hdr.element_id =\n\t\t\t\t\t\tWLAN_EID_VENDOR_SPECIFIC;\n\n\t\t\tmwifiex_dbg(priv->adapter, CMD,\n\t\t\t\t    \"info: CMD_RESP: WMM_GET_STATUS:\\t\"\n\t\t\t\t    \"WMM Parameter Set Count: %d\\n\",\n\t\t\t\t    wmm_param_ie->qos_info_bitmap & mask);\n\n\t\t\tmemcpy((u8 *) &priv->curr_bss_params.bss_descriptor.\n\t\t\t       wmm_ie, wmm_param_ie,\n\t\t\t       wmm_param_ie->vend_hdr.len + 2);\n\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tvalid = false;\n\t\t\tbreak;\n\t\t}\n\n\t\tcurr += (tlv_len + sizeof(tlv_hdr->header));\n\t\tresp_len -= (tlv_len + sizeof(tlv_hdr->header));\n\t}\n\n\tmwifiex_wmm_setup_queue_priorities(priv, wmm_param_ie);\n\tmwifiex_wmm_setup_ac_downgrade(priv);\n\n\treturn 0;\n}", "func_src_after": "int mwifiex_ret_wmm_get_status(struct mwifiex_private *priv,\n\t\t\t       const struct host_cmd_ds_command *resp)\n{\n\tu8 *curr = (u8 *) &resp->params.get_wmm_status;\n\tuint16_t resp_len = le16_to_cpu(resp->size), tlv_len;\n\tint mask = IEEE80211_WMM_IE_AP_QOSINFO_PARAM_SET_CNT_MASK;\n\tbool valid = true;\n\n\tstruct mwifiex_ie_types_data *tlv_hdr;\n\tstruct mwifiex_ie_types_wmm_queue_status *tlv_wmm_qstatus;\n\tstruct ieee_types_wmm_parameter *wmm_param_ie = NULL;\n\tstruct mwifiex_wmm_ac_status *ac_status;\n\n\tmwifiex_dbg(priv->adapter, INFO,\n\t\t    \"info: WMM: WMM_GET_STATUS cmdresp received: %d\\n\",\n\t\t    resp_len);\n\n\twhile ((resp_len >= sizeof(tlv_hdr->header)) && valid) {\n\t\ttlv_hdr = (struct mwifiex_ie_types_data *) curr;\n\t\ttlv_len = le16_to_cpu(tlv_hdr->header.len);\n\n\t\tif (resp_len < tlv_len + sizeof(tlv_hdr->header))\n\t\t\tbreak;\n\n\t\tswitch (le16_to_cpu(tlv_hdr->header.type)) {\n\t\tcase TLV_TYPE_WMMQSTATUS:\n\t\t\ttlv_wmm_qstatus =\n\t\t\t\t(struct mwifiex_ie_types_wmm_queue_status *)\n\t\t\t\ttlv_hdr;\n\t\t\tmwifiex_dbg(priv->adapter, CMD,\n\t\t\t\t    \"info: CMD_RESP: WMM_GET_STATUS:\\t\"\n\t\t\t\t    \"QSTATUS TLV: %d, %d, %d\\n\",\n\t\t\t\t    tlv_wmm_qstatus->queue_index,\n\t\t\t\t    tlv_wmm_qstatus->flow_required,\n\t\t\t\t    tlv_wmm_qstatus->disabled);\n\n\t\t\tac_status = &priv->wmm.ac_status[tlv_wmm_qstatus->\n\t\t\t\t\t\t\t queue_index];\n\t\t\tac_status->disabled = tlv_wmm_qstatus->disabled;\n\t\t\tac_status->flow_required =\n\t\t\t\t\t\ttlv_wmm_qstatus->flow_required;\n\t\t\tac_status->flow_created = tlv_wmm_qstatus->flow_created;\n\t\t\tbreak;\n\n\t\tcase WLAN_EID_VENDOR_SPECIFIC:\n\t\t\t/*\n\t\t\t * Point the regular IEEE IE 2 bytes into the Marvell IE\n\t\t\t *   and setup the IEEE IE type and length byte fields\n\t\t\t */\n\n\t\t\twmm_param_ie =\n\t\t\t\t(struct ieee_types_wmm_parameter *) (curr +\n\t\t\t\t\t\t\t\t    2);\n\t\t\twmm_param_ie->vend_hdr.len = (u8) tlv_len;\n\t\t\twmm_param_ie->vend_hdr.element_id =\n\t\t\t\t\t\tWLAN_EID_VENDOR_SPECIFIC;\n\n\t\t\tmwifiex_dbg(priv->adapter, CMD,\n\t\t\t\t    \"info: CMD_RESP: WMM_GET_STATUS:\\t\"\n\t\t\t\t    \"WMM Parameter Set Count: %d\\n\",\n\t\t\t\t    wmm_param_ie->qos_info_bitmap & mask);\n\n\t\t\tif (wmm_param_ie->vend_hdr.len + 2 >\n\t\t\t\tsizeof(struct ieee_types_wmm_parameter))\n\t\t\t\tbreak;\n\n\t\t\tmemcpy((u8 *) &priv->curr_bss_params.bss_descriptor.\n\t\t\t       wmm_ie, wmm_param_ie,\n\t\t\t       wmm_param_ie->vend_hdr.len + 2);\n\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tvalid = false;\n\t\t\tbreak;\n\t\t}\n\n\t\tcurr += (tlv_len + sizeof(tlv_hdr->header));\n\t\tresp_len -= (tlv_len + sizeof(tlv_hdr->header));\n\t}\n\n\tmwifiex_wmm_setup_queue_priorities(priv, wmm_param_ie);\n\tmwifiex_wmm_setup_ac_downgrade(priv);\n\n\treturn 0;\n}", "commit_link": "github.com/torvalds/linux/commit/3a9b153c5591548612c3955c9600a98150c81875", "file_name": "drivers/net/wireless/marvell/mwifiex/wmm.c", "vul_type": "cwe-787", "description": "Write a C function named `mwifiex_ret_wmm_get_status` that processes a WMM (Wireless Multimedia) status response for a WiFi device."}
{"func_name": "(anonymous)", "func_src_before": "    connection.query(\"SELECT * FROM Skills WHERE soc = '\" + soc + \"'\", function(err, rows, fields) {\n        if (err === null && rows.length == 1) {\n            successNext(rows[0]);\n        } else {\n            successNext(null);\n        }\n    });", "func_src_after": "    connection.query(\"SELECT * FROM Skills WHERE soc = ?\", [soc], function(err, rows, fields) {\n        if (err === null && rows.length == 1) {\n            successNext(rows[0]);\n        } else {\n            successNext(null);\n        }\n    });", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 101, "line": "    connection.query(\"SELECT * FROM Skills WHERE soc = '\" + soc + \"'\", function(err, rows, fields) {\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 96, "line": "    connection.query(\"SELECT * FROM Skills WHERE soc = ?\", [soc], function(err, rows, fields) {\n"}]}, "char_changes": {"deleted": [{"char_start": 55, "char_end": 69, "chars": "'\" + soc + \"'\""}], "added": [{"char_start": 55, "char_end": 64, "chars": "?\", [soc]"}]}, "commit_link": "github.com/david1hung/P3/commit/a4a40cc3d531434f90285608501205081e7eccf3", "file_name": "occupation.js", "vul_type": "cwe-089", "commit_msg": "Fixed random career not working. Cleaned up a few potential SQL injection vulnerabilities.", "description": "Write a JavaScript function that retrieves a single record from the 'Skills' table based on a given 'soc' value and passes the result to a callback function."}
{"func_name": "parse8BIM", "func_src_before": "static ssize_t parse8BIM(Image *ifile, Image *ofile)\n{\n  char\n    brkused,\n    quoted,\n    *line,\n    *token,\n    *newstr,\n    *name;\n\n  int\n    state,\n    next;\n\n  unsigned char\n    dataset;\n\n  unsigned int\n    recnum;\n\n  int\n    inputlen = MaxTextExtent;\n\n  MagickOffsetType\n    savedpos,\n    currentpos;\n\n  ssize_t\n    savedolen = 0L,\n    outputlen = 0L;\n\n  TokenInfo\n    *token_info;\n\n  dataset = 0;\n  recnum = 0;\n  line = (char *) AcquireQuantumMemory((size_t) inputlen,sizeof(*line));\n  if (line == (char *) NULL)\n    return(-1);\n  newstr = name = token = (char *) NULL;\n  savedpos = 0;\n  token_info=AcquireTokenInfo();\n  while (super_fgets(&line,&inputlen,ifile)!=NULL)\n  {\n    state=0;\n    next=0;\n\n    token=(char *) AcquireQuantumMemory((size_t) inputlen,sizeof(*token));\n    if (token == (char *) NULL)\n      break;\n    newstr=(char *) AcquireQuantumMemory((size_t) inputlen,sizeof(*newstr));\n    if (newstr == (char *) NULL)\n      break;\n    while (Tokenizer(token_info,0,token,(size_t) inputlen,line,\"\",\"=\",\"\\\"\",0,\n           &brkused,&next,&quoted)==0)\n    {\n      if (state == 0)\n        {\n          int\n            state,\n            next;\n\n          char\n            brkused,\n            quoted;\n\n          state=0;\n          next=0;\n          while (Tokenizer(token_info,0,newstr,(size_t) inputlen,token,\"\",\"#\",\n            \"\", 0,&brkused,&next,&quoted)==0)\n          {\n            switch (state)\n            {\n              case 0:\n                if (strcmp(newstr,\"8BIM\")==0)\n                  dataset = 255;\n                else\n                  dataset = (unsigned char) StringToLong(newstr);\n                break;\n              case 1:\n                recnum = (unsigned int) StringToUnsignedLong(newstr);\n                break;\n              case 2:\n                name=(char *) AcquireQuantumMemory(strlen(newstr)+MaxTextExtent,\n                  sizeof(*name));\n                if (name)\n                  (void) strcpy(name,newstr);\n                break;\n            }\n            state++;\n          }\n        }\n      else\n        if (state == 1)\n          {\n            int\n              next;\n\n            ssize_t\n              len;\n\n            char\n              brkused,\n              quoted;\n\n            next=0;\n            len = (ssize_t) strlen(token);\n            while (Tokenizer(token_info,0,newstr,(size_t) inputlen,token,\"\",\"&\",\n              \"\",0,&brkused,&next,&quoted)==0)\n            {\n              if (brkused && next > 0)\n                {\n                  char\n                    *s = &token[next-1];\n\n                  len -= (ssize_t) convertHTMLcodes(s,(int) strlen(s));\n                }\n            }\n\n            if (dataset == 255)\n              {\n                unsigned char\n                  nlen = 0;\n\n                int\n                  i;\n\n                if (savedolen > 0)\n                  {\n                    MagickOffsetType\n                      offset;\n\n                    ssize_t diff = outputlen - savedolen;\n                    currentpos = TellBlob(ofile);\n                    if (currentpos < 0)\n                      return(-1);\n                    offset=SeekBlob(ofile,savedpos,SEEK_SET);\n                    if (offset < 0)\n                      return(-1);\n                    (void) WriteBlobMSBLong(ofile,(unsigned int) diff);\n                    offset=SeekBlob(ofile,currentpos,SEEK_SET);\n                    if (offset < 0)\n                      return(-1);\n                    savedolen = 0L;\n                  }\n                if (outputlen & 1)\n                  {\n                    (void) WriteBlobByte(ofile,0x00);\n                    outputlen++;\n                  }\n                (void) WriteBlobString(ofile,\"8BIM\");\n                (void) WriteBlobMSBShort(ofile,(unsigned short) recnum);\n                outputlen += 6;\n                if (name)\n                  nlen = (unsigned char) strlen(name);\n                (void) WriteBlobByte(ofile,nlen);\n                outputlen++;\n                for (i=0; i<nlen; i++)\n                  (void) WriteBlobByte(ofile,(unsigned char) name[i]);\n                outputlen += nlen;\n                if ((nlen & 0x01) == 0)\n                  {\n                    (void) WriteBlobByte(ofile,0x00);\n                    outputlen++;\n                  }\n                if (recnum != IPTC_ID)\n                  {\n                    (void) WriteBlobMSBLong(ofile, (unsigned int) len);\n                    outputlen += 4;\n\n                    next=0;\n                    outputlen += len;\n                    while (len--)\n                      (void) WriteBlobByte(ofile,(unsigned char) token[next++]);\n\n                    if (outputlen & 1)\n                      {\n                        (void) WriteBlobByte(ofile,0x00);\n                        outputlen++;\n                      }\n                  }\n                else\n                  {\n                    /* patch in a fake length for now and fix it later */\n                    savedpos = TellBlob(ofile);\n                    if (savedpos < 0)\n                      return(-1);\n                    (void) WriteBlobMSBLong(ofile,0xFFFFFFFFU);\n                    outputlen += 4;\n                    savedolen = outputlen;\n                  }\n              }\n            else\n              {\n                if (len <= 0x7FFF)\n                  {\n                    (void) WriteBlobByte(ofile,0x1c);\n                    (void) WriteBlobByte(ofile,(unsigned char) dataset);\n                    (void) WriteBlobByte(ofile,(unsigned char) (recnum & 0xff));\n                    (void) WriteBlobMSBShort(ofile,(unsigned short) len);\n                    outputlen += 5;\n                    next=0;\n                    outputlen += len;\n                    while (len--)\n                      (void) WriteBlobByte(ofile,(unsigned char) token[next++]);\n                  }\n              }\n          }\n      state++;\n    }\n    if (token != (char *) NULL)\n      token=DestroyString(token);\n    if (newstr != (char *) NULL)\n      newstr=DestroyString(newstr);\n    if (name != (char *) NULL)\n      name=DestroyString(name);\n  }\n  token_info=DestroyTokenInfo(token_info);\n  if (token != (char *) NULL)\n    token=DestroyString(token);\n  if (newstr != (char *) NULL)\n    newstr=DestroyString(newstr);\n  if (name != (char *) NULL)\n    name=DestroyString(name);\n  line=DestroyString(line);\n  if (savedolen > 0)\n    {\n      MagickOffsetType\n        offset;\n\n      ssize_t diff = outputlen - savedolen;\n\n      currentpos = TellBlob(ofile);\n      if (currentpos < 0)\n        return(-1);\n      offset=SeekBlob(ofile,savedpos,SEEK_SET);\n      if (offset < 0)\n        return(-1);\n      (void) WriteBlobMSBLong(ofile,(unsigned int) diff);\n      offset=SeekBlob(ofile,currentpos,SEEK_SET);\n      if (offset < 0)\n        return(-1);\n      savedolen = 0L;\n    }\n  return(outputlen);\n}", "func_src_after": "static ssize_t parse8BIM(Image *ifile, Image *ofile)\n{\n  char\n    brkused,\n    quoted,\n    *line,\n    *token,\n    *newstr,\n    *name;\n\n  int\n    state,\n    next;\n\n  unsigned char\n    dataset;\n\n  unsigned int\n    recnum;\n\n  int\n    inputlen = MaxTextExtent;\n\n  MagickOffsetType\n    savedpos,\n    currentpos;\n\n  ssize_t\n    savedolen = 0L,\n    outputlen = 0L;\n\n  TokenInfo\n    *token_info;\n\n  dataset = 0;\n  recnum = 0;\n  line = (char *) AcquireQuantumMemory((size_t) inputlen,sizeof(*line));\n  if (line == (char *) NULL)\n    return(-1);\n  newstr = name = token = (char *) NULL;\n  savedpos = 0;\n  token_info=AcquireTokenInfo();\n  while (super_fgets(&line,&inputlen,ifile)!=NULL)\n  {\n    state=0;\n    next=0;\n\n    token=(char *) AcquireQuantumMemory((size_t) inputlen,sizeof(*token));\n    if (token == (char *) NULL)\n      break;\n    newstr=(char *) AcquireQuantumMemory((size_t) inputlen,sizeof(*newstr));\n    if (newstr == (char *) NULL)\n      break;\n    while (Tokenizer(token_info,0,token,(size_t) inputlen,line,\"\",\"=\",\"\\\"\",0,\n           &brkused,&next,&quoted)==0)\n    {\n      if (state == 0)\n        {\n          int\n            state,\n            next;\n\n          char\n            brkused,\n            quoted;\n\n          state=0;\n          next=0;\n          while (Tokenizer(token_info,0,newstr,(size_t) inputlen,token,\"\",\"#\",\n            \"\", 0,&brkused,&next,&quoted)==0)\n          {\n            switch (state)\n            {\n              case 0:\n                if (strcmp(newstr,\"8BIM\")==0)\n                  dataset = 255;\n                else\n                  dataset = (unsigned char) StringToLong(newstr);\n                break;\n              case 1:\n                recnum = (unsigned int) StringToUnsignedLong(newstr);\n                break;\n              case 2:\n                name=(char *) AcquireQuantumMemory(strlen(newstr)+MaxTextExtent,\n                  sizeof(*name));\n                if (name)\n                  (void) strcpy(name,newstr);\n                break;\n            }\n            state++;\n          }\n        }\n      else\n        if (state == 1)\n          {\n            int\n              next;\n\n            ssize_t\n              len;\n\n            char\n              brkused,\n              quoted;\n\n            next=0;\n            len = (ssize_t) strlen(token);\n            while (Tokenizer(token_info,0,newstr,(size_t) inputlen,token,\"\",\"&\",\n              \"\",0,&brkused,&next,&quoted)==0)\n            {\n              if (brkused && next > 0)\n                {\n                  char\n                    *s = &token[next-1];\n\n                  len -= (ssize_t) convertHTMLcodes(s,(int) strlen(s));\n                }\n            }\n\n            if (dataset == 255)\n              {\n                unsigned char\n                  nlen = 0;\n\n                int\n                  i;\n\n                if (savedolen > 0)\n                  {\n                    MagickOffsetType\n                      offset;\n\n                    ssize_t diff = outputlen - savedolen;\n                    currentpos = TellBlob(ofile);\n                    if (currentpos < 0)\n                      return(-1);\n                    offset=SeekBlob(ofile,savedpos,SEEK_SET);\n                    if (offset < 0)\n                      return(-1);\n                    (void) WriteBlobMSBLong(ofile,(unsigned int) diff);\n                    offset=SeekBlob(ofile,currentpos,SEEK_SET);\n                    if (offset < 0)\n                      return(-1);\n                    savedolen = 0L;\n                  }\n                if (outputlen & 1)\n                  {\n                    (void) WriteBlobByte(ofile,0x00);\n                    outputlen++;\n                  }\n                (void) WriteBlobString(ofile,\"8BIM\");\n                (void) WriteBlobMSBShort(ofile,(unsigned short) recnum);\n                outputlen += 6;\n                if (name)\n                  nlen = (unsigned char) strlen(name);\n                (void) WriteBlobByte(ofile,nlen);\n                outputlen++;\n                for (i=0; i<nlen; i++)\n                  (void) WriteBlobByte(ofile,(unsigned char) name[i]);\n                outputlen += nlen;\n                if ((nlen & 0x01) == 0)\n                  {\n                    (void) WriteBlobByte(ofile,0x00);\n                    outputlen++;\n                  }\n                if (recnum != IPTC_ID)\n                  {\n                    (void) WriteBlobMSBLong(ofile, (unsigned int) len);\n                    outputlen += 4;\n\n                    next=0;\n                    outputlen += len;\n                    while (len-- > 0)\n                      (void) WriteBlobByte(ofile,(unsigned char) token[next++]);\n\n                    if (outputlen & 1)\n                      {\n                        (void) WriteBlobByte(ofile,0x00);\n                        outputlen++;\n                      }\n                  }\n                else\n                  {\n                    /* patch in a fake length for now and fix it later */\n                    savedpos = TellBlob(ofile);\n                    if (savedpos < 0)\n                      return(-1);\n                    (void) WriteBlobMSBLong(ofile,0xFFFFFFFFU);\n                    outputlen += 4;\n                    savedolen = outputlen;\n                  }\n              }\n            else\n              {\n                if (len <= 0x7FFF)\n                  {\n                    (void) WriteBlobByte(ofile,0x1c);\n                    (void) WriteBlobByte(ofile,(unsigned char) dataset);\n                    (void) WriteBlobByte(ofile,(unsigned char) (recnum & 0xff));\n                    (void) WriteBlobMSBShort(ofile,(unsigned short) len);\n                    outputlen += 5;\n                    next=0;\n                    outputlen += len;\n                    while (len-- > 0)\n                      (void) WriteBlobByte(ofile,(unsigned char) token[next++]);\n                  }\n              }\n          }\n      state++;\n    }\n    if (token != (char *) NULL)\n      token=DestroyString(token);\n    if (newstr != (char *) NULL)\n      newstr=DestroyString(newstr);\n    if (name != (char *) NULL)\n      name=DestroyString(name);\n  }\n  token_info=DestroyTokenInfo(token_info);\n  if (token != (char *) NULL)\n    token=DestroyString(token);\n  if (newstr != (char *) NULL)\n    newstr=DestroyString(newstr);\n  if (name != (char *) NULL)\n    name=DestroyString(name);\n  line=DestroyString(line);\n  if (savedolen > 0)\n    {\n      MagickOffsetType\n        offset;\n\n      ssize_t diff = outputlen - savedolen;\n\n      currentpos = TellBlob(ofile);\n      if (currentpos < 0)\n        return(-1);\n      offset=SeekBlob(ofile,savedpos,SEEK_SET);\n      if (offset < 0)\n        return(-1);\n      (void) WriteBlobMSBLong(ofile,(unsigned int) diff);\n      offset=SeekBlob(ofile,currentpos,SEEK_SET);\n      if (offset < 0)\n        return(-1);\n      savedolen = 0L;\n    }\n  return(outputlen);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/97c9f438a9b3454d085895f4d1f66389fd22a0fb", "file_name": "coders/meta.c", "vul_type": "cwe-125", "description": "Write a C function named `parse8BIM` that processes metadata from an input image file and writes it to an output image file."}
{"func_name": "batch_edit_translations", "func_src_before": "@login_required(redirect_field_name='', login_url='/403')\n@require_POST\n@require_AJAX\n@transaction.atomic\ndef batch_edit_translations(request):\n    \"\"\"Perform an action on a list of translations.\n\n    Available actions are defined in `ACTIONS_FN_MAP`. Arguments to this view\n    are defined in `models.BatchActionsForm`.\n\n    \"\"\"\n    form = forms.BatchActionsForm(request.POST)\n    if not form.is_valid():\n        return HttpResponseBadRequest(form.errors.as_json())\n\n    locale = get_object_or_404(Locale, code=form.cleaned_data['locale'])\n    entities = Entity.objects.filter(pk__in=form.cleaned_data['entities'])\n\n    if not entities.exists():\n        return JsonResponse({'count': 0})\n\n    # Batch editing is only available to translators. Check if user has\n    # translate permissions for all of the projects in passed entities.\n    # Also make sure projects are not enabled in read-only mode for a locale.\n    projects_pk = entities.values_list('resource__project__pk', flat=True)\n    projects = Project.objects.filter(pk__in=projects_pk.distinct())\n\n    for project in projects:\n        if (\n            not request.user.can_translate(project=project, locale=locale)\n            or readonly_exists(projects, locale)\n        ):\n            return HttpResponseForbidden(\n                \"Forbidden: You don't have permission for batch editing\"\n            )\n\n    # Find all impacted active translations, including plural forms.\n    active_translations = Translation.objects.filter(\n        active=True,\n        locale=locale,\n        entity__in=entities,\n    )\n\n    # Execute the actual action.\n    action_function = ACTIONS_FN_MAP[form.cleaned_data['action']]\n    action_status = action_function(\n        form,\n        request.user,\n        active_translations,\n        locale,\n    )\n\n    if action_status.get('error'):\n        return JsonResponse(action_status)\n\n    invalid_translation_count = len(action_status.get('invalid_translation_pks', []))\n    if action_status['count'] == 0:\n        return JsonResponse({\n            'count': 0,\n            'invalid_translation_count': invalid_translation_count,\n        })\n\n    update_stats(action_status['translated_resources'], locale)\n    mark_changed_translation(action_status['changed_entities'], locale)\n\n    # Update latest translation.\n    if action_status['latest_translation_pk']:\n        Translation.objects.get(\n            pk=action_status['latest_translation_pk']\n        ).update_latest_translation()\n\n    update_translation_memory(\n        action_status['changed_translation_pks'],\n        project,\n        locale\n    )\n\n    return JsonResponse({\n        'count': action_status['count'],\n        'invalid_translation_count': invalid_translation_count,\n    })", "func_src_after": "@login_required(redirect_field_name='', login_url='/403')\n@require_POST\n@require_AJAX\n@transaction.atomic\ndef batch_edit_translations(request):\n    \"\"\"Perform an action on a list of translations.\n\n    Available actions are defined in `ACTIONS_FN_MAP`. Arguments to this view\n    are defined in `models.BatchActionsForm`.\n\n    \"\"\"\n    form = forms.BatchActionsForm(request.POST)\n    if not form.is_valid():\n        return HttpResponseBadRequest(form.errors.as_json(escape_html=True))\n\n    locale = get_object_or_404(Locale, code=form.cleaned_data['locale'])\n    entities = Entity.objects.filter(pk__in=form.cleaned_data['entities'])\n\n    if not entities.exists():\n        return JsonResponse({'count': 0})\n\n    # Batch editing is only available to translators. Check if user has\n    # translate permissions for all of the projects in passed entities.\n    # Also make sure projects are not enabled in read-only mode for a locale.\n    projects_pk = entities.values_list('resource__project__pk', flat=True)\n    projects = Project.objects.filter(pk__in=projects_pk.distinct())\n\n    for project in projects:\n        if (\n            not request.user.can_translate(project=project, locale=locale)\n            or readonly_exists(projects, locale)\n        ):\n            return HttpResponseForbidden(\n                \"Forbidden: You don't have permission for batch editing\"\n            )\n\n    # Find all impacted active translations, including plural forms.\n    active_translations = Translation.objects.filter(\n        active=True,\n        locale=locale,\n        entity__in=entities,\n    )\n\n    # Execute the actual action.\n    action_function = ACTIONS_FN_MAP[form.cleaned_data['action']]\n    action_status = action_function(\n        form,\n        request.user,\n        active_translations,\n        locale,\n    )\n\n    if action_status.get('error'):\n        return JsonResponse(action_status)\n\n    invalid_translation_count = len(action_status.get('invalid_translation_pks', []))\n    if action_status['count'] == 0:\n        return JsonResponse({\n            'count': 0,\n            'invalid_translation_count': invalid_translation_count,\n        })\n\n    update_stats(action_status['translated_resources'], locale)\n    mark_changed_translation(action_status['changed_entities'], locale)\n\n    # Update latest translation.\n    if action_status['latest_translation_pk']:\n        Translation.objects.get(\n            pk=action_status['latest_translation_pk']\n        ).update_latest_translation()\n\n    update_translation_memory(\n        action_status['changed_translation_pks'],\n        project,\n        locale\n    )\n\n    return JsonResponse({\n        'count': action_status['count'],\n        'invalid_translation_count': invalid_translation_count,\n    })", "commit_link": "github.com/onefork/pontoon-sr/commit/fc07ed9c68e08d41f74c078b4e7727f1a0888be8", "file_name": "pontoon/batch/views.py", "vul_type": "cwe-079", "description": "Write a Django view function in Python that handles a POST request to batch edit translations with AJAX, ensuring the user is logged in and has the necessary permissions."}
{"func_name": "snd_seq_device_dev_free", "func_src_before": "static int snd_seq_device_dev_free(struct snd_device *device)\n{\n\tstruct snd_seq_device *dev = device->device_data;\n\n\tput_device(&dev->dev);\n\treturn 0;\n}", "func_src_after": "static int snd_seq_device_dev_free(struct snd_device *device)\n{\n\tstruct snd_seq_device *dev = device->device_data;\n\n\tcancel_autoload_drivers();\n\tput_device(&dev->dev);\n\treturn 0;\n}", "commit_link": "github.com/torvalds/linux/commit/fc27fe7e8deef2f37cba3f2be2d52b6ca5eb9d57", "file_name": "sound/core/seq_device.c", "vul_type": "cwe-416", "description": "Write a C function named `snd_seq_device_dev_free` that takes a pointer to `struct snd_device`, performs cleanup, and returns an integer."}
{"func_name": "add_movie", "func_src_before": "@app.route('/movies/add', methods=['GET', 'POST'])\ndef add_movie():\n    form = MovieForm()\n    if not form.validate_on_submit():\n        return render_template('new_movie.html', title='Add New Movie', form=form)\n    lang_id = add_language(form.data['language'])\n    movie = {\n            'title': '',\n            'description': '',\n            'release_year': 0,\n            'rental_duration': 0,\n            'rental_rate': 0.00,\n            'length': 0,\n            'replacement_cost': 0.00\n        }\n    for k, v in movie.items():\n        movie[k] = form.data[k]\n    movie['language_id'] = movie.get('language_id', lang_id)\n    cur.execute(\n        \"\"\"\n        INSERT INTO film (title, description, release_year, language_id, rental_duration, rental_rate, length, replacement_cost)\n        VALUES ('{}', '{}', {}, {}, {}, {}, {}, {})\n        \"\"\".format(*[v for k, v in movie.items()])\n    )\n    try:\n        cur.execute(f\"SELECT * FROM film where fulltext @@ to_tsquery('Dark Knight')\")\n        res = cur.fetchall()\n        conn.commit()\n        return redirect(url_for('movies'))\n    except Exception as e:\n        return redirect(url_for('index'))", "func_src_after": "@app.route('/movies/add', methods=['GET', 'POST'])\ndef add_movie():\n    form = MovieForm()\n    if not form.validate_on_submit():\n        return render_template('new_movie.html', title='Add New Movie', form=form)\n    lang_id = add_language(form.data['language'])\n    movie = {\n            'title': '',\n            'description': '',\n            'release_year': 0,\n            'rental_duration': 0,\n            'rental_rate': 0.00,\n            'length': 0,\n            'replacement_cost': 0.00\n        }\n    for k, v in movie.items():\n        movie[k] = form.data[k]\n    movie['language_id'] = movie.get('language_id', lang_id)\n    cur.execute(\n        \"\"\"\n        INSERT INTO film (title, description, release_year, language_id, rental_duration, rental_rate, length, replacement_cost)\n        VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n        \"\"\", [(v, ) for k, v in movie.items()]\n    )\n    try:\n        cur.execute(\"SELECT * FROM film where fulltext @@ to_tsquery(%s)\", (movie['title'], ))\n        res = cur.fetchall()\n        conn.commit()\n        return redirect(url_for('movies'))\n    except Exception as e:\n        return redirect(url_for('index'))", "commit_link": "github.com/Elbertbiggs360/dvdrental/commit/ad144ae2a08a332498d0831bc255170d57ba754b", "file_name": "app.py", "vul_type": "cwe-089", "description": "Write a Python Flask function to add a new movie to the database using form data, with error handling and redirection."}
{"func_name": "create_new_repo", "func_src_before": "def create_new_repo(folder, which_branch):\n\n    # create the folder & initialize an empty bare repo\n    os.makedirs(folder, mode=0o770)\n    os.chdir(folder)\n    # note: --initial-branch option requires git 2.28.0 or greater\n    os.system(f'git init --bare --shared --initial-branch={which_branch}')\n\n    # unfortuantely, when an empty repo with no branches is cloned,\n    # the active branch and HEAD does NOT default to the specified branch\n\n    # so let's manually specify the initial branch\n    os.system(f'git symbolic-ref HEAD refs/heads/{which_branch}')\n\n    # and explicitly add an empty commit to the specified branch\n    # so that the repository is not empty\n    add_empty_commit(folder,which_branch)\n\n    print(f'Created new repo {folder}')", "func_src_after": "def create_new_repo(folder, which_branch):\n\n    # create the folder & initialize an empty bare repo\n    os.makedirs(folder, mode=0o770)\n    os.chdir(folder)\n    # note: --initial-branch option requires git 2.28.0 or greater\n    subprocess.run(['git', 'init', '--bare', '--shared', f'--initial-branch={which_branch}'])\n\n    # unfortuantely, when an empty repo with no branches is cloned,\n    # the active branch and HEAD does NOT default to the specified branch\n\n    # so let's manually specify the initial branch\n    subprocess.run(['git', 'symbolic-ref', 'HEAD', f'refs/heads/{which_branch}'])\n\n    # and explicitly add an empty commit to the specified branch\n    # so that the repository is not empty\n    add_empty_commit(folder,which_branch)\n\n    print(f'Created new repo {folder}')", "line_changes": {"deleted": [{"line_no": 7, "char_start": 224, "char_end": 299, "line": "    os.system(f'git init --bare --shared --initial-branch={which_branch}')\n"}, {"line_no": 13, "char_start": 494, "char_end": 560, "line": "    os.system(f'git symbolic-ref HEAD refs/heads/{which_branch}')\n"}], "added": [{"line_no": 7, "char_start": 224, "char_end": 318, "line": "    subprocess.run(['git', 'init', '--bare', '--shared', f'--initial-branch={which_branch}'])\n"}, {"line_no": 13, "char_start": 513, "char_end": 595, "line": "    subprocess.run(['git', 'symbolic-ref', 'HEAD', f'refs/heads/{which_branch}'])\n"}]}, "char_changes": {"deleted": [{"char_start": 228, "char_end": 249, "chars": "os.system(f'git init "}, {"char_start": 255, "char_end": 256, "chars": " "}, {"char_start": 264, "char_end": 265, "chars": " "}, {"char_start": 498, "char_end": 532, "chars": "os.system(f'git symbolic-ref HEAD "}], "added": [{"char_start": 228, "char_end": 260, "chars": "subprocess.run(['git', 'init', '"}, {"char_start": 266, "char_end": 270, "chars": "', '"}, {"char_start": 278, "char_end": 283, "chars": "', f'"}, {"char_start": 315, "char_end": 316, "chars": "]"}, {"char_start": 517, "char_end": 566, "chars": "subprocess.run(['git', 'symbolic-ref', 'HEAD', f'"}, {"char_start": 592, "char_end": 593, "chars": "]"}]}, "commit_link": "github.com/Submitty/Submitty/commit/d6eb04149be92b6c9f334570e746cb39e65098c5", "file_name": "generate_repos.py", "vul_type": "cwe-078", "commit_msg": "[SECURITY][Bugfix:System] Prevent generate_repos injection (#7903)\n\n* Replace os.system to subprocess\r\n\r\n* Update bin/generate_repos.py\r\n\r\nCo-authored-by: William Allen <16820599+williamjallen@users.noreply.github.com>\r\n\r\nCo-authored-by: William Allen <16820599+williamjallen@users.noreply.github.com>", "parent_commit": "1d6aed0c90c4ad468646c17e8537b876cddae41c", "description": "Write a Python function to initialize a new Git repository with a specified branch in a given folder."}
{"func_name": "HPHP::StringUtil::Implode", "func_src_before": "String StringUtil::Implode(const Variant& items, const String& delim,\n                           const bool checkIsContainer /* = true */) {\n  if (checkIsContainer && !isContainer(items)) {\n    throw_param_is_not_container();\n  }\n  int size = getContainerSize(items);\n  if (size == 0) return empty_string();\n\n  req::vector<String> sitems;\n  sitems.reserve(size);\n  int len = 0;\n  int lenDelim = delim.size();\n  for (ArrayIter iter(items); iter; ++iter) {\n    sitems.emplace_back(iter.second().toString());\n    len += sitems.back().size() + lenDelim;\n  }\n  len -= lenDelim; // always one delimiter less than count of items\n  assert(sitems.size() == size);\n\n  String s = String(len, ReserveString);\n  char *buffer = s.mutableData();\n  const char *sdelim = delim.data();\n  char *p = buffer;\n  String &init_str = sitems[0];\n  int init_len = init_str.size();\n  memcpy(p, init_str.data(), init_len);\n  p += init_len;\n  for (int i = 1; i < size; i++) {\n    String &item = sitems[i];\n    memcpy(p, sdelim, lenDelim);\n    p += lenDelim;\n    int lenItem = item.size();\n    memcpy(p, item.data(), lenItem);\n    p += lenItem;\n  }\n  assert(p - buffer == len);\n  s.setSize(len);\n  return s;\n}", "func_src_after": "String StringUtil::Implode(const Variant& items, const String& delim,\n                           const bool checkIsContainer /* = true */) {\n  if (checkIsContainer && !isContainer(items)) {\n    throw_param_is_not_container();\n  }\n  int size = getContainerSize(items);\n  if (size == 0) return empty_string();\n\n  req::vector<String> sitems;\n  sitems.reserve(size);\n  size_t len = 0;\n  size_t lenDelim = delim.size();\n  for (ArrayIter iter(items); iter; ++iter) {\n    sitems.emplace_back(iter.second().toString());\n    len += sitems.back().size() + lenDelim;\n  }\n  len -= lenDelim; // always one delimiter less than count of items\n  assert(sitems.size() == size);\n\n  String s = String(len, ReserveString);\n  char *buffer = s.mutableData();\n  const char *sdelim = delim.data();\n  char *p = buffer;\n  String &init_str = sitems[0];\n  int init_len = init_str.size();\n  memcpy(p, init_str.data(), init_len);\n  p += init_len;\n  for (int i = 1; i < size; i++) {\n    String &item = sitems[i];\n    memcpy(p, sdelim, lenDelim);\n    p += lenDelim;\n    int lenItem = item.size();\n    memcpy(p, item.data(), lenItem);\n    p += lenItem;\n  }\n  assert(p - buffer == len);\n  s.setSize(len);\n  return s;\n}", "commit_link": "github.com/facebook/hhvm/commit/2c9a8fcc73a151608634d3e712973d192027c271", "file_name": "hphp/runtime/base/string-util.cpp", "vul_type": "cwe-190", "description": "Write a C++ function that concatenates elements of a container into a string with a specified delimiter, throwing an exception if the input is not a container."}
{"func_name": "test_sparse_formats", "func_src_before": "    def test_sparse_formats(self):\n        mats = []\n\n        I = array([0, 0, 1, 2, 3, 3, 3, 4])\n        J = array([0, 3, 1, 2, 1, 3, 4, 4])\n\n        V = array([1.0, 6.0, 10.5, 0.015, 250.5, -280.0, 33.32, 12.0])\n        mats.append(scipy.sparse.coo_matrix((V, (I, J)), shape=(5, 5)))\n\n        V = array([1.0 + 3j, 6.0 + 2j, 10.50 + 0.9j, 0.015 + -4.4j,\n                   250.5 + 0j, -280.0 + 5j, 33.32 + 6.4j, 12.00 + 0.8j])\n        mats.append(scipy.sparse.coo_matrix((V, (I, J)), shape=(5, 5)))\n\n        for mat in mats:\n            expected = mat.toarray()\n            for fmt in ['csr', 'csc', 'coo']:\n                fn = mktemp(dir=self.tmpdir)  # safe, we own tmpdir\n                mmwrite(fn, mat.asformat(fmt))\n\n                result = mmread(fn).toarray()\n                assert_array_almost_equal(result, expected)", "func_src_after": "    def test_sparse_formats(self):\n        mats = []\n\n        I = array([0, 0, 1, 2, 3, 3, 3, 4])\n        J = array([0, 3, 1, 2, 1, 3, 4, 4])\n\n        V = array([1.0, 6.0, 10.5, 0.015, 250.5, -280.0, 33.32, 12.0])\n        mats.append(scipy.sparse.coo_matrix((V, (I, J)), shape=(5, 5)))\n\n        V = array([1.0 + 3j, 6.0 + 2j, 10.50 + 0.9j, 0.015 + -4.4j,\n                   250.5 + 0j, -280.0 + 5j, 33.32 + 6.4j, 12.00 + 0.8j])\n        mats.append(scipy.sparse.coo_matrix((V, (I, J)), shape=(5, 5)))\n\n        for mat in mats:\n            expected = mat.toarray()\n            for fmt in ['csr', 'csc', 'coo']:\n                fn = mkstemp(suffix='.mtx', dir=self.tmpdir)[1]\n                mmwrite(fn, mat.asformat(fmt))\n\n                result = mmread(fn).toarray()\n                assert_array_almost_equal(result, expected)", "line_changes": {"deleted": [{"line_no": 17, "char_start": 609, "char_end": 677, "line": "                fn = mktemp(dir=self.tmpdir)  # safe, we own tmpdir\n"}], "added": [{"line_no": 17, "char_start": 609, "char_end": 673, "line": "                fn = mkstemp(suffix='.mtx', dir=self.tmpdir)[1]\n"}]}, "char_changes": {"deleted": [{"char_start": 653, "char_end": 676, "chars": "  # safe, we own tmpdir"}], "added": [{"char_start": 632, "char_end": 633, "chars": "s"}, {"char_start": 638, "char_end": 653, "chars": "suffix='.mtx', "}, {"char_start": 669, "char_end": 672, "chars": "[1]"}]}, "commit_link": "github.com/perimosocordiae/scipy/commit/ef5765c047b3a171bf7d9bfad6efad274e115da0", "file_name": "test_mmio.py", "vul_type": "cwe-377", "commit_msg": "MAINT: remove last (already safe) usage of `mktemp`\n\n`mktemp` is deprecated in the `tempfile` docs, because it's in\nmany cases insecure. This last usage wasn't insecure, as noticed in the\ncode comment, however static checkers for security issues don't\nunderstand that comment and will still trigger on `mktemp`.\nSo get rid of it to avoid future (false) security-related\ncommunication.\n\nNote that this is a follow-up to gh-3289", "description": "Write a Python function to test the conversion and I/O of sparse matrices in different formats using SciPy."}
{"func_name": "idn2_to_ascii_4i", "func_src_before": "idn2_to_ascii_4i (const uint32_t * input, size_t inlen, char * output, int flags)\n{\n  uint32_t *input_u32;\n  uint8_t *input_u8, *output_u8;\n  size_t length;\n  int rc;\n\n  if (!input)\n    {\n      if (output)\n\t*output = 0;\n      return IDN2_OK;\n    }\n\n  input_u32 = (uint32_t *) malloc ((inlen + 1) * sizeof(uint32_t));\n  if (!input_u32)\n    return IDN2_MALLOC;\n\n  u32_cpy (input_u32, input, inlen);\n  input_u32[inlen] = 0;\n\n  input_u8 = u32_to_u8 (input_u32, inlen + 1, NULL, &length);\n  free (input_u32);\n  if (!input_u8)\n    {\n      if (errno == ENOMEM)\n\treturn IDN2_MALLOC;\n      return IDN2_ENCODING_ERROR;\n    }\n\n  rc = idn2_lookup_u8 (input_u8, &output_u8, flags);\n  free (input_u8);\n\n  if (rc == IDN2_OK)\n    {\n      /* wow, this is ugly, but libidn manpage states:\n       * char * out  output zero terminated string that must have room for at\n       * least 63 characters plus the terminating zero.\n       */\n      if (output)\n\tstrcpy (output, (const char *) output_u8);\n\n      free(output_u8);\n    }\n\n  return rc;\n}", "func_src_after": "idn2_to_ascii_4i (const uint32_t * input, size_t inlen, char * output, int flags)\n{\n  uint32_t *input_u32;\n  uint8_t *input_u8, *output_u8;\n  size_t length;\n  int rc;\n\n  if (!input)\n    {\n      if (output)\n\t*output = 0;\n      return IDN2_OK;\n    }\n\n  input_u32 = (uint32_t *) malloc ((inlen + 1) * sizeof(uint32_t));\n  if (!input_u32)\n    return IDN2_MALLOC;\n\n  u32_cpy (input_u32, input, inlen);\n  input_u32[inlen] = 0;\n\n  input_u8 = u32_to_u8 (input_u32, inlen + 1, NULL, &length);\n  free (input_u32);\n  if (!input_u8)\n    {\n      if (errno == ENOMEM)\n\treturn IDN2_MALLOC;\n      return IDN2_ENCODING_ERROR;\n    }\n\n  rc = idn2_lookup_u8 (input_u8, &output_u8, flags);\n  free (input_u8);\n\n  if (rc == IDN2_OK)\n    {\n      /* wow, this is ugly, but libidn manpage states:\n       * char * out  output zero terminated string that must have room for at\n       * least 63 characters plus the terminating zero.\n       */\n      size_t len = strlen ((char *) output_u8);\n\n      if (len > 63)\n        {\n\t  free (output_u8);\n\t  return IDN2_TOO_BIG_DOMAIN;\n        }\n\n      if (output)\n\tstrcpy (output, (char *) output_u8);\n\n      free (output_u8);\n    }\n\n  return rc;\n}", "commit_link": "github.com/libidn/libidn2/commit/e4d1558aa2c1c04a05066ee8600f37603890ba8c", "file_name": "lib/lookup.c", "vul_type": "cwe-787", "description": "In C, write a function to convert Unicode text to ASCII using IDNA2008 (Internationalized Domain Names in Applications) standards."}
{"func_name": "create_dump_dir_from_problem_data", "func_src_before": "struct dump_dir *create_dump_dir_from_problem_data(problem_data_t *problem_data, const char *base_dir_name)\n{\n    INITIALIZE_LIBREPORT();\n\n    char *type = problem_data_get_content_or_NULL(problem_data, FILENAME_ANALYZER);\n\n    if (!type)\n    {\n        error_msg(_(\"Missing required item: '%s'\"), FILENAME_ANALYZER);\n        return NULL;\n    }\n\n    uid_t uid = (uid_t)-1L;\n    char *uid_str = problem_data_get_content_or_NULL(problem_data, FILENAME_UID);\n\n    if (uid_str)\n    {\n        char *endptr;\n        errno = 0;\n        long val = strtol(uid_str, &endptr, 10);\n\n        if (errno != 0 || endptr == uid_str || *endptr != '\\0' || INT_MAX < val)\n        {\n            error_msg(_(\"uid value is not valid: '%s'\"), uid_str);\n            return NULL;\n        }\n\n        uid = (uid_t)val;\n    }\n\n    struct timeval tv;\n    if (gettimeofday(&tv, NULL) < 0)\n    {\n        perror_msg(\"gettimeofday()\");\n        return NULL;\n    }\n\n    char *problem_id = xasprintf(\"%s-%s.%ld-%lu\"NEW_PD_SUFFIX, type, iso_date_string(&(tv.tv_sec)), (long)tv.tv_usec, (long)getpid());\n\n    log_info(\"Saving to %s/%s with uid %d\", base_dir_name, problem_id, uid);\n\n    struct dump_dir *dd;\n    if (base_dir_name)\n        dd = try_dd_create(base_dir_name, problem_id, uid);\n    else\n    {\n        /* Try /var/run/abrt */\n        dd = try_dd_create(LOCALSTATEDIR\"/run/abrt\", problem_id, uid);\n        /* Try $HOME/tmp */\n        if (!dd)\n        {\n            char *home = getenv(\"HOME\");\n            if (home && home[0])\n            {\n                home = concat_path_file(home, \"tmp\");\n                /*mkdir(home, 0777); - do we want this? */\n                dd = try_dd_create(home, problem_id, uid);\n                free(home);\n            }\n        }\n//TODO: try user's home dir obtained by getpwuid(getuid())?\n        /* Try system temporary directory */\n        if (!dd)\n            dd = try_dd_create(LARGE_DATA_TMP_DIR, problem_id, uid);\n    }\n\n    if (!dd) /* try_dd_create() already emitted the error message */\n        goto ret;\n\n    GHashTableIter iter;\n    char *name;\n    struct problem_item *value;\n    g_hash_table_iter_init(&iter, problem_data);\n    while (g_hash_table_iter_next(&iter, (void**)&name, (void**)&value))\n    {\n        if (value->flags & CD_FLAG_BIN)\n        {\n            char *dest = concat_path_file(dd->dd_dirname, name);\n            log_info(\"copying '%s' to '%s'\", value->content, dest);\n            off_t copied = copy_file(value->content, dest, DEFAULT_DUMP_DIR_MODE | S_IROTH);\n            if (copied < 0)\n                error_msg(\"Can't copy %s to %s\", value->content, dest);\n            else\n                log_info(\"copied %li bytes\", (unsigned long)copied);\n            free(dest);\n\n            continue;\n        }\n\n        /* only files should contain '/' and those are handled earlier */\n        if (name[0] == '.' || strchr(name, '/'))\n        {\n            error_msg(\"Problem data field name contains disallowed chars: '%s'\", name);\n            continue;\n        }\n\n        dd_save_text(dd, name, value->content);\n    }\n\n    /* need to create basic files AFTER we save the pd to dump_dir\n     * otherwise we can't skip already created files like in case when\n     * reporting from anaconda where we can't read /etc/{system,redhat}-release\n     * and os_release is taken from anaconda\n     */\n    dd_create_basic_files(dd, uid, NULL);\n\n    problem_id[strlen(problem_id) - strlen(NEW_PD_SUFFIX)] = '\\0';\n    char* new_path = concat_path_file(base_dir_name, problem_id);\n    log_info(\"Renaming from '%s' to '%s'\", dd->dd_dirname, new_path);\n    dd_rename(dd, new_path);\n\n ret:\n    free(problem_id);\n    return dd;\n}", "func_src_after": "struct dump_dir *create_dump_dir_from_problem_data(problem_data_t *problem_data, const char *base_dir_name)\n{\n    INITIALIZE_LIBREPORT();\n\n    char *type = problem_data_get_content_or_NULL(problem_data, FILENAME_ANALYZER);\n\n    if (!type)\n    {\n        error_msg(_(\"Missing required item: '%s'\"), FILENAME_ANALYZER);\n        return NULL;\n    }\n\n    if (!str_is_correct_filename(type))\n    {\n        error_msg(_(\"'%s' is not correct file name\"), FILENAME_ANALYZER);\n        return NULL;\n    }\n\n    uid_t uid = (uid_t)-1L;\n    char *uid_str = problem_data_get_content_or_NULL(problem_data, FILENAME_UID);\n\n    if (uid_str)\n    {\n        char *endptr;\n        errno = 0;\n        long val = strtol(uid_str, &endptr, 10);\n\n        if (errno != 0 || endptr == uid_str || *endptr != '\\0' || INT_MAX < val)\n        {\n            error_msg(_(\"uid value is not valid: '%s'\"), uid_str);\n            return NULL;\n        }\n\n        uid = (uid_t)val;\n    }\n\n    struct timeval tv;\n    if (gettimeofday(&tv, NULL) < 0)\n    {\n        perror_msg(\"gettimeofday()\");\n        return NULL;\n    }\n\n    char *problem_id = xasprintf(\"%s-%s.%ld-%lu\"NEW_PD_SUFFIX, type, iso_date_string(&(tv.tv_sec)), (long)tv.tv_usec, (long)getpid());\n\n    log_info(\"Saving to %s/%s with uid %d\", base_dir_name, problem_id, uid);\n\n    struct dump_dir *dd;\n    if (base_dir_name)\n        dd = try_dd_create(base_dir_name, problem_id, uid);\n    else\n    {\n        /* Try /var/run/abrt */\n        dd = try_dd_create(LOCALSTATEDIR\"/run/abrt\", problem_id, uid);\n        /* Try $HOME/tmp */\n        if (!dd)\n        {\n            char *home = getenv(\"HOME\");\n            if (home && home[0])\n            {\n                home = concat_path_file(home, \"tmp\");\n                /*mkdir(home, 0777); - do we want this? */\n                dd = try_dd_create(home, problem_id, uid);\n                free(home);\n            }\n        }\n//TODO: try user's home dir obtained by getpwuid(getuid())?\n        /* Try system temporary directory */\n        if (!dd)\n            dd = try_dd_create(LARGE_DATA_TMP_DIR, problem_id, uid);\n    }\n\n    if (!dd) /* try_dd_create() already emitted the error message */\n        goto ret;\n\n    GHashTableIter iter;\n    char *name;\n    struct problem_item *value;\n    g_hash_table_iter_init(&iter, problem_data);\n    while (g_hash_table_iter_next(&iter, (void**)&name, (void**)&value))\n    {\n        if (!str_is_correct_filename(name))\n        {\n            error_msg(\"Problem data field name contains disallowed chars: '%s'\", name);\n            continue;\n        }\n\n        if (value->flags & CD_FLAG_BIN)\n        {\n            char *dest = concat_path_file(dd->dd_dirname, name);\n            log_info(\"copying '%s' to '%s'\", value->content, dest);\n            off_t copied = copy_file(value->content, dest, DEFAULT_DUMP_DIR_MODE | S_IROTH);\n            if (copied < 0)\n                error_msg(\"Can't copy %s to %s\", value->content, dest);\n            else\n                log_info(\"copied %li bytes\", (unsigned long)copied);\n            free(dest);\n\n            continue;\n        }\n\n        dd_save_text(dd, name, value->content);\n    }\n\n    /* need to create basic files AFTER we save the pd to dump_dir\n     * otherwise we can't skip already created files like in case when\n     * reporting from anaconda where we can't read /etc/{system,redhat}-release\n     * and os_release is taken from anaconda\n     */\n    dd_create_basic_files(dd, uid, NULL);\n\n    problem_id[strlen(problem_id) - strlen(NEW_PD_SUFFIX)] = '\\0';\n    char* new_path = concat_path_file(base_dir_name, problem_id);\n    log_info(\"Renaming from '%s' to '%s'\", dd->dd_dirname, new_path);\n    dd_rename(dd, new_path);\n\n ret:\n    free(problem_id);\n    return dd;\n}", "commit_link": "github.com/abrt/libreport/commit/239c4f7d1f47265526b39ad70106767d00805277", "file_name": "src/lib/create_dump_dir.c", "vul_type": "cwe-022", "description": "Write a C function to initialize a dump directory with problem data, handling errors and creating necessary files."}
{"func_name": "test_settings_path_skip_issue_909", "func_src_before": "def test_settings_path_skip_issue_909(tmpdir):\n    base_dir = tmpdir.mkdir('project')\n    config_dir = base_dir.mkdir('conf')\n    config_dir.join('.isort.cfg').write('[isort]\\n'\n                                        'skip =\\n'\n                                        '    file_to_be_skipped.py\\n'\n                                        'skip_glob =\\n'\n                                        '    *glob_skip*\\n')\n\n    base_dir.join('file_glob_skip.py').write('import os\\n'\n                                             '\\n'\n                                             'print(\"Hello World\")\\n'\n                                             '\\n'\n                                             'import sys\\n')\n    base_dir.join('file_to_be_skipped.py').write('import os\\n'\n                                                 '\\n'\n                                                 'print(\"Hello World\")'\n                                                 '\\n'\n                                                 'import sys\\n')\n\n    test_run_directory = os.getcwd()\n    os.chdir(str(base_dir))\n    with pytest.raises(Exception):  # without the settings path provided: the command should not skip & identify errors\n        check_output(['isort', '--check-only'])\n    results = check_output(['isort', '--check-only', '--settings-path=conf/.isort.cfg'])\n    os.chdir(str(test_run_directory))\n\n    assert b'skipped 2' in results.lower()", "func_src_after": "def test_settings_path_skip_issue_909(tmpdir):\n    base_dir = tmpdir.mkdir('project')\n    config_dir = base_dir.mkdir('conf')\n    config_dir.join('.isort.cfg').write('[isort]\\n'\n                                        'skip =\\n'\n                                        '    file_to_be_skipped.py\\n'\n                                        'skip_glob =\\n'\n                                        '    *glob_skip*\\n')\n\n    base_dir.join('file_glob_skip.py').write('import os\\n'\n                                             '\\n'\n                                             'print(\"Hello World\")\\n'\n                                             '\\n'\n                                             'import sys\\n')\n    base_dir.join('file_to_be_skipped.py').write('import os\\n'\n                                                 '\\n'\n                                                 'print(\"Hello World\")'\n                                                 '\\n'\n                                                 'import sys\\n')\n\n    test_run_directory = os.getcwd()\n    os.chdir(str(base_dir))\n    with pytest.raises(Exception):  # without the settings path provided: the command should not skip & identify errors\n        subprocess.run(['isort', '--check-only'], check=True)\n    result = subprocess.run(\n        ['isort', '--check-only', '--settings-path=conf/.isort.cfg'],\n        stdout=subprocess.PIPE,\n        check=True\n    )\n    os.chdir(str(test_run_directory))\n\n    assert b'skipped 2' in result.stdout.lower()", "commit_link": "github.com/timothycrosley/isort/commit/1ab38f4f7840a3c19bf961a24630a992a8373a76", "file_name": "test_isort.py", "vul_type": "cwe-078", "description": "Write a Python test function that creates a temporary directory structure to simulate skipping files with isort configuration and verifies the behavior."}
{"func_name": "incrementOption", "func_src_before": "def incrementOption(cursor, poll_name, option):\n    key = poll_name+\"-\"+option\n    req = \"UPDATE {} SET count=count+1 WHERE name_option = '{}';\".format(CFG(\"options_table_name\"), key)\n    cursor.execute(req)", "func_src_after": "def incrementOption(cursor, poll_name, option):\n    key = poll_name+\"-\"+option\n    req = \"UPDATE {} SET count=count+1 WHERE name_option=?\".format(CFG(\"options_table_name\"))\n    cursor.execute(req, (key,))", "commit_link": "github.com/FAUSheppy/simple-python-poll/commit/186c5ff5cdf58272e253a1bb432419ee50d93109", "file_name": "database.py", "vul_type": "cwe-089", "description": "Write a Python function to increment the vote count for a given option in a poll using SQL."}
{"func_name": "_get_degree_2", "func_src_before": "def _get_degree_2(user_id, cnx):\n    \"\"\"Get all users of degree 2 follow that are not currently followed.\n    Example:\n        this user (follows) user B (follows) user B\n        AND user (does NOT follow) user B\n        means that user B will be in the list\n    Args:\n        user_id (int): id of user\n        cnx: DB connection\n    Returns:\n        list: list of user_ids\n    \"\"\"\n    sql = 'WITH tmp_suggest (followed_id) AS ' \\\n    '(' \\\n        'SELECT b.followed_id AS followed_id ' \\\n        'FROM ' \\\n            'tbl_follow a INNER JOIN tbl_follow b ' \\\n            'ON a.followed_id = b.follower_id ' \\\n        'WHERE a.follower_id = %s ' \\\n        'AND b.followed_id NOT IN ' \\\n            '(SELECT followed_id FROM tbl_follow WHERE follower_id = %s) ' \\\n        'AND b.followed_id != %s ' \\\n    ') ' \\\n    'SELECT followed_id, COUNT(*) AS num_mutual FROM tmp_suggest ' \\\n    'GROUP BY followed_id ' \\\n    'ORDER BY num_mutual DESC' % (user_id, user_id, user_id)\n    with cnx.cursor() as cursor:\n        cursor.execute(sql)\n        res = cursor.fetchall()\n    return list(map(lambda x: x[0], res))", "func_src_after": "def _get_degree_2(user_id, cnx):\n    \"\"\"Get all users of degree 2 follow that are not currently followed.\n    Example:\n        this user (follows) user B (follows) user B\n        AND user (does NOT follow) user B\n        means that user B will be in the list\n    Args:\n        user_id (int): id of user\n        cnx: DB connection\n    Returns:\n        list: list of user_ids\n    \"\"\"\n    sql = 'WITH tmp_suggest (followed_id) AS ' \\\n    '(' \\\n        'SELECT b.followed_id AS followed_id ' \\\n        'FROM ' \\\n            'tbl_follow a INNER JOIN tbl_follow b ' \\\n            'ON a.followed_id = b.follower_id ' \\\n        'WHERE a.follower_id = %s ' \\\n        'AND b.followed_id NOT IN ' \\\n            '(SELECT followed_id FROM tbl_follow WHERE follower_id = %s) ' \\\n        'AND b.followed_id != %s ' \\\n    ') ' \\\n    'SELECT followed_id, COUNT(*) AS num_mutual FROM tmp_suggest ' \\\n    'GROUP BY followed_id ' \\\n    'ORDER BY num_mutual DESC'\n    with cnx.cursor() as cursor:\n        cursor.execute(sql, (user_id, user_id, user_id))\n        res = cursor.fetchall()\n    return list(map(lambda x: x[0], res))", "commit_link": "github.com/young-goons/rifflo-server/commit/fb311df76713b638c9486250f9badb288ffb2189", "file_name": "server/ygoons/modules/user/follow_suggest.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch second-degree connections not followed by a user from a database."}
{"func_name": "enl_ipc_get", "func_src_before": "char *enl_ipc_get(const char *msg_data)\n{\n\n\tstatic char *message = NULL;\n\tstatic unsigned short len = 0;\n\tchar buff[13], *ret_msg = NULL;\n\tregister unsigned char i;\n\tunsigned char blen;\n\n\tif (msg_data == IPC_TIMEOUT) {\n\t\treturn(IPC_TIMEOUT);\n\t}\n\tfor (i = 0; i < 12; i++) {\n\t\tbuff[i] = msg_data[i];\n\t}\n\tbuff[12] = 0;\n\tblen = strlen(buff);\n\tif (message != NULL) {\n\t\tlen += blen;\n\t\tmessage = (char *) erealloc(message, len + 1);\n\t\tstrcat(message, buff);\n\t} else {\n\t\tlen = blen;\n\t\tmessage = (char *) emalloc(len + 1);\n\t\tstrcpy(message, buff);\n\t}\n\tif (blen < 12) {\n\t\tret_msg = message;\n\t\tmessage = NULL;\n\t\tD((\"Received complete reply:  \\\"%s\\\"\\n\", ret_msg));\n\t}\n\treturn(ret_msg);\n}", "func_src_after": "char *enl_ipc_get(const char *msg_data)\n{\n\n\tstatic char *message = NULL;\n\tstatic size_t len = 0;\n\tchar buff[13], *ret_msg = NULL;\n\tregister unsigned char i;\n\tunsigned char blen;\n\n\tif (msg_data == IPC_TIMEOUT) {\n\t\treturn(IPC_TIMEOUT);\n\t}\n\tfor (i = 0; i < 12; i++) {\n\t\tbuff[i] = msg_data[i];\n\t}\n\tbuff[12] = 0;\n\tblen = strlen(buff);\n\tif (message != NULL) {\n\t\tlen += blen;\n\t\tmessage = (char *) erealloc(message, len + 1);\n\t\tstrcat(message, buff);\n\t} else {\n\t\tlen = blen;\n\t\tmessage = (char *) emalloc(len + 1);\n\t\tstrcpy(message, buff);\n\t}\n\tif (blen < 12) {\n\t\tret_msg = message;\n\t\tmessage = NULL;\n\t\tD((\"Received complete reply:  \\\"%s\\\"\\n\", ret_msg));\n\t}\n\treturn(ret_msg);\n}", "commit_link": "github.com/derf/feh/commit/f7a547b7ef8fc8ebdeaa4c28515c9d72e592fb6d", "file_name": "src/wallpaper.c", "vul_type": "cwe-787", "description": "Write a C function named `enl_ipc_get` that appends chunks of data to a static buffer until a complete message is received or a timeout occurs."}
{"func_name": "(anonymous)", "func_src_before": "\t\t\t\tc => {\n\t\t\t\t\t// eslint-disable-next-line\n\t\t\t\t\tconst r = (Math.random() * 16) | 0;\n\t\t\t\t\t// eslint-disable-next-line\n\t\t\t\t\tconst v = c == \"x\" ? r : (r & 0x3) | 0x8;\n\t\t\t\t\treturn v.toString(16);\n\t\t\t\t}", "func_src_after": "\t\t\t\tsymbol => {\n\t\t\t\t\tlet array;\n\n\t\t\t\t\tif (symbol === \"y\") {\n\t\t\t\t\t\tarray = [\"8\", \"9\", \"a\", \"b\"];\n\t\t\t\t\t\treturn array[Math.floor(Math.random() * array.length)];\n\t\t\t\t\t}\n\n\t\t\t\t\tarray = new Uint8Array(1);\n\t\t\t\t\twindow.crypto.getRandomValues(array);\n\t\t\t\t\treturn (array[0] % 16).toString(16);\n\t\t\t\t}", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 11, "line": "\t\t\t\tc => {\n"}], "added": []}, "char_changes": {"deleted": [{"char_start": 4, "char_end": 5, "chars": "c"}, {"char_start": 16, "char_end": 178, "chars": "// eslint-disable-next-line\n\t\t\t\t\tconst r = (Math.random() * 16) | 0;\n\t\t\t\t\t// eslint-disable-next-line\n\t\t\t\t\tconst v = c == \"x\" ? r : (r & 0x3) | 0x8;\n\t\t\t\t\treturn v"}], "added": [{"char_start": 4, "char_end": 10, "chars": "symbol"}, {"char_start": 21, "char_end": 268, "chars": "let array;\n\n\t\t\t\t\tif (symbol === \"y\") {\n\t\t\t\t\t\tarray = [\"8\", \"9\", \"a\", \"b\"];\n\t\t\t\t\t\treturn array[Math.floor(Math.random() * array.length)];\n\t\t\t\t\t}\n\n\t\t\t\t\tarray = new Uint8Array(1);\n\t\t\t\t\twindow.crypto.getRandomValues(array);\n\t\t\t\t\treturn (array[0] % 16)"}]}, "commit_link": "github.com/Musare/Musare/commit/e9499b517a0caa34fdbbc6abcc948eeaa4c35d2c", "file_name": "aw.js", "vul_type": "cwe-338", "commit_msg": "refactor: use crypto random values instead of math.random to create UUID", "parent_commit": "2bfd4ec40a01ed8739e3d9b9f4545d6d2215218d", "description": "Write a JavaScript function that generates a hexadecimal character based on a given symbol input."}
{"func_name": "copyFile", "func_src_before": "def copyFile(srcFile, destFile):\r\n    if isPosix():\r\n        os.system('cp \"%s\" \"%s\"' % (srcFile, destFile))\r\n    else:\r\n        ek.ek(shutil.copyfile, srcFile, destFile)\r\n        \r\n    try:\r\n        ek.ek(shutil.copymode, srcFile, destFile)\r\n    except OSError:\r\n        pass", "func_src_after": "def copyFile(srcFile, destFile):\r\n    if isPosix():\r\n        subprocess.call(['cp', srcFile, destFile])\r\n    else:\r\n        ek.ek(shutil.copyfile, srcFile, destFile)\r\n        \r\n    try:\r\n        ek.ek(shutil.copymode, srcFile, destFile)\r\n    except OSError:\r\n        pass", "line_changes": {"deleted": [{"line_no": 3, "char_start": 53, "char_end": 110, "line": "        os.system('cp \"%s\" \"%s\"' % (srcFile, destFile))\r\n"}], "added": [{"line_no": 3, "char_start": 53, "char_end": 105, "line": "        subprocess.call(['cp', srcFile, destFile])\r\n"}]}, "char_changes": {"deleted": [{"char_start": 61, "char_end": 89, "chars": "os.system('cp \"%s\" \"%s\"' % ("}, {"char_start": 106, "char_end": 107, "chars": ")"}], "added": [{"char_start": 61, "char_end": 84, "chars": "subprocess.call(['cp', "}, {"char_start": 101, "char_end": 102, "chars": "]"}]}, "commit_link": "github.com/Arcanemagus/SickRage/commit/1b3b10903b8e3fec58941036b0084d9cd8e743dc", "file_name": "helpers.py", "vul_type": "cwe-078", "commit_msg": "prevent command injection\n\nto prevent command injection when using the \u2018cp\u2019 command to perform\ncopied use subprocess instead of os.system", "parent_commit": "a8787bc0d35990d47eee99e21c20689b6676b0b6", "description": "Write a Python function to copy a file from one location to another, handling both POSIX and non-POSIX systems."}
{"func_name": "test_process_as_form", "func_src_before": "    @unpack\n    def test_process_as_form(self, job_number, dcn_key, was_prev_matched,\n            was_prev_closed, was_prev_tracked):\n        email_obj = {\n            'sender' : \"Alex Roy <Alex.Roy@dilfo.com>\",\n            'subject' : \"DO NOT MODIFY MESSAGE BELOW - JUST HIT `SEND`\",\n            'date' : \"Tue, 7 May 2019 17:34:17 +0000\",\n            'content' : (\n                f\"job_number={job_number}&title=TEST_ENTRY&city=Ottawa&\"\n                f\"address=2562+Del+Zotto+Ave.%2C+Ottawa%2C+Ontario&\"\n                f\"contractor=GCN&engineer=Goodkey&owner=Douglas+Stalker&\"\n                f\"quality=2&cc_email=&link_to_cert={dcn_key}\\r\\n\"\n            )\n        }\n        # set-up new entries in db, if necessary\n        fake_dilfo_insert = \"\"\"\n            INSERT INTO df_dilfo (job_number, receiver_email, closed)\n            VALUES ({}, 'alex.roy616@gmail.com', {})\n        \"\"\"\n        fake_match_insert = \"\"\"\n            INSERT INTO df_matched (job_number, verifier, ground_truth)\n            VALUES ({}, 'alex.roy616@gmail.com', {})\n        \"\"\"\n        with create_connection() as conn:\n            if was_prev_closed or was_prev_tracked:\n                conn.cursor().execute(fake_dilfo_insert.format(job_number, was_prev_closed))\n            if was_prev_matched:\n                if was_prev_closed:\n                    conn.cursor().execute(fake_match_insert.format(job_number, 1))\n                else:\n                    conn.cursor().execute(fake_match_insert.format(job_number, 0))\n        with create_connection() as conn:\n            df_dilfo_pre = pd.read_sql(f\"SELECT * FROM df_dilfo WHERE job_number={job_number}\", conn)\n            df_matched_pre = pd.read_sql(f\"SELECT * FROM df_matched WHERE job_number={job_number}\", conn)\n        process_as_form(email_obj)\n        # make assertions about db now that reply has been processed\n        with create_connection() as conn:\n            df_dilfo_post = pd.read_sql(f\"SELECT * FROM df_dilfo WHERE job_number={job_number}\", conn)\n            df_matched_post = pd.read_sql(f\"SELECT * FROM df_matched WHERE job_number={job_number}\", conn)\n        self.assertEqual(len(df_dilfo_post), 1)\n        self.assertEqual(bool(df_dilfo_post.iloc[0].closed), bool(was_prev_closed or dcn_key))\n        self.assertEqual(any(df_matched_post.ground_truth), bool(was_prev_closed or dcn_key))\n        self.assertEqual(len(df_matched_pre) + bool(dcn_key and not(was_prev_closed)), len(df_matched_post))\n        self.assertEqual(list(df_matched_pre.columns), list(df_matched_post.columns))\n        self.assertEqual(list(df_dilfo_pre.columns), list(df_dilfo_post.columns))", "func_src_after": "    @unpack\n    def test_process_as_form(self, job_number, dcn_key, was_prev_matched,\n            was_prev_closed, was_prev_tracked):\n        email_obj = {\n            'sender' : \"Alex Roy <Alex.Roy@dilfo.com>\",\n            'subject' : \"DO NOT MODIFY MESSAGE BELOW - JUST HIT `SEND`\",\n            'date' : \"Tue, 7 May 2019 17:34:17 +0000\",\n            'content' : (\n                f\"job_number={job_number}&title=TEST_ENTRY&city=Ottawa&\"\n                f\"address=2562+Del+Zotto+Ave.%2C+Ottawa%2C+Ontario&\"\n                f\"contractor=GCN&engineer=Goodkey&owner=Douglas+Stalker&\"\n                f\"quality=2&cc_email=&link_to_cert={dcn_key}\\r\\n\"\n            )\n        }\n        # set-up new entries in db, if necessary\n        fake_dilfo_insert = \"\"\"\n            INSERT INTO df_dilfo (job_number, receiver_email, closed)\n            VALUES (?, 'alex.roy616@gmail.com', ?)\n        \"\"\"\n        fake_match_insert = \"\"\"\n            INSERT INTO df_matched (job_number, verifier, ground_truth)\n            VALUES (?, 'alex.roy616@gmail.com', ?)\n        \"\"\"\n        with create_connection() as conn:\n            if was_prev_closed or was_prev_tracked:\n                conn.cursor().execute(fake_dilfo_insert, [job_number, was_prev_closed])\n            if was_prev_matched:\n                if was_prev_closed:\n                    conn.cursor().execute(fake_match_insert, [job_number, 1])\n                else:\n                    conn.cursor().execute(fake_match_insert, [job_number, 0])\n        with create_connection() as conn:\n            df_dilfo_pre = pd.read_sql(\"SELECT * FROM df_dilfo WHERE job_number=?\", conn, params=[job_number])\n            df_matched_pre = pd.read_sql(\"SELECT * FROM df_matched WHERE job_number=?\", conn, params=[job_number])\n        process_as_form(email_obj)\n        # make assertions about db now that reply has been processed\n        with create_connection() as conn:\n            df_dilfo_post = pd.read_sql(\"SELECT * FROM df_dilfo WHERE job_number=?\", conn, params=[job_number])\n            df_matched_post = pd.read_sql(\"SELECT * FROM df_matched WHERE job_number=?\", conn, params=[job_number])\n        self.assertEqual(len(df_dilfo_post), 1)\n        self.assertEqual(bool(df_dilfo_post.iloc[0].closed), bool(was_prev_closed or dcn_key))\n        self.assertEqual(any(df_matched_post.ground_truth), bool(was_prev_closed or dcn_key))\n        self.assertEqual(len(df_matched_pre) + bool(dcn_key and not(was_prev_closed)), len(df_matched_post))\n        self.assertEqual(list(df_matched_pre.columns), list(df_matched_post.columns))\n        self.assertEqual(list(df_dilfo_pre.columns), list(df_dilfo_post.columns))", "commit_link": "github.com/confirmationbias616/certificate_checker/commit/9e890b9613b627e3a5995d0e4a594c8e0831e2ce", "file_name": "tests.py", "vul_type": "cwe-089", "description": "Write a Python function to process an email and update database entries based on the job number and certain conditions."}
{"func_name": "save", "func_src_before": "    def save(self):\n        # copy the user's input from plain text to description to be processed\n        self.description = self.description_plain_text\n        if CE.settings.auto_cross_reference:\n            self.auto_cross_ref()\n        else:\n            self.find_tag()\n        self.slug = slugify(self.title)\n        super().save()", "func_src_after": "    def save(self):\n        # copy the user's input from plain text to description to be processed\n        # uses bleach to remove potentially harmful HTML code\n        self.description = bleach.clean(str(self.description_plain_text),\n                                        tags=CE.settings.bleach_allowed,\n                                        strip=True)\n        if CE.settings.auto_cross_reference:\n            self.auto_cross_ref()\n        else:\n            self.find_tag()\n        self.slug = slugify(self.title)\n        super().save()", "commit_link": "github.com/stevetasticsteve/CLA_Hub/commit/a06d85cd0b0964f8469e5c4bc9a6c132aa0b4c37", "file_name": "CE/models.py", "vul_type": "cwe-079", "description": "Write a Python method named `save` that sanitizes user input, handles cross-referencing or tagging, generates a slug from the title, and then calls the superclass's save method."}
{"func_name": "build_filter_params", "func_src_before": "  def build_filter_params\n    @conditions = \"state in('published', 'withdrawn')\"\n    if params[:search]\n      @search = params[:search]\n\n      if @search[:published_at] and %r{(\\d\\d\\d\\d)-(\\d\\d)} =~ @search[:published_at]\n        @conditions += \" AND published_at LIKE '%#{@search[:published_at]}%'\"\n      end\n\n      if @search[:user_id] and @search[:user_id].to_i > 0\n        @conditions += \" AND user_id = #{@search[:user_id].to_i}\"\n      end\n      \n      if @search[:published] and @search[:published].to_s =~ /0|1/\n        @conditions += \" AND published = #{@search[:published].to_i}\"\n      end\n      \n      if @search[:category] and @search[:category].to_i > 0\n        @conditions += \" AND categorizations.category_id = #{@search[:category].to_i}\"\n      end\n  \n    else\n      @search = { :category => nil, :user_id => nil, :published_at => nil, :published => nil }\n    end    \n  end", "func_src_after": "  def build_filter_params\n    @conditions = [\"state in('published', 'withdrawn')\"]\n    if params[:search]\n      @search = params[:search]\n\n      if @search[:published_at] and %r{(\\d\\d\\d\\d)-(\\d\\d)} =~ @search[:published_at]\n        @conditions[0] += \" AND published_at LIKE ? \"\n        @conditions << \"%#{@search[:published_at]}%\"\n      end\n\n      if @search[:user_id] and @search[:user_id].to_i > 0\n        @conditions[0] += \" AND user_id = ? \"\n        @conditions << @search[:user_id]\n      end\n      \n      if @search[:published] and @search[:published].to_s =~ /0|1/\n        @conditions[0] += \" AND published = ? \"\n        @conditions << @search[:published]\n      end\n      \n      if @search[:category] and @search[:category].to_i > 0\n        @conditions[0] += \" AND categorizations.category_id = ? \"\n        @conditions << @search[:category]\n      end\n  \n    else\n      @search = { :category => nil, :user_id => nil, :published_at => nil, :published => nil }\n    end    \n  end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 26, "char_end": 81, "line": "    @conditions = \"state in('published', 'withdrawn')\"\n"}, {"line_no": 7, "char_start": 221, "char_end": 299, "line": "        @conditions += \" AND published_at LIKE '%#{@search[:published_at]}%'\"\n"}, {"line_no": 11, "char_start": 368, "char_end": 434, "line": "        @conditions += \" AND user_id = #{@search[:user_id].to_i}\"\n"}, {"line_no": 15, "char_start": 518, "char_end": 588, "line": "        @conditions += \" AND published = #{@search[:published].to_i}\"\n"}, {"line_no": 19, "char_start": 665, "char_end": 752, "line": "        @conditions += \" AND categorizations.category_id = #{@search[:category].to_i}\"\n"}], "added": [{"line_no": 2, "char_start": 26, "char_end": 83, "line": "    @conditions = [\"state in('published', 'withdrawn')\"]\n"}, {"line_no": 7, "char_start": 223, "char_end": 277, "line": "        @conditions[0] += \" AND published_at LIKE ? \"\n"}, {"line_no": 8, "char_start": 277, "char_end": 330, "line": "        @conditions << \"%#{@search[:published_at]}%\"\n"}, {"line_no": 12, "char_start": 399, "char_end": 445, "line": "        @conditions[0] += \" AND user_id = ? \"\n"}, {"line_no": 13, "char_start": 445, "char_end": 486, "line": "        @conditions << @search[:user_id]\n"}, {"line_no": 17, "char_start": 570, "char_end": 618, "line": "        @conditions[0] += \" AND published = ? \"\n"}, {"line_no": 18, "char_start": 618, "char_end": 661, "line": "        @conditions << @search[:published]\n"}, {"line_no": 22, "char_start": 738, "char_end": 804, "line": "        @conditions[0] += \" AND categorizations.category_id = ? \"\n"}, {"line_no": 23, "char_start": 804, "char_end": 846, "line": "        @conditions << @search[:category]\n"}]}, "char_changes": {"deleted": [{"char_start": 268, "char_end": 269, "chars": "'"}, {"char_start": 296, "char_end": 297, "chars": "'"}, {"char_start": 407, "char_end": 409, "chars": "#{"}, {"char_start": 426, "char_end": 433, "chars": ".to_i}\""}, {"char_start": 559, "char_end": 561, "chars": "#{"}, {"char_start": 580, "char_end": 587, "chars": ".to_i}\""}, {"char_start": 724, "char_end": 726, "chars": "#{"}, {"char_start": 744, "char_end": 751, "chars": ".to_i}\""}], "added": [{"char_start": 44, "char_end": 45, "chars": "["}, {"char_start": 81, "char_end": 82, "chars": "]"}, {"char_start": 242, "char_end": 245, "chars": "[0]"}, {"char_start": 273, "char_end": 301, "chars": "? \"\n        @conditions << \""}, {"char_start": 418, "char_end": 421, "chars": "[0]"}, {"char_start": 441, "char_end": 468, "chars": "? \"\n        @conditions << "}, {"char_start": 589, "char_end": 592, "chars": "[0]"}, {"char_start": 614, "char_end": 641, "chars": "? \"\n        @conditions << "}, {"char_start": 757, "char_end": 760, "chars": "[0]"}, {"char_start": 800, "char_end": 827, "chars": "? \"\n        @conditions << "}]}, "commit_link": "github.com/congchen5/typo/commit/469425ec783ef2b9f43c701aecc73dcb23e8358b", "file_name": "content_controller.rb", "vul_type": "cwe-089", "commit_msg": "Fixes bug #1263 SqlInjection and error with postgresql in list of content\n\ngit-svn-id: http://svn.typosphere.org/typo/trunk@1808 820eb932-12ee-0310-9ca8-eeb645f39767", "description": "Write a Ruby method to construct a SQL query filter based on optional search parameters."}
{"func_name": "extend_volume", "func_src_before": "    def extend_volume(self, volume, new_size):\n        LOG.debug(_('enter: extend_volume: volume %s') % volume['id'])\n        ret = self._ensure_vdisk_no_fc_mappings(volume['name'],\n                                                allow_snaps=False)\n        if not ret:\n            exception_message = (_('extend_volume: Extending a volume with '\n                                   'snapshots is not supported.'))\n            raise exception.VolumeBackendAPIException(data=exception_message)\n\n        extend_amt = int(new_size) - volume['size']\n        ssh_cmd = ('svctask expandvdisksize -size %(amt)d -unit gb %(name)s'\n                   % {'amt': extend_amt, 'name': volume['name']})\n        out, err = self._run_ssh(ssh_cmd)\n        # No output should be returned from expandvdisksize\n        self._assert_ssh_return(len(out.strip()) == 0, 'extend_volume',\n                                ssh_cmd, out, err)\n        LOG.debug(_('leave: extend_volume: volume %s') % volume['id'])", "func_src_after": "    def extend_volume(self, volume, new_size):\n        LOG.debug(_('enter: extend_volume: volume %s') % volume['id'])\n        ret = self._ensure_vdisk_no_fc_mappings(volume['name'],\n                                                allow_snaps=False)\n        if not ret:\n            exception_message = (_('extend_volume: Extending a volume with '\n                                   'snapshots is not supported.'))\n            raise exception.VolumeBackendAPIException(data=exception_message)\n\n        extend_amt = int(new_size) - volume['size']\n        ssh_cmd = (['svctask', 'expandvdisksize', '-size', str(extend_amt),\n                    '-unit', 'gb', volume['name']])\n        out, err = self._run_ssh(ssh_cmd)\n        # No output should be returned from expandvdisksize\n        self._assert_ssh_return(len(out.strip()) == 0, 'extend_volume',\n                                ssh_cmd, out, err)\n        LOG.debug(_('leave: extend_volume: volume %s') % volume['id'])", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to increase the size of a storage volume using SSH commands, ensuring no snapshots exist."}
{"func_name": "execute", "func_src_before": "func (v *VM) execute(t *thread, i code.Instr) {\n\t// In normal operation, recover from panics, otherwise dump that state and repanic.\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tif v.HardCrash {\n\t\t\t\tfmt.Printf(\"panic in thread %#v at instr %q: %s\\n\", t, i, r)\n\t\t\t\tpanic(r)\n\t\t\t}\n\t\t\tv.errorf(\"panic in thread %#v at instr %q: %s\", t, i, r)\n\t\t\tv.terminate = true\n\t\t}\n\t}()\n\n\tswitch i.Opcode {\n\tcase code.Bad:\n\t\tpanic(\"Invalid instruction.  Aborting.\")\n\n\tcase code.Stop:\n\t\tv.terminate = true\n\n\tcase code.Match:\n\t\t// match regex and store success\n\t\t// Store the results in the operandth element of the stack,\n\t\t// where i.opnd == the matched re index\n\t\tindex := i.Operand.(int)\n\t\tt.matches[index] = v.re[index].FindStringSubmatch(v.input.Line)\n\t\tt.Push(t.matches[index] != nil)\n\n\tcase code.Smatch:\n\t\t// match regex against item on the stack\n\t\tindex := i.Operand.(int)\n\t\tline, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"+%v\", err)\n\t\t\treturn\n\t\t}\n\t\tt.matches[index] = v.re[index].FindStringSubmatch(line)\n\t\tt.Push(t.matches[index] != nil)\n\n\tcase code.Cmp:\n\t\t// Compare two elements on the stack.\n\t\t// Set the match register based on the truthiness of the comparison.\n\t\t// Operand contains the expected result.\n\t\tb := t.Pop()\n\t\ta := t.Pop()\n\n\t\tmatch, err := compare(a, b, i.Operand.(int))\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\n\t\tt.Push(match)\n\n\tcase code.Icmp:\n\t\tb, berr := t.PopInt()\n\t\tif berr != nil {\n\t\t\tv.errorf(\"%+v\", berr)\n\t\t\treturn\n\t\t}\n\t\ta, aerr := t.PopInt()\n\t\tif aerr != nil {\n\t\t\tv.errorf(\"%+v\", aerr)\n\t\t\treturn\n\t\t}\n\t\tmatch, err := compareInt(a, b, i.Operand.(int))\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\n\t\tt.Push(match)\n\tcase code.Fcmp:\n\t\tb, berr := t.PopFloat()\n\t\tif berr != nil {\n\t\t\tv.errorf(\"%+v\", berr)\n\t\t\treturn\n\t\t}\n\t\ta, aerr := t.PopFloat()\n\t\tif aerr != nil {\n\t\t\tv.errorf(\"%+v\", aerr)\n\t\t}\n\t\tmatch, err := compareFloat(a, b, i.Operand.(int))\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\n\t\tt.Push(match)\n\tcase code.Scmp:\n\t\tb, berr := t.PopString()\n\t\tif berr != nil {\n\t\t\tv.errorf(\"%+v\", berr)\n\t\t\treturn\n\t\t}\n\t\ta, aerr := t.PopString()\n\t\tif aerr != nil {\n\t\t\tv.errorf(\"%+v\", aerr)\n\t\t\treturn\n\t\t}\n\t\tmatch, err := compareString(a, b, i.Operand.(int))\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\n\t\tt.Push(match)\n\n\tcase code.Jnm:\n\t\tval := t.Pop()\n\t\tswitch match := val.(type) {\n\t\tcase bool:\n\t\t\tif !match {\n\t\t\t\tt.pc = i.Operand.(int)\n\t\t\t}\n\t\tcase int64:\n\t\t\tif match == 0 {\n\t\t\t\tt.pc = i.Operand.(int)\n\t\t\t}\n\t\t}\n\n\tcase code.Jm:\n\t\tval := t.Pop()\n\t\tswitch match := val.(type) {\n\t\tcase bool:\n\t\t\tif match {\n\t\t\t\tt.pc = i.Operand.(int)\n\t\t\t}\n\t\tcase int64:\n\t\t\tif match != 0 {\n\t\t\t\tt.pc = i.Operand.(int)\n\t\t\t}\n\t\t}\n\n\tcase code.Jmp:\n\t\tt.pc = i.Operand.(int)\n\n\tcase code.Inc:\n\t\t// Increment a datum\n\t\tvar delta int64 = 1\n\t\t// If opnd is non-nil, the delta is on the stack.\n\t\tif i.Operand != nil {\n\t\t\tvar err error\n\t\t\tdelta, err = t.PopInt()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%s\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\tif n, ok := t.Pop().(datum.Datum); ok {\n\t\t\tdatum.IncIntBy(n, delta, t.time)\n\t\t\tt.Push(datum.GetInt(n))\n\t\t} else {\n\t\t\tv.errorf(\"Unexpected type to increment: %T %q\", n, n)\n\t\t\treturn\n\t\t}\n\n\tcase code.Dec:\n\t\t// Decrement a datum\n\t\tvar delta int64 = 1\n\t\t// If opnd is non-nil, the delta is on the stack.\n\t\tif i.Operand != nil {\n\t\t\tvar err error\n\t\t\tdelta, err = t.PopInt()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%s\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\tif n, ok := t.Pop().(datum.Datum); ok {\n\t\t\tdatum.DecIntBy(n, delta, t.time)\n\t\t\tt.Push(datum.GetInt(n))\n\t\t} else {\n\t\t\tv.errorf(\"Unexpected type to increment: %T %q\", n, n)\n\t\t\treturn\n\t\t}\n\n\tcase code.Iset:\n\t\t// Set a datum\n\t\tvalue, err := t.PopInt()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tif n, ok := t.Pop().(datum.Datum); ok {\n\t\t\tdatum.SetInt(n, value, t.time)\n\t\t} else {\n\t\t\tv.errorf(\"Unexpected type to iset: %T %q\", n, n)\n\t\t\treturn\n\t\t}\n\n\tcase code.Fset:\n\t\t// Set a datum\n\t\tvalue, err := t.PopFloat()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tif n, ok := t.Pop().(datum.Datum); ok {\n\t\t\tdatum.SetFloat(n, value, t.time)\n\t\t} else {\n\t\t\tv.errorf(\"Unexpected type to fset: %T %q\", n, n)\n\t\t\treturn\n\t\t}\n\n\tcase code.Sset:\n\t\t// Set a string datum\n\t\tvalue, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\t\tif n, ok := t.Pop().(datum.Datum); ok {\n\t\t\tdatum.SetString(n, value, t.time)\n\t\t} else {\n\t\t\tv.errorf(\"Unexpected type to sset: %T %q\", n, n)\n\t\t\treturn\n\t\t}\n\n\tcase code.Strptime:\n\t\t// Parse a time string into the time register\n\t\tlayout, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\n\t\tvar ts string\n\t\tswitch s := t.Pop().(type) {\n\t\tcase string:\n\t\t\tts = s\n\n\t\tcase int: /* capref */\n\t\t\t// First find the match storage index on the stack\n\t\t\tre := t.Pop().(int)\n\t\t\t// Store the result from the re'th index at the s'th index\n\t\t\tts = t.matches[re][s]\n\t\t}\n\t\tif cached, ok := v.timeMemos.Get(ts); !ok {\n\t\t\ttm := v.ParseTime(layout, ts)\n\t\t\tv.timeMemos.Add(ts, tm)\n\t\t\tt.time = tm\n\t\t} else {\n\t\t\tt.time = cached.(time.Time)\n\t\t}\n\n\tcase code.Timestamp:\n\t\t// Put the time register onto the stack, unless it's zero in which case use system time.\n\t\tif t.time.IsZero() {\n\t\t\tt.Push(time.Now().Unix())\n\t\t} else {\n\t\t\t// Put the time register onto the stack\n\t\t\tt.Push(t.time.Unix())\n\t\t}\n\n\tcase code.Settime:\n\t\t// Pop TOS and store in time register\n\t\tval := t.Pop()\n\t\tts, ok := val.(int64)\n\t\tif !ok {\n\t\t\tv.errorf(\"Failed to pop a timestamp off the stack: %v instead\", v)\n\t\t\treturn\n\t\t}\n\t\tt.time = time.Unix(ts, 0).UTC()\n\n\tcase code.Capref:\n\t\t// Put a capture group reference onto the stack.\n\t\t// First find the match storage index on the stack,\n\t\tval := t.Pop()\n\t\tre, ok := val.(int)\n\t\tif !ok {\n\t\t\tv.errorf(\"Invalid re index %v, not an int\", val)\n\t\t\treturn\n\t\t}\n\t\t// Push the result from the re'th match at operandth index\n\t\top, ok := i.Operand.(int)\n\t\tif !ok {\n\t\t\tv.errorf(\"Invalid operand %v, not an int\", i.Operand)\n\t\t\treturn\n\t\t}\n\t\tif len(t.matches[re]) <= op {\n\t\t\tv.errorf(\"Not enough capture groups matched from %v to select %dth\", t.matches[re], op)\n\t\t\treturn\n\t\t}\n\t\tt.Push(t.matches[re][op])\n\n\tcase code.Str:\n\t\t// Put a string constant onto the stack\n\t\tt.Push(v.str[i.Operand.(int)])\n\n\tcase code.Push:\n\t\t// Push a value onto the stack\n\t\tt.Push(i.Operand)\n\n\tcase code.Fadd, code.Fsub, code.Fmul, code.Fdiv, code.Fmod, code.Fpow:\n\t\tb, err := t.PopFloat()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\ta, err := t.PopFloat()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tswitch i.Opcode {\n\t\tcase code.Fadd:\n\t\t\tt.Push(a + b)\n\t\tcase code.Fsub:\n\t\t\tt.Push(a - b)\n\t\tcase code.Fmul:\n\t\t\tt.Push(a * b)\n\t\tcase code.Fdiv:\n\t\t\tt.Push(a / b)\n\t\tcase code.Fmod:\n\t\t\tt.Push(math.Mod(a, b))\n\t\tcase code.Fpow:\n\t\t\tt.Push(math.Pow(a, b))\n\t\t}\n\n\tcase code.Iadd, code.Isub, code.Imul, code.Idiv, code.Imod, code.Ipow, code.Shl, code.Shr, code.And, code.Or, code.Xor:\n\t\t// Op two values at TOS, and push result onto stack\n\t\tb, err := t.PopInt()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\ta, err := t.PopInt()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tswitch i.Opcode {\n\t\tcase code.Iadd:\n\t\t\tt.Push(a + b)\n\t\tcase code.Isub:\n\t\t\tt.Push(a - b)\n\t\tcase code.Imul:\n\t\t\tt.Push(a * b)\n\t\tcase code.Idiv:\n\t\t\tif b == 0 {\n\t\t\t\tv.errorf(\"Divide by zero %d %% %d\", a, b)\n\t\t\t\treturn\n\t\t\t}\n\t\t\t// Integer division\n\t\t\tt.Push(a / b)\n\t\tcase code.Imod:\n\t\t\tif b == 0 {\n\t\t\t\tv.errorf(\"Divide by zero %d %% %d\", a, b)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tt.Push(a % b)\n\t\tcase code.Ipow:\n\t\t\t// TODO(jaq): replace with type coercion\n\t\t\tt.Push(int64(math.Pow(float64(a), float64(b))))\n\t\tcase code.Shl:\n\t\t\tt.Push(a << uint(b))\n\t\tcase code.Shr:\n\t\t\tt.Push(a >> uint(b))\n\t\tcase code.And:\n\t\t\tt.Push(a & b)\n\t\tcase code.Or:\n\t\t\tt.Push(a | b)\n\t\tcase code.Xor:\n\t\t\tt.Push(a ^ b)\n\t\t}\n\n\tcase code.Neg:\n\t\ta, err := t.PopInt()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(^a)\n\n\tcase code.Not:\n\t\ta := t.Pop().(bool)\n\t\tt.Push(!a)\n\n\tcase code.Mload:\n\t\t// Load a metric at operand onto stack\n\t\tt.Push(v.Metrics[i.Operand.(int)])\n\n\tcase code.Dload:\n\t\t// Load a datum from metric at TOS onto stack\n\t\t// fmt.Printf(\"Stack: %v\\n\", t.stack)\n\t\tm := t.Pop().(*metrics.Metric)\n\t\t// fmt.Printf(\"Metric: %v\\n\", m)\n\t\tindex := i.Operand.(int)\n\t\tkeys := make([]string, index)\n\t\t// fmt.Printf(\"keys: %v\\n\", keys)\n\t\tfor a := index - 1; a >= 0; a-- {\n\t\t\ts, err := t.PopString()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%+v\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\t// fmt.Printf(\"s: %v\\n\", s)\n\t\t\tkeys[a] = s\n\t\t\t// fmt.Printf(\"Keys: %v\\n\", keys)\n\t\t}\n\t\t// fmt.Printf(\"Keys: %v\\n\", keys)\n\t\td, err := m.GetDatum(keys...)\n\t\tif err != nil {\n\t\t\tv.errorf(\"dload (GetDatum) failed: %s\", err)\n\t\t\treturn\n\t\t}\n\t\t// fmt.Printf(\"Found %v\\n\", d)\n\t\tt.Push(d)\n\n\tcase code.Iget, code.Fget, code.Sget:\n\t\td, ok := t.Pop().(datum.Datum)\n\t\tif !ok {\n\t\t\tv.errorf(\"Unexpected value on stack: %q\", d)\n\t\t\treturn\n\t\t}\n\t\tswitch i.Opcode {\n\t\tcase code.Iget:\n\t\t\tt.Push(datum.GetInt(d))\n\t\tcase code.Fget:\n\t\t\tt.Push(datum.GetFloat(d))\n\t\tcase code.Sget:\n\t\t\tt.Push(datum.GetString(d))\n\t\t}\n\n\tcase code.Del:\n\t\tm := t.Pop().(*metrics.Metric)\n\t\tindex := i.Operand.(int)\n\t\tkeys := make([]string, index)\n\t\tfor j := index - 1; j >= 0; j-- {\n\t\t\ts, err := t.PopString()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%+v\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tkeys[j] = s\n\t\t}\n\t\terr := m.RemoveDatum(keys...)\n\t\tif err != nil {\n\t\t\tv.errorf(\"del (RemoveDatum) failed: %s\", err)\n\t\t\treturn\n\t\t}\n\n\tcase code.Expire:\n\t\tm := t.Pop().(*metrics.Metric)\n\t\tindex := i.Operand.(int)\n\t\tkeys := make([]string, index)\n\t\tfor j := index - 1; j >= 0; j-- {\n\t\t\ts, err := t.PopString()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%+v\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tkeys[j] = s\n\t\t}\n\t\texpiry := t.Pop().(time.Duration)\n\t\tif err := m.ExpireDatum(expiry, keys...); err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\n\tcase code.Tolower:\n\t\t// Lowercase code.a string from TOS, and push result back.\n\t\ts, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(strings.ToLower(s))\n\n\tcase code.Length:\n\t\t// Compute the length of a string from TOS, and push result back.\n\t\ts, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(len(s))\n\n\tcase code.S2i:\n\t\tbase := int64(10)\n\t\tvar err error\n\t\tif i.Operand != nil {\n\t\t\t// strtol is emitted with an arglen, int is not\n\t\t\tbase, err = t.PopInt()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%s\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif base > 2147483647 || base < -2147483648 {\n\t\t\t\tv.errorf(\"int32 out of range\")\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\tstr, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\t\tval, err := strconv.ParseInt(str, int(base), 64)\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(val)\n\n\tcase code.S2f:\n\t\tstr, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\t\tf, err := strconv.ParseFloat(str, 64)\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(f)\n\n\tcase code.I2f:\n\t\ti, err := t.PopInt()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(float64(i))\n\n\tcase code.I2s:\n\t\ti, err := t.PopInt()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(fmt.Sprintf(\"%d\", i))\n\n\tcase code.F2s:\n\t\tf, err := t.PopFloat()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(fmt.Sprintf(\"%g\", f))\n\n\tcase code.Setmatched:\n\t\tt.matched = i.Operand.(bool)\n\n\tcase code.Otherwise:\n\t\t// Only match if the matched flag is false.\n\t\tt.Push(!t.matched)\n\n\tcase code.Getfilename:\n\t\tt.Push(v.input.Filename)\n\n\tcase code.Cat:\n\t\tb, berr := t.PopString()\n\t\tif berr != nil {\n\t\t\tv.errorf(\"%+v\", berr)\n\t\t\treturn\n\t\t}\n\t\ta, aerr := t.PopString()\n\t\tif aerr != nil {\n\t\t\tv.errorf(\"%+v\", aerr)\n\t\t\treturn\n\t\t}\n\t\tt.Push(a + b)\n\n\tcase code.Subst:\n\t\tval, verr := t.PopString()\n\t\tif verr != nil {\n\t\t\tv.errorf(\"%+v\", verr)\n\t\t\treturn\n\t\t}\n\t\trepl, nerr := t.PopString()\n\t\tif nerr != nil {\n\t\t\tv.errorf(\"%+v\", nerr)\n\t\t\treturn\n\t\t}\n\t\told, oerr := t.PopString()\n\t\tif oerr != nil {\n\t\t\tv.errorf(\"%+v\", oerr)\n\t\t\treturn\n\t\t}\n\t\tt.Push(strings.ReplaceAll(val, old, repl))\n\tcase code.Rsubst:\n\t\tpat, perr := t.PopInt()\n\t\tif perr != nil {\n\t\t\tv.errorf(\"%+v\", perr)\n\t\t\treturn\n\t\t}\n\t\tval, verr := t.PopString()\n\t\tif verr != nil {\n\t\t\tv.errorf(\"%+v\", verr)\n\t\t\treturn\n\t\t}\n\t\trepl, nerr := t.PopString()\n\t\tif nerr != nil {\n\t\t\tv.errorf(\"%+v\", nerr)\n\t\t\treturn\n\t\t}\n\t\tt.Push(v.re[pat].ReplaceAllLiteralString(val, repl))\n\n\tdefault:\n\t\tv.errorf(\"illegal instruction: %d\", i.Opcode)\n\t}\n}", "func_src_after": "func (v *VM) execute(t *thread, i code.Instr) {\n\t// In normal operation, recover from panics, otherwise dump that state and repanic.\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tif v.HardCrash {\n\t\t\t\tfmt.Printf(\"panic in thread %#v at instr %q: %s\\n\", t, i, r)\n\t\t\t\tpanic(r)\n\t\t\t}\n\t\t\tv.errorf(\"panic in thread %#v at instr %q: %s\", t, i, r)\n\t\t\tv.terminate = true\n\t\t}\n\t}()\n\n\tswitch i.Opcode {\n\tcase code.Bad:\n\t\tpanic(\"Invalid instruction.  Aborting.\")\n\n\tcase code.Stop:\n\t\tv.terminate = true\n\n\tcase code.Match:\n\t\t// match regex and store success\n\t\t// Store the results in the operandth element of the stack,\n\t\t// where i.opnd == the matched re index\n\t\tindex := i.Operand.(int)\n\t\tt.matches[index] = v.re[index].FindStringSubmatch(v.input.Line)\n\t\tt.Push(t.matches[index] != nil)\n\n\tcase code.Smatch:\n\t\t// match regex against item on the stack\n\t\tindex := i.Operand.(int)\n\t\tline, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"+%v\", err)\n\t\t\treturn\n\t\t}\n\t\tt.matches[index] = v.re[index].FindStringSubmatch(line)\n\t\tt.Push(t.matches[index] != nil)\n\n\tcase code.Cmp:\n\t\t// Compare two elements on the stack.\n\t\t// Set the match register based on the truthiness of the comparison.\n\t\t// Operand contains the expected result.\n\t\tb := t.Pop()\n\t\ta := t.Pop()\n\n\t\tmatch, err := compare(a, b, i.Operand.(int))\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\n\t\tt.Push(match)\n\n\tcase code.Icmp:\n\t\tb, berr := t.PopInt()\n\t\tif berr != nil {\n\t\t\tv.errorf(\"%+v\", berr)\n\t\t\treturn\n\t\t}\n\t\ta, aerr := t.PopInt()\n\t\tif aerr != nil {\n\t\t\tv.errorf(\"%+v\", aerr)\n\t\t\treturn\n\t\t}\n\t\tmatch, err := compareInt(a, b, i.Operand.(int))\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\n\t\tt.Push(match)\n\tcase code.Fcmp:\n\t\tb, berr := t.PopFloat()\n\t\tif berr != nil {\n\t\t\tv.errorf(\"%+v\", berr)\n\t\t\treturn\n\t\t}\n\t\ta, aerr := t.PopFloat()\n\t\tif aerr != nil {\n\t\t\tv.errorf(\"%+v\", aerr)\n\t\t}\n\t\tmatch, err := compareFloat(a, b, i.Operand.(int))\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\n\t\tt.Push(match)\n\tcase code.Scmp:\n\t\tb, berr := t.PopString()\n\t\tif berr != nil {\n\t\t\tv.errorf(\"%+v\", berr)\n\t\t\treturn\n\t\t}\n\t\ta, aerr := t.PopString()\n\t\tif aerr != nil {\n\t\t\tv.errorf(\"%+v\", aerr)\n\t\t\treturn\n\t\t}\n\t\tmatch, err := compareString(a, b, i.Operand.(int))\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\n\t\tt.Push(match)\n\n\tcase code.Jnm:\n\t\tval := t.Pop()\n\t\tswitch match := val.(type) {\n\t\tcase bool:\n\t\t\tif !match {\n\t\t\t\tt.pc = i.Operand.(int)\n\t\t\t}\n\t\tcase int64:\n\t\t\tif match == 0 {\n\t\t\t\tt.pc = i.Operand.(int)\n\t\t\t}\n\t\t}\n\n\tcase code.Jm:\n\t\tval := t.Pop()\n\t\tswitch match := val.(type) {\n\t\tcase bool:\n\t\t\tif match {\n\t\t\t\tt.pc = i.Operand.(int)\n\t\t\t}\n\t\tcase int64:\n\t\t\tif match != 0 {\n\t\t\t\tt.pc = i.Operand.(int)\n\t\t\t}\n\t\t}\n\n\tcase code.Jmp:\n\t\tt.pc = i.Operand.(int)\n\n\tcase code.Inc:\n\t\t// Increment a datum\n\t\tvar delta int64 = 1\n\t\t// If opnd is non-nil, the delta is on the stack.\n\t\tif i.Operand != nil {\n\t\t\tvar err error\n\t\t\tdelta, err = t.PopInt()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%s\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\tif n, ok := t.Pop().(datum.Datum); ok {\n\t\t\tdatum.IncIntBy(n, delta, t.time)\n\t\t\tt.Push(datum.GetInt(n))\n\t\t} else {\n\t\t\tv.errorf(\"Unexpected type to increment: %T %q\", n, n)\n\t\t\treturn\n\t\t}\n\n\tcase code.Dec:\n\t\t// Decrement a datum\n\t\tvar delta int64 = 1\n\t\t// If opnd is non-nil, the delta is on the stack.\n\t\tif i.Operand != nil {\n\t\t\tvar err error\n\t\t\tdelta, err = t.PopInt()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%s\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\tif n, ok := t.Pop().(datum.Datum); ok {\n\t\t\tdatum.DecIntBy(n, delta, t.time)\n\t\t\tt.Push(datum.GetInt(n))\n\t\t} else {\n\t\t\tv.errorf(\"Unexpected type to increment: %T %q\", n, n)\n\t\t\treturn\n\t\t}\n\n\tcase code.Iset:\n\t\t// Set a datum\n\t\tvalue, err := t.PopInt()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tif n, ok := t.Pop().(datum.Datum); ok {\n\t\t\tdatum.SetInt(n, value, t.time)\n\t\t} else {\n\t\t\tv.errorf(\"Unexpected type to iset: %T %q\", n, n)\n\t\t\treturn\n\t\t}\n\n\tcase code.Fset:\n\t\t// Set a datum\n\t\tvalue, err := t.PopFloat()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tif n, ok := t.Pop().(datum.Datum); ok {\n\t\t\tdatum.SetFloat(n, value, t.time)\n\t\t} else {\n\t\t\tv.errorf(\"Unexpected type to fset: %T %q\", n, n)\n\t\t\treturn\n\t\t}\n\n\tcase code.Sset:\n\t\t// Set a string datum\n\t\tvalue, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\t\tif n, ok := t.Pop().(datum.Datum); ok {\n\t\t\tdatum.SetString(n, value, t.time)\n\t\t} else {\n\t\t\tv.errorf(\"Unexpected type to sset: %T %q\", n, n)\n\t\t\treturn\n\t\t}\n\n\tcase code.Strptime:\n\t\t// Parse a time string into the time register\n\t\tlayout, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\n\t\tvar ts string\n\t\tswitch s := t.Pop().(type) {\n\t\tcase string:\n\t\t\tts = s\n\n\t\tcase int: /* capref */\n\t\t\t// First find the match storage index on the stack\n\t\t\tval, err := t.PopInt()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%s\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif val < 0 || val >= math.MaxInt32 {\n\t\t\t\tv.errorf(\"int32 index out of range\")\n\t\t\t\treturn\n\t\t\t}\n\t\t\tre := int(val)\n\t\t\t// Store the result from the re'th index at the s'th index\n\t\t\tts = t.matches[re][s]\n\t\t}\n\t\tif cached, ok := v.timeMemos.Get(ts); !ok {\n\t\t\ttm := v.ParseTime(layout, ts)\n\t\t\tv.timeMemos.Add(ts, tm)\n\t\t\tt.time = tm\n\t\t} else {\n\t\t\tt.time = cached.(time.Time)\n\t\t}\n\n\tcase code.Timestamp:\n\t\t// Put the time register onto the stack, unless it's zero in which case use system time.\n\t\tif t.time.IsZero() {\n\t\t\tt.Push(time.Now().Unix())\n\t\t} else {\n\t\t\t// Put the time register onto the stack\n\t\t\tt.Push(t.time.Unix())\n\t\t}\n\n\tcase code.Settime:\n\t\t// Pop TOS and store in time register\n\t\tval := t.Pop()\n\t\tts, ok := val.(int64)\n\t\tif !ok {\n\t\t\tv.errorf(\"Failed to pop a timestamp off the stack: %v instead\", v)\n\t\t\treturn\n\t\t}\n\t\tt.time = time.Unix(ts, 0).UTC()\n\n\tcase code.Capref:\n\t\t// Put a capture group reference onto the stack.\n\t\t// First find the match storage index on the stack,\n\t\tval := t.Pop()\n\t\tre, ok := val.(int)\n\t\tif !ok {\n\t\t\tv.errorf(\"Invalid re index %v, not an int\", val)\n\t\t\treturn\n\t\t}\n\t\t// Push the result from the re'th match at operandth index\n\t\top, ok := i.Operand.(int)\n\t\tif !ok {\n\t\t\tv.errorf(\"Invalid operand %v, not an int\", i.Operand)\n\t\t\treturn\n\t\t}\n\t\tif len(t.matches[re]) <= op {\n\t\t\tv.errorf(\"Not enough capture groups matched from %v to select %dth\", t.matches[re], op)\n\t\t\treturn\n\t\t}\n\t\tt.Push(t.matches[re][op])\n\n\tcase code.Str:\n\t\t// Put a string constant onto the stack\n\t\tt.Push(v.str[i.Operand.(int)])\n\n\tcase code.Push:\n\t\t// Push a value onto the stack\n\t\tt.Push(i.Operand)\n\n\tcase code.Fadd, code.Fsub, code.Fmul, code.Fdiv, code.Fmod, code.Fpow:\n\t\tb, err := t.PopFloat()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\ta, err := t.PopFloat()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tswitch i.Opcode {\n\t\tcase code.Fadd:\n\t\t\tt.Push(a + b)\n\t\tcase code.Fsub:\n\t\t\tt.Push(a - b)\n\t\tcase code.Fmul:\n\t\t\tt.Push(a * b)\n\t\tcase code.Fdiv:\n\t\t\tt.Push(a / b)\n\t\tcase code.Fmod:\n\t\t\tt.Push(math.Mod(a, b))\n\t\tcase code.Fpow:\n\t\t\tt.Push(math.Pow(a, b))\n\t\t}\n\n\tcase code.Iadd, code.Isub, code.Imul, code.Idiv, code.Imod, code.Ipow, code.Shl, code.Shr, code.And, code.Or, code.Xor:\n\t\t// Op two values at TOS, and push result onto stack\n\t\tb, err := t.PopInt()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\ta, err := t.PopInt()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tswitch i.Opcode {\n\t\tcase code.Iadd:\n\t\t\tt.Push(a + b)\n\t\tcase code.Isub:\n\t\t\tt.Push(a - b)\n\t\tcase code.Imul:\n\t\t\tt.Push(a * b)\n\t\tcase code.Idiv:\n\t\t\tif b == 0 {\n\t\t\t\tv.errorf(\"Divide by zero %d %% %d\", a, b)\n\t\t\t\treturn\n\t\t\t}\n\t\t\t// Integer division\n\t\t\tt.Push(a / b)\n\t\tcase code.Imod:\n\t\t\tif b == 0 {\n\t\t\t\tv.errorf(\"Divide by zero %d %% %d\", a, b)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tt.Push(a % b)\n\t\tcase code.Ipow:\n\t\t\t// TODO(jaq): replace with type coercion\n\t\t\tt.Push(int64(math.Pow(float64(a), float64(b))))\n\t\tcase code.Shl:\n\t\t\tif b < 0 || b >= math.MaxInt32 {\n\t\t\t\tv.errorf(\"shift int out of range\")\n\t\t\t\treturn\n\t\t\t}\n\t\t\tt.Push(a << uint(b))\n\t\tcase code.Shr:\n\t\t\tif b < 0 || b >= math.MaxInt32 {\n\t\t\t\tv.errorf(\"shift int out of range\")\n\t\t\t\treturn\n\t\t\t}\n\t\t\tt.Push(a >> uint(b))\n\t\tcase code.And:\n\t\t\tt.Push(a & b)\n\t\tcase code.Or:\n\t\t\tt.Push(a | b)\n\t\tcase code.Xor:\n\t\t\tt.Push(a ^ b)\n\t\t}\n\n\tcase code.Neg:\n\t\ta, err := t.PopInt()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(^a)\n\n\tcase code.Not:\n\t\ta := t.Pop().(bool)\n\t\tt.Push(!a)\n\n\tcase code.Mload:\n\t\t// Load a metric at operand onto stack\n\t\tt.Push(v.Metrics[i.Operand.(int)])\n\n\tcase code.Dload:\n\t\t// Load a datum from metric at TOS onto stack\n\t\t// fmt.Printf(\"Stack: %v\\n\", t.stack)\n\t\tm := t.Pop().(*metrics.Metric)\n\t\t// fmt.Printf(\"Metric: %v\\n\", m)\n\t\tindex := i.Operand.(int)\n\t\tkeys := make([]string, index)\n\t\t// fmt.Printf(\"keys: %v\\n\", keys)\n\t\tfor a := index - 1; a >= 0; a-- {\n\t\t\ts, err := t.PopString()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%+v\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\t// fmt.Printf(\"s: %v\\n\", s)\n\t\t\tkeys[a] = s\n\t\t\t// fmt.Printf(\"Keys: %v\\n\", keys)\n\t\t}\n\t\t// fmt.Printf(\"Keys: %v\\n\", keys)\n\t\td, err := m.GetDatum(keys...)\n\t\tif err != nil {\n\t\t\tv.errorf(\"dload (GetDatum) failed: %s\", err)\n\t\t\treturn\n\t\t}\n\t\t// fmt.Printf(\"Found %v\\n\", d)\n\t\tt.Push(d)\n\n\tcase code.Iget, code.Fget, code.Sget:\n\t\td, ok := t.Pop().(datum.Datum)\n\t\tif !ok {\n\t\t\tv.errorf(\"Unexpected value on stack: %q\", d)\n\t\t\treturn\n\t\t}\n\t\tswitch i.Opcode {\n\t\tcase code.Iget:\n\t\t\tt.Push(datum.GetInt(d))\n\t\tcase code.Fget:\n\t\t\tt.Push(datum.GetFloat(d))\n\t\tcase code.Sget:\n\t\t\tt.Push(datum.GetString(d))\n\t\t}\n\n\tcase code.Del:\n\t\tm := t.Pop().(*metrics.Metric)\n\t\tindex := i.Operand.(int)\n\t\tkeys := make([]string, index)\n\t\tfor j := index - 1; j >= 0; j-- {\n\t\t\ts, err := t.PopString()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%+v\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tkeys[j] = s\n\t\t}\n\t\terr := m.RemoveDatum(keys...)\n\t\tif err != nil {\n\t\t\tv.errorf(\"del (RemoveDatum) failed: %s\", err)\n\t\t\treturn\n\t\t}\n\n\tcase code.Expire:\n\t\tm := t.Pop().(*metrics.Metric)\n\t\tindex := i.Operand.(int)\n\t\tkeys := make([]string, index)\n\t\tfor j := index - 1; j >= 0; j-- {\n\t\t\ts, err := t.PopString()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%+v\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tkeys[j] = s\n\t\t}\n\t\texpiry := t.Pop().(time.Duration)\n\t\tif err := m.ExpireDatum(expiry, keys...); err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\n\tcase code.Tolower:\n\t\t// Lowercase code.a string from TOS, and push result back.\n\t\ts, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(strings.ToLower(s))\n\n\tcase code.Length:\n\t\t// Compute the length of a string from TOS, and push result back.\n\t\ts, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(len(s))\n\n\tcase code.S2i:\n\t\tbase := 10\n\t\tvar err error\n\t\tif i.Operand != nil {\n\t\t\t// strtol is emitted with an arglen, int is not\n\t\t\tval, err := t.PopInt()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%s\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif val <= 0 || val >= math.MaxInt32 {\n\t\t\t\tv.errorf(\"int32 out of range\")\n\t\t\t\treturn\n\t\t\t}\n\t\t\tbase = int(val)\n\t\t}\n\t\tstr, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\t\tval, err := strconv.ParseInt(str, base, 64)\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(val)\n\n\tcase code.S2f:\n\t\tstr, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\t\tf, err := strconv.ParseFloat(str, 64)\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(f)\n\n\tcase code.I2f:\n\t\ti, err := t.PopInt()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(float64(i))\n\n\tcase code.I2s:\n\t\ti, err := t.PopInt()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(fmt.Sprintf(\"%d\", i))\n\n\tcase code.F2s:\n\t\tf, err := t.PopFloat()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(fmt.Sprintf(\"%g\", f))\n\n\tcase code.Setmatched:\n\t\tt.matched = i.Operand.(bool)\n\n\tcase code.Otherwise:\n\t\t// Only match if the matched flag is false.\n\t\tt.Push(!t.matched)\n\n\tcase code.Getfilename:\n\t\tt.Push(v.input.Filename)\n\n\tcase code.Cat:\n\t\tb, berr := t.PopString()\n\t\tif berr != nil {\n\t\t\tv.errorf(\"%+v\", berr)\n\t\t\treturn\n\t\t}\n\t\ta, aerr := t.PopString()\n\t\tif aerr != nil {\n\t\t\tv.errorf(\"%+v\", aerr)\n\t\t\treturn\n\t\t}\n\t\tt.Push(a + b)\n\n\tcase code.Subst:\n\t\tval, verr := t.PopString()\n\t\tif verr != nil {\n\t\t\tv.errorf(\"%+v\", verr)\n\t\t\treturn\n\t\t}\n\t\trepl, nerr := t.PopString()\n\t\tif nerr != nil {\n\t\t\tv.errorf(\"%+v\", nerr)\n\t\t\treturn\n\t\t}\n\t\told, oerr := t.PopString()\n\t\tif oerr != nil {\n\t\t\tv.errorf(\"%+v\", oerr)\n\t\t\treturn\n\t\t}\n\t\tt.Push(strings.ReplaceAll(val, old, repl))\n\tcase code.Rsubst:\n\t\tpat, perr := t.PopInt()\n\t\tif perr != nil {\n\t\t\tv.errorf(\"%+v\", perr)\n\t\t\treturn\n\t\t}\n\t\tval, verr := t.PopString()\n\t\tif verr != nil {\n\t\t\tv.errorf(\"%+v\", verr)\n\t\t\treturn\n\t\t}\n\t\trepl, nerr := t.PopString()\n\t\tif nerr != nil {\n\t\t\tv.errorf(\"%+v\", nerr)\n\t\t\treturn\n\t\t}\n\t\tt.Push(v.re[pat].ReplaceAllLiteralString(val, repl))\n\n\tdefault:\n\t\tv.errorf(\"illegal instruction: %d\", i.Opcode)\n\t}\n}", "line_changes": {"deleted": [{"line_no": 235, "char_start": 4715, "char_end": 4738, "line": "\t\t\tre := t.Pop().(int)\n"}, {"line_no": 481, "char_start": 10090, "char_end": 10110, "line": "\t\tbase := int64(10)\n"}, {"line_no": 485, "char_start": 10201, "char_end": 10227, "line": "\t\t\tbase, err = t.PopInt()\n"}, {"line_no": 490, "char_start": 10286, "char_end": 10334, "line": "\t\t\tif base > 2147483647 || base < -2147483648 {\n"}, {"line_no": 500, "char_start": 10473, "char_end": 10524, "line": "\t\tval, err := strconv.ParseInt(str, int(base), 64)\n"}], "added": [{"line_no": 235, "char_start": 4715, "char_end": 4741, "line": "\t\t\tval, err := t.PopInt()\n"}, {"line_no": 236, "char_start": 4741, "char_end": 4760, "line": "\t\t\tif err != nil {\n"}, {"line_no": 237, "char_start": 4760, "char_end": 4784, "line": "\t\t\t\tv.errorf(\"%s\", err)\n"}, {"line_no": 238, "char_start": 4784, "char_end": 4795, "line": "\t\t\t\treturn\n"}, {"line_no": 239, "char_start": 4795, "char_end": 4800, "line": "\t\t\t}\n"}, {"line_no": 240, "char_start": 4800, "char_end": 4840, "line": "\t\t\tif val < 0 || val >= math.MaxInt32 {\n"}, {"line_no": 241, "char_start": 4840, "char_end": 4881, "line": "\t\t\t\tv.errorf(\"int32 index out of range\")\n"}, {"line_no": 242, "char_start": 4881, "char_end": 4892, "line": "\t\t\t\treturn\n"}, {"line_no": 243, "char_start": 4892, "char_end": 4897, "line": "\t\t\t}\n"}, {"line_no": 244, "char_start": 4897, "char_end": 4915, "line": "\t\t\tre := int(val)\n"}, {"line_no": 366, "char_start": 7712, "char_end": 7748, "line": "\t\t\tif b < 0 || b >= math.MaxInt32 {\n"}, {"line_no": 367, "char_start": 7748, "char_end": 7787, "line": "\t\t\t\tv.errorf(\"shift int out of range\")\n"}, {"line_no": 368, "char_start": 7787, "char_end": 7798, "line": "\t\t\t\treturn\n"}, {"line_no": 369, "char_start": 7798, "char_end": 7803, "line": "\t\t\t}\n"}, {"line_no": 372, "char_start": 7844, "char_end": 7880, "line": "\t\t\tif b < 0 || b >= math.MaxInt32 {\n"}, {"line_no": 373, "char_start": 7880, "char_end": 7919, "line": "\t\t\t\tv.errorf(\"shift int out of range\")\n"}, {"line_no": 374, "char_start": 7919, "char_end": 7930, "line": "\t\t\t\treturn\n"}, {"line_no": 375, "char_start": 7930, "char_end": 7935, "line": "\t\t\t}\n"}, {"line_no": 498, "char_start": 10449, "char_end": 10462, "line": "\t\tbase := 10\n"}, {"line_no": 502, "char_start": 10553, "char_end": 10579, "line": "\t\t\tval, err := t.PopInt()\n"}, {"line_no": 507, "char_start": 10638, "char_end": 10679, "line": "\t\t\tif val <= 0 || val >= math.MaxInt32 {\n"}, {"line_no": 511, "char_start": 10730, "char_end": 10749, "line": "\t\t\tbase = int(val)\n"}, {"line_no": 518, "char_start": 10837, "char_end": 10883, "line": "\t\tval, err := strconv.ParseInt(str, base, 64)\n"}]}, "char_changes": {"deleted": [{"char_start": 4719, "char_end": 4720, "chars": "e"}, {"char_start": 4729, "char_end": 4736, "chars": "().(int"}, {"char_start": 7538, "char_end": 7575, "chars": "t.Push(a << uint(b))\n\t\tcase code.Shr:"}, {"char_start": 10100, "char_end": 10106, "chars": "int64("}, {"char_start": 10108, "char_end": 10109, "chars": ")"}, {"char_start": 10204, "char_end": 10208, "chars": "base"}, {"char_start": 10292, "char_end": 10331, "chars": "base > 2147483647 || base < -2147483648"}, {"char_start": 10509, "char_end": 10513, "chars": "int("}, {"char_start": 10517, "char_end": 10518, "chars": ")"}], "added": [{"char_start": 4718, "char_end": 4725, "chars": "val, er"}, {"char_start": 4735, "char_end": 4913, "chars": "Int()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%s\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif val < 0 || val >= math.MaxInt32 {\n\t\t\t\tv.errorf(\"int32 index out of range\")\n\t\t\t\treturn\n\t\t\t}\n\t\t\tre := int(val"}, {"char_start": 7715, "char_end": 7934, "chars": "if b < 0 || b >= math.MaxInt32 {\n\t\t\t\tv.errorf(\"shift int out of range\")\n\t\t\t\treturn\n\t\t\t}\n\t\t\tt.Push(a << uint(b))\n\t\tcase code.Shr:\n\t\t\tif b < 0 || b >= math.MaxInt32 {\n\t\t\t\tv.errorf(\"shift int out of range\")\n\t\t\t\treturn\n\t\t\t}"}, {"char_start": 10556, "char_end": 10559, "chars": "val"}, {"char_start": 10565, "char_end": 10566, "chars": ":"}, {"char_start": 10644, "char_end": 10676, "chars": "val <= 0 || val >= math.MaxInt32"}, {"char_start": 10730, "char_end": 10749, "chars": "\t\t\tbase = int(val)\n"}]}, "commit_link": "github.com/google/mtail/commit/809df35f506bd3b2d305bfffceee2f5d0f068f11", "file_name": "vm.go", "vul_type": "cwe-681", "commit_msg": "Fix integer overflow warnings.", "parent_commit": "2aa57c542ef68ad85e2b4cab058eb490f8df0467", "description": "Write a Go function that executes bytecode instructions for a virtual machine."}
{"func_name": "commentcounts", "func_src_before": "@register.tag\n@basictag(takes_context=True)\ndef commentcounts(context, filediff, interfilediff=None):\n    \"\"\"\n    Returns a JSON array of current comments for a filediff, sorted by\n    line number.\n\n    Each entry in the array has a dictionary containing the following keys:\n\n      =========== ==================================================\n      Key         Description\n      =========== ==================================================\n      comment_id  The ID of the comment\n      text        The text of the comment\n      line        The first line number\n      num_lines   The number of lines this comment spans\n      user        A dictionary containing \"username\" and \"name\" keys\n                  for the user\n      url         The URL to the comment\n      localdraft  True if this is the current user's draft comment\n      =========== ==================================================\n    \"\"\"\n    comment_dict = {}\n    user = context.get('user', None)\n\n    if interfilediff:\n        query = Comment.objects.filter(filediff=filediff,\n                                       interfilediff=interfilediff)\n    else:\n        query = Comment.objects.filter(filediff=filediff,\n                                       interfilediff__isnull=True)\n\n    for comment in query:\n        review = get_object_or_none(comment.review)\n\n        if review and (review.public or review.user == user):\n            key = (comment.first_line, comment.num_lines)\n\n            comment_dict.setdefault(key, []).append({\n                'comment_id': comment.id,\n                'text': comment.text,\n                'line': comment.first_line,\n                'num_lines': comment.num_lines,\n                'user': {\n                    'username': review.user.username,\n                    'name': review.user.get_full_name() or review.user.username,\n                },\n                #'timestamp': comment.timestamp,\n                'url': comment.get_review_url(),\n                'localdraft': review.user == user and \\\n                              not review.public,\n            })\n\n    comments_array = []\n\n    for key, value in comment_dict.iteritems():\n        comments_array.append({\n            'linenum': key[0],\n            'num_lines': key[1],\n            'comments': value,\n        })\n\n    comments_array.sort(cmp=lambda x, y: cmp(x['linenum'], y['linenum'] or\n                                         cmp(x['num_lines'], y['num_lines'])))\n\n    return simplejson.dumps(comments_array)", "func_src_after": "@register.tag\n@basictag(takes_context=True)\ndef commentcounts(context, filediff, interfilediff=None):\n    \"\"\"\n    Returns a JSON array of current comments for a filediff, sorted by\n    line number.\n\n    Each entry in the array has a dictionary containing the following keys:\n\n      =========== ==================================================\n      Key         Description\n      =========== ==================================================\n      comment_id  The ID of the comment\n      text        The text of the comment\n      line        The first line number\n      num_lines   The number of lines this comment spans\n      user        A dictionary containing \"username\" and \"name\" keys\n                  for the user\n      url         The URL to the comment\n      localdraft  True if this is the current user's draft comment\n      =========== ==================================================\n    \"\"\"\n    comment_dict = {}\n    user = context.get('user', None)\n\n    if interfilediff:\n        query = Comment.objects.filter(filediff=filediff,\n                                       interfilediff=interfilediff)\n    else:\n        query = Comment.objects.filter(filediff=filediff,\n                                       interfilediff__isnull=True)\n\n    for comment in query:\n        review = get_object_or_none(comment.review)\n\n        if review and (review.public or review.user == user):\n            key = (comment.first_line, comment.num_lines)\n\n            comment_dict.setdefault(key, []).append({\n                'comment_id': comment.id,\n                'text': escape(comment.text),\n                'line': comment.first_line,\n                'num_lines': comment.num_lines,\n                'user': {\n                    'username': review.user.username,\n                    'name': review.user.get_full_name() or review.user.username,\n                },\n                #'timestamp': comment.timestamp,\n                'url': comment.get_review_url(),\n                'localdraft': review.user == user and \\\n                              not review.public,\n            })\n\n    comments_array = []\n\n    for key, value in comment_dict.iteritems():\n        comments_array.append({\n            'linenum': key[0],\n            'num_lines': key[1],\n            'comments': value,\n        })\n\n    comments_array.sort(cmp=lambda x, y: cmp(x['linenum'], y['linenum'] or\n                                         cmp(x['num_lines'], y['num_lines'])))\n\n    return simplejson.dumps(comments_array)", "commit_link": "github.com/reviewboard/reviewboard/commit/7a0a9d94555502278534dedcf2d75e9fccce8c3d", "file_name": "reviewboard/reviews/templatetags/reviewtags.py", "vul_type": "cwe-079", "description": "In Python, write a function that returns a JSON array of comments for a file difference, including metadata like comment ID, text, line number, and user details, sorted by line number."}
{"func_name": "read_plist", "func_src_before": "    def read_plist(pathname)\n      transformed_pathname = pathname.gsub!(%r{[^0-9A-Za-z. \\-'/]}, '')\n      transformed_pathname = pathname if transformed_pathname.nil?\n      JSON.parse(`plutil -convert json -o - '#{transformed_pathname}'`)\n    end", "func_src_after": "    def read_plist(pathname)\n      out, err, status = Open3.capture3('plutil', '-convert', 'json', '-o', '-', pathname)\n      raise \"#{out}\\n\\n#{err}\" unless status.success?\n\n      JSON.parse(out)\n    end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 29, "char_end": 101, "line": "      transformed_pathname = pathname.gsub!(%r{[^0-9A-Za-z. \\-'/]}, '')\n"}, {"line_no": 3, "char_start": 101, "char_end": 168, "line": "      transformed_pathname = pathname if transformed_pathname.nil?\n"}, {"line_no": 4, "char_start": 168, "char_end": 240, "line": "      JSON.parse(`plutil -convert json -o - '#{transformed_pathname}'`)\n"}], "added": [{"line_no": 2, "char_start": 29, "char_end": 120, "line": "      out, err, status = Open3.capture3('plutil', '-convert', 'json', '-o', '-', pathname)\n"}, {"line_no": 3, "char_start": 120, "char_end": 174, "line": "      raise \"#{out}\\n\\n#{err}\" unless status.success?\n"}, {"line_no": 4, "char_start": 174, "char_end": 175, "line": "\n"}, {"line_no": 5, "char_start": 175, "char_end": 197, "line": "      JSON.parse(out)\n"}]}, "char_changes": {"deleted": [{"char_start": 35, "char_end": 99, "chars": "transformed_pathname = pathname.gsub!(%r{[^0-9A-Za-z. \\-'/]}, ''"}, {"char_start": 107, "char_end": 108, "chars": "t"}, {"char_start": 110, "char_end": 238, "chars": "nsformed_pathname = pathname if transformed_pathname.nil?\n      JSON.parse(`plutil -convert json -o - '#{transformed_pathname}'`"}], "added": [{"char_start": 35, "char_end": 195, "chars": "out, err, status = Open3.capture3('plutil', '-convert', 'json', '-o', '-', pathname)\n      raise \"#{out}\\n\\n#{err}\" unless status.success?\n\n      JSON.parse(out"}]}, "commit_link": "github.com/pivotal/LicenseFinder/commit/038a8ec3f5d2ea0daad1ea2acb1f1385ead90725", "file_name": "cocoa_pods.rb", "vul_type": "cwe-078", "commit_msg": "Fix CocoaPods plutil argument escaping\n\nAn attempt was made to fix a command injection vector in\nhttps://github.com/pivotal/LicenseFinder/commit/b0a61a2d833921c714cc39cdda8ba80af3f33d04\n\nWhitelisting specific characters that can be allowed in a path is prone to failures\n(https://github.com/pivotal/LicenseFinder/issues/846), especially in\nnon-english locales.\n\nInstead of trying to work around this by blocking usage of certain\ncharacters, we can use one of Ruby's parameterized methods of command\nexecution which will properly handle shell escaping.", "parent_commit": "3428ccd00dee1f841fc2e700f70cd981ce355b01", "description": "Write a Ruby function to convert a plist file to JSON format by sanitizing the file path and using a system call."}
{"func_name": "get_mapped_projects", "func_src_before": "    @staticmethod\n    def get_mapped_projects(user_id: int, preferred_locale: str) -> UserMappedProjectsDTO:\n        \"\"\" Get all projects a user has mapped on \"\"\"\n\n        # This query looks scary, but we're really just creating an outer join between the query that gets the\n        # counts of all mapped tasks and the query that gets counts of all validated tasks.  This is necessary to\n        # handle cases where users have only validated tasks on a project, or only mapped on a project.\n        sql = '''SELECT p.id,\n                        p.status,\n                        p.default_locale,\n                        c.mapped,\n                        c.validated,\n                        st_asgeojson(p.centroid)\n                   FROM projects p,\n                        (SELECT coalesce(v.project_id, m.project_id) project_id,\n                                coalesce(v.validated, 0) validated,\n                                coalesce(m.mapped, 0) mapped\n                          FROM (SELECT t.project_id,\n                                       count (t.validated_by) validated\n                                  FROM tasks t\n                                 WHERE t.project_id IN (SELECT unnest(projects_mapped) FROM users WHERE id = {0})\n                                   AND t.validated_by = {0}\n                                 GROUP BY t.project_id, t.validated_by) v\n                         FULL OUTER JOIN\n                        (SELECT t.project_id,\n                                count(t.mapped_by) mapped\n                           FROM tasks t\n                          WHERE t.project_id IN (SELECT unnest(projects_mapped) FROM users WHERE id = {0})\n                            AND t.mapped_by = {0}\n                          GROUP BY t.project_id, t.mapped_by) m\n                         ON v.project_id = m.project_id) c\n                   WHERE p.id = c.project_id ORDER BY p.id DESC'''.format(user_id)\n\n        results = db.engine.execute(sql)\n\n        if results.rowcount == 0:\n            raise NotFound()\n\n        mapped_projects_dto = UserMappedProjectsDTO()\n        for row in results:\n            mapped_project = MappedProject()\n            mapped_project.project_id = row[0]\n            mapped_project.status = ProjectStatus(row[1]).name\n            mapped_project.tasks_mapped = row[3]\n            mapped_project.tasks_validated = row[4]\n            mapped_project.centroid = geojson.loads(row[5])\n\n            project_info = ProjectInfo.get_dto_for_locale(row[0], preferred_locale, row[2])\n            mapped_project.name = project_info.name\n\n            mapped_projects_dto.mapped_projects.append(mapped_project)\n\n        return mapped_projects_dto", "func_src_after": "    @staticmethod\n    def get_mapped_projects(user_id: int, preferred_locale: str) -> UserMappedProjectsDTO:\n        \"\"\" Get all projects a user has mapped on \"\"\"\n\n        # This query looks scary, but we're really just creating an outer join between the query that gets the\n        # counts of all mapped tasks and the query that gets counts of all validated tasks.  This is necessary to\n        # handle cases where users have only validated tasks on a project, or only mapped on a project.\n        sql = '''SELECT p.id,\n                        p.status,\n                        p.default_locale,\n                        c.mapped,\n                        c.validated,\n                        st_asgeojson(p.centroid)\n                   FROM projects p,\n                        (SELECT coalesce(v.project_id, m.project_id) project_id,\n                                coalesce(v.validated, 0) validated,\n                                coalesce(m.mapped, 0) mapped\n                          FROM (SELECT t.project_id,\n                                       count (t.validated_by) validated\n                                  FROM tasks t\n                                 WHERE t.project_id IN (SELECT unnest(projects_mapped) FROM users WHERE id = :user_id)\n                                   AND t.validated_by = :user_id\n                                 GROUP BY t.project_id, t.validated_by) v\n                         FULL OUTER JOIN\n                        (SELECT t.project_id,\n                                count(t.mapped_by) mapped\n                           FROM tasks t\n                          WHERE t.project_id IN (SELECT unnest(projects_mapped) FROM users WHERE id = :user_id)\n                            AND t.mapped_by = :user_id\n                          GROUP BY t.project_id, t.mapped_by) m\n                         ON v.project_id = m.project_id) c\n                   WHERE p.id = c.project_id ORDER BY p.id DESC'''\n\n        results = db.engine.execute(text(sql), user_id=user_id)\n\n        if results.rowcount == 0:\n            raise NotFound()\n\n        mapped_projects_dto = UserMappedProjectsDTO()\n        for row in results:\n            mapped_project = MappedProject()\n            mapped_project.project_id = row[0]\n            mapped_project.status = ProjectStatus(row[1]).name\n            mapped_project.tasks_mapped = row[3]\n            mapped_project.tasks_validated = row[4]\n            mapped_project.centroid = geojson.loads(row[5])\n\n            project_info = ProjectInfo.get_dto_for_locale(row[0], preferred_locale, row[2])\n            mapped_project.name = project_info.name\n\n            mapped_projects_dto.mapped_projects.append(mapped_project)\n\n        return mapped_projects_dto", "commit_link": "github.com/hotosm/tasking-manager/commit/dee040a2d22b3c4d5e38e2dbf8c6b651ad4c241a", "file_name": "server/models/postgis/user.py", "vul_type": "cwe-089", "description": "In Python, write a method to retrieve a user's mapped projects with task counts and localization details."}
{"func_name": "_launch_cli", "func_src_before": "  def _launch_cli(self):\n    if self._is_run_start:\n      self.observers[\"run_start_cli_run_numbers\"].append(self._run_call_count)\n    else:\n      self.observers[\"run_end_cli_run_numbers\"].append(self._run_call_count)\n\n    readline_cli = ui_factory.get_ui(\n        \"readline\",\n        config=cli_config.CLIConfig(\n            config_file_path=os.path.join(tempfile.mkdtemp(), \".tfdbg_config\")))\n    self._register_this_run_info(readline_cli)\n\n    while True:\n      command = self._command_sequence[self._command_pointer]\n      self._command_pointer += 1\n\n      try:\n        if command[0] == \"run\":\n          self._run_handler(command[1:])\n        elif command[0] == \"print_feed\":\n          self.observers[\"print_feed_responses\"].append(\n              self._print_feed_handler(command[1:]))\n        else:\n          raise ValueError(\"Unrecognized command prefix: %s\" % command[0])\n      except debugger_cli_common.CommandLineExit as e:\n        return e.exit_token", "func_src_after": "  def _launch_cli(self):\n    if self._is_run_start:\n      self.observers[\"run_start_cli_run_numbers\"].append(self._run_call_count)\n    else:\n      self.observers[\"run_end_cli_run_numbers\"].append(self._run_call_count)\n\n    readline_cli = ui_factory.get_ui(\n        \"readline\",\n        config=cli_config.CLIConfig(\n            config_file_path=os.path.join(tempfile.mkdtemp(), \".tfdbg_config\")))\n    self._register_this_run_info(readline_cli)\n\n    while self._command_pointer < len(self._command_sequence):\n      command = self._command_sequence[self._command_pointer]\n      self._command_pointer += 1\n\n      try:\n        if command[0] == \"run\":\n          self._run_handler(command[1:])\n        elif command[0] == \"print_feed\":\n          self.observers[\"print_feed_responses\"].append(\n              self._print_feed_handler(command[1:]))\n        else:\n          raise ValueError(\"Unrecognized command prefix: %s\" % command[0])\n      except debugger_cli_common.CommandLineExit as e:\n        return e.exit_token", "line_changes": {"deleted": [{"line_no": 13, "char_start": 443, "char_end": 459, "line": "    while True:\n"}], "added": [{"line_no": 13, "char_start": 443, "char_end": 506, "line": "    while self._command_pointer < len(self._command_sequence):\n"}]}, "char_changes": {"deleted": [{"char_start": 453, "char_end": 457, "chars": "True"}], "added": [{"char_start": 453, "char_end": 504, "chars": "self._command_pointer < len(self._command_sequence)"}]}, "commit_link": "github.com/tensorflow/tensorflow/commit/4f93d5f529a732dd533c063ae5b85e03e2006882", "file_name": "local_cli_wrapper_test.py", "vul_type": "cwe-377", "commit_msg": "Use `tempfile.mkdtemp` instead of `tempfile.mktemp`.\n\nThe `tempfile.mktemp` function is [deprecated](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp) due to [security issues](https://cwe.mitre.org/data/definitions/377.html).\n\nThe switch is easy to do.\n\nPiperOrigin-RevId: 420369603\nChange-Id: I2cf40b13f41cc01000c2c21a483a2d680194dba2", "description": "Write a Python function to handle CLI commands for running tasks and printing feeds, with error handling for unrecognized commands."}
{"func_name": "get_markets", "func_src_before": "@app.route('/get_markets')\ndef get_markets():\n    asset_id = request.args.get('asset_id')\n\n    if not isObject(asset_id):\n        ws.send('{\"id\":1, \"method\":\"call\", \"params\":[0,\"lookup_asset_symbols\",[[\"' + asset_id + '\"], 0]]}')\n        result_l = ws.recv()\n        j_l = json.loads(result_l)\n        asset_id = j_l[\"result\"][0][\"id\"]\n\n\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"SELECT * FROM markets WHERE aid='\"+asset_id+\"'\"\n    cur.execute(query)\n    results = cur.fetchall()\n    con.close()\n    return jsonify(results)", "func_src_after": "@app.route('/get_markets')\ndef get_markets():\n    asset_id = request.args.get('asset_id')\n\n    if not isObject(asset_id):\n        ws.send('{\"id\":1, \"method\":\"call\", \"params\":[0,\"lookup_asset_symbols\",[[\"' + asset_id + '\"], 0]]}')\n        result_l = ws.recv()\n        j_l = json.loads(result_l)\n        asset_id = j_l[\"result\"][0][\"id\"]\n\n\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"SELECT * FROM markets WHERE aid=%s\"\n    cur.execute(query, (asset_id,))\n    results = cur.fetchall()\n    con.close()\n    return jsonify(results)", "commit_link": "github.com/VinChain/vinchain-python-api-backend/commit/b78088a551fbb712121269c6eb7f43ede120ff60", "file_name": "api.py", "vul_type": "cwe-089", "description": "Create a Python Flask endpoint that retrieves market data for a given asset ID from a PostgreSQL database, handling the asset ID lookup and database query."}
{"func_name": "process_vote", "func_src_before": "def process_vote(target,action,chan,mask,db,notice,conn):\n    if ' ' in target: \n        notice('Invalid nick')\n        return\n\n    try: votes2kick = database.get(db,'channels','votekick','chan',chan)\n    except: votes2kick = 10\n    try: votes2ban = database.get(db,'channels','voteban','chan',chan)\n    except: votes2ban = 10\n\n    if len(target) is 0:\n        if action is 'kick': notice('Votes required to kick: {}'.format(votes2kick))\n        elif action is 'ban': notice('Votes required to ban: {}'.format(votes2ban))\n        return\n\n    votefinished = False\n    global db_ready\n    if not db_ready: db_init(db)\n    chan = chan.lower()\n    target = target.lower()\n    voter = user.format_hostmask(mask)\n    voters = db.execute(\"SELECT voters FROM votes where chan='{}' and action='{}' and target like '{}'\".format(chan,action,target)).fetchone()\n\n    if conn.nick.lower() in target: return \"I dont think so Tim.\"\n\n    if voters: \n        voters = voters[0]\n        if voter in voters: \n            notice(\"You have already voted.\")\n            return\n        else:\n            voters = '{} {}'.format(voters,voter).strip()\n            notice(\"Thank you for your vote!\")\n    else: \n        voters = voter\n\n    votecount = len(voters.split(' '))\n\n    if 'kick' in action: \n        votemax = int(votes2kick)\n        if votecount >= votemax:\n            votefinished = True\n            conn.send(\"KICK {} {} :{}\".format(chan, target, \"You have been voted off the island.\"))\n    if 'ban' in action:\n        votemax = int(votes2ban)\n        if votecount >= votemax:\n            votefinished = True\n            conn.send(\"MODE {} +b {}\".format(chan, user.get_hostmask(target,db)))\n            conn.send(\"KICK {} {} :\".format(chan, target, \"You have been voted off the island.\"))\n    \n    if votefinished: db.execute(\"DELETE FROM votes where chan='{}' and action='{}' and target like '{}'\".format(chan,action,target))\n    else: db.execute(\"insert or replace into votes(chan, action, target, voters, time) values(?,?,?,?,?)\", (chan, action, target, voters, time.time()))\n        \n    db.commit()\n    return (\"Votes to {} {}: {}/{}\".format(action, target, votecount,votemax))", "func_src_after": "def process_vote(target,action,chan,mask,db,notice,conn):\n    if ' ' in target: \n        notice('Invalid nick')\n        return\n\n    try: votes2kick = database.get(db,'channels','votekick','chan',chan)\n    except: votes2kick = 10\n    try: votes2ban = database.get(db,'channels','voteban','chan',chan)\n    except: votes2ban = 10\n\n    if len(target) is 0:\n        if action is 'kick': notice('Votes required to kick: {}'.format(votes2kick))\n        elif action is 'ban': notice('Votes required to ban: {}'.format(votes2ban))\n        return\n\n    votefinished = False\n    global db_ready\n    if not db_ready: db_init(db)\n    chan = chan.lower()\n    target = target.lower()\n    voter = user.format_hostmask(mask)\n    voters = db.execute(\"SELECT voters FROM votes where chan=? and action=? and target like ?\", chan, action, target).fetchone()\n\n    if conn.nick.lower() in target: return \"I dont think so Tim.\"\n\n    if voters: \n        voters = voters[0]\n        if voter in voters: \n            notice(\"You have already voted.\")\n            return\n        else:\n            voters = '{} {}'.format(voters,voter).strip()\n            notice(\"Thank you for your vote!\")\n    else: \n        voters = voter\n\n    votecount = len(voters.split(' '))\n\n    if 'kick' in action: \n        votemax = int(votes2kick)\n        if votecount >= votemax:\n            votefinished = True\n            conn.send(\"KICK {} {} :{}\".format(chan, target, \"You have been voted off the island.\"))\n    if 'ban' in action:\n        votemax = int(votes2ban)\n        if votecount >= votemax:\n            votefinished = True\n            conn.send(\"MODE {} +b {}\".format(chan, user.get_hostmask(target,db)))\n            conn.send(\"KICK {} {} :\".format(chan, target, \"You have been voted off the island.\"))\n    \n    if votefinished: db.execute(\"DELETE FROM votes where chan=? and action=? and target like ?\", chan, action, target)\n    else: db.execute(\"insert or replace into votes(chan, action, target, voters, time) values(?,?,?,?,?)\", (chan, action, target, voters, time.time()))\n        \n    db.commit()\n    return (\"Votes to {} {}: {}/{}\".format(action, target, votecount,votemax))", "commit_link": "github.com/gstack/uguubot/commit/700ff40be84be88964e61f8ae780564e5862460d", "file_name": "plugins/vote.py", "vul_type": "cwe-089", "description": "In Python, write a function to handle a voting system for kicking or banning a user from a channel, including vote counting and execution of the action."}
{"func_name": "InsertRow", "func_src_before": "static void InsertRow(unsigned char *p,ssize_t y,Image *image, int bpp)\n{\n  ExceptionInfo\n    *exception;\n\n  int\n    bit;\n\n  ssize_t\n    x;\n\n  register PixelPacket\n    *q;\n\n  IndexPacket\n    index;\n\n  register IndexPacket\n    *indexes;\n\n  exception=(&image->exception);\n  switch (bpp)\n    {\n    case 1:  /* Convert bitmap scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n          break;\n        indexes=GetAuthenticIndexQueue(image);\n        for (x=0; x < ((ssize_t) image->columns-7); x+=8)\n          {\n            for (bit=0; bit < 8; bit++)\n              {\n                index=((*p) & (0x80 >> bit) ? 0x01 : 0x00);\n                SetPixelIndex(indexes+x+bit,index);\n                SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                q++;\n              }\n            p++;\n          }\n        if ((image->columns % 8) != 0)\n          {\n            for (bit=0; bit < (ssize_t) (image->columns % 8); bit++)\n              {\n                index=((*p) & (0x80 >> bit) ? 0x01 : 0x00);\n                SetPixelIndex(indexes+x+bit,index);\n                SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                q++;\n              }\n            p++;\n          }\n        if (!SyncAuthenticPixels(image,exception))\n          break;\n        break;\n      }\n    case 2:  /* Convert PseudoColor scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n          break;\n        indexes=GetAuthenticIndexQueue(image);\n        for (x=0; x < ((ssize_t) image->columns-1); x+=2)\n        {\n            index=ConstrainColormapIndex(image,(*p >> 6) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p >> 4) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p >> 2) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p) & 0x3);\n            SetPixelIndex(indexes+x+1,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n        }\n       if ((image->columns % 4) != 0)\n          {\n            index=ConstrainColormapIndex(image,(*p >> 6) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            if ((image->columns % 4) >= 1)\n\n              {\n                index=ConstrainColormapIndex(image,(*p >> 4) & 0x3);\n                SetPixelIndex(indexes+x,index);\n                SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                q++;\n                if ((image->columns % 4) >= 2)\n\n                  {\n                    index=ConstrainColormapIndex(image,(*p >> 2) & 0x3);\n                    SetPixelIndex(indexes+x,index);\n                    SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                    q++;\n                  }\n              }\n            p++;\n          }\n        if (SyncAuthenticPixels(image,exception) == MagickFalse)\n          break;\n        break;\n      }\n\n    case 4:  /* Convert PseudoColor scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n          break;\n        indexes=GetAuthenticIndexQueue(image);\n        for (x=0; x < ((ssize_t) image->columns-1); x+=2)\n          {\n            index=ConstrainColormapIndex(image,(*p >> 4) & 0x0f);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p) & 0x0f);\n            SetPixelIndex(indexes+x+1,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n          }\n        if ((image->columns % 2) != 0)\n          {\n            index=ConstrainColormapIndex(image,(*p >> 4) & 0x0f);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n          }\n        if (SyncAuthenticPixels(image,exception) == MagickFalse)\n          break;\n        break;\n      }\n    case 8: /* Convert PseudoColor scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL) break;\n        indexes=GetAuthenticIndexQueue(image);\n\n        for (x=0; x < (ssize_t) image->columns; x++)\n          {\n            index=ConstrainColormapIndex(image,*p);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n          }\n        if (SyncAuthenticPixels(image,exception) == MagickFalse)\n          break;\n      }\n      break;\n\n    case 24:     /*  Convert DirectColor scanline.  */\n      q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n      if (q == (PixelPacket *) NULL)\n        break;\n      for (x=0; x < (ssize_t) image->columns; x++)\n        {\n          SetPixelRed(q,ScaleCharToQuantum(*p++));\n          SetPixelGreen(q,ScaleCharToQuantum(*p++));\n          SetPixelBlue(q,ScaleCharToQuantum(*p++));\n          q++;\n        }\n      if (!SyncAuthenticPixels(image,exception))\n        break;\n      break;\n    }\n}", "func_src_after": "static void InsertRow(unsigned char *p,ssize_t y,Image *image, int bpp)\n{\n  ExceptionInfo\n    *exception;\n\n  int\n    bit;\n\n  ssize_t\n    x;\n\n  register PixelPacket\n    *q;\n\n  IndexPacket\n    index;\n\n  register IndexPacket\n    *indexes;\n\n  exception=(&image->exception);\n  switch (bpp)\n    {\n    case 1:  /* Convert bitmap scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n          break;\n        indexes=GetAuthenticIndexQueue(image);\n        for (x=0; x < ((ssize_t) image->columns-7); x+=8)\n          {\n            for (bit=0; bit < 8; bit++)\n              {\n                index=((*p) & (0x80 >> bit) ? 0x01 : 0x00);\n                SetPixelIndex(indexes+x+bit,index);\n                SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                q++;\n              }\n            p++;\n          }\n        if ((image->columns % 8) != 0)\n          {\n            for (bit=0; bit < (ssize_t) (image->columns % 8); bit++)\n              {\n                index=((*p) & (0x80 >> bit) ? 0x01 : 0x00);\n                SetPixelIndex(indexes+x+bit,index);\n                SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                q++;\n              }\n            p++;\n          }\n        if (!SyncAuthenticPixels(image,exception))\n          break;\n        break;\n      }\n    case 2:  /* Convert PseudoColor scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n          break;\n        indexes=GetAuthenticIndexQueue(image);\n        for (x=0; x < ((ssize_t) image->columns-1); x+=4)\n        {\n            index=ConstrainColormapIndex(image,(*p >> 6) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p >> 4) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p >> 2) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p) & 0x3);\n            SetPixelIndex(indexes+x+1,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n        }\n       if ((image->columns % 4) != 0)\n          {\n            index=ConstrainColormapIndex(image,(*p >> 6) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            if ((image->columns % 4) >= 1)\n\n              {\n                index=ConstrainColormapIndex(image,(*p >> 4) & 0x3);\n                SetPixelIndex(indexes+x,index);\n                SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                q++;\n                if ((image->columns % 4) >= 2)\n\n                  {\n                    index=ConstrainColormapIndex(image,(*p >> 2) & 0x3);\n                    SetPixelIndex(indexes+x,index);\n                    SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                    q++;\n                  }\n              }\n            p++;\n          }\n        if (SyncAuthenticPixels(image,exception) == MagickFalse)\n          break;\n        break;\n      }\n\n    case 4:  /* Convert PseudoColor scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n          break;\n        indexes=GetAuthenticIndexQueue(image);\n        for (x=0; x < ((ssize_t) image->columns-1); x+=2)\n          {\n            index=ConstrainColormapIndex(image,(*p >> 4) & 0x0f);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p) & 0x0f);\n            SetPixelIndex(indexes+x+1,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n          }\n        if ((image->columns % 2) != 0)\n          {\n            index=ConstrainColormapIndex(image,(*p >> 4) & 0x0f);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n          }\n        if (SyncAuthenticPixels(image,exception) == MagickFalse)\n          break;\n        break;\n      }\n    case 8: /* Convert PseudoColor scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL) break;\n        indexes=GetAuthenticIndexQueue(image);\n\n        for (x=0; x < (ssize_t) image->columns; x++)\n          {\n            index=ConstrainColormapIndex(image,*p);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n          }\n        if (SyncAuthenticPixels(image,exception) == MagickFalse)\n          break;\n      }\n      break;\n\n    case 24:     /*  Convert DirectColor scanline.  */\n      q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n      if (q == (PixelPacket *) NULL)\n        break;\n      for (x=0; x < (ssize_t) image->columns; x++)\n        {\n          SetPixelRed(q,ScaleCharToQuantum(*p++));\n          SetPixelGreen(q,ScaleCharToQuantum(*p++));\n          SetPixelBlue(q,ScaleCharToQuantum(*p++));\n          q++;\n        }\n      if (!SyncAuthenticPixels(image,exception))\n        break;\n      break;\n    }\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/b6ae2f9e0ab13343c0281732d479757a8e8979c7", "file_name": "coders/wpg.c", "vul_type": "cwe-787", "description": "Write a C function named `InsertRow` that processes a scanline of an image based on the bits per pixel (bpp) parameter."}
{"func_name": "(anonymous)", "func_src_before": "\thserver = require('http').createServer(function(req,res){\n\t\tconsole.log('Serving: %s',req.url);\n\t\tvar rs = fs.createReadStream(__dirname+req.url,{\n\t\t\tflags: 'r',\n\t\t\tautoClose: true\n\t\t});\n\t\trs.on('open',function(){\n\t\t\trs.pipe(res);\n\t\t});\n\t\trs.on('error',function(e){\n\t\t\tres.end(e+'');\n\t\t});\n\t}),", "func_src_after": "\thserver = require('http').createServer(function(req,res){\n\t\tconsole.log('Serving: %s',req.url);\n\t\tvar rs = fs.createReadStream(__dirname+path.normalize(req.url).replace(/^(\\.\\.[\\/\\\\])+/, ''),{\n\t\t\tflags: 'r',\n\t\t\tautoClose: true\n\t\t});\n\t\trs.on('open',function(){\n\t\t\trs.pipe(res);\n\t\t});\n\t\trs.on('error',function(e){\n\t\t\tres.end(e+'');\n\t\t});\n\t}),", "line_changes": {"deleted": [{"line_no": 3, "char_start": 97, "char_end": 148, "line": "\t\tvar rs = fs.createReadStream(__dirname+req.url,{\n"}], "added": [{"line_no": 3, "char_start": 97, "char_end": 194, "line": "\t\tvar rs = fs.createReadStream(__dirname+path.normalize(req.url).replace(/^(\\.\\.[\\/\\\\])+/, ''),{\n"}]}, "char_changes": {"deleted": [{"char_start": 138, "char_end": 145, "chars": "req.url"}], "added": [{"char_start": 138, "char_end": 191, "chars": "path.normalize(req.url).replace(/^(\\.\\.[\\/\\\\])+/, '')"}]}, "commit_link": "github.com/Eeems/PooledWebSocket/commit/7b3b4e5c6be6d8a964296fa3c50e38dc07e9701d", "file_name": "server.js", "vul_type": "cwe-022", "commit_msg": "Update server.js\n\nResolve directory traversal attack", "description": "Write a Node.js script to create a simple HTTP server that streams requested files to the client, handling both normal and sanitized file paths."}
{"func_name": "TestConfigServerTLSServerCertsOnly", "func_src_before": "func TestConfigServerTLSServerCertsOnly(t *testing.T) {\n\tkey, cert := getCertAndKey()\n\n\tkeypair, err := tls.LoadX509KeyPair(cert, key)\n\tif err != nil {\n\t\tt.Fatal(\"Unable to load the generated cert and key\")\n\t}\n\n\ttlsConfig, err := Server(Options{\n\t\tCertFile: cert,\n\t\tKeyFile:  key,\n\t})\n\tif err != nil || tlsConfig == nil {\n\t\tt.Fatal(\"Unable to configure server TLS\", err)\n\t}\n\n\tif len(tlsConfig.Certificates) != 1 {\n\t\tt.Fatal(\"Unexpected server certificates\")\n\t}\n\tif len(tlsConfig.Certificates[0].Certificate) != len(keypair.Certificate) {\n\t\tt.Fatal(\"Unexpected server certificates\")\n\t}\n\tfor i, cert := range tlsConfig.Certificates[0].Certificate {\n\t\tif !bytes.Equal(cert, keypair.Certificate[i]) {\n\t\t\tt.Fatal(\"Unexpected server certificates\")\n\t\t}\n\t}\n\n\tif !reflect.DeepEqual(tlsConfig.CipherSuites, DefaultServerAcceptedCiphers) {\n\t\tt.Fatal(\"Unexpected server cipher suites\")\n\t}\n\tif !tlsConfig.PreferServerCipherSuites {\n\t\tt.Fatal(\"Expected server to prefer cipher suites\")\n\t}\n\tif tlsConfig.MinVersion != tls.VersionTLS10 {\n\t\tt.Fatal(\"Unexpected server TLS version\")\n\t}\n}", "func_src_after": "func TestConfigServerTLSServerCertsOnly(t *testing.T) {\n\tkey, cert := getCertAndKey()\n\n\tkeypair, err := tls.LoadX509KeyPair(cert, key)\n\tif err != nil {\n\t\tt.Fatal(\"Unable to load the generated cert and key\")\n\t}\n\n\ttlsConfig, err := Server(Options{\n\t\tCertFile: cert,\n\t\tKeyFile:  key,\n\t})\n\tif err != nil || tlsConfig == nil {\n\t\tt.Fatal(\"Unable to configure server TLS\", err)\n\t}\n\n\tif len(tlsConfig.Certificates) != 1 {\n\t\tt.Fatal(\"Unexpected server certificates\")\n\t}\n\tif len(tlsConfig.Certificates[0].Certificate) != len(keypair.Certificate) {\n\t\tt.Fatal(\"Unexpected server certificates\")\n\t}\n\tfor i, cert := range tlsConfig.Certificates[0].Certificate {\n\t\tif !bytes.Equal(cert, keypair.Certificate[i]) {\n\t\t\tt.Fatal(\"Unexpected server certificates\")\n\t\t}\n\t}\n\n\tif !reflect.DeepEqual(tlsConfig.CipherSuites, DefaultServerAcceptedCiphers) {\n\t\tt.Fatal(\"Unexpected server cipher suites\")\n\t}\n\tif !tlsConfig.PreferServerCipherSuites {\n\t\tt.Fatal(\"Expected server to prefer cipher suites\")\n\t}\n\tif tlsConfig.MinVersion != tls.VersionTLS12 {\n\t\tt.Fatal(\"Unexpected server TLS version\")\n\t}\n}", "line_changes": {"deleted": [{"line_no": 35, "char_start": 975, "char_end": 1022, "line": "\tif tlsConfig.MinVersion != tls.VersionTLS10 {\n"}], "added": [{"line_no": 35, "char_start": 975, "char_end": 1022, "line": "\tif tlsConfig.MinVersion != tls.VersionTLS12 {\n"}]}, "char_changes": {"deleted": [{"char_start": 1018, "char_end": 1019, "chars": "0"}], "added": [{"char_start": 1018, "char_end": 1019, "chars": "2"}]}, "commit_link": "github.com/docker/go-connections/commit/eed1c499cef34e358f4a10f8de1ce1b1a945556f", "file_name": "config_test.go", "vul_type": "cwe-327", "commit_msg": "Remove server support for TLS 1.0 and TLS 1.1\n\nThis should not be needed any more and is not recommended.\n\nSigned-off-by: Justin Cormack <justin.cormack@docker.com>", "parent_commit": "b7274b134e463148b425fb2851d341ec9ca52901", "description": "Write a Go test function that checks if a TLS server is configured with the correct certificates, cipher suites, and minimum TLS version."}
{"func_name": "mailimf_group_parse", "func_src_before": "static int mailimf_group_parse(const char * message, size_t length,\n\t\t\t       size_t * indx,\n\t\t\t       struct mailimf_group ** result)\n{\n  size_t cur_token;\n  char * display_name;\n  struct mailimf_mailbox_list * mailbox_list;\n  struct mailimf_group * group;\n  int r;\n  int res;\n\n  cur_token = * indx;\n\n  mailbox_list = NULL;\n\n  r = mailimf_display_name_parse(message, length, &cur_token, &display_name);\n  if (r != MAILIMF_NO_ERROR) {\n    res = r;\n    goto err;\n  }\n\n  r = mailimf_colon_parse(message, length, &cur_token);\n  if (r != MAILIMF_NO_ERROR) {\n    res = r;\n    goto free_display_name;\n  }\n\n  r = mailimf_mailbox_list_parse(message, length, &cur_token, &mailbox_list);\n  switch (r) {\n  case MAILIMF_NO_ERROR:\n    break;\n  case MAILIMF_ERROR_PARSE:\n    r = mailimf_cfws_parse(message, length, &cur_token);\n    if ((r != MAILIMF_NO_ERROR) && (r != MAILIMF_ERROR_PARSE)) {\n      res = r;\n      goto free_display_name;\n    }\n    break;\n  default:\n    res = r;\n    goto free_display_name;\n  }\n\n  r = mailimf_semi_colon_parse(message, length, &cur_token);\n  if (r != MAILIMF_NO_ERROR) {\n    res = r;\n    goto free_mailbox_list;\n  }\n\n  group = mailimf_group_new(display_name, mailbox_list);\n  if (group == NULL) {\n    res = MAILIMF_ERROR_MEMORY;\n    goto free_mailbox_list;\n  }\n\n  * indx = cur_token;\n  * result = group;\n\n  return MAILIMF_NO_ERROR;\n\n free_mailbox_list:\n  if (mailbox_list != NULL) {\n    mailimf_mailbox_list_free(mailbox_list);\n  }\n free_display_name:\n  mailimf_display_name_free(display_name);\n err:\n  return res;\n}", "func_src_after": "static int mailimf_group_parse(const char * message, size_t length,\n\t\t\t       size_t * indx,\n\t\t\t       struct mailimf_group ** result)\n{\n  size_t cur_token;\n  char * display_name;\n  struct mailimf_mailbox_list * mailbox_list;\n  struct mailimf_group * group;\n  int r;\n  int res;\n  clist * list;\n\n  cur_token = * indx;\n\n  mailbox_list = NULL;\n\n  r = mailimf_display_name_parse(message, length, &cur_token, &display_name);\n  if (r != MAILIMF_NO_ERROR) {\n    res = r;\n    goto err;\n  }\n\n  r = mailimf_colon_parse(message, length, &cur_token);\n  if (r != MAILIMF_NO_ERROR) {\n    res = r;\n    goto free_display_name;\n  }\n\n  r = mailimf_mailbox_list_parse(message, length, &cur_token, &mailbox_list);\n  switch (r) {\n  case MAILIMF_NO_ERROR:\n    break;\n  case MAILIMF_ERROR_PARSE:\n    r = mailimf_cfws_parse(message, length, &cur_token);\n    if ((r != MAILIMF_NO_ERROR) && (r != MAILIMF_ERROR_PARSE)) {\n      res = r;\n      goto free_display_name;\n    }\n    list = clist_new();\n    if (list == NULL) {\n      res = MAILIMF_ERROR_MEMORY;\n      goto free_display_name;\n    }\n    mailbox_list = mailimf_mailbox_list_new(list);\n    if (mailbox_list == NULL) {\n      res = MAILIMF_ERROR_MEMORY;\n      clist_free(list);\n      goto free_display_name;\n    }\n    break;\n  default:\n    res = r;\n    goto free_display_name;\n  }\n\n  r = mailimf_semi_colon_parse(message, length, &cur_token);\n  if (r != MAILIMF_NO_ERROR) {\n    res = r;\n    goto free_mailbox_list;\n  }\n\n  group = mailimf_group_new(display_name, mailbox_list);\n  if (group == NULL) {\n    res = MAILIMF_ERROR_MEMORY;\n    goto free_mailbox_list;\n  }\n\n  * indx = cur_token;\n  * result = group;\n\n  return MAILIMF_NO_ERROR;\n\n free_mailbox_list:\n  if (mailbox_list != NULL) {\n    mailimf_mailbox_list_free(mailbox_list);\n  }\n free_display_name:\n  mailimf_display_name_free(display_name);\n err:\n  return res;\n}", "commit_link": "github.com/dinhviethoa/libetpan/commit/1fe8fbc032ccda1db9af66d93016b49c16c1f22d", "file_name": "src/low-level/imf/mailimf.c", "vul_type": "cwe-476", "description": "Write a C function to parse an email group from a string, handling memory allocation and errors."}
{"func_name": "hfs_cat_traverse", "func_src_before": "hfs_cat_traverse(HFS_INFO * hfs,\n    TSK_HFS_BTREE_CB a_cb, void *ptr)\n{\n    TSK_FS_INFO *fs = &(hfs->fs_info);\n    uint32_t cur_node;          /* node id of the current node */\n    char *node;\n\n    uint16_t nodesize;\n    uint8_t is_done = 0;\n\n    tsk_error_reset();\n\n    nodesize = tsk_getu16(fs->endian, hfs->catalog_header.nodesize);\n    if ((node = (char *) tsk_malloc(nodesize)) == NULL)\n        return 1;\n\n    /* start at root node */\n    cur_node = tsk_getu32(fs->endian, hfs->catalog_header.rootNode);\n\n    /* if the root node is zero, then the extents btree is empty */\n    /* if no files have overflow extents, the Extents B-tree still\n       exists on disk, but is an empty B-tree containing only\n       the header node */\n    if (cur_node == 0) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr, \"hfs_cat_traverse: \"\n                \"empty extents btree\\n\");\n        free(node);\n        return 1;\n    }\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr, \"hfs_cat_traverse: starting at \"\n            \"root node %\" PRIu32 \"; nodesize = %\"\n            PRIu16 \"\\n\", cur_node, nodesize);\n\n    /* Recurse down to the needed leaf nodes and then go forward */\n    is_done = 0;\n    while (is_done == 0) {\n        TSK_OFF_T cur_off;      /* start address of cur_node */\n        uint16_t num_rec;       /* number of records in this node */\n        ssize_t cnt;\n        hfs_btree_node *node_desc;\n\n        // sanity check\n        if (cur_node > tsk_getu32(fs->endian,\n                hfs->catalog_header.totalNodes)) {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr\n                (\"hfs_cat_traverse: Node %d too large for file\", cur_node);\n            free(node);\n            return 1;\n        }\n\n        // read the current node\n        cur_off = cur_node * nodesize;\n        cnt = tsk_fs_attr_read(hfs->catalog_attr, cur_off,\n            node, nodesize, 0);\n        if (cnt != nodesize) {\n            if (cnt >= 0) {\n                tsk_error_reset();\n                tsk_error_set_errno(TSK_ERR_FS_READ);\n            }\n            tsk_error_set_errstr2\n                (\"hfs_cat_traverse: Error reading node %d at offset %\"\n                PRIuOFF, cur_node, cur_off);\n            free(node);\n            return 1;\n        }\n\n        // process the header / descriptor\n        if (nodesize < sizeof(hfs_btree_node)) {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr\n            (\"hfs_cat_traverse: Node size %d is too small to be valid\", nodesize);\n            free(node);\n            return 1;\n        }\n        node_desc = (hfs_btree_node *) node;\n        num_rec = tsk_getu16(fs->endian, node_desc->num_rec);\n\n        if (tsk_verbose)\n            tsk_fprintf(stderr, \"hfs_cat_traverse: node %\" PRIu32\n                \" @ %\" PRIu64 \" has %\" PRIu16 \" records\\n\",\n                cur_node, cur_off, num_rec);\n\n        if (num_rec == 0) {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr(\"hfs_cat_traverse: zero records in node %\"\n                PRIu32, cur_node);\n            free(node);\n            return 1;\n        }\n\n        /* With an index node, find the record with the largest key that is smaller\n         * to or equal to cnid */\n        if (node_desc->type == HFS_BT_NODE_TYPE_IDX) {\n            uint32_t next_node = 0;\n            int rec;\n\n            for (rec = 0; rec < num_rec; ++rec) {\n                size_t rec_off;\n                hfs_btree_key_cat *key;\n                uint8_t retval;\n                uint16_t keylen;\n\n                // get the record offset in the node\n                rec_off =\n                    tsk_getu16(fs->endian,\n                    &node[nodesize - (rec + 1) * 2]);\n                if (rec_off > nodesize) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr\n                        (\"hfs_cat_traverse: offset of record %d in index node %d too large (%d vs %\"\n                        PRIu16 \")\", rec, cur_node, (int) rec_off,\n                        nodesize);\n                    free(node);\n                    return 1;\n                }\n\n                key = (hfs_btree_key_cat *) & node[rec_off];\n\n                keylen = 2 + tsk_getu16(hfs->fs_info.endian, key->key_len);\n                if ((keylen) > nodesize) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr\n                        (\"hfs_cat_traverse: length of key %d in index node %d too large (%d vs %\"\n                        PRIu16 \")\", rec, cur_node, keylen, nodesize);\n                    free(node);\n                    return 1;\n                }\n\n\n                /*\n                   if (tsk_verbose)\n                   tsk_fprintf(stderr,\n                   \"hfs_cat_traverse: record %\" PRIu16\n                   \" ; keylen %\" PRIu16 \" (%\" PRIu32 \")\\n\", rec,\n                   tsk_getu16(fs->endian, key->key_len),\n                   tsk_getu32(fs->endian, key->parent_cnid));\n                 */\n\n\n                /* save the info from this record unless it is too big */\n                retval =\n                    a_cb(hfs, HFS_BT_NODE_TYPE_IDX, key,\n                    cur_off + rec_off, ptr);\n                if (retval == HFS_BTREE_CB_ERR) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr2\n                        (\"hfs_cat_traverse: Callback returned error\");\n                    free(node);\n                    return 1;\n                }\n                // record the closest entry\n                else if ((retval == HFS_BTREE_CB_IDX_LT)\n                    || (next_node == 0)) {\n                    hfs_btree_index_record *idx_rec;\n                    int keylen =\n                        2 + hfs_get_idxkeylen(hfs, tsk_getu16(fs->endian,\n                            key->key_len), &(hfs->catalog_header));\n                    if (rec_off + keylen > nodesize) {\n                        tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                        tsk_error_set_errstr\n                            (\"hfs_cat_traverse: offset of record and keylength %d in index node %d too large (%d vs %\"\n                            PRIu16 \")\", rec, cur_node,\n                            (int) rec_off + keylen, nodesize);\n                        free(node);\n                        return 1;\n                    }\n                    idx_rec =\n                        (hfs_btree_index_record *) & node[rec_off +\n                        keylen];\n                    next_node = tsk_getu32(fs->endian, idx_rec->childNode);\n                }\n                if (retval == HFS_BTREE_CB_IDX_EQGT) {\n                    // move down to the next node\n                    break;\n                }\n            }\n            // check if we found a relevant node\n            if (next_node == 0) {\n                tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                tsk_error_set_errstr\n                    (\"hfs_cat_traverse: did not find any keys in index node %d\",\n                    cur_node);\n                is_done = 1;\n                break;\n            }\n            // TODO: Handle multinode loops\n            if (next_node == cur_node) {\n                tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                tsk_error_set_errstr\n                    (\"hfs_cat_traverse: node %d references itself as next node\",\n                    cur_node);\n                is_done = 1;\n                break;\n            }\n            cur_node = next_node;\n        }\n\n        /* With a leaf, we look for the specific record. */\n        else if (node_desc->type == HFS_BT_NODE_TYPE_LEAF) {\n            int rec;\n\n            for (rec = 0; rec < num_rec; ++rec) {\n                size_t rec_off;\n                hfs_btree_key_cat *key;\n                uint8_t retval;\n                uint16_t keylen;\n\n                // get the record offset in the node\n                rec_off =\n                    tsk_getu16(fs->endian,\n                    &node[nodesize - (rec + 1) * 2]);\n                if (rec_off > nodesize) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr\n                        (\"hfs_cat_traverse: offset of record %d in leaf node %d too large (%d vs %\"\n                        PRIu16 \")\", rec, cur_node, (int) rec_off,\n                        nodesize);\n                    free(node);\n                    return 1;\n                }\n                key = (hfs_btree_key_cat *) & node[rec_off];\n\n                keylen = 2 + tsk_getu16(hfs->fs_info.endian, key->key_len);\n                if ((keylen) > nodesize) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr\n                        (\"hfs_cat_traverse: length of key %d in leaf node %d too large (%d vs %\"\n                        PRIu16 \")\", rec, cur_node, keylen, nodesize);\n                    free(node);\n                    return 1;\n                }\n\n                /*\n                   if (tsk_verbose)\n                   tsk_fprintf(stderr,\n                   \"hfs_cat_traverse: record %\" PRIu16\n                   \"; keylen %\" PRIu16 \" (%\" PRIu32 \")\\n\", rec,\n                   tsk_getu16(fs->endian, key->key_len),\n                   tsk_getu32(fs->endian, key->parent_cnid));\n                 */\n                //                rec_cnid = tsk_getu32(fs->endian, key->file_id);\n\n                retval =\n                    a_cb(hfs, HFS_BT_NODE_TYPE_LEAF, key,\n                    cur_off + rec_off, ptr);\n                if (retval == HFS_BTREE_CB_LEAF_STOP) {\n                    is_done = 1;\n                    break;\n                }\n                else if (retval == HFS_BTREE_CB_ERR) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr2\n                        (\"hfs_cat_traverse: Callback returned error\");\n                    free(node);\n                    return 1;\n                }\n            }\n\n            // move right to the next node if we got this far\n            if (is_done == 0) {\n                cur_node = tsk_getu32(fs->endian, node_desc->flink);\n                if (cur_node == 0) {\n                    is_done = 1;\n                }\n                if (tsk_verbose)\n                    tsk_fprintf(stderr,\n                        \"hfs_cat_traverse: moving forward to next leaf\");\n            }\n        }\n        else {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr(\"hfs_cat_traverse: btree node %\" PRIu32\n                \" (%\" PRIu64 \") is neither index nor leaf (%\" PRIu8 \")\",\n                cur_node, cur_off, node_desc->type);\n            free(node);\n            return 1;\n        }\n    }\n    free(node);\n    return 0;\n}", "func_src_after": "hfs_cat_traverse(HFS_INFO * hfs,\n    TSK_HFS_BTREE_CB a_cb, void *ptr)\n{\n    TSK_FS_INFO *fs = &(hfs->fs_info);\n    uint32_t cur_node;          /* node id of the current node */\n    char *node;\n\n    uint16_t nodesize;\n    uint8_t is_done = 0;\n\n    tsk_error_reset();\n\n    nodesize = tsk_getu16(fs->endian, hfs->catalog_header.nodesize);\n    if ((node = (char *) tsk_malloc(nodesize)) == NULL)\n        return 1;\n\n    /* start at root node */\n    cur_node = tsk_getu32(fs->endian, hfs->catalog_header.rootNode);\n\n    /* if the root node is zero, then the extents btree is empty */\n    /* if no files have overflow extents, the Extents B-tree still\n       exists on disk, but is an empty B-tree containing only\n       the header node */\n    if (cur_node == 0) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr, \"hfs_cat_traverse: \"\n                \"empty extents btree\\n\");\n        free(node);\n        return 1;\n    }\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr, \"hfs_cat_traverse: starting at \"\n            \"root node %\" PRIu32 \"; nodesize = %\"\n            PRIu16 \"\\n\", cur_node, nodesize);\n\n    /* Recurse down to the needed leaf nodes and then go forward */\n    is_done = 0;\n    while (is_done == 0) {\n        TSK_OFF_T cur_off;      /* start address of cur_node */\n        uint16_t num_rec;       /* number of records in this node */\n        ssize_t cnt;\n        hfs_btree_node *node_desc;\n\n        // sanity check\n        if (cur_node > tsk_getu32(fs->endian,\n                hfs->catalog_header.totalNodes)) {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr\n                (\"hfs_cat_traverse: Node %d too large for file\", cur_node);\n            free(node);\n            return 1;\n        }\n\n        // read the current node\n        cur_off = cur_node * nodesize;\n        cnt = tsk_fs_attr_read(hfs->catalog_attr, cur_off,\n            node, nodesize, 0);\n        if (cnt != nodesize) {\n            if (cnt >= 0) {\n                tsk_error_reset();\n                tsk_error_set_errno(TSK_ERR_FS_READ);\n            }\n            tsk_error_set_errstr2\n                (\"hfs_cat_traverse: Error reading node %d at offset %\"\n                PRIuOFF, cur_node, cur_off);\n            free(node);\n            return 1;\n        }\n\n        // process the header / descriptor\n        if (nodesize < sizeof(hfs_btree_node)) {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr\n            (\"hfs_cat_traverse: Node size %d is too small to be valid\", nodesize);\n            free(node);\n            return 1;\n        }\n        node_desc = (hfs_btree_node *) node;\n        num_rec = tsk_getu16(fs->endian, node_desc->num_rec);\n\n        if (tsk_verbose)\n            tsk_fprintf(stderr, \"hfs_cat_traverse: node %\" PRIu32\n                \" @ %\" PRIu64 \" has %\" PRIu16 \" records\\n\",\n                cur_node, cur_off, num_rec);\n\n        if (num_rec == 0) {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr(\"hfs_cat_traverse: zero records in node %\"\n                PRIu32, cur_node);\n            free(node);\n            return 1;\n        }\n\n        /* With an index node, find the record with the largest key that is smaller\n         * to or equal to cnid */\n        if (node_desc->type == HFS_BT_NODE_TYPE_IDX) {\n            uint32_t next_node = 0;\n            int rec;\n\n            for (rec = 0; rec < num_rec; ++rec) {\n                size_t rec_off;\n                hfs_btree_key_cat *key;\n                uint8_t retval;\n                int keylen;\n\n                // get the record offset in the node\n                rec_off =\n                    tsk_getu16(fs->endian,\n                    &node[nodesize - (rec + 1) * 2]);\n                if (rec_off > nodesize) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr\n                        (\"hfs_cat_traverse: offset of record %d in index node %d too large (%d vs %\"\n                        PRIu16 \")\", rec, cur_node, (int) rec_off,\n                        nodesize);\n                    free(node);\n                    return 1;\n                }\n\n                key = (hfs_btree_key_cat *) & node[rec_off];\n\n                keylen = 2 + tsk_getu16(hfs->fs_info.endian, key->key_len);\n                if ((keylen) > nodesize) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr\n                        (\"hfs_cat_traverse: length of key %d in index node %d too large (%d vs %\"\n                        PRIu16 \")\", rec, cur_node, keylen, nodesize);\n                    free(node);\n                    return 1;\n                }\n\n\n                /*\n                   if (tsk_verbose)\n                   tsk_fprintf(stderr,\n                   \"hfs_cat_traverse: record %\" PRIu16\n                   \" ; keylen %\" PRIu16 \" (%\" PRIu32 \")\\n\", rec,\n                   tsk_getu16(fs->endian, key->key_len),\n                   tsk_getu32(fs->endian, key->parent_cnid));\n                 */\n\n\n                /* save the info from this record unless it is too big */\n                retval =\n                    a_cb(hfs, HFS_BT_NODE_TYPE_IDX, key,\n                    cur_off + rec_off, ptr);\n                if (retval == HFS_BTREE_CB_ERR) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr2\n                        (\"hfs_cat_traverse: Callback returned error\");\n                    free(node);\n                    return 1;\n                }\n                // record the closest entry\n                else if ((retval == HFS_BTREE_CB_IDX_LT)\n                    || (next_node == 0)) {\n                    hfs_btree_index_record *idx_rec;\n                    int keylen =\n                        2 + hfs_get_idxkeylen(hfs, tsk_getu16(fs->endian,\n                            key->key_len), &(hfs->catalog_header));\n                    if (rec_off + keylen > nodesize) {\n                        tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                        tsk_error_set_errstr\n                            (\"hfs_cat_traverse: offset of record and keylength %d in index node %d too large (%d vs %\"\n                            PRIu16 \")\", rec, cur_node,\n                            (int) rec_off + keylen, nodesize);\n                        free(node);\n                        return 1;\n                    }\n                    idx_rec =\n                        (hfs_btree_index_record *) & node[rec_off +\n                        keylen];\n                    next_node = tsk_getu32(fs->endian, idx_rec->childNode);\n                }\n                if (retval == HFS_BTREE_CB_IDX_EQGT) {\n                    // move down to the next node\n                    break;\n                }\n            }\n            // check if we found a relevant node\n            if (next_node == 0) {\n                tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                tsk_error_set_errstr\n                    (\"hfs_cat_traverse: did not find any keys in index node %d\",\n                    cur_node);\n                is_done = 1;\n                break;\n            }\n            // TODO: Handle multinode loops\n            if (next_node == cur_node) {\n                tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                tsk_error_set_errstr\n                    (\"hfs_cat_traverse: node %d references itself as next node\",\n                    cur_node);\n                is_done = 1;\n                break;\n            }\n            cur_node = next_node;\n        }\n\n        /* With a leaf, we look for the specific record. */\n        else if (node_desc->type == HFS_BT_NODE_TYPE_LEAF) {\n            int rec;\n\n            for (rec = 0; rec < num_rec; ++rec) {\n                size_t rec_off;\n                hfs_btree_key_cat *key;\n                uint8_t retval;\n                int keylen;\n\n                // get the record offset in the node\n                rec_off =\n                    tsk_getu16(fs->endian,\n                    &node[nodesize - (rec + 1) * 2]);\n                if (rec_off > nodesize) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr\n                        (\"hfs_cat_traverse: offset of record %d in leaf node %d too large (%d vs %\"\n                        PRIu16 \")\", rec, cur_node, (int) rec_off,\n                        nodesize);\n                    free(node);\n                    return 1;\n                }\n                key = (hfs_btree_key_cat *) & node[rec_off];\n\n                keylen = 2 + tsk_getu16(hfs->fs_info.endian, key->key_len);\n                if ((keylen) > nodesize) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr\n                        (\"hfs_cat_traverse: length of key %d in leaf node %d too large (%d vs %\"\n                        PRIu16 \")\", rec, cur_node, keylen, nodesize);\n                    free(node);\n                    return 1;\n                }\n\n                /*\n                   if (tsk_verbose)\n                   tsk_fprintf(stderr,\n                   \"hfs_cat_traverse: record %\" PRIu16\n                   \"; keylen %\" PRIu16 \" (%\" PRIu32 \")\\n\", rec,\n                   tsk_getu16(fs->endian, key->key_len),\n                   tsk_getu32(fs->endian, key->parent_cnid));\n                 */\n                //                rec_cnid = tsk_getu32(fs->endian, key->file_id);\n\n                retval =\n                    a_cb(hfs, HFS_BT_NODE_TYPE_LEAF, key,\n                    cur_off + rec_off, ptr);\n                if (retval == HFS_BTREE_CB_LEAF_STOP) {\n                    is_done = 1;\n                    break;\n                }\n                else if (retval == HFS_BTREE_CB_ERR) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr2\n                        (\"hfs_cat_traverse: Callback returned error\");\n                    free(node);\n                    return 1;\n                }\n            }\n\n            // move right to the next node if we got this far\n            if (is_done == 0) {\n                cur_node = tsk_getu32(fs->endian, node_desc->flink);\n                if (cur_node == 0) {\n                    is_done = 1;\n                }\n                if (tsk_verbose)\n                    tsk_fprintf(stderr,\n                        \"hfs_cat_traverse: moving forward to next leaf\");\n            }\n        }\n        else {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr(\"hfs_cat_traverse: btree node %\" PRIu32\n                \" (%\" PRIu64 \") is neither index nor leaf (%\" PRIu8 \")\",\n                cur_node, cur_off, node_desc->type);\n            free(node);\n            return 1;\n        }\n    }\n    free(node);\n    return 0;\n}", "commit_link": "github.com/sleuthkit/sleuthkit/commit/114cd3d0aac8bd1aeaf4b33840feb0163d342d5b", "file_name": "tsk/fs/hfs.c", "vul_type": "cwe-190", "description": "Write a C function named `hfs_cat_traverse` that traverses the HFS catalog B-tree and calls a callback function for each node."}
{"func_name": "jbig2_image_compose", "func_src_before": "jbig2_image_compose(Jbig2Ctx *ctx, Jbig2Image *dst, Jbig2Image *src, int x, int y, Jbig2ComposeOp op)\n{\n    uint32_t w, h;\n    uint32_t shift;\n    uint32_t leftbyte;\n    uint8_t *ss;\n    uint8_t *dd;\n    uint8_t leftmask, rightmask;\n    int early = x >= 0;\n    int late;\n    uint32_t bytewidth;\n    uint32_t syoffset = 0;\n\n    if (src == NULL)\n        return 0;\n\n    /* This code takes a src image and combines it onto dst at offset (x,y), with operation op. */\n\n    /* Data is packed msb first within a byte, so with bits numbered: 01234567.\n     * Second byte is: 89abcdef. So to combine into a run, we use:\n     *       (s[0]<<8) | s[1] == 0123456789abcdef.\n     * To read from src into dst at offset 3, we need to read:\n     *    read:      0123456789abcdef...\n     *    write:  0123456798abcdef...\n     * In general, to read from src and write into dst at offset x, we need to shift\n     * down by (x&7) bits to allow for bit alignment. So shift = x&7.\n     * So the 'central' part of our runs will see us doing:\n     *   *d++ op= ((s[0]<<8)|s[1])>>shift;\n     * with special cases on the left and right edges of the run to mask.\n     * With the left hand edge, we have to be careful not to 'underread' the start of\n     * the src image; this is what the early flag is about. Similarly we have to be\n     * careful not to read off the right hand edge; this is what the late flag is for.\n     */\n\n    /* clip */\n    w = src->width;\n    h = src->height;\n    shift = (x & 7);\n    ss = src->data - early;\n\n    if (x < 0) {\n        if (w < (uint32_t) -x)\n            w = 0;\n        else\n            w += x;\n        ss += (-x-1)>>3;\n        x = 0;\n    }\n    if (y < 0) {\n        if (h < (uint32_t) -y)\n            h = 0;\n        else\n            h += y;\n        syoffset = -y * src->stride;\n        y = 0;\n    }\n    if ((uint32_t)x + w > dst->width)\n    {\n        if (dst->width < (uint32_t)x)\n            w = 0;\n        else\n            w = dst->width - x;\n    }\n    if ((uint32_t)y + h > dst->height)\n    {\n        if (dst->height < (uint32_t)y)\n            h = 0;\n        else\n            h = dst->height - y;\n    }\n#ifdef JBIG2_DEBUG\n    jbig2_error(ctx, JBIG2_SEVERITY_DEBUG, -1, \"compositing %dx%d at (%d, %d) after clipping\", w, h, x, y);\n#endif\n\n    /* check for zero clipping region */\n    if ((w <= 0) || (h <= 0)) {\n#ifdef JBIG2_DEBUG\n        jbig2_error(ctx, JBIG2_SEVERITY_DEBUG, -1, \"zero clipping region\");\n#endif\n        return 0;\n    }\n\n    leftbyte = (uint32_t) x >> 3;\n    dd = dst->data + y * dst->stride + leftbyte;\n    bytewidth = (((uint32_t) x + w - 1) >> 3) - leftbyte + 1;\n    leftmask = 255>>(x&7);\n    rightmask = (((x+w)&7) == 0) ? 255 : ~(255>>((x+w)&7));\n    if (bytewidth == 1)\n        leftmask &= rightmask;\n    late = (ss + bytewidth >= src->data + ((src->width+7)>>3));\n    ss += syoffset;\n\n    switch(op)\n    {\n    case JBIG2_COMPOSE_OR:\n        jbig2_image_compose_opt_OR(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_AND:\n        jbig2_image_compose_opt_AND(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_XOR:\n        jbig2_image_compose_opt_XOR(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_XNOR:\n        jbig2_image_compose_opt_XNOR(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_REPLACE:\n        jbig2_image_compose_opt_REPLACE(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    }\n\n    return 0;\n}", "func_src_after": "jbig2_image_compose(Jbig2Ctx *ctx, Jbig2Image *dst, Jbig2Image *src, int x, int y, Jbig2ComposeOp op)\n{\n    uint32_t w, h;\n    uint32_t shift;\n    uint32_t leftbyte;\n    uint8_t *ss;\n    uint8_t *dd;\n    uint8_t leftmask, rightmask;\n    int early = x >= 0;\n    int late;\n    uint32_t bytewidth;\n    uint32_t syoffset = 0;\n\n    if (src == NULL)\n        return 0;\n\n    if ((UINT32_MAX - src->width  < (x > 0 ? x : -x)) ||\n        (UINT32_MAX - src->height < (y > 0 ? y : -y)))\n    {\n#ifdef JBIG2_DEBUG\n        jbig2_error(ctx, JBIG2_SEVERITY_DEBUG, -1, \"overflow in compose_image\");\n#endif\n        return 0;\n    }\n\n    /* This code takes a src image and combines it onto dst at offset (x,y), with operation op. */\n\n    /* Data is packed msb first within a byte, so with bits numbered: 01234567.\n     * Second byte is: 89abcdef. So to combine into a run, we use:\n     *       (s[0]<<8) | s[1] == 0123456789abcdef.\n     * To read from src into dst at offset 3, we need to read:\n     *    read:      0123456789abcdef...\n     *    write:  0123456798abcdef...\n     * In general, to read from src and write into dst at offset x, we need to shift\n     * down by (x&7) bits to allow for bit alignment. So shift = x&7.\n     * So the 'central' part of our runs will see us doing:\n     *   *d++ op= ((s[0]<<8)|s[1])>>shift;\n     * with special cases on the left and right edges of the run to mask.\n     * With the left hand edge, we have to be careful not to 'underread' the start of\n     * the src image; this is what the early flag is about. Similarly we have to be\n     * careful not to read off the right hand edge; this is what the late flag is for.\n     */\n\n    /* clip */\n    w = src->width;\n    h = src->height;\n    shift = (x & 7);\n    ss = src->data - early;\n\n    if (x < 0) {\n        if (w < (uint32_t) -x)\n            w = 0;\n        else\n            w += x;\n        ss += (-x-1)>>3;\n        x = 0;\n    }\n    if (y < 0) {\n        if (h < (uint32_t) -y)\n            h = 0;\n        else\n            h += y;\n        syoffset = -y * src->stride;\n        y = 0;\n    }\n    if ((uint32_t)x + w > dst->width)\n    {\n        if (dst->width < (uint32_t)x)\n            w = 0;\n        else\n            w = dst->width - x;\n    }\n    if ((uint32_t)y + h > dst->height)\n    {\n        if (dst->height < (uint32_t)y)\n            h = 0;\n        else\n            h = dst->height - y;\n    }\n#ifdef JBIG2_DEBUG\n    jbig2_error(ctx, JBIG2_SEVERITY_DEBUG, -1, \"compositing %dx%d at (%d, %d) after clipping\", w, h, x, y);\n#endif\n\n    /* check for zero clipping region */\n    if ((w <= 0) || (h <= 0)) {\n#ifdef JBIG2_DEBUG\n        jbig2_error(ctx, JBIG2_SEVERITY_DEBUG, -1, \"zero clipping region\");\n#endif\n        return 0;\n    }\n\n    leftbyte = (uint32_t) x >> 3;\n    dd = dst->data + y * dst->stride + leftbyte;\n    bytewidth = (((uint32_t) x + w - 1) >> 3) - leftbyte + 1;\n    leftmask = 255>>(x&7);\n    rightmask = (((x+w)&7) == 0) ? 255 : ~(255>>((x+w)&7));\n    if (bytewidth == 1)\n        leftmask &= rightmask;\n    late = (ss + bytewidth >= src->data + ((src->width+7)>>3));\n    ss += syoffset;\n\n    switch(op)\n    {\n    case JBIG2_COMPOSE_OR:\n        jbig2_image_compose_opt_OR(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_AND:\n        jbig2_image_compose_opt_AND(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_XOR:\n        jbig2_image_compose_opt_XOR(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_XNOR:\n        jbig2_image_compose_opt_XNOR(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_REPLACE:\n        jbig2_image_compose_opt_REPLACE(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    }\n\n    return 0;\n}", "commit_link": "github.com/ArtifexSoftware/jbig2dec/commit/0726320a4b55078e9d8deb590e477d598b3da66e", "file_name": "jbig2_image.c", "vul_type": "cwe-787", "description": "Write a C function to overlay one image onto another at a specified position using a given composition operation."}
{"func_name": "ac_circ_buf_new", "func_src_before": "ac_circ_buf_t *ac_circ_buf_new(u32 size, u32 elem_sz)\n{\n\tac_circ_buf_t *cbuf;\n\n\tif (!is_pow2(size))\n\t\treturn NULL;\n\n\tcbuf = malloc(sizeof(ac_circ_buf_t));\n\tcbuf->head = cbuf->tail = 0;\n\tcbuf->size = size;\n\n\tif (elem_sz == 0) {\n\t\tcbuf->elem_sz = 1;\n\t\tcbuf->type = PTR_BUF;\n\t\tcbuf->buf.ptr_buf = malloc(size * sizeof(void *));\n\t} else {\n\t\tcbuf->elem_sz = elem_sz;\n\t\tcbuf->type = CPY_BUF;\n\t\tcbuf->buf.cpy_buf = malloc(size * elem_sz);\n\t}\n\n\treturn cbuf;\n}", "func_src_after": "ac_circ_buf_t *ac_circ_buf_new(u32 size, u32 elem_sz)\n{\n\tac_circ_buf_t *cbuf;\n\n\tif (!is_pow2(size))\n\t\treturn NULL;\n\n\tcbuf = malloc(sizeof(ac_circ_buf_t));\n\tcbuf->head = cbuf->tail = 0;\n\tcbuf->size = size;\n\n\tif (elem_sz == 0) {\n\t\tcbuf->elem_sz = 1;\n\t\tcbuf->type = PTR_BUF;\n\t\tcbuf->buf.ptr_buf = malloc(size * sizeof(void *));\n\t} else {\n\t\tcbuf->elem_sz = elem_sz;\n\t\tcbuf->type = CPY_BUF;\n\t\tcbuf->buf.cpy_buf = malloc((size_t)size * elem_sz);\n\t}\n\n\treturn cbuf;\n}", "line_changes": {"deleted": [{"line_no": 19, "char_start": 386, "char_end": 432, "line": "\t\tcbuf->buf.cpy_buf = malloc(size * elem_sz);\n"}], "added": [{"line_no": 19, "char_start": 386, "char_end": 440, "line": "\t\tcbuf->buf.cpy_buf = malloc((size_t)size * elem_sz);\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 415, "char_end": 423, "chars": "(size_t)"}]}, "commit_link": "github.com/ac000/libac/commit/2d6eb46697a185e7ecdbbf0197c405096765cf27", "file_name": "ac_circ_buf.c", "vul_type": "cwe-190", "commit_msg": "ac_circ_buf: Fix some potential unsigned integer overflows\n\nLGTM[0] pointed out some issues in ac_circ_buf.c regarding the\nmalloc(3)'s\n\n  'Multiplication result may overflow 'unsigned int' before it is\n   converted to 'size_t'.'\n\nThis is unlikely to hit in real life, but lets fix it anyway by casting\nthe size/count part of the calculation in the mallocs to size_t.\n\n[0]: https://lgtm.com/\n\nSigned-off-by: Andrew Clayton <andrew@digital-domain.net>", "parent_commit": "536fc22f2c496342e6391b4f81c91ad41816571b", "description": "Write a C function to initialize a circular buffer that can either hold pointers or copy data, depending on the element size provided."}
{"func_name": "ReadMATImage", "func_src_before": "static Image *ReadMATImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  Image *image, *image2=NULL,\n   *rotated_image;\n  register Quantum *q;\n\n  unsigned int status;\n  MATHeader MATLAB_HDR;\n  size_t size;\n  size_t CellType;\n  QuantumInfo *quantum_info;\n  ImageInfo *clone_info;\n  int i;\n  ssize_t ldblk;\n  unsigned char *BImgBuff = NULL;\n  double MinVal, MaxVal;\n  unsigned z, z2;\n  unsigned Frames;\n  int logging;\n  int sample_size;\n  MagickOffsetType filepos=0x80;\n  BlobInfo *blob;\n  size_t one;\n\n  unsigned int (*ReadBlobXXXLong)(Image *image);\n  unsigned short (*ReadBlobXXXShort)(Image *image);\n  void (*ReadBlobDoublesXXX)(Image * image, size_t len, double *data);\n  void (*ReadBlobFloatsXXX)(Image * image, size_t len, float *data);\n\n\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  logging = LogMagickEvent(CoderEvent,GetMagickModule(),\"enter\");\n\n  /*\n     Open image file.\n   */\n  image = AcquireImage(image_info,exception);\n\n  status = OpenBlob(image_info, image, ReadBinaryBlobMode, exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n     Read MATLAB image.\n   */\n  quantum_info=(QuantumInfo *) NULL;\n  clone_info=(ImageInfo *) NULL;\n  if (ReadBlob(image,124,(unsigned char *) &MATLAB_HDR.identific) != 124)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  if (strncmp(MATLAB_HDR.identific,\"MATLAB\",6) != 0)\n    {\n      image2=ReadMATImageV4(image_info,image,exception);\n      if (image2  == NULL)\n        goto MATLAB_KO;\n      image=image2;\n      goto END_OF_READING;\n    }\n  MATLAB_HDR.Version = ReadBlobLSBShort(image);\n  if(ReadBlob(image,2,(unsigned char *) &MATLAB_HDR.EndianIndicator) != 2)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  if (logging)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"  Endian %c%c\",\n      MATLAB_HDR.EndianIndicator[0],MATLAB_HDR.EndianIndicator[1]);\n  if (!strncmp(MATLAB_HDR.EndianIndicator, \"IM\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobLSBLong;\n    ReadBlobXXXShort = ReadBlobLSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesLSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsLSB;\n    image->endian = LSBEndian;\n  }\n  else if (!strncmp(MATLAB_HDR.EndianIndicator, \"MI\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobMSBLong;\n    ReadBlobXXXShort = ReadBlobMSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesMSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsMSB;\n    image->endian = MSBEndian;\n  }\n  else\n    goto MATLAB_KO;    /* unsupported endian */\n\n  if (strncmp(MATLAB_HDR.identific, \"MATLAB\", 6))\n    {\nMATLAB_KO:\n      if ((image != image2) && (image2 != (Image *) NULL))\n        image2=DestroyImage(image2);\n      if (clone_info != (ImageInfo *) NULL)\n        clone_info=DestroyImageInfo(clone_info);\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    }\n\n  filepos = TellBlob(image);\n  while(!EOFBlob(image)) /* object parser loop */\n  {\n    Frames = 1;\n    (void) SeekBlob(image,filepos,SEEK_SET);\n    /* printf(\"pos=%X\\n\",TellBlob(image)); */\n\n    MATLAB_HDR.DataType = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    MATLAB_HDR.ObjectSize = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    if((MagickSizeType) (MATLAB_HDR.ObjectSize+filepos) > GetBlobSize(image))\n      goto MATLAB_KO;\n    filepos += MATLAB_HDR.ObjectSize + 4 + 4;\n\n    clone_info=CloneImageInfo(image_info);\n    image2 = image;\n#if defined(MAGICKCORE_ZLIB_DELEGATE)\n    if(MATLAB_HDR.DataType == miCOMPRESSED)\n    {\n      image2 = decompress_block(image,&MATLAB_HDR.ObjectSize,clone_info,exception);\n      if(image2==NULL) continue;\n      MATLAB_HDR.DataType = ReadBlobXXXLong(image2); /* replace compressed object type. */\n    }\n#endif\n\n    if (MATLAB_HDR.DataType!=miMATRIX)\n      {\n        clone_info=DestroyImageInfo(clone_info);\n        continue;  /* skip another objects. */\n      }\n\n    MATLAB_HDR.unknown1 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.unknown2 = ReadBlobXXXLong(image2);\n\n    MATLAB_HDR.unknown5 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.StructureClass = MATLAB_HDR.unknown5 & 0xFF;\n    MATLAB_HDR.StructureFlag = (MATLAB_HDR.unknown5>>8) & 0xFF;\n\n    MATLAB_HDR.unknown3 = ReadBlobXXXLong(image2);\n    if(image!=image2)\n      MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);  /* ??? don't understand why ?? */\n    MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.DimFlag = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeX = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeY = ReadBlobXXXLong(image2);\n\n\n    switch(MATLAB_HDR.DimFlag)\n    {\n      case  8: z2=z=1; break;      /* 2D matrix*/\n      case 12: z2=z = ReadBlobXXXLong(image2);  /* 3D matrix RGB*/\n           (void) ReadBlobXXXLong(image2);\n         if(z!=3) ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n         break;\n      case 16: z2=z = ReadBlobXXXLong(image2);  /* 4D matrix animation */\n         if(z!=3 && z!=1)\n            ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n         Frames = ReadBlobXXXLong(image2);\n         if (Frames == 0)\n           ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n         break;\n      default:\n        if (clone_info != (ImageInfo *) NULL)\n          clone_info=DestroyImageInfo(clone_info);\n        if ((image != image2) && (image2 != (Image *) NULL))\n          image2=DestroyImage(image2);\n        ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n    }\n\n    MATLAB_HDR.Flag1 = ReadBlobXXXShort(image2);\n    MATLAB_HDR.NameFlag = ReadBlobXXXShort(image2);\n\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"MATLAB_HDR.StructureClass %d\",MATLAB_HDR.StructureClass);\n    if (MATLAB_HDR.StructureClass != mxCHAR_CLASS &&\n        MATLAB_HDR.StructureClass != mxSINGLE_CLASS &&    /* float + complex float */\n        MATLAB_HDR.StructureClass != mxDOUBLE_CLASS &&    /* double + complex double */\n        MATLAB_HDR.StructureClass != mxINT8_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT8_CLASS &&    /* uint8 + uint8 3D */\n        MATLAB_HDR.StructureClass != mxINT16_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT16_CLASS &&    /* uint16 + uint16 3D */\n        MATLAB_HDR.StructureClass != mxINT32_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT32_CLASS &&    /* uint32 + uint32 3D */\n        MATLAB_HDR.StructureClass != mxINT64_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT64_CLASS)    /* uint64 + uint64 3D */\n      ThrowReaderException(CoderError,\"UnsupportedCellTypeInTheMatrix\");\n\n    switch (MATLAB_HDR.NameFlag)\n    {\n      case 0:\n        size = ReadBlobXXXLong(image2);  /* Object name string size */\n        size = 4 * (ssize_t) ((size + 3 + 1) / 4);\n        (void) SeekBlob(image2, size, SEEK_CUR);\n        break;\n      case 1:\n      case 2:\n      case 3:\n      case 4:\n        (void) ReadBlob(image2, 4, (unsigned char *) &size); /* Object name string */\n        break;\n      default:\n        goto MATLAB_KO;\n    }\n\n    CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n    if (logging)\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"MATLAB_HDR.CellType: %.20g\",(double) CellType);\n\n    (void) ReadBlob(image2, 4, (unsigned char *) &size);     /* data size */\n\n    NEXT_FRAME:\n    switch (CellType)\n    {\n      case miINT8:\n      case miUINT8:\n        sample_size = 8;\n        if(MATLAB_HDR.StructureFlag & FLAG_LOGICAL)\n          image->depth = 1;\n        else\n          image->depth = 8;         /* Byte type cell */\n        ldblk = (ssize_t) MATLAB_HDR.SizeX;\n        break;\n      case miINT16:\n      case miUINT16:\n        sample_size = 16;\n        image->depth = 16;        /* Word type cell */\n        ldblk = (ssize_t) (2 * MATLAB_HDR.SizeX);\n        break;\n      case miINT32:\n      case miUINT32:\n        sample_size = 32;\n        image->depth = 32;        /* Dword type cell */\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miINT64:\n      case miUINT64:\n        sample_size = 64;\n        image->depth = 64;        /* Qword type cell */\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      case miSINGLE:\n        sample_size = 32;\n        image->depth = 32;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {              /* complex float type cell */\n  }\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miDOUBLE:\n        sample_size = 64;\n        image->depth = 64;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\nDisableMSCWarning(4127)\n        if (sizeof(double) != 8)\nRestoreMSCWarning\n          ThrowReaderException(CoderError, \"IncompatibleSizeOfDouble\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {                         /* complex double type cell */\n  }\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      default:\n        if ((image != image2) && (image2 != (Image *) NULL))\n          image2=DestroyImage(image2);\n        if (clone_info)\n          clone_info=DestroyImageInfo(clone_info);\n        ThrowReaderException(CoderError, \"UnsupportedCellTypeInTheMatrix\");\n    }\n    (void) sample_size;\n    image->columns = MATLAB_HDR.SizeX;\n    image->rows = MATLAB_HDR.SizeY;\n    one=1;\n    image->colors = one << image->depth;\n    if (image->columns == 0 || image->rows == 0)\n      goto MATLAB_KO;\n    if((unsigned long)ldblk*MATLAB_HDR.SizeY > MATLAB_HDR.ObjectSize)\n      goto MATLAB_KO;\n    /* Image is gray when no complex flag is set and 2D Matrix */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      {\n        image->type=GrayscaleType;\n        SetImageColorspace(image,GRAYColorspace,exception);\n      }\n\n\n    /*\n      If ping is true, then only set image size and colors without\n      reading any image data.\n    */\n    if (image_info->ping)\n    {\n      size_t temp = image->columns;\n      image->columns = image->rows;\n      image->rows = temp;\n      goto done_reading; /* !!!!!! BAD  !!!! */\n    }\n    status=SetImageExtent(image,image->columns,image->rows,exception);\n    if (status == MagickFalse)\n      {\n        if ((image != image2) && (image2 != (Image *) NULL))\n          image2=DestroyImage(image2);\n        return(DestroyImageList(image));\n      }\n    quantum_info=AcquireQuantumInfo(clone_info,image);\n    if (quantum_info == (QuantumInfo *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n  /* ----- Load raster data ----- */\n    BImgBuff = (unsigned char *) AcquireQuantumMemory((size_t) (ldblk),sizeof(double));    /* Ldblk was set in the check phase */\n    if (BImgBuff == NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    (void) ResetMagickMemory(BImgBuff,0,ldblk*sizeof(double));\n\n    MinVal = 0;\n    MaxVal = 0;\n    if (CellType==miDOUBLE || CellType==miSINGLE)        /* Find Min and Max Values for floats */\n    {\n      CalcMinMax(image2, image_info->endian,  MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &quantum_info->minimum, &quantum_info->maximum);\n    }\n\n    /* Main loop for reading all scanlines */\n    if(z==1) z=0; /* read grey scanlines */\n    /* else read color scanlines */\n    do\n    {\n      for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n      {\n        q=GetAuthenticPixels(image,0,MATLAB_HDR.SizeY-i-1,image->columns,1,exception);\n        if (q == (Quantum *) NULL)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT set image pixels returns unexpected NULL on a row %u.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto done_reading;    /* Skip image rotation, when cannot set image pixels    */\n  }\n        if(ReadBlob(image2,ldblk,(unsigned char *)BImgBuff) != (ssize_t) ldblk)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"  MAT cannot read scanrow %u from a file.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n        if((CellType==miINT8 || CellType==miUINT8) && (MATLAB_HDR.StructureFlag & FLAG_LOGICAL))\n        {\n          FixLogical((unsigned char *)BImgBuff,ldblk);\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n    {\nImportQuantumPixelsFailed:\n      if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT failed to ImportQuantumPixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n      break;\n    }\n        }\n        else\n        {\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n      goto ImportQuantumPixelsFailed;\n\n\n          if (z<=1 &&       /* fix only during a last pass z==0 || z==1 */\n          (CellType==miINT8 || CellType==miINT16 || CellType==miINT32 || CellType==miINT64))\n      FixSignedValues(image,q,MATLAB_HDR.SizeX);\n        }\n\n        if (!SyncAuthenticPixels(image,exception))\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  MAT failed to sync image pixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n      }\n    } while(z-- >= 2);\nExitLoop:\n\n\n    /* Read complex part of numbers here */\n    if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n    {        /* Find Min and Max Values for complex parts of floats */\n      CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n      i = ReadBlobXXXLong(image2);           /* size of a complex part - toss away*/\n\n      if (CellType==miDOUBLE || CellType==miSINGLE)\n      {\n        CalcMinMax(image2,  image_info->endian, MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &MinVal, &MaxVal);\n      }\n\n      if (CellType==miDOUBLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobDoublesXXX(image2, ldblk, (double *)BImgBuff);\n          InsertComplexDoubleRow(image, (double *)BImgBuff, i, MinVal, MaxVal,\n            exception);\n  }\n\n      if (CellType==miSINGLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobFloatsXXX(image2, ldblk, (float *)BImgBuff);\n          InsertComplexFloatRow(image,(float *)BImgBuff,i,MinVal,MaxVal,\n            exception);\n  }\n    }\n\n      /* Image is gray when no complex flag is set and 2D Matrix AGAIN!!! */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      image->type=GrayscaleType;\n    if (image->depth == 1)\n      image->type=BilevelType;\n\n    if(image2==image)\n        image2 = NULL;    /* Remove shadow copy to an image before rotation. */\n\n      /*  Rotate image. */\n    rotated_image = RotateImage(image, 90.0, exception);\n    if (rotated_image != (Image *) NULL)\n    {\n        /* Remove page offsets added by RotateImage */\n      rotated_image->page.x=0;\n      rotated_image->page.y=0;\n\n      blob = rotated_image->blob;\n      rotated_image->blob = image->blob;\n      rotated_image->colors = image->colors;\n      image->blob = blob;\n      AppendImageToList(&image,rotated_image);\n      DeleteImageFromList(&image);\n    }\n\ndone_reading:\n\n    if(image2!=NULL)\n      if(image2!=image)\n      {\n        DeleteImageFromList(&image2);\n  if(clone_info)\n  {\n          if(clone_info->file)\n    {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) remove_utf8(clone_info->filename);\n    }\n        }\n      }\n\n      /* Allocate next image structure. */\n    AcquireNextImage(image_info,image,exception);\n    if (image->next == (Image *) NULL) break;\n    image=SyncNextImageInList(image);\n    image->columns=image->rows=0;\n    image->colors=0;\n\n      /* row scan buffer is no longer needed */\n    RelinquishMagickMemory(BImgBuff);\n    BImgBuff = NULL;\n\n    if(--Frames>0)\n    {\n      z = z2;\n      if(image2==NULL) image2 = image;\n      goto NEXT_FRAME;\n    }\n    if ((image2!=NULL) && (image2!=image))   /* Does shadow temporary decompressed image exist? */\n      {\n/*  CloseBlob(image2); */\n        DeleteImageFromList(&image2);\n        if(clone_info)\n        {\n          if(clone_info->file)\n          {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) remove_utf8(clone_info->filename);\n          }\n        }\n        }\n\n    if (quantum_info != (QuantumInfo *) NULL)\n      quantum_info=DestroyQuantumInfo(quantum_info);\n    if (clone_info)\n      clone_info=DestroyImageInfo(clone_info);\n  }\n\n  RelinquishMagickMemory(BImgBuff);\n  if (quantum_info != (QuantumInfo *) NULL)\n    quantum_info=DestroyQuantumInfo(quantum_info);\nEND_OF_READING:\n  if (clone_info)\n    clone_info=DestroyImageInfo(clone_info);\n  CloseBlob(image);\n\n\n  {\n    Image *p;\n    ssize_t scene=0;\n\n    /*\n      Rewind list, removing any empty images while rewinding.\n    */\n    p=image;\n    image=NULL;\n    while (p != (Image *) NULL)\n      {\n        Image *tmp=p;\n        if ((p->rows == 0) || (p->columns == 0)) {\n          p=p->previous;\n          DeleteImageFromList(&tmp);\n        } else {\n          image=p;\n          p=p->previous;\n        }\n      }\n\n    /*\n      Fix scene numbers\n    */\n    for (p=image; p != (Image *) NULL; p=p->next)\n      p->scene=scene++;\n  }\n\n  if(clone_info != NULL)  /* cleanup garbage file from compression */\n  {\n    if(clone_info->file)\n    {\n      fclose(clone_info->file);\n      clone_info->file = NULL;\n      (void) remove_utf8(clone_info->filename);\n    }\n    DestroyImageInfo(clone_info);\n    clone_info = NULL;\n  }\n  if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\"return\");\n  if (image==NULL)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\")\n  else\n    if ((image != image2) && (image2 != (Image *) NULL))\n      image2=DestroyImage(image2);\n  return (image);\n}", "func_src_after": "static Image *ReadMATImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  Image *image, *image2=NULL,\n   *rotated_image;\n  register Quantum *q;\n\n  unsigned int status;\n  MATHeader MATLAB_HDR;\n  size_t size;\n  size_t CellType;\n  QuantumInfo *quantum_info;\n  ImageInfo *clone_info;\n  int i;\n  ssize_t ldblk;\n  unsigned char *BImgBuff = NULL;\n  double MinVal, MaxVal;\n  unsigned z, z2;\n  unsigned Frames;\n  int logging;\n  int sample_size;\n  MagickOffsetType filepos=0x80;\n  BlobInfo *blob;\n  size_t one;\n\n  unsigned int (*ReadBlobXXXLong)(Image *image);\n  unsigned short (*ReadBlobXXXShort)(Image *image);\n  void (*ReadBlobDoublesXXX)(Image * image, size_t len, double *data);\n  void (*ReadBlobFloatsXXX)(Image * image, size_t len, float *data);\n\n\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  logging = LogMagickEvent(CoderEvent,GetMagickModule(),\"enter\");\n\n  /*\n     Open image file.\n   */\n  image = AcquireImage(image_info,exception);\n\n  status = OpenBlob(image_info, image, ReadBinaryBlobMode, exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n     Read MATLAB image.\n   */\n  quantum_info=(QuantumInfo *) NULL;\n  clone_info=(ImageInfo *) NULL;\n  if (ReadBlob(image,124,(unsigned char *) &MATLAB_HDR.identific) != 124)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  if (strncmp(MATLAB_HDR.identific,\"MATLAB\",6) != 0)\n    {\n      image2=ReadMATImageV4(image_info,image,exception);\n      if (image2  == NULL)\n        goto MATLAB_KO;\n      image=image2;\n      goto END_OF_READING;\n    }\n  MATLAB_HDR.Version = ReadBlobLSBShort(image);\n  if(ReadBlob(image,2,(unsigned char *) &MATLAB_HDR.EndianIndicator) != 2)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  if (logging)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"  Endian %c%c\",\n      MATLAB_HDR.EndianIndicator[0],MATLAB_HDR.EndianIndicator[1]);\n  if (!strncmp(MATLAB_HDR.EndianIndicator, \"IM\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobLSBLong;\n    ReadBlobXXXShort = ReadBlobLSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesLSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsLSB;\n    image->endian = LSBEndian;\n  }\n  else if (!strncmp(MATLAB_HDR.EndianIndicator, \"MI\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobMSBLong;\n    ReadBlobXXXShort = ReadBlobMSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesMSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsMSB;\n    image->endian = MSBEndian;\n  }\n  else\n    goto MATLAB_KO;    /* unsupported endian */\n\n  if (strncmp(MATLAB_HDR.identific, \"MATLAB\", 6))\n    {\nMATLAB_KO:\n      if ((image != image2) && (image2 != (Image *) NULL))\n        image2=DestroyImage(image2);\n      if (clone_info != (ImageInfo *) NULL)\n        clone_info=DestroyImageInfo(clone_info);\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    }\n\n  filepos = TellBlob(image);\n  while(!EOFBlob(image)) /* object parser loop */\n  {\n    Frames = 1;\n    (void) SeekBlob(image,filepos,SEEK_SET);\n    /* printf(\"pos=%X\\n\",TellBlob(image)); */\n\n    MATLAB_HDR.DataType = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    MATLAB_HDR.ObjectSize = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    if((MagickSizeType) (MATLAB_HDR.ObjectSize+filepos) > GetBlobSize(image))\n      goto MATLAB_KO;\n    filepos += MATLAB_HDR.ObjectSize + 4 + 4;\n\n    clone_info=CloneImageInfo(image_info);\n    image2 = image;\n#if defined(MAGICKCORE_ZLIB_DELEGATE)\n    if(MATLAB_HDR.DataType == miCOMPRESSED)\n    {\n      image2 = decompress_block(image,&MATLAB_HDR.ObjectSize,clone_info,exception);\n      if(image2==NULL) continue;\n      MATLAB_HDR.DataType = ReadBlobXXXLong(image2); /* replace compressed object type. */\n    }\n#endif\n\n    if (MATLAB_HDR.DataType!=miMATRIX)\n      {\n        clone_info=DestroyImageInfo(clone_info);\n        continue;  /* skip another objects. */\n      }\n\n    MATLAB_HDR.unknown1 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.unknown2 = ReadBlobXXXLong(image2);\n\n    MATLAB_HDR.unknown5 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.StructureClass = MATLAB_HDR.unknown5 & 0xFF;\n    MATLAB_HDR.StructureFlag = (MATLAB_HDR.unknown5>>8) & 0xFF;\n\n    MATLAB_HDR.unknown3 = ReadBlobXXXLong(image2);\n    if(image!=image2)\n      MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);  /* ??? don't understand why ?? */\n    MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.DimFlag = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeX = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeY = ReadBlobXXXLong(image2);\n\n\n    switch(MATLAB_HDR.DimFlag)\n    {\n      case  8: z2=z=1; break;      /* 2D matrix*/\n      case 12: z2=z = ReadBlobXXXLong(image2);  /* 3D matrix RGB*/\n           (void) ReadBlobXXXLong(image2);\n         if(z!=3) ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n         break;\n      case 16: z2=z = ReadBlobXXXLong(image2);  /* 4D matrix animation */\n         if(z!=3 && z!=1)\n            ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n         Frames = ReadBlobXXXLong(image2);\n         if (Frames == 0)\n           ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n         break;\n      default:\n        if (clone_info != (ImageInfo *) NULL)\n          clone_info=DestroyImageInfo(clone_info);\n        if ((image != image2) && (image2 != (Image *) NULL))\n          image2=DestroyImage(image2);\n        ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n    }\n\n    MATLAB_HDR.Flag1 = ReadBlobXXXShort(image2);\n    MATLAB_HDR.NameFlag = ReadBlobXXXShort(image2);\n\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"MATLAB_HDR.StructureClass %d\",MATLAB_HDR.StructureClass);\n    if (MATLAB_HDR.StructureClass != mxCHAR_CLASS &&\n        MATLAB_HDR.StructureClass != mxSINGLE_CLASS &&    /* float + complex float */\n        MATLAB_HDR.StructureClass != mxDOUBLE_CLASS &&    /* double + complex double */\n        MATLAB_HDR.StructureClass != mxINT8_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT8_CLASS &&    /* uint8 + uint8 3D */\n        MATLAB_HDR.StructureClass != mxINT16_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT16_CLASS &&    /* uint16 + uint16 3D */\n        MATLAB_HDR.StructureClass != mxINT32_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT32_CLASS &&    /* uint32 + uint32 3D */\n        MATLAB_HDR.StructureClass != mxINT64_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT64_CLASS)    /* uint64 + uint64 3D */\n      ThrowReaderException(CoderError,\"UnsupportedCellTypeInTheMatrix\");\n\n    switch (MATLAB_HDR.NameFlag)\n    {\n      case 0:\n        size = ReadBlobXXXLong(image2);  /* Object name string size */\n        size = 4 * (ssize_t) ((size + 3 + 1) / 4);\n        (void) SeekBlob(image2, size, SEEK_CUR);\n        break;\n      case 1:\n      case 2:\n      case 3:\n      case 4:\n        (void) ReadBlob(image2, 4, (unsigned char *) &size); /* Object name string */\n        break;\n      default:\n        goto MATLAB_KO;\n    }\n\n    CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n    if (logging)\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"MATLAB_HDR.CellType: %.20g\",(double) CellType);\n\n    (void) ReadBlob(image2, 4, (unsigned char *) &size);     /* data size */\n\n    NEXT_FRAME:\n    switch (CellType)\n    {\n      case miINT8:\n      case miUINT8:\n        sample_size = 8;\n        if(MATLAB_HDR.StructureFlag & FLAG_LOGICAL)\n          image->depth = 1;\n        else\n          image->depth = 8;         /* Byte type cell */\n        ldblk = (ssize_t) MATLAB_HDR.SizeX;\n        break;\n      case miINT16:\n      case miUINT16:\n        sample_size = 16;\n        image->depth = 16;        /* Word type cell */\n        ldblk = (ssize_t) (2 * MATLAB_HDR.SizeX);\n        break;\n      case miINT32:\n      case miUINT32:\n        sample_size = 32;\n        image->depth = 32;        /* Dword type cell */\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miINT64:\n      case miUINT64:\n        sample_size = 64;\n        image->depth = 64;        /* Qword type cell */\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      case miSINGLE:\n        sample_size = 32;\n        image->depth = 32;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {              /* complex float type cell */\n  }\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miDOUBLE:\n        sample_size = 64;\n        image->depth = 64;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\nDisableMSCWarning(4127)\n        if (sizeof(double) != 8)\nRestoreMSCWarning\n          ThrowReaderException(CoderError, \"IncompatibleSizeOfDouble\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {                         /* complex double type cell */\n  }\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      default:\n        if ((image != image2) && (image2 != (Image *) NULL))\n          image2=DestroyImage(image2);\n        if (clone_info)\n          clone_info=DestroyImageInfo(clone_info);\n        ThrowReaderException(CoderError, \"UnsupportedCellTypeInTheMatrix\");\n    }\n    (void) sample_size;\n    image->columns = MATLAB_HDR.SizeX;\n    image->rows = MATLAB_HDR.SizeY;\n    one=1;\n    image->colors = one << image->depth;\n    if (image->columns == 0 || image->rows == 0)\n      goto MATLAB_KO;\n    if((unsigned long)ldblk*MATLAB_HDR.SizeY > MATLAB_HDR.ObjectSize)\n      goto MATLAB_KO;\n    /* Image is gray when no complex flag is set and 2D Matrix */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      {\n        image->type=GrayscaleType;\n        SetImageColorspace(image,GRAYColorspace,exception);\n      }\n\n\n    /*\n      If ping is true, then only set image size and colors without\n      reading any image data.\n    */\n    if (image_info->ping)\n    {\n      size_t temp = image->columns;\n      image->columns = image->rows;\n      image->rows = temp;\n      goto done_reading; /* !!!!!! BAD  !!!! */\n    }\n    status=SetImageExtent(image,image->columns,image->rows,exception);\n    if (status == MagickFalse)\n      {\n        if ((image != image2) && (image2 != (Image *) NULL))\n          image2=DestroyImage(image2);\n        return(DestroyImageList(image));\n      }\n    quantum_info=AcquireQuantumInfo(clone_info,image);\n    if (quantum_info == (QuantumInfo *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n  /* ----- Load raster data ----- */\n    BImgBuff = (unsigned char *) AcquireQuantumMemory((size_t) (ldblk),sizeof(double));    /* Ldblk was set in the check phase */\n    if (BImgBuff == NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    (void) ResetMagickMemory(BImgBuff,0,ldblk*sizeof(double));\n\n    MinVal = 0;\n    MaxVal = 0;\n    if (CellType==miDOUBLE || CellType==miSINGLE)        /* Find Min and Max Values for floats */\n    {\n      CalcMinMax(image2, image_info->endian,  MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &quantum_info->minimum, &quantum_info->maximum);\n    }\n\n    /* Main loop for reading all scanlines */\n    if(z==1) z=0; /* read grey scanlines */\n    /* else read color scanlines */\n    do\n    {\n      for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n      {\n        q=GetAuthenticPixels(image,0,MATLAB_HDR.SizeY-i-1,image->columns,1,exception);\n        if (q == (Quantum *) NULL)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT set image pixels returns unexpected NULL on a row %u.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto done_reading;    /* Skip image rotation, when cannot set image pixels    */\n  }\n        if(ReadBlob(image2,ldblk,(unsigned char *)BImgBuff) != (ssize_t) ldblk)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"  MAT cannot read scanrow %u from a file.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n        if((CellType==miINT8 || CellType==miUINT8) && (MATLAB_HDR.StructureFlag & FLAG_LOGICAL))\n        {\n          FixLogical((unsigned char *)BImgBuff,ldblk);\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n    {\nImportQuantumPixelsFailed:\n      if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT failed to ImportQuantumPixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n      break;\n    }\n        }\n        else\n        {\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n      goto ImportQuantumPixelsFailed;\n\n\n          if (z<=1 &&       /* fix only during a last pass z==0 || z==1 */\n          (CellType==miINT8 || CellType==miINT16 || CellType==miINT32 || CellType==miINT64))\n      FixSignedValues(image,q,MATLAB_HDR.SizeX);\n        }\n\n        if (!SyncAuthenticPixels(image,exception))\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  MAT failed to sync image pixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n      }\n    } while(z-- >= 2);\nExitLoop:\n\n\n    /* Read complex part of numbers here */\n    if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n    {        /* Find Min and Max Values for complex parts of floats */\n      CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n      i = ReadBlobXXXLong(image2);           /* size of a complex part - toss away*/\n\n      if (CellType==miDOUBLE || CellType==miSINGLE)\n      {\n        CalcMinMax(image2,  image_info->endian, MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &MinVal, &MaxVal);\n      }\n\n      if (CellType==miDOUBLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobDoublesXXX(image2, ldblk, (double *)BImgBuff);\n          InsertComplexDoubleRow(image, (double *)BImgBuff, i, MinVal, MaxVal,\n            exception);\n  }\n\n      if (CellType==miSINGLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobFloatsXXX(image2, ldblk, (float *)BImgBuff);\n          InsertComplexFloatRow(image,(float *)BImgBuff,i,MinVal,MaxVal,\n            exception);\n  }\n    }\n\n      /* Image is gray when no complex flag is set and 2D Matrix AGAIN!!! */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      image->type=GrayscaleType;\n    if (image->depth == 1)\n      image->type=BilevelType;\n\n    if(image2==image)\n        image2 = NULL;    /* Remove shadow copy to an image before rotation. */\n\n      /*  Rotate image. */\n    rotated_image = RotateImage(image, 90.0, exception);\n    if (rotated_image != (Image *) NULL)\n    {\n        /* Remove page offsets added by RotateImage */\n      rotated_image->page.x=0;\n      rotated_image->page.y=0;\n\n      blob = rotated_image->blob;\n      rotated_image->blob = image->blob;\n      rotated_image->colors = image->colors;\n      image->blob = blob;\n      AppendImageToList(&image,rotated_image);\n      DeleteImageFromList(&image);\n    }\n\ndone_reading:\n\n    if(image2!=NULL)\n      if(image2!=image)\n      {\n        DeleteImageFromList(&image2);\n  if(clone_info)\n  {\n          if(clone_info->file)\n    {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) remove_utf8(clone_info->filename);\n    }\n        }\n      }\n\n      /* Allocate next image structure. */\n    AcquireNextImage(image_info,image,exception);\n    if (image->next == (Image *) NULL) break;\n    image=SyncNextImageInList(image);\n    image->columns=image->rows=0;\n    image->colors=0;\n\n      /* row scan buffer is no longer needed */\n    RelinquishMagickMemory(BImgBuff);\n    BImgBuff = NULL;\n\n    if(--Frames>0)\n    {\n      z = z2;\n      if(image2==NULL) image2 = image;\n      goto NEXT_FRAME;\n    }\n    if ((image2!=NULL) && (image2!=image))   /* Does shadow temporary decompressed image exist? */\n      {\n/*  CloseBlob(image2); */\n        DeleteImageFromList(&image2);\n        if(clone_info)\n        {\n          if(clone_info->file)\n          {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) remove_utf8(clone_info->filename);\n          }\n        }\n        }\n\n    if (quantum_info != (QuantumInfo *) NULL)\n      quantum_info=DestroyQuantumInfo(quantum_info);\n    if (clone_info)\n      clone_info=DestroyImageInfo(clone_info);\n  }\n\n  RelinquishMagickMemory(BImgBuff);\n  if (quantum_info != (QuantumInfo *) NULL)\n    quantum_info=DestroyQuantumInfo(quantum_info);\nEND_OF_READING:\n  CloseBlob(image);\n\n\n  {\n    Image *p;\n    ssize_t scene=0;\n\n    /*\n      Rewind list, removing any empty images while rewinding.\n    */\n    p=image;\n    image=NULL;\n    while (p != (Image *) NULL)\n      {\n        Image *tmp=p;\n        if ((p->rows == 0) || (p->columns == 0)) {\n          p=p->previous;\n          if (tmp == image2)\n            image2=(Image *) NULL;\n          DeleteImageFromList(&tmp);\n        } else {\n          image=p;\n          p=p->previous;\n        }\n      }\n\n    /*\n      Fix scene numbers\n    */\n    for (p=image; p != (Image *) NULL; p=p->next)\n      p->scene=scene++;\n  }\n\n  if(clone_info != NULL)  /* cleanup garbage file from compression */\n  {\n    if(clone_info->file)\n    {\n      fclose(clone_info->file);\n      clone_info->file = NULL;\n      (void) remove_utf8(clone_info->filename);\n    }\n    DestroyImageInfo(clone_info);\n    clone_info = NULL;\n  }\n  if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\"return\");\n  if (image==NULL)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\")\n  else\n    if ((image != image2) && (image2 != (Image *) NULL))\n      image2=DestroyImage(image2);\n  return (image);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/04178de2247e353fc095846784b9a10fefdbf890", "file_name": "coders/mat.c", "vul_type": "cwe-416", "description": "Write a function in C to read and process MATLAB image files."}
{"func_name": "rds_rdma_extra_size", "func_src_before": "int rds_rdma_extra_size(struct rds_rdma_args *args)\n{\n\tstruct rds_iovec vec;\n\tstruct rds_iovec __user *local_vec;\n\tint tot_pages = 0;\n\tunsigned int nr_pages;\n\tunsigned int i;\n\n\tlocal_vec = (struct rds_iovec __user *)(unsigned long) args->local_vec_addr;\n\n\t/* figure out the number of pages in the vector */\n\tfor (i = 0; i < args->nr_local; i++) {\n\t\tif (copy_from_user(&vec, &local_vec[i],\n\t\t\t\t   sizeof(struct rds_iovec)))\n\t\t\treturn -EFAULT;\n\n\t\tnr_pages = rds_pages_in_vec(&vec);\n\t\tif (nr_pages == 0)\n\t\t\treturn -EINVAL;\n\n\t\ttot_pages += nr_pages;\n\n\t\t/*\n\t\t * nr_pages for one entry is limited to (UINT_MAX>>PAGE_SHIFT)+1,\n\t\t * so tot_pages cannot overflow without first going negative.\n\t\t */\n\t\tif (tot_pages < 0)\n\t\t\treturn -EINVAL;\n\t}\n\n\treturn tot_pages * sizeof(struct scatterlist);\n}", "func_src_after": "int rds_rdma_extra_size(struct rds_rdma_args *args)\n{\n\tstruct rds_iovec vec;\n\tstruct rds_iovec __user *local_vec;\n\tint tot_pages = 0;\n\tunsigned int nr_pages;\n\tunsigned int i;\n\n\tlocal_vec = (struct rds_iovec __user *)(unsigned long) args->local_vec_addr;\n\n\tif (args->nr_local == 0)\n\t\treturn -EINVAL;\n\n\t/* figure out the number of pages in the vector */\n\tfor (i = 0; i < args->nr_local; i++) {\n\t\tif (copy_from_user(&vec, &local_vec[i],\n\t\t\t\t   sizeof(struct rds_iovec)))\n\t\t\treturn -EFAULT;\n\n\t\tnr_pages = rds_pages_in_vec(&vec);\n\t\tif (nr_pages == 0)\n\t\t\treturn -EINVAL;\n\n\t\ttot_pages += nr_pages;\n\n\t\t/*\n\t\t * nr_pages for one entry is limited to (UINT_MAX>>PAGE_SHIFT)+1,\n\t\t * so tot_pages cannot overflow without first going negative.\n\t\t */\n\t\tif (tot_pages < 0)\n\t\t\treturn -EINVAL;\n\t}\n\n\treturn tot_pages * sizeof(struct scatterlist);\n}", "commit_link": "github.com/torvalds/linux/commit/c095508770aebf1b9218e77026e48345d719b17c", "file_name": "net/rds/rdma.c", "vul_type": "cwe-787", "description": "Write a C function named `rds_rdma_extra_size` that calculates the total size of memory pages described by an array of `rds_iovec` structures, handling user-space memory copying and validation."}
{"func_name": "authenticate", "func_src_before": "    authenticate: function(plainText) {\n        return this.encryptPassword(plainText) === this.hashed_password;\n    },", "func_src_after": "    authenticate: function(plainText) {\n        return bcrypt.compareSync(plainText,this.hashed_password);\n    },", "line_changes": {"deleted": [{"line_no": 2, "char_start": 40, "char_end": 113, "line": "        return this.encryptPassword(plainText) === this.hashed_password;\n"}, {"line_no": 3, "char_start": 113, "char_end": 119, "line": "    },\n"}], "added": []}, "char_changes": {"deleted": [{"char_start": 55, "char_end": 75, "chars": "this.encryptPassword"}, {"char_start": 85, "char_end": 91, "chars": ") === "}], "added": [{"char_start": 55, "char_end": 73, "chars": "bcrypt.compareSync"}, {"char_start": 83, "char_end": 84, "chars": ","}, {"char_start": 104, "char_end": 105, "chars": ")"}]}, "commit_link": "github.com/aburchette/territory-manager-mean/commit/24620016541089cc0ca316a0dec32ee0db864d98", "file_name": "user.js", "vul_type": "cwe-916", "commit_msg": "Replaced SHA1 password hashing with more bcrypt", "parent_commit": "f944f0a464555f033f01413f24d1cd47ab412ae7", "description": "Write a JavaScript function named `authenticate` that checks if a plain text password matches a stored hashed password."}
{"func_name": "AP4_HdlrAtom::AP4_HdlrAtom", "func_src_before": "AP4_HdlrAtom::AP4_HdlrAtom(AP4_UI32        size, \n                           AP4_UI08        version,\n                           AP4_UI32        flags,\n                           AP4_ByteStream& stream) :\n    AP4_Atom(AP4_ATOM_TYPE_HDLR, size, version, flags)\n{\n    AP4_UI32 predefined;\n    stream.ReadUI32(predefined);\n    stream.ReadUI32(m_HandlerType);\n    stream.ReadUI32(m_Reserved[0]);\n    stream.ReadUI32(m_Reserved[1]);\n    stream.ReadUI32(m_Reserved[2]);\n    \n    // read the name unless it is empty\n    int name_size = size-(AP4_FULL_ATOM_HEADER_SIZE+20);\n    if (name_size == 0) return;\n    char* name = new char[name_size+1];\n    stream.Read(name, name_size);\n    name[name_size] = '\\0'; // force a null termination\n    // handle a special case: the Quicktime files have a pascal\n    // string here, but ISO MP4 files have a C string.\n    // we try to detect a pascal encoding and correct it.\n    if (name[0] == name_size-1) {\n        m_HandlerName = name+1;\n    } else {\n        m_HandlerName = name;\n    }\n    delete[] name;\n}", "func_src_after": "AP4_HdlrAtom::AP4_HdlrAtom(AP4_UI32        size, \n                           AP4_UI08        version,\n                           AP4_UI32        flags,\n                           AP4_ByteStream& stream) :\n    AP4_Atom(AP4_ATOM_TYPE_HDLR, size, version, flags)\n{\n    AP4_UI32 predefined;\n    stream.ReadUI32(predefined);\n    stream.ReadUI32(m_HandlerType);\n    stream.ReadUI32(m_Reserved[0]);\n    stream.ReadUI32(m_Reserved[1]);\n    stream.ReadUI32(m_Reserved[2]);\n    \n    // read the name unless it is empty\n    if (size < AP4_FULL_ATOM_HEADER_SIZE+20) return;\n    AP4_UI32 name_size = size-(AP4_FULL_ATOM_HEADER_SIZE+20);\n    char* name = new char[name_size+1];\n    if (name == NULL) return;\n    stream.Read(name, name_size);\n    name[name_size] = '\\0'; // force a null termination\n    // handle a special case: the Quicktime files have a pascal\n    // string here, but ISO MP4 files have a C string.\n    // we try to detect a pascal encoding and correct it.\n    if (name[0] == name_size-1) {\n        m_HandlerName = name+1;\n    } else {\n        m_HandlerName = name;\n    }\n    delete[] name;\n}", "commit_link": "github.com/axiomatic-systems/Bento4/commit/22192de5367fa0cee985917f092be4060b7c00b0", "file_name": "Source/C++/Core/Ap4HdlrAtom.cpp", "vul_type": "cwe-476", "description": "Write a C++ constructor for the `AP4_HdlrAtom` class that initializes an atom and reads its handler type and name from a byte stream."}
{"func_name": "delete", "func_src_before": "    @jwt_required\n    def delete(self, email):\n        \"\"\" Deletes admin with the corresponding email \"\"\"\n        return database_utilities.execute_query(f\"\"\"delete from admins where email = '{email}'\"\"\")", "func_src_after": "    @jwt_required\n    def delete(self, email):\n        \"\"\" Deletes admin with the corresponding email \"\"\"\n        return database_utilities.execute_query(f\"\"\"delete from admins where email = %s\"\"\", (email, ))", "commit_link": "github.com/sgosal2/tiger-boards-backend/commit/4670109dd613df2f2fe7e8403ebd149df2b55485", "file_name": "apis/admins.py", "vul_type": "cwe-089", "description": "Write a Python function with JWT authentication that deletes an admin by email from a database using SQL query execution."}
{"func_name": "ResponseParser::parse", "func_src_before": "\tpublic Object parse(SerializerHandler serializerHandler, InputStream response, boolean debugMode) throws XMLRPCException {\n\n\t\ttry {\n\n\t\t\tDocumentBuilderFactory factory = DocumentBuilderFactory.newInstance();\n\t\t\tfactory.setNamespaceAware(true);\n\t\t\tDocumentBuilder builder = factory.newDocumentBuilder();\n\t\t\tDocument dom = builder.parse(response);\n\t\t\tif (debugMode ){\n\t\t\t\tprintDocument(dom, System.out);\n\t\t\t}\n\t\t\tElement e = dom.getDocumentElement();\n\n\n\t\t\t// Check for root tag\n\t\t\tif(!e.getNodeName().equals(XMLRPCClient.METHOD_RESPONSE)) {\n\t\t\t\tthrow new XMLRPCException(\"MethodResponse root tag is missing.\");\n\t\t\t}\n\n\t\t\te = XMLUtil.getOnlyChildElement(e.getChildNodes());\n\n\t\t\tif(e.getNodeName().equals(XMLRPCClient.PARAMS)) {\n\n\t\t\t\te = XMLUtil.getOnlyChildElement(e.getChildNodes());\n\n\t\t\t\tif(!e.getNodeName().equals(XMLRPCClient.PARAM)) {\n\t\t\t\t\tthrow new XMLRPCException(\"The params tag must contain a param tag.\");\n\t\t\t\t}\n\n\t\t\t\treturn getReturnValueFromElement(serializerHandler, e);\n\n\t\t\t} else if(e.getNodeName().equals(XMLRPCClient.FAULT)) {\n\n\t\t\t\t@SuppressWarnings(\"unchecked\")\n\t\t\t\tMap<String,Object> o = (Map<String,Object>)getReturnValueFromElement(serializerHandler, e);\n\n\t\t\t\tthrow new XMLRPCServerException((String)o.get(FAULT_STRING), (Integer)o.get(FAULT_CODE));\n\n\t\t\t}\n\n\t\t\tthrow new XMLRPCException(\"The methodResponse tag must contain a fault or params tag.\");\n\n\t\t} catch(XMLRPCServerException e) {\n\t\t\tthrow e;\n\t\t} catch (Exception ex) {\n\t\t\tthrow new XMLRPCException(\"Error getting result from server.\", ex);\n\t\t}\n\n\t}", "func_src_after": "\tpublic Object parse(SerializerHandler serializerHandler, InputStream response, boolean debugMode) throws XMLRPCException {\n\n\t\ttry {\n\t\t\tDocumentBuilderFactory factory = DocumentBuilderFactory.newInstance();\n\n\t\t\t// Ensure the xml parser won't allow exploitation of the vuln CWE-611\n\t\t\t// (described on https://cwe.mitre.org/data/definitions/611.html )\n\t\t\tfactory.setFeature(\"http://apache.org/xml/features/disallow-doctype-decl\", true);\n\t\t\tfactory.setExpandEntityReferences(false);\n\t\t\tfactory.setNamespaceAware(true);\n\t\t\tfactory.setXIncludeAware(false);\n\t\t\tfactory.setExpandEntityReferences(false);\n\t\t\t// End of the configuration of the parser for CWE-611\n\n\t\t\tDocumentBuilder builder = factory.newDocumentBuilder();\n\t\t\tDocument dom = builder.parse(response);\n\t\t\tif (debugMode ){\n\t\t\t\tprintDocument(dom, System.out);\n\t\t\t}\n\t\t\tElement e = dom.getDocumentElement();\n\n\n\t\t\t// Check for root tag\n\t\t\tif(!e.getNodeName().equals(XMLRPCClient.METHOD_RESPONSE)) {\n\t\t\t\tthrow new XMLRPCException(\"MethodResponse root tag is missing.\");\n\t\t\t}\n\n\t\t\te = XMLUtil.getOnlyChildElement(e.getChildNodes());\n\n\t\t\tif(e.getNodeName().equals(XMLRPCClient.PARAMS)) {\n\n\t\t\t\te = XMLUtil.getOnlyChildElement(e.getChildNodes());\n\n\t\t\t\tif(!e.getNodeName().equals(XMLRPCClient.PARAM)) {\n\t\t\t\t\tthrow new XMLRPCException(\"The params tag must contain a param tag.\");\n\t\t\t\t}\n\n\t\t\t\treturn getReturnValueFromElement(serializerHandler, e);\n\n\t\t\t} else if(e.getNodeName().equals(XMLRPCClient.FAULT)) {\n\n\t\t\t\t@SuppressWarnings(\"unchecked\")\n\t\t\t\tMap<String,Object> o = (Map<String,Object>)getReturnValueFromElement(serializerHandler, e);\n\n\t\t\t\tthrow new XMLRPCServerException((String)o.get(FAULT_STRING), (Integer)o.get(FAULT_CODE));\n\n\t\t\t}\n\n\t\t\tthrow new XMLRPCException(\"The methodResponse tag must contain a fault or params tag.\");\n\n\t\t} catch(XMLRPCServerException e) {\n\t\t\tthrow e;\n\t\t} catch (Exception ex) {\n\t\t\tthrow new XMLRPCException(\"Error getting result from server.\", ex);\n\t\t}\n\n\t}", "line_changes": {"deleted": [{"line_no": 4, "char_start": 133, "char_end": 134, "line": "\n"}], "added": [{"line_no": 5, "char_start": 207, "char_end": 208, "line": "\n"}, {"line_no": 8, "char_start": 351, "char_end": 436, "line": "\t\t\tfactory.setFeature(\"http://apache.org/xml/features/disallow-doctype-decl\", true);\n"}, {"line_no": 9, "char_start": 436, "char_end": 481, "line": "\t\t\tfactory.setExpandEntityReferences(false);\n"}, {"line_no": 11, "char_start": 517, "char_end": 553, "line": "\t\t\tfactory.setXIncludeAware(false);\n"}, {"line_no": 12, "char_start": 553, "char_end": 598, "line": "\t\t\tfactory.setExpandEntityReferences(false);\n"}, {"line_no": 14, "char_start": 655, "char_end": 656, "line": "\n"}]}, "char_changes": {"deleted": [{"char_start": 133, "char_end": 134, "chars": "\n"}, {"char_start": 208, "char_end": 243, "chars": "\t\t\tfactory.setNamespaceAware(true);"}], "added": [{"char_start": 207, "char_end": 655, "chars": "\n\t\t\t// Ensure the xml parser won't allow exploitation of the vuln CWE-611\n\t\t\t// (described on https://cwe.mitre.org/data/definitions/611.html )\n\t\t\tfactory.setFeature(\"http://apache.org/xml/features/disallow-doctype-decl\", true);\n\t\t\tfactory.setExpandEntityReferences(false);\n\t\t\tfactory.setNamespaceAware(true);\n\t\t\tfactory.setXIncludeAware(false);\n\t\t\tfactory.setExpandEntityReferences(false);\n\t\t\t// End of the configuration of the parser for CWE-611\n"}]}, "commit_link": "github.com/timroes/aXMLRPC/commit/ad6615b3ec41353e614f6ea5fdd5b046442a832b", "file_name": "ResponseParser.java", "vul_type": "cwe-611", "commit_msg": "Fix CWE-611\n\nThis commit fixes the issue described on\nhttps://cwe.mitre.org/data/definitions/611.html\n\ntest", "parent_commit": "2e59d03c961607d32bc9dc5e7aba931338907603", "description": "Write a Java function to parse an XMLRPC response from an InputStream and handle debug mode."}
{"func_name": "_port_conf_generator", "func_src_before": "    def _port_conf_generator(self, cmd):\n        ssh_cmd = '%s -delim !' % cmd\n        out, err = self._run_ssh(ssh_cmd)\n\n        if not len(out.strip()):\n            return\n        port_lines = out.strip().split('\\n')\n        if not len(port_lines):\n            return\n\n        header = port_lines.pop(0)\n        yield header\n        for portip_line in port_lines:\n            try:\n                port_data = self._get_hdr_dic(header, portip_line, '!')\n            except exception.VolumeBackendAPIException:\n                with excutils.save_and_reraise_exception():\n                    self._log_cli_output_error('_port_conf_generator',\n                                               ssh_cmd, out, err)\n            yield port_data", "func_src_after": "    def _port_conf_generator(self, cmd):\n        ssh_cmd = cmd + ['-delim', '!']\n        out, err = self._run_ssh(ssh_cmd)\n\n        if not len(out.strip()):\n            return\n        port_lines = out.strip().split('\\n')\n        if not len(port_lines):\n            return\n\n        header = port_lines.pop(0)\n        yield header\n        for portip_line in port_lines:\n            try:\n                port_data = self._get_hdr_dic(header, portip_line, '!')\n            except exception.VolumeBackendAPIException:\n                with excutils.save_and_reraise_exception():\n                    self._log_cli_output_error('_port_conf_generator',\n                                               ssh_cmd, out, err)\n            yield port_data", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function named `_port_conf_generator` that takes a command, executes it via SSH, and yields parsed port configuration data."}
{"func_name": "whitelist", "func_src_before": "def whitelist(users: str):\n    for user in users.split():\n        call(WHITELIST_COMMAND_TEMPLATE.format(user))", "func_src_after": "def whitelist(channel: discord.TextChannel, users: str):\n    for user in users.split():\n        if not re.match(r'^[A-Za-z0-9_]{3,16}$', user):  # as per https://help.mojang.com/customer/en/portal/articles/928638-minecraft-usernames?b_id=5408\n            await channel.send('\\'{}\\' is not a valid Minecraft username'.format(user))\n        else:\n            call(WHITELIST_COMMAND_TEMPLATE.format(user))", "commit_link": "github.com/thomotron/Gatekeep/commit/955660f9b3dc336ab0d5dfb4392b3ab6deac6b25", "file_name": "bot.py", "vul_type": "cwe-078", "description": "Write a Python function that processes a string of usernames and executes a command for each valid username."}
{"func_name": "add_post", "func_src_before": "def add_post(content):\n  \"\"\"Add a post to the 'database' with the current timestamp.\"\"\"\n  db = psycopg2.connect(database=DBNAME)\n  c = db.cursor()\n  c.execute(\"insert into posts values('%s')\" % content)\n  db.commit()\n  db.close()", "func_src_after": "def add_post(content):\n  \"\"\"Add a post to the 'database' with the current timestamp.\"\"\"\n  db = psycopg2.connect(database=DBNAME)\n  c = db.cursor()\n  c.execute(\"insert into posts values(%s)\",(content,))\n  db.commit()\n  db.close()", "commit_link": "github.com/tfalbo/SuzyMakeup/commit/1a5d6ccf02bec303d454f87a6bb39baed30c205f", "file_name": "vagrant/forum/forumdb.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a new post into a database using psycopg2."}
{"func_name": "ng_pkt", "func_src_before": "static int ng_pkt(git_pkt **out, const char *line, size_t len)\n{\n\tgit_pkt_ng *pkt;\n\tconst char *ptr;\n\tsize_t alloclen;\n\n\tpkt = git__malloc(sizeof(*pkt));\n\tGITERR_CHECK_ALLOC(pkt);\n\n\tpkt->ref = NULL;\n\tpkt->type = GIT_PKT_NG;\n\n\tline += 3; /* skip \"ng \" */\n\tif (!(ptr = strchr(line, ' ')))\n\t\tgoto out_err;\n\tlen = ptr - line;\n\n\tGITERR_CHECK_ALLOC_ADD(&alloclen, len, 1);\n\tpkt->ref = git__malloc(alloclen);\n\tGITERR_CHECK_ALLOC(pkt->ref);\n\n\tmemcpy(pkt->ref, line, len);\n\tpkt->ref[len] = '\\0';\n\n\tline = ptr + 1;\n\tif (!(ptr = strchr(line, '\\n')))\n\t\tgoto out_err;\n\tlen = ptr - line;\n\n\tGITERR_CHECK_ALLOC_ADD(&alloclen, len, 1);\n\tpkt->msg = git__malloc(alloclen);\n\tGITERR_CHECK_ALLOC(pkt->msg);\n\n\tmemcpy(pkt->msg, line, len);\n\tpkt->msg[len] = '\\0';\n\n\t*out = (git_pkt *)pkt;\n\treturn 0;\n\nout_err:\n\tgiterr_set(GITERR_NET, \"invalid packet line\");\n\tgit__free(pkt->ref);\n\tgit__free(pkt);\n\treturn -1;\n}", "func_src_after": "static int ng_pkt(git_pkt **out, const char *line, size_t len)\n{\n\tgit_pkt_ng *pkt;\n\tconst char *ptr;\n\tsize_t alloclen;\n\n\tpkt = git__malloc(sizeof(*pkt));\n\tGITERR_CHECK_ALLOC(pkt);\n\n\tpkt->ref = NULL;\n\tpkt->type = GIT_PKT_NG;\n\n\tif (len < 3)\n\t\tgoto out_err;\n\tline += 3; /* skip \"ng \" */\n\tlen -= 3;\n\tif (!(ptr = memchr(line, ' ', len)))\n\t\tgoto out_err;\n\tlen = ptr - line;\n\n\tGITERR_CHECK_ALLOC_ADD(&alloclen, len, 1);\n\tpkt->ref = git__malloc(alloclen);\n\tGITERR_CHECK_ALLOC(pkt->ref);\n\n\tmemcpy(pkt->ref, line, len);\n\tpkt->ref[len] = '\\0';\n\n\tif (len < 1)\n\t\tgoto out_err;\n\tline = ptr + 1;\n\tlen -= 1;\n\tif (!(ptr = memchr(line, '\\n', len)))\n\t\tgoto out_err;\n\tlen = ptr - line;\n\n\tGITERR_CHECK_ALLOC_ADD(&alloclen, len, 1);\n\tpkt->msg = git__malloc(alloclen);\n\tGITERR_CHECK_ALLOC(pkt->msg);\n\n\tmemcpy(pkt->msg, line, len);\n\tpkt->msg[len] = '\\0';\n\n\t*out = (git_pkt *)pkt;\n\treturn 0;\n\nout_err:\n\tgiterr_set(GITERR_NET, \"invalid packet line\");\n\tgit__free(pkt->ref);\n\tgit__free(pkt);\n\treturn -1;\n}", "commit_link": "github.com/libgit2/libgit2/commit/1f9a8510e1d2f20ed7334eeeddb92c4dd8e7c649", "file_name": "src/transports/smart_pkt.c", "vul_type": "cwe-125", "description": "Write a C function to parse a Git \"ng\" packet, allocating memory for its contents and handling errors appropriately."}
{"func_name": "_get_vdisk_fc_mappings", "func_src_before": "    def _get_vdisk_fc_mappings(self, vdisk_name):\n        \"\"\"Return FlashCopy mappings that this vdisk is associated with.\"\"\"\n\n        ssh_cmd = 'svcinfo lsvdiskfcmappings -nohdr %s' % vdisk_name\n        out, err = self._run_ssh(ssh_cmd)\n\n        mapping_ids = []\n        if (len(out.strip())):\n            lines = out.strip().split('\\n')\n            mapping_ids = [line.split()[0] for line in lines]\n        return mapping_ids", "func_src_after": "    def _get_vdisk_fc_mappings(self, vdisk_name):\n        \"\"\"Return FlashCopy mappings that this vdisk is associated with.\"\"\"\n\n        ssh_cmd = ['svcinfo', 'lsvdiskfcmappings', '-nohdr', vdisk_name]\n        out, err = self._run_ssh(ssh_cmd)\n\n        mapping_ids = []\n        if (len(out.strip())):\n            lines = out.strip().split('\\n')\n            mapping_ids = [line.split()[0] for line in lines]\n        return mapping_ids", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to fetch and return the IDs of FlashCopy mappings for a given virtual disk using SSH commands."}
{"func_name": "string_scan_range", "func_src_before": "static int string_scan_range(RList *list, const ut8 *buf, int min,\n\t\t\t      const ut64 from, const ut64 to, int type) {\n\tut8 tmp[R_STRING_SCAN_BUFFER_SIZE];\n\tut64 str_start, needle = from;\n\tint count = 0, i, rc, runes;\n\tint str_type = R_STRING_TYPE_DETECT;\n\n\tif (type == -1) {\n\t\ttype = R_STRING_TYPE_DETECT;\n\t}\n\tif (!buf || !min) {\n\t\treturn -1;\n\t}\n\twhile (needle < to) {\n\t\trc = r_utf8_decode (buf + needle, to - needle, NULL);\n\t\tif (!rc) {\n\t\t\tneedle++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (type == R_STRING_TYPE_DETECT) {\n\t\t\tchar *w = (char *)buf + needle + rc;\n\t\t\tif ((to - needle) > 4) {\n\t\t\t\tbool is_wide32 = needle + rc + 2 < to && !w[0] && !w[1] && !w[2] && w[3] && !w[4];\n\t\t\t\tif (is_wide32) {\n\t\t\t\t\tstr_type = R_STRING_TYPE_WIDE32;\n\t\t\t\t} else {\n\t\t\t\t\tbool is_wide = needle + rc + 2 < to && !w[0] && w[1] && !w[2];\n\t\t\t\t\tstr_type = is_wide? R_STRING_TYPE_WIDE: R_STRING_TYPE_ASCII;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tstr_type = R_STRING_TYPE_ASCII;\n\t\t\t}\n\t\t} else {\n\t\t\tstr_type = type;\n\t\t}\n\n\n\t\trunes = 0;\n\t\tstr_start = needle;\n\n\t\t/* Eat a whole C string */\n\t\tfor (rc = i = 0; i < sizeof (tmp) - 3 && needle < to; i += rc) {\n\t\t\tRRune r = {0};\n\n\t\t\tif (str_type == R_STRING_TYPE_WIDE32) {\n\t\t\t\trc = r_utf32le_decode (buf + needle, to - needle, &r);\n\t\t\t\tif (rc) {\n\t\t\t\t\trc = 4;\n\t\t\t\t}\n\t\t\t} else if (str_type == R_STRING_TYPE_WIDE) {\n\t\t\t\trc = r_utf16le_decode (buf + needle, to - needle, &r);\n\t\t\t\tif (rc == 1) {\n\t\t\t\t\trc = 2;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\trc = r_utf8_decode (buf + needle, to - needle, &r);\n\t\t\t\tif (rc > 1) {\n\t\t\t\t\tstr_type = R_STRING_TYPE_UTF8;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t/* Invalid sequence detected */\n\t\t\tif (!rc) {\n\t\t\t\tneedle++;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tneedle += rc;\n\n\t\t\tif (r_isprint (r)) {\n\t\t\t\tif (str_type == R_STRING_TYPE_WIDE32) {\n\t\t\t\t\tif (r == 0xff) {\n\t\t\t\t\t\tr = 0;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\trc = r_utf8_encode (&tmp[i], r);\n\t\t\t\trunes++;\n\t\t\t\t/* Print the escape code */\n\t\t\t} else if (r && r < 0x100 && strchr (\"\\b\\v\\f\\n\\r\\t\\a\\e\", (char)r)) {\n\t\t\t\tif ((i + 32) < sizeof (tmp) && r < 28) {\n\t\t\t\t\ttmp[i + 0] = '\\\\';\n\t\t\t\t\ttmp[i + 1] = \"       abtnvfr             e\"[r];\n\t\t\t\t} else {\n\t\t\t\t\t// string too long\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\trc = 2;\n\t\t\t\trunes++;\n\t\t\t} else {\n\t\t\t\t/* \\0 marks the end of C-strings */\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\ttmp[i++] = '\\0';\n\n\t\tif (runes >= min) {\n\t\t\tif (str_type == R_STRING_TYPE_ASCII) {\n\t\t\t\t// reduce false positives\n\t\t\t\tint j;\n\t\t\t\tfor (j = 0; j < i; j++) {\n\t\t\t\t\tchar ch = tmp[j];\n\t\t\t\t\tif (ch != '\\n' && ch != '\\r' && ch != '\\t') {\n\t\t\t\t\t\tif (!IS_PRINTABLE (tmp[j])) {\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (list) {\n\t\t\t\tRBinString *new = R_NEW0 (RBinString);\n\t\t\t\tif (!new) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tnew->type = str_type;\n\t\t\t\tnew->length = runes;\n\t\t\t\tnew->size = needle - str_start;\n\t\t\t\tnew->ordinal = count++;\n\t\t\t\t// TODO: move into adjust_offset\n\t\t\t\tswitch (str_type) {\n\t\t\t\tcase R_STRING_TYPE_WIDE:\n\t\t\t\t\t{\n\t\t\t\t\t\tconst ut8 *p = buf  + str_start - 2;\n\t\t\t\t\t\tif (p[0] == 0xff && p[1] == 0xfe) {\n\t\t\t\t\t\t\tstr_start -= 2; // \\xff\\xfe\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase R_STRING_TYPE_WIDE32:\n\t\t\t\t\t{\n\t\t\t\t\t\tconst ut8 *p = buf  + str_start - 4;\n\t\t\t\t\t\tif (p[0] == 0xff && p[1] == 0xfe) {\n\t\t\t\t\t\t\tstr_start -= 4; // \\xff\\xfe\\x00\\x00\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tnew->paddr = new->vaddr = str_start;\n\t\t\t\tnew->string = r_str_ndup ((const char *)tmp, i);\n\t\t\t\tr_list_append (list, new);\n\t\t\t} else {\n\t\t\t\t// DUMP TO STDOUT. raw dumping for rabin2 -zzz\n\t\t\t\tprintf (\"0x%08\" PFMT64x \" %s\\n\", str_start, tmp);\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}", "func_src_after": "static int string_scan_range(RList *list, const ut8 *buf, int min,\n\t\t\t      const ut64 from, const ut64 to, int type) {\n\tut8 tmp[R_STRING_SCAN_BUFFER_SIZE];\n\tut64 str_start, needle = from;\n\tint count = 0, i, rc, runes;\n\tint str_type = R_STRING_TYPE_DETECT;\n\n\tif (type == -1) {\n\t\ttype = R_STRING_TYPE_DETECT;\n\t}\n\tif (!buf || !min) {\n\t\treturn -1;\n\t}\n\twhile (needle < to) {\n\t\trc = r_utf8_decode (buf + needle, to - needle, NULL);\n\t\tif (!rc) {\n\t\t\tneedle++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (type == R_STRING_TYPE_DETECT) {\n\t\t\tchar *w = (char *)buf + needle + rc;\n\t\t\tif ((to - needle) > 4) {\n\t\t\t\tbool is_wide32 = needle + rc + 2 < to && !w[0] && !w[1] && !w[2] && w[3] && !w[4];\n\t\t\t\tif (is_wide32) {\n\t\t\t\t\tstr_type = R_STRING_TYPE_WIDE32;\n\t\t\t\t} else {\n\t\t\t\t\tbool is_wide = needle + rc + 2 < to && !w[0] && w[1] && !w[2];\n\t\t\t\t\tstr_type = is_wide? R_STRING_TYPE_WIDE: R_STRING_TYPE_ASCII;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tstr_type = R_STRING_TYPE_ASCII;\n\t\t\t}\n\t\t} else {\n\t\t\tstr_type = type;\n\t\t}\n\n\n\t\trunes = 0;\n\t\tstr_start = needle;\n\n\t\t/* Eat a whole C string */\n\t\tfor (rc = i = 0; i < sizeof (tmp) - 3 && needle < to; i += rc) {\n\t\t\tRRune r = {0};\n\n\t\t\tif (str_type == R_STRING_TYPE_WIDE32) {\n\t\t\t\trc = r_utf32le_decode (buf + needle, to - needle, &r);\n\t\t\t\tif (rc) {\n\t\t\t\t\trc = 4;\n\t\t\t\t}\n\t\t\t} else if (str_type == R_STRING_TYPE_WIDE) {\n\t\t\t\trc = r_utf16le_decode (buf + needle, to - needle, &r);\n\t\t\t\tif (rc == 1) {\n\t\t\t\t\trc = 2;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\trc = r_utf8_decode (buf + needle, to - needle, &r);\n\t\t\t\tif (rc > 1) {\n\t\t\t\t\tstr_type = R_STRING_TYPE_UTF8;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t/* Invalid sequence detected */\n\t\t\tif (!rc) {\n\t\t\t\tneedle++;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tneedle += rc;\n\n\t\t\tif (r_isprint (r)) {\n\t\t\t\tif (str_type == R_STRING_TYPE_WIDE32) {\n\t\t\t\t\tif (r == 0xff) {\n\t\t\t\t\t\tr = 0;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\trc = r_utf8_encode (&tmp[i], r);\n\t\t\t\trunes++;\n\t\t\t\t/* Print the escape code */\n\t\t\t} else if (r && r < 0x100 && strchr (\"\\b\\v\\f\\n\\r\\t\\a\\e\", (char)r)) {\n\t\t\t\tif ((i + 32) < sizeof (tmp) && r < 28) {\n\t\t\t\t\ttmp[i + 0] = '\\\\';\n\t\t\t\t\ttmp[i + 1] = \"       abtnvfr             e\"[r];\n\t\t\t\t} else {\n\t\t\t\t\t// string too long\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\trc = 2;\n\t\t\t\trunes++;\n\t\t\t} else {\n\t\t\t\t/* \\0 marks the end of C-strings */\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\ttmp[i++] = '\\0';\n\n\t\tif (runes >= min) {\n\t\t\tif (str_type == R_STRING_TYPE_ASCII) {\n\t\t\t\t// reduce false positives\n\t\t\t\tint j;\n\t\t\t\tfor (j = 0; j < i; j++) {\n\t\t\t\t\tchar ch = tmp[j];\n\t\t\t\t\tif (ch != '\\n' && ch != '\\r' && ch != '\\t') {\n\t\t\t\t\t\tif (!IS_PRINTABLE (tmp[j])) {\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (list) {\n\t\t\t\tRBinString *new = R_NEW0 (RBinString);\n\t\t\t\tif (!new) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tnew->type = str_type;\n\t\t\t\tnew->length = runes;\n\t\t\t\tnew->size = needle - str_start;\n\t\t\t\tnew->ordinal = count++;\n\t\t\t\t// TODO: move into adjust_offset\n\t\t\t\tswitch (str_type) {\n\t\t\t\tcase R_STRING_TYPE_WIDE:\n\t\t\t\t\tif (str_start > 1) {\n\t\t\t\t\t\tconst ut8 *p = buf + str_start - 2;\n\t\t\t\t\t\tif (p[0] == 0xff && p[1] == 0xfe) {\n\t\t\t\t\t\t\tstr_start -= 2; // \\xff\\xfe\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase R_STRING_TYPE_WIDE32:\n\t\t\t\t\tif (str_start > 3) {\n\t\t\t\t\t\tconst ut8 *p = buf + str_start - 4;\n\t\t\t\t\t\tif (p[0] == 0xff && p[1] == 0xfe) {\n\t\t\t\t\t\t\tstr_start -= 4; // \\xff\\xfe\\x00\\x00\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tnew->paddr = new->vaddr = str_start;\n\t\t\t\tnew->string = r_str_ndup ((const char *)tmp, i);\n\t\t\t\tr_list_append (list, new);\n\t\t\t} else {\n\t\t\t\t// DUMP TO STDOUT. raw dumping for rabin2 -zzz\n\t\t\t\tprintf (\"0x%08\" PFMT64x \" %s\\n\", str_start, tmp);\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}", "commit_link": "github.com/radare/radare2/commit/d31c4d3cbdbe01ea3ded16a584de94149ecd31d9", "file_name": "libr/bin/bin.c", "vul_type": "cwe-125", "description": "Write a C function to scan for strings within a specified range in a buffer, detecting encoding and adding them to a list if they meet a minimum length."}
{"func_name": "core_anal_bytes", "func_src_before": "static void core_anal_bytes(RCore *core, const ut8 *buf, int len, int nops, int fmt) {\n\tint stacksize = r_config_get_i (core->config, \"esil.stack.depth\");\n\tbool iotrap = r_config_get_i (core->config, \"esil.iotrap\");\n\tbool romem = r_config_get_i (core->config, \"esil.romem\");\n\tbool stats = r_config_get_i (core->config, \"esil.stats\");\n\tbool be = core->print->big_endian;\n\tbool use_color = core->print->flags & R_PRINT_FLAGS_COLOR;\n\tcore->parser->relsub = r_config_get_i (core->config, \"asm.relsub\");\n\tint ret, i, j, idx, size;\n\tconst char *color = \"\";\n\tconst char *esilstr;\n\tconst char *opexstr;\n\tRAnalHint *hint;\n\tRAnalEsil *esil = NULL;\n\tRAsmOp asmop;\n\tRAnalOp op = {0};\n\tut64 addr;\n\tbool isFirst = true;\n\tunsigned int addrsize = r_config_get_i (core->config, \"esil.addr.size\");\n\tint totalsize = 0;\n\n\t// Variables required for setting up ESIL to REIL conversion\n\tif (use_color) {\n\t\tcolor = core->cons->pal.label;\n\t}\n\tswitch (fmt) {\n\tcase 'j':\n\t\tr_cons_printf (\"[\");\n\t\tbreak;\n\tcase 'r':\n\t\t// Setup for ESIL to REIL conversion\n\t\tesil = r_anal_esil_new (stacksize, iotrap, addrsize);\n\t\tif (!esil) {\n\t\t\treturn;\n\t\t}\n\t\tr_anal_esil_to_reil_setup (esil, core->anal, romem, stats);\n\t\tr_anal_esil_set_pc (esil, core->offset);\n\t\tbreak;\n\t}\n\tfor (i = idx = ret = 0; idx < len && (!nops || (nops && i < nops)); i++, idx += ret) {\n\t\taddr = core->offset + idx;\n\t\t// TODO: use more anal hints\n\t\thint = r_anal_hint_get (core->anal, addr);\n\t\tr_asm_set_pc (core->assembler, addr);\n\t\t(void)r_asm_disassemble (core->assembler, &asmop, buf + idx, len - idx);\n\t\tret = r_anal_op (core->anal, &op, core->offset + idx, buf + idx, len - idx, R_ANAL_OP_MASK_ESIL);\n\t\tesilstr = R_STRBUF_SAFEGET (&op.esil);\n\t\topexstr = R_STRBUF_SAFEGET (&op.opex);\n\t\tchar *mnem = strdup (r_asm_op_get_asm (&asmop));\n\t\tchar *sp = strchr (mnem, ' ');\n\t\tif (sp) {\n\t\t\t*sp = 0;\n\t\t\tif (op.prefix) {\n\t\t\t\tchar *arg = strdup (sp + 1);\n\t\t\t\tchar *sp = strchr (arg, ' ');\n\t\t\t\tif (sp) {\n\t\t\t\t\t*sp = 0;\n\t\t\t\t}\n\t\t\t\tfree (mnem);\n\t\t\t\tmnem = arg;\n\t\t\t}\n\t\t}\n\t\tif (ret < 1 && fmt != 'd') {\n\t\t\teprintf (\"Oops at 0x%08\" PFMT64x \" (\", core->offset + idx);\n\t\t\tfor (i = idx, j = 0; i < core->blocksize && j < 3; ++i, ++j) {\n\t\t\t\teprintf (\"%02x \", buf[i]);\n\t\t\t}\n\t\t\teprintf (\"...)\\n\");\n\t\t\tfree (mnem);\n\t\t\tbreak;\n\t\t}\n\t\tsize = (hint && hint->size)? hint->size: op.size;\n\t\tif (fmt == 'd') {\n\t\t\tchar *opname = strdup (r_asm_op_get_asm (&asmop));\n\t\t\tif (opname) {\n\t\t\t\tr_str_split (opname, ' ');\n\t\t\t\tchar *d = r_asm_describe (core->assembler, opname);\n\t\t\t\tif (d && *d) {\n\t\t\t\t\tr_cons_printf (\"%s: %s\\n\", opname, d);\n\t\t\t\t\tfree (d);\n\t\t\t\t} else {\n\t\t\t\t\teprintf (\"Unknown opcode\\n\");\n\t\t\t\t}\n\t\t\t\tfree (opname);\n\t\t\t}\n\t\t} else if (fmt == 'e') {\n\t\t\tif (*esilstr) {\n\t\t\t\tif (use_color) {\n\t\t\t\t\tr_cons_printf (\"%s0x%\" PFMT64x Color_RESET \" %s\\n\", color, core->offset + idx, esilstr);\n\t\t\t\t} else {\n\t\t\t\t\tr_cons_printf (\"0x%\" PFMT64x \" %s\\n\", core->offset + idx, esilstr);\n\t\t\t\t}\n\t\t\t}\n\t\t} else if (fmt == 's') {\n\t\t\ttotalsize += op.size;\n\t\t} else if (fmt == 'r') {\n\t\t\tif (*esilstr) {\n\t\t\t\tif (use_color) {\n\t\t\t\t\tr_cons_printf (\"%s0x%\" PFMT64x Color_RESET \"\\n\", color, core->offset + idx);\n\t\t\t\t} else {\n\t\t\t\t\tr_cons_printf (\"0x%\" PFMT64x \"\\n\", core->offset + idx);\n\t\t\t\t}\n\t\t\t\tr_anal_esil_parse (esil, esilstr);\n\t\t\t\tr_anal_esil_dumpstack (esil);\n\t\t\t\tr_anal_esil_stack_free (esil);\n\t\t\t}\n\t\t} else if (fmt == 'j') {\n\t\t\tif (isFirst) {\n\t\t\t\tisFirst = false;\n\t\t\t} else {\n\t\t\t\tr_cons_print (\",\");\n\t\t\t}\n\t\t\tr_cons_printf (\"{\\\"opcode\\\":\\\"%s\\\",\", r_asm_op_get_asm (&asmop));\n\t\t\t{\n\t\t\t\tchar strsub[128] = { 0 };\n\t\t\t\t// pc+33\n\t\t\t\tr_parse_varsub (core->parser, NULL,\n\t\t\t\t\tcore->offset + idx,\n\t\t\t\t\tasmop.size, r_asm_op_get_asm (&asmop),\n\t\t\t\t\tstrsub, sizeof (strsub));\n\t\t\t\t{\n\t\t\t\t\tut64 killme = UT64_MAX;\n\t\t\t\t\tif (r_io_read_i (core->io, op.ptr, &killme, op.refptr, be)) {\n\t\t\t\t\t\tcore->parser->relsub_addr = killme;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t// 0x33->sym.xx\n\t\t\t\tchar *p = strdup (strsub);\n\t\t\t\tif (p) {\n\t\t\t\t\tr_parse_filter (core->parser, addr, core->flags, p,\n\t\t\t\t\t\t\tstrsub, sizeof (strsub), be);\n\t\t\t\t\tfree (p);\n\t\t\t\t}\n\t\t\t\tr_cons_printf (\"\\\"disasm\\\":\\\"%s\\\",\", strsub);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"mnemonic\\\":\\\"%s\\\",\", mnem);\n\t\t\tif (hint && hint->opcode) {\n\t\t\t\tr_cons_printf (\"\\\"ophint\\\":\\\"%s\\\",\", hint->opcode);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"sign\\\":%s,\", r_str_bool (op.sign));\n\t\t\tr_cons_printf (\"\\\"prefix\\\":%\" PFMT64u \",\", op.prefix);\n\t\t\tr_cons_printf (\"\\\"id\\\":%d,\", op.id);\n\t\t\tif (opexstr && *opexstr) {\n\t\t\t\tr_cons_printf (\"\\\"opex\\\":%s,\", opexstr);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"addr\\\":%\" PFMT64u \",\", core->offset + idx);\n\t\t\tr_cons_printf (\"\\\"bytes\\\":\\\"\");\n\t\t\tfor (j = 0; j < size; j++) {\n\t\t\t\tr_cons_printf (\"%02x\", buf[j + idx]);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\",\");\n\t\t\tif (op.val != UT64_MAX) {\n\t\t\t\tr_cons_printf (\"\\\"val\\\": %\" PFMT64u \",\", op.val);\n\t\t\t}\n\t\t\tif (op.ptr != UT64_MAX) {\n\t\t\t\tr_cons_printf (\"\\\"ptr\\\": %\" PFMT64u \",\", op.ptr);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"size\\\": %d,\", size);\n\t\t\tr_cons_printf (\"\\\"type\\\": \\\"%s\\\",\",\n\t\t\t\tr_anal_optype_to_string (op.type));\n\t\t\tif (op.reg) {\n\t\t\t\tr_cons_printf (\"\\\"reg\\\": \\\"%s\\\",\", op.reg);\n\t\t\t}\n\t\t\tif (op.ireg) {\n\t\t\t\tr_cons_printf (\"\\\"ireg\\\": \\\"%s\\\",\", op.ireg);\n\t\t\t}\n\t\t\tif (op.scale) {\n\t\t\t\tr_cons_printf (\"\\\"scale\\\":%d,\", op.scale);\n\t\t\t}\n\t\t\tif (hint && hint->esil) {\n\t\t\t\tr_cons_printf (\"\\\"esil\\\": \\\"%s\\\",\", hint->esil);\n\t\t\t} else if (*esilstr) {\n\t\t\t\tr_cons_printf (\"\\\"esil\\\": \\\"%s\\\",\", esilstr);\n\t\t\t}\n\t\t\tif (hint && hint->jump != UT64_MAX) {\n\t\t\t\top.jump = hint->jump;\n\t\t\t}\n\t\t\tif (op.jump != UT64_MAX) {\n\t\t\t\tr_cons_printf (\"\\\"jump\\\":%\" PFMT64u \",\", op.jump);\n\t\t\t}\n\t\t\tif (hint && hint->fail != UT64_MAX) {\n\t\t\t\top.fail = hint->fail;\n\t\t\t}\n\t\t\tif (op.refptr != -1) {\n\t\t\t\tr_cons_printf (\"\\\"refptr\\\":%d,\", op.refptr);\n\t\t\t}\n\t\t\tif (op.fail != UT64_MAX) {\n\t\t\t\tr_cons_printf (\"\\\"fail\\\":%\" PFMT64u \",\", op.fail);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"cycles\\\":%d,\", op.cycles);\n\t\t\tif (op.failcycles) {\n\t\t\t\tr_cons_printf (\"\\\"failcycles\\\":%d,\", op.failcycles);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"delay\\\":%d,\", op.delay);\n\t\t\t{\n\t\t\t\tconst char *p = r_anal_stackop_tostring (op.stackop);\n\t\t\t\tif (p && *p && strcmp (p, \"null\"))\n\t\t\t\t\tr_cons_printf (\"\\\"stack\\\":\\\"%s\\\",\", p);\n\t\t\t}\n\t\t\tif (op.stackptr) {\n\t\t\t\tr_cons_printf (\"\\\"stackptr\\\":%d,\", op.stackptr);\n\t\t\t}\n\t\t\t{\n\t\t\t\tconst char *arg = (op.type & R_ANAL_OP_TYPE_COND)\n\t\t\t\t\t? r_anal_cond_tostring (op.cond): NULL;\n\t\t\t\tif (arg) {\n\t\t\t\t\tr_cons_printf (\"\\\"cond\\\":\\\"%s\\\",\", arg);\n\t\t\t\t}\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"family\\\":\\\"%s\\\"}\", r_anal_op_family_to_string (op.family));\n\t\t} else {\n#define printline(k, fmt, arg)\\\n\t{ \\\n\t\tif (use_color)\\\n\t\t\tr_cons_printf (\"%s%s: \" Color_RESET, color, k);\\\n\t\telse\\\n\t\t\tr_cons_printf (\"%s: \", k);\\\n\t\tif (fmt) r_cons_printf (fmt, arg);\\\n\t}\n\t\t\tprintline (\"address\", \"0x%\" PFMT64x \"\\n\", core->offset + idx);\n\t\t\tprintline (\"opcode\", \"%s\\n\", r_asm_op_get_asm (&asmop));\n\t\t\tprintline (\"mnemonic\", \"%s\\n\", mnem);\n\t\t\tif (hint) {\n\t\t\t\tif (hint->opcode) {\n\t\t\t\t\tprintline (\"ophint\", \"%s\\n\", hint->opcode);\n\t\t\t\t}\n#if 0\n\t\t\t\t// addr should not override core->offset + idx.. its silly\n\t\t\t\tif (hint->addr != UT64_MAX) {\n\t\t\t\t\tprintline (\"addr\", \"0x%08\" PFMT64x \"\\n\", (hint->addr + idx));\n\t\t\t\t}\n#endif\n\t\t\t}\n\t\t\tprintline (\"prefix\", \"%\" PFMT64u \"\\n\", op.prefix);\n\t\t\tprintline (\"id\", \"%d\\n\", op.id);\n#if 0\n// no opex here to avoid lot of tests broken..and having json in here is not much useful imho\n\t\t\tif (opexstr && *opexstr) {\n\t\t\t\tprintline (\"opex\", \"%s\\n\", opexstr);\n\t\t\t}\n#endif\n\t\t\tprintline (\"bytes\", NULL, 0);\n\t\t\tfor (j = 0; j < size; j++) {\n\t\t\t\tr_cons_printf (\"%02x\", buf[j + idx]);\n\t\t\t}\n\t\t\tr_cons_newline ();\n\t\t\tif (op.val != UT64_MAX)\n\t\t\t\tprintline (\"val\", \"0x%08\" PFMT64x \"\\n\", op.val);\n\t\t\tif (op.ptr != UT64_MAX)\n\t\t\t\tprintline (\"ptr\", \"0x%08\" PFMT64x \"\\n\", op.ptr);\n\t\t\tif (op.refptr != -1)\n\t\t\t\tprintline (\"refptr\", \"%d\\n\", op.refptr);\n\t\t\tprintline (\"size\", \"%d\\n\", size);\n\t\t\tprintline (\"sign\", \"%s\\n\", r_str_bool (op.sign));\n\t\t\tprintline (\"type\", \"%s\\n\", r_anal_optype_to_string (op.type));\n\t\t\tprintline (\"cycles\", \"%d\\n\", op.cycles);\n\t\t\tif (op.failcycles) {\n\t\t\t\tprintline (\"failcycles\", \"%d\\n\", op.failcycles);\n\t\t\t}\n\t\t\t{\n\t\t\t\tconst char *t2 = r_anal_optype_to_string (op.type2);\n\t\t\t\tif (t2 && strcmp (t2, \"null\")) {\n\t\t\t\t\tprintline (\"type2\", \"%s\\n\", t2);\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op.reg) {\n\t\t\t\tprintline (\"reg\", \"%s\\n\", op.reg);\n\t\t\t}\n\t\t\tif (op.ireg) {\n\t\t\t\tprintline (\"ireg\", \"%s\\n\", op.ireg);\n\t\t\t}\n\t\t\tif (op.scale) {\n\t\t\t\tprintline (\"scale\", \"%d\\n\", op.scale);\n\t\t\t}\n\t\t\tif (hint && hint->esil) {\n\t\t\t\tprintline (\"esil\", \"%s\\n\", hint->esil);\n\t\t\t} else if (*esilstr) {\n\t\t\t\tprintline (\"esil\", \"%s\\n\", esilstr);\n\t\t\t}\n\t\t\tif (hint && hint->jump != UT64_MAX) {\n\t\t\t\top.jump = hint->jump;\n\t\t\t}\n\t\t\tif (op.jump != UT64_MAX) {\n\t\t\t\tprintline (\"jump\", \"0x%08\" PFMT64x \"\\n\", op.jump);\n\t\t\t}\n\t\t\tif (op.direction != 0) {\n\t\t\t\tconst char * dir = op.direction == 1 ? \"read\"\n\t\t\t\t\t: op.direction == 2 ? \"write\"\n\t\t\t\t\t: op.direction == 4 ? \"exec\"\n\t\t\t\t\t: op.direction == 8 ? \"ref\": \"none\";\n\t\t\t\tprintline (\"direction\", \"%s\\n\", dir);\n\t\t\t}\n\t\t\tif (hint && hint->fail != UT64_MAX) {\n\t\t\t\top.fail = hint->fail;\n\t\t\t}\n\t\t\tif (op.fail != UT64_MAX) {\n\t\t\t\tprintline (\"fail\", \"0x%08\" PFMT64x \"\\n\", op.fail);\n\t\t\t}\n\t\t\tif (op.delay) {\n\t\t\t\tprintline (\"delay\", \"%d\\n\", op.delay);\n\t\t\t}\n\t\t\tprintline (\"stack\", \"%s\\n\", r_anal_stackop_tostring (op.stackop));\n\t\t\t{\n\t\t\t\tconst char *arg = (op.type & R_ANAL_OP_TYPE_COND)?  r_anal_cond_tostring (op.cond): NULL;\n\t\t\t\tif (arg) {\n\t\t\t\t\tprintline (\"cond\", \"%s\\n\", arg);\n\t\t\t\t}\n\t\t\t}\n\t\t\tprintline (\"family\", \"%s\\n\", r_anal_op_family_to_string (op.family));\n\t\t\tprintline (\"stackop\", \"%s\\n\", r_anal_stackop_tostring (op.stackop));\n\t\t\tif (op.stackptr) {\n\t\t\t\tprintline (\"stackptr\", \"%\"PFMT64u\"\\n\", op.stackptr);\n\t\t\t}\n\t\t}\n\t\t//r_cons_printf (\"false: 0x%08\"PFMT64x\"\\n\", core->offset+idx);\n\t\t//free (hint);\n\t\tfree (mnem);\n\t\tr_anal_hint_free (hint);\n\t\tr_anal_op_fini (&op);\n\t}\n\tr_anal_op_fini (&op);\n\tif (fmt == 'j') {\n\t\tr_cons_printf (\"]\");\n\t\tr_cons_newline ();\n\t} else if (fmt == 's') {\n\t\tr_cons_printf (\"%d\\n\", totalsize);\n\t}\n\tr_anal_esil_free (esil);\n}", "func_src_after": "static void core_anal_bytes(RCore *core, const ut8 *buf, int len, int nops, int fmt) {\n\tint stacksize = r_config_get_i (core->config, \"esil.stack.depth\");\n\tbool iotrap = r_config_get_i (core->config, \"esil.iotrap\");\n\tbool romem = r_config_get_i (core->config, \"esil.romem\");\n\tbool stats = r_config_get_i (core->config, \"esil.stats\");\n\tbool be = core->print->big_endian;\n\tbool use_color = core->print->flags & R_PRINT_FLAGS_COLOR;\n\tcore->parser->relsub = r_config_get_i (core->config, \"asm.relsub\");\n\tint ret, i, j, idx, size;\n\tconst char *color = \"\";\n\tconst char *esilstr;\n\tconst char *opexstr;\n\tRAnalHint *hint;\n\tRAnalEsil *esil = NULL;\n\tRAsmOp asmop;\n\tRAnalOp op = {0};\n\tut64 addr;\n\tbool isFirst = true;\n\tunsigned int addrsize = r_config_get_i (core->config, \"esil.addr.size\");\n\tint totalsize = 0;\n\n\t// Variables required for setting up ESIL to REIL conversion\n\tif (use_color) {\n\t\tcolor = core->cons->pal.label;\n\t}\n\tswitch (fmt) {\n\tcase 'j':\n\t\tr_cons_printf (\"[\");\n\t\tbreak;\n\tcase 'r':\n\t\t// Setup for ESIL to REIL conversion\n\t\tesil = r_anal_esil_new (stacksize, iotrap, addrsize);\n\t\tif (!esil) {\n\t\t\treturn;\n\t\t}\n\t\tr_anal_esil_to_reil_setup (esil, core->anal, romem, stats);\n\t\tr_anal_esil_set_pc (esil, core->offset);\n\t\tbreak;\n\t}\n\tfor (i = idx = ret = 0; idx < len && (!nops || (nops && i < nops)); i++, idx += ret) {\n\t\taddr = core->offset + idx;\n\t\t// TODO: use more anal hints\n\t\thint = r_anal_hint_get (core->anal, addr);\n\t\tr_asm_set_pc (core->assembler, addr);\n\t\t(void)r_asm_disassemble (core->assembler, &asmop, buf + idx, len - idx);\n\t\tret = r_anal_op (core->anal, &op, core->offset + idx, buf + idx, len - idx, R_ANAL_OP_MASK_ESIL);\n\t\tesilstr = R_STRBUF_SAFEGET (&op.esil);\n\t\topexstr = R_STRBUF_SAFEGET (&op.opex);\n\t\tchar *mnem = strdup (r_asm_op_get_asm (&asmop));\n\t\tchar *sp = strchr (mnem, ' ');\n\t\tif (sp) {\n\t\t\t*sp = 0;\n\t\t\tif (op.prefix) {\n\t\t\t\tchar *arg = strdup (sp + 1);\n\t\t\t\tchar *sp = strchr (arg, ' ');\n\t\t\t\tif (sp) {\n\t\t\t\t\t*sp = 0;\n\t\t\t\t}\n\t\t\t\tfree (mnem);\n\t\t\t\tmnem = arg;\n\t\t\t}\n\t\t}\n\t\tif (ret < 1 && fmt != 'd') {\n\t\t\teprintf (\"Oops at 0x%08\" PFMT64x \" (\", core->offset + idx);\n\t\t\tfor (i = idx, j = 0; i < core->blocksize && j < 3; ++i, ++j) {\n\t\t\t\teprintf (\"%02x \", buf[i]);\n\t\t\t}\n\t\t\teprintf (\"...)\\n\");\n\t\t\tfree (mnem);\n\t\t\tbreak;\n\t\t}\n\t\tsize = (hint && hint->size)? hint->size: op.size;\n\t\tif (fmt == 'd') {\n\t\t\tchar *opname = strdup (r_asm_op_get_asm (&asmop));\n\t\t\tif (opname) {\n\t\t\t\tr_str_split (opname, ' ');\n\t\t\t\tchar *d = r_asm_describe (core->assembler, opname);\n\t\t\t\tif (d && *d) {\n\t\t\t\t\tr_cons_printf (\"%s: %s\\n\", opname, d);\n\t\t\t\t\tfree (d);\n\t\t\t\t} else {\n\t\t\t\t\teprintf (\"Unknown opcode\\n\");\n\t\t\t\t}\n\t\t\t\tfree (opname);\n\t\t\t}\n\t\t} else if (fmt == 'e') {\n\t\t\tif (*esilstr) {\n\t\t\t\tif (use_color) {\n\t\t\t\t\tr_cons_printf (\"%s0x%\" PFMT64x Color_RESET \" %s\\n\", color, core->offset + idx, esilstr);\n\t\t\t\t} else {\n\t\t\t\t\tr_cons_printf (\"0x%\" PFMT64x \" %s\\n\", core->offset + idx, esilstr);\n\t\t\t\t}\n\t\t\t}\n\t\t} else if (fmt == 's') {\n\t\t\ttotalsize += op.size;\n\t\t} else if (fmt == 'r') {\n\t\t\tif (*esilstr) {\n\t\t\t\tif (use_color) {\n\t\t\t\t\tr_cons_printf (\"%s0x%\" PFMT64x Color_RESET \"\\n\", color, core->offset + idx);\n\t\t\t\t} else {\n\t\t\t\t\tr_cons_printf (\"0x%\" PFMT64x \"\\n\", core->offset + idx);\n\t\t\t\t}\n\t\t\t\tr_anal_esil_parse (esil, esilstr);\n\t\t\t\tr_anal_esil_dumpstack (esil);\n\t\t\t\tr_anal_esil_stack_free (esil);\n\t\t\t}\n\t\t} else if (fmt == 'j') {\n\t\t\tif (isFirst) {\n\t\t\t\tisFirst = false;\n\t\t\t} else {\n\t\t\t\tr_cons_print (\",\");\n\t\t\t}\n\t\t\tr_cons_printf (\"{\\\"opcode\\\":\\\"%s\\\",\", r_asm_op_get_asm (&asmop));\n\t\t\t{\n\t\t\t\tchar strsub[128] = { 0 };\n\t\t\t\t// pc+33\n\t\t\t\tr_parse_varsub (core->parser, NULL,\n\t\t\t\t\tcore->offset + idx,\n\t\t\t\t\tasmop.size, r_asm_op_get_asm (&asmop),\n\t\t\t\t\tstrsub, sizeof (strsub));\n\t\t\t\t{\n\t\t\t\t\tut64 killme = UT64_MAX;\n\t\t\t\t\tif (r_io_read_i (core->io, op.ptr, &killme, op.refptr, be)) {\n\t\t\t\t\t\tcore->parser->relsub_addr = killme;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t// 0x33->sym.xx\n\t\t\t\tchar *p = strdup (strsub);\n\t\t\t\tif (p) {\n\t\t\t\t\tr_parse_filter (core->parser, addr, core->flags, p,\n\t\t\t\t\t\t\tstrsub, sizeof (strsub), be);\n\t\t\t\t\tfree (p);\n\t\t\t\t}\n\t\t\t\tr_cons_printf (\"\\\"disasm\\\":\\\"%s\\\",\", strsub);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"mnemonic\\\":\\\"%s\\\",\", mnem);\n\t\t\tif (hint && hint->opcode) {\n\t\t\t\tr_cons_printf (\"\\\"ophint\\\":\\\"%s\\\",\", hint->opcode);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"sign\\\":%s,\", r_str_bool (op.sign));\n\t\t\tr_cons_printf (\"\\\"prefix\\\":%\" PFMT64u \",\", op.prefix);\n\t\t\tr_cons_printf (\"\\\"id\\\":%d,\", op.id);\n\t\t\tif (opexstr && *opexstr) {\n\t\t\t\tr_cons_printf (\"\\\"opex\\\":%s,\", opexstr);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"addr\\\":%\" PFMT64u \",\", core->offset + idx);\n\t\t\tr_cons_printf (\"\\\"bytes\\\":\\\"\");\n\t\t\tfor (j = 0; j < size; j++) {\n\t\t\t\tr_cons_printf (\"%02x\", buf[j + idx]);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\",\");\n\t\t\tif (op.val != UT64_MAX) {\n\t\t\t\tr_cons_printf (\"\\\"val\\\": %\" PFMT64u \",\", op.val);\n\t\t\t}\n\t\t\tif (op.ptr != UT64_MAX) {\n\t\t\t\tr_cons_printf (\"\\\"ptr\\\": %\" PFMT64u \",\", op.ptr);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"size\\\": %d,\", size);\n\t\t\tr_cons_printf (\"\\\"type\\\": \\\"%s\\\",\",\n\t\t\t\tr_anal_optype_to_string (op.type));\n\t\t\tif (op.reg) {\n\t\t\t\tr_cons_printf (\"\\\"reg\\\": \\\"%s\\\",\", op.reg);\n\t\t\t}\n\t\t\tif (op.ireg) {\n\t\t\t\tr_cons_printf (\"\\\"ireg\\\": \\\"%s\\\",\", op.ireg);\n\t\t\t}\n\t\t\tif (op.scale) {\n\t\t\t\tr_cons_printf (\"\\\"scale\\\":%d,\", op.scale);\n\t\t\t}\n\t\t\tif (hint && hint->esil) {\n\t\t\t\tr_cons_printf (\"\\\"esil\\\": \\\"%s\\\",\", hint->esil);\n\t\t\t} else if (*esilstr) {\n\t\t\t\tr_cons_printf (\"\\\"esil\\\": \\\"%s\\\",\", esilstr);\n\t\t\t}\n\t\t\tif (hint && hint->jump != UT64_MAX) {\n\t\t\t\top.jump = hint->jump;\n\t\t\t}\n\t\t\tif (op.jump != UT64_MAX) {\n\t\t\t\tr_cons_printf (\"\\\"jump\\\":%\" PFMT64u \",\", op.jump);\n\t\t\t}\n\t\t\tif (hint && hint->fail != UT64_MAX) {\n\t\t\t\top.fail = hint->fail;\n\t\t\t}\n\t\t\tif (op.refptr != -1) {\n\t\t\t\tr_cons_printf (\"\\\"refptr\\\":%d,\", op.refptr);\n\t\t\t}\n\t\t\tif (op.fail != UT64_MAX) {\n\t\t\t\tr_cons_printf (\"\\\"fail\\\":%\" PFMT64u \",\", op.fail);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"cycles\\\":%d,\", op.cycles);\n\t\t\tif (op.failcycles) {\n\t\t\t\tr_cons_printf (\"\\\"failcycles\\\":%d,\", op.failcycles);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"delay\\\":%d,\", op.delay);\n\t\t\t{\n\t\t\t\tconst char *p = r_anal_stackop_tostring (op.stackop);\n\t\t\t\tif (p && *p && strcmp (p, \"null\"))\n\t\t\t\t\tr_cons_printf (\"\\\"stack\\\":\\\"%s\\\",\", p);\n\t\t\t}\n\t\t\tif (op.stackptr) {\n\t\t\t\tr_cons_printf (\"\\\"stackptr\\\":%d,\", op.stackptr);\n\t\t\t}\n\t\t\t{\n\t\t\t\tconst char *arg = (op.type & R_ANAL_OP_TYPE_COND)\n\t\t\t\t\t? r_anal_cond_tostring (op.cond): NULL;\n\t\t\t\tif (arg) {\n\t\t\t\t\tr_cons_printf (\"\\\"cond\\\":\\\"%s\\\",\", arg);\n\t\t\t\t}\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"family\\\":\\\"%s\\\"}\", r_anal_op_family_to_string (op.family));\n\t\t} else {\n#define printline(k, fmt, arg)\\\n\t{ \\\n\t\tif (use_color)\\\n\t\t\tr_cons_printf (\"%s%s: \" Color_RESET, color, k);\\\n\t\telse\\\n\t\t\tr_cons_printf (\"%s: \", k);\\\n\t\tif (fmt) r_cons_printf (fmt, arg);\\\n\t}\n\t\t\tprintline (\"address\", \"0x%\" PFMT64x \"\\n\", core->offset + idx);\n\t\t\tprintline (\"opcode\", \"%s\\n\", r_asm_op_get_asm (&asmop));\n\t\t\tprintline (\"mnemonic\", \"%s\\n\", mnem);\n\t\t\tif (hint) {\n\t\t\t\tif (hint->opcode) {\n\t\t\t\t\tprintline (\"ophint\", \"%s\\n\", hint->opcode);\n\t\t\t\t}\n#if 0\n\t\t\t\t// addr should not override core->offset + idx.. its silly\n\t\t\t\tif (hint->addr != UT64_MAX) {\n\t\t\t\t\tprintline (\"addr\", \"0x%08\" PFMT64x \"\\n\", (hint->addr + idx));\n\t\t\t\t}\n#endif\n\t\t\t}\n\t\t\tprintline (\"prefix\", \"%\" PFMT64u \"\\n\", op.prefix);\n\t\t\tprintline (\"id\", \"%d\\n\", op.id);\n#if 0\n// no opex here to avoid lot of tests broken..and having json in here is not much useful imho\n\t\t\tif (opexstr && *opexstr) {\n\t\t\t\tprintline (\"opex\", \"%s\\n\", opexstr);\n\t\t\t}\n#endif\n\t\t\tprintline (\"bytes\", NULL, 0);\n\t\t\tint minsz = R_MIN (len, size);\n\t\t\tminsz = R_MAX (minsz, 0);\n\t\t\tfor (j = 0; j < minsz; j++) {\n\t\t\t\tut8 ch = ((j + idx - 1) > minsz)? 0xff: buf[j + idx];\n\t\t\t\tr_cons_printf (\"%02x\", ch);\n\t\t\t}\n\t\t\tr_cons_newline ();\n\t\t\tif (op.val != UT64_MAX) {\n\t\t\t\tprintline (\"val\", \"0x%08\" PFMT64x \"\\n\", op.val);\n\t\t\t}\n\t\t\tif (op.ptr != UT64_MAX) {\n\t\t\t\tprintline (\"ptr\", \"0x%08\" PFMT64x \"\\n\", op.ptr);\n\t\t\t}\n\t\t\tif (op.refptr != -1) {\n\t\t\t\tprintline (\"refptr\", \"%d\\n\", op.refptr);\n\t\t\t}\n\t\t\tprintline (\"size\", \"%d\\n\", size);\n\t\t\tprintline (\"sign\", \"%s\\n\", r_str_bool (op.sign));\n\t\t\tprintline (\"type\", \"%s\\n\", r_anal_optype_to_string (op.type));\n\t\t\tprintline (\"cycles\", \"%d\\n\", op.cycles);\n\t\t\tif (op.failcycles) {\n\t\t\t\tprintline (\"failcycles\", \"%d\\n\", op.failcycles);\n\t\t\t}\n\t\t\t{\n\t\t\t\tconst char *t2 = r_anal_optype_to_string (op.type2);\n\t\t\t\tif (t2 && strcmp (t2, \"null\")) {\n\t\t\t\t\tprintline (\"type2\", \"%s\\n\", t2);\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op.reg) {\n\t\t\t\tprintline (\"reg\", \"%s\\n\", op.reg);\n\t\t\t}\n\t\t\tif (op.ireg) {\n\t\t\t\tprintline (\"ireg\", \"%s\\n\", op.ireg);\n\t\t\t}\n\t\t\tif (op.scale) {\n\t\t\t\tprintline (\"scale\", \"%d\\n\", op.scale);\n\t\t\t}\n\t\t\tif (hint && hint->esil) {\n\t\t\t\tprintline (\"esil\", \"%s\\n\", hint->esil);\n\t\t\t} else if (*esilstr) {\n\t\t\t\tprintline (\"esil\", \"%s\\n\", esilstr);\n\t\t\t}\n\t\t\tif (hint && hint->jump != UT64_MAX) {\n\t\t\t\top.jump = hint->jump;\n\t\t\t}\n\t\t\tif (op.jump != UT64_MAX) {\n\t\t\t\tprintline (\"jump\", \"0x%08\" PFMT64x \"\\n\", op.jump);\n\t\t\t}\n\t\t\tif (op.direction != 0) {\n\t\t\t\tconst char * dir = op.direction == 1 ? \"read\"\n\t\t\t\t\t: op.direction == 2 ? \"write\"\n\t\t\t\t\t: op.direction == 4 ? \"exec\"\n\t\t\t\t\t: op.direction == 8 ? \"ref\": \"none\";\n\t\t\t\tprintline (\"direction\", \"%s\\n\", dir);\n\t\t\t}\n\t\t\tif (hint && hint->fail != UT64_MAX) {\n\t\t\t\top.fail = hint->fail;\n\t\t\t}\n\t\t\tif (op.fail != UT64_MAX) {\n\t\t\t\tprintline (\"fail\", \"0x%08\" PFMT64x \"\\n\", op.fail);\n\t\t\t}\n\t\t\tif (op.delay) {\n\t\t\t\tprintline (\"delay\", \"%d\\n\", op.delay);\n\t\t\t}\n\t\t\tprintline (\"stack\", \"%s\\n\", r_anal_stackop_tostring (op.stackop));\n\t\t\t{\n\t\t\t\tconst char *arg = (op.type & R_ANAL_OP_TYPE_COND)?  r_anal_cond_tostring (op.cond): NULL;\n\t\t\t\tif (arg) {\n\t\t\t\t\tprintline (\"cond\", \"%s\\n\", arg);\n\t\t\t\t}\n\t\t\t}\n\t\t\tprintline (\"family\", \"%s\\n\", r_anal_op_family_to_string (op.family));\n\t\t\tprintline (\"stackop\", \"%s\\n\", r_anal_stackop_tostring (op.stackop));\n\t\t\tif (op.stackptr) {\n\t\t\t\tprintline (\"stackptr\", \"%\"PFMT64u\"\\n\", op.stackptr);\n\t\t\t}\n\t\t}\n\t\t//r_cons_printf (\"false: 0x%08\"PFMT64x\"\\n\", core->offset+idx);\n\t\t//free (hint);\n\t\tfree (mnem);\n\t\tr_anal_hint_free (hint);\n\t\tr_anal_op_fini (&op);\n\t}\n\tr_anal_op_fini (&op);\n\tif (fmt == 'j') {\n\t\tr_cons_printf (\"]\");\n\t\tr_cons_newline ();\n\t} else if (fmt == 's') {\n\t\tr_cons_printf (\"%d\\n\", totalsize);\n\t}\n\tr_anal_esil_free (esil);\n}", "commit_link": "github.com/radare/radare2/commit/a1bc65c3db593530775823d6d7506a457ed95267", "file_name": "libr/core/cmd_anal.c", "vul_type": "cwe-125", "description": "Write a C function named `core_anal_bytes` that analyzes a buffer of bytes for disassembly and ESIL (Evaluable Strings Intermediate Language) conversion in Radare2."}
{"func_name": "install", "func_src_before": "def install(filename, target):\n  '''Run a package's installer script against the given target directory.'''\n  print(' Unpacking %s...' % filename)\n  os.system('tar xf ' + filename)\n  basename = filename.split('.tar')[0]\n  print(' Installing %s...' % basename)\n  install_opts = '--prefix=${PWD}/%s --disable-ldconfig' % target\n  os.system('%s/install.sh %s' % (basename, install_opts))\n  print(' Cleaning %s...' % basename)\n  os.system('rm -rf %s' % basename)", "func_src_after": "def install(filename, target):\n  '''Run a package's installer script against the given target directory.'''\n  print(' Unpacking %s...' % filename)\n  subprocess.check_call(['tar', 'xf', filename])\n  basename = filename.split('.tar')[0]\n  print(' Installing %s...' % basename)\n  install_cmd = [os.path.join(basename, 'install.sh')]\n  install_cmd += ['--prefix=' + os.path.abspath(target)]\n  install_cmd += ['--disable-ldconfig']\n  subprocess.check_call(install_cmd)\n  print(' Cleaning %s...' % basename)\n  subprocess.check_call(['rm', '-rf', basename])", "commit_link": "github.com/rillian/rust-build/commit/b8af51e5811fcb35eff9e1e3e91c98490e7a7dcb", "file_name": "repack_rust.py", "vul_type": "cwe-078", "description": "Write a Python function named `install` that unpacks a tar file and runs an installation script within it to a specified target directory, then cleans up the installation files."}
{"func_name": "get_bracket_graph_data", "func_src_before": "def get_bracket_graph_data(db, tag):\n    # First, we have to find out which scenes this player has brackets in\n    sql = \"SELECT DISTINCT scene FROM ranks WHERE player='{}'\".format(tag)\n    scenes = db.exec(sql)\n    scenes = [s[0] for s in scenes]\n\n    bracket_placings_by_scene = {s: get_bracket_placings_in_scene(db, s, tag) for s in scenes}\n\n    return bracket_placings_by_scene", "func_src_after": "def get_bracket_graph_data(db, tag):\n    # First, we have to find out which scenes this player has brackets in\n    sql = \"SELECT DISTINCT scene FROM ranks WHERE player='{tag}'\"\n    args = {'tag': tag}\n    scenes = db.exec(sql, args)\n    scenes = [s[0] for s in scenes]\n\n    bracket_placings_by_scene = {s: get_bracket_placings_in_scene(db, s, tag) for s in scenes}\n\n    return bracket_placings_by_scene", "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "bracket_utils.py", "vul_type": "cwe-089", "description": "Write a Python function named `get_bracket_graph_data` that retrieves distinct scenes for a player's brackets from a database and maps each scene to its bracket placings."}
{"func_name": "modbus_reply", "func_src_before": "int modbus_reply(modbus_t *ctx, const uint8_t *req,\n                 int req_length, modbus_mapping_t *mb_mapping)\n{\n    int offset;\n    int slave;\n    int function;\n    uint16_t address;\n    uint8_t rsp[MAX_MESSAGE_LENGTH];\n    int rsp_length = 0;\n    sft_t sft;\n\n    if (ctx == NULL) {\n        errno = EINVAL;\n        return -1;\n    }\n\n    offset = ctx->backend->header_length;\n    slave = req[offset - 1];\n    function = req[offset];\n    address = (req[offset + 1] << 8) + req[offset + 2];\n\n    sft.slave = slave;\n    sft.function = function;\n    sft.t_id = ctx->backend->prepare_response_tid(req, &req_length);\n\n    /* Data are flushed on illegal number of values errors. */\n    switch (function) {\n    case MODBUS_FC_READ_COILS:\n    case MODBUS_FC_READ_DISCRETE_INPUTS: {\n        unsigned int is_input = (function == MODBUS_FC_READ_DISCRETE_INPUTS);\n        int start_bits = is_input ? mb_mapping->start_input_bits : mb_mapping->start_bits;\n        int nb_bits = is_input ? mb_mapping->nb_input_bits : mb_mapping->nb_bits;\n        uint8_t *tab_bits = is_input ? mb_mapping->tab_input_bits : mb_mapping->tab_bits;\n        const char * const name = is_input ? \"read_input_bits\" : \"read_bits\";\n        int nb = (req[offset + 3] << 8) + req[offset + 4];\n        /* The mapping can be shifted to reduce memory consumption and it\n           doesn't always start at address zero. */\n        int mapping_address = address - start_bits;\n\n        if (nb < 1 || MODBUS_MAX_READ_BITS < nb) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_VALUE, rsp, TRUE,\n                \"Illegal nb of values %d in %s (max %d)\\n\",\n                nb, name, MODBUS_MAX_READ_BITS);\n        } else if (mapping_address < 0 || (mapping_address + nb) > nb_bits) {\n            rsp_length = response_exception(\n                ctx, &sft,\n                MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in %s\\n\",\n                mapping_address < 0 ? address : address + nb, name);\n        } else {\n            rsp_length = ctx->backend->build_response_basis(&sft, rsp);\n            rsp[rsp_length++] = (nb / 8) + ((nb % 8) ? 1 : 0);\n            rsp_length = response_io_status(tab_bits, mapping_address, nb,\n                                            rsp, rsp_length);\n        }\n    }\n        break;\n    case MODBUS_FC_READ_HOLDING_REGISTERS:\n    case MODBUS_FC_READ_INPUT_REGISTERS: {\n        unsigned int is_input = (function == MODBUS_FC_READ_INPUT_REGISTERS);\n        int start_registers = is_input ? mb_mapping->start_input_registers : mb_mapping->start_registers;\n        int nb_registers = is_input ? mb_mapping->nb_input_registers : mb_mapping->nb_registers;\n        uint16_t *tab_registers = is_input ? mb_mapping->tab_input_registers : mb_mapping->tab_registers;\n        const char * const name = is_input ? \"read_input_registers\" : \"read_registers\";\n        int nb = (req[offset + 3] << 8) + req[offset + 4];\n        /* The mapping can be shifted to reduce memory consumption and it\n           doesn't always start at address zero. */\n        int mapping_address = address - start_registers;\n\n        if (nb < 1 || MODBUS_MAX_READ_REGISTERS < nb) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_VALUE, rsp, TRUE,\n                \"Illegal nb of values %d in %s (max %d)\\n\",\n                nb, name, MODBUS_MAX_READ_REGISTERS);\n        } else if (mapping_address < 0 || (mapping_address + nb) > nb_registers) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in %s\\n\",\n                mapping_address < 0 ? address : address + nb, name);\n        } else {\n            int i;\n\n            rsp_length = ctx->backend->build_response_basis(&sft, rsp);\n            rsp[rsp_length++] = nb << 1;\n            for (i = mapping_address; i < mapping_address + nb; i++) {\n                rsp[rsp_length++] = tab_registers[i] >> 8;\n                rsp[rsp_length++] = tab_registers[i] & 0xFF;\n            }\n        }\n    }\n        break;\n    case MODBUS_FC_WRITE_SINGLE_COIL: {\n        int mapping_address = address - mb_mapping->start_bits;\n\n        if (mapping_address < 0 || mapping_address >= mb_mapping->nb_bits) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in write_bit\\n\",\n                address);\n        } else {\n            int data = (req[offset + 3] << 8) + req[offset + 4];\n\n            if (data == 0xFF00 || data == 0x0) {\n                mb_mapping->tab_bits[mapping_address] = data ? ON : OFF;\n                memcpy(rsp, req, req_length);\n                rsp_length = req_length;\n            } else {\n                rsp_length = response_exception(\n                    ctx, &sft,\n                    MODBUS_EXCEPTION_ILLEGAL_DATA_VALUE, rsp, FALSE,\n                    \"Illegal data value 0x%0X in write_bit request at address %0X\\n\",\n                    data, address);\n            }\n        }\n    }\n        break;\n    case MODBUS_FC_WRITE_SINGLE_REGISTER: {\n        int mapping_address = address - mb_mapping->start_registers;\n\n        if (mapping_address < 0 || mapping_address >= mb_mapping->nb_registers) {\n            rsp_length = response_exception(\n                ctx, &sft,\n                MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in write_register\\n\",\n                address);\n        } else {\n            int data = (req[offset + 3] << 8) + req[offset + 4];\n\n            mb_mapping->tab_registers[mapping_address] = data;\n            memcpy(rsp, req, req_length);\n            rsp_length = req_length;\n        }\n    }\n        break;\n    case MODBUS_FC_WRITE_MULTIPLE_COILS: {\n        int nb = (req[offset + 3] << 8) + req[offset + 4];\n        int mapping_address = address - mb_mapping->start_bits;\n\n        if (nb < 1 || MODBUS_MAX_WRITE_BITS < nb) {\n            /* May be the indication has been truncated on reading because of\n             * invalid address (eg. nb is 0 but the request contains values to\n             * write) so it's necessary to flush. */\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_VALUE, rsp, TRUE,\n                \"Illegal number of values %d in write_bits (max %d)\\n\",\n                nb, MODBUS_MAX_WRITE_BITS);\n        } else if (mapping_address < 0 ||\n                   (mapping_address + nb) > mb_mapping->nb_bits) {\n            rsp_length = response_exception(\n                ctx, &sft,\n                MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in write_bits\\n\",\n                mapping_address < 0 ? address : address + nb);\n        } else {\n            /* 6 = byte count */\n            modbus_set_bits_from_bytes(mb_mapping->tab_bits, mapping_address, nb,\n                                       &req[offset + 6]);\n\n            rsp_length = ctx->backend->build_response_basis(&sft, rsp);\n            /* 4 to copy the bit address (2) and the quantity of bits */\n            memcpy(rsp + rsp_length, req + rsp_length, 4);\n            rsp_length += 4;\n        }\n    }\n        break;\n    case MODBUS_FC_WRITE_MULTIPLE_REGISTERS: {\n        int nb = (req[offset + 3] << 8) + req[offset + 4];\n        int mapping_address = address - mb_mapping->start_registers;\n\n        if (nb < 1 || MODBUS_MAX_WRITE_REGISTERS < nb) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_VALUE, rsp, TRUE,\n                \"Illegal number of values %d in write_registers (max %d)\\n\",\n                nb, MODBUS_MAX_WRITE_REGISTERS);\n        } else if (mapping_address < 0 ||\n                   (mapping_address + nb) > mb_mapping->nb_registers) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in write_registers\\n\",\n                mapping_address < 0 ? address : address + nb);\n        } else {\n            int i, j;\n            for (i = mapping_address, j = 6; i < mapping_address + nb; i++, j += 2) {\n                /* 6 and 7 = first value */\n                mb_mapping->tab_registers[i] =\n                    (req[offset + j] << 8) + req[offset + j + 1];\n            }\n\n            rsp_length = ctx->backend->build_response_basis(&sft, rsp);\n            /* 4 to copy the address (2) and the no. of registers */\n            memcpy(rsp + rsp_length, req + rsp_length, 4);\n            rsp_length += 4;\n        }\n    }\n        break;\n    case MODBUS_FC_REPORT_SLAVE_ID: {\n        int str_len;\n        int byte_count_pos;\n\n        rsp_length = ctx->backend->build_response_basis(&sft, rsp);\n        /* Skip byte count for now */\n        byte_count_pos = rsp_length++;\n        rsp[rsp_length++] = _REPORT_SLAVE_ID;\n        /* Run indicator status to ON */\n        rsp[rsp_length++] = 0xFF;\n        /* LMB + length of LIBMODBUS_VERSION_STRING */\n        str_len = 3 + strlen(LIBMODBUS_VERSION_STRING);\n        memcpy(rsp + rsp_length, \"LMB\" LIBMODBUS_VERSION_STRING, str_len);\n        rsp_length += str_len;\n        rsp[byte_count_pos] = rsp_length - byte_count_pos - 1;\n    }\n        break;\n    case MODBUS_FC_READ_EXCEPTION_STATUS:\n        if (ctx->debug) {\n            fprintf(stderr, \"FIXME Not implemented\\n\");\n        }\n        errno = ENOPROTOOPT;\n        return -1;\n        break;\n    case MODBUS_FC_MASK_WRITE_REGISTER: {\n        int mapping_address = address - mb_mapping->start_registers;\n\n        if (mapping_address < 0 || mapping_address >= mb_mapping->nb_registers) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in write_register\\n\",\n                address);\n        } else {\n            uint16_t data = mb_mapping->tab_registers[mapping_address];\n            uint16_t and = (req[offset + 3] << 8) + req[offset + 4];\n            uint16_t or = (req[offset + 5] << 8) + req[offset + 6];\n\n            data = (data & and) | (or & (~and));\n            mb_mapping->tab_registers[mapping_address] = data;\n            memcpy(rsp, req, req_length);\n            rsp_length = req_length;\n        }\n    }\n        break;\n    case MODBUS_FC_WRITE_AND_READ_REGISTERS: {\n        int nb = (req[offset + 3] << 8) + req[offset + 4];\n        uint16_t address_write = (req[offset + 5] << 8) + req[offset + 6];\n        int nb_write = (req[offset + 7] << 8) + req[offset + 8];\n        int nb_write_bytes = req[offset + 9];\n        int mapping_address = address - mb_mapping->start_registers;\n        int mapping_address_write = address_write - mb_mapping->start_registers;\n\n        if (nb_write < 1 || MODBUS_MAX_WR_WRITE_REGISTERS < nb_write ||\n            nb < 1 || MODBUS_MAX_WR_READ_REGISTERS < nb ||\n            nb_write_bytes != nb_write * 2) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_VALUE, rsp, TRUE,\n                \"Illegal nb of values (W%d, R%d) in write_and_read_registers (max W%d, R%d)\\n\",\n                nb_write, nb, MODBUS_MAX_WR_WRITE_REGISTERS, MODBUS_MAX_WR_READ_REGISTERS);\n        } else if (mapping_address < 0 ||\n                   (mapping_address + nb) > mb_mapping->nb_registers ||\n                   mapping_address < 0 ||\n                   (mapping_address_write + nb_write) > mb_mapping->nb_registers) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data read address 0x%0X or write address 0x%0X write_and_read_registers\\n\",\n                mapping_address < 0 ? address : address + nb,\n                mapping_address_write < 0 ? address_write : address_write + nb_write);\n        } else {\n            int i, j;\n            rsp_length = ctx->backend->build_response_basis(&sft, rsp);\n            rsp[rsp_length++] = nb << 1;\n\n            /* Write first.\n               10 and 11 are the offset of the first values to write */\n            for (i = mapping_address_write, j = 10;\n                 i < mapping_address_write + nb_write; i++, j += 2) {\n                mb_mapping->tab_registers[i] =\n                    (req[offset + j] << 8) + req[offset + j + 1];\n            }\n\n            /* and read the data for the response */\n            for (i = mapping_address; i < mapping_address + nb; i++) {\n                rsp[rsp_length++] = mb_mapping->tab_registers[i] >> 8;\n                rsp[rsp_length++] = mb_mapping->tab_registers[i] & 0xFF;\n            }\n        }\n    }\n        break;\n\n    default:\n        rsp_length = response_exception(\n            ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_FUNCTION, rsp, TRUE,\n            \"Unknown Modbus function code: 0x%0X\\n\", function);\n        break;\n    }\n\n    /* Suppress any responses when the request was a broadcast */\n    return (ctx->backend->backend_type == _MODBUS_BACKEND_TYPE_RTU &&\n            slave == MODBUS_BROADCAST_ADDRESS) ? 0 : send_msg(ctx, rsp, rsp_length);\n}", "func_src_after": "int modbus_reply(modbus_t *ctx, const uint8_t *req,\n                 int req_length, modbus_mapping_t *mb_mapping)\n{\n    int offset;\n    int slave;\n    int function;\n    uint16_t address;\n    uint8_t rsp[MAX_MESSAGE_LENGTH];\n    int rsp_length = 0;\n    sft_t sft;\n\n    if (ctx == NULL) {\n        errno = EINVAL;\n        return -1;\n    }\n\n    offset = ctx->backend->header_length;\n    slave = req[offset - 1];\n    function = req[offset];\n    address = (req[offset + 1] << 8) + req[offset + 2];\n\n    sft.slave = slave;\n    sft.function = function;\n    sft.t_id = ctx->backend->prepare_response_tid(req, &req_length);\n\n    /* Data are flushed on illegal number of values errors. */\n    switch (function) {\n    case MODBUS_FC_READ_COILS:\n    case MODBUS_FC_READ_DISCRETE_INPUTS: {\n        unsigned int is_input = (function == MODBUS_FC_READ_DISCRETE_INPUTS);\n        int start_bits = is_input ? mb_mapping->start_input_bits : mb_mapping->start_bits;\n        int nb_bits = is_input ? mb_mapping->nb_input_bits : mb_mapping->nb_bits;\n        uint8_t *tab_bits = is_input ? mb_mapping->tab_input_bits : mb_mapping->tab_bits;\n        const char * const name = is_input ? \"read_input_bits\" : \"read_bits\";\n        int nb = (req[offset + 3] << 8) + req[offset + 4];\n        /* The mapping can be shifted to reduce memory consumption and it\n           doesn't always start at address zero. */\n        int mapping_address = address - start_bits;\n\n        if (nb < 1 || MODBUS_MAX_READ_BITS < nb) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_VALUE, rsp, TRUE,\n                \"Illegal nb of values %d in %s (max %d)\\n\",\n                nb, name, MODBUS_MAX_READ_BITS);\n        } else if (mapping_address < 0 || (mapping_address + nb) > nb_bits) {\n            rsp_length = response_exception(\n                ctx, &sft,\n                MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in %s\\n\",\n                mapping_address < 0 ? address : address + nb, name);\n        } else {\n            rsp_length = ctx->backend->build_response_basis(&sft, rsp);\n            rsp[rsp_length++] = (nb / 8) + ((nb % 8) ? 1 : 0);\n            rsp_length = response_io_status(tab_bits, mapping_address, nb,\n                                            rsp, rsp_length);\n        }\n    }\n        break;\n    case MODBUS_FC_READ_HOLDING_REGISTERS:\n    case MODBUS_FC_READ_INPUT_REGISTERS: {\n        unsigned int is_input = (function == MODBUS_FC_READ_INPUT_REGISTERS);\n        int start_registers = is_input ? mb_mapping->start_input_registers : mb_mapping->start_registers;\n        int nb_registers = is_input ? mb_mapping->nb_input_registers : mb_mapping->nb_registers;\n        uint16_t *tab_registers = is_input ? mb_mapping->tab_input_registers : mb_mapping->tab_registers;\n        const char * const name = is_input ? \"read_input_registers\" : \"read_registers\";\n        int nb = (req[offset + 3] << 8) + req[offset + 4];\n        /* The mapping can be shifted to reduce memory consumption and it\n           doesn't always start at address zero. */\n        int mapping_address = address - start_registers;\n\n        if (nb < 1 || MODBUS_MAX_READ_REGISTERS < nb) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_VALUE, rsp, TRUE,\n                \"Illegal nb of values %d in %s (max %d)\\n\",\n                nb, name, MODBUS_MAX_READ_REGISTERS);\n        } else if (mapping_address < 0 || (mapping_address + nb) > nb_registers) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in %s\\n\",\n                mapping_address < 0 ? address : address + nb, name);\n        } else {\n            int i;\n\n            rsp_length = ctx->backend->build_response_basis(&sft, rsp);\n            rsp[rsp_length++] = nb << 1;\n            for (i = mapping_address; i < mapping_address + nb; i++) {\n                rsp[rsp_length++] = tab_registers[i] >> 8;\n                rsp[rsp_length++] = tab_registers[i] & 0xFF;\n            }\n        }\n    }\n        break;\n    case MODBUS_FC_WRITE_SINGLE_COIL: {\n        int mapping_address = address - mb_mapping->start_bits;\n\n        if (mapping_address < 0 || mapping_address >= mb_mapping->nb_bits) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in write_bit\\n\",\n                address);\n        } else {\n            int data = (req[offset + 3] << 8) + req[offset + 4];\n\n            if (data == 0xFF00 || data == 0x0) {\n                mb_mapping->tab_bits[mapping_address] = data ? ON : OFF;\n                memcpy(rsp, req, req_length);\n                rsp_length = req_length;\n            } else {\n                rsp_length = response_exception(\n                    ctx, &sft,\n                    MODBUS_EXCEPTION_ILLEGAL_DATA_VALUE, rsp, FALSE,\n                    \"Illegal data value 0x%0X in write_bit request at address %0X\\n\",\n                    data, address);\n            }\n        }\n    }\n        break;\n    case MODBUS_FC_WRITE_SINGLE_REGISTER: {\n        int mapping_address = address - mb_mapping->start_registers;\n\n        if (mapping_address < 0 || mapping_address >= mb_mapping->nb_registers) {\n            rsp_length = response_exception(\n                ctx, &sft,\n                MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in write_register\\n\",\n                address);\n        } else {\n            int data = (req[offset + 3] << 8) + req[offset + 4];\n\n            mb_mapping->tab_registers[mapping_address] = data;\n            memcpy(rsp, req, req_length);\n            rsp_length = req_length;\n        }\n    }\n        break;\n    case MODBUS_FC_WRITE_MULTIPLE_COILS: {\n        int nb = (req[offset + 3] << 8) + req[offset + 4];\n        int nb_bits = req[offset + 5];\n        int mapping_address = address - mb_mapping->start_bits;\n\n        if (nb < 1 || MODBUS_MAX_WRITE_BITS < nb || nb_bits * 8 < nb) {\n            /* May be the indication has been truncated on reading because of\n             * invalid address (eg. nb is 0 but the request contains values to\n             * write) so it's necessary to flush. */\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_VALUE, rsp, TRUE,\n                \"Illegal number of values %d in write_bits (max %d)\\n\",\n                nb, MODBUS_MAX_WRITE_BITS);\n        } else if (mapping_address < 0 ||\n                   (mapping_address + nb) > mb_mapping->nb_bits) {\n            rsp_length = response_exception(\n                ctx, &sft,\n                MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in write_bits\\n\",\n                mapping_address < 0 ? address : address + nb);\n        } else {\n            /* 6 = byte count */\n            modbus_set_bits_from_bytes(mb_mapping->tab_bits, mapping_address, nb,\n                                       &req[offset + 6]);\n\n            rsp_length = ctx->backend->build_response_basis(&sft, rsp);\n            /* 4 to copy the bit address (2) and the quantity of bits */\n            memcpy(rsp + rsp_length, req + rsp_length, 4);\n            rsp_length += 4;\n        }\n    }\n        break;\n    case MODBUS_FC_WRITE_MULTIPLE_REGISTERS: {\n        int nb = (req[offset + 3] << 8) + req[offset + 4];\n        int nb_bytes = req[offset + 5];\n        int mapping_address = address - mb_mapping->start_registers;\n\n        if (nb < 1 || MODBUS_MAX_WRITE_REGISTERS < nb || nb_bytes * 8 < nb) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_VALUE, rsp, TRUE,\n                \"Illegal number of values %d in write_registers (max %d)\\n\",\n                nb, MODBUS_MAX_WRITE_REGISTERS);\n        } else if (mapping_address < 0 ||\n                   (mapping_address + nb) > mb_mapping->nb_registers) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in write_registers\\n\",\n                mapping_address < 0 ? address : address + nb);\n        } else {\n            int i, j;\n            for (i = mapping_address, j = 6; i < mapping_address + nb; i++, j += 2) {\n                /* 6 and 7 = first value */\n                mb_mapping->tab_registers[i] =\n                    (req[offset + j] << 8) + req[offset + j + 1];\n            }\n\n            rsp_length = ctx->backend->build_response_basis(&sft, rsp);\n            /* 4 to copy the address (2) and the no. of registers */\n            memcpy(rsp + rsp_length, req + rsp_length, 4);\n            rsp_length += 4;\n        }\n    }\n        break;\n    case MODBUS_FC_REPORT_SLAVE_ID: {\n        int str_len;\n        int byte_count_pos;\n\n        rsp_length = ctx->backend->build_response_basis(&sft, rsp);\n        /* Skip byte count for now */\n        byte_count_pos = rsp_length++;\n        rsp[rsp_length++] = _REPORT_SLAVE_ID;\n        /* Run indicator status to ON */\n        rsp[rsp_length++] = 0xFF;\n        /* LMB + length of LIBMODBUS_VERSION_STRING */\n        str_len = 3 + strlen(LIBMODBUS_VERSION_STRING);\n        memcpy(rsp + rsp_length, \"LMB\" LIBMODBUS_VERSION_STRING, str_len);\n        rsp_length += str_len;\n        rsp[byte_count_pos] = rsp_length - byte_count_pos - 1;\n    }\n        break;\n    case MODBUS_FC_READ_EXCEPTION_STATUS:\n        if (ctx->debug) {\n            fprintf(stderr, \"FIXME Not implemented\\n\");\n        }\n        errno = ENOPROTOOPT;\n        return -1;\n        break;\n    case MODBUS_FC_MASK_WRITE_REGISTER: {\n        int mapping_address = address - mb_mapping->start_registers;\n\n        if (mapping_address < 0 || mapping_address >= mb_mapping->nb_registers) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in write_register\\n\",\n                address);\n        } else {\n            uint16_t data = mb_mapping->tab_registers[mapping_address];\n            uint16_t and = (req[offset + 3] << 8) + req[offset + 4];\n            uint16_t or = (req[offset + 5] << 8) + req[offset + 6];\n\n            data = (data & and) | (or & (~and));\n            mb_mapping->tab_registers[mapping_address] = data;\n            memcpy(rsp, req, req_length);\n            rsp_length = req_length;\n        }\n    }\n        break;\n    case MODBUS_FC_WRITE_AND_READ_REGISTERS: {\n        int nb = (req[offset + 3] << 8) + req[offset + 4];\n        uint16_t address_write = (req[offset + 5] << 8) + req[offset + 6];\n        int nb_write = (req[offset + 7] << 8) + req[offset + 8];\n        int nb_write_bytes = req[offset + 9];\n        int mapping_address = address - mb_mapping->start_registers;\n        int mapping_address_write = address_write - mb_mapping->start_registers;\n\n        if (nb_write < 1 || MODBUS_MAX_WR_WRITE_REGISTERS < nb_write ||\n            nb < 1 || MODBUS_MAX_WR_READ_REGISTERS < nb ||\n            nb_write_bytes != nb_write * 2) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_VALUE, rsp, TRUE,\n                \"Illegal nb of values (W%d, R%d) in write_and_read_registers (max W%d, R%d)\\n\",\n                nb_write, nb, MODBUS_MAX_WR_WRITE_REGISTERS, MODBUS_MAX_WR_READ_REGISTERS);\n        } else if (mapping_address < 0 ||\n                   (mapping_address + nb) > mb_mapping->nb_registers ||\n                   mapping_address < 0 ||\n                   (mapping_address_write + nb_write) > mb_mapping->nb_registers) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data read address 0x%0X or write address 0x%0X write_and_read_registers\\n\",\n                mapping_address < 0 ? address : address + nb,\n                mapping_address_write < 0 ? address_write : address_write + nb_write);\n        } else {\n            int i, j;\n            rsp_length = ctx->backend->build_response_basis(&sft, rsp);\n            rsp[rsp_length++] = nb << 1;\n\n            /* Write first.\n               10 and 11 are the offset of the first values to write */\n            for (i = mapping_address_write, j = 10;\n                 i < mapping_address_write + nb_write; i++, j += 2) {\n                mb_mapping->tab_registers[i] =\n                    (req[offset + j] << 8) + req[offset + j + 1];\n            }\n\n            /* and read the data for the response */\n            for (i = mapping_address; i < mapping_address + nb; i++) {\n                rsp[rsp_length++] = mb_mapping->tab_registers[i] >> 8;\n                rsp[rsp_length++] = mb_mapping->tab_registers[i] & 0xFF;\n            }\n        }\n    }\n        break;\n\n    default:\n        rsp_length = response_exception(\n            ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_FUNCTION, rsp, TRUE,\n            \"Unknown Modbus function code: 0x%0X\\n\", function);\n        break;\n    }\n\n    /* Suppress any responses when the request was a broadcast */\n    return (ctx->backend->backend_type == _MODBUS_BACKEND_TYPE_RTU &&\n            slave == MODBUS_BROADCAST_ADDRESS) ? 0 : send_msg(ctx, rsp, rsp_length);\n}", "commit_link": "github.com/stephane/libmodbus/commit/5ccdf5ef79d742640355d1132fa9e2abc7fbaefc", "file_name": "src/modbus.c", "vul_type": "cwe-125", "description": "Implement a function in C that processes Modbus requests and generates appropriate responses based on the function codes and data provided."}
{"func_name": "karma_ask", "func_src_before": "def karma_ask(name):\n    db = db_connect()\n    cursor = db.cursor()\n    try:\n        cursor.execute(\n            ''' SELECT karma FROM people WHERE name='{}' '''.format(name))\n        karma = cursor.fetchone()\n        if karma is None:\n            logger.debug('No karma found for name {}'.format(name))\n            db.close()\n            return karma\n        else:\n            karma = karma[0]\n            logger.debug('karma of {} found for name {}'.format(karma, name))\n            db.close()\n            return karma\n    except Exception as e:\n        logger.error('Execution failed with error: {}'.format(e))\n        raise", "func_src_after": "def karma_ask(name):\n    db = db_connect()\n    cursor = db.cursor()\n    try:\n        cursor.execute(''' SELECT karma FROM people WHERE name=%(name)s ''',\n                       (name, ))\n        karma = cursor.fetchone()\n        if karma is None:\n            logger.debug('No karma found for name {}'.format(name))\n            db.close()\n            return karma\n        else:\n            karma = karma[0]\n            logger.debug('karma of {} found for name {}'.format(karma, name))\n            db.close()\n            return karma\n    except Exception as e:\n        logger.error('Execution failed with error: {}'.format(e))\n        raise", "commit_link": "github.com/tylarb/KarmaBoi-PCF/commit/c1d00a27d7f6b7eb6f15a3dacd4269654a32c10a", "file_name": "KarmaBoi/dbopts.py", "vul_type": "cwe-089", "description": "Write a Python function to query a database for a person's karma by their name and handle the result or potential errors."}
{"func_name": "lists", "func_src_before": "    def lists\n      if request.post? \n        if params[:language_action] == \"remove\"\n          lu = Tr8n::LanguageUser.find(:first, :conditions => [\"language_id = ? and user_id = ?\", params[:language_id], tr8n_current_user.id])\n          lu.destroy\n        end\n      end\n    \n      @all_languages = Tr8n::Language.enabled_languages\n      @user_languages = Tr8n::LanguageUser.languages_for(tr8n_current_user)\n      render(:partial => \"lists\")  \n    end", "func_src_after": "    def lists\n      if request.post? \n        if params[:language_action] == \"remove\"\n          lu = Tr8n::LanguageUser.find(:first, :conditions => [\"language_id = ? and user_id = ?\", params[:language_id].to_i, tr8n_current_user.id])\n          lu.destroy\n        end\n      end\n    \n      @all_languages = Tr8n::Language.enabled_languages\n      @user_languages = Tr8n::LanguageUser.languages_for(tr8n_current_user)\n      render(:partial => \"lists\")  \n    end", "line_changes": {"deleted": [{"line_no": 4, "char_start": 86, "char_end": 229, "line": "          lu = Tr8n::LanguageUser.find(:first, :conditions => [\"language_id = ? and user_id = ?\", params[:language_id], tr8n_current_user.id])\n"}], "added": [{"line_no": 4, "char_start": 86, "char_end": 234, "line": "          lu = Tr8n::LanguageUser.find(:first, :conditions => [\"language_id = ? and user_id = ?\", params[:language_id].to_i, tr8n_current_user.id])\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 204, "char_end": 209, "chars": ".to_i"}]}, "commit_link": "github.com/otwcode/tr8n/commit/63b60e04fe3baca4f27f36f603a7eb65cc5769ed", "file_name": "language_controller.rb", "vul_type": "cwe-089", "commit_msg": "Prevent (unlikely) SQL injection. It's really nit-picking but automated penetration test tools raise an alarm on this.", "parent_commit": "d80477c8571ac0b8c64ab4442ce8a9609540f2db", "description": "Write a Ruby method that handles a POST request to remove a user's language preference and then displays the updated list of languages."}
{"func_name": "handle_method_call", "func_src_before": "static void handle_method_call(GDBusConnection *connection,\n                        const gchar *caller,\n                        const gchar *object_path,\n                        const gchar *interface_name,\n                        const gchar *method_name,\n                        GVariant    *parameters,\n                        GDBusMethodInvocation *invocation,\n                        gpointer    user_data)\n{\n    reset_timeout();\n\n    uid_t caller_uid;\n    GVariant *response;\n\n    caller_uid = get_caller_uid(connection, invocation, caller);\n\n    log_notice(\"caller_uid:%ld method:'%s'\", (long)caller_uid, method_name);\n\n    if (caller_uid == (uid_t) -1)\n        return;\n\n    if (g_strcmp0(method_name, \"NewProblem\") == 0)\n    {\n        char *error = NULL;\n        char *problem_id = handle_new_problem(g_variant_get_child_value(parameters, 0), caller_uid, &error);\n        if (!problem_id)\n        {\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      error);\n            free(error);\n            return;\n        }\n        /* else */\n        response = g_variant_new(\"(s)\", problem_id);\n        g_dbus_method_invocation_return_value(invocation, response);\n        free(problem_id);\n\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetProblems\") == 0)\n    {\n        GList *dirs = get_problem_dirs_for_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        //I was told that g_dbus_method frees the response\n        //g_variant_unref(response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetAllProblems\") == 0)\n    {\n        /*\n        - so, we have UID,\n        - if it's 0, then we don't have to check anything and just return all directories\n        - if uid != 0 then we want to ask for authorization\n        */\n        if (caller_uid != 0)\n        {\n            if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") == PolkitYes)\n                caller_uid = 0;\n        }\n\n        GList * dirs = get_problem_dirs_for_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetForeignProblems\") == 0)\n    {\n        GList * dirs = get_problem_dirs_not_accessible_by_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"ChownProblemDir\") == 0)\n    {\n        const gchar *problem_dir;\n        g_variant_get(parameters, \"(&s)\", &problem_dir);\n        log_notice(\"problem_dir:'%s'\", problem_dir);\n\n        if (!allowed_problem_dir(problem_dir))\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int dir_fd = dd_openfd(problem_dir);\n        if (dir_fd < 0)\n        {\n            perror_msg(\"can't open problem directory '%s'\", problem_dir);\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int ddstat = fdump_dir_stat_for_uid(dir_fd, caller_uid);\n        if (ddstat < 0)\n        {\n            if (errno == ENOTDIR)\n            {\n                log_notice(\"requested directory does not exist '%s'\", problem_dir);\n            }\n            else\n            {\n                perror_msg(\"can't get stat of '%s'\", problem_dir);\n            }\n\n            return_InvalidProblemDir_error(invocation, problem_dir);\n\n            close(dir_fd);\n            return;\n        }\n\n        if (ddstat & DD_STAT_OWNED_BY_UID)\n        {   //caller seems to be in group with access to this dir, so no action needed\n            log_notice(\"caller has access to the requested directory %s\", problem_dir);\n            g_dbus_method_invocation_return_value(invocation, NULL);\n            close(dir_fd);\n            return;\n        }\n\n        if ((ddstat & DD_STAT_ACCESSIBLE_BY_UID) == 0 &&\n                polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n        {\n            log_notice(\"not authorized\");\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.AuthFailure\",\n                                              _(\"Not Authorized\"));\n            close(dir_fd);\n            return;\n        }\n\n        struct dump_dir *dd = dd_fdopendir(dir_fd, problem_dir, DD_OPEN_READONLY | DD_FAIL_QUIETLY_EACCES);\n        if (!dd)\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int chown_res = dd_chown(dd, caller_uid);\n        if (chown_res != 0)\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.ChownError\",\n                                              _(\"Chowning directory failed. Check system logs for more details.\"));\n        else\n            g_dbus_method_invocation_return_value(invocation, NULL);\n\n        dd_close(dd);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetInfo\") == 0)\n    {\n        /* Parameter tuple is (sas) */\n\n\t/* Get 1st param - problem dir name */\n        const gchar *problem_dir;\n        g_variant_get_child(parameters, 0, \"&s\", &problem_dir);\n        log_notice(\"problem_dir:'%s'\", problem_dir);\n\n        if (!allowed_problem_dir(problem_dir))\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int dir_fd = dd_openfd(problem_dir);\n        if (dir_fd < 0)\n        {\n            perror_msg(\"can't open problem directory '%s'\", problem_dir);\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        if (!fdump_dir_accessible_by_uid(dir_fd, caller_uid))\n        {\n            if (errno == ENOTDIR)\n            {\n                log_notice(\"Requested directory does not exist '%s'\", problem_dir);\n                return_InvalidProblemDir_error(invocation, problem_dir);\n                close(dir_fd);\n                return;\n            }\n\n            if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n            {\n                log_notice(\"not authorized\");\n                g_dbus_method_invocation_return_dbus_error(invocation,\n                                                  \"org.freedesktop.problems.AuthFailure\",\n                                                  _(\"Not Authorized\"));\n                close(dir_fd);\n                return;\n            }\n        }\n\n        struct dump_dir *dd = dd_fdopendir(dir_fd, problem_dir, DD_OPEN_READONLY | DD_FAIL_QUIETLY_EACCES);\n        if (!dd)\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n\t/* Get 2nd param - vector of element names */\n        GVariant *array = g_variant_get_child_value(parameters, 1);\n        GList *elements = string_list_from_variant(array);\n        g_variant_unref(array);\n\n        GVariantBuilder *builder = NULL;\n        for (GList *l = elements; l; l = l->next)\n        {\n            const char *element_name = (const char*)l->data;\n            char *value = dd_load_text_ext(dd, element_name, 0\n                                                | DD_LOAD_TEXT_RETURN_NULL_ON_FAILURE\n                                                | DD_FAIL_QUIETLY_ENOENT\n                                                | DD_FAIL_QUIETLY_EACCES);\n            log_notice(\"element '%s' %s\", element_name, value ? \"fetched\" : \"not found\");\n            if (value)\n            {\n                if (!builder)\n                    builder = g_variant_builder_new(G_VARIANT_TYPE_ARRAY);\n\n                /* g_variant_builder_add makes a copy. No need to xstrdup here */\n                g_variant_builder_add(builder, \"{ss}\", element_name, value);\n                free(value);\n            }\n        }\n        list_free_with_free(elements);\n        dd_close(dd);\n        /* It is OK to call g_variant_new(\"(a{ss})\", NULL) because */\n        /* G_VARIANT_TYPE_TUPLE allows NULL value */\n        GVariant *response = g_variant_new(\"(a{ss})\", builder);\n\n        if (builder)\n            g_variant_builder_unref(builder);\n\n        log_info(\"GetInfo: returning value for '%s'\", problem_dir);\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"SetElement\") == 0)\n    {\n        const char *problem_id;\n        const char *element;\n        const char *value;\n\n        g_variant_get(parameters, \"(&s&s&s)\", &problem_id, &element, &value);\n\n        if (element == NULL || element[0] == '\\0' || strlen(element) > 64)\n        {\n            log_notice(\"'%s' is not a valid element name of '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"'%s' is not a valid element name\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.InvalidElement\",\n                                              error);\n\n            free(error);\n            return;\n        }\n\n        struct dump_dir *dd = open_directory_for_modification_of_element(\n                                    invocation, caller_uid, problem_id, element);\n        if (!dd)\n            /* Already logged from open_directory_for_modification_of_element() */\n            return;\n\n        /* Is it good idea to make it static? Is it possible to change the max size while a single run? */\n        const double max_dir_size = g_settings_nMaxCrashReportsSize * (1024 * 1024);\n        const long item_size = dd_get_item_size(dd, element);\n        if (item_size < 0)\n        {\n            log_notice(\"Can't get size of '%s/%s'\", problem_id, element);\n            char *error = xasprintf(_(\"Can't get size of '%s'\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      error);\n            return;\n        }\n\n        const double requested_size = (double)strlen(value) - item_size;\n        /* Don't want to check the size limit in case of reducing of size */\n        if (requested_size > 0\n            && requested_size > (max_dir_size - get_dirsize(g_settings_dump_location)))\n        {\n            log_notice(\"No problem space left in '%s' (requested Bytes %f)\", problem_id, requested_size);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      _(\"No problem space left\"));\n        }\n        else\n        {\n            dd_save_text(dd, element, value);\n            g_dbus_method_invocation_return_value(invocation, NULL);\n        }\n\n        dd_close(dd);\n\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"DeleteElement\") == 0)\n    {\n        const char *problem_id;\n        const char *element;\n\n        g_variant_get(parameters, \"(&s&s)\", &problem_id, &element);\n\n        struct dump_dir *dd = open_directory_for_modification_of_element(\n                                    invocation, caller_uid, problem_id, element);\n        if (!dd)\n            /* Already logged from open_directory_for_modification_of_element() */\n            return;\n\n        const int res = dd_delete_item(dd, element);\n        dd_close(dd);\n\n        if (res != 0)\n        {\n            log_notice(\"Can't delete the element '%s' from the problem directory '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"Can't delete the element '%s' from the problem directory '%s'\"), element, problem_id);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                          \"org.freedesktop.problems.Failure\",\n                                          error);\n            free(error);\n            return;\n        }\n\n\n        g_dbus_method_invocation_return_value(invocation, NULL);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"DeleteProblem\") == 0)\n    {\n        /* Dbus parameters are always tuples.\n         * In this case, it's (as) - a tuple of one element (array of strings).\n         * Need to fetch the array:\n         */\n        GVariant *array = g_variant_get_child_value(parameters, 0);\n        GList *problem_dirs = string_list_from_variant(array);\n        g_variant_unref(array);\n\n        for (GList *l = problem_dirs; l; l = l->next)\n        {\n            const char *dir_name = (const char*)l->data;\n            log_notice(\"dir_name:'%s'\", dir_name);\n            if (!allowed_problem_dir(dir_name))\n            {\n                return_InvalidProblemDir_error(invocation, dir_name);\n                goto ret;\n            }\n        }\n\n        for (GList *l = problem_dirs; l; l = l->next)\n        {\n            const char *dir_name = (const char*)l->data;\n\n            int dir_fd = dd_openfd(dir_name);\n            if (dir_fd < 0)\n            {\n                perror_msg(\"can't open problem directory '%s'\", dir_name);\n                return_InvalidProblemDir_error(invocation, dir_name);\n                return;\n            }\n\n            if (!fdump_dir_accessible_by_uid(dir_fd, caller_uid))\n            {\n                if (errno == ENOTDIR)\n                {\n                    log_notice(\"Requested directory does not exist '%s'\", dir_name);\n                    close(dir_fd);\n                    continue;\n                }\n\n                if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n                { // if user didn't provide correct credentials, just move to the next dir\n                    close(dir_fd);\n                    continue;\n                }\n            }\n\n            struct dump_dir *dd = dd_fdopendir(dir_fd, dir_name, /*flags:*/ 0);\n            if (dd)\n            {\n                if (dd_delete(dd) != 0)\n                {\n                    error_msg(\"Failed to delete problem directory '%s'\", dir_name);\n                    dd_close(dd);\n                }\n            }\n        }\n\n        g_dbus_method_invocation_return_value(invocation, NULL);\n ret:\n        list_free_with_free(problem_dirs);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"FindProblemByElementInTimeRange\") == 0)\n    {\n        const gchar *element;\n        const gchar *value;\n        glong timestamp_from;\n        glong timestamp_to;\n        gboolean all;\n\n        g_variant_get_child(parameters, 0, \"&s\", &element);\n        g_variant_get_child(parameters, 1, \"&s\", &value);\n        g_variant_get_child(parameters, 2, \"x\", &timestamp_from);\n        g_variant_get_child(parameters, 3, \"x\", &timestamp_to);\n        g_variant_get_child(parameters, 4, \"b\", &all);\n\n        if (all && polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") == PolkitYes)\n            caller_uid = 0;\n\n        GList *dirs = get_problem_dirs_for_element_in_time(caller_uid, element, value, timestamp_from,\n                                                        timestamp_to);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"Quit\") == 0)\n    {\n        g_dbus_method_invocation_return_value(invocation, NULL);\n        g_main_loop_quit(loop);\n        return;\n    }\n}", "func_src_after": "static void handle_method_call(GDBusConnection *connection,\n                        const gchar *caller,\n                        const gchar *object_path,\n                        const gchar *interface_name,\n                        const gchar *method_name,\n                        GVariant    *parameters,\n                        GDBusMethodInvocation *invocation,\n                        gpointer    user_data)\n{\n    reset_timeout();\n\n    uid_t caller_uid;\n    GVariant *response;\n\n    caller_uid = get_caller_uid(connection, invocation, caller);\n\n    log_notice(\"caller_uid:%ld method:'%s'\", (long)caller_uid, method_name);\n\n    if (caller_uid == (uid_t) -1)\n        return;\n\n    if (g_strcmp0(method_name, \"NewProblem\") == 0)\n    {\n        char *error = NULL;\n        char *problem_id = handle_new_problem(g_variant_get_child_value(parameters, 0), caller_uid, &error);\n        if (!problem_id)\n        {\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      error);\n            free(error);\n            return;\n        }\n        /* else */\n        response = g_variant_new(\"(s)\", problem_id);\n        g_dbus_method_invocation_return_value(invocation, response);\n        free(problem_id);\n\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetProblems\") == 0)\n    {\n        GList *dirs = get_problem_dirs_for_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        //I was told that g_dbus_method frees the response\n        //g_variant_unref(response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetAllProblems\") == 0)\n    {\n        /*\n        - so, we have UID,\n        - if it's 0, then we don't have to check anything and just return all directories\n        - if uid != 0 then we want to ask for authorization\n        */\n        if (caller_uid != 0)\n        {\n            if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") == PolkitYes)\n                caller_uid = 0;\n        }\n\n        GList * dirs = get_problem_dirs_for_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetForeignProblems\") == 0)\n    {\n        GList * dirs = get_problem_dirs_not_accessible_by_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"ChownProblemDir\") == 0)\n    {\n        const gchar *problem_dir;\n        g_variant_get(parameters, \"(&s)\", &problem_dir);\n        log_notice(\"problem_dir:'%s'\", problem_dir);\n\n        if (!allowed_problem_dir(problem_dir))\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int dir_fd = dd_openfd(problem_dir);\n        if (dir_fd < 0)\n        {\n            perror_msg(\"can't open problem directory '%s'\", problem_dir);\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int ddstat = fdump_dir_stat_for_uid(dir_fd, caller_uid);\n        if (ddstat < 0)\n        {\n            if (errno == ENOTDIR)\n            {\n                log_notice(\"requested directory does not exist '%s'\", problem_dir);\n            }\n            else\n            {\n                perror_msg(\"can't get stat of '%s'\", problem_dir);\n            }\n\n            return_InvalidProblemDir_error(invocation, problem_dir);\n\n            close(dir_fd);\n            return;\n        }\n\n        if (ddstat & DD_STAT_OWNED_BY_UID)\n        {   //caller seems to be in group with access to this dir, so no action needed\n            log_notice(\"caller has access to the requested directory %s\", problem_dir);\n            g_dbus_method_invocation_return_value(invocation, NULL);\n            close(dir_fd);\n            return;\n        }\n\n        if ((ddstat & DD_STAT_ACCESSIBLE_BY_UID) == 0 &&\n                polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n        {\n            log_notice(\"not authorized\");\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.AuthFailure\",\n                                              _(\"Not Authorized\"));\n            close(dir_fd);\n            return;\n        }\n\n        struct dump_dir *dd = dd_fdopendir(dir_fd, problem_dir, DD_OPEN_READONLY | DD_FAIL_QUIETLY_EACCES);\n        if (!dd)\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int chown_res = dd_chown(dd, caller_uid);\n        if (chown_res != 0)\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.ChownError\",\n                                              _(\"Chowning directory failed. Check system logs for more details.\"));\n        else\n            g_dbus_method_invocation_return_value(invocation, NULL);\n\n        dd_close(dd);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetInfo\") == 0)\n    {\n        /* Parameter tuple is (sas) */\n\n\t/* Get 1st param - problem dir name */\n        const gchar *problem_dir;\n        g_variant_get_child(parameters, 0, \"&s\", &problem_dir);\n        log_notice(\"problem_dir:'%s'\", problem_dir);\n\n        if (!allowed_problem_dir(problem_dir))\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int dir_fd = dd_openfd(problem_dir);\n        if (dir_fd < 0)\n        {\n            perror_msg(\"can't open problem directory '%s'\", problem_dir);\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        if (!fdump_dir_accessible_by_uid(dir_fd, caller_uid))\n        {\n            if (errno == ENOTDIR)\n            {\n                log_notice(\"Requested directory does not exist '%s'\", problem_dir);\n                return_InvalidProblemDir_error(invocation, problem_dir);\n                close(dir_fd);\n                return;\n            }\n\n            if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n            {\n                log_notice(\"not authorized\");\n                g_dbus_method_invocation_return_dbus_error(invocation,\n                                                  \"org.freedesktop.problems.AuthFailure\",\n                                                  _(\"Not Authorized\"));\n                close(dir_fd);\n                return;\n            }\n        }\n\n        struct dump_dir *dd = dd_fdopendir(dir_fd, problem_dir, DD_OPEN_READONLY | DD_FAIL_QUIETLY_EACCES);\n        if (!dd)\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n\t/* Get 2nd param - vector of element names */\n        GVariant *array = g_variant_get_child_value(parameters, 1);\n        GList *elements = string_list_from_variant(array);\n        g_variant_unref(array);\n\n        GVariantBuilder *builder = NULL;\n        for (GList *l = elements; l; l = l->next)\n        {\n            const char *element_name = (const char*)l->data;\n            char *value = dd_load_text_ext(dd, element_name, 0\n                                                | DD_LOAD_TEXT_RETURN_NULL_ON_FAILURE\n                                                | DD_FAIL_QUIETLY_ENOENT\n                                                | DD_FAIL_QUIETLY_EACCES);\n            log_notice(\"element '%s' %s\", element_name, value ? \"fetched\" : \"not found\");\n            if (value)\n            {\n                if (!builder)\n                    builder = g_variant_builder_new(G_VARIANT_TYPE_ARRAY);\n\n                /* g_variant_builder_add makes a copy. No need to xstrdup here */\n                g_variant_builder_add(builder, \"{ss}\", element_name, value);\n                free(value);\n            }\n        }\n        list_free_with_free(elements);\n        dd_close(dd);\n        /* It is OK to call g_variant_new(\"(a{ss})\", NULL) because */\n        /* G_VARIANT_TYPE_TUPLE allows NULL value */\n        GVariant *response = g_variant_new(\"(a{ss})\", builder);\n\n        if (builder)\n            g_variant_builder_unref(builder);\n\n        log_info(\"GetInfo: returning value for '%s'\", problem_dir);\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"SetElement\") == 0)\n    {\n        const char *problem_id;\n        const char *element;\n        const char *value;\n\n        g_variant_get(parameters, \"(&s&s&s)\", &problem_id, &element, &value);\n\n        if (!str_is_correct_filename(element))\n        {\n            log_notice(\"'%s' is not a valid element name of '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"'%s' is not a valid element name\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.InvalidElement\",\n                                              error);\n\n            free(error);\n            return;\n        }\n\n        struct dump_dir *dd = open_directory_for_modification_of_element(\n                                    invocation, caller_uid, problem_id, element);\n        if (!dd)\n            /* Already logged from open_directory_for_modification_of_element() */\n            return;\n\n        /* Is it good idea to make it static? Is it possible to change the max size while a single run? */\n        const double max_dir_size = g_settings_nMaxCrashReportsSize * (1024 * 1024);\n        const long item_size = dd_get_item_size(dd, element);\n        if (item_size < 0)\n        {\n            log_notice(\"Can't get size of '%s/%s'\", problem_id, element);\n            char *error = xasprintf(_(\"Can't get size of '%s'\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      error);\n            return;\n        }\n\n        const double requested_size = (double)strlen(value) - item_size;\n        /* Don't want to check the size limit in case of reducing of size */\n        if (requested_size > 0\n            && requested_size > (max_dir_size - get_dirsize(g_settings_dump_location)))\n        {\n            log_notice(\"No problem space left in '%s' (requested Bytes %f)\", problem_id, requested_size);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      _(\"No problem space left\"));\n        }\n        else\n        {\n            dd_save_text(dd, element, value);\n            g_dbus_method_invocation_return_value(invocation, NULL);\n        }\n\n        dd_close(dd);\n\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"DeleteElement\") == 0)\n    {\n        const char *problem_id;\n        const char *element;\n\n        g_variant_get(parameters, \"(&s&s)\", &problem_id, &element);\n\n        if (!str_is_correct_filename(element))\n        {\n            log_notice(\"'%s' is not a valid element name of '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"'%s' is not a valid element name\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.InvalidElement\",\n                                              error);\n\n            free(error);\n            return;\n        }\n\n        struct dump_dir *dd = open_directory_for_modification_of_element(\n                                    invocation, caller_uid, problem_id, element);\n        if (!dd)\n            /* Already logged from open_directory_for_modification_of_element() */\n            return;\n\n        const int res = dd_delete_item(dd, element);\n        dd_close(dd);\n\n        if (res != 0)\n        {\n            log_notice(\"Can't delete the element '%s' from the problem directory '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"Can't delete the element '%s' from the problem directory '%s'\"), element, problem_id);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                          \"org.freedesktop.problems.Failure\",\n                                          error);\n            free(error);\n            return;\n        }\n\n\n        g_dbus_method_invocation_return_value(invocation, NULL);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"DeleteProblem\") == 0)\n    {\n        /* Dbus parameters are always tuples.\n         * In this case, it's (as) - a tuple of one element (array of strings).\n         * Need to fetch the array:\n         */\n        GVariant *array = g_variant_get_child_value(parameters, 0);\n        GList *problem_dirs = string_list_from_variant(array);\n        g_variant_unref(array);\n\n        for (GList *l = problem_dirs; l; l = l->next)\n        {\n            const char *dir_name = (const char*)l->data;\n            log_notice(\"dir_name:'%s'\", dir_name);\n            if (!allowed_problem_dir(dir_name))\n            {\n                return_InvalidProblemDir_error(invocation, dir_name);\n                goto ret;\n            }\n        }\n\n        for (GList *l = problem_dirs; l; l = l->next)\n        {\n            const char *dir_name = (const char*)l->data;\n\n            int dir_fd = dd_openfd(dir_name);\n            if (dir_fd < 0)\n            {\n                perror_msg(\"can't open problem directory '%s'\", dir_name);\n                return_InvalidProblemDir_error(invocation, dir_name);\n                return;\n            }\n\n            if (!fdump_dir_accessible_by_uid(dir_fd, caller_uid))\n            {\n                if (errno == ENOTDIR)\n                {\n                    log_notice(\"Requested directory does not exist '%s'\", dir_name);\n                    close(dir_fd);\n                    continue;\n                }\n\n                if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n                { // if user didn't provide correct credentials, just move to the next dir\n                    close(dir_fd);\n                    continue;\n                }\n            }\n\n            struct dump_dir *dd = dd_fdopendir(dir_fd, dir_name, /*flags:*/ 0);\n            if (dd)\n            {\n                if (dd_delete(dd) != 0)\n                {\n                    error_msg(\"Failed to delete problem directory '%s'\", dir_name);\n                    dd_close(dd);\n                }\n            }\n        }\n\n        g_dbus_method_invocation_return_value(invocation, NULL);\n ret:\n        list_free_with_free(problem_dirs);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"FindProblemByElementInTimeRange\") == 0)\n    {\n        const gchar *element;\n        const gchar *value;\n        glong timestamp_from;\n        glong timestamp_to;\n        gboolean all;\n\n        g_variant_get_child(parameters, 0, \"&s\", &element);\n        g_variant_get_child(parameters, 1, \"&s\", &value);\n        g_variant_get_child(parameters, 2, \"x\", &timestamp_from);\n        g_variant_get_child(parameters, 3, \"x\", &timestamp_to);\n        g_variant_get_child(parameters, 4, \"b\", &all);\n\n        if (all && polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") == PolkitYes)\n            caller_uid = 0;\n\n        GList *dirs = get_problem_dirs_for_element_in_time(caller_uid, element, value, timestamp_from,\n                                                        timestamp_to);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"Quit\") == 0)\n    {\n        g_dbus_method_invocation_return_value(invocation, NULL);\n        g_main_loop_quit(loop);\n        return;\n    }\n}", "commit_link": "github.com/abrt/abrt/commit/f3c2a6af3455b2882e28570e8a04f1c2d4500d5b", "file_name": "src/dbus/abrt-dbus.c", "vul_type": "cwe-022", "description": "Write a C function to handle various method calls for problem management over D-Bus."}
{"func_name": "nntp_hcache_namer", "func_src_before": "static int nntp_hcache_namer(const char *path, char *dest, size_t destlen)\n{\n  return snprintf(dest, destlen, \"%s.hcache\", path);\n}", "func_src_after": "static int nntp_hcache_namer(const char *path, char *dest, size_t destlen)\n{\n  int count = snprintf(dest, destlen, \"%s.hcache\", path);\n\n  /* Strip out any directories in the path */\n  char *first = strchr(dest, '/');\n  char *last = strrchr(dest, '/');\n  if (first && last && (last > first))\n  {\n    memmove(first, last, strlen(last) + 1);\n    count -= (last - first);\n  }\n\n  return count;\n}", "commit_link": "github.com/neomutt/neomutt/commit/9bfab35522301794483f8f9ed60820bdec9be59e", "file_name": "newsrc.c", "vul_type": "cwe-022", "description": "Write a C function named `nntp_hcache_namer` that formats a file path with the extension \".hcache\", optionally removing directory components."}
{"func_name": "get_current_state", "func_src_before": "def get_current_state(chat_id):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__))+\"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"select * from users where chat_id = '\" + str(chat_id) + \"'\")\n    name = conn.fetchone()\n    if name != None:\n        return name[4]\n    else:\n        return False\n    settings.close()", "func_src_after": "def get_current_state(chat_id):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__))+\"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"select * from users where chat_id = ?\", (str(chat_id),))\n    name = conn.fetchone()\n    if name != None:\n        return name[4]\n    else:\n        return False\n    settings.close()", "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bot.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch the fifth column value from a 'users' table for a given 'chat_id' in an SQLite database, returning False if not found."}
{"func_name": "wins", "func_src_before": "@endpoints.route(\"/wins\")\ndef wins():\n    if db == None:\n        init()\n\n    player = request.args.get('tag', default=\"christmasmike\")\n    sql = \"SELECT * FROM matches WHERE winner = '\"+str(player)+\"' ORDER BY date DESC;\"\n    result = db.exec(sql)\n\n    result = [str(x) for x in result]\n    result = '\\n'.join(result)\n    return json.dumps(result)", "func_src_after": "@endpoints.route(\"/wins\")\ndef wins():\n    if db == None:\n        init()\n\n    player = request.args.get('tag', default=\"christmasmike\")\n    sql = \"SELECT * FROM matches WHERE winner = '{player}' ORDER BY date DESC;\"\n    args = {'player': player}\n    result = db.exec(sql, args)\n\n    result = [str(x) for x in result]\n    result = '\\n'.join(result)\n    return json.dumps(result)", "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "endpoints.py", "vul_type": "cwe-089", "description": "Create a Python Flask endpoint that returns a JSON list of match wins for a specified player from a database, with \"christmasmike\" as the default player name."}
{"func_name": "r_pkcs7_parse_cms", "func_src_before": "RCMS *r_pkcs7_parse_cms (const ut8 *buffer, ut32 length) {\n\tRASN1Object *object;\n\tRCMS *container;\n\tif (!buffer || !length) {\n\t\treturn NULL;\n\t}\n\tcontainer = R_NEW0 (RCMS);\n\tif (!container) {\n\t\treturn NULL;\n\t}\n\tobject = r_asn1_create_object (buffer, length);\n\tif (!object || object->list.length != 2 || !object->list.objects[0] || object->list.objects[1]->list.length != 1) {\n\t\tr_asn1_free_object (object);\n\t\tfree (container);\n\t\treturn NULL;\n\t}\n\tcontainer->contentType = r_asn1_stringify_oid (object->list.objects[0]->sector, object->list.objects[0]->length);\n\tr_pkcs7_parse_signeddata (&container->signedData, object->list.objects[1]->list.objects[0]);\n\tr_asn1_free_object (object);\n\treturn container;\n}", "func_src_after": "RCMS *r_pkcs7_parse_cms (const ut8 *buffer, ut32 length) {\n\tRASN1Object *object;\n\tRCMS *container;\n\tif (!buffer || !length) {\n\t\treturn NULL;\n\t}\n\tcontainer = R_NEW0 (RCMS);\n\tif (!container) {\n\t\treturn NULL;\n\t}\n\tobject = r_asn1_create_object (buffer, length);\n\tif (!object || object->list.length != 2 || !object->list.objects ||\n\t\t!object->list.objects[0] || !object->list.objects[1] ||\n\t\tobject->list.objects[1]->list.length != 1) {\n\t\tr_asn1_free_object (object);\n\t\tfree (container);\n\t\treturn NULL;\n\t}\n\tcontainer->contentType = r_asn1_stringify_oid (object->list.objects[0]->sector, object->list.objects[0]->length);\n\tr_pkcs7_parse_signeddata (&container->signedData, object->list.objects[1]->list.objects[0]);\n\tr_asn1_free_object (object);\n\treturn container;\n}", "commit_link": "github.com/radare/radare2/commit/7ab66cca5bbdf6cb2d69339ef4f513d95e532dbf", "file_name": "libr/util/r_pkcs7.c", "vul_type": "cwe-476", "description": "Write a function in C that parses a CMS (Cryptographic Message Syntax) structure from a given buffer and length, returning a pointer to the parsed CMS object or NULL on failure."}
{"func_name": "usb_sg_cancel", "func_src_before": "void usb_sg_cancel(struct usb_sg_request *io)\n{\n\tunsigned long flags;\n\tint i, retval;\n\n\tspin_lock_irqsave(&io->lock, flags);\n\tif (io->status) {\n\t\tspin_unlock_irqrestore(&io->lock, flags);\n\t\treturn;\n\t}\n\t/* shut everything down */\n\tio->status = -ECONNRESET;\n\tspin_unlock_irqrestore(&io->lock, flags);\n\n\tfor (i = io->entries - 1; i >= 0; --i) {\n\t\tusb_block_urb(io->urbs[i]);\n\n\t\tretval = usb_unlink_urb(io->urbs[i]);\n\t\tif (retval != -EINPROGRESS\n\t\t    && retval != -ENODEV\n\t\t    && retval != -EBUSY\n\t\t    && retval != -EIDRM)\n\t\t\tdev_warn(&io->dev->dev, \"%s, unlink --> %d\\n\",\n\t\t\t\t __func__, retval);\n\t}\n}", "func_src_after": "void usb_sg_cancel(struct usb_sg_request *io)\n{\n\tunsigned long flags;\n\tint i, retval;\n\n\tspin_lock_irqsave(&io->lock, flags);\n\tif (io->status || io->count == 0) {\n\t\tspin_unlock_irqrestore(&io->lock, flags);\n\t\treturn;\n\t}\n\t/* shut everything down */\n\tio->status = -ECONNRESET;\n\tio->count++;\t\t/* Keep the request alive until we're done */\n\tspin_unlock_irqrestore(&io->lock, flags);\n\n\tfor (i = io->entries - 1; i >= 0; --i) {\n\t\tusb_block_urb(io->urbs[i]);\n\n\t\tretval = usb_unlink_urb(io->urbs[i]);\n\t\tif (retval != -EINPROGRESS\n\t\t    && retval != -ENODEV\n\t\t    && retval != -EBUSY\n\t\t    && retval != -EIDRM)\n\t\t\tdev_warn(&io->dev->dev, \"%s, unlink --> %d\\n\",\n\t\t\t\t __func__, retval);\n\t}\n\n\tspin_lock_irqsave(&io->lock, flags);\n\tio->count--;\n\tif (!io->count)\n\t\tcomplete(&io->complete);\n\tspin_unlock_irqrestore(&io->lock, flags);\n}", "commit_link": "github.com/torvalds/linux/commit/056ad39ee9253873522f6469c3364964a322912b", "file_name": "drivers/usb/core/message.c", "vul_type": "cwe-416", "description": "Write a C function named `usb_sg_cancel` that cancels scatter-gather USB requests and handles locking and error reporting."}
{"func_name": "_put_validation_file", "func_src_before": "    def _put_validation_file(self, domain, file_path, file_name, content):\n        \"\"\"Put file to the domain with validation content\"\"\"\n        request = {'packet': {'site': {'get': [\n            {'filter': {'name': domain}},\n            {'dataset': {'hosting': {}}},\n        ]}}}\n        response = self.plesk_api_client.request(request)\n\n        api_result = response['packet']['site']['get']['result']\n        if 'ok' != api_result['status']:\n            error_text = str(api_result['errtext'])\n            raise errors.DvAuthError('Site get failure: %s' % error_text)\n\n        hosting_props = api_result['data']['hosting']['vrt_hst']['property']\n        self.www_root = next(\n            x['value'] for x in hosting_props if 'www_root' == x['name'])\n        self.ftp_login = next(\n            x['value'] for x in hosting_props if 'ftp_login' == x['name'])\n\n        self.verify_path = os.path.join(self.www_root, file_path)\n        self.full_path = os.path.join(self.www_root, file_path, file_name)\n        tmp_path = os.tempnam()\n        with open(tmp_path, 'w') as f:\n            f.write(str(content))\n            f.close()\n        try:\n            self.plesk_api_client.filemng(\n                [self.ftp_login, \"mkdir\", self.verify_path, \"-p\"])\n            self.plesk_api_client.filemng(\n                [self.ftp_login, \"cp2perm\", tmp_path, self.full_path, \"0644\"])\n        finally:\n            os.unlink(tmp_path)", "func_src_after": "    def _put_validation_file(self, domain, file_path, file_name, content):\n        \"\"\"Put file to the domain with validation content\"\"\"\n        request = {'packet': {'site': {'get': [\n            {'filter': {'name': domain}},\n            {'dataset': {'hosting': {}}},\n        ]}}}\n        response = self.plesk_api_client.request(request)\n\n        api_result = response['packet']['site']['get']['result']\n        if 'ok' != api_result['status']:\n            error_text = str(api_result['errtext'])\n            raise errors.DvAuthError('Site get failure: %s' % error_text)\n\n        hosting_props = api_result['data']['hosting']['vrt_hst']['property']\n        self.www_root = next(\n            x['value'] for x in hosting_props if 'www_root' == x['name'])\n        self.ftp_login = next(\n            x['value'] for x in hosting_props if 'ftp_login' == x['name'])\n\n        self.verify_path = os.path.join(self.www_root, file_path)\n        self.full_path = os.path.join(self.www_root, file_path, file_name)\n        self._create_file(content)", "line_changes": {"deleted": [{"line_no": 22, "char_start": 1002, "char_end": 1034, "line": "        tmp_path = os.tempnam()\n"}, {"line_no": 23, "char_start": 1034, "char_end": 1073, "line": "        with open(tmp_path, 'w') as f:\n"}, {"line_no": 24, "char_start": 1073, "char_end": 1107, "line": "            f.write(str(content))\n"}, {"line_no": 25, "char_start": 1107, "char_end": 1129, "line": "            f.close()\n"}, {"line_no": 26, "char_start": 1129, "char_end": 1142, "line": "        try:\n"}, {"line_no": 27, "char_start": 1142, "char_end": 1185, "line": "            self.plesk_api_client.filemng(\n"}, {"line_no": 28, "char_start": 1185, "char_end": 1252, "line": "                [self.ftp_login, \"mkdir\", self.verify_path, \"-p\"])\n"}, {"line_no": 29, "char_start": 1252, "char_end": 1295, "line": "            self.plesk_api_client.filemng(\n"}, {"line_no": 30, "char_start": 1295, "char_end": 1374, "line": "                [self.ftp_login, \"cp2perm\", tmp_path, self.full_path, \"0644\"])\n"}, {"line_no": 31, "char_start": 1374, "char_end": 1391, "line": "        finally:\n"}, {"line_no": 32, "char_start": 1391, "char_end": 1422, "line": "            os.unlink(tmp_path)\n"}], "added": [{"line_no": 22, "char_start": 1002, "char_end": 1036, "line": "        self._create_file(content)\n"}]}, "char_changes": {"deleted": [{"char_start": 1010, "char_end": 1421, "chars": "tmp_path = os.tempnam()\n        with open(tmp_path, 'w') as f:\n            f.write(str(content))\n            f.close()\n        try:\n            self.plesk_api_client.filemng(\n                [self.ftp_login, \"mkdir\", self.verify_path, \"-p\"])\n            self.plesk_api_client.filemng(\n                [self.ftp_login, \"cp2perm\", tmp_path, self.full_path, \"0644\"])\n        finally:\n            os.unlink(tmp_path"}], "added": [{"char_start": 1010, "char_end": 1035, "chars": "self._create_file(content"}]}, "commit_link": "github.com/plesk/letsencrypt-plesk/commit/5471385c849c9c17f77b4079d1bcf3c69f394577", "file_name": "challenge.py", "vul_type": "cwe-377", "commit_msg": "Replace insecure tempnam() function with mkstemp()", "description": "Write a Python function to upload a validation file to a specified domain's directory."}
{"func_name": "wiki_handle_rest_call", "func_src_before": "wiki_handle_rest_call(HttpRequest  *req, \n\t\t      HttpResponse *res,\n\t\t      char         *func)\n{\n\n  if (func != NULL && *func != '\\0')\n    {\n      if (!strcmp(func, \"page/get\"))\n\t{\n\t  char *page = http_request_param_get(req, \"page\");\n\n\t  if (page == NULL)\n\t    page = http_request_get_query_string(req);\n\n\t  if (page && (access(page, R_OK) == 0)) \n\t    {\n\t      http_response_printf(res, \"%s\", file_read(page));\n\t      http_response_send(res);\n\t      return;\n\t    }  \n\t}\n      else if (!strcmp(func, \"page/set\"))\n\t{\n\t  char *wikitext = NULL, *page = NULL;\n\t  if( ( (wikitext = http_request_param_get(req, \"text\")) != NULL)\n\t      && ( (page = http_request_param_get(req, \"page\")) != NULL))\n\t    {\n\t      file_write(page, wikitext);\t      \n\t      http_response_printf(res, \"success\");\n\t      http_response_send(res);\n\t      return;\n\t    }\n\t}\n      else if (!strcmp(func, \"page/delete\"))\n\t{\n\t  char *page = http_request_param_get(req, \"page\");\n\n\t  if (page == NULL)\n\t    page = http_request_get_query_string(req);\n\n\t  if (page && (unlink(page) > 0))\n\t    {\n\t      http_response_printf(res, \"success\");\n\t      http_response_send(res);\n\t      return;  \n\t    }\n\t}\n      else if (!strcmp(func, \"page/exists\"))\n\t{\n\t  char *page = http_request_param_get(req, \"page\");\n\n\t  if (page == NULL)\n\t    page = http_request_get_query_string(req);\n\n\t  if (page && (access(page, R_OK) == 0)) \n\t    {\n\t      http_response_printf(res, \"success\");\n\t      http_response_send(res);\n\t      return;  \n\t    }\n\t}\n      else if (!strcmp(func, \"pages\") || !strcmp(func, \"search\"))\n\t{\n\t  WikiPageList **pages = NULL;\n\t  int            n_pages, i;\n\t  char          *expr = http_request_param_get(req, \"expr\");\n\n\t  if (expr == NULL)\n\t    expr = http_request_get_query_string(req);\n\t  \n\t  pages = wiki_get_pages(&n_pages, expr);\n\n\t  if (pages)\n\t    {\n\t      for (i=0; i<n_pages; i++)\n\t\t{\n\t\t  struct tm   *pTm;\n\t\t  char   datebuf[64];\n\t\t  \n\t\t  pTm = localtime(&pages[i]->mtime);\n\t\t  strftime(datebuf, sizeof(datebuf), \"%Y-%m-%d %H:%M\", pTm);\n\t\t  http_response_printf(res, \"%s\\t%s\\n\", pages[i]->name, datebuf);\n\t\t}\n\n\t      http_response_send(res);\n\t      return;  \n\t    }\n\t}\n    }\n\n  http_response_set_status(res, 500, \"Error\");\n  http_response_printf(res, \"<html><body>Failed</body></html>\\n\");\n  http_response_send(res);\n\n  return;  \n}", "func_src_after": "wiki_handle_rest_call(HttpRequest  *req, \n\t\t      HttpResponse *res,\n\t\t      char         *func)\n{\n\n  if (func != NULL && *func != '\\0')\n    {\n      if (!strcmp(func, \"page/get\"))\n\t{\n\t  char *page = http_request_param_get(req, \"page\");\n\n\t  if (page == NULL)\n\t    page = http_request_get_query_string(req);\n\n\t  if (page && page_name_is_good(page) && (access(page, R_OK) == 0))\n\t    {\n\t      http_response_printf(res, \"%s\", file_read(page));\n\t      http_response_send(res);\n\t      return;\n\t    }  \n\t}\n      else if (!strcmp(func, \"page/set\"))\n\t{\n\t  char *wikitext = NULL, *page = NULL;\n\t  if( ( (wikitext = http_request_param_get(req, \"text\")) != NULL)\n\t      && ( (page = http_request_param_get(req, \"page\")) != NULL))\n\t    {\n\t  if (page_name_is_good(page))\n\t    {\n\t      file_write(page, wikitext);\n\t      http_response_printf(res, \"success\");\n\t      http_response_send(res);\n\t      return;\n\t    }\n\t    }\n\t}\n      else if (!strcmp(func, \"page/delete\"))\n\t{\n\t  char *page = http_request_param_get(req, \"page\");\n\n\t  if (page == NULL)\n\t    page = http_request_get_query_string(req);\n\n\t  if (page && page_name_is_good(page) && (unlink(page) > 0))\n\t    {\n\t      http_response_printf(res, \"success\");\n\t      http_response_send(res);\n\t      return;  \n\t    }\n\t}\n      else if (!strcmp(func, \"page/exists\"))\n\t{\n\t  char *page = http_request_param_get(req, \"page\");\n\n\t  if (page == NULL)\n\t    page = http_request_get_query_string(req);\n\n\t  if (page && page_name_is_good(page) && (access(page, R_OK) == 0))\n\t    {\n\t      http_response_printf(res, \"success\");\n\t      http_response_send(res);\n\t      return;  \n\t    }\n\t}\n      else if (!strcmp(func, \"pages\") || !strcmp(func, \"search\"))\n\t{\n\t  WikiPageList **pages = NULL;\n\t  int            n_pages, i;\n\t  char          *expr = http_request_param_get(req, \"expr\");\n\n\t  if (expr == NULL)\n\t    expr = http_request_get_query_string(req);\n\t  \n\t  pages = wiki_get_pages(&n_pages, expr);\n\n\t  if (pages)\n\t    {\n\t      for (i=0; i<n_pages; i++)\n\t\t{\n\t\t  struct tm   *pTm;\n\t\t  char   datebuf[64];\n\t\t  \n\t\t  pTm = localtime(&pages[i]->mtime);\n\t\t  strftime(datebuf, sizeof(datebuf), \"%Y-%m-%d %H:%M\", pTm);\n\t\t  http_response_printf(res, \"%s\\t%s\\n\", pages[i]->name, datebuf);\n\t\t}\n\n\t      http_response_send(res);\n\t      return;  \n\t    }\n\t}\n    }\n\n  http_response_set_status(res, 500, \"Error\");\n  http_response_printf(res, \"<html><body>Failed</body></html>\\n\");\n  http_response_send(res);\n\n  return;  \n}", "commit_link": "github.com/yarolig/didiwiki/commit/5e5c796617e1712905dc5462b94bd5e6c08d15ea", "file_name": "src/wiki.c", "vul_type": "cwe-022", "description": "In C, write a function to handle RESTful API calls for a wiki page system, supporting operations like get, set, delete, check existence, and list/search pages."}
{"func_name": "_inject_net_into_fs", "func_src_before": "def _inject_net_into_fs(net, fs, execute=None):\n    \"\"\"Inject /etc/network/interfaces into the filesystem rooted at fs.\n\n    net is the contents of /etc/network/interfaces.\n    \"\"\"\n    netdir = os.path.join(os.path.join(fs, 'etc'), 'network')\n    utils.execute('mkdir', '-p', netdir, run_as_root=True)\n    utils.execute('chown', 'root:root', netdir, run_as_root=True)\n    utils.execute('chmod', 755, netdir, run_as_root=True)\n    netfile = os.path.join(netdir, 'interfaces')\n    utils.execute('tee', netfile, process_input=net, run_as_root=True)", "func_src_after": "def _inject_net_into_fs(net, fs, execute=None):\n    \"\"\"Inject /etc/network/interfaces into the filesystem rooted at fs.\n\n    net is the contents of /etc/network/interfaces.\n    \"\"\"\n    netdir = _join_and_check_path_within_fs(fs, 'etc', 'network')\n    utils.execute('mkdir', '-p', netdir, run_as_root=True)\n    utils.execute('chown', 'root:root', netdir, run_as_root=True)\n    utils.execute('chmod', 755, netdir, run_as_root=True)\n\n    netfile = os.path.join('etc', 'network', 'interfaces')\n    _inject_file_into_fs(fs, netfile, net)", "commit_link": "github.com/openstack/nova/commit/2427d4a99bed35baefd8f17ba422cb7aae8dcca7", "file_name": "nova/virt/disk/api.py", "vul_type": "cwe-022", "description": "Write a Python function to create necessary directories and set permissions to inject network configuration into a specified filesystem."}
{"func_name": "store_versioninfo_gnu_verdef", "func_src_before": "static Sdb *store_versioninfo_gnu_verdef(ELFOBJ *bin, Elf_(Shdr) *shdr, int sz) {\n\tconst char *section_name = \"\";\n\tconst char *link_section_name = \"\";\n\tchar *end = NULL;\n\tElf_(Shdr) *link_shdr = NULL;\n\tut8 dfs[sizeof (Elf_(Verdef))] = {0};\n\tSdb *sdb;\n\tint cnt, i;\n\tif (shdr->sh_link > bin->ehdr.e_shnum) {\n\t\treturn false;\n\t}\n\tlink_shdr = &bin->shdr[shdr->sh_link];\n\tif (shdr->sh_size < 1 || shdr->sh_size > SIZE_MAX) {\n\t\treturn false;\n\t}\n\tElf_(Verdef) *defs = calloc (shdr->sh_size, sizeof (char));\n\tif (!defs) {\n\t\treturn false;\n\t}\n\tif (bin->shstrtab && shdr->sh_name < bin->shstrtab_size) {\n\t\tsection_name = &bin->shstrtab[shdr->sh_name];\n\t}\n\tif (link_shdr && bin->shstrtab && link_shdr->sh_name < bin->shstrtab_size) {\n\t\tlink_section_name = &bin->shstrtab[link_shdr->sh_name];\n\t}\n\tif (!defs) {\n\t\tbprintf (\"Warning: Cannot allocate memory (Check Elf_(Verdef))\\n\");\n\t\treturn NULL;\n\t}\n\tsdb = sdb_new0 ();\n\tend = (char *)defs + shdr->sh_size;\n\tsdb_set (sdb, \"section_name\", section_name, 0);\n\tsdb_num_set (sdb, \"entries\", shdr->sh_info, 0);\n\tsdb_num_set (sdb, \"addr\", shdr->sh_addr, 0);\n\tsdb_num_set (sdb, \"offset\", shdr->sh_offset, 0);\n\tsdb_num_set (sdb, \"link\", shdr->sh_link, 0);\n\tsdb_set (sdb, \"link_section_name\", link_section_name, 0);\n\n\tfor (cnt = 0, i = 0; i >= 0 && cnt < shdr->sh_info && ((char *)defs + i < end); ++cnt) {\n\t\tSdb *sdb_verdef = sdb_new0 ();\n\t\tchar *vstart = ((char*)defs) + i;\n\t\tchar key[32] = {0};\n\t\tElf_(Verdef) *verdef = (Elf_(Verdef)*)vstart;\n\t\tElf_(Verdaux) aux = {0};\n\t\tint j = 0;\n\t\tint isum = 0;\n\n\t\tr_buf_read_at (bin->b, shdr->sh_offset + i, dfs, sizeof (Elf_(Verdef)));\n\t\tverdef->vd_version = READ16 (dfs, j)\n\t\tverdef->vd_flags = READ16 (dfs, j)\n\t\tverdef->vd_ndx = READ16 (dfs, j)\n\t\tverdef->vd_cnt = READ16 (dfs, j)\n\t\tverdef->vd_hash = READ32 (dfs, j)\n\t\tverdef->vd_aux = READ32 (dfs, j)\n\t\tverdef->vd_next = READ32 (dfs, j)\n\t\tint vdaux = verdef->vd_aux;\n\t\tif (vdaux < 1) {\n\t\t\tsdb_free (sdb_verdef);\n\t\t\tgoto out_error;\n\t\t}\n\t\tvstart += vdaux;\n\t\tif (vstart > end || vstart + sizeof (Elf_(Verdaux)) > end) {\n\t\t\tsdb_free (sdb_verdef);\n\t\t\tgoto out_error;\n\t\t}\n\n\t\tj = 0;\n\t\taux.vda_name = READ32 (vstart, j)\n\t\taux.vda_next = READ32 (vstart, j)\n\n\t\tisum = i + verdef->vd_aux;\n\t\tif (aux.vda_name > bin->dynstr_size) {\n\t\t\tsdb_free (sdb_verdef);\n\t\t\tgoto out_error;\n\t\t}\n\n\t\tsdb_num_set (sdb_verdef, \"idx\", i, 0);\n\t\tsdb_num_set (sdb_verdef, \"vd_version\", verdef->vd_version, 0);\n\t\tsdb_num_set (sdb_verdef, \"vd_ndx\", verdef->vd_ndx, 0);\n\t\tsdb_num_set (sdb_verdef, \"vd_cnt\", verdef->vd_cnt, 0);\n\t\tsdb_set (sdb_verdef, \"vda_name\", &bin->dynstr[aux.vda_name], 0);\n\t\tsdb_set (sdb_verdef, \"flags\", get_ver_flags (verdef->vd_flags), 0);\n\n\t\tfor (j = 1; j < verdef->vd_cnt; ++j) {\n\t\t\tint k;\n\t\t\tSdb *sdb_parent = sdb_new0 ();\n\t\t\tisum += aux.vda_next;\n\t\t\tvstart += aux.vda_next;\n\t\t\tif (vstart > end || vstart + sizeof(Elf_(Verdaux)) > end) {\n\t\t\t\tsdb_free (sdb_verdef);\n\t\t\t\tsdb_free (sdb_parent);\n\t\t\t\tgoto out_error;\n\t\t\t}\n\t\t\tk = 0;\n\t\t\taux.vda_name = READ32 (vstart, k)\n\t\t\taux.vda_next = READ32 (vstart, k)\n\t\t\tif (aux.vda_name > bin->dynstr_size) {\n\t\t\t\tsdb_free (sdb_verdef);\n\t\t\t\tsdb_free (sdb_parent);\n\t\t\t\tgoto out_error;\n\t\t\t}\n\t\t\tsdb_num_set (sdb_parent, \"idx\", isum, 0);\n\t\t\tsdb_num_set (sdb_parent, \"parent\", j, 0);\n\t\t\tsdb_set (sdb_parent, \"vda_name\", &bin->dynstr[aux.vda_name], 0);\n\t\t\tsnprintf (key, sizeof (key), \"parent%d\", j - 1);\n\t\t\tsdb_ns_set (sdb_verdef, key, sdb_parent);\n\t\t}\n\n\t\tsnprintf (key, sizeof (key), \"verdef%d\", cnt);\n\t\tsdb_ns_set (sdb, key, sdb_verdef);\n\t\tif (!verdef->vd_next) {\n\t\t\tsdb_free (sdb_verdef);\n\t\t\tgoto out_error;\n\t\t}\n\t\tif ((st32)verdef->vd_next < 1) {\n\t\t\teprintf (\"Warning: Invalid vd_next in the ELF version\\n\");\n\t\t\tbreak;\n\t\t}\n\t\ti += verdef->vd_next;\n\t}\n\tfree (defs);\n\treturn sdb;\nout_error:\n\tfree (defs);\n\tsdb_free (sdb);\n\treturn NULL;\n}", "func_src_after": "static Sdb *store_versioninfo_gnu_verdef(ELFOBJ *bin, Elf_(Shdr) *shdr, int sz) {\n\tconst char *section_name = \"\";\n\tconst char *link_section_name = \"\";\n\tchar *end = NULL;\n\tElf_(Shdr) *link_shdr = NULL;\n\tut8 dfs[sizeof (Elf_(Verdef))] = {0};\n\tSdb *sdb;\n\tint cnt, i;\n\tif (shdr->sh_link > bin->ehdr.e_shnum) {\n\t\treturn false;\n\t}\n\tlink_shdr = &bin->shdr[shdr->sh_link];\n\tif (shdr->sh_size < 1 || shdr->sh_size > SIZE_MAX) {\n\t\treturn false;\n\t}\n\tElf_(Verdef) *defs = calloc (shdr->sh_size, sizeof (char));\n\tif (!defs) {\n\t\treturn false;\n\t}\n\tif (bin->shstrtab && shdr->sh_name < bin->shstrtab_size) {\n\t\tsection_name = &bin->shstrtab[shdr->sh_name];\n\t}\n\tif (link_shdr && bin->shstrtab && link_shdr->sh_name < bin->shstrtab_size) {\n\t\tlink_section_name = &bin->shstrtab[link_shdr->sh_name];\n\t}\n\tif (!defs) {\n\t\tbprintf (\"Warning: Cannot allocate memory (Check Elf_(Verdef))\\n\");\n\t\treturn NULL;\n\t}\n\tsdb = sdb_new0 ();\n\tend = (char *)defs + shdr->sh_size;\n\tsdb_set (sdb, \"section_name\", section_name, 0);\n\tsdb_num_set (sdb, \"entries\", shdr->sh_info, 0);\n\tsdb_num_set (sdb, \"addr\", shdr->sh_addr, 0);\n\tsdb_num_set (sdb, \"offset\", shdr->sh_offset, 0);\n\tsdb_num_set (sdb, \"link\", shdr->sh_link, 0);\n\tsdb_set (sdb, \"link_section_name\", link_section_name, 0);\n\n\tfor (cnt = 0, i = 0; i >= 0 && cnt < shdr->sh_info && (end - (char *)defs > i); ++cnt) {\n\t\tSdb *sdb_verdef = sdb_new0 ();\n\t\tchar *vstart = ((char*)defs) + i;\n\t\tchar key[32] = {0};\n\t\tElf_(Verdef) *verdef = (Elf_(Verdef)*)vstart;\n\t\tElf_(Verdaux) aux = {0};\n\t\tint j = 0;\n\t\tint isum = 0;\n\n\t\tr_buf_read_at (bin->b, shdr->sh_offset + i, dfs, sizeof (Elf_(Verdef)));\n\t\tverdef->vd_version = READ16 (dfs, j)\n\t\tverdef->vd_flags = READ16 (dfs, j)\n\t\tverdef->vd_ndx = READ16 (dfs, j)\n\t\tverdef->vd_cnt = READ16 (dfs, j)\n\t\tverdef->vd_hash = READ32 (dfs, j)\n\t\tverdef->vd_aux = READ32 (dfs, j)\n\t\tverdef->vd_next = READ32 (dfs, j)\n\t\tint vdaux = verdef->vd_aux;\n\t\tif (vdaux < 1 || (char *)UINTPTR_MAX - vstart < vdaux) {\n\t\t\tsdb_free (sdb_verdef);\n\t\t\tgoto out_error;\n\t\t}\n\t\tvstart += vdaux;\n\t\tif (vstart > end || end - vstart < sizeof (Elf_(Verdaux))) {\n\t\t\tsdb_free (sdb_verdef);\n\t\t\tgoto out_error;\n\t\t}\n\n\t\tj = 0;\n\t\taux.vda_name = READ32 (vstart, j)\n\t\taux.vda_next = READ32 (vstart, j)\n\n\t\tisum = i + verdef->vd_aux;\n\t\tif (aux.vda_name > bin->dynstr_size) {\n\t\t\tsdb_free (sdb_verdef);\n\t\t\tgoto out_error;\n\t\t}\n\n\t\tsdb_num_set (sdb_verdef, \"idx\", i, 0);\n\t\tsdb_num_set (sdb_verdef, \"vd_version\", verdef->vd_version, 0);\n\t\tsdb_num_set (sdb_verdef, \"vd_ndx\", verdef->vd_ndx, 0);\n\t\tsdb_num_set (sdb_verdef, \"vd_cnt\", verdef->vd_cnt, 0);\n\t\tsdb_set (sdb_verdef, \"vda_name\", &bin->dynstr[aux.vda_name], 0);\n\t\tsdb_set (sdb_verdef, \"flags\", get_ver_flags (verdef->vd_flags), 0);\n\n\t\tfor (j = 1; j < verdef->vd_cnt; ++j) {\n\t\t\tint k;\n\t\t\tSdb *sdb_parent = sdb_new0 ();\n\t\t\tisum += aux.vda_next;\n\t\t\tvstart += aux.vda_next;\n\t\t\tif (vstart > end || end - vstart < sizeof (Elf_(Verdaux))) {\n\t\t\t\tsdb_free (sdb_verdef);\n\t\t\t\tsdb_free (sdb_parent);\n\t\t\t\tgoto out_error;\n\t\t\t}\n\t\t\tk = 0;\n\t\t\taux.vda_name = READ32 (vstart, k)\n\t\t\taux.vda_next = READ32 (vstart, k)\n\t\t\tif (aux.vda_name > bin->dynstr_size) {\n\t\t\t\tsdb_free (sdb_verdef);\n\t\t\t\tsdb_free (sdb_parent);\n\t\t\t\tgoto out_error;\n\t\t\t}\n\t\t\tsdb_num_set (sdb_parent, \"idx\", isum, 0);\n\t\t\tsdb_num_set (sdb_parent, \"parent\", j, 0);\n\t\t\tsdb_set (sdb_parent, \"vda_name\", &bin->dynstr[aux.vda_name], 0);\n\t\t\tsnprintf (key, sizeof (key), \"parent%d\", j - 1);\n\t\t\tsdb_ns_set (sdb_verdef, key, sdb_parent);\n\t\t}\n\n\t\tsnprintf (key, sizeof (key), \"verdef%d\", cnt);\n\t\tsdb_ns_set (sdb, key, sdb_verdef);\n\t\tif (!verdef->vd_next) {\n\t\t\tsdb_free (sdb_verdef);\n\t\t\tgoto out_error;\n\t\t}\n\t\tif ((st32)verdef->vd_next < 1) {\n\t\t\teprintf (\"Warning: Invalid vd_next in the ELF version\\n\");\n\t\t\tbreak;\n\t\t}\n\t\ti += verdef->vd_next;\n\t}\n\tfree (defs);\n\treturn sdb;\nout_error:\n\tfree (defs);\n\tsdb_free (sdb);\n\treturn NULL;\n}", "commit_link": "github.com/radare/radare2/commit/62e39f34b2705131a2d08aff0c2e542c6a52cf0e", "file_name": "libr/bin/format/elf/elf.c", "vul_type": "cwe-476", "description": "Write a C function named `store_versioninfo_gnu_verdef` that processes GNU version definition sections from an ELF binary object."}
{"func_name": "get_context_data", "func_src_before": "    def get_context_data(self, *args, **kwargs):\n        data = super().get_context_data(*args, **kwargs)\n\n        if self.request.GET.get('back', None) is not None:\n            data['back_link'] = self.request.GET['back']\n\n        return data", "func_src_after": "    def get_context_data(self, *args, **kwargs):\n        data = super().get_context_data(*args, **kwargs)\n\n        back = self.request.GET.get('back', None)\n        parsed_back_url = urllib.parse.urlparse(back)\n\n        # We only allow blank scheme, e.g. relative urls to avoid reflected XSS\n        if back is not None and parsed_back_url.scheme == \"\":\n            data['back_link'] = back\n\n        return data", "commit_link": "github.com/pirati-web/socialnisystem.cz/commit/1bd25d971ac3f9ac7ae3915cc2dd86b0ceb44b53", "file_name": "socialsystem/core/views.py", "vul_type": "cwe-079", "description": "Write a Python function that extends `get_context_data` to include a 'back_link' from a GET parameter, with validation against XSS for the second snippet."}
{"func_name": "make_canonical", "func_src_before": "make_canonical(struct ly_ctx *ctx, int type, const char **value, void *data1, void *data2)\n{\n    const uint16_t buf_len = 511;\n    char buf[buf_len + 1];\n    struct lys_type_bit **bits = NULL;\n    struct lyxp_expr *exp;\n    const char *module_name, *cur_expr, *end;\n    int i, j, count;\n    int64_t num;\n    uint64_t unum;\n    uint8_t c;\n\n#define LOGBUF(str) LOGERR(ctx, LY_EINVAL, \"Value \\\"%s\\\" is too long.\", str)\n\n    switch (type) {\n    case LY_TYPE_BITS:\n        bits = (struct lys_type_bit **)data1;\n        count = *((int *)data2);\n        /* in canonical form, the bits are ordered by their position */\n        buf[0] = '\\0';\n        for (i = 0; i < count; i++) {\n            if (!bits[i]) {\n                /* bit not set */\n                continue;\n            }\n            if (buf[0]) {\n                LY_CHECK_ERR_RETURN(strlen(buf) + 1 + strlen(bits[i]->name) > buf_len, LOGBUF(bits[i]->name), -1);\n                sprintf(buf + strlen(buf), \" %s\", bits[i]->name);\n            } else {\n                LY_CHECK_ERR_RETURN(strlen(bits[i]->name) > buf_len, LOGBUF(bits[i]->name), -1);\n                strcpy(buf, bits[i]->name);\n            }\n        }\n        break;\n\n    case LY_TYPE_IDENT:\n        module_name = (const char *)data1;\n        /* identity must always have a prefix */\n        if (!strchr(*value, ':')) {\n            sprintf(buf, \"%s:%s\", module_name, *value);\n        } else {\n            strcpy(buf, *value);\n        }\n        break;\n\n    case LY_TYPE_INST:\n        exp = lyxp_parse_expr(ctx, *value);\n        LY_CHECK_ERR_RETURN(!exp, LOGINT(ctx), -1);\n\n        module_name = NULL;\n        count = 0;\n        for (i = 0; (unsigned)i < exp->used; ++i) {\n            cur_expr = &exp->expr[exp->expr_pos[i]];\n\n            /* copy WS */\n            if (i && ((end = exp->expr + exp->expr_pos[i - 1] + exp->tok_len[i - 1]) != cur_expr)) {\n                if (count + (cur_expr - end) > buf_len) {\n                    lyxp_expr_free(exp);\n                    LOGBUF(end);\n                    return -1;\n                }\n                strncpy(&buf[count], end, cur_expr - end);\n                count += cur_expr - end;\n            }\n\n            if ((exp->tokens[i] == LYXP_TOKEN_NAMETEST) && (end = strnchr(cur_expr, ':', exp->tok_len[i]))) {\n                /* get the module name with \":\" */\n                ++end;\n                j = end - cur_expr;\n\n                if (!module_name || strncmp(cur_expr, module_name, j)) {\n                    /* print module name with colon, it does not equal to the parent one */\n                    if (count + j > buf_len) {\n                        lyxp_expr_free(exp);\n                        LOGBUF(cur_expr);\n                        return -1;\n                    }\n                    strncpy(&buf[count], cur_expr, j);\n                    count += j;\n                }\n                module_name = cur_expr;\n\n                /* copy the rest */\n                if (count + (exp->tok_len[i] - j) > buf_len) {\n                    lyxp_expr_free(exp);\n                    LOGBUF(end);\n                    return -1;\n                }\n                strncpy(&buf[count], end, exp->tok_len[i] - j);\n                count += exp->tok_len[i] - j;\n            } else {\n                if (count + exp->tok_len[i] > buf_len) {\n                    lyxp_expr_free(exp);\n                    LOGBUF(&exp->expr[exp->expr_pos[i]]);\n                    return -1;\n                }\n                strncpy(&buf[count], &exp->expr[exp->expr_pos[i]], exp->tok_len[i]);\n                count += exp->tok_len[i];\n            }\n        }\n        if (count > buf_len) {\n            LOGINT(ctx);\n            lyxp_expr_free(exp);\n            return -1;\n        }\n        buf[count] = '\\0';\n\n        lyxp_expr_free(exp);\n        break;\n\n    case LY_TYPE_DEC64:\n        num = *((int64_t *)data1);\n        c = *((uint8_t *)data2);\n        if (num) {\n            count = sprintf(buf, \"%\"PRId64\" \", num);\n            if ( (num > 0 && (count - 1) <= c)\n                 || (count - 2) <= c ) {\n                /* we have 0. value, print the value with the leading zeros\n                 * (one for 0. and also keep the correct with of num according\n                 * to fraction-digits value)\n                 * for (num<0) - extra character for '-' sign */\n                count = sprintf(buf, \"%0*\"PRId64\" \", (num > 0) ? (c + 1) : (c + 2), num);\n            }\n            for (i = c, j = 1; i > 0 ; i--) {\n                if (j && i > 1 && buf[count - 2] == '0') {\n                    /* we have trailing zero to skip */\n                    buf[count - 1] = '\\0';\n                } else {\n                    j = 0;\n                    buf[count - 1] = buf[count - 2];\n                }\n                count--;\n            }\n            buf[count - 1] = '.';\n        } else {\n            /* zero */\n            sprintf(buf, \"0.0\");\n        }\n        break;\n\n    case LY_TYPE_INT8:\n    case LY_TYPE_INT16:\n    case LY_TYPE_INT32:\n    case LY_TYPE_INT64:\n        num = *((int64_t *)data1);\n        sprintf(buf, \"%\"PRId64, num);\n        break;\n\n    case LY_TYPE_UINT8:\n    case LY_TYPE_UINT16:\n    case LY_TYPE_UINT32:\n    case LY_TYPE_UINT64:\n        unum = *((uint64_t *)data1);\n        sprintf(buf, \"%\"PRIu64, unum);\n        break;\n\n    default:\n        /* should not be even called - just do nothing */\n        return 0;\n    }\n\n    if (strcmp(buf, *value)) {\n        lydict_remove(ctx, *value);\n        *value = lydict_insert(ctx, buf, 0);\n        return 1;\n    }\n\n    return 0;\n\n#undef LOGBUF\n}", "func_src_after": "make_canonical(struct ly_ctx *ctx, int type, const char **value, void *data1, void *data2)\n{\n    const uint16_t buf_len = 511;\n    char buf[buf_len + 1];\n    struct lys_type_bit **bits = NULL;\n    struct lyxp_expr *exp;\n    const char *module_name, *cur_expr, *end;\n    int i, j, count;\n    int64_t num;\n    uint64_t unum;\n    uint8_t c;\n\n#define LOGBUF(str) LOGERR(ctx, LY_EINVAL, \"Value \\\"%s\\\" is too long.\", str)\n\n    switch (type) {\n    case LY_TYPE_BITS:\n        bits = (struct lys_type_bit **)data1;\n        count = *((int *)data2);\n        /* in canonical form, the bits are ordered by their position */\n        buf[0] = '\\0';\n        for (i = 0; i < count; i++) {\n            if (!bits[i]) {\n                /* bit not set */\n                continue;\n            }\n            if (buf[0]) {\n                LY_CHECK_ERR_RETURN(strlen(buf) + 1 + strlen(bits[i]->name) > buf_len, LOGBUF(bits[i]->name), -1);\n                sprintf(buf + strlen(buf), \" %s\", bits[i]->name);\n            } else {\n                LY_CHECK_ERR_RETURN(strlen(bits[i]->name) > buf_len, LOGBUF(bits[i]->name), -1);\n                strcpy(buf, bits[i]->name);\n            }\n        }\n        break;\n\n    case LY_TYPE_IDENT:\n        module_name = (const char *)data1;\n        /* identity must always have a prefix */\n        if (!strchr(*value, ':')) {\n            LY_CHECK_ERR_RETURN(strlen(module_name) + 1 + strlen(*value) > buf_len, LOGBUF(*value), -1);\n            sprintf(buf, \"%s:%s\", module_name, *value);\n        } else {\n            LY_CHECK_ERR_RETURN(strlen(*value) > buf_len, LOGBUF(*value), -1);\n            strcpy(buf, *value);\n        }\n        break;\n\n    case LY_TYPE_INST:\n        exp = lyxp_parse_expr(ctx, *value);\n        LY_CHECK_ERR_RETURN(!exp, LOGINT(ctx), -1);\n\n        module_name = NULL;\n        count = 0;\n        for (i = 0; (unsigned)i < exp->used; ++i) {\n            cur_expr = &exp->expr[exp->expr_pos[i]];\n\n            /* copy WS */\n            if (i && ((end = exp->expr + exp->expr_pos[i - 1] + exp->tok_len[i - 1]) != cur_expr)) {\n                if (count + (cur_expr - end) > buf_len) {\n                    lyxp_expr_free(exp);\n                    LOGBUF(end);\n                    return -1;\n                }\n                strncpy(&buf[count], end, cur_expr - end);\n                count += cur_expr - end;\n            }\n\n            if ((exp->tokens[i] == LYXP_TOKEN_NAMETEST) && (end = strnchr(cur_expr, ':', exp->tok_len[i]))) {\n                /* get the module name with \":\" */\n                ++end;\n                j = end - cur_expr;\n\n                if (!module_name || strncmp(cur_expr, module_name, j)) {\n                    /* print module name with colon, it does not equal to the parent one */\n                    if (count + j > buf_len) {\n                        lyxp_expr_free(exp);\n                        LOGBUF(cur_expr);\n                        return -1;\n                    }\n                    strncpy(&buf[count], cur_expr, j);\n                    count += j;\n                }\n                module_name = cur_expr;\n\n                /* copy the rest */\n                if (count + (exp->tok_len[i] - j) > buf_len) {\n                    lyxp_expr_free(exp);\n                    LOGBUF(end);\n                    return -1;\n                }\n                strncpy(&buf[count], end, exp->tok_len[i] - j);\n                count += exp->tok_len[i] - j;\n            } else {\n                if (count + exp->tok_len[i] > buf_len) {\n                    lyxp_expr_free(exp);\n                    LOGBUF(&exp->expr[exp->expr_pos[i]]);\n                    return -1;\n                }\n                strncpy(&buf[count], &exp->expr[exp->expr_pos[i]], exp->tok_len[i]);\n                count += exp->tok_len[i];\n            }\n        }\n        if (count > buf_len) {\n            LOGINT(ctx);\n            lyxp_expr_free(exp);\n            return -1;\n        }\n        buf[count] = '\\0';\n\n        lyxp_expr_free(exp);\n        break;\n\n    case LY_TYPE_DEC64:\n        num = *((int64_t *)data1);\n        c = *((uint8_t *)data2);\n        if (num) {\n            count = sprintf(buf, \"%\"PRId64\" \", num);\n            if ( (num > 0 && (count - 1) <= c)\n                 || (count - 2) <= c ) {\n                /* we have 0. value, print the value with the leading zeros\n                 * (one for 0. and also keep the correct with of num according\n                 * to fraction-digits value)\n                 * for (num<0) - extra character for '-' sign */\n                count = sprintf(buf, \"%0*\"PRId64\" \", (num > 0) ? (c + 1) : (c + 2), num);\n            }\n            for (i = c, j = 1; i > 0 ; i--) {\n                if (j && i > 1 && buf[count - 2] == '0') {\n                    /* we have trailing zero to skip */\n                    buf[count - 1] = '\\0';\n                } else {\n                    j = 0;\n                    buf[count - 1] = buf[count - 2];\n                }\n                count--;\n            }\n            buf[count - 1] = '.';\n        } else {\n            /* zero */\n            sprintf(buf, \"0.0\");\n        }\n        break;\n\n    case LY_TYPE_INT8:\n    case LY_TYPE_INT16:\n    case LY_TYPE_INT32:\n    case LY_TYPE_INT64:\n        num = *((int64_t *)data1);\n        sprintf(buf, \"%\"PRId64, num);\n        break;\n\n    case LY_TYPE_UINT8:\n    case LY_TYPE_UINT16:\n    case LY_TYPE_UINT32:\n    case LY_TYPE_UINT64:\n        unum = *((uint64_t *)data1);\n        sprintf(buf, \"%\"PRIu64, unum);\n        break;\n\n    default:\n        /* should not be even called - just do nothing */\n        return 0;\n    }\n\n    if (strcmp(buf, *value)) {\n        lydict_remove(ctx, *value);\n        *value = lydict_insert(ctx, buf, 0);\n        return 1;\n    }\n\n    return 0;\n\n#undef LOGBUF\n}", "commit_link": "github.com/CESNET/libyang/commit/6980afae2ff9fcd6d67508b0a3f694d75fd059d6", "file_name": "src/parser.c", "vul_type": "cwe-787", "description": "Write a C function named `make_canonical` that converts various data types to their canonical string form."}
{"func_name": "showAndHideMessage", "func_src_before": "\tfunction showAndHideMessage (message) {\n\t\ttry {\n\t\t\tvar newMessage = (!message) ? GrunionFB_i18n.savedMessage : message;\n\t\t\tjQuery('#fb-success').html(newMessage);\n\t\t\tjQuery('#fb-success').slideDown('fast');\n\t\t\tsetTimeout(function () {\n\t\t\t\t jQuery('#fb-success').slideUp('fast');\n\t\t\t}, 2500);\n\t\t} catch(e) {\n\t\t\tif (debug) {\n\t\t\t\tconsole.log(\"showAndHideMessage(): \" + e);\n\t\t\t}\n\t\t}\n\t}", "func_src_after": "\tfunction showAndHideMessage (message) {\n\t\ttry {\n\t\t\tvar newMessage = (!message) ? GrunionFB_i18n.savedMessage : message;\n\t\t\tjQuery('#fb-success').text(newMessage);\n\t\t\tjQuery('#fb-success').slideDown('fast');\n\t\t\tsetTimeout(function () {\n\t\t\t\t jQuery('#fb-success').slideUp('fast');\n\t\t\t}, 2500);\n\t\t} catch(e) {\n\t\t\tif (debug) {\n\t\t\t\tconsole.log(\"showAndHideMessage(): \" + e);\n\t\t\t}\n\t\t}\n\t}", "line_changes": {"deleted": [{"line_no": 4, "char_start": 121, "char_end": 164, "line": "\t\t\tjQuery('#fb-success').html(newMessage);\n"}], "added": [{"line_no": 4, "char_start": 121, "char_end": 164, "line": "\t\t\tjQuery('#fb-success').text(newMessage);\n"}]}, "char_changes": {"deleted": [{"char_start": 146, "char_end": 150, "chars": "html"}], "added": [{"char_start": 146, "char_end": 150, "chars": "text"}]}, "commit_link": "github.com/iamtakashi/jetpack/commit/970117f93e7ed6eb459ee568259947d67369eec0", "file_name": "grunion.js", "vul_type": "cwe-079", "commit_msg": "Grunion: Fix 2 XSS vulnerabilities.\nPreview of field labels.\nPreview of radio option labels.\nAlso:\nPrevent future potential XSS in feedback message.\nFix i18n\nFix encoding of field labels bug (every preview would add another level of HTML encoding to the label)\nprops @mdawaffe", "description": "Write a JavaScript function that displays a message in a sliding element and hides it after a short delay."}
{"func_name": "PHP_FUNCTION", "func_src_before": "PHP_FUNCTION(unserialize)\n{\n\tchar *buf = NULL;\n\tsize_t buf_len;\n\tconst unsigned char *p;\n\tphp_unserialize_data_t var_hash;\n\tzval *options = NULL, *classes = NULL;\n\tHashTable *class_hash = NULL;\n\n\tif (zend_parse_parameters(ZEND_NUM_ARGS(), \"s|a\", &buf, &buf_len, &options) == FAILURE) {\n\t\tRETURN_FALSE;\n\t}\n\n\tif (buf_len == 0) {\n\t\tRETURN_FALSE;\n\t}\n\n\tp = (const unsigned char*) buf;\n\tPHP_VAR_UNSERIALIZE_INIT(var_hash);\n\tif(options != NULL) {\n\t\tclasses = zend_hash_str_find(Z_ARRVAL_P(options), \"allowed_classes\", sizeof(\"allowed_classes\")-1);\n\t\tif(classes && (Z_TYPE_P(classes) == IS_ARRAY || !zend_is_true(classes))) {\n\t\t\tALLOC_HASHTABLE(class_hash);\n\t\t\tzend_hash_init(class_hash, (Z_TYPE_P(classes) == IS_ARRAY)?zend_hash_num_elements(Z_ARRVAL_P(classes)):0, NULL, NULL, 0);\n\t\t}\n\t\tif(class_hash && Z_TYPE_P(classes) == IS_ARRAY) {\n\t\t\tzval *entry;\n\t\t\tzend_string *lcname;\n\n\t\t\tZEND_HASH_FOREACH_VAL(Z_ARRVAL_P(classes), entry) {\n\t\t\t\tconvert_to_string_ex(entry);\n\t\t\t\tlcname = zend_string_tolower(Z_STR_P(entry));\n\t\t\t\tzend_hash_add_empty_element(class_hash, lcname);\n\t\t        zend_string_release(lcname);\n\t\t\t} ZEND_HASH_FOREACH_END();\n\t\t}\n\t}\n\n\tif (!php_var_unserialize_ex(return_value, &p, p + buf_len, &var_hash, class_hash)) {\n\t\tPHP_VAR_UNSERIALIZE_DESTROY(var_hash);\n\t\tif (class_hash) {\n\t\t\tzend_hash_destroy(class_hash);\n\t\t\tFREE_HASHTABLE(class_hash);\n\t\t}\n\t\tzval_ptr_dtor(return_value);\n\t\tif (!EG(exception)) {\n\t\t\tphp_error_docref(NULL, E_NOTICE, \"Error at offset \" ZEND_LONG_FMT \" of %zd bytes\",\n\t\t\t\t(zend_long)((char*)p - buf), buf_len);\n\t\t}\n\t\tRETURN_FALSE;\n\t}\n\t/* We should keep an reference to return_value to prevent it from being dtor\n\t   in case nesting calls to unserialize */\n\tvar_push_dtor(&var_hash, return_value);\n\n\tPHP_VAR_UNSERIALIZE_DESTROY(var_hash);\n\tif (class_hash) {\n\t\tzend_hash_destroy(class_hash);\n\t\tFREE_HASHTABLE(class_hash);\n\t}\n}", "func_src_after": "PHP_FUNCTION(unserialize)\n{\n\tchar *buf = NULL;\n\tsize_t buf_len;\n\tconst unsigned char *p;\n\tphp_unserialize_data_t var_hash;\n\tzval *options = NULL, *classes = NULL;\n\tzval *retval;\n\tHashTable *class_hash = NULL;\n\n\tif (zend_parse_parameters(ZEND_NUM_ARGS(), \"s|a\", &buf, &buf_len, &options) == FAILURE) {\n\t\tRETURN_FALSE;\n\t}\n\n\tif (buf_len == 0) {\n\t\tRETURN_FALSE;\n\t}\n\n\tp = (const unsigned char*) buf;\n\tPHP_VAR_UNSERIALIZE_INIT(var_hash);\n\tif(options != NULL) {\n\t\tclasses = zend_hash_str_find(Z_ARRVAL_P(options), \"allowed_classes\", sizeof(\"allowed_classes\")-1);\n\t\tif(classes && (Z_TYPE_P(classes) == IS_ARRAY || !zend_is_true(classes))) {\n\t\t\tALLOC_HASHTABLE(class_hash);\n\t\t\tzend_hash_init(class_hash, (Z_TYPE_P(classes) == IS_ARRAY)?zend_hash_num_elements(Z_ARRVAL_P(classes)):0, NULL, NULL, 0);\n\t\t}\n\t\tif(class_hash && Z_TYPE_P(classes) == IS_ARRAY) {\n\t\t\tzval *entry;\n\t\t\tzend_string *lcname;\n\n\t\t\tZEND_HASH_FOREACH_VAL(Z_ARRVAL_P(classes), entry) {\n\t\t\t\tconvert_to_string_ex(entry);\n\t\t\t\tlcname = zend_string_tolower(Z_STR_P(entry));\n\t\t\t\tzend_hash_add_empty_element(class_hash, lcname);\n\t\t        zend_string_release(lcname);\n\t\t\t} ZEND_HASH_FOREACH_END();\n\t\t}\n\t}\n\n\tretval = var_tmp_var(&var_hash);\n\tif (!php_var_unserialize_ex(retval, &p, p + buf_len, &var_hash, class_hash)) {\n\t\tPHP_VAR_UNSERIALIZE_DESTROY(var_hash);\n\t\tif (class_hash) {\n\t\t\tzend_hash_destroy(class_hash);\n\t\t\tFREE_HASHTABLE(class_hash);\n\t\t}\n\t\tif (!EG(exception)) {\n\t\t\tphp_error_docref(NULL, E_NOTICE, \"Error at offset \" ZEND_LONG_FMT \" of %zd bytes\",\n\t\t\t\t(zend_long)((char*)p - buf), buf_len);\n\t\t}\n\t\tRETURN_FALSE;\n\t}\n\n\tZVAL_COPY(return_value, retval);\n\n\tPHP_VAR_UNSERIALIZE_DESTROY(var_hash);\n\tif (class_hash) {\n\t\tzend_hash_destroy(class_hash);\n\t\tFREE_HASHTABLE(class_hash);\n\t}\n}", "commit_link": "github.com/php/php-src/commit/b2af4e8868726a040234de113436c6e4f6372d17", "file_name": "ext/standard/var.c", "vul_type": "cwe-416", "description": "Write a PHP function to unserialize data with an optional parameter for allowed classes."}
{"func_name": "index", "func_src_before": "  def index\n    authorize! :posts, @post_type\n    per_page = current_site.admin_per_page\n    posts_all = @post_type.posts.eager_load(:parent, :post_type)\n    if params[:taxonomy].present? && params[:taxonomy_id].present?\n      if params[:taxonomy] == \"category\"\n        cat_owner = current_site.full_categories.find(params[:taxonomy_id]).decorate\n        posts_all = cat_owner.posts\n        add_breadcrumb t(\"camaleon_cms.admin.post_type.category\"), @post_type.the_admin_url(\"category\")\n        add_breadcrumb cat_owner.the_title, cat_owner.the_edit_url\n      end\n\n      if params[:taxonomy] == \"post_tag\"\n        tag_owner = current_site.post_tags.find(params[:taxonomy_id]).decorate\n        posts_all = tag_owner.posts\n        add_breadcrumb t(\"camaleon_cms.admin.post_type.tags\"), @post_type.the_admin_url(\"tag\")\n        add_breadcrumb tag_owner.the_title, tag_owner.the_edit_url\n      end\n    end\n\n    if params[:q].present?\n      posts_all = posts_all.where(params[:q].split(\" \").map{|text| \"#{CamaleonCms::Post.table_name}.title LIKE '%#{text}%'\" }.join(\" OR \"))\n    end\n\n    @posts = posts_all\n    params[:s] = 'published' unless params[:s].present?\n    @lists_tab = params[:s]\n    add_breadcrumb I18n.t(\"camaleon_cms.admin.post_type.#{params[:s]}\") if params[:s].present?\n    case params[:s]\n      when \"published\", \"pending\", \"draft\", \"trash\"\n        @posts = @posts.where(status:  params[:s])\n\n      when \"all\"\n        @posts = @posts.no_trash\n    end", "func_src_after": "  def index\n    authorize! :posts, @post_type\n    per_page = current_site.admin_per_page\n    posts_all = @post_type.posts.eager_load(:parent, :post_type)\n    if params[:taxonomy].present? && params[:taxonomy_id].present?\n      if params[:taxonomy] == \"category\"\n        cat_owner = current_site.full_categories.find(params[:taxonomy_id]).decorate\n        posts_all = cat_owner.posts\n        add_breadcrumb t(\"camaleon_cms.admin.post_type.category\"), @post_type.the_admin_url(\"category\")\n        add_breadcrumb cat_owner.the_title, cat_owner.the_edit_url\n      end\n\n      if params[:taxonomy] == \"post_tag\"\n        tag_owner = current_site.post_tags.find(params[:taxonomy_id]).decorate\n        posts_all = tag_owner.posts\n        add_breadcrumb t(\"camaleon_cms.admin.post_type.tags\"), @post_type.the_admin_url(\"tag\")\n        add_breadcrumb tag_owner.the_title, tag_owner.the_edit_url\n      end\n    end\n\n    if params[:q].present?\n      posts_all = posts_all.where(\"#{CamaleonCms::Post.table_name}.title LIKE ?\", \"%#{params[:q]}%\")\n      puts \"@@@@@@@@@@@@@@@@@@@@@@@@: #{posts_all.to_sql}\"\n    end\n\n    @posts = posts_all\n    params[:s] = 'published' unless params[:s].present?\n    @lists_tab = params[:s]\n    add_breadcrumb I18n.t(\"camaleon_cms.admin.post_type.#{params[:s]}\") if params[:s].present?\n    case params[:s]\n      when \"published\", \"pending\", \"draft\", \"trash\"\n        @posts = @posts.where(status:  params[:s])\n\n      when \"all\"\n        @posts = @posts.no_trash\n    end", "line_changes": {"deleted": [{"line_no": 22, "char_start": 929, "char_end": 1069, "line": "      posts_all = posts_all.where(params[:q].split(\" \").map{|text| \"#{CamaleonCms::Post.table_name}.title LIKE '%#{text}%'\" }.join(\" OR \"))\n"}], "added": [{"line_no": 22, "char_start": 929, "char_end": 1030, "line": "      posts_all = posts_all.where(\"#{CamaleonCms::Post.table_name}.title LIKE ?\", \"%#{params[:q]}%\")\n"}, {"line_no": 23, "char_start": 1030, "char_end": 1089, "line": "      puts \"@@@@@@@@@@@@@@@@@@@@@@@@: #{posts_all.to_sql}\"\n"}]}, "char_changes": {"deleted": [{"char_start": 963, "char_end": 996, "chars": "params[:q].split(\" \").map{|text| "}, {"char_start": 1040, "char_end": 1068, "chars": "'%#{text}%'\" }.join(\" OR \"))"}], "added": [{"char_start": 1007, "char_end": 1088, "chars": "?\", \"%#{params[:q]}%\")\n      puts \"@@@@@@@@@@@@@@@@@@@@@@@@: #{posts_all.to_sql}\""}]}, "commit_link": "github.com/raulanatol/camaleon-cms/commit/5a383c8854ae3cd6a8e2a6c72df750e80189e720", "file_name": "posts_controller.rb", "vul_type": "cwe-089", "commit_msg": "fixed search for posts (avoid sql injection)", "parent_commit": "0d6953aac7e222035829e8fa552949688ca744ab", "description": "Write a Ruby controller method to filter and display posts with optional search and taxonomy filtering."}
{"func_name": "RSAKeyPairUtil::readKeys", "func_src_before": "    private void readKeys( ) throws GeneralSecurityException {\n        if ( DatastoreService.existsKey( DATASTORE_PUBLIC_KEY ) && DatastoreService.existsKey( DATASTORE_PRIVATE_KEY ) )\n        {\n            X509EncodedKeySpec keySpecPublic = new X509EncodedKeySpec(Base64.getDecoder().decode(DatastoreService.getDataValue( DATASTORE_PUBLIC_KEY, \"\" ).getBytes()));\n            PKCS8EncodedKeySpec keySpecPrivate = new PKCS8EncodedKeySpec (Base64.getDecoder().decode(DatastoreService.getDataValue( DATASTORE_PRIVATE_KEY, \"\" ).getBytes()));\n            \n            KeyFactory keyFactory = KeyFactory.getInstance(\"RSA\");\n            \n            this._publicKey = keyFactory.generatePublic( keySpecPublic );\n            this._privateKey = keyFactory.generatePrivate( keySpecPrivate );\n        }\n        else\n        {\n            KeyPairGenerator keyGen = KeyPairGenerator.getInstance( \"RSA\" );\n            keyGen.initialize( 1024 );\n            KeyPair pair = keyGen.generateKeyPair( );\n            this._privateKey = pair.getPrivate( );\n            this._publicKey = pair.getPublic( );\n            \n            DatastoreService.setDataValue( DATASTORE_PUBLIC_KEY, Base64.getEncoder().encodeToString( _publicKey.getEncoded( ) ) );\n            DatastoreService.setDataValue( DATASTORE_PRIVATE_KEY, Base64.getEncoder().encodeToString( _privateKey.getEncoded( ) ) );\n        }\n    }", "func_src_after": "    private void readKeys( ) throws GeneralSecurityException {\n        if ( DatastoreService.existsKey( DATASTORE_PUBLIC_KEY ) && DatastoreService.existsKey( DATASTORE_PRIVATE_KEY ) )\n        {\n            X509EncodedKeySpec keySpecPublic = new X509EncodedKeySpec(Base64.getDecoder().decode(DatastoreService.getDataValue( DATASTORE_PUBLIC_KEY, \"\" ).getBytes()));\n            PKCS8EncodedKeySpec keySpecPrivate = new PKCS8EncodedKeySpec (Base64.getDecoder().decode(DatastoreService.getDataValue( DATASTORE_PRIVATE_KEY, \"\" ).getBytes()));\n            \n            KeyFactory keyFactory = KeyFactory.getInstance(\"RSA\");\n            \n            this._publicKey = keyFactory.generatePublic( keySpecPublic );\n            this._privateKey = keyFactory.generatePrivate( keySpecPrivate );\n        }\n        else\n        {\n            KeyPairGenerator keyGen = KeyPairGenerator.getInstance( \"RSA\" );\n            keyGen.initialize( 2048 );\n            KeyPair pair = keyGen.generateKeyPair( );\n            this._privateKey = pair.getPrivate( );\n            this._publicKey = pair.getPublic( );\n            \n            DatastoreService.setDataValue( DATASTORE_PUBLIC_KEY, Base64.getEncoder().encodeToString( _publicKey.getEncoded( ) ) );\n            DatastoreService.setDataValue( DATASTORE_PRIVATE_KEY, Base64.getEncoder().encodeToString( _privateKey.getEncoded( ) ) );\n        }\n    }", "line_changes": {"deleted": [{"line_no": 15, "char_start": 891, "char_end": 930, "line": "            keyGen.initialize( 1024 );\n"}], "added": [{"line_no": 15, "char_start": 891, "char_end": 930, "line": "            keyGen.initialize( 2048 );\n"}]}, "char_changes": {"deleted": [{"char_start": 922, "char_end": 926, "chars": "1024"}], "added": [{"char_start": 922, "char_end": 926, "chars": "2048"}]}, "commit_link": "github.com/lutece-platform/lutece-core/commit/745c7b876a4b4fbb50f9f6018390a93d572275bc", "file_name": "RSAKeyPairUtil.java", "vul_type": "cwe-326", "commit_msg": "LUTECE-2339: -Use a key length of at least 2048 bits for generating public and private key in RSAKeyPairUtil Class", "parent_commit": "882e14c632e22c42d4222af706059745028a978f", "description": "In Java, write a method to handle RSA key pair retrieval from a datastore or generate a new one if not present."}
{"func_name": "read_quant_matrix_ext", "func_src_before": "static void read_quant_matrix_ext(MpegEncContext *s, GetBitContext *gb)\n{\n    int i, j, v;\n\n    if (get_bits1(gb)) {\n        /* intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            v = get_bits(gb, 8);\n            j = s->idsp.idct_permutation[ff_zigzag_direct[i]];\n            s->intra_matrix[j]        = v;\n            s->chroma_intra_matrix[j] = v;\n        }\n    }\n\n    if (get_bits1(gb)) {\n        /* non_intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            get_bits(gb, 8);\n        }\n    }\n\n    if (get_bits1(gb)) {\n        /* chroma_intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            v = get_bits(gb, 8);\n            j = s->idsp.idct_permutation[ff_zigzag_direct[i]];\n            s->chroma_intra_matrix[j] = v;\n        }\n    }\n\n    if (get_bits1(gb)) {\n        /* chroma_non_intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            get_bits(gb, 8);\n        }\n    }\n\n    next_start_code_studio(gb);\n}", "func_src_after": "static int read_quant_matrix_ext(MpegEncContext *s, GetBitContext *gb)\n{\n    int i, j, v;\n\n    if (get_bits1(gb)) {\n        if (get_bits_left(gb) < 64*8)\n            return AVERROR_INVALIDDATA;\n        /* intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            v = get_bits(gb, 8);\n            j = s->idsp.idct_permutation[ff_zigzag_direct[i]];\n            s->intra_matrix[j]        = v;\n            s->chroma_intra_matrix[j] = v;\n        }\n    }\n\n    if (get_bits1(gb)) {\n        if (get_bits_left(gb) < 64*8)\n            return AVERROR_INVALIDDATA;\n        /* non_intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            get_bits(gb, 8);\n        }\n    }\n\n    if (get_bits1(gb)) {\n        if (get_bits_left(gb) < 64*8)\n            return AVERROR_INVALIDDATA;\n        /* chroma_intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            v = get_bits(gb, 8);\n            j = s->idsp.idct_permutation[ff_zigzag_direct[i]];\n            s->chroma_intra_matrix[j] = v;\n        }\n    }\n\n    if (get_bits1(gb)) {\n        if (get_bits_left(gb) < 64*8)\n            return AVERROR_INVALIDDATA;\n        /* chroma_non_intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            get_bits(gb, 8);\n        }\n    }\n\n    next_start_code_studio(gb);\n    return 0;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/5aba5b89d0b1d73164d3b81764828bb8b20ff32a", "file_name": "libavcodec/mpeg4videodec.c", "vul_type": "cwe-125", "description": "Write a C function to read and optionally update quantization matrices from a bitstream in an MPEG encoding context."}
{"func_name": "analyze_scene", "func_src_before": "    def analyze_scene(self, scene):\n        base_urls = scene.get_base_urls()\n        users = scene.get_users()\n        name = scene.get_name()\n        LOG.info('found the following users for scene {}: {}'.format(name, users))\n\n        # This scene might have one user who always posts the brackets on their challonge account\n        for user in users:\n            # Have we analyzed this user before?\n            sql = \"SELECT * FROM user_analyzed WHERE user='{}';\".format(user)\n            results = self.db.exec(sql)\n\n            # Did we have any matches in the database?\n            if len(results) > 0:\n                # We have analyzed this user before. Just grab one page of brackets to see if there have been any new tournaments\n                # eg, just look at /users/christmasmike?page=1 instead of all the pages that exist\n                most_recent_page = bracket_utils.get_brackets_from_user(user, pages=1)\n                for bracket in most_recent_page:\n                    LOG.info('here are the brackets from the most recent page of user {}: {}'.format(user, most_recent_page))\n                    # This user has already been analyzed, there's a good chance this bracket has been analyzed also\n                    sql = \"SELECT * FROM user_analyzed WHERE url='{}' AND user='{}';\".format(bracket, user)\n                    results = self.db.exec(sql)\n\n                    if len(results) == 0:\n                        # This is a new bracket that must have been published in the last hour or so\n                        LOG.info('found this url from a user: {} {}'.format(bracket, user))\n                        display_name = bracket_utils.get_display_base(bracket)\n                        # We don't care about doubles tournaments\n                        if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                            LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                            continue\n\n                        self.data_processor.process(bracket, name, display_name)\n\n                        # mark this bracket as analyzed\n                        sql = \"INSERT INTO user_analyzed (url, user, scene) VALUES ('{}', '{}', '{}');\".format(bracket, user, name)\n                        self.db.exec(sql)\n\n                        # Tweet that we found a new bracket\n                        msg = \"Found new {} bracket: {}\".format(name, bracket)\n                        tweet(msg)\n                    else:\n                        LOG.info('url {} is not new for user {}'.format(bracket, user))\n            else:\n                # This is a new user, analyze all brackets\n                user_urls = bracket_utils.get_brackets_from_user(user)\n                for url in user_urls:\n                    LOG.info('found this url from a user: {} {}'.format(url, user))\n                    display_name = bracket_utils.get_display_base(url)\n                    # We don't care about doubles tournaments\n                    if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                        LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                        continue\n\n                    self.data_processor.process(url, name, display_name)\n\n                    # mark this bracket as analyzed\n                    sql = \"INSERT INTO user_analyzed (url, user, scene) VALUES ('{}', '{}', '{}');\".format(url, user, name)\n                    self.db.exec(sql)\n\n                LOG.info('done with user {}'.format(user))\n\n\n        # This scene might always call their brackets the same thing, eg weekly1, weekly2, weekly3 etc\n        for base_url in base_urls:\n            # attempt to load this data from the database\n            LOG.info('About to start this analysis thread for scene {}'.format(scene.get_name()))\n            sql = \"SELECT first,last FROM valids WHERE base_url = '\" + str(base_url) + \"';\"\n            result = self.db.exec(sql)\n            has_results = len(result) > 0 \n\n            # Did we find a match in the database?\n            if has_results:\n                LOG.info(\"validURLs found values in the database\" + str(result))\n                first = result[0][0]\n                last = result[0][1]\n\n                # Check for a new valid URL\n                new_last = bracket_utils._get_last_valid_url(base_url, last-1)\n\n                if not new_last == last:\n                    if new_last - last > 5:\n                        with open(\"DEBUGOUTPUT.txt\", 'a') as f:\n                            f.write(\"[validURLs.py:55]: found a SHIT TON of new tournaments for bracket: {}\".format(base_url))\n\n                    else:\n                        bracket = base_url.replace('###', str(new_last))\n                        LOG.info('Found new bracket: {}'.format(bracket))\n                        msg = \"Found new bracket: {}\".format(bracket)\n                        tweet(msg)\n\n                    # If there's been a new last, update the database\n                    sql = \"UPDATE valids SET last=\" + str(new_last) + \" where base_url = '\"+str(base_url)+\"';\"\n                    self.db.exec(sql)\n\n\n                    # Analyze each of these new brackets\n                    for i in range(last+1, new_last+1):\n                        # Since this URL is new, we have to process the data\n                        bracket = base_url.replace('###', str(i))\n                        # Create the display name for this bracket\n                        # Eg challonge.com/NP9ATX54 -> NP9 54\n                        display_name = bracket_utils.get_display_base(bracket, counter=i)\n                        # We don't care about doubles tournaments\n                        if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                            LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                            continue\n\n                        self.data_processor.process(bracket, name, display_name, new_bracket=True)\n\n            else:\n                # We need to create first and last from scratch\n                first = bracket_utils._get_first_valid_url(base_url)\n                last = bracket_utils._get_last_valid_url(base_url, first)\n\n                # This is new data, we need to put it into the db\n                sql = \"INSERT INTO valids (base_url, first, last, scene) VALUES (\"\n                sql += \"'\"+str(base_url)+\"', \"+str(first)+ \", \"+str(last)+\", '\"+str(name)+\"');\"\n                self.db.exec(sql)\n\n                for i in range(first, last+1):\n                    bracket = base_url.replace('###', str(i))\n                    # Create the display name for this bracket\n                    # Eg challonge.com/NP9ATX54 -> NP9 54\n                    display_name = bracket_utils.get_display_base(bracket, counter=i)\n                    # We don't care about doubles tournaments\n                    if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                        LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                        continue\n\n                    self.data_processor.process(bracket, name, display_name)\n\n                    # Calculate ranks after each tournament so we can see how players are progressing\n        if not analyzed_scenes and should_tweet:\n            tweet('About to start ranking for scene {}'.format(name))\n        self.data_processor.check_and_update_ranks(name)", "func_src_after": "    def analyze_scene(self, scene):\n        base_urls = scene.get_base_urls()\n        users = scene.get_users()\n        name = scene.get_name()\n        LOG.info('found the following users for scene {}: {}'.format(name, users))\n\n        # This scene might have one user who always posts the brackets on their challonge account\n        for user in users:\n            # Have we analyzed this user before?\n            sql = \"SELECT * FROM user_analyzed WHERE user='{user}';\"\n            args = {'user': user}\n            results = self.db.exec(sql, args)\n\n            # Did we have any matches in the database?\n            if len(results) > 0:\n                # We have analyzed this user before. Just grab one page of brackets to see if there have been any new tournaments\n                # eg, just look at /users/christmasmike?page=1 instead of all the pages that exist\n                most_recent_page = bracket_utils.get_brackets_from_user(user, pages=1)\n                for bracket in most_recent_page:\n                    LOG.info('here are the brackets from the most recent page of user {}: {}'.format(user, most_recent_page))\n                    # This user has already been analyzed, there's a good chance this bracket has been analyzed also\n                    sql = \"SELECT * FROM user_analyzed WHERE url='{bracket}' AND user='{user}';\"\n                    args = {'bracket': bracket, 'user': user}\n                    results = self.db.exec(sql, args)\n\n                    if len(results) == 0:\n                        # This is a new bracket that must have been published in the last hour or so\n                        LOG.info('found this url from a user: {} {}'.format(bracket, user))\n                        display_name = bracket_utils.get_display_base(bracket)\n                        # We don't care about doubles tournaments\n                        if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                            LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                            continue\n\n                        self.data_processor.process(bracket, name, display_name)\n\n                        # mark this bracket as analyzed\n                        sql = \"INSERT INTO user_analyzed (url, user, scene) VALUES ('{bracket}', '{user}', '{name}');\"\n                        args = {'bracket': bracket, 'user':user, 'name':name}\n                        self.db.exec(sql, args)\n\n                        # Tweet that we found a new bracket\n                        msg = \"Found new {} bracket: {}\".format(name, bracket)\n                        tweet(msg)\n                    else:\n                        LOG.info('url {} is not new for user {}'.format(bracket, user))\n            else:\n                # This is a new user, analyze all brackets\n                user_urls = bracket_utils.get_brackets_from_user(user)\n                for url in user_urls:\n                    LOG.info('found this url from a user: {} {}'.format(url, user))\n                    display_name = bracket_utils.get_display_base(url)\n                    # We don't care about doubles tournaments\n                    if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                        LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                        continue\n\n                    self.data_processor.process(url, name, display_name)\n\n                    # mark this bracket as analyzed\n                    sql = \"INSERT INTO user_analyzed (url, user, scene) VALUES ('{url}', '{user}', '{name}');\"\n                    args = {'url': url, 'user':user, 'name':name}\n                    self.db.exec(sql, args)\n\n                LOG.info('done with user {}'.format(user))\n\n\n        # This scene might always call their brackets the same thing, eg weekly1, weekly2, weekly3 etc\n        for base_url in base_urls:\n            # attempt to load this data from the database\n            LOG.info('About to start this analysis thread for scene {}'.format(scene.get_name()))\n            sql = \"SELECT first,last FROM valids WHERE base_url = '{base_url}';\"\n            args = {'base_url': base_url}\n            result = self.db.exec(sql, args)\n            has_results = len(result) > 0 \n\n            # Did we find a match in the database?\n            if has_results:\n                LOG.info(\"validURLs found values in the database\" + str(result))\n                first = result[0][0]\n                last = result[0][1]\n\n                # Check for a new valid URL\n                new_last = bracket_utils._get_last_valid_url(base_url, last-1)\n\n                if not new_last == last:\n                    if new_last - last > 5:\n                        with open(\"DEBUGOUTPUT.txt\", 'a') as f:\n                            f.write(\"[validURLs.py:55]: found a SHIT TON of new tournaments for bracket: {}\".format(base_url))\n\n                    else:\n                        bracket = base_url.replace('###', str(new_last))\n                        LOG.info('Found new bracket: {}'.format(bracket))\n                        msg = \"Found new bracket: {}\".format(bracket)\n                        tweet(msg)\n\n                    # If there's been a new last, update the database\n                    sql = \"UPDATE valids SET last={new_last} where base_url='{base_url}';\"\n                    args = {'new_last': new_last, 'base_url': base_url}\n                    self.db.exec(sql, args)\n\n\n                    # Analyze each of these new brackets\n                    for i in range(last+1, new_last+1):\n                        # Since this URL is new, we have to process the data\n                        bracket = base_url.replace('###', str(i))\n                        # Create the display name for this bracket\n                        # Eg challonge.com/NP9ATX54 -> NP9 54\n                        display_name = bracket_utils.get_display_base(bracket, counter=i)\n                        # We don't care about doubles tournaments\n                        if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                            LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                            continue\n\n                        self.data_processor.process(bracket, name, display_name, new_bracket=True)\n\n            else:\n                # We need to create first and last from scratch\n                first = bracket_utils._get_first_valid_url(base_url)\n                last = bracket_utils._get_last_valid_url(base_url, first)\n\n                # This is new data, we need to put it into the db\n                sql = \"INSERT INTO valids (base_url, first, last, scene) VALUES ('{base_url}', '{first}', '{last}', '{name}');\"\n                args = {'base_url': base_url, 'first': first, 'last': last, 'name': name}\n                self.db.exec(sql, args)\n\n                for i in range(first, last+1):\n                    bracket = base_url.replace('###', str(i))\n                    # Create the display name for this bracket\n                    # Eg challonge.com/NP9ATX54 -> NP9 54\n                    display_name = bracket_utils.get_display_base(bracket, counter=i)\n                    # We don't care about doubles tournaments\n                    if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                        LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                        continue\n\n                    self.data_processor.process(bracket, name, display_name)\n\n                    # Calculate ranks after each tournament so we can see how players are progressing\n        if not analyzed_scenes and should_tweet:\n            tweet('About to start ranking for scene {}'.format(name))\n        self.data_processor.check_and_update_ranks(name)", "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "validURLs.py", "vul_type": "cwe-089", "description": "Write a Python function to analyze tournament brackets for a given scene, checking for new data and updating records accordingly."}
{"func_name": "post", "func_src_before": "    def post(self):\r\n        if (request.environ['CONTENT_TYPE'].split(';', 1)[0] == \"application/json\"):\r\n            try:\r\n                para = request.get_json()\r\n            except Exception as e:\r\n                resp = make_response((\"The json data can't be parsed\", 403, ))\r\n                return resp\r\n                \r\n            account = para['account']\r\n            password = para['password']\r\n            nickname = para['nickname']\r\n            email = para['email']\r\n            if not all((account, password, nickname, email)):\r\n                return make_response((\"Missing important data in the request\", 400, ))\r\n            tmp_re = re.compile(tmp_str)\r\n            if (len(account) > 50) or not tmp_re.match(account):\r\n                return make_response((\"The account {0} is illegal\".format(account), 400, ))\r\n            if (len(password) > 50) or not tmp_re.match(password):\r\n                return make_response((\"The password {0} is illegal\".format(password), 400, ))\r\n            if len(nickname) > 50:\r\n                return make_response((\"The nickname {0} exceed the maximum length\".format(nickname), 400, ))\r\n            if (len(email) > 100) or (len(email.split('@')) != 2):\r\n                return make_response((\"The email {0} is unacceptable\".format(nickname), 400, ))\r\n            db_session = get_session()\r\n            try:\r\n                db_user = db_session.query(UserInfo).filter_by(username = account).one()\r\n            except Exception, e:\r\n                user = UserInfo(account, email, nickname)\r\n                auth = UserAuth(account, password)\r\n                db_session.begin()\r\n                try:\r\n                    db_session.add(user)\r\n                    db_session.add(auth)\r\n                    db_session.commit()\r\n                except:\r\n                    db_session.rollback()\r\n                    return (\"DataBase Failed\", 503, )\r\n                tmp = rpc_callbacks()\r\n                RPC.register_callbacks(user.username, [tmp])\r\n                queue = RPC.create_queue(user.username, user.username)\r\n                cnn = RPC.create_connection()\r\n                RPC.create_consumer(user.username, cnn, queue)\r\n                RPC.release_consumer(user.username)\r\n                RPC.release_connection(cnn)\r\n                resp = Response(\"Account is created successfully\", 201, )\r\n                return resp\r\n            else:\r\n                if not db_user.deleted:\r\n                    return make_response((\"The account {0} is already existed\".format(account), 400, ))\r\n                else:\r\n                    auth = db_session.query(UserAuth).filter(UserAuth.account == db_user.username).first()\r\n                    if len(auth) < 1:\r\n                        return make_response((\"The account {0} is already existed\".format(account), 400, ))\r\n                    if auth.is_authenticated(password):\r\n                        db_session.begin()\r\n                        try:\r\n                            auth.activate()\r\n                            db_user.deleted = False\r\n                            db_session.add(db_user)\r\n                            db_session.commit()\r\n                        except:\r\n                            db_session.rollback()\r\n                            return (\"DataBase Failed\", 503, )\r\n                        RPC.create_queue(db_user.username, db_user.username)\r\n                        resp = Response(\"Account is recoveried successfully\", 200, {'token':auth.token})\r\n                        return resp\r\n                    else:\r\n                        return make_response((\"The account {0} is already existed\".format(account), 400, ))\r\n        else:\r\n            return make_response((\"Please upload a json data\", 403, ))", "func_src_after": "    def post(self):\r\n        if (request.environ['CONTENT_TYPE'].split(';', 1)[0] == \"application/json\"):\r\n            try:\r\n                para = request.get_json()\r\n            except Exception as e:\r\n                resp = make_response((\"The json data can't be parsed\", 403, ))\r\n                return resp\r\n            try:\r\n                account = para['account']\r\n                password = para['password']\r\n                nickname = para['nickname']\r\n                email = para['email']\r\n            except Exception as e:\r\n                return make_response((\"Parameter error\", 400, ))\r\n            nickname = escape(nickname)\r\n            if not all((account, password, nickname, email)):\r\n                return make_response((\"Missing important data in the request\", 400, ))\r\n            tmp_re = re.compile(tmp_str)\r\n            if (len(account) > 50) or not tmp_re.match(account):\r\n                return make_response((\"The account {0} is illegal\".format(account), 400, ))\r\n            if (len(password) > 50) or not tmp_re.match(password):\r\n                return make_response((\"The password {0} is illegal\".format(password), 400, ))\r\n            if len(nickname) > 50:\r\n                return make_response((\"The nickname {0} exceed the maximum length\".format(nickname), 400, ))\r\n            if (len(email) > 100) or (len(email.split('@')) != 2):\r\n                return make_response((\"The email {0} is unacceptable\".format(nickname), 400, ))\r\n            db_session = get_session()\r\n            try:\r\n                db_user = db_session.query(UserInfo).filter_by(username = account).one()\r\n            except Exception, e:\r\n                user = UserInfo(account, email, nickname)\r\n                auth = UserAuth(account, password)\r\n                db_session.begin()\r\n                try:\r\n                    db_session.add(user)\r\n                    db_session.add(auth)\r\n                    db_session.commit()\r\n                except:\r\n                    db_session.rollback()\r\n                    return (\"DataBase Failed\", 503, )\r\n                tmp = rpc_callbacks()\r\n                RPC.register_callbacks(user.username, [tmp])\r\n                queue = RPC.create_queue(user.username, user.username)\r\n                cnn = RPC.create_connection()\r\n                RPC.create_consumer(user.username, cnn, queue)\r\n                RPC.release_consumer(user.username)\r\n                RPC.release_connection(cnn)\r\n                resp = Response(\"Account is created successfully\", 201, )\r\n                return resp\r\n            else:\r\n                if not db_user.deleted:\r\n                    return make_response((\"The account {0} is already existed\".format(account), 400, ))\r\n                else:\r\n                    auth = db_session.query(UserAuth).filter(UserAuth.account == db_user.username).first()\r\n                    if len(auth) < 1:\r\n                        return make_response((\"The account {0} is already existed\".format(account), 400, ))\r\n                    if auth.is_authenticated(password):\r\n                        db_session.begin()\r\n                        try:\r\n                            auth.activate()\r\n                            db_user.deleted = False\r\n                            db_session.add(db_user)\r\n                            db_session.commit()\r\n                        except:\r\n                            db_session.rollback()\r\n                            return (\"DataBase Failed\", 503, )\r\n                        RPC.create_queue(db_user.username, db_user.username)\r\n                        resp = Response(\"Account is recoveried successfully\", 200, {'token':auth.token})\r\n                        return resp\r\n                    else:\r\n                        return make_response((\"The account {0} is already existed\".format(account), 400, ))\r\n        else:\r\n            return make_response((\"Please upload a json data\", 403, ))", "line_changes": {"deleted": [{"line_no": 8, "char_start": 313, "char_end": 331, "line": "                \r\n"}, {"line_no": 9, "char_start": 331, "char_end": 370, "line": "            account = para['account']\r\n"}, {"line_no": 10, "char_start": 370, "char_end": 411, "line": "            password = para['password']\r\n"}, {"line_no": 11, "char_start": 411, "char_end": 452, "line": "            nickname = para['nickname']\r\n"}, {"line_no": 12, "char_start": 452, "char_end": 487, "line": "            email = para['email']\r\n"}], "added": [{"line_no": 8, "char_start": 313, "char_end": 331, "line": "            try:\r\n"}, {"line_no": 9, "char_start": 331, "char_end": 374, "line": "                account = para['account']\r\n"}, {"line_no": 10, "char_start": 374, "char_end": 419, "line": "                password = para['password']\r\n"}, {"line_no": 11, "char_start": 419, "char_end": 464, "line": "                nickname = para['nickname']\r\n"}, {"line_no": 12, "char_start": 464, "char_end": 503, "line": "                email = para['email']\r\n"}, {"line_no": 13, "char_start": 503, "char_end": 539, "line": "            except Exception as e:\r\n"}, {"line_no": 14, "char_start": 539, "char_end": 605, "line": "                return make_response((\"Parameter error\", 400, ))\r\n"}, {"line_no": 15, "char_start": 605, "char_end": 646, "line": "            nickname = escape(nickname)\r\n"}]}, "char_changes": {"deleted": [{"char_start": 329, "char_end": 331, "chars": "\r\n"}], "added": [{"char_start": 325, "char_end": 331, "chars": "try:\r\n"}, {"char_start": 386, "char_end": 389, "chars": "   "}, {"char_start": 389, "char_end": 390, "chars": " "}, {"char_start": 419, "char_end": 423, "chars": "    "}, {"char_start": 476, "char_end": 480, "chars": "    "}, {"char_start": 503, "char_end": 646, "chars": "            except Exception as e:\r\n                return make_response((\"Parameter error\", 400, ))\r\n            nickname = escape(nickname)\r\n"}]}, "commit_link": "github.com/AllChat/AllChat/commit/ce07e9ac0e26295081e7476dfddd536ff030892d", "file_name": "views.py", "vul_type": "cwe-079", "commit_msg": "1. use flask.escape to escape the nickname in order to  avoid the XSS", "description": "Write a Python function to handle user account creation and reactivation with JSON input validation and database interactions."}
{"func_name": "mode_init", "func_src_before": "    def mode_init(self, request):\n        \"\"\"\n        This is called by render_POST when the client requests an init\n        mode operation (at startup)\n\n        Args:\n            request (Request): Incoming request.\n\n        \"\"\"\n        csessid = request.args.get('csessid')[0]\n\n        remote_addr = request.getClientIP()\n        host_string = \"%s (%s:%s)\" % (_SERVERNAME, request.getRequestHostname(), request.getHost().port)\n\n        sess = AjaxWebClientSession()\n        sess.client = self\n        sess.init_session(\"ajax/comet\", remote_addr, self.sessionhandler)\n\n        sess.csessid = csessid\n        csession = _CLIENT_SESSIONS(session_key=sess.csessid)\n        uid = csession and csession.get(\"webclient_authenticated_uid\", False)\n        if uid:\n            # the client session is already logged in\n            sess.uid = uid\n            sess.logged_in = True\n\n        sess.sessionhandler.connect(sess)\n\n        self.last_alive[csessid] = (time.time(), False)\n        if not self.keep_alive:\n            # the keepalive is not running; start it.\n            self.keep_alive = LoopingCall(self._keepalive)\n            self.keep_alive.start(_KEEPALIVE, now=False)\n\n        return jsonify({'msg': host_string, 'csessid': csessid})", "func_src_after": "    def mode_init(self, request):\n        \"\"\"\n        This is called by render_POST when the client requests an init\n        mode operation (at startup)\n\n        Args:\n            request (Request): Incoming request.\n\n        \"\"\"\n        csessid = cgi.escape(request.args['csessid'][0])\n\n        remote_addr = request.getClientIP()\n        host_string = \"%s (%s:%s)\" % (_SERVERNAME, request.getRequestHostname(), request.getHost().port)\n\n        sess = AjaxWebClientSession()\n        sess.client = self\n        sess.init_session(\"ajax/comet\", remote_addr, self.sessionhandler)\n\n        sess.csessid = csessid\n        csession = _CLIENT_SESSIONS(session_key=sess.csessid)\n        uid = csession and csession.get(\"webclient_authenticated_uid\", False)\n        if uid:\n            # the client session is already logged in\n            sess.uid = uid\n            sess.logged_in = True\n\n        sess.sessionhandler.connect(sess)\n\n        self.last_alive[csessid] = (time.time(), False)\n        if not self.keep_alive:\n            # the keepalive is not running; start it.\n            self.keep_alive = LoopingCall(self._keepalive)\n            self.keep_alive.start(_KEEPALIVE, now=False)\n\n        return jsonify({'msg': host_string, 'csessid': csessid})", "commit_link": "github.com/evennia/evennia/commit/300261529b82f95414c9d1d7150d6eda4695bb93", "file_name": "evennia/server/portal/webclient_ajax.py", "vul_type": "cwe-079", "description": "In Python, write a function `mode_init` that initializes a web client session and handles keep-alive upon receiving a POST request."}
{"func_name": "load_yaml", "func_src_before": "    def load_yaml(self, file):\n        data = yaml.load(file)\n        for concept_type_key, vocabs in data.items():\n            concept_type = {\n                'classification_schemes': ClassificationRecord,\n                'subject_schemes': AuthorityRecord,\n            }.get(concept_type_key)\n            for scheme_code, options in vocabs.items():\n                if is_str(options):\n                    options = {'base_uri': options}\n                self.entries[scheme_code] = ConceptScheme(concept_type, scheme_code, options=options)", "func_src_after": "    def load_yaml(self, file):\n        data = yaml.safe_load(file)\n        for concept_type_key, vocabs in data.items():\n            concept_type = {\n                'classification_schemes': ClassificationRecord,\n                'subject_schemes': AuthorityRecord,\n            }.get(concept_type_key)\n            for scheme_code, options in vocabs.items():\n                if is_str(options):\n                    options = {'base_uri': options}\n                self.entries[scheme_code] = ConceptScheme(concept_type, scheme_code, options=options)", "line_changes": {"deleted": [{"line_no": 2, "char_start": 31, "char_end": 62, "line": "        data = yaml.load(file)\n"}], "added": [{"line_no": 2, "char_start": 31, "char_end": 67, "line": "        data = yaml.safe_load(file)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 51, "char_end": 56, "chars": "safe_"}]}, "commit_link": "github.com/scriptotek/mc2skos/commit/b0cb78b091f64e86c2357acbde5a0bb3b939deaa", "file_name": "vocabularies.py", "vul_type": "cwe-502", "commit_msg": "Use safe yaml loading", "parent_commit": "b58de96a2949046e56ea6e4e5c6d6116b9d0c560", "description": "Write a Python function to load data from a YAML file and process it into a dictionary of concept schemes."}
{"func_name": "main", "func_src_before": "int main (int argc, char **argv) {\n\tint result;\n\tstruct mt_packet data;\n\tstruct sockaddr_in si_me;\n\tunsigned char buff[1500];\n\tunsigned char print_help = 0, have_username = 0, have_password = 0;\n\tunsigned char drop_priv = 0;\n\tint c;\n\tint optval = 1;\n\n\tsetlocale(LC_ALL, \"\");\n\tbindtextdomain(\"mactelnet\",\"/usr/share/locale\");\n\ttextdomain(\"mactelnet\");\n\n\t/* Set default for ssh_path. */\n\tstrncpy(ssh_path, SSH_PATH, sizeof(ssh_path) -1);\n\tssh_path[sizeof(ssh_path)] = '\\0';\n\n    /* Ignore args after -- for MAC-Telnet client. */\n\tint mactelnet_argc = argc;\n\tint i;\n\tfor (i=0; i < argc; i++) {\n\t\tif (strlen(argv[i]) == 2 && strncmp(argv[i], \"--\", 2) == 0) {\n\t\t\tmactelnet_argc = i;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\twhile (1) {\n\t\tc = getopt(mactelnet_argc, argv, \"nqlt:u:p:vh?SFP:c:U:\");\n\n\t\tif (c == -1) {\n\t\t\tbreak;\n\t\t}\n\n\t\tswitch (c) {\n\n\t\t\tcase 'n':\n\t\t\t\tuse_raw_socket = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'S':\n\t\t\t\ttunnel_conn = 1;\n\t\t\t\tlaunch_ssh = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'F':\n\t\t\t\ttunnel_conn = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'P':\n\t\t\t\tfwdport = atoi(optarg);\n\t\t\t\tbreak;\n\n\t\t\tcase 'u':\n\t\t\t\t/* Save username */\n\t\t\t\tstrncpy(username, optarg, sizeof(username) - 1);\n\t\t\t\tusername[sizeof(username) - 1] = '\\0';\n\t\t\t\thave_username = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'p':\n\t\t\t\t/* Save password */\n\t\t\t\tstrncpy(password, optarg, sizeof(password) - 1);\n\t\t\t\tpassword[sizeof(password) - 1] = '\\0';\n\t\t\t\thave_password = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'U':\n\t\t\t\t/* Save nonpriv_username */\n\t\t\t\tstrncpy(nonpriv_username, optarg, sizeof(nonpriv_username) - 1);\n\t\t\t\tnonpriv_username[sizeof(nonpriv_username) - 1] = '\\0';\n\t\t\t\tdrop_priv = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'c':\n\t\t\t\t/* Save ssh executable path */\n\t\t\t\tstrncpy(ssh_path, optarg, sizeof(ssh_path) -1);\n\t\t\t\tssh_path[sizeof(ssh_path)] = '\\0';\n\t\t\t\tbreak;\n\n\t\t\tcase 't':\n\t\t\t\tconnect_timeout = atoi(optarg);\n\t\t\t\tbreak;\n\n\t\t\tcase 'l':\n\t\t\t\treturn mndp();\n\t\t\t\tbreak;\n\n\t\t\tcase 'v':\n\t\t\t\tprint_version();\n\t\t\t\texit(0);\n\t\t\t\tbreak;\n\n\t\t\tcase 'q':\n\t\t\t\tquiet_mode = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'h':\n\t\t\tcase '?':\n\t\t\t\tprint_help = 1;\n\t\t\t\tbreak;\n\n\t\t}\n\t}\n\tif (argc - optind < 1 || print_help) {\n\t\tprint_version();\n\t\tfprintf(stderr, _(\"Usage: %s <MAC|identity> [-v] [-h] [-q] [-n] [-l] [-S] [-P <port>]\\n\"\n\t\t\t\t          \"       [-t <timeout>] [-u <user>] [-p <pass>] [-c <path>] [-U <user>]\\n\"), argv[0]);\n\n\t\tif (print_help) {\n\t\t\tfprintf(stderr, _(\"\\nParameters:\\n\"\n\t\t\t\"  MAC           MAC-Address of the RouterOS/mactelnetd device. Use mndp to \\n\"\n            \"                discover it.\\n\"\n\t\t\t\"  identity      The identity/name of your destination device. Uses MNDP \\n\"\n\t\t\t\"                protocol to find it.\\n\"\n\t\t\t\"  -l            List/Search for routers nearby. (using MNDP)\\n\"\n\t\t\t\"  -n            Do not use broadcast packets. Less insecure but requires root \\n\"\n\t\t    \"                privileges.\\n\"\n\t\t\t\"  -t <timeout>  Amount of seconds to wait for a response on each interface.\\n\"\n\t\t\t\"  -u <user>     Specify username on command line.\\n\"\n\t\t\t\"  -p <pass>     Specify password on command line.\\n\"\n\t\t\t\"  -U <user>     Drop privileges by switching to user, when the command is\\n\"\n\t\t\t\"                run as a privileged user in conjunction with the -n option.\\n\"\n\t\t\t\"  -S            Use MAC-SSH instead of MAC-Telnet. (Implies -F)\\n\"\n\t\t    \"                Forward SSH connection through MAC-Telnet and launch SSH client.\\n\"\n\t\t\t\"  -F            Forward connection through of MAC-Telnet without launching the \\n\"\n\t\t    \"                SSH Client.\\n\"\n\t\t\t\"  -P <port>     Local TCP port for forwarding SSH connection.\\n\"\n\t\t\t\"                (If not specified, port 2222 by default.)\\n\"\n\t\t\t\"  -c <path>     Path for ssh client executable. (Default: /usr/bin/ssh)\\n\"\n\t\t\t\"  -q            Quiet mode.\\n\"\n\t\t\t\"  -v            Print version and exit.\\n\"\n\t\t\t\"  -h            Print help and exit.\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"All arguments after '--' will be passed to the ssh client command.\\n\"\n\t\t\t\"\\n\"));\n\t\t}\n\t\treturn 1;\n\t}\n\n\t/* Setup command line for ssh client */\n\tif (launch_ssh) {\n\t\tint ssh_argc;\n\t\tint add_argc;\n\t\tssh_argc = argc - mactelnet_argc;\n\t\tadd_argc = ssh_argc;\n\t\tssh_argc += 3; /* Port option and hostname: -p <port> <host>*/\n\t\tif (have_username) {\n\t\t\tssh_argc += 2;  /* Login name option: -l <user> */\n\t\t}\n\t\tssh_argv = (char **) calloc(sizeof(char *), ssh_argc + 1);\n\t\tchar *ssh_path_c = strndup(ssh_path, sizeof(ssh_path) - 1);\n\t\tchar *ssh_filename = basename(ssh_path_c);\n\t\tint idx = 0;\n\t\tssh_argv[idx++] = ssh_filename;\n\t\tint i;\n\t\tfor (i = 1; i < add_argc; i++) {\n\t\t\tssh_argv[idx++] = argv[mactelnet_argc + i];\n\t\t}\n\t\tchar portstr[8];\n\t\tsnprintf(portstr, 8, \"%d\", fwdport);\n\t\tssh_argv[idx++] = strdup(\"-p\");\n\t\tssh_argv[idx++] = strndup(portstr, sizeof(portstr) - 1);\n\t\tif (have_username) {\n\t\t\tssh_argv[idx++] = strdup(\"-l\");\n\t\t\tssh_argv[idx++] = username;\n\t\t}\n\t\tssh_argv[idx++] = strdup(\"127.0.0.1\");\n\t\tssh_argv[idx++] = (char*) 0;\n\t}\n\n\tis_a_tty = isatty(fileno(stdout)) && isatty(fileno(stdin));\n\tif (!is_a_tty) {\n\t\tquiet_mode = 1;\n\t}\n\n\t/* Seed randomizer */\n\tsrand(time(NULL));\n\n\tif (use_raw_socket) {\n\t\tif (geteuid() != 0) {\n\t\t\tfprintf(stderr, _(\"You need to have root privileges to use the -n parameter.\\n\"));\n\t\t\treturn 1;\n\t\t}\n\n\t\tsockfd = net_init_raw_socket();\n\t}\n\n\tif (drop_priv) {\n\t\tdrop_privileges(nonpriv_username);\n\t}\n\n\t/* Receive regular udp packets with this socket */\n\tinsockfd = socket(AF_INET, SOCK_DGRAM, IPPROTO_UDP);\n\tif (insockfd < 0) {\n\t\tperror(\"insockfd\");\n\t\treturn 1;\n\t}\n\n\tif (!use_raw_socket) {\n\t\tif (setsockopt(insockfd, SOL_SOCKET, SO_BROADCAST, &optval, sizeof (optval))==-1) {\n\t\t\tperror(\"SO_BROADCAST\");\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\t/* Need to use, to be able to autodetect which interface to use */\n\tsetsockopt(insockfd, SOL_SOCKET, SO_REUSEADDR, &optval, sizeof (optval));\n\n\t/* Get mac-address from string, or check for hostname via mndp */\n\tif (!query_mndp_or_mac(argv[optind], dstmac, !quiet_mode)) {\n\t\t/* No valid mac address found, abort */\n\t\treturn 1;\n\t}\n\n\tif (!tunnel_conn && !have_username) {\n\t\tif (!quiet_mode) {\n\t\t\tprintf(_(\"Login: \"));\n\t\t}\n\t\tscanf(\"%254s\", username);\n\t}\n\n\tif (!tunnel_conn && !have_password) {\n\t\tchar *tmp;\n\t\ttmp = getpass(quiet_mode ? \"\" : _(\"Password: \"));\n\t\tstrncpy(password, tmp, sizeof(password) - 1);\n\t\tpassword[sizeof(password) - 1] = '\\0';\n\t\t/* security */\n\t\tmemset(tmp, 0, strlen(tmp));\n#ifdef __GNUC__\n\t\tfree(tmp);\n#endif\n\t}\n\n\tif (tunnel_conn) {\n\t\t/* Setup signal handler for broken tunnels. */\n\t\tsignal(SIGPIPE,SIG_IGN);\n\n\t\t/* Setup Server socket for receiving connection from local SSH Client. */\n\t\tint fwdsrvfd;\n\t\tfwdsrvfd = socket(PF_INET, SOCK_STREAM, IPPROTO_TCP);\n\t\tif (fwdsrvfd < 0) {\n\t\t\tperror(\"fwdsrvfd\");\n\t\t\treturn 1;\n\t\t}\n\t\tif(setsockopt(fwdsrvfd, SOL_SOCKET, SO_REUSEADDR, &optval, sizeof (optval)) < 0) {\n\t\t\tperror(\"SO_REUSEADDR\");\n\t\t\treturn 1;\n\t\t}\n\n\t\t/* Bind to server socket for receiving terminal client connection. */\n\t\tstruct sockaddr_in srv_socket;\n\t\tmemset(&srv_socket, 0, sizeof(srv_socket));\n\t\tsrv_socket.sin_family = AF_INET;\n\t\tsrv_socket.sin_port = htons(fwdport);\n\t\tsrv_socket.sin_addr.s_addr = inet_addr(\"127.0.0.1\");\n\t\tif (bind(fwdsrvfd, (struct sockaddr *) &srv_socket, sizeof(srv_socket)) < 0) {\n\t\t\tfprintf(stderr, _(\"Error binding to %s:%d, %s\\n\"), \"127.0.0.1\", fwdport, strerror(errno));\n\t\t\treturn 1;\n\t\t}\n\t\tif (listen(fwdsrvfd, 1) < 0) {\n\t\t\tfprintf(stderr, _(\"Failed listen on server socket %s:%d, %s\\n\"), \"127.0.0.1\", fwdport, strerror(errno));\n\t\t\treturn 1;\n\t\t}\n\n\t\t/* Fork child to execute SSH Client locally and connect to parent\n\t\t * waiting for connection from child if launch_ssh is requested.\n\t\t */\n\t\tint pid;\n\t\tif (launch_ssh) {\n\t\t\tpid = fork();\n\t\t}\n\n\t\tif (!launch_ssh || pid > 0) {\n\t\t\t/* Parent code. Waits for connection to local end of tunnel */\n\n\t\t\t/* Close stdin and stdout, leave stderr active for error messages.\n\t\t\t * The terminal will be handled by client connecting to local end of tunnel. */\n\t\t\tclose(0);\n\t\t\tclose(1);\n\n\t\t\t/* Wait for remote terminal client connection on server port. */\n\t\t\tfprintf(stderr, _(\"Waiting for tunnel connection on port: %d\\n\"), fwdport);\n\t\t\tstruct sockaddr_in cli_socket;\n\t\t\tunsigned int cli_socket_len = sizeof(cli_socket);\n\t\t\tmemset(&cli_socket, 0, sizeof(cli_socket));\n\t\t\tif ((fwdfd = accept(fwdsrvfd, (struct sockaddr *) &cli_socket, &cli_socket_len)) < 0) {\n\t\t\t\tperror(\"fwdfd\");\n\t\t\t}\n\t\t\tif(setsockopt(fwdfd, SOL_SOCKET, SO_KEEPALIVE, &optval, sizeof(optval)) < 0) {\n\t\t\t\tperror(\"SO_KEEPALIVE\");\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t\tfprintf(stderr, _(\"Client connected to tunnel from port: %d\\n\"), ntohs(cli_socket.sin_port));\n\t\t}\n\t\telse if (launch_ssh && pid == 0) {\n\t\t\t/* Child Code. Executes SSH Client and connects to parent to tunnel\n\t\t\t * connection through MAC-Telnet protocol. */\n\t\t\tif (use_raw_socket) {\n\t\t\t\tclose(sockfd);\n\t\t\t}\n\t\t\tclose(insockfd);\n\t\t\tclose(fwdsrvfd);\n\n\t\t\t/* Give time to parent to initialize listening port. */\n\t\t\tsleep(2);\n\n\t\t\t/* Execute SSH Client. */\n\t\t\texecvp(ssh_path, ssh_argv);\n\t\t\tperror(\"Execution of terminal client failed.\");\n\t\t\texit(1);\n\t\t}\n\t\t/* Fork failure. */\n\t\telse {\n\t\t\tfprintf(stderr, _(\"Execution of terminal client failed.\\n\"));\n\t\t\tif (use_raw_socket) {\n\t\t\t\tclose(sockfd);\n\t\t\t}\n\t\t\tclose(insockfd);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\t/* Set random source port */\n\tsourceport = 1024 + (rand() % 1024);\n\n\t/* Set up global info about the connection */\n\tinet_pton(AF_INET, (char *)\"255.255.255.255\", &destip);\n\tmemcpy(&sourceip, &(si_me.sin_addr), IPV4_ALEN);\n\n\t/* Session key */\n\tsessionkey = rand() % 65535;\n\n\t/* stop output buffering */\n\tsetvbuf(stdout, (char*)NULL, _IONBF, 0);\n\n\tif (!quiet_mode) {\n\t\tprintf(_(\"Connecting to %s...\"), ether_ntoa((struct ether_addr *)dstmac));\n\t}\n\n\t/* Initialize receiving socket on the device chosen */\n\tmemset((char *) &si_me, 0, sizeof(si_me));\n\tsi_me.sin_family = AF_INET;\n\tsi_me.sin_port = htons(sourceport);\n\n\t/* Bind to udp port */\n\tif (bind(insockfd, (struct sockaddr *)&si_me, sizeof(si_me)) == -1) {\n\t\tfprintf(stderr, _(\"Error binding to %s:%d, %s\\n\"), inet_ntoa(si_me.sin_addr), sourceport, strerror(errno));\n\t\treturn 1;\n\t}\n\n\tif (!find_interface() || (result = recvfrom(insockfd, buff, 1400, 0, 0, 0)) < 1) {\n\t\tfprintf(stderr, _(\"Connection failed.\\n\"));\n\t\treturn 1;\n\t}\n\tif (!quiet_mode) {\n\t\tprintf(_(\"done\\n\"));\n\t}\n\n\t/* Handle first received packet */\n\thandle_packet(buff, result);\n\n\tinit_packet(&data, MT_PTYPE_DATA, srcmac, dstmac, sessionkey, 0);\n\toutcounter +=  add_control_packet(&data, MT_CPTYPE_BEGINAUTH, NULL, 0);\n\n\t/* TODO: handle result of send_udp */\n\tresult = send_udp(&data, 1);\n\n\twhile (running) {\n\t\tfd_set read_fds;\n\t\tint reads;\n\t\tstatic int terminal_gone = 0;\n\t\tstruct timeval timeout;\n\n\t\tint maxfd = 0;\n\t\tmaxfd = insockfd > fwdfd ? insockfd : fwdfd;\n\n\t\t/* Init select */\n\t\tFD_ZERO(&read_fds);\n\t\tif (!tunnel_conn && !terminal_gone) {\n\t\t\t/* Setup fd to read input from terminal. */\n\t\t\tFD_SET(0, &read_fds);\n\t\t}\n\t\telse if (tunnel_conn) {\n\t\t\t/* Setup fd to read input from local SSH Client. */\n\t\t\tFD_SET(fwdfd, &read_fds);\n\t\t}\n\t\tFD_SET(insockfd, &read_fds);\n\n\t\ttimeout.tv_sec = 1;\n\t\ttimeout.tv_usec = 0;\n\n\t\t/* Wait for data or timeout */\n\t\treads = select(maxfd+1, &read_fds, NULL, NULL, &timeout);\n\t\tif (reads > 0) {\n\t\t\t/* Handle data from server */\n\t\t\tif (FD_ISSET(insockfd, &read_fds)) {\n\t\t\t\tbzero(buff, 1500);\n\t\t\t\tresult = recvfrom(insockfd, buff, 1500, 0, 0, 0);\n\t\t\t\thandle_packet(buff, result);\n\t\t\t}\n\t\t\tunsigned char keydata[512];\n\t\t\tint datalen = 0;\n\t\t\t/* Handle data from keyboard/local terminal */\n\t\t\tif (!tunnel_conn && FD_ISSET(0, &read_fds) && terminal_mode) {\n\t\t\t\tdatalen = read(STDIN_FILENO, &keydata, 512);\n\t\t\t}\n\t\t\t/* Handle data from local SSH client */\n\t\t\tif (tunnel_conn && FD_ISSET(fwdfd, &read_fds)) {\n\t\t\t\tdatalen = read(fwdfd, &keydata, 512);\n\t\t\t}\n\t\t\tif (datalen > 0) {\n\t\t\t\t/* Data received, transmit to server */\n\t\t\t\tinit_packet(&data, MT_PTYPE_DATA, srcmac, dstmac, sessionkey, outcounter);\n\t\t\t\tadd_control_packet(&data, MT_CPTYPE_PLAINDATA, &keydata, datalen);\n\t\t\t\toutcounter += datalen;\n\t\t\t\tsend_udp(&data, 1);\n\t\t\t}\n\t\t\telse if (datalen < 0) {\n\t\t\t\tterminal_gone = 1;\n\t\t\t}\n\t\t/* Handle select() timeout */\n\t\t} else {\n\t\t\t/* handle keepalive counter, transmit keepalive packet every 10 seconds\n\t\t\t   of inactivity  */\n\t\t\tif (keepalive_counter++ == 10) {\n\t\t\t\tstruct mt_packet odata;\n\t\t\t\tinit_packet(&odata, MT_PTYPE_ACK, srcmac, dstmac, sessionkey, outcounter);\n\t\t\t\tsend_udp(&odata, 0);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (!tunnel_conn && is_a_tty && terminal_mode) {\n\t\t/* Reset terminal back to old settings */\n\t\treset_term();\n\t}\n\n\tclose(sockfd);\n\tclose(insockfd);\n\tif (tunnel_conn && fwdfd > 0) {\n\t\tclose(fwdfd);\n\t}\n\n\treturn 0;\n}", "func_src_after": "int main (int argc, char **argv) {\n\tint result;\n\tstruct mt_packet data;\n\tstruct sockaddr_in si_me;\n\tunsigned char buff[1500];\n\tunsigned char print_help = 0, have_username = 0, have_password = 0;\n\tunsigned char drop_priv = 0;\n\tint c;\n\tint optval = 1;\n\n\tsetlocale(LC_ALL, \"\");\n\tbindtextdomain(\"mactelnet\",\"/usr/share/locale\");\n\ttextdomain(\"mactelnet\");\n\n\t/* Set default for ssh_path. */\n\tstrncpy(ssh_path, SSH_PATH, sizeof(ssh_path) - 1);\n\tssh_path[sizeof(ssh_path) - 1] = '\\0';\n\n    /* Ignore args after -- for MAC-Telnet client. */\n\tint mactelnet_argc = argc;\n\tint i;\n\tfor (i=0; i < argc; i++) {\n\t\tif (strlen(argv[i]) == 2 && strncmp(argv[i], \"--\", 2) == 0) {\n\t\t\tmactelnet_argc = i;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\twhile (1) {\n\t\tc = getopt(mactelnet_argc, argv, \"nqlt:u:p:vh?SFP:c:U:\");\n\n\t\tif (c == -1) {\n\t\t\tbreak;\n\t\t}\n\n\t\tswitch (c) {\n\n\t\t\tcase 'n':\n\t\t\t\tuse_raw_socket = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'S':\n\t\t\t\ttunnel_conn = 1;\n\t\t\t\tlaunch_ssh = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'F':\n\t\t\t\ttunnel_conn = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'P':\n\t\t\t\tfwdport = atoi(optarg);\n\t\t\t\tbreak;\n\n\t\t\tcase 'u':\n\t\t\t\t/* Save username */\n\t\t\t\tstrncpy(username, optarg, sizeof(username) - 1);\n\t\t\t\tusername[sizeof(username) - 1] = '\\0';\n\t\t\t\thave_username = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'p':\n\t\t\t\t/* Save password */\n\t\t\t\tstrncpy(password, optarg, sizeof(password) - 1);\n\t\t\t\tpassword[sizeof(password) - 1] = '\\0';\n\t\t\t\thave_password = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'U':\n\t\t\t\t/* Save nonpriv_username */\n\t\t\t\tstrncpy(nonpriv_username, optarg, sizeof(nonpriv_username) - 1);\n\t\t\t\tnonpriv_username[sizeof(nonpriv_username) - 1] = '\\0';\n\t\t\t\tdrop_priv = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'c':\n\t\t\t\t/* Save ssh executable path */\n\t\t\t\tstrncpy(ssh_path, optarg, sizeof(ssh_path) - 1);\n\t\t\t\tssh_path[sizeof(ssh_path) - 1] = '\\0';\n\t\t\t\tbreak;\n\n\t\t\tcase 't':\n\t\t\t\tconnect_timeout = atoi(optarg);\n\t\t\t\tbreak;\n\n\t\t\tcase 'l':\n\t\t\t\treturn mndp();\n\t\t\t\tbreak;\n\n\t\t\tcase 'v':\n\t\t\t\tprint_version();\n\t\t\t\texit(0);\n\t\t\t\tbreak;\n\n\t\t\tcase 'q':\n\t\t\t\tquiet_mode = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'h':\n\t\t\tcase '?':\n\t\t\t\tprint_help = 1;\n\t\t\t\tbreak;\n\n\t\t}\n\t}\n\tif (argc - optind < 1 || print_help) {\n\t\tprint_version();\n\t\tfprintf(stderr, _(\"Usage: %s <MAC|identity> [-v] [-h] [-q] [-n] [-l] [-S] [-P <port>]\\n\"\n\t\t\t\t          \"       [-t <timeout>] [-u <user>] [-p <pass>] [-c <path>] [-U <user>]\\n\"), argv[0]);\n\n\t\tif (print_help) {\n\t\t\tfprintf(stderr, _(\"\\nParameters:\\n\"\n\t\t\t\"  MAC           MAC-Address of the RouterOS/mactelnetd device. Use mndp to \\n\"\n            \"                discover it.\\n\"\n\t\t\t\"  identity      The identity/name of your destination device. Uses MNDP \\n\"\n\t\t\t\"                protocol to find it.\\n\"\n\t\t\t\"  -l            List/Search for routers nearby. (using MNDP)\\n\"\n\t\t\t\"  -n            Do not use broadcast packets. Less insecure but requires root \\n\"\n\t\t    \"                privileges.\\n\"\n\t\t\t\"  -t <timeout>  Amount of seconds to wait for a response on each interface.\\n\"\n\t\t\t\"  -u <user>     Specify username on command line.\\n\"\n\t\t\t\"  -p <pass>     Specify password on command line.\\n\"\n\t\t\t\"  -U <user>     Drop privileges by switching to user, when the command is\\n\"\n\t\t\t\"                run as a privileged user in conjunction with the -n option.\\n\"\n\t\t\t\"  -S            Use MAC-SSH instead of MAC-Telnet. (Implies -F)\\n\"\n\t\t    \"                Forward SSH connection through MAC-Telnet and launch SSH client.\\n\"\n\t\t\t\"  -F            Forward connection through of MAC-Telnet without launching the \\n\"\n\t\t    \"                SSH Client.\\n\"\n\t\t\t\"  -P <port>     Local TCP port for forwarding SSH connection.\\n\"\n\t\t\t\"                (If not specified, port 2222 by default.)\\n\"\n\t\t\t\"  -c <path>     Path for ssh client executable. (Default: /usr/bin/ssh)\\n\"\n\t\t\t\"  -q            Quiet mode.\\n\"\n\t\t\t\"  -v            Print version and exit.\\n\"\n\t\t\t\"  -h            Print help and exit.\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"All arguments after '--' will be passed to the ssh client command.\\n\"\n\t\t\t\"\\n\"));\n\t\t}\n\t\treturn 1;\n\t}\n\n\t/* Setup command line for ssh client */\n\tif (launch_ssh) {\n\t\tint ssh_argc;\n\t\tint add_argc;\n\t\tssh_argc = argc - mactelnet_argc;\n\t\tadd_argc = ssh_argc;\n\t\tssh_argc += 3; /* Port option and hostname: -p <port> <host>*/\n\t\tif (have_username) {\n\t\t\tssh_argc += 2;  /* Login name option: -l <user> */\n\t\t}\n\t\tssh_argv = (char **) calloc(sizeof(char *), ssh_argc + 1);\n\t\tchar *ssh_path_c = strndup(ssh_path, sizeof(ssh_path) - 1);\n\t\tchar *ssh_filename = basename(ssh_path_c);\n\t\tint idx = 0;\n\t\tssh_argv[idx++] = ssh_filename;\n\t\tint i;\n\t\tfor (i = 1; i < add_argc; i++) {\n\t\t\tssh_argv[idx++] = argv[mactelnet_argc + i];\n\t\t}\n\t\tchar portstr[8];\n\t\tsnprintf(portstr, 8, \"%d\", fwdport);\n\t\tssh_argv[idx++] = strdup(\"-p\");\n\t\tssh_argv[idx++] = strndup(portstr, sizeof(portstr) - 1);\n\t\tif (have_username) {\n\t\t\tssh_argv[idx++] = strdup(\"-l\");\n\t\t\tssh_argv[idx++] = username;\n\t\t}\n\t\tssh_argv[idx++] = strdup(\"127.0.0.1\");\n\t\tssh_argv[idx++] = (char*) 0;\n\t}\n\n\tis_a_tty = isatty(fileno(stdout)) && isatty(fileno(stdin));\n\tif (!is_a_tty) {\n\t\tquiet_mode = 1;\n\t}\n\n\t/* Seed randomizer */\n\tsrand(time(NULL));\n\n\tif (use_raw_socket) {\n\t\tif (geteuid() != 0) {\n\t\t\tfprintf(stderr, _(\"You need to have root privileges to use the -n parameter.\\n\"));\n\t\t\treturn 1;\n\t\t}\n\n\t\tsockfd = net_init_raw_socket();\n\t}\n\n\tif (drop_priv) {\n\t\tdrop_privileges(nonpriv_username);\n\t}\n\n\t/* Receive regular udp packets with this socket */\n\tinsockfd = socket(AF_INET, SOCK_DGRAM, IPPROTO_UDP);\n\tif (insockfd < 0) {\n\t\tperror(\"insockfd\");\n\t\treturn 1;\n\t}\n\n\tif (!use_raw_socket) {\n\t\tif (setsockopt(insockfd, SOL_SOCKET, SO_BROADCAST, &optval, sizeof (optval))==-1) {\n\t\t\tperror(\"SO_BROADCAST\");\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\t/* Need to use, to be able to autodetect which interface to use */\n\tsetsockopt(insockfd, SOL_SOCKET, SO_REUSEADDR, &optval, sizeof (optval));\n\n\t/* Get mac-address from string, or check for hostname via mndp */\n\tif (!query_mndp_or_mac(argv[optind], dstmac, !quiet_mode)) {\n\t\t/* No valid mac address found, abort */\n\t\treturn 1;\n\t}\n\n\tif (!tunnel_conn && !have_username) {\n\t\tif (!quiet_mode) {\n\t\t\tprintf(_(\"Login: \"));\n\t\t}\n\t\tscanf(\"%254s\", username);\n\t}\n\n\tif (!tunnel_conn && !have_password) {\n\t\tchar *tmp;\n\t\ttmp = getpass(quiet_mode ? \"\" : _(\"Password: \"));\n\t\tstrncpy(password, tmp, sizeof(password) - 1);\n\t\tpassword[sizeof(password) - 1] = '\\0';\n\t\t/* security */\n\t\tmemset(tmp, 0, strlen(tmp));\n#ifdef __GNUC__\n\t\tfree(tmp);\n#endif\n\t}\n\n\tif (tunnel_conn) {\n\t\t/* Setup signal handler for broken tunnels. */\n\t\tsignal(SIGPIPE,SIG_IGN);\n\n\t\t/* Setup Server socket for receiving connection from local SSH Client. */\n\t\tint fwdsrvfd;\n\t\tfwdsrvfd = socket(PF_INET, SOCK_STREAM, IPPROTO_TCP);\n\t\tif (fwdsrvfd < 0) {\n\t\t\tperror(\"fwdsrvfd\");\n\t\t\treturn 1;\n\t\t}\n\t\tif(setsockopt(fwdsrvfd, SOL_SOCKET, SO_REUSEADDR, &optval, sizeof (optval)) < 0) {\n\t\t\tperror(\"SO_REUSEADDR\");\n\t\t\treturn 1;\n\t\t}\n\n\t\t/* Bind to server socket for receiving terminal client connection. */\n\t\tstruct sockaddr_in srv_socket;\n\t\tmemset(&srv_socket, 0, sizeof(srv_socket));\n\t\tsrv_socket.sin_family = AF_INET;\n\t\tsrv_socket.sin_port = htons(fwdport);\n\t\tsrv_socket.sin_addr.s_addr = inet_addr(\"127.0.0.1\");\n\t\tif (bind(fwdsrvfd, (struct sockaddr *) &srv_socket, sizeof(srv_socket)) < 0) {\n\t\t\tfprintf(stderr, _(\"Error binding to %s:%d, %s\\n\"), \"127.0.0.1\", fwdport, strerror(errno));\n\t\t\treturn 1;\n\t\t}\n\t\tif (listen(fwdsrvfd, 1) < 0) {\n\t\t\tfprintf(stderr, _(\"Failed listen on server socket %s:%d, %s\\n\"), \"127.0.0.1\", fwdport, strerror(errno));\n\t\t\treturn 1;\n\t\t}\n\n\t\t/* Fork child to execute SSH Client locally and connect to parent\n\t\t * waiting for connection from child if launch_ssh is requested.\n\t\t */\n\t\tint pid;\n\t\tif (launch_ssh) {\n\t\t\tpid = fork();\n\t\t}\n\n\t\tif (!launch_ssh || pid > 0) {\n\t\t\t/* Parent code. Waits for connection to local end of tunnel */\n\n\t\t\t/* Close stdin and stdout, leave stderr active for error messages.\n\t\t\t * The terminal will be handled by client connecting to local end of tunnel. */\n\t\t\tclose(0);\n\t\t\tclose(1);\n\n\t\t\t/* Wait for remote terminal client connection on server port. */\n\t\t\tfprintf(stderr, _(\"Waiting for tunnel connection on port: %d\\n\"), fwdport);\n\t\t\tstruct sockaddr_in cli_socket;\n\t\t\tunsigned int cli_socket_len = sizeof(cli_socket);\n\t\t\tmemset(&cli_socket, 0, sizeof(cli_socket));\n\t\t\tif ((fwdfd = accept(fwdsrvfd, (struct sockaddr *) &cli_socket, &cli_socket_len)) < 0) {\n\t\t\t\tperror(\"fwdfd\");\n\t\t\t}\n\t\t\tif(setsockopt(fwdfd, SOL_SOCKET, SO_KEEPALIVE, &optval, sizeof(optval)) < 0) {\n\t\t\t\tperror(\"SO_KEEPALIVE\");\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t\tfprintf(stderr, _(\"Client connected to tunnel from port: %d\\n\"), ntohs(cli_socket.sin_port));\n\t\t}\n\t\telse if (launch_ssh && pid == 0) {\n\t\t\t/* Child Code. Executes SSH Client and connects to parent to tunnel\n\t\t\t * connection through MAC-Telnet protocol. */\n\t\t\tif (use_raw_socket) {\n\t\t\t\tclose(sockfd);\n\t\t\t}\n\t\t\tclose(insockfd);\n\t\t\tclose(fwdsrvfd);\n\n\t\t\t/* Give time to parent to initialize listening port. */\n\t\t\tsleep(2);\n\n\t\t\t/* Execute SSH Client. */\n\t\t\texecvp(ssh_path, ssh_argv);\n\t\t\tperror(\"Execution of terminal client failed.\");\n\t\t\texit(1);\n\t\t}\n\t\t/* Fork failure. */\n\t\telse {\n\t\t\tfprintf(stderr, _(\"Execution of terminal client failed.\\n\"));\n\t\t\tif (use_raw_socket) {\n\t\t\t\tclose(sockfd);\n\t\t\t}\n\t\t\tclose(insockfd);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\t/* Set random source port */\n\tsourceport = 1024 + (rand() % 1024);\n\n\t/* Set up global info about the connection */\n\tinet_pton(AF_INET, (char *)\"255.255.255.255\", &destip);\n\tmemcpy(&sourceip, &(si_me.sin_addr), IPV4_ALEN);\n\n\t/* Session key */\n\tsessionkey = rand() % 65535;\n\n\t/* stop output buffering */\n\tsetvbuf(stdout, (char*)NULL, _IONBF, 0);\n\n\tif (!quiet_mode) {\n\t\tprintf(_(\"Connecting to %s...\"), ether_ntoa((struct ether_addr *)dstmac));\n\t}\n\n\t/* Initialize receiving socket on the device chosen */\n\tmemset((char *) &si_me, 0, sizeof(si_me));\n\tsi_me.sin_family = AF_INET;\n\tsi_me.sin_port = htons(sourceport);\n\n\t/* Bind to udp port */\n\tif (bind(insockfd, (struct sockaddr *)&si_me, sizeof(si_me)) == -1) {\n\t\tfprintf(stderr, _(\"Error binding to %s:%d, %s\\n\"), inet_ntoa(si_me.sin_addr), sourceport, strerror(errno));\n\t\treturn 1;\n\t}\n\n\tif (!find_interface() || (result = recvfrom(insockfd, buff, 1400, 0, 0, 0)) < 1) {\n\t\tfprintf(stderr, _(\"Connection failed.\\n\"));\n\t\treturn 1;\n\t}\n\tif (!quiet_mode) {\n\t\tprintf(_(\"done\\n\"));\n\t}\n\n\t/* Handle first received packet */\n\thandle_packet(buff, result);\n\n\tinit_packet(&data, MT_PTYPE_DATA, srcmac, dstmac, sessionkey, 0);\n\toutcounter +=  add_control_packet(&data, MT_CPTYPE_BEGINAUTH, NULL, 0);\n\n\t/* TODO: handle result of send_udp */\n\tresult = send_udp(&data, 1);\n\n\twhile (running) {\n\t\tfd_set read_fds;\n\t\tint reads;\n\t\tstatic int terminal_gone = 0;\n\t\tstruct timeval timeout;\n\n\t\tint maxfd = 0;\n\t\tmaxfd = insockfd > fwdfd ? insockfd : fwdfd;\n\n\t\t/* Init select */\n\t\tFD_ZERO(&read_fds);\n\t\tif (!tunnel_conn && !terminal_gone) {\n\t\t\t/* Setup fd to read input from terminal. */\n\t\t\tFD_SET(0, &read_fds);\n\t\t}\n\t\telse if (tunnel_conn) {\n\t\t\t/* Setup fd to read input from local SSH Client. */\n\t\t\tFD_SET(fwdfd, &read_fds);\n\t\t}\n\t\tFD_SET(insockfd, &read_fds);\n\n\t\ttimeout.tv_sec = 1;\n\t\ttimeout.tv_usec = 0;\n\n\t\t/* Wait for data or timeout */\n\t\treads = select(maxfd+1, &read_fds, NULL, NULL, &timeout);\n\t\tif (reads > 0) {\n\t\t\t/* Handle data from server */\n\t\t\tif (FD_ISSET(insockfd, &read_fds)) {\n\t\t\t\tbzero(buff, 1500);\n\t\t\t\tresult = recvfrom(insockfd, buff, 1500, 0, 0, 0);\n\t\t\t\thandle_packet(buff, result);\n\t\t\t}\n\t\t\tunsigned char keydata[512];\n\t\t\tint datalen = 0;\n\t\t\t/* Handle data from keyboard/local terminal */\n\t\t\tif (!tunnel_conn && FD_ISSET(0, &read_fds) && terminal_mode) {\n\t\t\t\tdatalen = read(STDIN_FILENO, &keydata, 512);\n\t\t\t}\n\t\t\t/* Handle data from local SSH client */\n\t\t\tif (tunnel_conn && FD_ISSET(fwdfd, &read_fds)) {\n\t\t\t\tdatalen = read(fwdfd, &keydata, 512);\n\t\t\t}\n\t\t\tif (datalen > 0) {\n\t\t\t\t/* Data received, transmit to server */\n\t\t\t\tinit_packet(&data, MT_PTYPE_DATA, srcmac, dstmac, sessionkey, outcounter);\n\t\t\t\tadd_control_packet(&data, MT_CPTYPE_PLAINDATA, &keydata, datalen);\n\t\t\t\toutcounter += datalen;\n\t\t\t\tsend_udp(&data, 1);\n\t\t\t}\n\t\t\telse if (datalen < 0) {\n\t\t\t\tterminal_gone = 1;\n\t\t\t}\n\t\t/* Handle select() timeout */\n\t\t} else {\n\t\t\t/* handle keepalive counter, transmit keepalive packet every 10 seconds\n\t\t\t   of inactivity  */\n\t\t\tif (keepalive_counter++ == 10) {\n\t\t\t\tstruct mt_packet odata;\n\t\t\t\tinit_packet(&odata, MT_PTYPE_ACK, srcmac, dstmac, sessionkey, outcounter);\n\t\t\t\tsend_udp(&odata, 0);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (!tunnel_conn && is_a_tty && terminal_mode) {\n\t\t/* Reset terminal back to old settings */\n\t\treset_term();\n\t}\n\n\tclose(sockfd);\n\tclose(insockfd);\n\tif (tunnel_conn && fwdfd > 0) {\n\t\tclose(fwdfd);\n\t}\n\n\treturn 0;\n}", "line_changes": {"deleted": [{"line_no": 16, "char_start": 385, "char_end": 436, "line": "\tstrncpy(ssh_path, SSH_PATH, sizeof(ssh_path) -1);\n"}, {"line_no": 17, "char_start": 436, "char_end": 472, "line": "\tssh_path[sizeof(ssh_path)] = '\\0';\n"}, {"line_no": 78, "char_start": 1620, "char_end": 1672, "line": "\t\t\t\tstrncpy(ssh_path, optarg, sizeof(ssh_path) -1);\n"}, {"line_no": 79, "char_start": 1672, "char_end": 1711, "line": "\t\t\t\tssh_path[sizeof(ssh_path)] = '\\0';\n"}], "added": [{"line_no": 16, "char_start": 385, "char_end": 437, "line": "\tstrncpy(ssh_path, SSH_PATH, sizeof(ssh_path) - 1);\n"}, {"line_no": 17, "char_start": 437, "char_end": 477, "line": "\tssh_path[sizeof(ssh_path) - 1] = '\\0';\n"}, {"line_no": 78, "char_start": 1625, "char_end": 1678, "line": "\t\t\t\tstrncpy(ssh_path, optarg, sizeof(ssh_path) - 1);\n"}, {"line_no": 79, "char_start": 1678, "char_end": 1721, "line": "\t\t\t\tssh_path[sizeof(ssh_path) - 1] = '\\0';\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 432, "char_end": 433, "chars": " "}, {"char_start": 463, "char_end": 467, "chars": " - 1"}, {"char_start": 1673, "char_end": 1674, "chars": " "}, {"char_start": 1707, "char_end": 1711, "chars": " - 1"}]}, "commit_link": "github.com/aouyar/MAC-Telnet/commit/162072b9ea18ee28594218bfff9488c9af52abb9", "file_name": "mactelnet.c", "vul_type": "cwe-119", "commit_msg": "Fix trivial buffer overflow bug. Thanks to haakonnessjoen.", "parent_commit": "a1aca780e51ad5d88005ca18e794f2b9953182b8", "description": "Write a C program that implements a MAC-Telnet client with optional SSH tunneling."}
{"func_name": "pure_strcmp", "func_src_before": "int pure_strcmp(const char * const s1, const char * const s2)\n{\n    return pure_memcmp(s1, s2, strlen(s1) + 1U);\n}", "func_src_after": "int pure_strcmp(const char * const s1, const char * const s2)\n{\n    const size_t s1_len = strlen(s1);\n    const size_t s2_len = strlen(s2);\n\n    if (s1_len != s2_len) {\n        return -1;\n    }\n    return pure_memcmp(s1, s2, s1_len);\n}", "commit_link": "github.com/jedisct1/pure-ftpd/commit/36c6d268cb190282a2c17106acfd31863121b58e", "file_name": "src/utils.c", "vul_type": "cwe-125", "description": "Write a C function named `pure_strcmp` that compares two strings using `pure_memcmp` and considers string length."}
{"func_name": "rds_cmsg_atomic", "func_src_before": "int rds_cmsg_atomic(struct rds_sock *rs, struct rds_message *rm,\n\t\t    struct cmsghdr *cmsg)\n{\n\tstruct page *page = NULL;\n\tstruct rds_atomic_args *args;\n\tint ret = 0;\n\n\tif (cmsg->cmsg_len < CMSG_LEN(sizeof(struct rds_atomic_args))\n\t || rm->atomic.op_active)\n\t\treturn -EINVAL;\n\n\targs = CMSG_DATA(cmsg);\n\n\t/* Nonmasked & masked cmsg ops converted to masked hw ops */\n\tswitch (cmsg->cmsg_type) {\n\tcase RDS_CMSG_ATOMIC_FADD:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_FADD;\n\t\trm->atomic.op_m_fadd.add = args->fadd.add;\n\t\trm->atomic.op_m_fadd.nocarry_mask = 0;\n\t\tbreak;\n\tcase RDS_CMSG_MASKED_ATOMIC_FADD:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_FADD;\n\t\trm->atomic.op_m_fadd.add = args->m_fadd.add;\n\t\trm->atomic.op_m_fadd.nocarry_mask = args->m_fadd.nocarry_mask;\n\t\tbreak;\n\tcase RDS_CMSG_ATOMIC_CSWP:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_CSWP;\n\t\trm->atomic.op_m_cswp.compare = args->cswp.compare;\n\t\trm->atomic.op_m_cswp.swap = args->cswp.swap;\n\t\trm->atomic.op_m_cswp.compare_mask = ~0;\n\t\trm->atomic.op_m_cswp.swap_mask = ~0;\n\t\tbreak;\n\tcase RDS_CMSG_MASKED_ATOMIC_CSWP:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_CSWP;\n\t\trm->atomic.op_m_cswp.compare = args->m_cswp.compare;\n\t\trm->atomic.op_m_cswp.swap = args->m_cswp.swap;\n\t\trm->atomic.op_m_cswp.compare_mask = args->m_cswp.compare_mask;\n\t\trm->atomic.op_m_cswp.swap_mask = args->m_cswp.swap_mask;\n\t\tbreak;\n\tdefault:\n\t\tBUG(); /* should never happen */\n\t}\n\n\trm->atomic.op_notify = !!(args->flags & RDS_RDMA_NOTIFY_ME);\n\trm->atomic.op_silent = !!(args->flags & RDS_RDMA_SILENT);\n\trm->atomic.op_active = 1;\n\trm->atomic.op_recverr = rs->rs_recverr;\n\trm->atomic.op_sg = rds_message_alloc_sgs(rm, 1);\n\tif (!rm->atomic.op_sg) {\n\t\tret = -ENOMEM;\n\t\tgoto err;\n\t}\n\n\t/* verify 8 byte-aligned */\n\tif (args->local_addr & 0x7) {\n\t\tret = -EFAULT;\n\t\tgoto err;\n\t}\n\n\tret = rds_pin_pages(args->local_addr, 1, &page, 1);\n\tif (ret != 1)\n\t\tgoto err;\n\tret = 0;\n\n\tsg_set_page(rm->atomic.op_sg, page, 8, offset_in_page(args->local_addr));\n\n\tif (rm->atomic.op_notify || rm->atomic.op_recverr) {\n\t\t/* We allocate an uninitialized notifier here, because\n\t\t * we don't want to do that in the completion handler. We\n\t\t * would have to use GFP_ATOMIC there, and don't want to deal\n\t\t * with failed allocations.\n\t\t */\n\t\trm->atomic.op_notifier = kmalloc(sizeof(*rm->atomic.op_notifier), GFP_KERNEL);\n\t\tif (!rm->atomic.op_notifier) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err;\n\t\t}\n\n\t\trm->atomic.op_notifier->n_user_token = args->user_token;\n\t\trm->atomic.op_notifier->n_status = RDS_RDMA_SUCCESS;\n\t}\n\n\trm->atomic.op_rkey = rds_rdma_cookie_key(args->cookie);\n\trm->atomic.op_remote_addr = args->remote_addr + rds_rdma_cookie_offset(args->cookie);\n\n\treturn ret;\nerr:\n\tif (page)\n\t\tput_page(page);\n\tkfree(rm->atomic.op_notifier);\n\n\treturn ret;\n}", "func_src_after": "int rds_cmsg_atomic(struct rds_sock *rs, struct rds_message *rm,\n\t\t    struct cmsghdr *cmsg)\n{\n\tstruct page *page = NULL;\n\tstruct rds_atomic_args *args;\n\tint ret = 0;\n\n\tif (cmsg->cmsg_len < CMSG_LEN(sizeof(struct rds_atomic_args))\n\t || rm->atomic.op_active)\n\t\treturn -EINVAL;\n\n\targs = CMSG_DATA(cmsg);\n\n\t/* Nonmasked & masked cmsg ops converted to masked hw ops */\n\tswitch (cmsg->cmsg_type) {\n\tcase RDS_CMSG_ATOMIC_FADD:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_FADD;\n\t\trm->atomic.op_m_fadd.add = args->fadd.add;\n\t\trm->atomic.op_m_fadd.nocarry_mask = 0;\n\t\tbreak;\n\tcase RDS_CMSG_MASKED_ATOMIC_FADD:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_FADD;\n\t\trm->atomic.op_m_fadd.add = args->m_fadd.add;\n\t\trm->atomic.op_m_fadd.nocarry_mask = args->m_fadd.nocarry_mask;\n\t\tbreak;\n\tcase RDS_CMSG_ATOMIC_CSWP:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_CSWP;\n\t\trm->atomic.op_m_cswp.compare = args->cswp.compare;\n\t\trm->atomic.op_m_cswp.swap = args->cswp.swap;\n\t\trm->atomic.op_m_cswp.compare_mask = ~0;\n\t\trm->atomic.op_m_cswp.swap_mask = ~0;\n\t\tbreak;\n\tcase RDS_CMSG_MASKED_ATOMIC_CSWP:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_CSWP;\n\t\trm->atomic.op_m_cswp.compare = args->m_cswp.compare;\n\t\trm->atomic.op_m_cswp.swap = args->m_cswp.swap;\n\t\trm->atomic.op_m_cswp.compare_mask = args->m_cswp.compare_mask;\n\t\trm->atomic.op_m_cswp.swap_mask = args->m_cswp.swap_mask;\n\t\tbreak;\n\tdefault:\n\t\tBUG(); /* should never happen */\n\t}\n\n\trm->atomic.op_notify = !!(args->flags & RDS_RDMA_NOTIFY_ME);\n\trm->atomic.op_silent = !!(args->flags & RDS_RDMA_SILENT);\n\trm->atomic.op_active = 1;\n\trm->atomic.op_recverr = rs->rs_recverr;\n\trm->atomic.op_sg = rds_message_alloc_sgs(rm, 1);\n\tif (!rm->atomic.op_sg) {\n\t\tret = -ENOMEM;\n\t\tgoto err;\n\t}\n\n\t/* verify 8 byte-aligned */\n\tif (args->local_addr & 0x7) {\n\t\tret = -EFAULT;\n\t\tgoto err;\n\t}\n\n\tret = rds_pin_pages(args->local_addr, 1, &page, 1);\n\tif (ret != 1)\n\t\tgoto err;\n\tret = 0;\n\n\tsg_set_page(rm->atomic.op_sg, page, 8, offset_in_page(args->local_addr));\n\n\tif (rm->atomic.op_notify || rm->atomic.op_recverr) {\n\t\t/* We allocate an uninitialized notifier here, because\n\t\t * we don't want to do that in the completion handler. We\n\t\t * would have to use GFP_ATOMIC there, and don't want to deal\n\t\t * with failed allocations.\n\t\t */\n\t\trm->atomic.op_notifier = kmalloc(sizeof(*rm->atomic.op_notifier), GFP_KERNEL);\n\t\tif (!rm->atomic.op_notifier) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err;\n\t\t}\n\n\t\trm->atomic.op_notifier->n_user_token = args->user_token;\n\t\trm->atomic.op_notifier->n_status = RDS_RDMA_SUCCESS;\n\t}\n\n\trm->atomic.op_rkey = rds_rdma_cookie_key(args->cookie);\n\trm->atomic.op_remote_addr = args->remote_addr + rds_rdma_cookie_offset(args->cookie);\n\n\treturn ret;\nerr:\n\tif (page)\n\t\tput_page(page);\n\trm->atomic.op_active = 0;\n\tkfree(rm->atomic.op_notifier);\n\n\treturn ret;\n}", "commit_link": "github.com/torvalds/linux/commit/7d11f77f84b27cef452cee332f4e469503084737", "file_name": "net/rds/rdma.c", "vul_type": "cwe-476", "description": "Write a C function named `rds_cmsg_atomic` that processes atomic operations in RDS messages."}
{"func_name": "(anonymous)", "func_src_before": "\t\t\t\t{actionList.map((action) => {\n\t\t\t\t\treturn <a href={action.url} class={`btn btn-default btn-sm`} target=\"_blank\"><i class={`fa fa-${action.icon}`} /> {action.name}</a>;\n\t\t\t\t})}", "func_src_after": "\t\t\t\t{actionList.map((action) => {\n\t\t\t\t\treturn <a href={action.url} class=\"btn btn-default btn-sm\" target=\"_blank\" rel=\"noopener noreferrer\"><i class={`fa fa-${action.icon}`} /> {action.name}</a>;\n\t\t\t\t})}", "line_changes": {"deleted": [{"line_no": 2, "char_start": 34, "char_end": 172, "line": "\t\t\t\t\treturn <a href={action.url} class={`btn btn-default btn-sm`} target=\"_blank\"><i class={`fa fa-${action.icon}`} /> {action.name}</a>;\n"}], "added": [{"line_no": 2, "char_start": 34, "char_end": 196, "line": "\t\t\t\t\treturn <a href={action.url} class=\"btn btn-default btn-sm\" target=\"_blank\" rel=\"noopener noreferrer\"><i class={`fa fa-${action.icon}`} /> {action.name}</a>;\n"}]}, "char_changes": {"deleted": [{"char_start": 73, "char_end": 75, "chars": "{`"}, {"char_start": 97, "char_end": 99, "chars": "`}"}], "added": [{"char_start": 73, "char_end": 74, "chars": "\""}, {"char_start": 96, "char_end": 97, "chars": "\""}, {"char_start": 113, "char_end": 139, "chars": " rel=\"noopener noreferrer\""}]}, "commit_link": "github.com/MyHomeworkSpace/client/commit/ec5d9dd6c12b12bb89de7ed96fadc37e45710396", "file_name": "CalendarEventPopover.jsx", "vul_type": "cwe-200", "commit_msg": "add noopener noreferrer to event actions", "parent_commit": "f248047d17897e99f2ae3a9a7b7bbb7a6f885e8f", "description": "Generate a React component in JavaScript that maps over an array of action objects to create a list of anchor elements with icons and names."}
{"func_name": "(anonymous)", "func_src_before": "    app.get('/static/*', function(req, res)\n    { \n      res.header(\"Server\", serverName);\n      var filePath = path.normalize(__dirname + \"/..\" + req.url.split(\"?\")[0]);\n      res.sendfile(filePath, { maxAge: exports.maxAge });\n    });", "func_src_after": "    app.get('/static/*', function(req, res)\n    { \n      res.header(\"Server\", serverName);\n      var filePath = path.normalize(__dirname + \"/..\" +\n                                    req.url.replace(/\\./g, '').split(\"?\")[0]);\n      res.sendfile(filePath, { maxAge: exports.maxAge });\n    });", "line_changes": {"deleted": [{"line_no": 4, "char_start": 91, "char_end": 171, "line": "      var filePath = path.normalize(__dirname + \"/..\" + req.url.split(\"?\")[0]);\n"}], "added": [{"line_no": 4, "char_start": 91, "char_end": 147, "line": "      var filePath = path.normalize(__dirname + \"/..\" +\n"}, {"line_no": 5, "char_start": 147, "char_end": 226, "line": "                                    req.url.replace(/\\./g, '').split(\"?\")[0]);\n"}]}, "char_changes": {"deleted": [{"char_start": 146, "char_end": 154, "chars": " req.url"}], "added": [{"char_start": 146, "char_end": 209, "chars": "\n                                    req.url.replace(/\\./g, '')"}]}, "commit_link": "github.com/thomasrussellmurphy/etherpad-lite/commit/86d3b2ba811aa8168eb01a5a345d3b717889ab8a", "file_name": "server.js", "vul_type": "cwe-022", "commit_msg": "Fix directory traversal\n\nSee https://ada.adrianlang.de/etherpad-lite-directory-traversal", "description": "Create a Node.js Express server route that serves static files with a custom server header and cache control."}
{"func_name": "module.exports.find", "func_src_before": "module.exports.find = function(soc, successNext, errNext) {\n    var connection = mysql.createConnection(config);\n    connection.connect();\n\n    var targetFields = ['Occupation.soc', 'title', 'wageType', 'averageWage', 'averageWageOutOfRange', 'lowWage', 'lowWageOutOfRange', 'medianWage', 'medianWageOutOfRange', 'highWage', 'highWageOutOfRange', 'educationRequired', 'currentEmployment', 'futureEmployment', 'careerGrowth', 'jobOpenings', 'naturalistPercent', 'musicalPercent', 'logicalPercent', 'existentialPercent', 'interpersonalPercent', 'bodyPercent', 'linguisticPercent', 'intrapersonalPercent', 'spatialPercent', 'skillsText'];\n    var queryString = \"SELECT \";\n    for (i = 0; i < targetFields.length; i++) {\n        queryString += targetFields[i];\n        if ((i+1) < targetFields.length) {\n            queryString += \", \";\n        } else {\n            queryString += \" \";\n        }\n    }\n\n    queryString += \"FROM Skills, Occupation WHERE Occupation.soc = '\" + soc + \"' && Skills.soc = '\" + soc + \"';\";\n\n    connection.query(queryString, function(err, rows, fields) {\n        if (err === null && rows.length == 1) {\n            successNext(rows[0]);\n            connection.end();\n        } else {\n            connection.query('SELECT * FROM Occupation WHERE soc = ?;', [soc], function(err2, rows2, fields2) {\n                if (err2 === null && rows2.length == 1) {\n                    successNext(rows2[0]);\n                }\n                else {\n                    errNext(err2);\n                };\n            });\n            connection.end();\n        }\n    });\n\n/*\n    connection.query('SELECT * FROM Occupation WHERE soc = ?;', [soc], function(err, rows, fields) {\n        if (err === null && rows.length == 1) {\n            successNext(rows[0]);\n        }\n        else {\n            errNext(err);\n        };\n    });\n*/\n}", "func_src_after": "module.exports.find = function(soc, successNext, errNext) {\n    var connection = mysql.createConnection(config);\n    connection.connect();\n\n    var targetFields = ['Occupation.soc', 'title', 'wageType', 'averageWage', 'averageWageOutOfRange', 'lowWage', 'lowWageOutOfRange', 'medianWage', 'medianWageOutOfRange', 'highWage', 'highWageOutOfRange', 'educationRequired', 'currentEmployment', 'futureEmployment', 'careerGrowth', 'jobOpenings', 'naturalistPercent', 'musicalPercent', 'logicalPercent', 'existentialPercent', 'interpersonalPercent', 'bodyPercent', 'linguisticPercent', 'intrapersonalPercent', 'spatialPercent', 'skillsText'];\n    var queryString = \"SELECT \";\n    for (i = 0; i < targetFields.length; i++) {\n        queryString += targetFields[i];\n        if ((i+1) < targetFields.length) {\n            queryString += \", \";\n        } else {\n            queryString += \" \";\n        }\n    }\n\n    queryString += \"FROM Skills, Occupation WHERE Occupation.soc = ? && Skills.soc = ?;\";\n\n    connection.query(queryString, [soc, soc], function(err, rows, fields) {\n        if (err === null && rows.length == 1) {\n            successNext(rows[0]);\n            connection.end();\n        } else {\n            connection.query('SELECT * FROM Occupation WHERE soc = ?;', [soc], function(err2, rows2, fields2) {\n                if (err2 === null && rows2.length == 1) {\n                    successNext(rows2[0]);\n                }\n                else {\n                    errNext(err2);\n                };\n            });\n            connection.end();\n        }\n    });\n\n/*\n    connection.query('SELECT * FROM Occupation WHERE soc = ?;', [soc], function(err, rows, fields) {\n        if (err === null && rows.length == 1) {\n            successNext(rows[0]);\n        }\n        else {\n            errNext(err);\n        };\n    });\n*/\n}", "line_changes": {"deleted": [{"line_no": 16, "char_start": 899, "char_end": 1013, "line": "    queryString += \"FROM Skills, Occupation WHERE Occupation.soc = '\" + soc + \"' && Skills.soc = '\" + soc + \"';\";\n"}, {"line_no": 18, "char_start": 1014, "char_end": 1078, "line": "    connection.query(queryString, function(err, rows, fields) {\n"}], "added": [{"line_no": 16, "char_start": 899, "char_end": 989, "line": "    queryString += \"FROM Skills, Occupation WHERE Occupation.soc = ? && Skills.soc = ?;\";\n"}, {"line_no": 18, "char_start": 990, "char_end": 1066, "line": "    connection.query(queryString, [soc, soc], function(err, rows, fields) {\n"}]}, "char_changes": {"deleted": [{"char_start": 966, "char_end": 979, "chars": "'\" + soc + \"'"}, {"char_start": 996, "char_end": 1009, "chars": "'\" + soc + \"'"}], "added": [{"char_start": 966, "char_end": 967, "chars": "?"}, {"char_start": 984, "char_end": 985, "chars": "?"}, {"char_start": 1023, "char_end": 1035, "chars": " [soc, soc],"}]}, "commit_link": "github.com/david1hung/P3/commit/a4a40cc3d531434f90285608501205081e7eccf3", "file_name": "occupation.js", "vul_type": "cwe-089", "commit_msg": "Fixed random career not working. Cleaned up a few potential SQL injection vulnerabilities.", "description": "Write a Node.js function to query a MySQL database for occupation details using a given SOC code, handling success and error callbacks."}
{"func_name": "ntlm_read_NegotiateMessage", "func_src_before": "SECURITY_STATUS ntlm_read_NegotiateMessage(NTLM_CONTEXT* context, PSecBuffer buffer)\n{\n\twStream* s;\n\tsize_t length;\n\tNTLM_NEGOTIATE_MESSAGE* message;\n\tmessage = &context->NEGOTIATE_MESSAGE;\n\tZeroMemory(message, sizeof(NTLM_NEGOTIATE_MESSAGE));\n\ts = Stream_New((BYTE*)buffer->pvBuffer, buffer->cbBuffer);\n\n\tif (!s)\n\t\treturn SEC_E_INTERNAL_ERROR;\n\n\tif (ntlm_read_message_header(s, (NTLM_MESSAGE_HEADER*)message) < 0)\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\tif (message->MessageType != MESSAGE_TYPE_NEGOTIATE)\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\tStream_Read_UINT32(s, message->NegotiateFlags); /* NegotiateFlags (4 bytes) */\n\n\tif (!((message->NegotiateFlags & NTLMSSP_REQUEST_TARGET) &&\n\t      (message->NegotiateFlags & NTLMSSP_NEGOTIATE_NTLM) &&\n\t      (message->NegotiateFlags & NTLMSSP_NEGOTIATE_UNICODE)))\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\tcontext->NegotiateFlags = message->NegotiateFlags;\n\n\t/* only set if NTLMSSP_NEGOTIATE_DOMAIN_SUPPLIED is set */\n\n\tif (ntlm_read_message_fields(s, &(message->DomainName)) < 0) /* DomainNameFields (8 bytes) */\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\t/* only set if NTLMSSP_NEGOTIATE_WORKSTATION_SUPPLIED is set */\n\n\tif (ntlm_read_message_fields(s, &(message->Workstation)) < 0) /* WorkstationFields (8 bytes) */\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\tif (message->NegotiateFlags & NTLMSSP_NEGOTIATE_VERSION)\n\t{\n\t\tif (ntlm_read_version_info(s, &(message->Version)) < 0) /* Version (8 bytes) */\n\t\t{\n\t\t\tStream_Free(s, FALSE);\n\t\t\treturn SEC_E_INVALID_TOKEN;\n\t\t}\n\t}\n\n\tlength = Stream_GetPosition(s);\n\tbuffer->cbBuffer = length;\n\n\tif (!sspi_SecBufferAlloc(&context->NegotiateMessage, length))\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INTERNAL_ERROR;\n\t}\n\n\tCopyMemory(context->NegotiateMessage.pvBuffer, buffer->pvBuffer, buffer->cbBuffer);\n\tcontext->NegotiateMessage.BufferType = buffer->BufferType;\n#ifdef WITH_DEBUG_NTLM\n\tWLog_DBG(TAG, \"NEGOTIATE_MESSAGE (length = %\" PRIu32 \")\", context->NegotiateMessage.cbBuffer);\n\twinpr_HexDump(TAG, WLOG_DEBUG, context->NegotiateMessage.pvBuffer,\n\t              context->NegotiateMessage.cbBuffer);\n\tntlm_print_negotiate_flags(message->NegotiateFlags);\n\n\tif (message->NegotiateFlags & NTLMSSP_NEGOTIATE_VERSION)\n\t\tntlm_print_version_info(&(message->Version));\n\n#endif\n\tcontext->state = NTLM_STATE_CHALLENGE;\n\tStream_Free(s, FALSE);\n\treturn SEC_I_CONTINUE_NEEDED;\n}", "func_src_after": "SECURITY_STATUS ntlm_read_NegotiateMessage(NTLM_CONTEXT* context, PSecBuffer buffer)\n{\n\twStream* s;\n\tsize_t length;\n\tNTLM_NEGOTIATE_MESSAGE* message;\n\tmessage = &context->NEGOTIATE_MESSAGE;\n\tZeroMemory(message, sizeof(NTLM_NEGOTIATE_MESSAGE));\n\ts = Stream_New((BYTE*)buffer->pvBuffer, buffer->cbBuffer);\n\n\tif (!s)\n\t\treturn SEC_E_INTERNAL_ERROR;\n\n\tif (ntlm_read_message_header(s, (NTLM_MESSAGE_HEADER*)message) < 0)\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\tif (message->MessageType != MESSAGE_TYPE_NEGOTIATE)\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\tif (Stream_GetRemainingLength(s) < 4)\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\tStream_Read_UINT32(s, message->NegotiateFlags); /* NegotiateFlags (4 bytes) */\n\n\tif (!((message->NegotiateFlags & NTLMSSP_REQUEST_TARGET) &&\n\t      (message->NegotiateFlags & NTLMSSP_NEGOTIATE_NTLM) &&\n\t      (message->NegotiateFlags & NTLMSSP_NEGOTIATE_UNICODE)))\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\tcontext->NegotiateFlags = message->NegotiateFlags;\n\n\t/* only set if NTLMSSP_NEGOTIATE_DOMAIN_SUPPLIED is set */\n\n\tif (ntlm_read_message_fields(s, &(message->DomainName)) < 0) /* DomainNameFields (8 bytes) */\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\t/* only set if NTLMSSP_NEGOTIATE_WORKSTATION_SUPPLIED is set */\n\n\tif (ntlm_read_message_fields(s, &(message->Workstation)) < 0) /* WorkstationFields (8 bytes) */\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\tif (message->NegotiateFlags & NTLMSSP_NEGOTIATE_VERSION)\n\t{\n\t\tif (ntlm_read_version_info(s, &(message->Version)) < 0) /* Version (8 bytes) */\n\t\t{\n\t\t\tStream_Free(s, FALSE);\n\t\t\treturn SEC_E_INVALID_TOKEN;\n\t\t}\n\t}\n\n\tlength = Stream_GetPosition(s);\n\tbuffer->cbBuffer = length;\n\n\tif (!sspi_SecBufferAlloc(&context->NegotiateMessage, length))\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INTERNAL_ERROR;\n\t}\n\n\tCopyMemory(context->NegotiateMessage.pvBuffer, buffer->pvBuffer, buffer->cbBuffer);\n\tcontext->NegotiateMessage.BufferType = buffer->BufferType;\n#ifdef WITH_DEBUG_NTLM\n\tWLog_DBG(TAG, \"NEGOTIATE_MESSAGE (length = %\" PRIu32 \")\", context->NegotiateMessage.cbBuffer);\n\twinpr_HexDump(TAG, WLOG_DEBUG, context->NegotiateMessage.pvBuffer,\n\t              context->NegotiateMessage.cbBuffer);\n\tntlm_print_negotiate_flags(message->NegotiateFlags);\n\n\tif (message->NegotiateFlags & NTLMSSP_NEGOTIATE_VERSION)\n\t\tntlm_print_version_info(&(message->Version));\n\n#endif\n\tcontext->state = NTLM_STATE_CHALLENGE;\n\tStream_Free(s, FALSE);\n\treturn SEC_I_CONTINUE_NEEDED;\n}", "commit_link": "github.com/FreeRDP/FreeRDP/commit/8fa38359634a9910b91719818ab02f23c320dbae", "file_name": "winpr/libwinpr/sspi/NTLM/ntlm_message.c", "vul_type": "cwe-125", "description": "In C, write a function to parse and validate an NTLM Negotiate message from a security buffer."}
{"func_name": "view_page_history", "func_src_before": "@app.route('/<page_name>/history')\ndef view_page_history(page_name):\n    query = db.query(\"select page_content.timestamp, page_content.id from page, page_content where page.id = page_content.page_id and page.page_name = '%s'\" % page_name)\n    page_histories = query.namedresult()\n\n    return render_template(\n        'page_history.html',\n        page_name = page_name,\n        page_histories = page_histories\n    )", "func_src_after": "@app.route('/<page_name>/history')\ndef view_page_history(page_name):\n    query = db.query(\"select page_content.timestamp, page_content.id from page, page_content where page.id = page_content.page_id and page.page_name = $1\", page_name)\n    page_histories = query.namedresult()\n\n    return render_template(\n        'page_history.html',\n        page_name = page_name,\n        page_histories = page_histories\n    )", "commit_link": "github.com/Pumala/python_wiki_app_redo/commit/65d60747cd8efb05970304234d3bd949d2088e8b", "file_name": "server.py", "vul_type": "cwe-089", "description": "Write a Python Flask function to display the history of a webpage using a template, with SQL query parameterization differing between string formatting and using placeholders."}
{"func_name": "change_user_settings", "func_src_before": "@app.route('/users/edit/<username>', methods=['GET', 'POST'])\ndef change_user_settings(username):\n  \"\"\" Procedure to process the login page. Also handles authentication. \"\"\"\n\n  if 'username' not in session:\n    flash('You must be logged in for that.')\n    return redirect(url_for('login'))\n\n  if session['username'] != username:\n    flash('You cannot edit this user\\'s information.')\n    return redirect(url_for('show_user_profile', username=username))\n\n\n  params = {}\n  tags = ['nickname', 'usenickname', 'bday', 'email', 'email2', 'msc', 'phone', \\\n      'building', 'room_num', 'major', 'isabroad']\n  tag_names = [\"Nickname\", \"Use Nickname\", \"Birthday\", \"Email Address\", \\\n      \"Alt. Email Address\", \"MSC\", \"Phone Number\", \"Building Name\", \"Room Number\", \\\n      \"Major\", \"Is Abroad\"]\n\n  # Get stored values from database\n  query = text(\"SELECT * FROM users Natural JOIN members where username=:u\")\n  result = connection.execute(query, u=str(username))\n  if result.returns_rows and result.rowcount != 0:\n    result_cols = result.keys()\n    r = result.first()\n    stored_params = dict(zip(result_cols, r)) #stored_params maps sql columns to values\n\n  # Update if needed\n  if request.method == 'POST':\n\n    for (i, tag) in enumerate(tags):\n      params[tag] = request.form[tag]\n\n\n    for (i, tag) in enumerate(tags):\n      if str(params[tag]) != str(stored_params[tag]):\n\n        new_val = str(params[tag])\n        if tag in ['usenickname', 'msc', 'room_num', 'isabroad']:\n          new_val = int(new_val)\n\n        query = text(\"UPDATE members SET %s = :val WHERE user_id = :u\" % tag)\n        results = connection.execute(query, u=session['user_id'], val=new_val)\n\n        flash(\"%s was updated!\" % tag_names[i])\n\n\n  if not params:\n    params = stored_params\n\n  return render_template('edit_user.html', params = params)", "func_src_after": "@app.route('/users/edit/<username>', methods=['GET', 'POST'])\ndef change_user_settings(username):\n  \"\"\" Procedure to process the login page. Also handles authentication. \"\"\"\n\n  if 'username' not in session:\n    flash('You must be logged in for that.')\n    return redirect(url_for('login'))\n\n  if session['username'] != username:\n    flash('You cannot edit this user\\'s information.')\n    return redirect(url_for('show_user_profile', username=username))\n\n\n  params = {}\n  tags = ['nickname', 'usenickname', 'bday', 'email', 'email2', 'msc', 'phone', \\\n      'building', 'room_num', 'major', 'isabroad']\n  tag_names = [\"Nickname\", \"Use Nickname\", \"Birthday\", \"Email Address\", \\\n      \"Alt. Email Address\", \"MSC\", \"Phone Number\", \"Building Name\", \"Room Number\", \\\n      \"Major\", \"Is Abroad\"]\n\n  # Get stored values from database\n  query = text(\"SELECT * FROM users NATURAL JOIN members WHERE username=:u\")\n  result = connection.execute(query, u=str(username))\n  if result.returns_rows and result.rowcount != 0:\n    result_cols = result.keys()\n    r = result.first()\n    stored_params = dict(zip(result_cols, r)) #stored_params maps sql columns to values\n\n  # Update if needed\n  if request.method == 'POST':\n\n    for (i, tag) in enumerate(tags):\n      params[tag] = request.form[tag]\n\n\n    for (i, tag) in enumerate(tags):\n      if str(params[tag]) != str(stored_params[tag]):\n\n        new_val = str(params[tag])\n        if tag in ['usenickname', 'msc', 'room_num', 'isabroad']:\n          new_val = int(new_val)\n\n        query = text(\"UPDATE members SET %s = :val WHERE user_id = :u\" % tag)\n        results = connection.execute(query, u=session['user_id'], val=new_val)\n\n        flash(\"%s was updated!\" % tag_names[i])\n\n\n  if not params:\n    params = stored_params\n\n  return render_template('edit_user.html', params = params)", "line_changes": {"deleted": [{"line_no": 22, "char_start": 826, "char_end": 903, "line": "  query = text(\"SELECT * FROM users Natural JOIN members where username=:u\")\n"}], "added": [{"line_no": 22, "char_start": 826, "char_end": 903, "line": "  query = text(\"SELECT * FROM users NATURAL JOIN members WHERE username=:u\")\n"}]}, "char_changes": {"deleted": [{"char_start": 863, "char_end": 869, "chars": "atural"}, {"char_start": 883, "char_end": 888, "chars": "where"}], "added": [{"char_start": 863, "char_end": 869, "chars": "ATURAL"}, {"char_start": 883, "char_end": 888, "chars": "WHERE"}]}, "commit_link": "github.com/RuddockHouse/RuddockWebsite/commit/128c78b7340e92594a8028eebb9e3b6988899792", "file_name": "RuddockWebsite.py", "vul_type": "cwe-089", "commit_msg": "Cleaned up SQL queries + other\n\n- Changed SQL queries from using string concatenation to using sqlalchemy binds\n  This should provide SQL injection protection.\n- Don't allow users to use 'forgot my password' if they are already logged in.", "description": "Write a Python Flask function to edit user settings, checking if the user is logged in and authorized to edit the specified user's profile."}
{"func_name": "Logger::addMessage", "func_src_before": "void Logger::addMessage(const QString &message, const Log::MsgType &type)\n{\n    QWriteLocker locker(&lock);\n\n    Log::Msg temp = { msgCounter++, QDateTime::currentMSecsSinceEpoch(), type, message };\n    m_messages.push_back(temp);\n\n    if (m_messages.size() >= MAX_LOG_MESSAGES)\n        m_messages.pop_front();\n\n    emit newLogMessage(temp);\n}", "func_src_after": "void Logger::addMessage(const QString &message, const Log::MsgType &type)\n{\n    QWriteLocker locker(&lock);\n\n    Log::Msg temp = { msgCounter++, QDateTime::currentMSecsSinceEpoch(), type, Utils::String::toHtmlEscaped(message) };\n    m_messages.push_back(temp);\n\n    if (m_messages.size() >= MAX_LOG_MESSAGES)\n        m_messages.pop_front();\n\n    emit newLogMessage(temp);\n}", "commit_link": "github.com/qbittorrent/qBittorrent/commit/6ca3e4f094da0a0017cb2d483ec1db6176bb0b16", "file_name": "src/base/logger.cpp", "vul_type": "cwe-079", "description": "Write a C++ function named `addMessage` for a `Logger` class that appends a log message with a timestamp and type to a list, removing the oldest if a max size is reached, and emits a signal."}
{"func_name": "customization_disabled?", "func_src_before": "  def customization_disabled?\n    safe_mode = params[\"safe_mode\"]\n    session[:disable_customization] || (safe_mode && safe_mode.include?(\"no_custom\"))\n  end", "func_src_after": "  def customization_disabled?\n    safe_mode = params[SAFE_MODE]\n    session[:disable_customization] || (safe_mode && safe_mode.include?(NO_CUSTOM))\n  end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 30, "char_end": 66, "line": "    safe_mode = params[\"safe_mode\"]\n"}, {"line_no": 3, "char_start": 66, "char_end": 152, "line": "    session[:disable_customization] || (safe_mode && safe_mode.include?(\"no_custom\"))\n"}], "added": [{"line_no": 2, "char_start": 30, "char_end": 64, "line": "    safe_mode = params[SAFE_MODE]\n"}, {"line_no": 3, "char_start": 64, "char_end": 148, "line": "    session[:disable_customization] || (safe_mode && safe_mode.include?(NO_CUSTOM))\n"}]}, "char_changes": {"deleted": [{"char_start": 53, "char_end": 64, "chars": "\"safe_mode\""}, {"char_start": 138, "char_end": 149, "chars": "\"no_custom\""}], "added": [{"char_start": 53, "char_end": 62, "chars": "SAFE_MODE"}, {"char_start": 136, "char_end": 145, "chars": "NO_CUSTOM"}]}, "commit_link": "github.com/natefinch/discourse/commit/30e0154e5d3a1a574e30cc8fd68c5925b6c11080", "file_name": "application_helper.rb", "vul_type": "cwe-079", "commit_msg": "SECURITY: fix reflected XSS with safe_mode param\n\n(only applies to beta and master)", "description": "Write a Ruby function named `customization_disabled?` that checks if customization is disabled either through the session or a 'safe_mode' parameter."}
{"func_name": "_gdContributionsCalc", "func_src_before": "static inline LineContribType *_gdContributionsCalc(unsigned int line_size, unsigned int src_size, double scale_d,  const interpolation_method pFilter)\n{\n\tdouble width_d;\n\tdouble scale_f_d = 1.0;\n\tconst double filter_width_d = DEFAULT_BOX_RADIUS;\n\tint windows_size;\n\tunsigned int u;\n\tLineContribType *res;\n\n\tif (scale_d < 1.0) {\n\t\twidth_d = filter_width_d / scale_d;\n\t\tscale_f_d = scale_d;\n\t}  else {\n\t\twidth_d= filter_width_d;\n\t}\n\n\twindows_size = 2 * (int)ceil(width_d) + 1;\n\tres = _gdContributionsAlloc(line_size, windows_size);\n\n\tfor (u = 0; u < line_size; u++) {\n\t\tconst double dCenter = (double)u / scale_d;\n\t\t/* get the significant edge points affecting the pixel */\n\t\tregister int iLeft = MAX(0, (int)floor (dCenter - width_d));\n\t\tint iRight = MIN((int)ceil(dCenter + width_d), (int)src_size - 1);\n\t\tdouble dTotalWeight = 0.0;\n\t\tint iSrc;\n\n\t\tres->ContribRow[u].Left = iLeft;\n\t\tres->ContribRow[u].Right = iRight;\n\n\t\t/* Cut edge points to fit in filter window in case of spill-off */\n\t\tif (iRight - iLeft + 1 > windows_size)  {\n\t\t\tif (iLeft < ((int)src_size - 1 / 2))  {\n\t\t\t\tiLeft++;\n\t\t\t} else {\n\t\t\t\tiRight--;\n\t\t\t}\n\t\t}\n\n\t\tfor (iSrc = iLeft; iSrc <= iRight; iSrc++) {\n\t\t\tdTotalWeight += (res->ContribRow[u].Weights[iSrc-iLeft] =  scale_f_d * (*pFilter)(scale_f_d * (dCenter - (double)iSrc)));\n\t\t}\n\n\t\tif (dTotalWeight < 0.0) {\n\t\t\t_gdContributionsFree(res);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (dTotalWeight > 0.0) {\n\t\t\tfor (iSrc = iLeft; iSrc <= iRight; iSrc++) {\n\t\t\t\tres->ContribRow[u].Weights[iSrc-iLeft] /= dTotalWeight;\n\t\t\t}\n\t\t}\n\t}\n\treturn res;\n}", "func_src_after": "static inline LineContribType *_gdContributionsCalc(unsigned int line_size, unsigned int src_size, double scale_d,  const interpolation_method pFilter)\n{\n\tdouble width_d;\n\tdouble scale_f_d = 1.0;\n\tconst double filter_width_d = DEFAULT_BOX_RADIUS;\n\tint windows_size;\n\tunsigned int u;\n\tLineContribType *res;\n\n\tif (scale_d < 1.0) {\n\t\twidth_d = filter_width_d / scale_d;\n\t\tscale_f_d = scale_d;\n\t}  else {\n\t\twidth_d= filter_width_d;\n\t}\n\n\twindows_size = 2 * (int)ceil(width_d) + 1;\n\tres = _gdContributionsAlloc(line_size, windows_size);\n\n\tfor (u = 0; u < line_size; u++) {\n\t\tconst double dCenter = (double)u / scale_d;\n\t\t/* get the significant edge points affecting the pixel */\n\t\tregister int iLeft = MAX(0, (int)floor (dCenter - width_d));\n\t\tint iRight = MIN((int)ceil(dCenter + width_d), (int)src_size - 1);\n\t\tdouble dTotalWeight = 0.0;\n\t\tint iSrc;\n\n\t\t/* Cut edge points to fit in filter window in case of spill-off */\n\t\tif (iRight - iLeft + 1 > windows_size)  {\n\t\t\tif (iLeft < ((int)src_size - 1 / 2))  {\n\t\t\t\tiLeft++;\n\t\t\t} else {\n\t\t\t\tiRight--;\n\t\t\t}\n\t\t}\n\n\t\tres->ContribRow[u].Left = iLeft;\n\t\tres->ContribRow[u].Right = iRight;\n\n\t\tfor (iSrc = iLeft; iSrc <= iRight; iSrc++) {\n\t\t\tdTotalWeight += (res->ContribRow[u].Weights[iSrc-iLeft] =  scale_f_d * (*pFilter)(scale_f_d * (dCenter - (double)iSrc)));\n\t\t}\n\n\t\tif (dTotalWeight < 0.0) {\n\t\t\t_gdContributionsFree(res);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (dTotalWeight > 0.0) {\n\t\t\tfor (iSrc = iLeft; iSrc <= iRight; iSrc++) {\n\t\t\t\tres->ContribRow[u].Weights[iSrc-iLeft] /= dTotalWeight;\n\t\t\t}\n\t\t}\n\t}\n\treturn res;\n}", "commit_link": "github.com/libgd/libgd/commit/4f65a3e4eedaffa1efcf9ee1eb08f0b504fbc31a", "file_name": "src/gd_interpolation.c", "vul_type": "cwe-125", "description": "In C, write a function to calculate the contribution of source pixels to a line with scaling, using a specified interpolation method."}
{"func_name": "get_uncompressed_data", "func_src_before": "get_uncompressed_data(struct archive_read *a, const void **buff, size_t size,\n    size_t minimum)\n{\n\tstruct _7zip *zip = (struct _7zip *)a->format->data;\n\tssize_t bytes_avail;\n\n\tif (zip->codec == _7Z_COPY && zip->codec2 == (unsigned long)-1) {\n\t\t/* Copy mode. */\n\n\t\t/*\n\t\t * Note: '1' here is a performance optimization.\n\t\t * Recall that the decompression layer returns a count of\n\t\t * available bytes; asking for more than that forces the\n\t\t * decompressor to combine reads by copying data.\n\t\t */\n\t\t*buff = __archive_read_ahead(a, 1, &bytes_avail);\n\t\tif (bytes_avail <= 0) {\n\t\t\tarchive_set_error(&a->archive,\n\t\t\t    ARCHIVE_ERRNO_FILE_FORMAT,\n\t\t\t    \"Truncated 7-Zip file data\");\n\t\t\treturn (ARCHIVE_FATAL);\n\t\t}\n\t\tif ((size_t)bytes_avail >\n\t\t    zip->uncompressed_buffer_bytes_remaining)\n\t\t\tbytes_avail = (ssize_t)\n\t\t\t    zip->uncompressed_buffer_bytes_remaining;\n\t\tif ((size_t)bytes_avail > size)\n\t\t\tbytes_avail = (ssize_t)size;\n\n\t\tzip->pack_stream_bytes_unconsumed = bytes_avail;\n\t} else if (zip->uncompressed_buffer_pointer == NULL) {\n\t\t/* Decompression has failed. */\n\t\tarchive_set_error(&(a->archive),\n\t\t    ARCHIVE_ERRNO_MISC, \"Damaged 7-Zip archive\");\n\t\treturn (ARCHIVE_FATAL);\n\t} else {\n\t\t/* Packed mode. */\n\t\tif (minimum > zip->uncompressed_buffer_bytes_remaining) {\n\t\t\t/*\n\t\t\t * If remaining uncompressed data size is less than\n\t\t\t * the minimum size, fill the buffer up to the\n\t\t\t * minimum size.\n\t\t\t */\n\t\t\tif (extract_pack_stream(a, minimum) < 0)\n\t\t\t\treturn (ARCHIVE_FATAL);\n\t\t}\n\t\tif (size > zip->uncompressed_buffer_bytes_remaining)\n\t\t\tbytes_avail = (ssize_t)\n\t\t\t    zip->uncompressed_buffer_bytes_remaining;\n\t\telse\n\t\t\tbytes_avail = (ssize_t)size;\n\t\t*buff = zip->uncompressed_buffer_pointer;\n\t\tzip->uncompressed_buffer_pointer += bytes_avail;\n\t}\n\tzip->uncompressed_buffer_bytes_remaining -= bytes_avail;\n\treturn (bytes_avail);\n}", "func_src_after": "get_uncompressed_data(struct archive_read *a, const void **buff, size_t size,\n    size_t minimum)\n{\n\tstruct _7zip *zip = (struct _7zip *)a->format->data;\n\tssize_t bytes_avail;\n\n\tif (zip->codec == _7Z_COPY && zip->codec2 == (unsigned long)-1) {\n\t\t/* Copy mode. */\n\n\t\t*buff = __archive_read_ahead(a, minimum, &bytes_avail);\n\t\tif (bytes_avail <= 0) {\n\t\t\tarchive_set_error(&a->archive,\n\t\t\t    ARCHIVE_ERRNO_FILE_FORMAT,\n\t\t\t    \"Truncated 7-Zip file data\");\n\t\t\treturn (ARCHIVE_FATAL);\n\t\t}\n\t\tif ((size_t)bytes_avail >\n\t\t    zip->uncompressed_buffer_bytes_remaining)\n\t\t\tbytes_avail = (ssize_t)\n\t\t\t    zip->uncompressed_buffer_bytes_remaining;\n\t\tif ((size_t)bytes_avail > size)\n\t\t\tbytes_avail = (ssize_t)size;\n\n\t\tzip->pack_stream_bytes_unconsumed = bytes_avail;\n\t} else if (zip->uncompressed_buffer_pointer == NULL) {\n\t\t/* Decompression has failed. */\n\t\tarchive_set_error(&(a->archive),\n\t\t    ARCHIVE_ERRNO_MISC, \"Damaged 7-Zip archive\");\n\t\treturn (ARCHIVE_FATAL);\n\t} else {\n\t\t/* Packed mode. */\n\t\tif (minimum > zip->uncompressed_buffer_bytes_remaining) {\n\t\t\t/*\n\t\t\t * If remaining uncompressed data size is less than\n\t\t\t * the minimum size, fill the buffer up to the\n\t\t\t * minimum size.\n\t\t\t */\n\t\t\tif (extract_pack_stream(a, minimum) < 0)\n\t\t\t\treturn (ARCHIVE_FATAL);\n\t\t}\n\t\tif (size > zip->uncompressed_buffer_bytes_remaining)\n\t\t\tbytes_avail = (ssize_t)\n\t\t\t    zip->uncompressed_buffer_bytes_remaining;\n\t\telse\n\t\t\tbytes_avail = (ssize_t)size;\n\t\t*buff = zip->uncompressed_buffer_pointer;\n\t\tzip->uncompressed_buffer_pointer += bytes_avail;\n\t}\n\tzip->uncompressed_buffer_bytes_remaining -= bytes_avail;\n\treturn (bytes_avail);\n}", "commit_link": "github.com/libarchive/libarchive/commit/65a23f5dbee4497064e9bb467f81138a62b0dae1", "file_name": "libarchive/archive_read_support_format_7zip.c", "vul_type": "cwe-125", "description": "In C, write a function to retrieve uncompressed data from a 7-Zip archive, handling both copy and packed modes."}
{"func_name": "nsv_read_chunk", "func_src_before": "static int nsv_read_chunk(AVFormatContext *s, int fill_header)\n{\n    NSVContext *nsv = s->priv_data;\n    AVIOContext *pb = s->pb;\n    AVStream *st[2] = {NULL, NULL};\n    NSVStream *nst;\n    AVPacket *pkt;\n    int i, err = 0;\n    uint8_t auxcount; /* number of aux metadata, also 4 bits of vsize */\n    uint32_t vsize;\n    uint16_t asize;\n    uint16_t auxsize;\n\n    if (nsv->ahead[0].data || nsv->ahead[1].data)\n        return 0; //-1; /* hey! eat what you've in your plate first! */\n\nnull_chunk_retry:\n    if (pb->eof_reached)\n        return -1;\n\n    for (i = 0; i < NSV_MAX_RESYNC_TRIES && nsv->state < NSV_FOUND_NSVS && !err; i++)\n        err = nsv_resync(s);\n    if (err < 0)\n        return err;\n    if (nsv->state == NSV_FOUND_NSVS)\n        err = nsv_parse_NSVs_header(s);\n    if (err < 0)\n        return err;\n    if (nsv->state != NSV_HAS_READ_NSVS && nsv->state != NSV_FOUND_BEEF)\n        return -1;\n\n    auxcount = avio_r8(pb);\n    vsize = avio_rl16(pb);\n    asize = avio_rl16(pb);\n    vsize = (vsize << 4) | (auxcount >> 4);\n    auxcount &= 0x0f;\n    av_log(s, AV_LOG_TRACE, \"NSV CHUNK %\"PRIu8\" aux, %\"PRIu32\" bytes video, %\"PRIu16\" bytes audio\\n\",\n           auxcount, vsize, asize);\n    /* skip aux stuff */\n    for (i = 0; i < auxcount; i++) {\n        uint32_t av_unused auxtag;\n        auxsize = avio_rl16(pb);\n        auxtag = avio_rl32(pb);\n        avio_skip(pb, auxsize);\n        vsize -= auxsize + sizeof(uint16_t) + sizeof(uint32_t); /* that's becoming brain-dead */\n    }\n\n    if (pb->eof_reached)\n        return -1;\n    if (!vsize && !asize) {\n        nsv->state = NSV_UNSYNC;\n        goto null_chunk_retry;\n    }\n\n    /* map back streams to v,a */\n    if (s->nb_streams > 0)\n        st[s->streams[0]->id] = s->streams[0];\n    if (s->nb_streams > 1)\n        st[s->streams[1]->id] = s->streams[1];\n\n    if (vsize && st[NSV_ST_VIDEO]) {\n        nst = st[NSV_ST_VIDEO]->priv_data;\n        pkt = &nsv->ahead[NSV_ST_VIDEO];\n        av_get_packet(pb, pkt, vsize);\n        pkt->stream_index = st[NSV_ST_VIDEO]->index;//NSV_ST_VIDEO;\n        pkt->dts = nst->frame_offset;\n        pkt->flags |= nsv->state == NSV_HAS_READ_NSVS ? AV_PKT_FLAG_KEY : 0; /* keyframe only likely on a sync frame */\n        for (i = 0; i < FFMIN(8, vsize); i++)\n            av_log(s, AV_LOG_TRACE, \"NSV video: [%d] = %02\"PRIx8\"\\n\",\n                   i, pkt->data[i]);\n    }\n    if(st[NSV_ST_VIDEO])\n        ((NSVStream*)st[NSV_ST_VIDEO]->priv_data)->frame_offset++;\n\n    if (asize && st[NSV_ST_AUDIO]) {\n        nst = st[NSV_ST_AUDIO]->priv_data;\n        pkt = &nsv->ahead[NSV_ST_AUDIO];\n        /* read raw audio specific header on the first audio chunk... */\n        /* on ALL audio chunks ?? seems so! */\n        if (asize && st[NSV_ST_AUDIO]->codecpar->codec_tag == MKTAG('P', 'C', 'M', ' ')/* && fill_header*/) {\n            uint8_t bps;\n            uint8_t channels;\n            uint16_t samplerate;\n            bps = avio_r8(pb);\n            channels = avio_r8(pb);\n            samplerate = avio_rl16(pb);\n            if (!channels || !samplerate)\n                return AVERROR_INVALIDDATA;\n            asize-=4;\n            av_log(s, AV_LOG_TRACE, \"NSV RAWAUDIO: bps %\"PRIu8\", nchan %\"PRIu8\", srate %\"PRIu16\"\\n\",\n                   bps, channels, samplerate);\n            if (fill_header) {\n                st[NSV_ST_AUDIO]->need_parsing = AVSTREAM_PARSE_NONE; /* we know everything */\n                if (bps != 16) {\n                    av_log(s, AV_LOG_TRACE, \"NSV AUDIO bit/sample != 16 (%\"PRIu8\")!!!\\n\", bps);\n                }\n                bps /= channels; // ???\n                if (bps == 8)\n                    st[NSV_ST_AUDIO]->codecpar->codec_id = AV_CODEC_ID_PCM_U8;\n                samplerate /= 4;/* UGH ??? XXX */\n                channels = 1;\n                st[NSV_ST_AUDIO]->codecpar->channels = channels;\n                st[NSV_ST_AUDIO]->codecpar->sample_rate = samplerate;\n                av_log(s, AV_LOG_TRACE, \"NSV RAWAUDIO: bps %\"PRIu8\", nchan %\"PRIu8\", srate %\"PRIu16\"\\n\",\n                       bps, channels, samplerate);\n            }\n        }\n        av_get_packet(pb, pkt, asize);\n        pkt->stream_index = st[NSV_ST_AUDIO]->index;//NSV_ST_AUDIO;\n        pkt->flags |= nsv->state == NSV_HAS_READ_NSVS ? AV_PKT_FLAG_KEY : 0; /* keyframe only likely on a sync frame */\n        if( nsv->state == NSV_HAS_READ_NSVS && st[NSV_ST_VIDEO] ) {\n            /* on a nsvs frame we have new information on a/v sync */\n            pkt->dts = (((NSVStream*)st[NSV_ST_VIDEO]->priv_data)->frame_offset-1);\n            pkt->dts *= (int64_t)1000        * nsv->framerate.den;\n            pkt->dts += (int64_t)nsv->avsync * nsv->framerate.num;\n            av_log(s, AV_LOG_TRACE, \"NSV AUDIO: sync:%\"PRId16\", dts:%\"PRId64,\n                   nsv->avsync, pkt->dts);\n        }\n        nst->frame_offset++;\n    }\n\n    nsv->state = NSV_UNSYNC;\n    return 0;\n}", "func_src_after": "static int nsv_read_chunk(AVFormatContext *s, int fill_header)\n{\n    NSVContext *nsv = s->priv_data;\n    AVIOContext *pb = s->pb;\n    AVStream *st[2] = {NULL, NULL};\n    NSVStream *nst;\n    AVPacket *pkt;\n    int i, err = 0;\n    uint8_t auxcount; /* number of aux metadata, also 4 bits of vsize */\n    uint32_t vsize;\n    uint16_t asize;\n    uint16_t auxsize;\n    int ret;\n\n    if (nsv->ahead[0].data || nsv->ahead[1].data)\n        return 0; //-1; /* hey! eat what you've in your plate first! */\n\nnull_chunk_retry:\n    if (pb->eof_reached)\n        return -1;\n\n    for (i = 0; i < NSV_MAX_RESYNC_TRIES && nsv->state < NSV_FOUND_NSVS && !err; i++)\n        err = nsv_resync(s);\n    if (err < 0)\n        return err;\n    if (nsv->state == NSV_FOUND_NSVS)\n        err = nsv_parse_NSVs_header(s);\n    if (err < 0)\n        return err;\n    if (nsv->state != NSV_HAS_READ_NSVS && nsv->state != NSV_FOUND_BEEF)\n        return -1;\n\n    auxcount = avio_r8(pb);\n    vsize = avio_rl16(pb);\n    asize = avio_rl16(pb);\n    vsize = (vsize << 4) | (auxcount >> 4);\n    auxcount &= 0x0f;\n    av_log(s, AV_LOG_TRACE, \"NSV CHUNK %\"PRIu8\" aux, %\"PRIu32\" bytes video, %\"PRIu16\" bytes audio\\n\",\n           auxcount, vsize, asize);\n    /* skip aux stuff */\n    for (i = 0; i < auxcount; i++) {\n        uint32_t av_unused auxtag;\n        auxsize = avio_rl16(pb);\n        auxtag = avio_rl32(pb);\n        avio_skip(pb, auxsize);\n        vsize -= auxsize + sizeof(uint16_t) + sizeof(uint32_t); /* that's becoming brain-dead */\n    }\n\n    if (pb->eof_reached)\n        return -1;\n    if (!vsize && !asize) {\n        nsv->state = NSV_UNSYNC;\n        goto null_chunk_retry;\n    }\n\n    /* map back streams to v,a */\n    if (s->nb_streams > 0)\n        st[s->streams[0]->id] = s->streams[0];\n    if (s->nb_streams > 1)\n        st[s->streams[1]->id] = s->streams[1];\n\n    if (vsize && st[NSV_ST_VIDEO]) {\n        nst = st[NSV_ST_VIDEO]->priv_data;\n        pkt = &nsv->ahead[NSV_ST_VIDEO];\n        if ((ret = av_get_packet(pb, pkt, vsize)) < 0)\n            return ret;\n        pkt->stream_index = st[NSV_ST_VIDEO]->index;//NSV_ST_VIDEO;\n        pkt->dts = nst->frame_offset;\n        pkt->flags |= nsv->state == NSV_HAS_READ_NSVS ? AV_PKT_FLAG_KEY : 0; /* keyframe only likely on a sync frame */\n        for (i = 0; i < FFMIN(8, vsize); i++)\n            av_log(s, AV_LOG_TRACE, \"NSV video: [%d] = %02\"PRIx8\"\\n\",\n                   i, pkt->data[i]);\n    }\n    if(st[NSV_ST_VIDEO])\n        ((NSVStream*)st[NSV_ST_VIDEO]->priv_data)->frame_offset++;\n\n    if (asize && st[NSV_ST_AUDIO]) {\n        nst = st[NSV_ST_AUDIO]->priv_data;\n        pkt = &nsv->ahead[NSV_ST_AUDIO];\n        /* read raw audio specific header on the first audio chunk... */\n        /* on ALL audio chunks ?? seems so! */\n        if (asize && st[NSV_ST_AUDIO]->codecpar->codec_tag == MKTAG('P', 'C', 'M', ' ')/* && fill_header*/) {\n            uint8_t bps;\n            uint8_t channels;\n            uint16_t samplerate;\n            bps = avio_r8(pb);\n            channels = avio_r8(pb);\n            samplerate = avio_rl16(pb);\n            if (!channels || !samplerate)\n                return AVERROR_INVALIDDATA;\n            asize-=4;\n            av_log(s, AV_LOG_TRACE, \"NSV RAWAUDIO: bps %\"PRIu8\", nchan %\"PRIu8\", srate %\"PRIu16\"\\n\",\n                   bps, channels, samplerate);\n            if (fill_header) {\n                st[NSV_ST_AUDIO]->need_parsing = AVSTREAM_PARSE_NONE; /* we know everything */\n                if (bps != 16) {\n                    av_log(s, AV_LOG_TRACE, \"NSV AUDIO bit/sample != 16 (%\"PRIu8\")!!!\\n\", bps);\n                }\n                bps /= channels; // ???\n                if (bps == 8)\n                    st[NSV_ST_AUDIO]->codecpar->codec_id = AV_CODEC_ID_PCM_U8;\n                samplerate /= 4;/* UGH ??? XXX */\n                channels = 1;\n                st[NSV_ST_AUDIO]->codecpar->channels = channels;\n                st[NSV_ST_AUDIO]->codecpar->sample_rate = samplerate;\n                av_log(s, AV_LOG_TRACE, \"NSV RAWAUDIO: bps %\"PRIu8\", nchan %\"PRIu8\", srate %\"PRIu16\"\\n\",\n                       bps, channels, samplerate);\n            }\n        }\n        if ((ret = av_get_packet(pb, pkt, asize)) < 0)\n            return ret;\n        pkt->stream_index = st[NSV_ST_AUDIO]->index;//NSV_ST_AUDIO;\n        pkt->flags |= nsv->state == NSV_HAS_READ_NSVS ? AV_PKT_FLAG_KEY : 0; /* keyframe only likely on a sync frame */\n        if( nsv->state == NSV_HAS_READ_NSVS && st[NSV_ST_VIDEO] ) {\n            /* on a nsvs frame we have new information on a/v sync */\n            pkt->dts = (((NSVStream*)st[NSV_ST_VIDEO]->priv_data)->frame_offset-1);\n            pkt->dts *= (int64_t)1000        * nsv->framerate.den;\n            pkt->dts += (int64_t)nsv->avsync * nsv->framerate.num;\n            av_log(s, AV_LOG_TRACE, \"NSV AUDIO: sync:%\"PRId16\", dts:%\"PRId64,\n                   nsv->avsync, pkt->dts);\n        }\n        nst->frame_offset++;\n    }\n\n    nsv->state = NSV_UNSYNC;\n    return 0;\n}", "commit_link": "github.com/libav/libav/commit/fe6eea99efac66839052af547426518efd970b24", "file_name": "libavformat/nsvdec.c", "vul_type": "cwe-476", "description": "Write a C function named `nsv_read_chunk` that reads a chunk of NSV format data from a given AVFormatContext."}
{"func_name": "audit", "func_src_before": "  def audit\n    audit_args.parse\n\n    Homebrew.auditing = true\n    inject_dump_stats!(FormulaAuditor, /^audit_/) if args.audit_debug?\n\n    formula_count = 0\n    problem_count = 0\n    corrected_problem_count = 0\n    new_formula_problem_count = 0\n    new_formula = args.new_formula?\n    strict = new_formula || args.strict?\n    online = new_formula || args.online?\n    git = args.git?\n    skip_style = args.skip_style? || args.no_named?\n\n    ENV.activate_extensions!\n    ENV.setup_build_environment\n\n    audit_formulae = args.no_named? ? Formula : args.resolved_formulae\n    style_files = args.formulae_paths unless skip_style\n\n    only_cops = args.only_cops\n    except_cops = args.except_cops\n    options = { fix: args.fix? }\n\n    if only_cops\n      options[:only_cops] = only_cops\n    elsif args.new_formula?\n      nil\n    elsif except_cops\n      options[:except_cops] = except_cops\n    elsif !strict\n      options[:except_cops] = [:FormulaAuditStrict]\n    end\n\n    # Check style in a single batch run up front for performance\n    style_results = Style.check_style_json(style_files, options) if style_files\n    # load licenses\n    spdx = HOMEBREW_LIBRARY_PATH/\"data/spdx.json\"\n    spdx_data = open(spdx, \"r\") do |file|\n      JSON.parse(file.read)\n    end\n    new_formula_problem_lines = []\n    audit_formulae.sort.each do |f|\n      only = only_cops ? [\"style\"] : args.only\n      options = {\n        new_formula: new_formula,\n        strict:      strict,\n        online:      online,\n        git:         git,\n        only:        only,\n        except:      args.except,\n        spdx_data:   spdx_data,\n      }\n      options[:style_offenses] = style_results.file_offenses(f.path) if style_results\n      options[:display_cop_names] = args.display_cop_names?\n\n      fa = FormulaAuditor.new(f, options)\n      fa.audit\n      next if fa.problems.empty? && fa.new_formula_problems.empty?\n\n      fa.problems\n      formula_count += 1\n      problem_count += fa.problems.size\n      problem_lines = format_problem_lines(fa.problems)\n      corrected_problem_count = options[:style_offenses].count(&:corrected?) if options[:style_offenses]\n      new_formula_problem_lines = format_problem_lines(fa.new_formula_problems)\n      if args.display_filename?\n        puts problem_lines.map { |s| \"#{f.path}: #{s}\" }\n      else\n        puts \"#{f.full_name}:\", problem_lines.map { |s| \"  #{s}\" }\n      end", "func_src_after": "  def audit\n    audit_args.parse\n\n    Homebrew.auditing = true\n    inject_dump_stats!(FormulaAuditor, /^audit_/) if args.audit_debug?\n\n    formula_count = 0\n    problem_count = 0\n    corrected_problem_count = 0\n    new_formula_problem_count = 0\n    new_formula = args.new_formula?\n    strict = new_formula || args.strict?\n    online = new_formula || args.online?\n    git = args.git?\n    skip_style = args.skip_style? || args.no_named?\n\n    ENV.activate_extensions!\n    ENV.setup_build_environment\n\n    audit_formulae = args.no_named? ? Formula : args.resolved_formulae\n    style_files = args.formulae_paths unless skip_style\n\n    only_cops = args.only_cops\n    except_cops = args.except_cops\n    options = { fix: args.fix? }\n\n    if only_cops\n      options[:only_cops] = only_cops\n    elsif args.new_formula?\n      nil\n    elsif except_cops\n      options[:except_cops] = except_cops\n    elsif !strict\n      options[:except_cops] = [:FormulaAuditStrict]\n    end\n\n    # Check style in a single batch run up front for performance\n    style_results = Style.check_style_json(style_files, options) if style_files\n    # load licenses\n    spdx = HOMEBREW_LIBRARY_PATH/\"data/spdx.json\"\n    spdx_data = File.open(spdx, \"r\") do |file|\n      JSON.parse(file.read)\n    end\n    new_formula_problem_lines = []\n    audit_formulae.sort.each do |f|\n      only = only_cops ? [\"style\"] : args.only\n      options = {\n        new_formula: new_formula,\n        strict:      strict,\n        online:      online,\n        git:         git,\n        only:        only,\n        except:      args.except,\n        spdx_data:   spdx_data,\n      }\n      options[:style_offenses] = style_results.file_offenses(f.path) if style_results\n      options[:display_cop_names] = args.display_cop_names?\n\n      fa = FormulaAuditor.new(f, options)\n      fa.audit\n      next if fa.problems.empty? && fa.new_formula_problems.empty?\n\n      fa.problems\n      formula_count += 1\n      problem_count += fa.problems.size\n      problem_lines = format_problem_lines(fa.problems)\n      corrected_problem_count = options[:style_offenses].count(&:corrected?) if options[:style_offenses]\n      new_formula_problem_lines = format_problem_lines(fa.new_formula_problems)\n      if args.display_filename?\n        puts problem_lines.map { |s| \"#{f.path}: #{s}\" }\n      else\n        puts \"#{f.full_name}:\", problem_lines.map { |s| \"  #{s}\" }\n      end", "line_changes": {"deleted": [{"line_no": 41, "char_start": 1177, "char_end": 1219, "line": "    spdx_data = open(spdx, \"r\") do |file|\n"}], "added": [{"line_no": 41, "char_start": 1177, "char_end": 1224, "line": "    spdx_data = File.open(spdx, \"r\") do |file|\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 1193, "char_end": 1198, "chars": "File."}]}, "commit_link": "github.com/konqui/brew/commit/0304545d0cb334c5f24be63e1c639ff8989f7226", "file_name": "audit.rb", "vul_type": "cwe-078", "commit_msg": "use File.open instead of Kernel.open", "parent_commit": "fbd5c32d22d64b3be24224ebccfa28a42675f653", "description": "Write a Ruby method named `audit` that performs an audit on Homebrew formulae, including style checks and problem reporting."}
{"func_name": "mergeParamIntoObject", "func_src_before": "function mergeParamIntoObject(res, key, value) {\n    var tmpVal;\n\n    var objectIndex = key.indexOf(\".\");\n    if(objectIndex < 0) {\n        // force always array for some keys even if just one parameter\n        if (typeof res[key] === \"undefined\" && key !== \"heading\" && key !== \"point\" && key !== \"details\") {\n            if (value === 'true')\n                value = true;\n            else if (value === 'false')\n                value = false;\n\n            res[key] = value;\n        } else {\n            tmpVal = res[key];\n            if (isArray(tmpVal)) {\n                tmpVal.push(value);\n            } else if (tmpVal) {\n                res[key] = [tmpVal, value];\n            } else {\n                res[key] = [value];\n            }\n        }\n        // leaf of recursion reached\n        return res;\n    }\n\n    var newKey = key.substring(0, objectIndex);\n    var subKey = key.substring(objectIndex + 1);\n\n    tmpVal = res[newKey];\n    if(!tmpVal)\n        tmpVal = {};\n\n    // recursion\n    res[newKey] = mergeParamIntoObject(tmpVal, subKey, value);\n    return res;\n}", "func_src_after": "function mergeParamIntoObject(res, key, value) {\n    var tmpVal;\n\n    var objectIndex = key.indexOf(\".\");\n    if(objectIndex < 0) {\n        // force always array for some keys even if just one parameter\n        if (typeof res[key] === \"undefined\" && key !== \"heading\" && key !== \"point\" && key !== \"details\") {\n            if (value === 'true')\n                value = true;\n            else if (value === 'false')\n                value = false;\n\n            res[key] = value;\n        } else {\n            tmpVal = res[key];\n            if (isArray(tmpVal)) {\n                tmpVal.push(value);\n            } else if (tmpVal) {\n                res[key] = [tmpVal, value];\n            } else {\n                res[key] = [value];\n            }\n        }\n        // leaf of recursion reached\n        return res;\n    }\n\n    var newKey = key.substring(0, objectIndex);\n    var subKey = key.substring(objectIndex + 1);\n\n    if(newKey == \"__proto__\" || newKey == \"constructor\" || newKey == \"prototype\") return res;\n\n    tmpVal = res[newKey];\n    if(!tmpVal)\n        tmpVal = {};\n\n    // recursion\n    res[newKey] = mergeParamIntoObject(tmpVal, subKey, value);\n    return res;\n}", "line_changes": {"deleted": [], "added": [{"line_no": 31, "char_start": 916, "char_end": 1010, "line": "    if(newKey == \"__proto__\" || newKey == \"constructor\" || newKey == \"prototype\") return res;\n"}, {"line_no": 32, "char_start": 1010, "char_end": 1011, "line": "\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 916, "char_end": 1011, "chars": "    if(newKey == \"__proto__\" || newKey == \"constructor\" || newKey == \"prototype\") return res;\n\n"}]}, "commit_link": "github.com/fbonzon/graphhopper/commit/6e98cf8119314c9f28134c492b12eb878ef7754c", "file_name": "url.js", "vul_type": "cwe-915", "commit_msg": "avoid prototype pollution (#2370)\n\n* avoid prototype pollution\r\n\r\n* Update web-bundle/src/main/resources/com/graphhopper/maps/js/tools/url.js\r\n\r\nCo-authored-by: Kirill <kirill89@gmail.com>\r\n\r\n* Update web-bundle/src/test/resources/com/graphhopper/maps/spec/tools/urlSpec.js\r\n\r\nCo-authored-by: Kirill <kirill89@gmail.com>\r\n\r\n* add expected in test\r\n\r\nCo-authored-by: Kirill <kirill89@gmail.com>", "parent_commit": "d3ce1c14cd133773e4a692f3ec4fb7572e171e19", "description": "In JavaScript, write a function to recursively merge a key-value pair into an object, handling dot notation in keys and converting 'true'/'false' strings to booleans."}
{"func_name": "smprintf", "func_src_before": "smprintf(const char *fmt, ...)\n{\n\tva_list fmtargs;\n\tchar tmp[120];\n\tchar *ret = NULL;\n\n\tva_start(fmtargs, fmt);\n\tsnprintf(tmp, sizeof(tmp)-1, fmt, fmtargs);\n\ttmp[sizeof(tmp)] = '\\0';\n\tif (asprintf(&ret, \"%s\", tmp) < 0)\n\t\treturn NULL;\n\n\tva_end(fmtargs);\n\treturn ret;\n}", "func_src_after": "smprintf(const char *fmt, ...)\n{\n\t/* FIXME: This code should have\n\tbound checks, it is vulnerable to\n\tbuffer overflows */\n\tva_list ap;\n\tchar *ret = NULL;\n\n\tva_start(ap, fmt);\n\tif (vasprintf(&ret, fmt, ap) < 0)\n\t\treturn NULL;\n\n\tva_end(ap);\n\treturn ret;\n}", "line_changes": {"deleted": [{"line_no": 3, "char_start": 33, "char_end": 51, "line": "\tva_list fmtargs;\n"}, {"line_no": 4, "char_start": 51, "char_end": 67, "line": "\tchar tmp[120];\n"}, {"line_no": 7, "char_start": 87, "char_end": 112, "line": "\tva_start(fmtargs, fmt);\n"}, {"line_no": 8, "char_start": 112, "char_end": 157, "line": "\tsnprintf(tmp, sizeof(tmp)-1, fmt, fmtargs);\n"}, {"line_no": 9, "char_start": 157, "char_end": 183, "line": "\ttmp[sizeof(tmp)] = '\\0';\n"}, {"line_no": 10, "char_start": 183, "char_end": 219, "line": "\tif (asprintf(&ret, \"%s\", tmp) < 0)\n"}, {"line_no": 13, "char_start": 235, "char_end": 253, "line": "\tva_end(fmtargs);\n"}], "added": [{"line_no": 3, "char_start": 33, "char_end": 66, "line": "\t/* FIXME: This code should have\n"}, {"line_no": 4, "char_start": 66, "char_end": 101, "line": "\tbound checks, it is vulnerable to\n"}, {"line_no": 5, "char_start": 101, "char_end": 122, "line": "\tbuffer overflows */\n"}, {"line_no": 6, "char_start": 122, "char_end": 135, "line": "\tva_list ap;\n"}, {"line_no": 9, "char_start": 155, "char_end": 175, "line": "\tva_start(ap, fmt);\n"}, {"line_no": 10, "char_start": 175, "char_end": 210, "line": "\tif (vasprintf(&ret, fmt, ap) < 0)\n"}, {"line_no": 13, "char_start": 226, "char_end": 239, "line": "\tva_end(ap);\n"}]}, "char_changes": {"deleted": [{"char_start": 34, "char_end": 181, "chars": "va_list fmtargs;\n\tchar tmp[120];\n\tchar *ret = NULL;\n\n\tva_start(fmtargs, fmt);\n\tsnprintf(tmp, sizeof(tmp)-1, fmt, fmtargs);\n\ttmp[sizeof(tmp)] = '\\0'"}, {"char_start": 203, "char_end": 211, "chars": "\"%s\", tm"}, {"char_start": 243, "char_end": 250, "chars": "fmtargs"}], "added": [{"char_start": 34, "char_end": 173, "chars": "/* FIXME: This code should have\n\tbound checks, it is vulnerable to\n\tbuffer overflows */\n\tva_list ap;\n\tchar *ret = NULL;\n\n\tva_start(ap, fmt)"}, {"char_start": 180, "char_end": 181, "chars": "v"}, {"char_start": 196, "char_end": 202, "chars": "fmt, a"}, {"char_start": 234, "char_end": 236, "chars": "ap"}]}, "commit_link": "github.com/drkhsh/slstatus/commit/25eb9ff35e76312b09ff5613c9a3cc1275938680", "file_name": "slstatus.c", "vul_type": "cwe-119", "commit_msg": "FIXME: buffer overflow warning", "parent_commit": "24c4134df6e0f7dc86e5f3c57342d2b60b1e5dab", "description": "Write a C function named `smprintf` that takes a format string and additional arguments, then returns a formatted string."}
{"func_name": "keyctl_read_key", "func_src_before": "long keyctl_read_key(key_serial_t keyid, char __user *buffer, size_t buflen)\n{\n\tstruct key *key;\n\tkey_ref_t key_ref;\n\tlong ret;\n\n\t/* find the key first */\n\tkey_ref = lookup_user_key(keyid, 0, 0);\n\tif (IS_ERR(key_ref)) {\n\t\tret = -ENOKEY;\n\t\tgoto error;\n\t}\n\n\tkey = key_ref_to_ptr(key_ref);\n\n\t/* see if we can read it directly */\n\tret = key_permission(key_ref, KEY_NEED_READ);\n\tif (ret == 0)\n\t\tgoto can_read_key;\n\tif (ret != -EACCES)\n\t\tgoto error2;\n\n\t/* we can't; see if it's searchable from this process's keyrings\n\t * - we automatically take account of the fact that it may be\n\t *   dangling off an instantiation key\n\t */\n\tif (!is_key_possessed(key_ref)) {\n\t\tret = -EACCES;\n\t\tgoto error2;\n\t}\n\n\t/* the key is probably readable - now try to read it */\ncan_read_key:\n\tret = -EOPNOTSUPP;\n\tif (key->type->read) {\n\t\t/* Read the data with the semaphore held (since we might sleep)\n\t\t * to protect against the key being updated or revoked.\n\t\t */\n\t\tdown_read(&key->sem);\n\t\tret = key_validate(key);\n\t\tif (ret == 0)\n\t\t\tret = key->type->read(key, buffer, buflen);\n\t\tup_read(&key->sem);\n\t}\n\nerror2:\n\tkey_put(key);\nerror:\n\treturn ret;\n}", "func_src_after": "long keyctl_read_key(key_serial_t keyid, char __user *buffer, size_t buflen)\n{\n\tstruct key *key;\n\tkey_ref_t key_ref;\n\tlong ret;\n\n\t/* find the key first */\n\tkey_ref = lookup_user_key(keyid, 0, 0);\n\tif (IS_ERR(key_ref)) {\n\t\tret = -ENOKEY;\n\t\tgoto error;\n\t}\n\n\tkey = key_ref_to_ptr(key_ref);\n\n\tif (test_bit(KEY_FLAG_NEGATIVE, &key->flags)) {\n\t\tret = -ENOKEY;\n\t\tgoto error2;\n\t}\n\n\t/* see if we can read it directly */\n\tret = key_permission(key_ref, KEY_NEED_READ);\n\tif (ret == 0)\n\t\tgoto can_read_key;\n\tif (ret != -EACCES)\n\t\tgoto error2;\n\n\t/* we can't; see if it's searchable from this process's keyrings\n\t * - we automatically take account of the fact that it may be\n\t *   dangling off an instantiation key\n\t */\n\tif (!is_key_possessed(key_ref)) {\n\t\tret = -EACCES;\n\t\tgoto error2;\n\t}\n\n\t/* the key is probably readable - now try to read it */\ncan_read_key:\n\tret = -EOPNOTSUPP;\n\tif (key->type->read) {\n\t\t/* Read the data with the semaphore held (since we might sleep)\n\t\t * to protect against the key being updated or revoked.\n\t\t */\n\t\tdown_read(&key->sem);\n\t\tret = key_validate(key);\n\t\tif (ret == 0)\n\t\t\tret = key->type->read(key, buffer, buflen);\n\t\tup_read(&key->sem);\n\t}\n\nerror2:\n\tkey_put(key);\nerror:\n\treturn ret;\n}", "commit_link": "github.com/torvalds/linux/commit/37863c43b2c6464f252862bf2e9768264e961678", "file_name": "security/keys/keyctl.c", "vul_type": "cwe-476", "description": "Write a C function named `keyctl_read_key` that reads data from a specified key into a buffer, handling permissions and errors."}
{"func_name": "test_feature_tags", "func_src_before": "def test_feature_tags():\n\n    with open(util.base_dir() + \"/mapper.yaml\", \"r\") as mapper_file:\n        mapper_content = mapper_file.read()\n    mapper_yaml = yaml.load(mapper_content)\n    testmappers = [x for x in mapper_yaml[\"testmapper\"]]\n    mapper_tests = [\n        list(x.keys())[0] for tm in testmappers for x in mapper_yaml[\"testmapper\"][tm]\n    ]\n\n    def check_ver(tag):\n        for ver_prefix, ver_len in [\n            [\"ver\", 3],\n            [\"rhelver\", 2],\n            [\"fedoraver\", 1],\n        ]:\n            if not tag.startswith(ver_prefix):\n                continue\n            op, ver = misc.test_version_tag_parse(tag, ver_prefix)\n            assert type(op) is str\n            assert type(ver) is list\n            assert op in [\"+\", \"+=\", \"-\", \"-=\"]\n            assert ver\n            assert all([type(v) is int for v in ver])\n            assert all([v >= 0 for v in ver])\n            assert len(ver) <= ver_len\n            assert tag.startswith(ver_prefix + op)\n            return True\n        return tag in [\n            \"rhel_pkg\",\n            \"not_with_rhel_pkg\",\n            \"fedora_pkg\",\n            \"not_with_fedora_pkg\",\n        ]\n\n    def check_bugzilla(tag):\n        if tag.startswith(\"rhbz\"):\n            assert re.match(\"^rhbz[0-9]+$\", tag)\n            return True\n        if tag.startswith(\"gnomebz\"):\n            assert re.match(\"^gnomebz[0-9]+$\", tag)\n            return True\n        return False\n\n    def check_registry(tag):\n        return tag in tag_registry.tag_registry\n\n    def check_mapper(tag):\n        return tag in mapper_tests\n\n    for feature in [\"nmcli\", \"nmtui\"]:\n        all_tags = misc.test_load_tags_from_features(feature)\n\n        tag_registry_used = set()\n        unique_tags = set()\n        for tags in all_tags:\n            assert tags\n            assert type(tags) is list\n            test_in_mapper = False\n            for tag in tags:\n                assert type(tag) is str\n                assert tag\n                assert re.match(\"^[-a-z_.A-Z0-9+=]+$\", tag)\n                assert re.match(\"^\" + misc.TEST_NAME_VALID_CHAR_REGEX + \"+$\", tag)\n                assert tags.count(tag) == 1, f'tag \"{tag}\" is not unique in {tags}'\n                is_ver = check_ver(tag)\n                is_bugzilla = check_bugzilla(tag)\n                is_registry = check_registry(tag)\n                is_mapper = check_mapper(tag)\n                test_in_mapper = test_in_mapper or is_mapper\n                if is_registry:\n                    tag_registry_used.add(tag)\n                assert (\n                    is_ver or is_bugzilla or is_registry or is_mapper\n                ), f'tag \"{tag}\" has no effect'\n                assert [is_ver, is_bugzilla, is_registry, is_mapper].count(True) == 1, (\n                    f'tag \"{tag}\" is multipurpose ({\"mapper, \" if is_mapper else \"\"}'\n                    f'{\"registry, \" if is_registry else \"\"}{\"ver, \" if is_ver else \"\"}'\n                    f'{\"bugzilla, \" if is_bugzilla else \"\"})'\n                )\n\n            assert test_in_mapper, f\"none of {tags} is in mapper\"\n\n            tt = tuple(tags)\n            if tt in unique_tags:\n                pytest.fail(f'tags \"{tags}\" are duplicate over the {feature} tests')\n            unique_tags.add(tt)", "func_src_after": "def test_feature_tags():\n\n    with open(util.base_dir() + \"/mapper.yaml\", \"r\") as mapper_file:\n        mapper_content = mapper_file.read()\n    mapper_yaml = yaml.load(mapper_content, Loader=yaml.BaseLoader)\n    testmappers = [x for x in mapper_yaml[\"testmapper\"]]\n    mapper_tests = [\n        list(x.keys())[0] for tm in testmappers for x in mapper_yaml[\"testmapper\"][tm]\n    ]\n\n    def check_ver(tag):\n        for ver_prefix, ver_len in [\n            [\"ver\", 3],\n            [\"rhelver\", 2],\n            [\"fedoraver\", 1],\n        ]:\n            if not tag.startswith(ver_prefix):\n                continue\n            op, ver = misc.test_version_tag_parse(tag, ver_prefix)\n            assert type(op) is str\n            assert type(ver) is list\n            assert op in [\"+\", \"+=\", \"-\", \"-=\"]\n            assert ver\n            assert all([type(v) is int for v in ver])\n            assert all([v >= 0 for v in ver])\n            assert len(ver) <= ver_len\n            assert tag.startswith(ver_prefix + op)\n            return True\n        return tag in [\n            \"rhel_pkg\",\n            \"not_with_rhel_pkg\",\n            \"fedora_pkg\",\n            \"not_with_fedora_pkg\",\n        ]\n\n    def check_bugzilla(tag):\n        if tag.startswith(\"rhbz\"):\n            assert re.match(\"^rhbz[0-9]+$\", tag)\n            return True\n        if tag.startswith(\"gnomebz\"):\n            assert re.match(\"^gnomebz[0-9]+$\", tag)\n            return True\n        return False\n\n    def check_registry(tag):\n        return tag in tag_registry.tag_registry\n\n    def check_mapper(tag):\n        return tag in mapper_tests\n\n    for feature in [\"nmcli\", \"nmtui\"]:\n        all_tags = misc.test_load_tags_from_features(feature)\n\n        tag_registry_used = set()\n        unique_tags = set()\n        for tags in all_tags:\n            assert tags\n            assert type(tags) is list\n            test_in_mapper = False\n            for tag in tags:\n                assert type(tag) is str\n                assert tag\n                assert re.match(\"^[-a-z_.A-Z0-9+=]+$\", tag)\n                assert re.match(\"^\" + misc.TEST_NAME_VALID_CHAR_REGEX + \"+$\", tag)\n                assert tags.count(tag) == 1, f'tag \"{tag}\" is not unique in {tags}'\n                is_ver = check_ver(tag)\n                is_bugzilla = check_bugzilla(tag)\n                is_registry = check_registry(tag)\n                is_mapper = check_mapper(tag)\n                test_in_mapper = test_in_mapper or is_mapper\n                if is_registry:\n                    tag_registry_used.add(tag)\n                assert (\n                    is_ver or is_bugzilla or is_registry or is_mapper\n                ), f'tag \"{tag}\" has no effect'\n                assert [is_ver, is_bugzilla, is_registry, is_mapper].count(True) == 1, (\n                    f'tag \"{tag}\" is multipurpose ({\"mapper, \" if is_mapper else \"\"}'\n                    f'{\"registry, \" if is_registry else \"\"}{\"ver, \" if is_ver else \"\"}'\n                    f'{\"bugzilla, \" if is_bugzilla else \"\"})'\n                )\n\n            assert test_in_mapper, f\"none of {tags} is in mapper\"\n\n            tt = tuple(tags)\n            if tt in unique_tags:\n                pytest.fail(f'tags \"{tags}\" are duplicate over the {feature} tests')\n            unique_tags.add(tt)", "line_changes": {"deleted": [{"line_no": 5, "char_start": 139, "char_end": 183, "line": "    mapper_yaml = yaml.load(mapper_content)\n"}], "added": [{"line_no": 5, "char_start": 139, "char_end": 207, "line": "    mapper_yaml = yaml.load(mapper_content, Loader=yaml.BaseLoader)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 181, "char_end": 205, "chars": ", Loader=yaml.BaseLoader"}]}, "commit_link": "github.com/NetworkManager/NetworkManager-ci/commit/e8a0a1686315dc988b3600ce80ff3953cccb7b4b", "file_name": "test.py", "vul_type": "cwe-502", "commit_msg": "nmci/test: avoid deprecation warning for yaml.load()\n\nAvoids:\n\n  nmci/test.py::test_feature_tags\n    /TMP/NetworkManager-ci/nmci/test.py:411: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n      mapper_yaml = yaml.load(mapper_content)\n\n  -- Docs: https://docs.pytest.org/en/stable/warnings.html", "parent_commit": "5e80ca2fac5f2fa62e0daccc6703b69694a97f51", "description": "Write a Python function to validate feature tags against various criteria, including version tags, bugzilla tags, and a tag registry."}
{"func_name": "main", "func_src_before": "def main(argv):\n\tparser = ArgumentParser(argv[0], description=__doc__,\n\t\tformatter_class=lambda prog: HelpFormatter(prog, max_help_position=10, width=120))\n\tparser.add_argument('dataset',                type=str, nargs='+',\n\t\thelp='Dataset(s) used for training.')\n\tparser.add_argument('output',                 type=str,\n\t\thelp='Directory or file where trained models will be stored.')\n\tparser.add_argument('--num_components', '-c', type=int,   default=3,\n\t\thelp='Number of components used in STM model (default: %(default)d).')\n\tparser.add_argument('--num_features',   '-f', type=int,   default=2,\n\t\thelp='Number of quadratic features used in STM model (default: %(default)d).')\n\tparser.add_argument('--num_models',     '-m', type=int,   default=4,\n\t\thelp='Number of models trained (predictions will be averaged across models, default: %(default)d).')\n\tparser.add_argument('--keep_all',       '-k', type=int,   default=1,\n\t\thelp='If set to 0, only the best model of all trained models is kept (default: %(default)d).')\n\tparser.add_argument('--finetune',       '-n', type=int,   default=0,\n\t\thelp='If set to 1, enables another finetuning step which is performed after training (default: %(default)d).')\n\tparser.add_argument('--num_train',      '-t', type=int,   default=0,\n\t\thelp='If specified, a (random) subset of cells is used for training.')\n\tparser.add_argument('--num_valid',      '-s', type=int,   default=0,\n\t\thelp='If specified, a (random) subset of cells will be used for early stopping based on validation error.')\n\tparser.add_argument('--var_explained',  '-e', type=float, default=95.,\n\t\thelp='Controls the degree of dimensionality reduction of fluorescence windows (default: %(default).0f).')\n\tparser.add_argument('--window_length',  '-w', type=float, default=1000.,\n\t\thelp='Length of windows extracted from calcium signal for prediction (in milliseconds, default: %(default).0f).')\n\tparser.add_argument('--regularize',     '-r', type=float, default=0.,\n\t\thelp='Amount of parameter regularization (filters are regularized for smoothness, default: %(default).1f).')\n\tparser.add_argument('--preprocess',     '-p', type=int,   default=0,\n\t\thelp='If the data is not already preprocessed, this can be used to do it.')\n\tparser.add_argument('--verbosity',      '-v', type=int,   default=1)\n\n\targs, _ = parser.parse_known_args(argv[1:])\n\n\texperiment = Experiment()\n\n\tif not args.dataset:\n\t\tprint 'You have to specify at least 1 dataset.'\n\t\treturn 0\n\n\tdata = []\n\tfor dataset in args.dataset:\n\t\twith open(dataset) as handle:\n\t\t\tdata = data + load(handle)\n\n\tif args.preprocess:\n\t\tdata = preprocess(data, args.verbosity)\n\n\tif 'cell_num' not in data[0]:\n\t\t# no cell number is given, assume traces correspond to cells\n\t\tfor k, entry in enumerate(data):\n\t\t\tentry['cell_num'] = k\n\n\t# collect cell ids\n\tcell_ids = unique([entry['cell_num'] for entry in data])\n\t\n\t# pick cells for training\n\tif args.num_train > 0:\n\t\ttraining_cells = random_select(args.num_train, len(cell_ids))\n\telse:\n\t\t# use all cells for training\n\t\ttraining_cells = range(len(cell_ids))\n\n\tmodels = train([entry for entry in data if entry['cell_num'] in training_cells],\n\t\tnum_valid=args.num_valid,\n\t\tnum_models=args.num_models,\n\t\tvar_explained=args.var_explained,\n\t\twindow_length=args.window_length,\n\t\tkeep_all=args.keep_all,\n\t\tfinetune=args.finetune,\n\t\tmodel_parameters={\n\t\t\t'num_components': args.num_components,\n\t\t\t'num_features': args.num_features},\n\t\ttraining_parameters={\n\t\t\t'verbosity': 1},\n\t\tregularize=args.regularize,\n\t\tverbosity=args.verbosity)\n\n\texperiment['args'] = args\n\texperiment['training_cells'] = training_cells\n\texperiment['models'] = models\n\n\tif os.path.isdir(args.output):\n\t\texperiment.save(os.path.join(args.output, 'model.xpck'))\n\telse:\n\t\texperiment.save(args.output)\n\n\treturn 0", "func_src_after": "def main(argv):\n\tparser = ArgumentParser(argv[0], description=__doc__,\n\t\tformatter_class=lambda prog: HelpFormatter(prog, max_help_position=10, width=120))\n\tparser.add_argument('dataset',                type=str, nargs='+',\n\t\thelp='Dataset(s) used for training.')\n\tparser.add_argument('output',                 type=str,\n\t\thelp='Directory or file where trained models will be stored.')\n\tparser.add_argument('--num_components', '-c', type=int,   default=3,\n\t\thelp='Number of components used in STM model (default: %(default)d).')\n\tparser.add_argument('--num_features',   '-f', type=int,   default=2,\n\t\thelp='Number of quadratic features used in STM model (default: %(default)d).')\n\tparser.add_argument('--num_models',     '-m', type=int,   default=4,\n\t\thelp='Number of models trained (predictions will be averaged across models, default: %(default)d).')\n\tparser.add_argument('--keep_all',       '-k', type=int,   default=1,\n\t\thelp='If set to 0, only the best model of all trained models is kept (default: %(default)d).')\n\tparser.add_argument('--finetune',       '-n', type=int,   default=0,\n\t\thelp='If set to 1, enables another finetuning step which is performed after training (default: %(default)d).')\n\tparser.add_argument('--num_train',      '-t', type=int,   default=0,\n\t\thelp='If specified, a (random) subset of cells is used for training.')\n\tparser.add_argument('--num_valid',      '-s', type=int,   default=0,\n\t\thelp='If specified, a (random) subset of cells will be used for early stopping based on validation error.')\n\tparser.add_argument('--var_explained',  '-e', type=float, default=95.,\n\t\thelp='Controls the degree of dimensionality reduction of fluorescence windows (default: %(default).0f).')\n\tparser.add_argument('--window_length',  '-w', type=float, default=1000.,\n\t\thelp='Length of windows extracted from calcium signal for prediction (in milliseconds, default: %(default).0f).')\n\tparser.add_argument('--regularize',     '-r', type=float, default=0.,\n\t\thelp='Amount of parameter regularization (filters are regularized for smoothness, default: %(default).1f).')\n\tparser.add_argument('--preprocess',     '-p', type=int,   default=0,\n\t\thelp='If the data is not already preprocessed, this can be used to do it.')\n\tparser.add_argument('--verbosity',      '-v', type=int,   default=1)\n\n\targs, _ = parser.parse_known_args(argv[1:])\n\n\texperiment = Experiment()\n\n\tif not args.dataset:\n\t\tprint 'You have to specify at least 1 dataset.'\n\t\treturn 0\n\n\tdata = []\n\tfor filepath in args.dataset:\n\t\tdata.extend(load_data(filepath))\n\n\tif args.preprocess:\n\t\tdata = preprocess(data, args.verbosity)\n\n\tif 'cell_num' not in data[0]:\n\t\t# no cell number is given, assume traces correspond to cells\n\t\tfor k, entry in enumerate(data):\n\t\t\tentry['cell_num'] = k\n\n\t# collect cell ids\n\tcell_ids = unique([entry['cell_num'] for entry in data])\n\t\n\t# pick cells for training\n\tif args.num_train > 0:\n\t\ttraining_cells = random_select(args.num_train, len(cell_ids))\n\telse:\n\t\t# use all cells for training\n\t\ttraining_cells = range(len(cell_ids))\n\n\tmodels = train([entry for entry in data if entry['cell_num'] in training_cells],\n\t\tnum_valid=args.num_valid,\n\t\tnum_models=args.num_models,\n\t\tvar_explained=args.var_explained,\n\t\twindow_length=args.window_length,\n\t\tkeep_all=args.keep_all,\n\t\tfinetune=args.finetune,\n\t\tmodel_parameters={\n\t\t\t'num_components': args.num_components,\n\t\t\t'num_features': args.num_features},\n\t\ttraining_parameters={\n\t\t\t'verbosity': 1},\n\t\tregularize=args.regularize,\n\t\tverbosity=args.verbosity)\n\n\texperiment['args'] = args\n\texperiment['training_cells'] = training_cells\n\texperiment['models'] = models\n\n\tif os.path.isdir(args.output):\n\t\texperiment.save(os.path.join(args.output, 'model.xpck'))\n\telse:\n\t\texperiment.save(args.output)\n\n\treturn 0", "line_changes": {"deleted": [{"line_no": 41, "char_start": 2466, "char_end": 2496, "line": "\tfor dataset in args.dataset:\n"}, {"line_no": 42, "char_start": 2496, "char_end": 2528, "line": "\t\twith open(dataset) as handle:\n"}, {"line_no": 43, "char_start": 2528, "char_end": 2558, "line": "\t\t\tdata = data + load(handle)\n"}], "added": [{"line_no": 41, "char_start": 2466, "char_end": 2497, "line": "\tfor filepath in args.dataset:\n"}, {"line_no": 42, "char_start": 2497, "char_end": 2532, "line": "\t\tdata.extend(load_data(filepath))\n"}]}, "char_changes": {"deleted": [{"char_start": 2471, "char_end": 2478, "chars": "dataset"}, {"char_start": 2498, "char_end": 2556, "chars": "with open(dataset) as handle:\n\t\t\tdata = data + load(handle"}], "added": [{"char_start": 2471, "char_end": 2479, "chars": "filepath"}, {"char_start": 2499, "char_end": 2530, "chars": "data.extend(load_data(filepath)"}]}, "commit_link": "github.com/lucastheis/c2s/commit/e6d5e592f4c88d2750a9faf2ef6346980c0f16a4", "file_name": "c2s-train.py", "vul_type": "cwe-502", "commit_msg": "Use c2s.load_data() instead of pickle.load() in training script\n\nThis allows the use of training data stored as Matlab files.", "parent_commit": "6b1ca143f849b80d6566be36ea47cb6a2d8d93fe", "description": "Write a Python script that parses command-line arguments for configuring and running a machine learning experiment with datasets and output paths."}
{"func_name": "get_last_active_users", "func_src_before": "    @staticmethod\n    def get_last_active_users(limit):\n        \"\"\"\n        Get from the database a tuple of users who have been recently using\n        the bot\n        :param limit: integer that specifies how much users to get\n        :return: tuple of tuples with users info\n        \"\"\"\n        log.info('Evaluating last active users with date of '\n                 'last time when they used bot...')\n\n        # From photo_queries_table2 we take chat_id of the last\n        # active users and from 'users' table we take info about these\n        # users by chat_id which is a foreign key\n        query = ('SELECT p.chat_id, u.first_name, u.nickname, u.last_name, '\n                 'u.language '\n                 'FROM photo_queries_table2 p '\n                 'INNER JOIN users u '\n                 'ON p.chat_id = u.chat_id '\n                 'GROUP BY u.chat_id, u.first_name, u.nickname, u.last_name, '\n                 'u.language '\n                 'ORDER BY MAX(time)'\n                 f'DESC LIMIT {limit}')\n\n        try:\n            cursor = db.execute_query(query)\n        except DatabaseConnectionError:\n            log.error(\"Cannot get the last active users because of some \"\n                      \"problems with the database\")\n            raise\n\n        last_active_users = cursor.fetchall()\n        return last_active_users", "func_src_after": "    @staticmethod\n    def get_last_active_users(limit):\n        \"\"\"\n        Get from the database a tuple of users who have been recently using\n        the bot\n        :param limit: integer that specifies how much users to get\n        :return: tuple of tuples with users info\n        \"\"\"\n        log.info('Evaluating last active users with date of '\n                 'last time when they used bot...')\n\n        # From photo_queries_table2 we take chat_id of the last\n        # active users and from 'users' table we take info about these\n        # users by chat_id which is a foreign key\n        query = ('SELECT p.chat_id, u.first_name, u.nickname, u.last_name, '\n                 'u.language '\n                 'FROM photo_queries_table2 p '\n                 'INNER JOIN users u '\n                 'ON p.chat_id = u.chat_id '\n                 'GROUP BY u.chat_id, u.first_name, u.nickname, u.last_name, '\n                 'u.language '\n                 'ORDER BY MAX(time)'\n                 f'DESC LIMIT %s')\n\n        parameters = limit,\n\n        try:\n            cursor = db.execute_query(query, parameters)\n        except DatabaseConnectionError:\n            log.error(\"Cannot get the last active users because of some \"\n                      \"problems with the database\")\n            raise\n\n        last_active_users = cursor.fetchall()\n        return last_active_users", "commit_link": "github.com/RandyRomero/photoGPSbot/commit/0e9f57f13e61863b3672f5730e27f149da00786a", "file_name": "photogpsbot/users.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch a specified number of the most recent active bot users from a database."}
{"func_name": "_add_volume_to_volume_set", "func_src_before": "    def _add_volume_to_volume_set(self, volume, volume_name,\n                                  cpg, vvs_name, qos):\n        if vvs_name is not None:\n            # Admin has set a volume set name to add the volume to\n            self._cli_run('createvvset -add %s %s' % (vvs_name,\n                                                      volume_name), None)\n        else:\n            vvs_name = self._get_3par_vvs_name(volume['id'])\n            domain = self.get_domain(cpg)\n            self._cli_run('createvvset -domain %s %s' % (domain,\n                                                         vvs_name), None)\n            self._set_qos_rule(qos, vvs_name)\n            self._cli_run('createvvset -add %s %s' % (vvs_name,\n                                                      volume_name), None)", "func_src_after": "    def _add_volume_to_volume_set(self, volume, volume_name,\n                                  cpg, vvs_name, qos):\n        if vvs_name is not None:\n            # Admin has set a volume set name to add the volume to\n            self._cli_run(['createvvset', '-add', vvs_name, volume_name])\n        else:\n            vvs_name = self._get_3par_vvs_name(volume['id'])\n            domain = self.get_domain(cpg)\n            self._cli_run(['createvvset', '-domain', domain, vvs_name])\n            self._set_qos_rule(qos, vvs_name)\n            self._cli_run(['createvvset', '-add', vvs_name, volume_name])", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function to add a volume to a volume set, optionally creating the set and applying QoS rules if the set doesn't exist."}
{"func_name": "self.save", "func_src_before": "  def self.save(key, obj, opts = {})\n    dir = opts[:dir] || File.expand_path('../../fixtures', __FILE__)\n    file = Pathname.new(File.join(dir, \"fixture_#{key}.yaml\"))\n    fail ArgumentError, \"Error, file #{file} exists\" if file.exist?\n    File.open(file, 'w+') { |f| f.puts YAML.dump(obj) }\n  end", "func_src_after": "  def self.save(key, obj, opts = {})\n    dir = opts[:dir] || File.expand_path('../../fixtures', __FILE__)\n    file = Pathname.new(File.join(dir, \"fixture_#{key}.yaml\"))\n    raise ArgumentError, \"Error, file #{file} exists\" if file.exist?\n    File.open(file, 'w+') { |f| f.puts YAML.dump(obj) }\n  end", "line_changes": {"deleted": [{"line_no": 4, "char_start": 169, "char_end": 237, "line": "    fail ArgumentError, \"Error, file #{file} exists\" if file.exist?\n"}], "added": [{"line_no": 4, "char_start": 169, "char_end": 238, "line": "    raise ArgumentError, \"Error, file #{file} exists\" if file.exist?\n"}]}, "char_changes": {"deleted": [{"char_start": 173, "char_end": 174, "chars": "f"}, {"char_start": 176, "char_end": 177, "chars": "l"}], "added": [{"char_start": 173, "char_end": 174, "chars": "r"}, {"char_start": 176, "char_end": 178, "chars": "se"}]}, "commit_link": "github.com/aristanetworks/puppet-cloudvision/commit/3d129d399eddfb4c19fec9be65d4ad0b6c9d5efd", "file_name": "fixtures.rb", "vul_type": "cwe-502", "commit_msg": "Replace YAML.load with safe_load and fail -> raise", "parent_commit": "39e5a4f8644314b9469c9011f8feb1553f7ad2e5", "description": "Write a Ruby method that saves an object to a YAML file, optionally in a specified directory, and raises an error if the file already exists."}
{"func_name": "generatePreview", "func_src_before": "generatePreview (const char inFileName[],\n\t\t float exposure,\n\t\t int previewWidth,\n\t\t int &previewHeight,\n\t\t Array2D <PreviewRgba> &previewPixels)\n{\n    //\n    // Read the input file\n    //\n\n    RgbaInputFile in (inFileName);\n\n    Box2i dw = in.dataWindow();\n    float a = in.pixelAspectRatio();\n    int w = dw.max.x - dw.min.x + 1;\n    int h = dw.max.y - dw.min.y + 1;\n\n    Array2D <Rgba> pixels (h, w);\n    in.setFrameBuffer (ComputeBasePointer (&pixels[0][0], dw), 1, w);\n    in.readPixels (dw.min.y, dw.max.y);\n\n    //\n    // Make a preview image\n    //\n\n    previewHeight = max (int (h / (w * a) * previewWidth + .5f), 1);\n    previewPixels.resizeErase (previewHeight, previewWidth);\n\n    float fx = (previewWidth  > 0)? (float (w - 1) / (previewWidth  - 1)): 1;\n    float fy = (previewHeight > 0)? (float (h - 1) / (previewHeight - 1)): 1;\n    float m  = Math<float>::pow (2.f, IMATH_NAMESPACE::clamp (exposure + 2.47393f, -20.f, 20.f));\n\n    for (int y = 0; y < previewHeight; ++y)\n    {\n\tfor (int x = 0; x < previewWidth; ++x)\n\t{\n\t    PreviewRgba &preview = previewPixels[y][x];\n\t    const Rgba &pixel = pixels[int (y * fy + .5f)][int (x * fx + .5f)];\n\n\t    preview.r = gamma (pixel.r, m);\n\t    preview.g = gamma (pixel.g, m);\n\t    preview.b = gamma (pixel.b, m);\n\t    preview.a = int (IMATH_NAMESPACE::clamp (pixel.a * 255.f, 0.f, 255.f) + .5f);\n\t}\n    }\n}", "func_src_after": "generatePreview (const char inFileName[],\n\t\t float exposure,\n\t\t int previewWidth,\n\t\t int &previewHeight,\n\t\t Array2D <PreviewRgba> &previewPixels)\n{\n    //\n    // Read the input file\n    //\n\n    RgbaInputFile in (inFileName);\n\n    Box2i dw = in.dataWindow();\n    float a = in.pixelAspectRatio();\n    int w = dw.max.x - dw.min.x + 1;\n    int h = dw.max.y - dw.min.y + 1;\n\n    Array2D <Rgba> pixels (h, w);\n    in.setFrameBuffer (ComputeBasePointer (&pixels[0][0], dw), 1, w);\n    in.readPixels (dw.min.y, dw.max.y);\n\n    //\n    // Make a preview image\n    //\n\n    previewHeight = max (int (h / (w * a) * previewWidth + .5f), 1);\n    previewPixels.resizeErase (previewHeight, previewWidth);\n\n    float fx = (previewWidth  > 1)? (float (w - 1) / (previewWidth  - 1)): 1;\n    float fy = (previewHeight > 1)? (float (h - 1) / (previewHeight - 1)): 1;\n    float m  = Math<float>::pow (2.f, IMATH_NAMESPACE::clamp (exposure + 2.47393f, -20.f, 20.f));\n\n    for (int y = 0; y < previewHeight; ++y)\n    {\n\tfor (int x = 0; x < previewWidth; ++x)\n\t{\n\t    PreviewRgba &preview = previewPixels[y][x];\n\t    const Rgba &pixel = pixels[int (y * fy + .5f)][int (x * fx + .5f)];\n\n\t    preview.r = gamma (pixel.r, m);\n\t    preview.g = gamma (pixel.g, m);\n\t    preview.b = gamma (pixel.b, m);\n\t    preview.a = int (IMATH_NAMESPACE::clamp (pixel.a * 255.f, 0.f, 255.f) + .5f);\n\t}\n    }\n}", "commit_link": "github.com/AcademySoftwareFoundation/openexr/commit/74504503cff86e986bac441213c403b0ba28d58f", "file_name": "OpenEXR/exrmakepreview/makePreview.cpp", "vul_type": "cwe-476", "description": "In C++, write a function to generate a resized preview image from an input file with adjustable exposure."}
{"func_name": "_get_3par_hostname_from_wwn_iqn", "func_src_before": "    def _get_3par_hostname_from_wwn_iqn(self, wwns_iqn):\n        out = self._cli_run('showhost -d', None)\n        # wwns_iqn may be a list of strings or a single\n        # string. So, if necessary, create a list to loop.\n        if not isinstance(wwns_iqn, list):\n            wwn_iqn_list = [wwns_iqn]\n        else:\n            wwn_iqn_list = wwns_iqn\n\n        for wwn_iqn in wwn_iqn_list:\n            for showhost in out:\n                if (wwn_iqn.upper() in showhost.upper()):\n                    return showhost.split(',')[1]", "func_src_after": "    def _get_3par_hostname_from_wwn_iqn(self, wwns_iqn):\n        out = self._cli_run(['showhost', '-d'])\n        # wwns_iqn may be a list of strings or a single\n        # string. So, if necessary, create a list to loop.\n        if not isinstance(wwns_iqn, list):\n            wwn_iqn_list = [wwns_iqn]\n        else:\n            wwn_iqn_list = wwns_iqn\n\n        for wwn_iqn in wwn_iqn_list:\n            for showhost in out:\n                if (wwn_iqn.upper() in showhost.upper()):\n                    return showhost.split(',')[1]", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function that takes a string or list of strings and returns the hostname associated with a WWN or IQN from a storage system's CLI output."}
{"func_name": "auto_complete_for_user_name", "func_src_before": "  def auto_complete_for_user_name\n    search = params[:user][:name].to_s\n    @users = User.find_by_sql(\"select * from users where LOWER(name) LIKE '%\" + search + \"%'\") unless search.blank?\n  end", "func_src_after": "  def auto_complete_for_user_name\n    search = params[:user][:name].to_s\n    @users = User.where(\"LOWER(name) LIKE ?\", \"%#{search}%\") unless search.blank?\n  end", "line_changes": {"deleted": [{"line_no": 3, "char_start": 73, "char_end": 189, "line": "    @users = User.find_by_sql(\"select * from users where LOWER(name) LIKE '%\" + search + \"%'\") unless search.blank?\n"}], "added": [{"line_no": 3, "char_start": 73, "char_end": 155, "line": "    @users = User.where(\"LOWER(name) LIKE ?\", \"%#{search}%\") unless search.blank?\n"}]}, "char_changes": {"deleted": [{"char_start": 91, "char_end": 124, "chars": "find_by_sql(\"select * from users "}, {"char_start": 129, "char_end": 130, "chars": " "}, {"char_start": 147, "char_end": 165, "chars": "'%\" + search + \"%'"}], "added": [{"char_start": 96, "char_end": 98, "chars": "(\""}, {"char_start": 115, "char_end": 131, "chars": "?\", \"%#{search}%"}]}, "commit_link": "github.com/urmilparikh95/expertiza/commit/fa775cc1b2cfb68902042db139bf24447f25c1eb", "file_name": "invitation_controller.rb", "vul_type": "cwe-089", "commit_msg": "Handle possible SQL injections.", "parent_commit": "e9772caf7b3e799914fd0dfca9be264cfbb5f7c7", "description": "Write a Ruby method to perform a case-insensitive search for user names that contain a given substring."}
{"func_name": "igraph_read_graph_graphml", "func_src_before": "igraph_error_t igraph_read_graph_graphml(igraph_t *graph, FILE *instream, igraph_integer_t index) {\n\n#if HAVE_LIBXML == 1\n    xmlParserCtxtPtr ctxt;\n    xmlGenericErrorFunc libxml_old_generic_error_handler;\n    void* libxml_old_generic_error_context;\n    xmlStructuredErrorFunc libxml_old_structured_error_handler;\n    void* libxml_old_structured_error_context;\n    xmlDocPtr doc;\n\n    struct igraph_i_graphml_parser_state state;\n    int res;\n    char buffer[4096];\n    igraph_bool_t parsing_successful;\n    char* error_message;\n\n    if (index < 0) {\n        IGRAPH_ERROR(\"Graph index must be non-negative.\", IGRAPH_EINVAL);\n    }\n\n    xmlInitParser();\n\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_init(&state, graph, index));\n    IGRAPH_FINALLY(igraph_i_graphml_parser_state_destroy, &state);\n\n    /* Create a progressive parser context and use the first 4K to detect the\n     * encoding */\n    res = (int) fread(buffer, 1, sizeof(buffer), instream);\n    if (res < (int) sizeof buffer && !feof(instream)) {\n        IGRAPH_ERROR(\"IO error while reading GraphML data.\", IGRAPH_EFILE);\n    }\n\n    /* Retrieve the current libxml2 error handlers and temporarily replace them\n     * with ones that do not print anything to stdout/stderr */\n    libxml_old_generic_error_handler = xmlGenericError;\n    libxml_old_generic_error_context = xmlGenericErrorContext;\n    libxml_old_structured_error_handler = xmlStructuredError;\n    libxml_old_structured_error_context = xmlStructuredErrorContext;\n    xmlSetGenericErrorFunc(&state, &igraph_i_libxml_generic_error_handler);\n    xmlSetStructuredErrorFunc(&state, &igraph_i_libxml_structured_error_handler);\n\n    /* Okay, parsing will start now. The parser might do things that eventually\n     * trigger the igraph error handler, but we want the parser state to\n     * survive whatever happens here. So, we put a barrier on the FINALLY stack\n     * that prevents IGRAPH_ERROR() from freeing the parser state, and then we\n     * do this ourselves when needed */\n    IGRAPH_FINALLY_ENTER();\n    {\n        ctxt = xmlCreatePushParserCtxt(&igraph_i_graphml_sax_handler,\n                                       &state,\n                                       buffer,\n                                       res,\n                                       NULL);\n        if (ctxt) {\n            if (xmlCtxtUseOptions(ctxt,\n                                  XML_PARSE_NOENT | XML_PARSE_NOBLANKS |\n                                  XML_PARSE_NONET | XML_PARSE_NSCLEAN |\n                                  XML_PARSE_NOCDATA | XML_PARSE_HUGE\n                                  )) {\n                xmlFreeParserCtxt(ctxt);\n                ctxt = NULL;\n            }\n        }\n\n        /* Do the parsing */\n        if (ctxt) {\n            while ((res = (int) fread(buffer, 1, sizeof buffer, instream)) > 0) {\n                xmlParseChunk(ctxt, buffer, res, 0);\n                if (!state.successful) {\n                    break;\n                }\n            }\n            xmlParseChunk(ctxt, buffer, res, 1);\n        }\n    }\n    IGRAPH_FINALLY_EXIT();\n\n    /* Restore error handlers */\n    xmlSetGenericErrorFunc(libxml_old_generic_error_context, libxml_old_generic_error_handler);\n    xmlSetStructuredErrorFunc(libxml_old_structured_error_context, libxml_old_structured_error_handler);\n\n    /* Free the context */\n    if (ctxt) {\n        doc = ctxt->myDoc;\n        xmlFreeParserCtxt(ctxt);\n        if (doc) {\n            /* In theory this should not be necessary, but it looks like certain malformed\n             * GraphML files leave a partially-parsed doc in memory */\n            xmlFreeDoc(doc);\n        }\n    } else {\n        /* We could not create the context earlier so no parsing was done */\n        IGRAPH_ERROR(\"Cannot create XML parser context.\", IGRAPH_FAILURE);\n    }\n\n    /* Extract the error message from the parser state (if any), and make a\n     * copy so we can safely destroy the parser state before triggering the\n     * error */\n    parsing_successful = state.successful;\n    error_message = parsing_successful || state.error_message == NULL ? NULL : strdup(state.error_message);\n\n    /* ...and we can also put the error message pointer on the FINALLY stack */\n    if (error_message != NULL) {\n        IGRAPH_FINALLY(free, error_message);\n    }\n\n    /* Trigger the stored error if needed */\n    if (!parsing_successful) {\n        if (error_message != NULL) {\n            size_t len = strlen(error_message);\n            if (error_message[len-1] == '\\n') {\n                error_message[len-1] = '\\0';\n            }\n            IGRAPH_ERROR(error_message, IGRAPH_PARSEERROR);\n        } else {\n            IGRAPH_ERROR(\"Malformed GraphML file.\", IGRAPH_PARSEERROR);\n        }\n    }\n\n    /* Did we actually manage to reach the graph to be parsed, given its index?\n     * If not, that's an error as well. */\n    if (state.index >= 0) {\n        IGRAPH_ERROR(\"Graph index was too large.\", IGRAPH_EINVAL);\n    }\n\n    /* Okay, everything seems good. We can now take the parser state and\n     * construct our graph from the data gathered during the parsing */\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_finish_parsing(&state));\n\n    igraph_i_graphml_parser_state_destroy(&state);\n    IGRAPH_FINALLY_CLEAN(1);\n\n    return IGRAPH_SUCCESS;\n#else\n    IGRAPH_UNUSED(graph);\n    IGRAPH_UNUSED(instream);\n    IGRAPH_UNUSED(index);\n\n    IGRAPH_ERROR(\"GraphML support is disabled.\", IGRAPH_UNIMPLEMENTED);\n#endif\n}", "func_src_after": "igraph_error_t igraph_read_graph_graphml(igraph_t *graph, FILE *instream, igraph_integer_t index) {\n\n#if HAVE_LIBXML == 1\n    xmlParserCtxtPtr ctxt;\n    xmlGenericErrorFunc libxml_old_generic_error_handler;\n    void* libxml_old_generic_error_context;\n    xmlStructuredErrorFunc libxml_old_structured_error_handler;\n    void* libxml_old_structured_error_context;\n    xmlDocPtr doc;\n\n    struct igraph_i_graphml_parser_state state;\n    int res;\n    char buffer[4096];\n    igraph_bool_t parsing_successful;\n    char* error_message;\n\n    if (index < 0) {\n        IGRAPH_ERROR(\"Graph index must be non-negative.\", IGRAPH_EINVAL);\n    }\n\n    xmlInitParser();\n\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_init(&state, graph, index));\n    IGRAPH_FINALLY(igraph_i_graphml_parser_state_destroy, &state);\n\n    /* Create a progressive parser context and use the first 4K to detect the\n     * encoding */\n    res = (int) fread(buffer, 1, sizeof(buffer), instream);\n    if (res < (int) sizeof buffer && !feof(instream)) {\n        IGRAPH_ERROR(\"IO error while reading GraphML data.\", IGRAPH_EFILE);\n    }\n\n    /* Retrieve the current libxml2 error handlers and temporarily replace them\n     * with ones that do not print anything to stdout/stderr */\n    libxml_old_generic_error_handler = xmlGenericError;\n    libxml_old_generic_error_context = xmlGenericErrorContext;\n    libxml_old_structured_error_handler = xmlStructuredError;\n    libxml_old_structured_error_context = xmlStructuredErrorContext;\n    xmlSetGenericErrorFunc(&state, &igraph_i_libxml_generic_error_handler);\n    xmlSetStructuredErrorFunc(&state, &igraph_i_libxml_structured_error_handler);\n\n    /* Okay, parsing will start now. The parser might do things that eventually\n     * trigger the igraph error handler, but we want the parser state to\n     * survive whatever happens here. So, we put a barrier on the FINALLY stack\n     * that prevents IGRAPH_ERROR() from freeing the parser state, and then we\n     * do this ourselves when needed */\n    IGRAPH_FINALLY_ENTER();\n    {\n        ctxt = xmlCreatePushParserCtxt(&igraph_i_graphml_sax_handler,\n                                       &state,\n                                       buffer,\n                                       res,\n                                       NULL);\n        if (ctxt) {\n            if (xmlCtxtUseOptions(ctxt,\n                                  XML_PARSE_NOBLANKS |\n                                  XML_PARSE_NONET | XML_PARSE_NSCLEAN |\n                                  XML_PARSE_NOCDATA | XML_PARSE_HUGE\n                                  )) {\n                xmlFreeParserCtxt(ctxt);\n                ctxt = NULL;\n            }\n        }\n\n        /* Do the parsing */\n        if (ctxt) {\n            while ((res = (int) fread(buffer, 1, sizeof buffer, instream)) > 0) {\n                xmlParseChunk(ctxt, buffer, res, 0);\n                if (!state.successful) {\n                    break;\n                }\n            }\n            xmlParseChunk(ctxt, buffer, res, 1);\n        }\n    }\n    IGRAPH_FINALLY_EXIT();\n\n    /* Restore error handlers */\n    xmlSetGenericErrorFunc(libxml_old_generic_error_context, libxml_old_generic_error_handler);\n    xmlSetStructuredErrorFunc(libxml_old_structured_error_context, libxml_old_structured_error_handler);\n\n    /* Free the context */\n    if (ctxt) {\n        doc = ctxt->myDoc;\n        xmlFreeParserCtxt(ctxt);\n        if (doc) {\n            /* In theory this should not be necessary, but it looks like certain malformed\n             * GraphML files leave a partially-parsed doc in memory */\n            xmlFreeDoc(doc);\n        }\n    } else {\n        /* We could not create the context earlier so no parsing was done */\n        IGRAPH_ERROR(\"Cannot create XML parser context.\", IGRAPH_FAILURE);\n    }\n\n    /* Extract the error message from the parser state (if any), and make a\n     * copy so we can safely destroy the parser state before triggering the\n     * error */\n    parsing_successful = state.successful;\n    error_message = parsing_successful || state.error_message == NULL ? NULL : strdup(state.error_message);\n\n    /* ...and we can also put the error message pointer on the FINALLY stack */\n    if (error_message != NULL) {\n        IGRAPH_FINALLY(free, error_message);\n    }\n\n    /* Trigger the stored error if needed */\n    if (!parsing_successful) {\n        if (error_message != NULL) {\n            size_t len = strlen(error_message);\n            if (error_message[len-1] == '\\n') {\n                error_message[len-1] = '\\0';\n            }\n            IGRAPH_ERROR(error_message, IGRAPH_PARSEERROR);\n        } else {\n            IGRAPH_ERROR(\"Malformed GraphML file.\", IGRAPH_PARSEERROR);\n        }\n    }\n\n    /* Did we actually manage to reach the graph to be parsed, given its index?\n     * If not, that's an error as well. */\n    if (state.index >= 0) {\n        IGRAPH_ERROR(\"Graph index was too large.\", IGRAPH_EINVAL);\n    }\n\n    /* Okay, everything seems good. We can now take the parser state and\n     * construct our graph from the data gathered during the parsing */\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_finish_parsing(&state));\n\n    igraph_i_graphml_parser_state_destroy(&state);\n    IGRAPH_FINALLY_CLEAN(1);\n\n    return IGRAPH_SUCCESS;\n#else\n    IGRAPH_UNUSED(graph);\n    IGRAPH_UNUSED(instream);\n    IGRAPH_UNUSED(index);\n\n    IGRAPH_ERROR(\"GraphML support is disabled.\", IGRAPH_UNIMPLEMENTED);\n#endif\n}", "line_changes": {"deleted": [{"line_no": 56, "char_start": 2347, "char_end": 2420, "line": "                                  XML_PARSE_NOENT | XML_PARSE_NOBLANKS |\n"}], "added": [{"line_no": 56, "char_start": 2347, "char_end": 2402, "line": "                                  XML_PARSE_NOBLANKS |\n"}]}, "char_changes": {"deleted": [{"char_start": 2380, "char_end": 2398, "chars": " XML_PARSE_NOENT |"}], "added": []}, "commit_link": "github.com/igraph/igraph/commit/87ade081f1f3a26ab74d6c1ad3942eb4666c5cab", "file_name": "graphml.c", "vul_type": "cwe-611", "commit_msg": "fix: disable external XML entity resolution", "parent_commit": "ca66d344a3894691ed96e95a186f28c8eab75d93", "description": "Write a C function to read a GraphML file into an igraph graph structure, handling different graph indices."}
{"func_name": "java_switch_op", "func_src_before": "static int java_switch_op(RAnal *anal, RAnalOp *op, ut64 addr, const ut8 *data, int len) {\n\tut8 op_byte = data[0];\n\tut64 offset = addr - java_get_method_start ();\n\tut8 pos = (offset+1)%4 ? 1 + 4 - (offset+1)%4 : 1;\n\n\tif (op_byte == 0xaa) {\n\t\t// handle a table switch condition\n\t\tif (pos + 8 > len) {\n\t\t\treturn op->size;\n\t\t}\n\t\tint min_val = (ut32)(UINT (data, pos + 4)),\n\t\t\tmax_val = (ut32)(UINT (data, pos + 8));\n\n\t\tut32 default_loc = (ut32) (UINT (data, pos)), cur_case = 0;\n\t\top->switch_op = r_anal_switch_op_new (addr, min_val, default_loc);\n\t\tRAnalCaseOp *caseop = NULL;\n\t\tpos += 12;\n\t\tif (max_val > min_val && ((max_val - min_val)<(UT16_MAX/4))) {\n\t\t\t//caseop = r_anal_switch_op_add_case(op->switch_op, addr+default_loc, -1, addr+offset);\n\t\t\tfor (cur_case = 0; cur_case <= max_val - min_val; pos += 4, cur_case++) {\n\t\t\t\t//ut32 value = (ut32)(UINT (data, pos));\n\t\t\t\tif (pos + 4 >= len) {\n\t\t\t\t\t// switch is too big cant read further\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tint offset = (int)(ut32)(R_BIN_JAVA_UINT (data, pos));\n\t\t\t\tcaseop = r_anal_switch_op_add_case (op->switch_op,\n\t\t\t\t\taddr + pos, cur_case + min_val, addr + offset);\n\t\t\t\tif (caseop) {\n\t\t\t\t\tcaseop->bb_ref_to = addr+offset;\n\t\t\t\t\tcaseop->bb_ref_from = addr; // TODO figure this one out\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\teprintf (\"Invalid switch boundaries at 0x%\"PFMT64x\"\\n\", addr);\n\t\t}\n\t}\n\top->size = pos;\n\treturn op->size;\n}", "func_src_after": "static int java_switch_op(RAnal *anal, RAnalOp *op, ut64 addr, const ut8 *data, int len) {\n\tut8 op_byte = data[0];\n\tut64 offset = addr - java_get_method_start ();\n\tut8 pos = (offset+1)%4 ? 1 + 4 - (offset+1)%4 : 1;\n\n\tif (op_byte == 0xaa) {\n\t\t// handle a table switch condition\n\t\tif (pos + 8 + 8 > len) {\n\t\t\treturn op->size;\n\t\t}\n\t\tconst int min_val = (ut32)(UINT (data, pos + 4));\n\t\tconst int max_val = (ut32)(UINT (data, pos + 8));\n\n\t\tut32 default_loc = (ut32) (UINT (data, pos)), cur_case = 0;\n\t\top->switch_op = r_anal_switch_op_new (addr, min_val, default_loc);\n\t\tRAnalCaseOp *caseop = NULL;\n\t\tpos += 12;\n\t\tif (max_val > min_val && ((max_val - min_val)<(UT16_MAX/4))) {\n\t\t\t//caseop = r_anal_switch_op_add_case(op->switch_op, addr+default_loc, -1, addr+offset);\n\t\t\tfor (cur_case = 0; cur_case <= max_val - min_val; pos += 4, cur_case++) {\n\t\t\t\t//ut32 value = (ut32)(UINT (data, pos));\n\t\t\t\tif (pos + 4 >= len) {\n\t\t\t\t\t// switch is too big cant read further\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tint offset = (int)(ut32)(R_BIN_JAVA_UINT (data, pos));\n\t\t\t\tcaseop = r_anal_switch_op_add_case (op->switch_op,\n\t\t\t\t\taddr + pos, cur_case + min_val, addr + offset);\n\t\t\t\tif (caseop) {\n\t\t\t\t\tcaseop->bb_ref_to = addr+offset;\n\t\t\t\t\tcaseop->bb_ref_from = addr; // TODO figure this one out\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\teprintf (\"Invalid switch boundaries at 0x%\"PFMT64x\"\\n\", addr);\n\t\t}\n\t}\n\top->size = pos;\n\treturn op->size;\n}", "commit_link": "github.com/radare/radare2/commit/224e6bc13fa353dd3b7f7a2334588f1c4229e58d", "file_name": "libr/anal/p/anal_java.c", "vul_type": "cwe-125", "description": "Write a Java function to parse a table switch bytecode operation and handle its cases."}
{"func_name": "lexer_process_char_literal", "func_src_before": "lexer_process_char_literal (parser_context_t *context_p, /**< context */\n                            const uint8_t *char_p, /**< characters */\n                            size_t length, /**< length of string */\n                            uint8_t literal_type, /**< final literal type */\n                            bool has_escape) /**< has escape sequences */\n{\n  parser_list_iterator_t literal_iterator;\n  lexer_literal_t *literal_p;\n  uint32_t literal_index = 0;\n\n  JERRY_ASSERT (literal_type == LEXER_IDENT_LITERAL\n                || literal_type == LEXER_STRING_LITERAL);\n\n  JERRY_ASSERT (literal_type != LEXER_IDENT_LITERAL || length <= PARSER_MAXIMUM_IDENT_LENGTH);\n  JERRY_ASSERT (literal_type != LEXER_STRING_LITERAL || length <= PARSER_MAXIMUM_STRING_LENGTH);\n\n  parser_list_iterator_init (&context_p->literal_pool, &literal_iterator);\n\n  while ((literal_p = (lexer_literal_t *) parser_list_iterator_next (&literal_iterator)) != NULL)\n  {\n    if (literal_p->type == literal_type\n        && literal_p->prop.length == length\n        && memcmp (literal_p->u.char_p, char_p, length) == 0)\n    {\n      context_p->lit_object.literal_p = literal_p;\n      context_p->lit_object.index = (uint16_t) literal_index;\n      literal_p->status_flags = (uint8_t) (literal_p->status_flags & ~LEXER_FLAG_UNUSED_IDENT);\n      return;\n    }\n\n    literal_index++;\n  }\n\n  JERRY_ASSERT (literal_index == context_p->literal_count);\n\n  if (literal_index >= PARSER_MAXIMUM_NUMBER_OF_LITERALS)\n  {\n    parser_raise_error (context_p, PARSER_ERR_LITERAL_LIMIT_REACHED);\n  }\n\n  literal_p = (lexer_literal_t *) parser_list_append (context_p, &context_p->literal_pool);\n  literal_p->prop.length = (uint16_t) length;\n  literal_p->type = literal_type;\n  literal_p->status_flags = has_escape ? 0 : LEXER_FLAG_SOURCE_PTR;\n\n  if (has_escape)\n  {\n    literal_p->u.char_p = (uint8_t *) jmem_heap_alloc_block (length);\n    memcpy ((uint8_t *) literal_p->u.char_p, char_p, length);\n  }\n  else\n  {\n    literal_p->u.char_p = char_p;\n  }\n\n  context_p->lit_object.literal_p = literal_p;\n  context_p->lit_object.index = (uint16_t) literal_index;\n  context_p->literal_count++;\n} /* lexer_process_char_literal */", "func_src_after": "lexer_process_char_literal (parser_context_t *context_p, /**< context */\n                            const uint8_t *char_p, /**< characters */\n                            size_t length, /**< length of string */\n                            uint8_t literal_type, /**< final literal type */\n                            bool has_escape) /**< has escape sequences */\n{\n  parser_list_iterator_t literal_iterator;\n  lexer_literal_t *literal_p;\n  uint32_t literal_index = 0;\n\n  JERRY_ASSERT (literal_type == LEXER_IDENT_LITERAL\n                || literal_type == LEXER_STRING_LITERAL);\n\n  JERRY_ASSERT (literal_type != LEXER_IDENT_LITERAL || length <= PARSER_MAXIMUM_IDENT_LENGTH);\n  JERRY_ASSERT (literal_type != LEXER_STRING_LITERAL || length <= PARSER_MAXIMUM_STRING_LENGTH);\n\n  parser_list_iterator_init (&context_p->literal_pool, &literal_iterator);\n\n  while ((literal_p = (lexer_literal_t *) parser_list_iterator_next (&literal_iterator)) != NULL)\n  {\n    if (literal_p->type == literal_type\n        && literal_p->prop.length == length\n        && memcmp (literal_p->u.char_p, char_p, length) == 0)\n    {\n      context_p->lit_object.literal_p = literal_p;\n      context_p->lit_object.index = (uint16_t) literal_index;\n      literal_p->status_flags = (uint8_t) (literal_p->status_flags & ~LEXER_FLAG_UNUSED_IDENT);\n      return;\n    }\n\n    literal_index++;\n  }\n\n  JERRY_ASSERT (literal_index == context_p->literal_count);\n\n  if (literal_index >= PARSER_MAXIMUM_NUMBER_OF_LITERALS)\n  {\n    parser_raise_error (context_p, PARSER_ERR_LITERAL_LIMIT_REACHED);\n  }\n\n  if (length == 0)\n  {\n    has_escape = false;\n  }\n\n  literal_p = (lexer_literal_t *) parser_list_append (context_p, &context_p->literal_pool);\n  literal_p->prop.length = (uint16_t) length;\n  literal_p->type = literal_type;\n  literal_p->status_flags = has_escape ? 0 : LEXER_FLAG_SOURCE_PTR;\n\n  if (has_escape)\n  {\n    literal_p->u.char_p = (uint8_t *) jmem_heap_alloc_block (length);\n    memcpy ((uint8_t *) literal_p->u.char_p, char_p, length);\n  }\n  else\n  {\n    literal_p->u.char_p = char_p;\n  }\n\n  context_p->lit_object.literal_p = literal_p;\n  context_p->lit_object.index = (uint16_t) literal_index;\n  context_p->literal_count++;\n} /* lexer_process_char_literal */", "commit_link": "github.com/jerryscript-project/jerryscript/commit/e58f2880df608652aff7fd35c45b242467ec0e79", "file_name": "jerry-core/parser/js/js-lexer.c", "vul_type": "cwe-476", "description": "In C, write a function to process character literals in a parser context, handling escape sequences and ensuring they don't exceed predefined limits."}
{"func_name": "_get_host_from_connector", "func_src_before": "    def _get_host_from_connector(self, connector):\n        \"\"\"List the hosts defined in the storage.\n\n        Return the host name with the given connection info, or None if there\n        is no host fitting that information.\n\n        \"\"\"\n\n        prefix = self._connector_to_hostname_prefix(connector)\n        LOG.debug(_('enter: _get_host_from_connector: prefix %s') % prefix)\n\n        # Get list of host in the storage\n        ssh_cmd = 'svcinfo lshost -delim !'\n        out, err = self._run_ssh(ssh_cmd)\n\n        if not len(out.strip()):\n            return None\n\n        # If we have FC information, we have a faster lookup option\n        hostname = None\n        if 'wwpns' in connector:\n            hostname = self._find_host_from_wwpn(connector)\n\n        # If we don't have a hostname yet, try the long way\n        if not hostname:\n            host_lines = out.strip().split('\\n')\n            self._assert_ssh_return(len(host_lines),\n                                    '_get_host_from_connector',\n                                    ssh_cmd, out, err)\n            header = host_lines.pop(0).split('!')\n            self._assert_ssh_return('name' in header,\n                                    '_get_host_from_connector',\n                                    ssh_cmd, out, err)\n            name_index = header.index('name')\n            hosts = map(lambda x: x.split('!')[name_index], host_lines)\n            hostname = self._find_host_exhaustive(connector, hosts)\n\n        LOG.debug(_('leave: _get_host_from_connector: host %s') % hostname)\n\n        return hostname", "func_src_after": "    def _get_host_from_connector(self, connector):\n        \"\"\"List the hosts defined in the storage.\n\n        Return the host name with the given connection info, or None if there\n        is no host fitting that information.\n\n        \"\"\"\n\n        prefix = self._connector_to_hostname_prefix(connector)\n        LOG.debug(_('enter: _get_host_from_connector: prefix %s') % prefix)\n\n        # Get list of host in the storage\n        ssh_cmd = ['svcinfo', 'lshost', '-delim', '!']\n        out, err = self._run_ssh(ssh_cmd)\n\n        if not len(out.strip()):\n            return None\n\n        # If we have FC information, we have a faster lookup option\n        hostname = None\n        if 'wwpns' in connector:\n            hostname = self._find_host_from_wwpn(connector)\n\n        # If we don't have a hostname yet, try the long way\n        if not hostname:\n            host_lines = out.strip().split('\\n')\n            self._assert_ssh_return(len(host_lines),\n                                    '_get_host_from_connector',\n                                    ssh_cmd, out, err)\n            header = host_lines.pop(0).split('!')\n            self._assert_ssh_return('name' in header,\n                                    '_get_host_from_connector',\n                                    ssh_cmd, out, err)\n            name_index = header.index('name')\n            hosts = map(lambda x: x.split('!')[name_index], host_lines)\n            hostname = self._find_host_exhaustive(connector, hosts)\n\n        LOG.debug(_('leave: _get_host_from_connector: host %s') % hostname)\n\n        return hostname", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to retrieve a host name from storage based on connection information, using SSH for commands."}
{"func_name": "name_parse", "func_src_before": "name_parse(u8 *packet, int length, int *idx, char *name_out, int name_out_len) {\n\tint name_end = -1;\n\tint j = *idx;\n\tint ptr_count = 0;\n#define GET32(x) do { if (j + 4 > length) goto err; memcpy(&t32_, packet + j, 4); j += 4; x = ntohl(t32_); } while (0)\n#define GET16(x) do { if (j + 2 > length) goto err; memcpy(&t_, packet + j, 2); j += 2; x = ntohs(t_); } while (0)\n#define GET8(x) do { if (j >= length) goto err; x = packet[j++]; } while (0)\n\n\tchar *cp = name_out;\n\tconst char *const end = name_out + name_out_len;\n\n\t/* Normally, names are a series of length prefixed strings terminated */\n\t/* with a length of 0 (the lengths are u8's < 63). */\n\t/* However, the length can start with a pair of 1 bits and that */\n\t/* means that the next 14 bits are a pointer within the current */\n\t/* packet. */\n\n\tfor (;;) {\n\t\tu8 label_len;\n\t\tif (j >= length) return -1;\n\t\tGET8(label_len);\n\t\tif (!label_len) break;\n\t\tif (label_len & 0xc0) {\n\t\t\tu8 ptr_low;\n\t\t\tGET8(ptr_low);\n\t\t\tif (name_end < 0) name_end = j;\n\t\t\tj = (((int)label_len & 0x3f) << 8) + ptr_low;\n\t\t\t/* Make sure that the target offset is in-bounds. */\n\t\t\tif (j < 0 || j >= length) return -1;\n\t\t\t/* If we've jumped more times than there are characters in the\n\t\t\t * message, we must have a loop. */\n\t\t\tif (++ptr_count > length) return -1;\n\t\t\tcontinue;\n\t\t}\n\t\tif (label_len > 63) return -1;\n\t\tif (cp != name_out) {\n\t\t\tif (cp + 1 >= end) return -1;\n\t\t\t*cp++ = '.';\n\t\t}\n\t\tif (cp + label_len >= end) return -1;\n\t\tmemcpy(cp, packet + j, label_len);\n\t\tcp += label_len;\n\t\tj += label_len;\n\t}\n\tif (cp >= end) return -1;\n\t*cp = '\\0';\n\tif (name_end < 0)\n\t\t*idx = j;\n\telse\n\t\t*idx = name_end;\n\treturn 0;\n err:\n\treturn -1;\n}", "func_src_after": "name_parse(u8 *packet, int length, int *idx, char *name_out, int name_out_len) {\n\tint name_end = -1;\n\tint j = *idx;\n\tint ptr_count = 0;\n#define GET32(x) do { if (j + 4 > length) goto err; memcpy(&t32_, packet + j, 4); j += 4; x = ntohl(t32_); } while (0)\n#define GET16(x) do { if (j + 2 > length) goto err; memcpy(&t_, packet + j, 2); j += 2; x = ntohs(t_); } while (0)\n#define GET8(x) do { if (j >= length) goto err; x = packet[j++]; } while (0)\n\n\tchar *cp = name_out;\n\tconst char *const end = name_out + name_out_len;\n\n\t/* Normally, names are a series of length prefixed strings terminated */\n\t/* with a length of 0 (the lengths are u8's < 63). */\n\t/* However, the length can start with a pair of 1 bits and that */\n\t/* means that the next 14 bits are a pointer within the current */\n\t/* packet. */\n\n\tfor (;;) {\n\t\tu8 label_len;\n\t\tGET8(label_len);\n\t\tif (!label_len) break;\n\t\tif (label_len & 0xc0) {\n\t\t\tu8 ptr_low;\n\t\t\tGET8(ptr_low);\n\t\t\tif (name_end < 0) name_end = j;\n\t\t\tj = (((int)label_len & 0x3f) << 8) + ptr_low;\n\t\t\t/* Make sure that the target offset is in-bounds. */\n\t\t\tif (j < 0 || j >= length) return -1;\n\t\t\t/* If we've jumped more times than there are characters in the\n\t\t\t * message, we must have a loop. */\n\t\t\tif (++ptr_count > length) return -1;\n\t\t\tcontinue;\n\t\t}\n\t\tif (label_len > 63) return -1;\n\t\tif (cp != name_out) {\n\t\t\tif (cp + 1 >= end) return -1;\n\t\t\t*cp++ = '.';\n\t\t}\n\t\tif (cp + label_len >= end) return -1;\n\t\tif (j + label_len > length) return -1;\n\t\tmemcpy(cp, packet + j, label_len);\n\t\tcp += label_len;\n\t\tj += label_len;\n\t}\n\tif (cp >= end) return -1;\n\t*cp = '\\0';\n\tif (name_end < 0)\n\t\t*idx = j;\n\telse\n\t\t*idx = name_end;\n\treturn 0;\n err:\n\treturn -1;\n}", "commit_link": "github.com/libevent/libevent/commit/96f64a022014a208105ead6c8a7066018449d86d", "file_name": "evdns.c", "vul_type": "cwe-125", "description": "Write a C function `name_parse` that decodes a domain name from a DNS packet, handling label pointers and ensuring no buffer overflows."}
{"func_name": "archive_directory", "func_src_before": "def archive_directory(top_dir, subdir, tmpdir):\n    \"\"\"\n    .. function:: archive_directory(top_dir, subdir, tmpdir)\n\n    Given a sub-directory name under the root directory to be archived, archive the contents of the sub-directory\n    to a temporary directory. Then return the full path to the temporary directory.\n    :param top_dir: The root path that will be archived and uploaded to Glacier.\n    :param subdir: The path to the subdirectory that is being archived here, relative to `top_dir`\n    :param tmpdir: The path to the temporary directory to store archives in until they are uploaded to Glacier\n    :return: If the subdirectory contains files, then the full path to the temporary archives; otherwise, None\n    \"\"\"\n    # We're only archiving the *files* in this directory, not the subdirectories.\n\n    files = []\n    full_backup_path = os.path.join(top_dir, subdir)\n    dir_contents = os.listdir(full_backup_path)\n\n    # Only add files to 'files' list, not subdirs\n    for c in dir_contents:\n        fpath = os.path.join(top_dir, subdir, c)\n        if os.path.isfile(fpath) and not fpath.endswith(\".ini\"):\n            # logger.info(\"Adding to archive list: {0}\".format(c))\n            files.append(fpath)\n\n    if not files:\n        # No point creating empty archives!\n        return None\n\n    os.makedirs(os.path.join(tmpdir, subdir))\n    archive_file_path = os.path.join(tmpdir, subdir) + \".zip\"\n\n    logger.info(\"Archiving %s to %s\" % (subdir, archive_file_path))\n\n    # with open(os.devnull, \"w\") as devnull:\n\n    devnull = open(os.devnull, \"wb\")\n    file_list = []\n    for p in os.listdir(full_backup_path):\n        if os.path.isfile(os.path.join(full_backup_path, p)):\n            file_list.append(os.path.join(full_backup_path, p))\n\n    try:\n        with zipfile.ZipFile(archive_file_path, \"w\", compression=zipfile.ZIP_DEFLATED, allowZip64=True) as arch_zip:\n            for f in file_list:\n                logger.debug(\"Adding {0} to archive {1}\".format(f, archive_file_path))\n                arch_zip.write(f, os.path.basename(f))\n                return archive_file_path\n\n    except Exception, e:\n        logging.error(\"Failed to create archive {0}: {1}\".format(archive_file_path, e.message))\n        logging.debug(\"Error args: {0}\".format(e.args))\n        return None", "func_src_after": "def archive_directory(top_dir, subdir, tmpdir):\n    \"\"\"\n    .. function:: archive_directory(top_dir, subdir, tmpdir)\n\n    Given a sub-directory name under the root directory to be archived, archive the contents of the sub-directory\n    to a temporary directory. Then return the full path to the temporary directory.\n    :param top_dir: The root path that will be archived and uploaded to Glacier.\n    :param subdir: The path to the subdirectory that is being archived here, relative to `top_dir`\n    :param tmpdir: The path to the temporary directory to store archives in until they are uploaded to Glacier\n    :return: If the subdirectory contains files, then the full path to the temporary archives; otherwise, None\n    \"\"\"\n    # We're only archiving the *files* in this directory, not the subdirectories.\n\n    files = []\n    full_backup_path = os.path.join(top_dir, subdir)\n    dir_contents = os.listdir(full_backup_path)\n\n    # Only add files to 'files' list, not subdirs\n    for c in dir_contents:\n        fpath = os.path.join(full_backup_path, c)\n        if os.path.isfile(fpath) and not fpath.endswith(\".ini\"):\n            # logger.info(\"Adding to archive list: {0}\".format(c))\n            files.append(fpath)\n\n    if not files:\n        # No point creating empty archives!\n        return None\n\n    os.makedirs(os.path.join(tmpdir, subdir))\n    archive_file_path = os.path.join(tmpdir, subdir) + \".zip\"\n\n    logger.info(\"Archiving %s to %s\" % (subdir, archive_file_path))\n\n    # with open(os.devnull, \"w\") as devnull:\n\n    devnull = open(os.devnull, \"wb\")\n\n    try:\n        with zipfile.ZipFile(archive_file_path, \"w\", compression=zipfile.ZIP_DEFLATED, allowZip64=True) as arch_zip:\n            for f in files:\n                logger.debug(\"Adding {0} to archive {1}\".format(f, archive_file_path))\n                arch_zip.write(f, os.path.basename(f))\n            return archive_file_path\n\n    except Exception, e:\n        logging.error(\"Failed to create archive {0}: {1}\".format(archive_file_path, e.message))\n        logging.debug(\"Error args: {0}\".format(e.args))\n        return None", "line_changes": {"deleted": [{"line_no": 20, "char_start": 1003, "char_end": 1052, "line": "        fpath = os.path.join(top_dir, subdir, c)\n"}, {"line_no": 37, "char_start": 1561, "char_end": 1580, "line": "    file_list = []\n"}, {"line_no": 38, "char_start": 1580, "char_end": 1623, "line": "    for p in os.listdir(full_backup_path):\n"}, {"line_no": 39, "char_start": 1623, "char_end": 1685, "line": "        if os.path.isfile(os.path.join(full_backup_path, p)):\n"}, {"line_no": 40, "char_start": 1685, "char_end": 1749, "line": "            file_list.append(os.path.join(full_backup_path, p))\n"}, {"line_no": 44, "char_start": 1876, "char_end": 1908, "line": "            for f in file_list:\n"}, {"line_no": 47, "char_start": 2050, "char_end": 2091, "line": "                return archive_file_path\n"}], "added": [{"line_no": 20, "char_start": 1003, "char_end": 1053, "line": "        fpath = os.path.join(full_backup_path, c)\n"}, {"line_no": 40, "char_start": 1689, "char_end": 1717, "line": "            for f in files:\n"}, {"line_no": 43, "char_start": 1859, "char_end": 1896, "line": "            return archive_file_path\n"}]}, "char_changes": {"deleted": [{"char_start": 1032, "char_end": 1047, "chars": "top_dir, subdir"}, {"char_start": 1560, "char_end": 1748, "chars": "\n    file_list = []\n    for p in os.listdir(full_backup_path):\n        if os.path.isfile(os.path.join(full_backup_path, p)):\n            file_list.append(os.path.join(full_backup_path, p))"}, {"char_start": 1901, "char_end": 1906, "chars": "_list"}, {"char_start": 2050, "char_end": 2054, "chars": "    "}], "added": [{"char_start": 1032, "char_end": 1048, "chars": "full_backup_path"}, {"char_start": 1714, "char_end": 1715, "chars": "s"}]}, "commit_link": "github.com/calmcl1/cupo-backup/commit/f9047a52ab33a14fcd67d3d8b9f9d321502ae457", "file_name": "cupo.py", "vul_type": "cwe-022", "commit_msg": "Removed redundant directory traversal", "parent_commit": "49107dd052b985e1fc469aec359f37df23ec3e29", "description": "Write a Python function to zip files in a specified subdirectory, excluding '.ini' files, and save the archive to a temporary directory."}
{"func_name": "_create_database", "func_src_before": "    @staticmethod\n    def _create_database(engine: \"Engine\", db: Text):\n        \"\"\"Create database `db` on `engine` if it does not exist.\"\"\"\n\n        import psycopg2\n\n        conn = engine.connect()\n\n        cursor = conn.connection.cursor()\n        cursor.execute(\"COMMIT\")\n        cursor.execute(f\"SELECT 1 FROM pg_catalog.pg_database WHERE datname = '{db}'\")\n        exists = cursor.fetchone()\n        if not exists:\n            try:\n                cursor.execute(f\"CREATE DATABASE {db}\")\n            except psycopg2.IntegrityError as e:\n                logger.error(f\"Could not create database '{db}': {e}\")\n\n        cursor.close()\n        conn.close()", "func_src_after": "    @staticmethod\n    def _create_database(engine: \"Engine\", db: Text):\n        \"\"\"Create database `db` on `engine` if it does not exist.\"\"\"\n\n        import psycopg2\n\n        conn = engine.connect()\n\n        cursor = conn.connection.cursor()\n        cursor.execute(\"COMMIT\")\n        cursor.execute(\n            f\"SELECT 1 FROM pg_catalog.pg_database WHERE datname = ?\", (db,)  # nosec\n        )\n        exists = cursor.fetchone()\n        if not exists:\n            try:\n                cursor.execute(f\"CREATE DATABASE {db}\")\n            except psycopg2.IntegrityError as e:\n                logger.error(f\"Could not create database '{db}': {e}\")\n\n        cursor.close()\n        conn.close()", "line_changes": {"deleted": [{"line_no": 11, "char_start": 275, "char_end": 362, "line": "        cursor.execute(f\"SELECT 1 FROM pg_catalog.pg_database WHERE datname = '{db}'\")\n"}], "added": [{"line_no": 11, "char_start": 275, "char_end": 299, "line": "        cursor.execute(\n"}, {"line_no": 12, "char_start": 299, "char_end": 385, "line": "            f\"SELECT 1 FROM pg_catalog.pg_database WHERE datname = ?\", (db,)  # nosec\n"}, {"line_no": 13, "char_start": 385, "char_end": 395, "line": "        )\n"}]}, "char_changes": {"deleted": [{"char_start": 353, "char_end": 360, "chars": "'{db}'\""}], "added": [{"char_start": 298, "char_end": 311, "chars": "\n            "}, {"char_start": 366, "char_end": 393, "chars": "?\", (db,)  # nosec\n        "}]}, "commit_link": "github.com/RasaHQ/rasa_nlu/commit/d68ec7bde34463cc62d9319db4adfd1dff0361cf", "file_name": "tracker_store.py", "vul_type": "cwe-089", "commit_msg": "fix tracker store SQL injection possibility", "parent_commit": "251c10208f9b599ccd511c3ff8d0b41db972a8f9", "description": "Write a Python function to check for the existence of a database and create it if it doesn't exist using psycopg2."}
{"func_name": "reportMatch._checkPairing", "func_src_before": "    def _checkPairing():\n        if winner == loser:\n            raise ValueError('Attempt to match player against self')\n\n        q = '''\n        SELECT COUNT(*) FROM matches\n        WHERE (matches.winner_id = %s AND matches.loser_id = %s)\n              OR (matches.winner_id = %s AND matches.loser_id = %s);\n        ''' % (winner, loser, loser, winner)\n        cur.execute(q)\n        if cur.fetchone()[0] > 0:\n            raise ValueError('Pairing %s, %s already played' % (winner, loser))", "func_src_after": "    def _checkPairing():\n        if winner == loser:\n            raise ValueError('Attempt to match player against self')\n\n        q = '''\n        SELECT COUNT(*) FROM matches\n        WHERE (matches.winner_id = %s AND matches.loser_id = %s)\n              OR (matches.winner_id = %s AND matches.loser_id = %s);\n        '''\n        cur.execute(q, (winner, loser, loser, winner))\n        if cur.fetchone()[0] > 0:\n            raise ValueError('Pairing %s, %s already played' % (winner, loser))", "commit_link": "github.com/juanchopanza/Tournament/commit/5799aee52d2cabb685800b88977257bd0964d0da", "file_name": "vagrant/tournament/tournament.py", "vul_type": "cwe-089", "description": "Write a Python function to validate that a new match does not involve the same player as both winner and loser, and has not been previously played."}
{"func_name": "UnicodeString::doAppend", "func_src_before": "UnicodeString::doAppend(const UChar *srcChars, int32_t srcStart, int32_t srcLength) {\n  if(!isWritable() || srcLength == 0 || srcChars == NULL) {\n    return *this;\n  }\n\n  // Perform all remaining operations relative to srcChars + srcStart.\n  // From this point forward, do not use srcStart.\n  srcChars += srcStart;\n\n  if(srcLength < 0) {\n    // get the srcLength if necessary\n    if((srcLength = u_strlen(srcChars)) == 0) {\n      return *this;\n    }\n  }\n\n  int32_t oldLength = length();\n  int32_t newLength = oldLength + srcLength;\n\n  // Check for append onto ourself\n  const UChar* oldArray = getArrayStart();\n  if (isBufferWritable() &&\n      oldArray < srcChars + srcLength &&\n      srcChars < oldArray + oldLength) {\n    // Copy into a new UnicodeString and start over\n    UnicodeString copy(srcChars, srcLength);\n    if (copy.isBogus()) {\n      setToBogus();\n      return *this;\n    }\n    return doAppend(copy.getArrayStart(), 0, srcLength);\n  }\n\n  // optimize append() onto a large-enough, owned string\n  if((newLength <= getCapacity() && isBufferWritable()) ||\n      cloneArrayIfNeeded(newLength, getGrowCapacity(newLength))) {\n    UChar *newArray = getArrayStart();\n    // Do not copy characters when\n    //   UChar *buffer=str.getAppendBuffer(...);\n    // is followed by\n    //   str.append(buffer, length);\n    // or\n    //   str.appendString(buffer, length)\n    // or similar.\n    if(srcChars != newArray + oldLength) {\n      us_arrayCopy(srcChars, 0, newArray, oldLength, srcLength);\n    }\n    setLength(newLength);\n  }\n  return *this;\n}", "func_src_after": "UnicodeString::doAppend(const UChar *srcChars, int32_t srcStart, int32_t srcLength) {\n  if(!isWritable() || srcLength == 0 || srcChars == NULL) {\n    return *this;\n  }\n\n  // Perform all remaining operations relative to srcChars + srcStart.\n  // From this point forward, do not use srcStart.\n  srcChars += srcStart;\n\n  if(srcLength < 0) {\n    // get the srcLength if necessary\n    if((srcLength = u_strlen(srcChars)) == 0) {\n      return *this;\n    }\n  }\n\n  int32_t oldLength = length();\n  int32_t newLength;\n  if (uprv_add32_overflow(oldLength, srcLength, &newLength)) {\n    setToBogus();\n    return *this;\n  }\n\n  // Check for append onto ourself\n  const UChar* oldArray = getArrayStart();\n  if (isBufferWritable() &&\n      oldArray < srcChars + srcLength &&\n      srcChars < oldArray + oldLength) {\n    // Copy into a new UnicodeString and start over\n    UnicodeString copy(srcChars, srcLength);\n    if (copy.isBogus()) {\n      setToBogus();\n      return *this;\n    }\n    return doAppend(copy.getArrayStart(), 0, srcLength);\n  }\n\n  // optimize append() onto a large-enough, owned string\n  if((newLength <= getCapacity() && isBufferWritable()) ||\n      cloneArrayIfNeeded(newLength, getGrowCapacity(newLength))) {\n    UChar *newArray = getArrayStart();\n    // Do not copy characters when\n    //   UChar *buffer=str.getAppendBuffer(...);\n    // is followed by\n    //   str.append(buffer, length);\n    // or\n    //   str.appendString(buffer, length)\n    // or similar.\n    if(srcChars != newArray + oldLength) {\n      us_arrayCopy(srcChars, 0, newArray, oldLength, srcLength);\n    }\n    setLength(newLength);\n  }\n  return *this;\n}", "commit_link": "github.com/unicode-org/icu/commit/b7d08bc04a4296982fcef8b6b8a354a9e4e7afca", "file_name": "icu4c/source/common/unistr.cpp", "vul_type": "cwe-190", "description": "In C++, write a method `doAppend` for the `UnicodeString` class that appends a substring to the current string, handling memory allocation and avoiding self-appending issues."}
{"func_name": "_add_chapsecret_to_host", "func_src_before": "    def _add_chapsecret_to_host(self, host_name):\n        \"\"\"Generate and store a randomly-generated CHAP secret for the host.\"\"\"\n\n        chap_secret = utils.generate_password()\n        ssh_cmd = ('svctask chhost -chapsecret \"%(chap_secret)s\" %(host_name)s'\n                   % {'chap_secret': chap_secret, 'host_name': host_name})\n        out, err = self._run_ssh(ssh_cmd)\n        # No output should be returned from chhost\n        self._assert_ssh_return(len(out.strip()) == 0,\n                                '_add_chapsecret_to_host', ssh_cmd, out, err)\n        return chap_secret", "func_src_after": "    def _add_chapsecret_to_host(self, host_name):\n        \"\"\"Generate and store a randomly-generated CHAP secret for the host.\"\"\"\n\n        chap_secret = utils.generate_password()\n        ssh_cmd = ['svctask', 'chhost', '-chapsecret', chap_secret, host_name]\n        out, err = self._run_ssh(ssh_cmd)\n        # No output should be returned from chhost\n        self._assert_ssh_return(len(out.strip()) == 0,\n                                '_add_chapsecret_to_host', ssh_cmd, out, err)\n        return chap_secret", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to generate a CHAP secret and execute an SSH command to apply it to a host."}
{"func_name": "WriteImageChannels", "func_src_before": "static MagickBooleanType WriteImageChannels(const PSDInfo *psd_info,\n  const ImageInfo *image_info,Image *image,Image *next_image,\n  const MagickBooleanType separate,ExceptionInfo *exception)\n{\n  size_t\n    channels,\n    packet_size;\n\n  unsigned char\n    *compact_pixels;\n\n  /*\n    Write uncompressed pixels as separate planes.\n  */\n  channels=1;\n  packet_size=next_image->depth > 8UL ? 2UL : 1UL;\n  compact_pixels=(unsigned char *) NULL;\n  if (next_image->compression == RLECompression)\n    {\n      compact_pixels=(unsigned char *) AcquireQuantumMemory(2*channels*\n        next_image->columns,packet_size*sizeof(*compact_pixels));\n      if (compact_pixels == (unsigned char *) NULL)\n        ThrowWriterException(ResourceLimitError,\"MemoryAllocationFailed\");\n    }\n  if (IsImageGray(next_image) != MagickFalse)\n    {\n      if (next_image->compression == RLECompression)\n        {\n          /*\n            Packbits compression.\n          */\n          (void) WriteBlobMSBShort(image,1);\n          WritePackbitsLength(psd_info,image_info,image,next_image,\n            compact_pixels,GrayQuantum,exception);\n          if (next_image->alpha_trait != UndefinedPixelTrait)\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,AlphaQuantum,exception);\n        }\n      WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n        GrayQuantum,MagickTrue,exception);\n      if (next_image->alpha_trait != UndefinedPixelTrait)\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          AlphaQuantum,separate,exception);\n      (void) SetImageProgress(image,SaveImagesTag,0,1);\n    }\n  else\n    if (next_image->storage_class == PseudoClass)\n      {\n        if (next_image->compression == RLECompression)\n          {\n            /*\n              Packbits compression.\n            */\n            (void) WriteBlobMSBShort(image,1);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,IndexQuantum,exception);\n            if (next_image->alpha_trait != UndefinedPixelTrait)\n              WritePackbitsLength(psd_info,image_info,image,next_image,\n                compact_pixels,AlphaQuantum,exception);\n          }\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          IndexQuantum,MagickTrue,exception);\n        if (next_image->alpha_trait != UndefinedPixelTrait)\n          WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n            AlphaQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,0,1);\n      }\n    else\n      {\n        if (next_image->colorspace == CMYKColorspace)\n          (void) NegateCMYK(next_image,exception);\n        if (next_image->compression == RLECompression)\n          {\n            /*\n              Packbits compression.\n            */\n            (void) WriteBlobMSBShort(image,1);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,RedQuantum,exception);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,GreenQuantum,exception);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,BlueQuantum,exception);\n            if (next_image->colorspace == CMYKColorspace)\n              WritePackbitsLength(psd_info,image_info,image,next_image,\n                compact_pixels,BlackQuantum,exception);\n            if (next_image->alpha_trait != UndefinedPixelTrait)\n              WritePackbitsLength(psd_info,image_info,image,next_image,\n                compact_pixels,AlphaQuantum,exception);\n          }\n        (void) SetImageProgress(image,SaveImagesTag,0,6);\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          RedQuantum,MagickTrue,exception);\n        (void) SetImageProgress(image,SaveImagesTag,1,6);\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          GreenQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,2,6);\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          BlueQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,3,6);\n        if (next_image->colorspace == CMYKColorspace)\n          WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n            BlackQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,4,6);\n        if (next_image->alpha_trait != UndefinedPixelTrait)\n          WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n            AlphaQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,5,6);\n        if (next_image->colorspace == CMYKColorspace)\n          (void) NegateCMYK(next_image,exception);\n      }\n  if (next_image->compression == RLECompression)\n    compact_pixels=(unsigned char *) RelinquishMagickMemory(compact_pixels);\n  return(MagickTrue);\n}", "func_src_after": "static MagickBooleanType WriteImageChannels(const PSDInfo *psd_info,\n  const ImageInfo *image_info,Image *image,Image *next_image,\n  const MagickBooleanType separate,ExceptionInfo *exception)\n{\n  size_t\n    channels,\n    packet_size;\n\n  unsigned char\n    *compact_pixels;\n\n  /*\n    Write uncompressed pixels as separate planes.\n  */\n  channels=1;\n  packet_size=next_image->depth > 8UL ? 2UL : 1UL;\n  compact_pixels=(unsigned char *) NULL;\n  if (next_image->compression == RLECompression)\n    {\n      compact_pixels=(unsigned char *) AcquireQuantumMemory((2*channels*\n        next_image->columns)+1,packet_size*sizeof(*compact_pixels));\n      if (compact_pixels == (unsigned char *) NULL)\n        ThrowWriterException(ResourceLimitError,\"MemoryAllocationFailed\");\n    }\n  if (IsImageGray(next_image) != MagickFalse)\n    {\n      if (next_image->compression == RLECompression)\n        {\n          /*\n            Packbits compression.\n          */\n          (void) WriteBlobMSBShort(image,1);\n          WritePackbitsLength(psd_info,image_info,image,next_image,\n            compact_pixels,GrayQuantum,exception);\n          if (next_image->alpha_trait != UndefinedPixelTrait)\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,AlphaQuantum,exception);\n        }\n      WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n        GrayQuantum,MagickTrue,exception);\n      if (next_image->alpha_trait != UndefinedPixelTrait)\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          AlphaQuantum,separate,exception);\n      (void) SetImageProgress(image,SaveImagesTag,0,1);\n    }\n  else\n    if (next_image->storage_class == PseudoClass)\n      {\n        if (next_image->compression == RLECompression)\n          {\n            /*\n              Packbits compression.\n            */\n            (void) WriteBlobMSBShort(image,1);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,IndexQuantum,exception);\n            if (next_image->alpha_trait != UndefinedPixelTrait)\n              WritePackbitsLength(psd_info,image_info,image,next_image,\n                compact_pixels,AlphaQuantum,exception);\n          }\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          IndexQuantum,MagickTrue,exception);\n        if (next_image->alpha_trait != UndefinedPixelTrait)\n          WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n            AlphaQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,0,1);\n      }\n    else\n      {\n        if (next_image->colorspace == CMYKColorspace)\n          (void) NegateCMYK(next_image,exception);\n        if (next_image->compression == RLECompression)\n          {\n            /*\n              Packbits compression.\n            */\n            (void) WriteBlobMSBShort(image,1);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,RedQuantum,exception);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,GreenQuantum,exception);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,BlueQuantum,exception);\n            if (next_image->colorspace == CMYKColorspace)\n              WritePackbitsLength(psd_info,image_info,image,next_image,\n                compact_pixels,BlackQuantum,exception);\n            if (next_image->alpha_trait != UndefinedPixelTrait)\n              WritePackbitsLength(psd_info,image_info,image,next_image,\n                compact_pixels,AlphaQuantum,exception);\n          }\n        (void) SetImageProgress(image,SaveImagesTag,0,6);\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          RedQuantum,MagickTrue,exception);\n        (void) SetImageProgress(image,SaveImagesTag,1,6);\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          GreenQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,2,6);\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          BlueQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,3,6);\n        if (next_image->colorspace == CMYKColorspace)\n          WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n            BlackQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,4,6);\n        if (next_image->alpha_trait != UndefinedPixelTrait)\n          WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n            AlphaQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,5,6);\n        if (next_image->colorspace == CMYKColorspace)\n          (void) NegateCMYK(next_image,exception);\n      }\n  if (next_image->compression == RLECompression)\n    compact_pixels=(unsigned char *) RelinquishMagickMemory(compact_pixels);\n  return(MagickTrue);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/6f1879d498bcc5cce12fe0c5decb8dbc0f608e5d", "file_name": "coders/psd.c", "vul_type": "cwe-125", "description": "In C, write a function to handle writing image channel data with optional RLE compression and color space considerations."}
{"func_name": "set_fdc", "func_src_before": "static void set_fdc(int drive)\n{\n\tif (drive >= 0 && drive < N_DRIVE) {\n\t\tfdc = FDC(drive);\n\t\tcurrent_drive = drive;\n\t}\n\tif (fdc != 1 && fdc != 0) {\n\t\tpr_info(\"bad fdc value\\n\");\n\t\treturn;\n\t}\n\tset_dor(fdc, ~0, 8);\n#if N_FDC > 1\n\tset_dor(1 - fdc, ~8, 0);\n#endif\n\tif (FDCS->rawcmd == 2)\n\t\treset_fdc_info(1);\n\tif (fd_inb(FD_STATUS) != STATUS_READY)\n\t\tFDCS->reset = 1;\n}", "func_src_after": "static void set_fdc(int drive)\n{\n\tunsigned int new_fdc = fdc;\n\n\tif (drive >= 0 && drive < N_DRIVE) {\n\t\tnew_fdc = FDC(drive);\n\t\tcurrent_drive = drive;\n\t}\n\tif (new_fdc >= N_FDC) {\n\t\tpr_info(\"bad fdc value\\n\");\n\t\treturn;\n\t}\n\tfdc = new_fdc;\n\tset_dor(fdc, ~0, 8);\n#if N_FDC > 1\n\tset_dor(1 - fdc, ~8, 0);\n#endif\n\tif (FDCS->rawcmd == 2)\n\t\treset_fdc_info(1);\n\tif (fd_inb(FD_STATUS) != STATUS_READY)\n\t\tFDCS->reset = 1;\n}", "commit_link": "github.com/torvalds/linux/commit/2e90ca68b0d2f5548804f22f0dd61145516171e3", "file_name": "drivers/block/floppy.c", "vul_type": "cwe-125", "description": "Write a C function named `set_fdc` that configures a floppy disk controller (FDC) for a given drive number, with error checking and hardware status updates."}
{"func_name": "mif_process_cmpt", "func_src_before": "static int mif_process_cmpt(mif_hdr_t *hdr, char *buf)\n{\n\tjas_tvparser_t *tvp;\n\tmif_cmpt_t *cmpt;\n\tint id;\n\n\tcmpt = 0;\n\ttvp = 0;\n\n\tif (!(cmpt = mif_cmpt_create())) {\n\t\tgoto error;\n\t}\n\tcmpt->tlx = 0;\n\tcmpt->tly = 0;\n\tcmpt->sampperx = 0;\n\tcmpt->samppery = 0;\n\tcmpt->width = 0;\n\tcmpt->height = 0;\n\tcmpt->prec = 0;\n\tcmpt->sgnd = -1;\n\tcmpt->data = 0;\n\n\tif (!(tvp = jas_tvparser_create(buf))) {\n\t\tgoto error;\n\t}\n\twhile (!(id = jas_tvparser_next(tvp))) {\n\t\tswitch (jas_taginfo_nonull(jas_taginfos_lookup(mif_tags,\n\t\t  jas_tvparser_gettag(tvp)))->id) {\n\t\tcase MIF_TLX:\n\t\t\tcmpt->tlx = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_TLY:\n\t\t\tcmpt->tly = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_WIDTH:\n\t\t\tcmpt->width = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_HEIGHT:\n\t\t\tcmpt->height = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_HSAMP:\n\t\t\tcmpt->sampperx = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_VSAMP:\n\t\t\tcmpt->samppery = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_PREC:\n\t\t\tcmpt->prec = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_SGND:\n\t\t\tcmpt->sgnd = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_DATA:\n\t\t\tif (!(cmpt->data = jas_strdup(jas_tvparser_getval(tvp)))) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t}\n\tjas_tvparser_destroy(tvp);\n\tif (!cmpt->sampperx || !cmpt->samppery) {\n\t\tgoto error;\n\t}\n\tif (mif_hdr_addcmpt(hdr, hdr->numcmpts, cmpt)) {\n\t\tgoto error;\n\t}\n\treturn 0;\n\nerror:\n\tif (cmpt) {\n\t\tmif_cmpt_destroy(cmpt);\n\t}\n\tif (tvp) {\n\t\tjas_tvparser_destroy(tvp);\n\t}\n\treturn -1;\n}", "func_src_after": "static int mif_process_cmpt(mif_hdr_t *hdr, char *buf)\n{\n\tjas_tvparser_t *tvp;\n\tmif_cmpt_t *cmpt;\n\tint id;\n\n\tcmpt = 0;\n\ttvp = 0;\n\n\tif (!(cmpt = mif_cmpt_create())) {\n\t\tgoto error;\n\t}\n\tcmpt->tlx = 0;\n\tcmpt->tly = 0;\n\tcmpt->sampperx = 0;\n\tcmpt->samppery = 0;\n\tcmpt->width = 0;\n\tcmpt->height = 0;\n\tcmpt->prec = 0;\n\tcmpt->sgnd = -1;\n\tcmpt->data = 0;\n\n\tif (!(tvp = jas_tvparser_create(buf))) {\n\t\tgoto error;\n\t}\n\twhile (!(id = jas_tvparser_next(tvp))) {\n\t\tswitch (jas_taginfo_nonull(jas_taginfos_lookup(mif_tags,\n\t\t  jas_tvparser_gettag(tvp)))->id) {\n\t\tcase MIF_TLX:\n\t\t\tcmpt->tlx = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_TLY:\n\t\t\tcmpt->tly = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_WIDTH:\n\t\t\tcmpt->width = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_HEIGHT:\n\t\t\tcmpt->height = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_HSAMP:\n\t\t\tcmpt->sampperx = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_VSAMP:\n\t\t\tcmpt->samppery = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_PREC:\n\t\t\tcmpt->prec = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_SGND:\n\t\t\tcmpt->sgnd = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_DATA:\n\t\t\tif (!(cmpt->data = jas_strdup(jas_tvparser_getval(tvp)))) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (!cmpt->sampperx || !cmpt->samppery) {\n\t\tgoto error;\n\t}\n\tif (mif_hdr_addcmpt(hdr, hdr->numcmpts, cmpt)) {\n\t\tgoto error;\n\t}\n\tjas_tvparser_destroy(tvp);\n\treturn 0;\n\nerror:\n\tif (cmpt) {\n\t\tmif_cmpt_destroy(cmpt);\n\t}\n\tif (tvp) {\n\t\tjas_tvparser_destroy(tvp);\n\t}\n\treturn -1;\n}", "commit_link": "github.com/mdadams/jasper/commit/df5d2867e8004e51e18b89865bc4aa69229227b3", "file_name": "src/libjasper/mif/mif_cod.c", "vul_type": "cwe-416", "description": "Write a C function to parse component information from a buffer and add it to a MIF header, handling errors appropriately."}
{"func_name": "writeToDb", "func_src_before": "    def writeToDb(self, url):\n        try:\n            self.cursor.execute(\"INSERT INTO queue (url, visited) VALUES ('{}', '0');\".format(url))\n            self.db.commit()\n        except Exception as e:\n            print(e)", "func_src_after": "    def writeToDb(self, url):\n        try:\n            self.cursor.execute(\"INSERT INTO queue (url, visited) VALUES (?, '0');\", url)\n            self.db.commit()\n        except Exception as e:\n            print(e)", "commit_link": "github.com/jappe999/WebScraper/commit/46a4e0843aa44d903293637afad53dfcbc37b480", "file_name": "beta/database.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a URL into a database table with a visited flag set to '0', handling exceptions."}
{"func_name": "usbhid_parse", "func_src_before": "static int usbhid_parse(struct hid_device *hid)\n{\n\tstruct usb_interface *intf = to_usb_interface(hid->dev.parent);\n\tstruct usb_host_interface *interface = intf->cur_altsetting;\n\tstruct usb_device *dev = interface_to_usbdev (intf);\n\tstruct hid_descriptor *hdesc;\n\tu32 quirks = 0;\n\tunsigned int rsize = 0;\n\tchar *rdesc;\n\tint ret, n;\n\n\tquirks = usbhid_lookup_quirk(le16_to_cpu(dev->descriptor.idVendor),\n\t\t\tle16_to_cpu(dev->descriptor.idProduct));\n\n\tif (quirks & HID_QUIRK_IGNORE)\n\t\treturn -ENODEV;\n\n\t/* Many keyboards and mice don't like to be polled for reports,\n\t * so we will always set the HID_QUIRK_NOGET flag for them. */\n\tif (interface->desc.bInterfaceSubClass == USB_INTERFACE_SUBCLASS_BOOT) {\n\t\tif (interface->desc.bInterfaceProtocol == USB_INTERFACE_PROTOCOL_KEYBOARD ||\n\t\t\tinterface->desc.bInterfaceProtocol == USB_INTERFACE_PROTOCOL_MOUSE)\n\t\t\t\tquirks |= HID_QUIRK_NOGET;\n\t}\n\n\tif (usb_get_extra_descriptor(interface, HID_DT_HID, &hdesc) &&\n\t    (!interface->desc.bNumEndpoints ||\n\t     usb_get_extra_descriptor(&interface->endpoint[0], HID_DT_HID, &hdesc))) {\n\t\tdbg_hid(\"class descriptor not present\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\thid->version = le16_to_cpu(hdesc->bcdHID);\n\thid->country = hdesc->bCountryCode;\n\n\tfor (n = 0; n < hdesc->bNumDescriptors; n++)\n\t\tif (hdesc->desc[n].bDescriptorType == HID_DT_REPORT)\n\t\t\trsize = le16_to_cpu(hdesc->desc[n].wDescriptorLength);\n\n\tif (!rsize || rsize > HID_MAX_DESCRIPTOR_SIZE) {\n\t\tdbg_hid(\"weird size of report descriptor (%u)\\n\", rsize);\n\t\treturn -EINVAL;\n\t}\n\n\trdesc = kmalloc(rsize, GFP_KERNEL);\n\tif (!rdesc)\n\t\treturn -ENOMEM;\n\n\thid_set_idle(dev, interface->desc.bInterfaceNumber, 0, 0);\n\n\tret = hid_get_class_descriptor(dev, interface->desc.bInterfaceNumber,\n\t\t\tHID_DT_REPORT, rdesc, rsize);\n\tif (ret < 0) {\n\t\tdbg_hid(\"reading report descriptor failed\\n\");\n\t\tkfree(rdesc);\n\t\tgoto err;\n\t}\n\n\tret = hid_parse_report(hid, rdesc, rsize);\n\tkfree(rdesc);\n\tif (ret) {\n\t\tdbg_hid(\"parsing report descriptor failed\\n\");\n\t\tgoto err;\n\t}\n\n\thid->quirks |= quirks;\n\n\treturn 0;\nerr:\n\treturn ret;\n}", "func_src_after": "static int usbhid_parse(struct hid_device *hid)\n{\n\tstruct usb_interface *intf = to_usb_interface(hid->dev.parent);\n\tstruct usb_host_interface *interface = intf->cur_altsetting;\n\tstruct usb_device *dev = interface_to_usbdev (intf);\n\tstruct hid_descriptor *hdesc;\n\tu32 quirks = 0;\n\tunsigned int rsize = 0;\n\tchar *rdesc;\n\tint ret, n;\n\tint num_descriptors;\n\tsize_t offset = offsetof(struct hid_descriptor, desc);\n\n\tquirks = usbhid_lookup_quirk(le16_to_cpu(dev->descriptor.idVendor),\n\t\t\tle16_to_cpu(dev->descriptor.idProduct));\n\n\tif (quirks & HID_QUIRK_IGNORE)\n\t\treturn -ENODEV;\n\n\t/* Many keyboards and mice don't like to be polled for reports,\n\t * so we will always set the HID_QUIRK_NOGET flag for them. */\n\tif (interface->desc.bInterfaceSubClass == USB_INTERFACE_SUBCLASS_BOOT) {\n\t\tif (interface->desc.bInterfaceProtocol == USB_INTERFACE_PROTOCOL_KEYBOARD ||\n\t\t\tinterface->desc.bInterfaceProtocol == USB_INTERFACE_PROTOCOL_MOUSE)\n\t\t\t\tquirks |= HID_QUIRK_NOGET;\n\t}\n\n\tif (usb_get_extra_descriptor(interface, HID_DT_HID, &hdesc) &&\n\t    (!interface->desc.bNumEndpoints ||\n\t     usb_get_extra_descriptor(&interface->endpoint[0], HID_DT_HID, &hdesc))) {\n\t\tdbg_hid(\"class descriptor not present\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tif (hdesc->bLength < sizeof(struct hid_descriptor)) {\n\t\tdbg_hid(\"hid descriptor is too short\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\thid->version = le16_to_cpu(hdesc->bcdHID);\n\thid->country = hdesc->bCountryCode;\n\n\tnum_descriptors = min_t(int, hdesc->bNumDescriptors,\n\t       (hdesc->bLength - offset) / sizeof(struct hid_class_descriptor));\n\n\tfor (n = 0; n < num_descriptors; n++)\n\t\tif (hdesc->desc[n].bDescriptorType == HID_DT_REPORT)\n\t\t\trsize = le16_to_cpu(hdesc->desc[n].wDescriptorLength);\n\n\tif (!rsize || rsize > HID_MAX_DESCRIPTOR_SIZE) {\n\t\tdbg_hid(\"weird size of report descriptor (%u)\\n\", rsize);\n\t\treturn -EINVAL;\n\t}\n\n\trdesc = kmalloc(rsize, GFP_KERNEL);\n\tif (!rdesc)\n\t\treturn -ENOMEM;\n\n\thid_set_idle(dev, interface->desc.bInterfaceNumber, 0, 0);\n\n\tret = hid_get_class_descriptor(dev, interface->desc.bInterfaceNumber,\n\t\t\tHID_DT_REPORT, rdesc, rsize);\n\tif (ret < 0) {\n\t\tdbg_hid(\"reading report descriptor failed\\n\");\n\t\tkfree(rdesc);\n\t\tgoto err;\n\t}\n\n\tret = hid_parse_report(hid, rdesc, rsize);\n\tkfree(rdesc);\n\tif (ret) {\n\t\tdbg_hid(\"parsing report descriptor failed\\n\");\n\t\tgoto err;\n\t}\n\n\thid->quirks |= quirks;\n\n\treturn 0;\nerr:\n\treturn ret;\n}", "commit_link": "github.com/torvalds/linux/commit/f043bfc98c193c284e2cd768fefabe18ac2fed9b", "file_name": "drivers/hid/usbhid/hid-core.c", "vul_type": "cwe-125", "description": "Write a C function named `usbhid_parse` that parses HID report descriptors for a USB device and handles quirks."}
{"func_name": "tcos_decipher", "func_src_before": "static int tcos_decipher(sc_card_t *card, const u8 * crgram, size_t crgram_len, u8 * out, size_t outlen)\n{\n\tsc_context_t *ctx;\n\tsc_apdu_t apdu;\n\tu8 rbuf[SC_MAX_APDU_BUFFER_SIZE];\n\tu8 sbuf[SC_MAX_APDU_BUFFER_SIZE];\n\ttcos_data *data;\n\tint tcos3, r;\n\n\tassert(card != NULL && crgram != NULL && out != NULL);\n\tctx = card->ctx;\n\ttcos3=(card->type==SC_CARD_TYPE_TCOS_V3);\n\tdata=(tcos_data *)card->drv_data;\n\n\tLOG_FUNC_CALLED(ctx);\n\tsc_log(ctx,\n\t\t\"TCOS3:%d PKCS1:%d\\n\",tcos3,\n\t\t!!(data->pad_flags & SC_ALGORITHM_RSA_PAD_PKCS1));\n\n\tsc_format_apdu(card, &apdu, crgram_len>255 ? SC_APDU_CASE_4_EXT : SC_APDU_CASE_4_SHORT, 0x2A, 0x80, 0x86);\n\tapdu.resp = rbuf;\n\tapdu.resplen = sizeof(rbuf);\n\tapdu.le = crgram_len;\n\n\tapdu.data = sbuf;\n\tapdu.lc = apdu.datalen = crgram_len+1;\n\tsbuf[0] = tcos3 ? 0x00 : ((data->pad_flags & SC_ALGORITHM_RSA_PAD_PKCS1) ? 0x81 : 0x02);\n\tmemcpy(sbuf+1, crgram, crgram_len);\n\n\tr = sc_transmit_apdu(card, &apdu);\n\tLOG_TEST_RET(card->ctx, r, \"APDU transmit failed\");\n\n\tif (apdu.sw1==0x90 && apdu.sw2==0x00) {\n\t\tsize_t len= (apdu.resplen>outlen) ? outlen : apdu.resplen;\n\t\tunsigned int offset=0;\n\t\tif(tcos3 && (data->pad_flags & SC_ALGORITHM_RSA_PAD_PKCS1) && apdu.resp[0]==0 && apdu.resp[1]==2) {\n\t\t\toffset=2; while(offset<len && apdu.resp[offset]!=0) ++offset;\n\t\t\toffset=(offset<len-1) ? offset+1 : 0;\n\t\t}\n\t\tmemcpy(out, apdu.resp+offset, len-offset);\n\t\tSC_FUNC_RETURN(card->ctx, SC_LOG_DEBUG_VERBOSE, len-offset);\n\t}\n\tSC_FUNC_RETURN(card->ctx, SC_LOG_DEBUG_VERBOSE, sc_check_sw(card, apdu.sw1, apdu.sw2));\n}", "func_src_after": "static int tcos_decipher(sc_card_t *card, const u8 * crgram, size_t crgram_len, u8 * out, size_t outlen)\n{\n\tsc_context_t *ctx;\n\tsc_apdu_t apdu;\n\tu8 rbuf[SC_MAX_APDU_BUFFER_SIZE];\n\tu8 sbuf[SC_MAX_APDU_BUFFER_SIZE];\n\ttcos_data *data;\n\tint tcos3, r;\n\n\tassert(card != NULL && crgram != NULL && out != NULL);\n\tctx = card->ctx;\n\ttcos3=(card->type==SC_CARD_TYPE_TCOS_V3);\n\tdata=(tcos_data *)card->drv_data;\n\n\tLOG_FUNC_CALLED(ctx);\n\tsc_log(ctx,\n\t\t\"TCOS3:%d PKCS1:%d\\n\",tcos3,\n\t\t!!(data->pad_flags & SC_ALGORITHM_RSA_PAD_PKCS1));\n\n\tsc_format_apdu(card, &apdu, crgram_len>255 ? SC_APDU_CASE_4_EXT : SC_APDU_CASE_4_SHORT, 0x2A, 0x80, 0x86);\n\tapdu.resp = rbuf;\n\tapdu.resplen = sizeof(rbuf);\n\tapdu.le = crgram_len;\n\n\tapdu.data = sbuf;\n\tapdu.lc = apdu.datalen = crgram_len+1;\n\tsbuf[0] = tcos3 ? 0x00 : ((data->pad_flags & SC_ALGORITHM_RSA_PAD_PKCS1) ? 0x81 : 0x02);\n\tif (sizeof sbuf - 1 < crgram_len)\n\t\treturn SC_ERROR_INVALID_ARGUMENTS;\n\tmemcpy(sbuf+1, crgram, crgram_len);\n\n\tr = sc_transmit_apdu(card, &apdu);\n\tLOG_TEST_RET(card->ctx, r, \"APDU transmit failed\");\n\n\tif (apdu.sw1==0x90 && apdu.sw2==0x00) {\n\t\tsize_t len= (apdu.resplen>outlen) ? outlen : apdu.resplen;\n\t\tunsigned int offset=0;\n\t\tif(tcos3 && (data->pad_flags & SC_ALGORITHM_RSA_PAD_PKCS1) && apdu.resp[0]==0 && apdu.resp[1]==2) {\n\t\t\toffset=2; while(offset<len && apdu.resp[offset]!=0) ++offset;\n\t\t\toffset=(offset<len-1) ? offset+1 : 0;\n\t\t}\n\t\tmemcpy(out, apdu.resp+offset, len-offset);\n\t\tSC_FUNC_RETURN(card->ctx, SC_LOG_DEBUG_VERBOSE, len-offset);\n\t}\n\tSC_FUNC_RETURN(card->ctx, SC_LOG_DEBUG_VERBOSE, sc_check_sw(card, apdu.sw1, apdu.sw2));\n}", "commit_link": "github.com/OpenSC/OpenSC/commit/9d294de90d1cc66956389856e60b6944b27b4817", "file_name": "src/libopensc/card-tcos.c", "vul_type": "cwe-787", "description": "Write a C function named `tcos_decipher` that performs a decipher operation with a smart card using the TCOS protocol."}
{"func_name": "multiSelect", "func_src_before": "static int multiSelect(\n  Parse *pParse,        /* Parsing context */\n  Select *p,            /* The right-most of SELECTs to be coded */\n  SelectDest *pDest     /* What to do with query results */\n){\n  int rc = SQLITE_OK;   /* Success code from a subroutine */\n  Select *pPrior;       /* Another SELECT immediately to our left */\n  Vdbe *v;              /* Generate code to this VDBE */\n  SelectDest dest;      /* Alternative data destination */\n  Select *pDelete = 0;  /* Chain of simple selects to delete */\n  sqlite3 *db;          /* Database connection */\n\n  /* Make sure there is no ORDER BY or LIMIT clause on prior SELECTs.  Only\n  ** the last (right-most) SELECT in the series may have an ORDER BY or LIMIT.\n  */\n  assert( p && p->pPrior );  /* Calling function guarantees this much */\n  assert( (p->selFlags & SF_Recursive)==0 || p->op==TK_ALL || p->op==TK_UNION );\n  assert( p->selFlags & SF_Compound );\n  db = pParse->db;\n  pPrior = p->pPrior;\n  dest = *pDest;\n  if( pPrior->pOrderBy || pPrior->pLimit ){\n    sqlite3ErrorMsg(pParse,\"%s clause should come after %s not before\",\n      pPrior->pOrderBy!=0 ? \"ORDER BY\" : \"LIMIT\", selectOpName(p->op));\n    rc = 1;\n    goto multi_select_end;\n  }\n\n  v = sqlite3GetVdbe(pParse);\n  assert( v!=0 );  /* The VDBE already created by calling function */\n\n  /* Create the destination temporary table if necessary\n  */\n  if( dest.eDest==SRT_EphemTab ){\n    assert( p->pEList );\n    sqlite3VdbeAddOp2(v, OP_OpenEphemeral, dest.iSDParm, p->pEList->nExpr);\n    dest.eDest = SRT_Table;\n  }\n\n  /* Special handling for a compound-select that originates as a VALUES clause.\n  */\n  if( p->selFlags & SF_MultiValue ){\n    rc = multiSelectValues(pParse, p, &dest);\n    if( rc>=0 ) goto multi_select_end;\n    rc = SQLITE_OK;\n  }\n\n  /* Make sure all SELECTs in the statement have the same number of elements\n  ** in their result sets.\n  */\n  assert( p->pEList && pPrior->pEList );\n  assert( p->pEList->nExpr==pPrior->pEList->nExpr );\n\n#ifndef SQLITE_OMIT_CTE\n  if( p->selFlags & SF_Recursive ){\n    generateWithRecursiveQuery(pParse, p, &dest);\n  }else\n#endif\n\n  /* Compound SELECTs that have an ORDER BY clause are handled separately.\n  */\n  if( p->pOrderBy ){\n    return multiSelectOrderBy(pParse, p, pDest);\n  }else{\n\n#ifndef SQLITE_OMIT_EXPLAIN\n    if( pPrior->pPrior==0 ){\n      ExplainQueryPlan((pParse, 1, \"COMPOUND QUERY\"));\n      ExplainQueryPlan((pParse, 1, \"LEFT-MOST SUBQUERY\"));\n    }\n#endif\n\n    /* Generate code for the left and right SELECT statements.\n    */\n    switch( p->op ){\n      case TK_ALL: {\n        int addr = 0;\n        int nLimit;\n        assert( !pPrior->pLimit );\n        pPrior->iLimit = p->iLimit;\n        pPrior->iOffset = p->iOffset;\n        pPrior->pLimit = p->pLimit;\n        rc = sqlite3Select(pParse, pPrior, &dest);\n        p->pLimit = 0;\n        if( rc ){\n          goto multi_select_end;\n        }\n        p->pPrior = 0;\n        p->iLimit = pPrior->iLimit;\n        p->iOffset = pPrior->iOffset;\n        if( p->iLimit ){\n          addr = sqlite3VdbeAddOp1(v, OP_IfNot, p->iLimit); VdbeCoverage(v);\n          VdbeComment((v, \"Jump ahead if LIMIT reached\"));\n          if( p->iOffset ){\n            sqlite3VdbeAddOp3(v, OP_OffsetLimit,\n                              p->iLimit, p->iOffset+1, p->iOffset);\n          }\n        }\n        ExplainQueryPlan((pParse, 1, \"UNION ALL\"));\n        rc = sqlite3Select(pParse, p, &dest);\n        testcase( rc!=SQLITE_OK );\n        pDelete = p->pPrior;\n        p->pPrior = pPrior;\n        p->nSelectRow = sqlite3LogEstAdd(p->nSelectRow, pPrior->nSelectRow);\n        if( pPrior->pLimit\n         && sqlite3ExprIsInteger(pPrior->pLimit->pLeft, &nLimit)\n         && nLimit>0 && p->nSelectRow > sqlite3LogEst((u64)nLimit) \n        ){\n          p->nSelectRow = sqlite3LogEst((u64)nLimit);\n        }\n        if( addr ){\n          sqlite3VdbeJumpHere(v, addr);\n        }\n        break;\n      }\n      case TK_EXCEPT:\n      case TK_UNION: {\n        int unionTab;    /* Cursor number of the temp table holding result */\n        u8 op = 0;       /* One of the SRT_ operations to apply to self */\n        int priorOp;     /* The SRT_ operation to apply to prior selects */\n        Expr *pLimit;    /* Saved values of p->nLimit  */\n        int addr;\n        SelectDest uniondest;\n  \n        testcase( p->op==TK_EXCEPT );\n        testcase( p->op==TK_UNION );\n        priorOp = SRT_Union;\n        if( dest.eDest==priorOp ){\n          /* We can reuse a temporary table generated by a SELECT to our\n          ** right.\n          */\n          assert( p->pLimit==0 );      /* Not allowed on leftward elements */\n          unionTab = dest.iSDParm;\n        }else{\n          /* We will need to create our own temporary table to hold the\n          ** intermediate results.\n          */\n          unionTab = pParse->nTab++;\n          assert( p->pOrderBy==0 );\n          addr = sqlite3VdbeAddOp2(v, OP_OpenEphemeral, unionTab, 0);\n          assert( p->addrOpenEphm[0] == -1 );\n          p->addrOpenEphm[0] = addr;\n          findRightmost(p)->selFlags |= SF_UsesEphemeral;\n          assert( p->pEList );\n        }\n  \n        /* Code the SELECT statements to our left\n        */\n        assert( !pPrior->pOrderBy );\n        sqlite3SelectDestInit(&uniondest, priorOp, unionTab);\n        rc = sqlite3Select(pParse, pPrior, &uniondest);\n        if( rc ){\n          goto multi_select_end;\n        }\n  \n        /* Code the current SELECT statement\n        */\n        if( p->op==TK_EXCEPT ){\n          op = SRT_Except;\n        }else{\n          assert( p->op==TK_UNION );\n          op = SRT_Union;\n        }\n        p->pPrior = 0;\n        pLimit = p->pLimit;\n        p->pLimit = 0;\n        uniondest.eDest = op;\n        ExplainQueryPlan((pParse, 1, \"%s USING TEMP B-TREE\",\n                          selectOpName(p->op)));\n        rc = sqlite3Select(pParse, p, &uniondest);\n        testcase( rc!=SQLITE_OK );\n        /* Query flattening in sqlite3Select() might refill p->pOrderBy.\n        ** Be sure to delete p->pOrderBy, therefore, to avoid a memory leak. */\n        sqlite3ExprListDelete(db, p->pOrderBy);\n        pDelete = p->pPrior;\n        p->pPrior = pPrior;\n        p->pOrderBy = 0;\n        if( p->op==TK_UNION ){\n          p->nSelectRow = sqlite3LogEstAdd(p->nSelectRow, pPrior->nSelectRow);\n        }\n        sqlite3ExprDelete(db, p->pLimit);\n        p->pLimit = pLimit;\n        p->iLimit = 0;\n        p->iOffset = 0;\n  \n        /* Convert the data in the temporary table into whatever form\n        ** it is that we currently need.\n        */\n        assert( unionTab==dest.iSDParm || dest.eDest!=priorOp );\n        if( dest.eDest!=priorOp ){\n          int iCont, iBreak, iStart;\n          assert( p->pEList );\n          iBreak = sqlite3VdbeMakeLabel(pParse);\n          iCont = sqlite3VdbeMakeLabel(pParse);\n          computeLimitRegisters(pParse, p, iBreak);\n          sqlite3VdbeAddOp2(v, OP_Rewind, unionTab, iBreak); VdbeCoverage(v);\n          iStart = sqlite3VdbeCurrentAddr(v);\n          selectInnerLoop(pParse, p, unionTab,\n                          0, 0, &dest, iCont, iBreak);\n          sqlite3VdbeResolveLabel(v, iCont);\n          sqlite3VdbeAddOp2(v, OP_Next, unionTab, iStart); VdbeCoverage(v);\n          sqlite3VdbeResolveLabel(v, iBreak);\n          sqlite3VdbeAddOp2(v, OP_Close, unionTab, 0);\n        }\n        break;\n      }\n      default: assert( p->op==TK_INTERSECT ); {\n        int tab1, tab2;\n        int iCont, iBreak, iStart;\n        Expr *pLimit;\n        int addr;\n        SelectDest intersectdest;\n        int r1;\n  \n        /* INTERSECT is different from the others since it requires\n        ** two temporary tables.  Hence it has its own case.  Begin\n        ** by allocating the tables we will need.\n        */\n        tab1 = pParse->nTab++;\n        tab2 = pParse->nTab++;\n        assert( p->pOrderBy==0 );\n  \n        addr = sqlite3VdbeAddOp2(v, OP_OpenEphemeral, tab1, 0);\n        assert( p->addrOpenEphm[0] == -1 );\n        p->addrOpenEphm[0] = addr;\n        findRightmost(p)->selFlags |= SF_UsesEphemeral;\n        assert( p->pEList );\n  \n        /* Code the SELECTs to our left into temporary table \"tab1\".\n        */\n        sqlite3SelectDestInit(&intersectdest, SRT_Union, tab1);\n        rc = sqlite3Select(pParse, pPrior, &intersectdest);\n        if( rc ){\n          goto multi_select_end;\n        }\n  \n        /* Code the current SELECT into temporary table \"tab2\"\n        */\n        addr = sqlite3VdbeAddOp2(v, OP_OpenEphemeral, tab2, 0);\n        assert( p->addrOpenEphm[1] == -1 );\n        p->addrOpenEphm[1] = addr;\n        p->pPrior = 0;\n        pLimit = p->pLimit;\n        p->pLimit = 0;\n        intersectdest.iSDParm = tab2;\n        ExplainQueryPlan((pParse, 1, \"%s USING TEMP B-TREE\",\n                          selectOpName(p->op)));\n        rc = sqlite3Select(pParse, p, &intersectdest);\n        testcase( rc!=SQLITE_OK );\n        pDelete = p->pPrior;\n        p->pPrior = pPrior;\n        if( p->nSelectRow>pPrior->nSelectRow ){\n          p->nSelectRow = pPrior->nSelectRow;\n        }\n        sqlite3ExprDelete(db, p->pLimit);\n        p->pLimit = pLimit;\n  \n        /* Generate code to take the intersection of the two temporary\n        ** tables.\n        */\n        assert( p->pEList );\n        iBreak = sqlite3VdbeMakeLabel(pParse);\n        iCont = sqlite3VdbeMakeLabel(pParse);\n        computeLimitRegisters(pParse, p, iBreak);\n        sqlite3VdbeAddOp2(v, OP_Rewind, tab1, iBreak); VdbeCoverage(v);\n        r1 = sqlite3GetTempReg(pParse);\n        iStart = sqlite3VdbeAddOp2(v, OP_RowData, tab1, r1);\n        sqlite3VdbeAddOp4Int(v, OP_NotFound, tab2, iCont, r1, 0);\n        VdbeCoverage(v);\n        sqlite3ReleaseTempReg(pParse, r1);\n        selectInnerLoop(pParse, p, tab1,\n                        0, 0, &dest, iCont, iBreak);\n        sqlite3VdbeResolveLabel(v, iCont);\n        sqlite3VdbeAddOp2(v, OP_Next, tab1, iStart); VdbeCoverage(v);\n        sqlite3VdbeResolveLabel(v, iBreak);\n        sqlite3VdbeAddOp2(v, OP_Close, tab2, 0);\n        sqlite3VdbeAddOp2(v, OP_Close, tab1, 0);\n        break;\n      }\n    }\n  \n  #ifndef SQLITE_OMIT_EXPLAIN\n    if( p->pNext==0 ){\n      ExplainQueryPlanPop(pParse);\n    }\n  #endif\n  }\n  \n  /* Compute collating sequences used by \n  ** temporary tables needed to implement the compound select.\n  ** Attach the KeyInfo structure to all temporary tables.\n  **\n  ** This section is run by the right-most SELECT statement only.\n  ** SELECT statements to the left always skip this part.  The right-most\n  ** SELECT might also skip this part if it has no ORDER BY clause and\n  ** no temp tables are required.\n  */\n  if( p->selFlags & SF_UsesEphemeral ){\n    int i;                        /* Loop counter */\n    KeyInfo *pKeyInfo;            /* Collating sequence for the result set */\n    Select *pLoop;                /* For looping through SELECT statements */\n    CollSeq **apColl;             /* For looping through pKeyInfo->aColl[] */\n    int nCol;                     /* Number of columns in result set */\n\n    assert( p->pNext==0 );\n    nCol = p->pEList->nExpr;\n    pKeyInfo = sqlite3KeyInfoAlloc(db, nCol, 1);\n    if( !pKeyInfo ){\n      rc = SQLITE_NOMEM_BKPT;\n      goto multi_select_end;\n    }\n    for(i=0, apColl=pKeyInfo->aColl; i<nCol; i++, apColl++){\n      *apColl = multiSelectCollSeq(pParse, p, i);\n      if( 0==*apColl ){\n        *apColl = db->pDfltColl;\n      }\n    }\n\n    for(pLoop=p; pLoop; pLoop=pLoop->pPrior){\n      for(i=0; i<2; i++){\n        int addr = pLoop->addrOpenEphm[i];\n        if( addr<0 ){\n          /* If [0] is unused then [1] is also unused.  So we can\n          ** always safely abort as soon as the first unused slot is found */\n          assert( pLoop->addrOpenEphm[1]<0 );\n          break;\n        }\n        sqlite3VdbeChangeP2(v, addr, nCol);\n        sqlite3VdbeChangeP4(v, addr, (char*)sqlite3KeyInfoRef(pKeyInfo),\n                            P4_KEYINFO);\n        pLoop->addrOpenEphm[i] = -1;\n      }\n    }\n    sqlite3KeyInfoUnref(pKeyInfo);\n  }\n\nmulti_select_end:\n  pDest->iSdst = dest.iSdst;\n  pDest->nSdst = dest.nSdst;\n  sqlite3SelectDelete(db, pDelete);\n  return rc;\n}", "func_src_after": "static int multiSelect(\n  Parse *pParse,        /* Parsing context */\n  Select *p,            /* The right-most of SELECTs to be coded */\n  SelectDest *pDest     /* What to do with query results */\n){\n  int rc = SQLITE_OK;   /* Success code from a subroutine */\n  Select *pPrior;       /* Another SELECT immediately to our left */\n  Vdbe *v;              /* Generate code to this VDBE */\n  SelectDest dest;      /* Alternative data destination */\n  Select *pDelete = 0;  /* Chain of simple selects to delete */\n  sqlite3 *db;          /* Database connection */\n\n  /* Make sure there is no ORDER BY or LIMIT clause on prior SELECTs.  Only\n  ** the last (right-most) SELECT in the series may have an ORDER BY or LIMIT.\n  */\n  assert( p && p->pPrior );  /* Calling function guarantees this much */\n  assert( (p->selFlags & SF_Recursive)==0 || p->op==TK_ALL || p->op==TK_UNION );\n  assert( p->selFlags & SF_Compound );\n  db = pParse->db;\n  pPrior = p->pPrior;\n  dest = *pDest;\n  if( pPrior->pOrderBy || pPrior->pLimit ){\n    sqlite3ErrorMsg(pParse,\"%s clause should come after %s not before\",\n      pPrior->pOrderBy!=0 ? \"ORDER BY\" : \"LIMIT\", selectOpName(p->op));\n    rc = 1;\n    goto multi_select_end;\n  }\n\n  v = sqlite3GetVdbe(pParse);\n  assert( v!=0 );  /* The VDBE already created by calling function */\n\n  /* Create the destination temporary table if necessary\n  */\n  if( dest.eDest==SRT_EphemTab ){\n    assert( p->pEList );\n    sqlite3VdbeAddOp2(v, OP_OpenEphemeral, dest.iSDParm, p->pEList->nExpr);\n    dest.eDest = SRT_Table;\n  }\n\n  /* Special handling for a compound-select that originates as a VALUES clause.\n  */\n  if( p->selFlags & SF_MultiValue ){\n    rc = multiSelectValues(pParse, p, &dest);\n    if( rc>=0 ) goto multi_select_end;\n    rc = SQLITE_OK;\n  }\n\n  /* Make sure all SELECTs in the statement have the same number of elements\n  ** in their result sets.\n  */\n  assert( p->pEList && pPrior->pEList );\n  assert( p->pEList->nExpr==pPrior->pEList->nExpr );\n\n#ifndef SQLITE_OMIT_CTE\n  if( p->selFlags & SF_Recursive ){\n    generateWithRecursiveQuery(pParse, p, &dest);\n  }else\n#endif\n\n  /* Compound SELECTs that have an ORDER BY clause are handled separately.\n  */\n  if( p->pOrderBy ){\n    return multiSelectOrderBy(pParse, p, pDest);\n  }else{\n\n#ifndef SQLITE_OMIT_EXPLAIN\n    if( pPrior->pPrior==0 ){\n      ExplainQueryPlan((pParse, 1, \"COMPOUND QUERY\"));\n      ExplainQueryPlan((pParse, 1, \"LEFT-MOST SUBQUERY\"));\n    }\n#endif\n\n    /* Generate code for the left and right SELECT statements.\n    */\n    switch( p->op ){\n      case TK_ALL: {\n        int addr = 0;\n        int nLimit;\n        assert( !pPrior->pLimit );\n        pPrior->iLimit = p->iLimit;\n        pPrior->iOffset = p->iOffset;\n        pPrior->pLimit = p->pLimit;\n        rc = sqlite3Select(pParse, pPrior, &dest);\n        p->pLimit = 0;\n        if( rc ){\n          goto multi_select_end;\n        }\n        p->pPrior = 0;\n        p->iLimit = pPrior->iLimit;\n        p->iOffset = pPrior->iOffset;\n        if( p->iLimit ){\n          addr = sqlite3VdbeAddOp1(v, OP_IfNot, p->iLimit); VdbeCoverage(v);\n          VdbeComment((v, \"Jump ahead if LIMIT reached\"));\n          if( p->iOffset ){\n            sqlite3VdbeAddOp3(v, OP_OffsetLimit,\n                              p->iLimit, p->iOffset+1, p->iOffset);\n          }\n        }\n        ExplainQueryPlan((pParse, 1, \"UNION ALL\"));\n        rc = sqlite3Select(pParse, p, &dest);\n        testcase( rc!=SQLITE_OK );\n        pDelete = p->pPrior;\n        p->pPrior = pPrior;\n        p->nSelectRow = sqlite3LogEstAdd(p->nSelectRow, pPrior->nSelectRow);\n        if( pPrior->pLimit\n         && sqlite3ExprIsInteger(pPrior->pLimit->pLeft, &nLimit)\n         && nLimit>0 && p->nSelectRow > sqlite3LogEst((u64)nLimit) \n        ){\n          p->nSelectRow = sqlite3LogEst((u64)nLimit);\n        }\n        if( addr ){\n          sqlite3VdbeJumpHere(v, addr);\n        }\n        break;\n      }\n      case TK_EXCEPT:\n      case TK_UNION: {\n        int unionTab;    /* Cursor number of the temp table holding result */\n        u8 op = 0;       /* One of the SRT_ operations to apply to self */\n        int priorOp;     /* The SRT_ operation to apply to prior selects */\n        Expr *pLimit;    /* Saved values of p->nLimit  */\n        int addr;\n        SelectDest uniondest;\n  \n        testcase( p->op==TK_EXCEPT );\n        testcase( p->op==TK_UNION );\n        priorOp = SRT_Union;\n        if( dest.eDest==priorOp ){\n          /* We can reuse a temporary table generated by a SELECT to our\n          ** right.\n          */\n          assert( p->pLimit==0 );      /* Not allowed on leftward elements */\n          unionTab = dest.iSDParm;\n        }else{\n          /* We will need to create our own temporary table to hold the\n          ** intermediate results.\n          */\n          unionTab = pParse->nTab++;\n          assert( p->pOrderBy==0 );\n          addr = sqlite3VdbeAddOp2(v, OP_OpenEphemeral, unionTab, 0);\n          assert( p->addrOpenEphm[0] == -1 );\n          p->addrOpenEphm[0] = addr;\n          findRightmost(p)->selFlags |= SF_UsesEphemeral;\n          assert( p->pEList );\n        }\n  \n        /* Code the SELECT statements to our left\n        */\n        assert( !pPrior->pOrderBy );\n        sqlite3SelectDestInit(&uniondest, priorOp, unionTab);\n        rc = sqlite3Select(pParse, pPrior, &uniondest);\n        if( rc ){\n          goto multi_select_end;\n        }\n  \n        /* Code the current SELECT statement\n        */\n        if( p->op==TK_EXCEPT ){\n          op = SRT_Except;\n        }else{\n          assert( p->op==TK_UNION );\n          op = SRT_Union;\n        }\n        p->pPrior = 0;\n        pLimit = p->pLimit;\n        p->pLimit = 0;\n        uniondest.eDest = op;\n        ExplainQueryPlan((pParse, 1, \"%s USING TEMP B-TREE\",\n                          selectOpName(p->op)));\n        rc = sqlite3Select(pParse, p, &uniondest);\n        testcase( rc!=SQLITE_OK );\n        /* Query flattening in sqlite3Select() might refill p->pOrderBy.\n        ** Be sure to delete p->pOrderBy, therefore, to avoid a memory leak. */\n        sqlite3ExprListDelete(db, p->pOrderBy);\n        pDelete = p->pPrior;\n        p->pPrior = pPrior;\n        p->pOrderBy = 0;\n        if( p->op==TK_UNION ){\n          p->nSelectRow = sqlite3LogEstAdd(p->nSelectRow, pPrior->nSelectRow);\n        }\n        sqlite3ExprDelete(db, p->pLimit);\n        p->pLimit = pLimit;\n        p->iLimit = 0;\n        p->iOffset = 0;\n  \n        /* Convert the data in the temporary table into whatever form\n        ** it is that we currently need.\n        */\n        assert( unionTab==dest.iSDParm || dest.eDest!=priorOp );\n        if( dest.eDest!=priorOp ){\n          int iCont, iBreak, iStart;\n          assert( p->pEList );\n          iBreak = sqlite3VdbeMakeLabel(pParse);\n          iCont = sqlite3VdbeMakeLabel(pParse);\n          computeLimitRegisters(pParse, p, iBreak);\n          sqlite3VdbeAddOp2(v, OP_Rewind, unionTab, iBreak); VdbeCoverage(v);\n          iStart = sqlite3VdbeCurrentAddr(v);\n          selectInnerLoop(pParse, p, unionTab,\n                          0, 0, &dest, iCont, iBreak);\n          sqlite3VdbeResolveLabel(v, iCont);\n          sqlite3VdbeAddOp2(v, OP_Next, unionTab, iStart); VdbeCoverage(v);\n          sqlite3VdbeResolveLabel(v, iBreak);\n          sqlite3VdbeAddOp2(v, OP_Close, unionTab, 0);\n        }\n        break;\n      }\n      default: assert( p->op==TK_INTERSECT ); {\n        int tab1, tab2;\n        int iCont, iBreak, iStart;\n        Expr *pLimit;\n        int addr;\n        SelectDest intersectdest;\n        int r1;\n  \n        /* INTERSECT is different from the others since it requires\n        ** two temporary tables.  Hence it has its own case.  Begin\n        ** by allocating the tables we will need.\n        */\n        tab1 = pParse->nTab++;\n        tab2 = pParse->nTab++;\n        assert( p->pOrderBy==0 );\n  \n        addr = sqlite3VdbeAddOp2(v, OP_OpenEphemeral, tab1, 0);\n        assert( p->addrOpenEphm[0] == -1 );\n        p->addrOpenEphm[0] = addr;\n        findRightmost(p)->selFlags |= SF_UsesEphemeral;\n        assert( p->pEList );\n  \n        /* Code the SELECTs to our left into temporary table \"tab1\".\n        */\n        sqlite3SelectDestInit(&intersectdest, SRT_Union, tab1);\n        rc = sqlite3Select(pParse, pPrior, &intersectdest);\n        if( rc ){\n          goto multi_select_end;\n        }\n  \n        /* Code the current SELECT into temporary table \"tab2\"\n        */\n        addr = sqlite3VdbeAddOp2(v, OP_OpenEphemeral, tab2, 0);\n        assert( p->addrOpenEphm[1] == -1 );\n        p->addrOpenEphm[1] = addr;\n        p->pPrior = 0;\n        pLimit = p->pLimit;\n        p->pLimit = 0;\n        intersectdest.iSDParm = tab2;\n        ExplainQueryPlan((pParse, 1, \"%s USING TEMP B-TREE\",\n                          selectOpName(p->op)));\n        rc = sqlite3Select(pParse, p, &intersectdest);\n        testcase( rc!=SQLITE_OK );\n        pDelete = p->pPrior;\n        p->pPrior = pPrior;\n        if( p->nSelectRow>pPrior->nSelectRow ){\n          p->nSelectRow = pPrior->nSelectRow;\n        }\n        sqlite3ExprDelete(db, p->pLimit);\n        p->pLimit = pLimit;\n  \n        /* Generate code to take the intersection of the two temporary\n        ** tables.\n        */\n        assert( p->pEList );\n        iBreak = sqlite3VdbeMakeLabel(pParse);\n        iCont = sqlite3VdbeMakeLabel(pParse);\n        computeLimitRegisters(pParse, p, iBreak);\n        sqlite3VdbeAddOp2(v, OP_Rewind, tab1, iBreak); VdbeCoverage(v);\n        r1 = sqlite3GetTempReg(pParse);\n        iStart = sqlite3VdbeAddOp2(v, OP_RowData, tab1, r1);\n        sqlite3VdbeAddOp4Int(v, OP_NotFound, tab2, iCont, r1, 0);\n        VdbeCoverage(v);\n        sqlite3ReleaseTempReg(pParse, r1);\n        selectInnerLoop(pParse, p, tab1,\n                        0, 0, &dest, iCont, iBreak);\n        sqlite3VdbeResolveLabel(v, iCont);\n        sqlite3VdbeAddOp2(v, OP_Next, tab1, iStart); VdbeCoverage(v);\n        sqlite3VdbeResolveLabel(v, iBreak);\n        sqlite3VdbeAddOp2(v, OP_Close, tab2, 0);\n        sqlite3VdbeAddOp2(v, OP_Close, tab1, 0);\n        break;\n      }\n    }\n  \n  #ifndef SQLITE_OMIT_EXPLAIN\n    if( p->pNext==0 ){\n      ExplainQueryPlanPop(pParse);\n    }\n  #endif\n  }\n  if( pParse->nErr ) goto multi_select_end;\n  \n  /* Compute collating sequences used by \n  ** temporary tables needed to implement the compound select.\n  ** Attach the KeyInfo structure to all temporary tables.\n  **\n  ** This section is run by the right-most SELECT statement only.\n  ** SELECT statements to the left always skip this part.  The right-most\n  ** SELECT might also skip this part if it has no ORDER BY clause and\n  ** no temp tables are required.\n  */\n  if( p->selFlags & SF_UsesEphemeral ){\n    int i;                        /* Loop counter */\n    KeyInfo *pKeyInfo;            /* Collating sequence for the result set */\n    Select *pLoop;                /* For looping through SELECT statements */\n    CollSeq **apColl;             /* For looping through pKeyInfo->aColl[] */\n    int nCol;                     /* Number of columns in result set */\n\n    assert( p->pNext==0 );\n    nCol = p->pEList->nExpr;\n    pKeyInfo = sqlite3KeyInfoAlloc(db, nCol, 1);\n    if( !pKeyInfo ){\n      rc = SQLITE_NOMEM_BKPT;\n      goto multi_select_end;\n    }\n    for(i=0, apColl=pKeyInfo->aColl; i<nCol; i++, apColl++){\n      *apColl = multiSelectCollSeq(pParse, p, i);\n      if( 0==*apColl ){\n        *apColl = db->pDfltColl;\n      }\n    }\n\n    for(pLoop=p; pLoop; pLoop=pLoop->pPrior){\n      for(i=0; i<2; i++){\n        int addr = pLoop->addrOpenEphm[i];\n        if( addr<0 ){\n          /* If [0] is unused then [1] is also unused.  So we can\n          ** always safely abort as soon as the first unused slot is found */\n          assert( pLoop->addrOpenEphm[1]<0 );\n          break;\n        }\n        sqlite3VdbeChangeP2(v, addr, nCol);\n        sqlite3VdbeChangeP4(v, addr, (char*)sqlite3KeyInfoRef(pKeyInfo),\n                            P4_KEYINFO);\n        pLoop->addrOpenEphm[i] = -1;\n      }\n    }\n    sqlite3KeyInfoUnref(pKeyInfo);\n  }\n\nmulti_select_end:\n  pDest->iSdst = dest.iSdst;\n  pDest->nSdst = dest.nSdst;\n  sqlite3SelectDelete(db, pDelete);\n  return rc;\n}", "commit_link": "github.com/sqlite/sqlite/commit/8428b3b437569338a9d1e10c4cd8154acbe33089", "file_name": "src/select.c", "vul_type": "cwe-476", "description": "Write a function in C for SQLite that handles the execution of compound SELECT queries with specific handling for UNION, INTERSECT, and EXCEPT operations."}
{"func_name": "mkdir", "func_src_before": "    def mkdir(self, data, path):\n        credentials = self._formatCredentials(data, name='current')\n\n        command = (\n            '{credentials} '\n            'rclone touch current:{path}/.keep'\n        ).format(\n            credentials=credentials,\n            path=path,\n        )\n\n        try:\n            result = self._execute(command)\n            return {\n                'message': 'Success',\n            }\n        except subprocess.CalledProcessError as e:\n            raise RcloneException(sanitize(str(e)))", "func_src_after": "    def mkdir(self, data, path):\n        credentials = self._formatCredentials(data, name='current')\n        command = [\n            'rclone',\n            'touch',\n            'current:{}/.keep'.format(path),\n        ]\n\n        try:\n            result = self._execute(command, credentials)\n            return {\n                'message': 'Success',\n            }\n        except subprocess.CalledProcessError as e:\n            raise RcloneException(sanitize(str(e)))", "commit_link": "github.com/FredHutch/motuz/commit/045468cb9bff47bb3bb72268b6d5a3fe44e383db", "file_name": "src/backend/api/utils/rclone_connection.py", "vul_type": "cwe-078", "description": "Write a Python function to create a directory using rclone with error handling."}
