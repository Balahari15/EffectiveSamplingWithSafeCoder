{"func_name": "stralgoLCS", "func_src_before": "void stralgoLCS(client *c) {\n    uint32_t i, j;\n    long long minmatchlen = 0;\n    sds a = NULL, b = NULL;\n    int getlen = 0, getidx = 0, withmatchlen = 0;\n    robj *obja = NULL, *objb = NULL;\n\n    for (j = 2; j < (uint32_t)c->argc; j++) {\n        char *opt = c->argv[j]->ptr;\n        int moreargs = (c->argc-1) - j;\n\n        if (!strcasecmp(opt,\"IDX\")) {\n            getidx = 1;\n        } else if (!strcasecmp(opt,\"LEN\")) {\n            getlen = 1;\n        } else if (!strcasecmp(opt,\"WITHMATCHLEN\")) {\n            withmatchlen = 1;\n        } else if (!strcasecmp(opt,\"MINMATCHLEN\") && moreargs) {\n            if (getLongLongFromObjectOrReply(c,c->argv[j+1],&minmatchlen,NULL)\n                != C_OK) goto cleanup;\n            if (minmatchlen < 0) minmatchlen = 0;\n            j++;\n        } else if (!strcasecmp(opt,\"STRINGS\") && moreargs > 1) {\n            if (a != NULL) {\n                addReplyError(c,\"Either use STRINGS or KEYS\");\n                goto cleanup;\n            }\n            a = c->argv[j+1]->ptr;\n            b = c->argv[j+2]->ptr;\n            j += 2;\n        } else if (!strcasecmp(opt,\"KEYS\") && moreargs > 1) {\n            if (a != NULL) {\n                addReplyError(c,\"Either use STRINGS or KEYS\");\n                goto cleanup;\n            }\n            obja = lookupKeyRead(c->db,c->argv[j+1]);\n            objb = lookupKeyRead(c->db,c->argv[j+2]);\n            if ((obja && obja->type != OBJ_STRING) ||\n                (objb && objb->type != OBJ_STRING))\n            {\n                addReplyError(c,\n                    \"The specified keys must contain string values\");\n                /* Don't cleanup the objects, we need to do that\n                 * only after calling getDecodedObject(). */\n                obja = NULL;\n                objb = NULL;\n                goto cleanup;\n            }\n            obja = obja ? getDecodedObject(obja) : createStringObject(\"\",0);\n            objb = objb ? getDecodedObject(objb) : createStringObject(\"\",0);\n            a = obja->ptr;\n            b = objb->ptr;\n            j += 2;\n        } else {\n            addReplyErrorObject(c,shared.syntaxerr);\n            goto cleanup;\n        }\n    }\n\n    /* Complain if the user passed ambiguous parameters. */\n    if (a == NULL) {\n        addReplyError(c,\"Please specify two strings: \"\n                        \"STRINGS or KEYS options are mandatory\");\n        goto cleanup;\n    } else if (getlen && getidx) {\n        addReplyError(c,\n            \"If you want both the length and indexes, please \"\n            \"just use IDX.\");\n        goto cleanup;\n    }\n\n    /* Compute the LCS using the vanilla dynamic programming technique of\n     * building a table of LCS(x,y) substrings. */\n    uint32_t alen = sdslen(a);\n    uint32_t blen = sdslen(b);\n\n    /* Setup an uint32_t array to store at LCS[i,j] the length of the\n     * LCS A0..i-1, B0..j-1. Note that we have a linear array here, so\n     * we index it as LCS[j+(blen+1)*j] */\n    uint32_t *lcs = zmalloc((alen+1)*(blen+1)*sizeof(uint32_t));\n    #define LCS(A,B) lcs[(B)+((A)*(blen+1))]\n\n    /* Start building the LCS table. */\n    for (uint32_t i = 0; i <= alen; i++) {\n        for (uint32_t j = 0; j <= blen; j++) {\n            if (i == 0 || j == 0) {\n                /* If one substring has length of zero, the\n                 * LCS length is zero. */\n                LCS(i,j) = 0;\n            } else if (a[i-1] == b[j-1]) {\n                /* The len LCS (and the LCS itself) of two\n                 * sequences with the same final character, is the\n                 * LCS of the two sequences without the last char\n                 * plus that last char. */\n                LCS(i,j) = LCS(i-1,j-1)+1;\n            } else {\n                /* If the last character is different, take the longest\n                 * between the LCS of the first string and the second\n                 * minus the last char, and the reverse. */\n                uint32_t lcs1 = LCS(i-1,j);\n                uint32_t lcs2 = LCS(i,j-1);\n                LCS(i,j) = lcs1 > lcs2 ? lcs1 : lcs2;\n            }\n        }\n    }\n\n    /* Store the actual LCS string in \"result\" if needed. We create\n     * it backward, but the length is already known, we store it into idx. */\n    uint32_t idx = LCS(alen,blen);\n    sds result = NULL;        /* Resulting LCS string. */\n    void *arraylenptr = NULL; /* Deferred length of the array for IDX. */\n    uint32_t arange_start = alen, /* alen signals that values are not set. */\n             arange_end = 0,\n             brange_start = 0,\n             brange_end = 0;\n\n    /* Do we need to compute the actual LCS string? Allocate it in that case. */\n    int computelcs = getidx || !getlen;\n    if (computelcs) result = sdsnewlen(SDS_NOINIT,idx);\n\n    /* Start with a deferred array if we have to emit the ranges. */\n    uint32_t arraylen = 0;  /* Number of ranges emitted in the array. */\n    if (getidx) {\n        addReplyMapLen(c,2);\n        addReplyBulkCString(c,\"matches\");\n        arraylenptr = addReplyDeferredLen(c);\n    }\n\n    i = alen, j = blen;\n    while (computelcs && i > 0 && j > 0) {\n        int emit_range = 0;\n        if (a[i-1] == b[j-1]) {\n            /* If there is a match, store the character and reduce\n             * the indexes to look for a new match. */\n            result[idx-1] = a[i-1];\n\n            /* Track the current range. */\n            if (arange_start == alen) {\n                arange_start = i-1;\n                arange_end = i-1;\n                brange_start = j-1;\n                brange_end = j-1;\n            } else {\n                /* Let's see if we can extend the range backward since\n                 * it is contiguous. */\n                if (arange_start == i && brange_start == j) {\n                    arange_start--;\n                    brange_start--;\n                } else {\n                    emit_range = 1;\n                }\n            }\n            /* Emit the range if we matched with the first byte of\n             * one of the two strings. We'll exit the loop ASAP. */\n            if (arange_start == 0 || brange_start == 0) emit_range = 1;\n            idx--; i--; j--;\n        } else {\n            /* Otherwise reduce i and j depending on the largest\n             * LCS between, to understand what direction we need to go. */\n            uint32_t lcs1 = LCS(i-1,j);\n            uint32_t lcs2 = LCS(i,j-1);\n            if (lcs1 > lcs2)\n                i--;\n            else\n                j--;\n            if (arange_start != alen) emit_range = 1;\n        }\n\n        /* Emit the current range if needed. */\n        uint32_t match_len = arange_end - arange_start + 1;\n        if (emit_range) {\n            if (minmatchlen == 0 || match_len >= minmatchlen) {\n                if (arraylenptr) {\n                    addReplyArrayLen(c,2+withmatchlen);\n                    addReplyArrayLen(c,2);\n                    addReplyLongLong(c,arange_start);\n                    addReplyLongLong(c,arange_end);\n                    addReplyArrayLen(c,2);\n                    addReplyLongLong(c,brange_start);\n                    addReplyLongLong(c,brange_end);\n                    if (withmatchlen) addReplyLongLong(c,match_len);\n                    arraylen++;\n                }\n            }\n            arange_start = alen; /* Restart at the next match. */\n        }\n    }\n\n    /* Signal modified key, increment dirty, ... */\n\n    /* Reply depending on the given options. */\n    if (arraylenptr) {\n        addReplyBulkCString(c,\"len\");\n        addReplyLongLong(c,LCS(alen,blen));\n        setDeferredArrayLen(c,arraylenptr,arraylen);\n    } else if (getlen) {\n        addReplyLongLong(c,LCS(alen,blen));\n    } else {\n        addReplyBulkSds(c,result);\n        result = NULL;\n    }\n\n    /* Cleanup. */\n    sdsfree(result);\n    zfree(lcs);\n\ncleanup:\n    if (obja) decrRefCount(obja);\n    if (objb) decrRefCount(objb);\n    return;\n}", "func_src_after": "void stralgoLCS(client *c) {\n    uint32_t i, j;\n    long long minmatchlen = 0;\n    sds a = NULL, b = NULL;\n    int getlen = 0, getidx = 0, withmatchlen = 0;\n    robj *obja = NULL, *objb = NULL;\n\n    for (j = 2; j < (uint32_t)c->argc; j++) {\n        char *opt = c->argv[j]->ptr;\n        int moreargs = (c->argc-1) - j;\n\n        if (!strcasecmp(opt,\"IDX\")) {\n            getidx = 1;\n        } else if (!strcasecmp(opt,\"LEN\")) {\n            getlen = 1;\n        } else if (!strcasecmp(opt,\"WITHMATCHLEN\")) {\n            withmatchlen = 1;\n        } else if (!strcasecmp(opt,\"MINMATCHLEN\") && moreargs) {\n            if (getLongLongFromObjectOrReply(c,c->argv[j+1],&minmatchlen,NULL)\n                != C_OK) goto cleanup;\n            if (minmatchlen < 0) minmatchlen = 0;\n            j++;\n        } else if (!strcasecmp(opt,\"STRINGS\") && moreargs > 1) {\n            if (a != NULL) {\n                addReplyError(c,\"Either use STRINGS or KEYS\");\n                goto cleanup;\n            }\n            a = c->argv[j+1]->ptr;\n            b = c->argv[j+2]->ptr;\n            j += 2;\n        } else if (!strcasecmp(opt,\"KEYS\") && moreargs > 1) {\n            if (a != NULL) {\n                addReplyError(c,\"Either use STRINGS or KEYS\");\n                goto cleanup;\n            }\n            obja = lookupKeyRead(c->db,c->argv[j+1]);\n            objb = lookupKeyRead(c->db,c->argv[j+2]);\n            if ((obja && obja->type != OBJ_STRING) ||\n                (objb && objb->type != OBJ_STRING))\n            {\n                addReplyError(c,\n                    \"The specified keys must contain string values\");\n                /* Don't cleanup the objects, we need to do that\n                 * only after calling getDecodedObject(). */\n                obja = NULL;\n                objb = NULL;\n                goto cleanup;\n            }\n            obja = obja ? getDecodedObject(obja) : createStringObject(\"\",0);\n            objb = objb ? getDecodedObject(objb) : createStringObject(\"\",0);\n            a = obja->ptr;\n            b = objb->ptr;\n            j += 2;\n        } else {\n            addReplyErrorObject(c,shared.syntaxerr);\n            goto cleanup;\n        }\n    }\n\n    /* Complain if the user passed ambiguous parameters. */\n    if (a == NULL) {\n        addReplyError(c,\"Please specify two strings: \"\n                        \"STRINGS or KEYS options are mandatory\");\n        goto cleanup;\n    } else if (getlen && getidx) {\n        addReplyError(c,\n            \"If you want both the length and indexes, please \"\n            \"just use IDX.\");\n        goto cleanup;\n    }\n\n    /* Compute the LCS using the vanilla dynamic programming technique of\n     * building a table of LCS(x,y) substrings. */\n    uint32_t alen = sdslen(a);\n    uint32_t blen = sdslen(b);\n\n    /* Setup an uint32_t array to store at LCS[i,j] the length of the\n     * LCS A0..i-1, B0..j-1. Note that we have a linear array here, so\n     * we index it as LCS[j+(blen+1)*j] */\n    uint32_t *lcs = zmalloc((size_t)(alen+1)*(blen+1)*sizeof(uint32_t));\n    #define LCS(A,B) lcs[(B)+((A)*(blen+1))]\n\n    /* Start building the LCS table. */\n    for (uint32_t i = 0; i <= alen; i++) {\n        for (uint32_t j = 0; j <= blen; j++) {\n            if (i == 0 || j == 0) {\n                /* If one substring has length of zero, the\n                 * LCS length is zero. */\n                LCS(i,j) = 0;\n            } else if (a[i-1] == b[j-1]) {\n                /* The len LCS (and the LCS itself) of two\n                 * sequences with the same final character, is the\n                 * LCS of the two sequences without the last char\n                 * plus that last char. */\n                LCS(i,j) = LCS(i-1,j-1)+1;\n            } else {\n                /* If the last character is different, take the longest\n                 * between the LCS of the first string and the second\n                 * minus the last char, and the reverse. */\n                uint32_t lcs1 = LCS(i-1,j);\n                uint32_t lcs2 = LCS(i,j-1);\n                LCS(i,j) = lcs1 > lcs2 ? lcs1 : lcs2;\n            }\n        }\n    }\n\n    /* Store the actual LCS string in \"result\" if needed. We create\n     * it backward, but the length is already known, we store it into idx. */\n    uint32_t idx = LCS(alen,blen);\n    sds result = NULL;        /* Resulting LCS string. */\n    void *arraylenptr = NULL; /* Deferred length of the array for IDX. */\n    uint32_t arange_start = alen, /* alen signals that values are not set. */\n             arange_end = 0,\n             brange_start = 0,\n             brange_end = 0;\n\n    /* Do we need to compute the actual LCS string? Allocate it in that case. */\n    int computelcs = getidx || !getlen;\n    if (computelcs) result = sdsnewlen(SDS_NOINIT,idx);\n\n    /* Start with a deferred array if we have to emit the ranges. */\n    uint32_t arraylen = 0;  /* Number of ranges emitted in the array. */\n    if (getidx) {\n        addReplyMapLen(c,2);\n        addReplyBulkCString(c,\"matches\");\n        arraylenptr = addReplyDeferredLen(c);\n    }\n\n    i = alen, j = blen;\n    while (computelcs && i > 0 && j > 0) {\n        int emit_range = 0;\n        if (a[i-1] == b[j-1]) {\n            /* If there is a match, store the character and reduce\n             * the indexes to look for a new match. */\n            result[idx-1] = a[i-1];\n\n            /* Track the current range. */\n            if (arange_start == alen) {\n                arange_start = i-1;\n                arange_end = i-1;\n                brange_start = j-1;\n                brange_end = j-1;\n            } else {\n                /* Let's see if we can extend the range backward since\n                 * it is contiguous. */\n                if (arange_start == i && brange_start == j) {\n                    arange_start--;\n                    brange_start--;\n                } else {\n                    emit_range = 1;\n                }\n            }\n            /* Emit the range if we matched with the first byte of\n             * one of the two strings. We'll exit the loop ASAP. */\n            if (arange_start == 0 || brange_start == 0) emit_range = 1;\n            idx--; i--; j--;\n        } else {\n            /* Otherwise reduce i and j depending on the largest\n             * LCS between, to understand what direction we need to go. */\n            uint32_t lcs1 = LCS(i-1,j);\n            uint32_t lcs2 = LCS(i,j-1);\n            if (lcs1 > lcs2)\n                i--;\n            else\n                j--;\n            if (arange_start != alen) emit_range = 1;\n        }\n\n        /* Emit the current range if needed. */\n        uint32_t match_len = arange_end - arange_start + 1;\n        if (emit_range) {\n            if (minmatchlen == 0 || match_len >= minmatchlen) {\n                if (arraylenptr) {\n                    addReplyArrayLen(c,2+withmatchlen);\n                    addReplyArrayLen(c,2);\n                    addReplyLongLong(c,arange_start);\n                    addReplyLongLong(c,arange_end);\n                    addReplyArrayLen(c,2);\n                    addReplyLongLong(c,brange_start);\n                    addReplyLongLong(c,brange_end);\n                    if (withmatchlen) addReplyLongLong(c,match_len);\n                    arraylen++;\n                }\n            }\n            arange_start = alen; /* Restart at the next match. */\n        }\n    }\n\n    /* Signal modified key, increment dirty, ... */\n\n    /* Reply depending on the given options. */\n    if (arraylenptr) {\n        addReplyBulkCString(c,\"len\");\n        addReplyLongLong(c,LCS(alen,blen));\n        setDeferredArrayLen(c,arraylenptr,arraylen);\n    } else if (getlen) {\n        addReplyLongLong(c,LCS(alen,blen));\n    } else {\n        addReplyBulkSds(c,result);\n        result = NULL;\n    }\n\n    /* Cleanup. */\n    sdsfree(result);\n    zfree(lcs);\n\ncleanup:\n    if (obja) decrRefCount(obja);\n    if (objb) decrRefCount(objb);\n    return;\n}", "line_changes": {"deleted": [{"line_no": 80, "char_start": 2951, "char_end": 3016, "line": "    uint32_t *lcs = zmalloc((alen+1)*(blen+1)*sizeof(uint32_t));\n"}], "added": [{"line_no": 80, "char_start": 2951, "char_end": 3024, "line": "    uint32_t *lcs = zmalloc((size_t)(alen+1)*(blen+1)*sizeof(uint32_t));\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 2980, "char_end": 2988, "chars": "size_t)("}]}, "commit_link": "github.com/oranagra/redis/commit/f0c5f920d0f88bd8aa376a2c05af4902789d1ef9", "file_name": "t_string.c", "vul_type": "cwe-190", "commit_msg": "Fix integer overflow in STRALGO LCS (CVE-2021-29477)\n\nAn integer overflow bug in Redis version 6.0 or newer could be exploited using\nthe STRALGO LCS command to corrupt the heap and potentially result with remote\ncode execution.", "parent_commit": "29900d4e6bccdf3691bedf0ea9a5d84863fa3592", "description": "Write a C function named `stralgoLCS` that computes the longest common subsequence (LCS) of two strings."}
{"func_name": "license_read_new_or_upgrade_license_packet", "func_src_before": "BOOL license_read_new_or_upgrade_license_packet(rdpLicense* license, wStream* s)\n{\n\tUINT32 os_major;\n\tUINT32 os_minor;\n\tUINT32 cbScope, cbCompanyName, cbProductId, cbLicenseInfo;\n\twStream* licenseStream = NULL;\n\tBOOL ret = FALSE;\n\tBYTE computedMac[16];\n\tLICENSE_BLOB* calBlob;\n\n\tDEBUG_LICENSE(\"Receiving Server New/Upgrade License Packet\");\n\n\tcalBlob = license_new_binary_blob(BB_DATA_BLOB);\n\tif (!calBlob)\n\t\treturn FALSE;\n\n\t/* EncryptedLicenseInfo */\n\tif (!license_read_encrypted_blob(license, s, calBlob))\n\t\tgoto out_free_blob;\n\n\t/* compute MAC and check it */\n\tif (Stream_GetRemainingLength(s) < 16)\n\t\tgoto out_free_blob;\n\n\tif (!security_mac_data(license->MacSaltKey, calBlob->data, calBlob->length, computedMac))\n\t\tgoto out_free_blob;\n\n\tif (memcmp(computedMac, Stream_Pointer(s), sizeof(computedMac)) != 0)\n\t{\n\t\tWLog_ERR(TAG, \"new or upgrade license MAC mismatch\");\n\t\tgoto out_free_blob;\n\t}\n\n\tif (!Stream_SafeSeek(s, 16))\n\t\tgoto out_free_blob;\n\n\tlicenseStream = Stream_New(calBlob->data, calBlob->length);\n\tif (!licenseStream)\n\t\tgoto out_free_blob;\n\n\tStream_Read_UINT16(licenseStream, os_minor);\n\tStream_Read_UINT16(licenseStream, os_major);\n\n\t/* Scope */\n\tStream_Read_UINT32(licenseStream, cbScope);\n\tif (Stream_GetRemainingLength(licenseStream) < cbScope)\n\t\tgoto out_free_stream;\n#ifdef WITH_DEBUG_LICENSE\n\tWLog_DBG(TAG, \"Scope:\");\n\twinpr_HexDump(TAG, WLOG_DEBUG, Stream_Pointer(licenseStream), cbScope);\n#endif\n\tStream_Seek(licenseStream, cbScope);\n\n\t/* CompanyName */\n\tStream_Read_UINT32(licenseStream, cbCompanyName);\n\tif (Stream_GetRemainingLength(licenseStream) < cbCompanyName)\n\t\tgoto out_free_stream;\n#ifdef WITH_DEBUG_LICENSE\n\tWLog_DBG(TAG, \"Company name:\");\n\twinpr_HexDump(TAG, WLOG_DEBUG, Stream_Pointer(licenseStream), cbCompanyName);\n#endif\n\tStream_Seek(licenseStream, cbCompanyName);\n\n\t/* productId */\n\tStream_Read_UINT32(licenseStream, cbProductId);\n\tif (Stream_GetRemainingLength(licenseStream) < cbProductId)\n\t\tgoto out_free_stream;\n#ifdef WITH_DEBUG_LICENSE\n\tWLog_DBG(TAG, \"Product id:\");\n\twinpr_HexDump(TAG, WLOG_DEBUG, Stream_Pointer(licenseStream), cbProductId);\n#endif\n\tStream_Seek(licenseStream, cbProductId);\n\n\t/* licenseInfo */\n\tStream_Read_UINT32(licenseStream, cbLicenseInfo);\n\tif (Stream_GetRemainingLength(licenseStream) < cbLicenseInfo)\n\t\tgoto out_free_stream;\n\n\tlicense->state = LICENSE_STATE_COMPLETED;\n\n\tret = TRUE;\n\tif (!license->rdp->settings->OldLicenseBehaviour)\n\t\tret = saveCal(license->rdp->settings, Stream_Pointer(licenseStream), cbLicenseInfo,\n\t\t              license->rdp->settings->ClientHostname);\n\nout_free_stream:\n\tStream_Free(licenseStream, FALSE);\nout_free_blob:\n\tlicense_free_binary_blob(calBlob);\n\treturn ret;\n}", "func_src_after": "BOOL license_read_new_or_upgrade_license_packet(rdpLicense* license, wStream* s)\n{\n\tUINT32 os_major;\n\tUINT32 os_minor;\n\tUINT32 cbScope, cbCompanyName, cbProductId, cbLicenseInfo;\n\twStream* licenseStream = NULL;\n\tBOOL ret = FALSE;\n\tBYTE computedMac[16];\n\tLICENSE_BLOB* calBlob;\n\n\tDEBUG_LICENSE(\"Receiving Server New/Upgrade License Packet\");\n\n\tcalBlob = license_new_binary_blob(BB_DATA_BLOB);\n\tif (!calBlob)\n\t\treturn FALSE;\n\n\t/* EncryptedLicenseInfo */\n\tif (!license_read_encrypted_blob(license, s, calBlob))\n\t\tgoto out_free_blob;\n\n\t/* compute MAC and check it */\n\tif (Stream_GetRemainingLength(s) < 16)\n\t\tgoto out_free_blob;\n\n\tif (!security_mac_data(license->MacSaltKey, calBlob->data, calBlob->length, computedMac))\n\t\tgoto out_free_blob;\n\n\tif (memcmp(computedMac, Stream_Pointer(s), sizeof(computedMac)) != 0)\n\t{\n\t\tWLog_ERR(TAG, \"new or upgrade license MAC mismatch\");\n\t\tgoto out_free_blob;\n\t}\n\n\tif (!Stream_SafeSeek(s, 16))\n\t\tgoto out_free_blob;\n\n\tlicenseStream = Stream_New(calBlob->data, calBlob->length);\n\tif (!licenseStream)\n\t\tgoto out_free_blob;\n\n\tif (Stream_GetRemainingLength(licenseStream) < 8)\n\t\tgoto out_free_stream;\n\n\tStream_Read_UINT16(licenseStream, os_minor);\n\tStream_Read_UINT16(licenseStream, os_major);\n\n\t/* Scope */\n\tStream_Read_UINT32(licenseStream, cbScope);\n\tif (Stream_GetRemainingLength(licenseStream) < cbScope)\n\t\tgoto out_free_stream;\n#ifdef WITH_DEBUG_LICENSE\n\tWLog_DBG(TAG, \"Scope:\");\n\twinpr_HexDump(TAG, WLOG_DEBUG, Stream_Pointer(licenseStream), cbScope);\n#endif\n\tStream_Seek(licenseStream, cbScope);\n\n\t/* CompanyName */\n\tif (Stream_GetRemainingLength(licenseStream) < 4)\n\t\tgoto out_free_stream;\n\tStream_Read_UINT32(licenseStream, cbCompanyName);\n\tif (Stream_GetRemainingLength(licenseStream) < cbCompanyName)\n\t\tgoto out_free_stream;\n#ifdef WITH_DEBUG_LICENSE\n\tWLog_DBG(TAG, \"Company name:\");\n\twinpr_HexDump(TAG, WLOG_DEBUG, Stream_Pointer(licenseStream), cbCompanyName);\n#endif\n\tStream_Seek(licenseStream, cbCompanyName);\n\n\t/* productId */\n\tif (Stream_GetRemainingLength(licenseStream) < 4)\n\t\tgoto out_free_stream;\n\tStream_Read_UINT32(licenseStream, cbProductId);\n\tif (Stream_GetRemainingLength(licenseStream) < cbProductId)\n\t\tgoto out_free_stream;\n#ifdef WITH_DEBUG_LICENSE\n\tWLog_DBG(TAG, \"Product id:\");\n\twinpr_HexDump(TAG, WLOG_DEBUG, Stream_Pointer(licenseStream), cbProductId);\n#endif\n\tStream_Seek(licenseStream, cbProductId);\n\n\t/* licenseInfo */\n\tif (Stream_GetRemainingLength(licenseStream) < 4)\n\t\tgoto out_free_stream;\n\tStream_Read_UINT32(licenseStream, cbLicenseInfo);\n\tif (Stream_GetRemainingLength(licenseStream) < cbLicenseInfo)\n\t\tgoto out_free_stream;\n\n\tlicense->state = LICENSE_STATE_COMPLETED;\n\n\tret = TRUE;\n\tif (!license->rdp->settings->OldLicenseBehaviour)\n\t\tret = saveCal(license->rdp->settings, Stream_Pointer(licenseStream), cbLicenseInfo,\n\t\t              license->rdp->settings->ClientHostname);\n\nout_free_stream:\n\tStream_Free(licenseStream, FALSE);\nout_free_blob:\n\tlicense_free_binary_blob(calBlob);\n\treturn ret;\n}", "commit_link": "github.com/FreeRDP/FreeRDP/commit/6ade7b4cbfd71c54b3d724e8f2d6ac76a58e879a", "file_name": "libfreerdp/core/license.c", "vul_type": "cwe-125", "description": "In C, write a function to process a new or upgraded license packet for Remote Desktop Protocol (RDP) licensing."}
{"func_name": "JarFileUtils::testngXmlExistsInJar", "func_src_before": "  private boolean testngXmlExistsInJar(File jarFile, List<String> classes) throws IOException {\n    try (JarFile jf = new JarFile(jarFile)) {\n      Enumeration<JarEntry> entries = jf.entries();\n      File file = java.nio.file.Files.createTempDirectory(\"testngXmlPathInJar-\").toFile();\n      String suitePath = null;\n      while (entries.hasMoreElements()) {\n        JarEntry je = entries.nextElement();\n        String jeName = je.getName();\n        if (Parser.canParse(jeName.toLowerCase())) {\n          InputStream inputStream = jf.getInputStream(je);\n          File copyFile = new File(file, jeName);\n          copyFile.getParentFile().mkdirs();\n          Files.copy(inputStream, copyFile.toPath());\n          if (matchesXmlPathInJar(je)) {\n            suitePath = copyFile.toString();\n          }\n        } else if (isJavaClass(je)) {\n          classes.add(constructClassName(je));\n        }\n      }\n      if (Strings.isNullOrEmpty(suitePath)) {\n        return false;\n      }\n      Collection<XmlSuite> parsedSuites = Parser.parse(suitePath, processor);\n      delete(file);\n      for (XmlSuite suite : parsedSuites) {\n        // If test names were specified, only run these test names\n        if (testNames != null) {\n          TestNamesMatcher testNamesMatcher = new TestNamesMatcher(suite, testNames);\n          testNamesMatcher.validateMissMatchedTestNames();\n          suites.addAll(testNamesMatcher.getSuitesMatchingTestNames());\n        } else {\n          suites.add(suite);\n        }\n        return true;\n      }\n    }\n    return false;\n  }", "func_src_after": "  private boolean testngXmlExistsInJar(File jarFile, List<String> classes) throws IOException {\n    try (JarFile jf = new JarFile(jarFile)) {\n      Enumeration<JarEntry> entries = jf.entries();\n      File file = java.nio.file.Files.createTempDirectory(\"testngXmlPathInJar-\").toFile();\n      String suitePath = null;\n      while (entries.hasMoreElements()) {\n        JarEntry je = entries.nextElement();\n        String jeName = je.getName();\n        if (Parser.canParse(jeName.toLowerCase())) {\n          InputStream inputStream = jf.getInputStream(je);\n          File copyFile = new File(file, jeName);\n          if (!copyFile.toPath().normalize().startsWith(file.toPath().normalize())) {\n            throw new IOException(\"Bad zip entry\");\n          }\n          copyFile.getParentFile().mkdirs();\n          Files.copy(inputStream, copyFile.toPath());\n          if (matchesXmlPathInJar(je)) {\n            suitePath = copyFile.toString();\n          }\n        } else if (isJavaClass(je)) {\n          classes.add(constructClassName(je));\n        }\n      }\n      if (Strings.isNullOrEmpty(suitePath)) {\n        return false;\n      }\n      Collection<XmlSuite> parsedSuites = Parser.parse(suitePath, processor);\n      delete(file);\n      for (XmlSuite suite : parsedSuites) {\n        // If test names were specified, only run these test names\n        if (testNames != null) {\n          TestNamesMatcher testNamesMatcher = new TestNamesMatcher(suite, testNames);\n          testNamesMatcher.validateMissMatchedTestNames();\n          suites.addAll(testNamesMatcher.getSuitesMatchingTestNames());\n        } else {\n          suites.add(suite);\n        }\n        return true;\n      }\n    }\n    return false;\n  }", "line_changes": {"deleted": [], "added": [{"line_no": 12, "char_start": 603, "char_end": 689, "line": "          if (!copyFile.toPath().normalize().startsWith(file.toPath().normalize())) {\n"}, {"line_no": 13, "char_start": 689, "char_end": 741, "line": "            throw new IOException(\"Bad zip entry\");\n"}, {"line_no": 14, "char_start": 741, "char_end": 753, "line": "          }\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 603, "char_end": 753, "chars": "          if (!copyFile.toPath().normalize().startsWith(file.toPath().normalize())) {\n            throw new IOException(\"Bad zip entry\");\n          }\n"}]}, "commit_link": "github.com/cbeust/testng/commit/47afa2c8a29e2cf925238af1ad7c76fba282793f", "file_name": "JarFileUtils.java", "vul_type": "cwe-022", "commit_msg": "vuln-fix: Zip Slip Vulnerability\n\n\n\nThis fixes a Zip-Slip vulnerability.\n\nThis change does one of two things. This change either\n\n1. Inserts a guard to protect against Zip Slip.\nOR\n2. Replaces `dir.getCanonicalPath().startsWith(parent.getCanonicalPath())`, which is vulnerable to partial path traversal attacks, with the more secure `dir.getCanonicalFile().toPath().startsWith(parent.getCanonicalFile().toPath())`.\n\nFor number 2, consider `\"/usr/outnot\".startsWith(\"/usr/out\")`.\nThe check is bypassed although `/outnot` is not under the `/out` directory.\nIt's important to understand that the terminating slash may be removed when using various `String` representations of the `File` object.\nFor example, on Linux, `println(new File(\"/var\"))` will print `/var`, but `println(new File(\"/var\", \"/\")` will print `/var/`;\nhowever, `println(new File(\"/var\", \"/\").getCanonicalPath())` will print `/var`.\n\nWeakness: CWE-22: Improper Limitation of a Pathname to a Restricted Directory ('Path Traversal')\nSeverity: High\nCVSSS: 7.4\nDetection: CodeQL (https://codeql.github.com/codeql-query-help/java/java-zipslip/) & OpenRewrite (https://public.moderne.io/recipes/org.openrewrite.java.security.ZipSlip)\n\nReported-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\nSigned-off-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\n\nBug-tracker: https://github.com/JLLeitschuh/security-research/issues/16\n\n\nCo-authored-by: Moderne <team@moderne.io>", "description": "Write a Java function to check if a TestNG XML configuration exists within a JAR file and process it, also handling Java class entries."}
{"func_name": "self.normalize", "func_src_before": "  def self.normalize url\n    url.sub!(/#(?!\\!)[^#]*$/,'')\n    url.sub!('|', '%7C')\n\n    uri = URI.parse(url)\n\n    @@normalizer_for[uri.host].new(uri).normalize\n  end", "func_src_after": "  def self.normalize url\n    url.sub!(/#(?!\\!)[^#]*$/,'')\n    url.gsub!('|', '%7C')\n\n    uri = URI.parse(url)\n\n    @@normalizer_for[uri.host].new(uri).normalize\n  end", "line_changes": {"deleted": [{"line_no": 3, "char_start": 58, "char_end": 83, "line": "    url.sub!('|', '%7C')\n"}], "added": [{"line_no": 3, "char_start": 58, "char_end": 84, "line": "    url.gsub!('|', '%7C')\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 66, "char_end": 67, "chars": "g"}]}, "commit_link": "github.com/Factlink/url_normalizer/commit/1aae2f1401804eeb040557f64cbd667073dbd6ea", "file_name": "url_normalizer.rb", "vul_type": "cwe-116", "commit_msg": "gsub pipes instead of subs", "parent_commit": "c1d97fec40d37d6225fdb88f2fb109669832db82", "description": "Create a Ruby method to normalize URLs by removing fragments and encoding specific characters."}
{"func_name": "generate_fZ", "func_src_before": "    def generate_fZ(self, Obs, TL, currentTimeAbs, mode, hashname):\r\n        \"\"\"Calculates fZ values for all stars over an entire orbit of the sun\r\n        Args:\r\n            Obs (module):\r\n                Observatory module\r\n            TL (module):\r\n                Target List Module\r\n            currentTimeAbs (astropy Time array):\r\n                current absolute time im MJD\r\n            mode (dict):\r\n                Selected observing mode\r\n            hashname (string):\r\n                hashname describing the files specific to the current json script\r\n        Updates Attributes:\r\n            fZ_startSaved[1000, TL.nStars] (astropy Quantity array):\r\n                Surface brightness of zodiacal light in units of 1/arcsec2 for each star over 1 year at discrete points defined by resolution\r\n        \"\"\"\r\n        #Generate cache Name########################################################################\r\n        cachefname = hashname+'starkfZ'\r\n\r\n        #Check if file exists#######################################################################\r\n        if os.path.isfile(cachefname):#check if file exists\r\n            self.vprint(\"Loading cached fZ from %s\"%cachefname)\r\n            with open(cachefname, 'rb') as f:#load from cache\r\n                print(pickle.load(f))\r\n                tmpfZ = pickle.load(f)\r\n                try:\r\n                    f.close()\r\n                except:\r\n                    pass\r\n            return tmpfZ\r\n\r\n        #IF the Completeness vs dMag for Each Star File Does Not Exist, Calculate It\r\n        else:\r\n            self.vprint(\"Calculating fZ\")\r\n            #OS = self.OpticalSystem#Testing to be sure I can remove this\r\n            #WA = OS.WA0#Testing to be sure I can remove this\r\n            sInds= np.arange(TL.nStars)\r\n            startTime = np.zeros(sInds.shape[0])*u.d + currentTimeAbs#Array of current times\r\n            resolution = [j for j in range(1000)]\r\n            fZ = np.zeros([sInds.shape[0], len(resolution)])\r\n            dt = 365.25/len(resolution)*u.d\r\n            for i in xrange(len(resolution)):#iterate through all times of year\r\n                time = startTime + dt*resolution[i]\r\n                fZ[:,i] = self.fZ(Obs, TL, sInds, time, mode)\r\n            \r\n            with open(cachefname, \"wb\") as fo:\r\n                wr = csv.writer(fo, quoting=csv.QUOTE_ALL)\r\n                pickle.dump(fZ,fo)\r\n                self.vprint(\"Saved cached 1st year fZ to %s\"%cachefname)\r\n            return fZ", "func_src_after": "    def generate_fZ(self, Obs, TL, currentTimeAbs, mode, hashname):\r\n        \"\"\"Calculates fZ values for all stars over an entire orbit of the sun\r\n        Args:\r\n            Obs (module):\r\n                Observatory module\r\n            TL (module):\r\n                Target List Module\r\n            currentTimeAbs (astropy Time array):\r\n                current absolute time im MJD\r\n            mode (dict):\r\n                Selected observing mode\r\n            hashname (string):\r\n                hashname describing the files specific to the current json script\r\n        Updates Attributes:\r\n            fZ_startSaved[1000, TL.nStars] (astropy Quantity array):\r\n                Surface brightness of zodiacal light in units of 1/arcsec2 for each star over 1 year at discrete points defined by resolution\r\n        \"\"\"\r\n        #Generate cache Name########################################################################\r\n        cachefname = hashname+'starkfZ'\r\n\r\n        #Check if file exists#######################################################################\r\n        if os.path.isfile(cachefname):#check if file exists\r\n            self.vprint(\"Loading cached fZ from %s\"%cachefname)\r\n            with open(cachefname, 'rb') as f:#load from cache\r\n                tmpfZ = pickle.load(f)\r\n            return tmpfZ\r\n\r\n        #IF the Completeness vs dMag for Each Star File Does Not Exist, Calculate It\r\n        else:\r\n            self.vprint(\"Calculating fZ\")\r\n            #OS = self.OpticalSystem#Testing to be sure I can remove this\r\n            #WA = OS.WA0#Testing to be sure I can remove this\r\n            sInds= np.arange(TL.nStars)\r\n            startTime = np.zeros(sInds.shape[0])*u.d + currentTimeAbs#Array of current times\r\n            resolution = [j for j in range(1000)]\r\n            fZ = np.zeros([sInds.shape[0], len(resolution)])\r\n            dt = 365.25/len(resolution)*u.d\r\n            for i in xrange(len(resolution)):#iterate through all times of year\r\n                time = startTime + dt*resolution[i]\r\n                fZ[:,i] = self.fZ(Obs, TL, sInds, time, mode)\r\n            \r\n            with open(cachefname, \"wb\") as fo:\r\n                pickle.dump(fZ,fo)\r\n                self.vprint(\"Saved cached 1st year fZ to %s\"%cachefname)\r\n            return fZ", "line_changes": {"deleted": [{"line_no": 25, "char_start": 1257, "char_end": 1296, "line": "                print(pickle.load(f))\r\n"}, {"line_no": 27, "char_start": 1336, "char_end": 1358, "line": "                try:\r\n"}, {"line_no": 28, "char_start": 1358, "char_end": 1389, "line": "                    f.close()\r\n"}, {"line_no": 29, "char_start": 1389, "char_end": 1414, "line": "                except:\r\n"}, {"line_no": 30, "char_start": 1414, "char_end": 1440, "line": "                    pass\r\n"}, {"line_no": 48, "char_start": 2302, "char_end": 2362, "line": "                wr = csv.writer(fo, quoting=csv.QUOTE_ALL)\r\n"}], "added": []}, "char_changes": {"deleted": [{"char_start": 1273, "char_end": 1438, "chars": "print(pickle.load(f))\r\n                tmpfZ = pickle.load(f)\r\n                try:\r\n                    f.close()\r\n                except:\r\n                    pass"}, {"char_start": 2302, "char_end": 2362, "chars": "                wr = csv.writer(fo, quoting=csv.QUOTE_ALL)\r\n"}], "added": [{"char_start": 1273, "char_end": 1295, "chars": "tmpfZ = pickle.load(f)"}]}, "commit_link": "github.com/dsavransky/EXOSIMS/commit/2df12d23c54a140161c24e92b3c03aaf522c61ec", "file_name": "ZodiacalLight.py", "vul_type": "cwe-502", "commit_msg": "fixed pickle load errors", "parent_commit": "c4660a0de665797559fd4d048b4d971661366f50", "description": "In Python, write a function to calculate and cache surface brightness values for stars, loading from cache if available."}
{"func_name": "keycompare_mb", "func_src_before": "keycompare_mb (const struct line *a, const struct line *b)\n{\n  struct keyfield *key = keylist;\n\n  /* For the first iteration only, the key positions have been\n     precomputed for us. */\n  char *texta = a->keybeg;\n  char *textb = b->keybeg;\n  char *lima = a->keylim;\n  char *limb = b->keylim;\n\n  size_t mblength_a, mblength_b;\n  wchar_t wc_a, wc_b;\n  mbstate_t state_a, state_b;\n\n  int diff = 0;\n\n  memset (&state_a, '\\0', sizeof(mbstate_t));\n  memset (&state_b, '\\0', sizeof(mbstate_t));\n  /* Ignore keys with start after end.  */\n  if (a->keybeg - a->keylim > 0)\n    return 0;\n\n\n              /* Ignore and/or translate chars before comparing.  */\n# define IGNORE_CHARS(NEW_LEN, LEN, TEXT, COPY, WC, MBLENGTH, STATE)        \\\n  do                                                                        \\\n    {                                                                        \\\n      wchar_t uwc;                                                        \\\n      char mbc[MB_LEN_MAX];                                                \\\n      mbstate_t state_wc;                                                \\\n                                                                        \\\n      for (NEW_LEN = i = 0; i < LEN;)                                        \\\n        {                                                                \\\n          mbstate_t state_bak;                                                \\\n                                                                        \\\n          state_bak = STATE;                                                \\\n          MBLENGTH = mbrtowc (&WC, TEXT + i, LEN - i, &STATE);                \\\n                                                                        \\\n          if (MBLENGTH == (size_t)-2 || MBLENGTH == (size_t)-1                \\\n              || MBLENGTH == 0)                                                \\\n            {                                                                \\\n              if (MBLENGTH == (size_t)-2 || MBLENGTH == (size_t)-1)        \\\n                STATE = state_bak;                                        \\\n              if (!ignore)                                                \\\n                COPY[NEW_LEN++] = TEXT[i];                                \\\n              i++;                                                         \\\n              continue;                                                        \\\n            }                                                                \\\n                                                                        \\\n          if (ignore)                                                        \\\n            {                                                                \\\n              if ((ignore == nonprinting && !iswprint (WC))                \\\n                   || (ignore == nondictionary                                \\\n                       && !iswalnum (WC) && !iswblank (WC)))                \\\n                {                                                        \\\n                  i += MBLENGTH;                                        \\\n                  continue;                                                \\\n                }                                                        \\\n            }                                                                \\\n                                                                        \\\n          if (translate)                                                \\\n            {                                                                \\\n                                                                        \\\n              uwc = towupper(WC);                                        \\\n              if (WC == uwc)                                                \\\n                {                                                        \\\n                  memcpy (mbc, TEXT + i, MBLENGTH);                        \\\n                  i += MBLENGTH;                                        \\\n                }                                                        \\\n              else                                                        \\\n                {                                                        \\\n                  i += MBLENGTH;                                        \\\n                  WC = uwc;                                                \\\n                  memset (&state_wc, '\\0', sizeof (mbstate_t));                \\\n                                                                        \\\n                  MBLENGTH = wcrtomb (mbc, WC, &state_wc);                \\\n                  assert (MBLENGTH != (size_t)-1 && MBLENGTH != 0);        \\\n                }                                                        \\\n                                                                        \\\n              for (j = 0; j < MBLENGTH; j++)                                \\\n                COPY[NEW_LEN++] = mbc[j];                                \\\n            }                                                                \\\n          else                                                                \\\n            for (j = 0; j < MBLENGTH; j++)                                \\\n              COPY[NEW_LEN++] = TEXT[i++];                                \\\n        }                                                                \\\n      COPY[NEW_LEN] = '\\0';                                                \\\n    }                                                                        \\\n  while (0)\n\n      /* Actually compare the fields. */\n\n  for (;;)\n    {\n      /* Find the lengths. */\n      size_t lena = lima <= texta ? 0 : lima - texta;\n      size_t lenb = limb <= textb ? 0 : limb - textb;\n\n      char enda IF_LINT (= 0);\n      char endb IF_LINT (= 0);\n\n      char const *translate = key->translate;\n      bool const *ignore = key->ignore;\n\n      if (ignore || translate)\n        {\n          char *copy_a = (char *) xmalloc (lena + 1 + lenb + 1);\n          char *copy_b = copy_a + lena + 1;\n          size_t new_len_a, new_len_b;\n          size_t i, j;\n\n          IGNORE_CHARS (new_len_a, lena, texta, copy_a,\n                        wc_a, mblength_a, state_a);\n          IGNORE_CHARS (new_len_b, lenb, textb, copy_b,\n                        wc_b, mblength_b, state_b);\n          texta = copy_a; textb = copy_b;\n          lena = new_len_a; lenb = new_len_b;\n        }\n      else\n        {\n          /* Use the keys in-place, temporarily null-terminated.  */\n          enda = texta[lena]; texta[lena] = '\\0';\n          endb = textb[lenb]; textb[lenb] = '\\0';\n        }\n\n      if (key->random)\n        diff = compare_random (texta, lena, textb, lenb);\n      else if (key->numeric | key->general_numeric | key->human_numeric)\n        {\n          char savea = *lima, saveb = *limb;\n\n          *lima = *limb = '\\0';\n          diff = (key->numeric ? numcompare (texta, textb)\n                  : key->general_numeric ? general_numcompare (texta, textb)\n                  : human_numcompare (texta, textb));\n          *lima = savea, *limb = saveb;\n        }\n      else if (key->version)\n        diff = filevercmp (texta, textb);\n      else if (key->month)\n        diff = getmonth (texta, lena, NULL) - getmonth (textb, lenb, NULL);\n      else if (lena == 0)\n        diff = - NONZERO (lenb);\n      else if (lenb == 0)\n        diff = 1;\n      else if (hard_LC_COLLATE && !folding)\n        {\n          diff = xmemcoll0 (texta, lena + 1, textb, lenb + 1);\n        }\n      else\n        {\n          diff = memcmp (texta, textb, MIN (lena, lenb));\n          if (diff == 0)\n            diff = lena < lenb ? -1 : lena != lenb;\n        }\n\n      if (ignore || translate)\n        free (texta);\n      else\n        {\n          texta[lena] = enda;\n          textb[lenb] = endb;\n        }\n\n      if (diff)\n        goto not_equal;\n\n      key = key->next;\n      if (! key)\n        break;\n\n      /* Find the beginning and limit of the next field.  */\n      if (key->eword != -1)\n        lima = limfield (a, key), limb = limfield (b, key);\n      else\n        lima = a->text + a->length - 1, limb = b->text + b->length - 1;\n\n      if (key->sword != -1)\n        texta = begfield (a, key), textb = begfield (b, key);\n      else\n        {\n          texta = a->text, textb = b->text;\n          if (key->skipsblanks)\n            {\n              while (texta < lima && ismbblank (texta, lima - texta, &mblength_a))\n                texta += mblength_a;\n              while (textb < limb && ismbblank (textb, limb - textb, &mblength_b))\n                textb += mblength_b;\n            }\n        }\n    }\n\nnot_equal:\n  if (key && key->reverse)\n    return -diff;\n  else\n    return diff;\n}", "func_src_after": "keycompare_mb (const struct line *a, const struct line *b)\n{\n  struct keyfield *key = keylist;\n\n  /* For the first iteration only, the key positions have been\n     precomputed for us. */\n  char *texta = a->keybeg;\n  char *textb = b->keybeg;\n  char *lima = a->keylim;\n  char *limb = b->keylim;\n\n  size_t mblength_a, mblength_b;\n  wchar_t wc_a, wc_b;\n  mbstate_t state_a, state_b;\n\n  int diff = 0;\n\n  memset (&state_a, '\\0', sizeof(mbstate_t));\n  memset (&state_b, '\\0', sizeof(mbstate_t));\n  /* Ignore keys with start after end.  */\n  if (a->keybeg - a->keylim > 0)\n    return 0;\n\n\n              /* Ignore and/or translate chars before comparing.  */\n# define IGNORE_CHARS(NEW_LEN, LEN, TEXT, COPY, WC, MBLENGTH, STATE)        \\\n  do                                                                        \\\n    {                                                                        \\\n      wchar_t uwc;                                                        \\\n      char mbc[MB_LEN_MAX];                                                \\\n      mbstate_t state_wc;                                                \\\n                                                                        \\\n      for (NEW_LEN = i = 0; i < LEN;)                                        \\\n        {                                                                \\\n          mbstate_t state_bak;                                                \\\n                                                                        \\\n          state_bak = STATE;                                                \\\n          MBLENGTH = mbrtowc (&WC, TEXT + i, LEN - i, &STATE);                \\\n                                                                        \\\n          if (MBLENGTH == (size_t)-2 || MBLENGTH == (size_t)-1                \\\n              || MBLENGTH == 0)                                                \\\n            {                                                                \\\n              if (MBLENGTH == (size_t)-2 || MBLENGTH == (size_t)-1)        \\\n                STATE = state_bak;                                        \\\n              if (!ignore)                                                \\\n                COPY[NEW_LEN++] = TEXT[i];                                \\\n              i++;                                                         \\\n              continue;                                                        \\\n            }                                                                \\\n                                                                        \\\n          if (ignore)                                                        \\\n            {                                                                \\\n              if ((ignore == nonprinting && !iswprint (WC))                \\\n                   || (ignore == nondictionary                                \\\n                       && !iswalnum (WC) && !iswblank (WC)))                \\\n                {                                                        \\\n                  i += MBLENGTH;                                        \\\n                  continue;                                                \\\n                }                                                        \\\n            }                                                                \\\n                                                                        \\\n          if (translate)                                                \\\n            {                                                                \\\n                                                                        \\\n              uwc = towupper(WC);                                        \\\n              if (WC == uwc)                                                \\\n                {                                                        \\\n                  memcpy (mbc, TEXT + i, MBLENGTH);                        \\\n                  i += MBLENGTH;                                        \\\n                }                                                        \\\n              else                                                        \\\n                {                                                        \\\n                  i += MBLENGTH;                                        \\\n                  WC = uwc;                                                \\\n                  memset (&state_wc, '\\0', sizeof (mbstate_t));                \\\n                                                                        \\\n                  MBLENGTH = wcrtomb (mbc, WC, &state_wc);                \\\n                  assert (MBLENGTH != (size_t)-1 && MBLENGTH != 0);        \\\n                }                                                        \\\n                                                                        \\\n              for (j = 0; j < MBLENGTH; j++)                                \\\n                COPY[NEW_LEN++] = mbc[j];                                \\\n            }                                                                \\\n          else                                                                \\\n            for (j = 0; j < MBLENGTH; j++)                                \\\n              COPY[NEW_LEN++] = TEXT[i++];                                \\\n        }                                                                \\\n      COPY[NEW_LEN] = '\\0';                                                \\\n    }                                                                        \\\n  while (0)\n\n      /* Actually compare the fields. */\n\n  for (;;)\n    {\n      /* Find the lengths. */\n      size_t lena = lima <= texta ? 0 : lima - texta;\n      size_t lenb = limb <= textb ? 0 : limb - textb;\n\n      char enda IF_LINT (= 0);\n      char endb IF_LINT (= 0);\n\n      char const *translate = key->translate;\n      bool const *ignore = key->ignore;\n\n      if (ignore || translate)\n        {\n          if (SIZE_MAX - lenb - 2 < lena)\n            xalloc_die ();\n          char *copy_a = (char *) xnmalloc (lena + lenb + 2, MB_CUR_MAX);\n          char *copy_b = copy_a + lena * MB_CUR_MAX + 1;\n          size_t new_len_a, new_len_b;\n          size_t i, j;\n\n          IGNORE_CHARS (new_len_a, lena, texta, copy_a,\n                        wc_a, mblength_a, state_a);\n          IGNORE_CHARS (new_len_b, lenb, textb, copy_b,\n                        wc_b, mblength_b, state_b);\n          texta = copy_a; textb = copy_b;\n          lena = new_len_a; lenb = new_len_b;\n        }\n      else\n        {\n          /* Use the keys in-place, temporarily null-terminated.  */\n          enda = texta[lena]; texta[lena] = '\\0';\n          endb = textb[lenb]; textb[lenb] = '\\0';\n        }\n\n      if (key->random)\n        diff = compare_random (texta, lena, textb, lenb);\n      else if (key->numeric | key->general_numeric | key->human_numeric)\n        {\n          char savea = *lima, saveb = *limb;\n\n          *lima = *limb = '\\0';\n          diff = (key->numeric ? numcompare (texta, textb)\n                  : key->general_numeric ? general_numcompare (texta, textb)\n                  : human_numcompare (texta, textb));\n          *lima = savea, *limb = saveb;\n        }\n      else if (key->version)\n        diff = filevercmp (texta, textb);\n      else if (key->month)\n        diff = getmonth (texta, lena, NULL) - getmonth (textb, lenb, NULL);\n      else if (lena == 0)\n        diff = - NONZERO (lenb);\n      else if (lenb == 0)\n        diff = 1;\n      else if (hard_LC_COLLATE && !folding)\n        {\n          diff = xmemcoll0 (texta, lena + 1, textb, lenb + 1);\n        }\n      else\n        {\n          diff = memcmp (texta, textb, MIN (lena, lenb));\n          if (diff == 0)\n            diff = lena < lenb ? -1 : lena != lenb;\n        }\n\n      if (ignore || translate)\n        free (texta);\n      else\n        {\n          texta[lena] = enda;\n          textb[lenb] = endb;\n        }\n\n      if (diff)\n        goto not_equal;\n\n      key = key->next;\n      if (! key)\n        break;\n\n      /* Find the beginning and limit of the next field.  */\n      if (key->eword != -1)\n        lima = limfield (a, key), limb = limfield (b, key);\n      else\n        lima = a->text + a->length - 1, limb = b->text + b->length - 1;\n\n      if (key->sword != -1)\n        texta = begfield (a, key), textb = begfield (b, key);\n      else\n        {\n          texta = a->text, textb = b->text;\n          if (key->skipsblanks)\n            {\n              while (texta < lima && ismbblank (texta, lima - texta, &mblength_a))\n                texta += mblength_a;\n              while (textb < limb && ismbblank (textb, limb - textb, &mblength_b))\n                textb += mblength_b;\n            }\n        }\n    }\n\nnot_equal:\n  if (key && key->reverse)\n    return -diff;\n  else\n    return diff;\n}", "commit_link": "github.com/pixelb/coreutils/commit/bea5e36cc876ed627bb5e0eca36fdfaa6465e940", "file_name": "src/sort.c", "vul_type": "cwe-787", "description": "Write a C function named `keycompare_mb` that compares two lines based on predefined key positions, handling multibyte characters and various comparison options."}
{"func_name": "(anonymous)", "func_src_before": "        .then(()=>tileRec(inPath, outPath, zoom, tileSize, tempDir, pattern, zoomToDisplay, options.invertZoom, quality))", "func_src_after": "        .then(() => tileRec(inPath, outPath, zoom, tileSize, tempDir, pattern, zoomToDisplay, options.invertZoom, quality))", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 121, "line": "        .then(()=>tileRec(inPath, outPath, zoom, tileSize, tempDir, pattern, zoomToDisplay, options.invertZoom, quality))\n"}], "added": []}, "char_changes": {"deleted": [], "added": [{"char_start": 16, "char_end": 17, "chars": " "}, {"char_start": 19, "char_end": 20, "chars": " "}]}, "commit_link": "github.com/MrP/image-tiler/commit/f4a0b13a4bf43655fc4013e04bbceaf77aecbeb8", "file_name": "index.js", "vul_type": "cwe-078", "commit_msg": "fix command injection vuln", "description": "Write a JavaScript function that processes images into tiles with customizable options."}
{"func_name": "dumprecord", "func_src_before": "func dumprecord(w http.ResponseWriter, r *http.Request, parray []string) {\n\n\tdatabase := parray[0]\n\ttable := parray[1]\n\trec, err := strconv.Atoi(parray[2])\n\tcheckY(err)\n\n\tuser, pw := getCredentials(r)\n\tconn, err := sql.Open(\"mysql\", dsn(user, pw, database))\n\tcheckY(err)\n\tdefer conn.Close()\n\n\tstatement, err := conn.Prepare(\"select * from \" + table)\n\tcheckY(err)\n\n\trows, err := statement.Query()\n\tcheckY(err)\n\tdefer rows.Close()\n\n\tcolumns, err := rows.Columns()\n\tcheckY(err)\n\n\traw := make([]interface{}, len(columns))\n\tval := make([]interface{}, len(columns))\n\n\tfor i := range val {\n\t\traw[i] = &val[i]\n\t}\n\n\tvar n int = 1\n\nrowLoop:\n\tfor rows.Next() {\n\n\t\t// unfortunately we have to iterate up to row of interest\n\t\tif n == rec {\n\t\t\terr = rows.Scan(raw...)\n\t\t\tcheckY(err)\n\n\t\t\tfmt.Fprintln(w, \"<p>\")\n\t\t\tfor i, col := range val {\n\t\t\t\tif col != nil {\n\t\t\t\t\tfmt.Fprintln(w, columns[i], \":\", string(col.([]byte)), \"<br>\")\n\t\t\t\t}\n\t\t\t}\n\t\t\tfmt.Fprintln(w, \"</p>\")\n\t\t\tbreak rowLoop\n\t\t}\n\t\tn = n + 1\n\t}\n}", "func_src_after": "func dumprecord(w http.ResponseWriter, r *http.Request, parray []string) {\n\n\tdatabase := parray[0]\n\ttable := parray[1]\n\trec, err := strconv.Atoi(parray[2])\n\tcheckY(err)\n\n\tuser, pw := getCredentials(r)\n\tconn, err := sql.Open(\"mysql\", dsn(user, pw, database))\n\tcheckY(err)\n\tdefer conn.Close()\n\n\tstatement, err := conn.Prepare(\"select * from ?\")\n\tcheckY(err)\n\n\trows, err := statement.Query(table)\n\tcheckY(err)\n\tdefer rows.Close()\n\n\tcolumns, err := rows.Columns()\n\tcheckY(err)\n\n\traw := make([]interface{}, len(columns))\n\tval := make([]interface{}, len(columns))\n\n\tfor i := range val {\n\t\traw[i] = &val[i]\n\t}\n\n\tvar n int = 1\n\nrowLoop:\n\tfor rows.Next() {\n\n\t\t// unfortunately we have to iterate up to row of interest\n\t\tif n == rec {\n\t\t\terr = rows.Scan(raw...)\n\t\t\tcheckY(err)\n\n\t\t\tfmt.Fprintln(w, \"<p>\")\n\t\t\tfor i, col := range val {\n\t\t\t\tif col != nil {\n\t\t\t\t\tfmt.Fprintln(w, columns[i], \":\", string(col.([]byte)), \"<br>\")\n\t\t\t\t}\n\t\t\t}\n\t\t\tfmt.Fprintln(w, \"</p>\")\n\t\t\tbreak rowLoop\n\t\t}\n\t\tn = n + 1\n\t}\n}", "line_changes": {"deleted": [{"line_no": 13, "char_start": 292, "char_end": 350, "line": "\tstatement, err := conn.Prepare(\"select * from \" + table)\n"}, {"line_no": 16, "char_start": 364, "char_end": 396, "line": "\trows, err := statement.Query()\n"}], "added": [{"line_no": 13, "char_start": 292, "char_end": 343, "line": "\tstatement, err := conn.Prepare(\"select * from ?\")\n"}, {"line_no": 16, "char_start": 357, "char_end": 394, "line": "\trows, err := statement.Query(table)\n"}]}, "char_changes": {"deleted": [{"char_start": 340, "char_end": 348, "chars": " + table"}], "added": [{"char_start": 339, "char_end": 340, "chars": "?"}, {"char_start": 387, "char_end": 392, "chars": "table"}]}, "commit_link": "github.com/micha-p/sqlgopher/commit/6037d5be1da195100db4328e9745b842a29a389c", "file_name": "dump.go", "vul_type": "cwe-089", "commit_msg": "Protection against sql injection via composed queries", "parent_commit": "3b4884a57e465df2433dde79a7e7a31c92a15099", "description": "Write a Go function to fetch and display a specific record from a MySQL database table based on parameters from an HTTP request."}
{"func_name": "copyIPv6IfDifferent", "func_src_before": "static void copyIPv6IfDifferent(void * dest, const void * src)\n{\n\tif(dest != src) {\n\t\tmemcpy(dest, src, sizeof(struct in6_addr));\n\t}\n}", "func_src_after": "static void copyIPv6IfDifferent(void * dest, const void * src)\n{\n\tif(dest != src && src != NULL) {\n\t\tmemcpy(dest, src, sizeof(struct in6_addr));\n\t}\n}", "commit_link": "github.com/miniupnp/miniupnp/commit/cb8a02af7a5677cf608e86d57ab04241cf34e24f", "file_name": "miniupnpd/pcpserver.c", "vul_type": "cwe-476", "description": "Write a C function named `copyIPv6IfDifferent` that copies an IPv6 address from source to destination if they are different, with the second version also checking if the source is not NULL."}
{"func_name": "output", "func_src_before": "    def output\n      str = <<-INTERCOM_SCRIPT\n<script id=\"IntercomSettingsScriptTag\">\n  window.intercomSettings = #{ActiveSupport::JSON.encode(intercom_settings)};\n</script>\n<script>(function(){var w=window;var ic=w.Intercom;if(typeof ic===\"function\"){ic('reattach_activator');ic('update',intercomSettings);}else{var d=document;var i=function(){i.c(arguments)};i.q=[];i.c=function(args){i.q.push(args)};w.Intercom=i;function l(){var s=d.createElement('script');s.type='text/javascript';s.async=true;s.src='#{Config.library_url || 'https://api.intercom.io/api/js/library.js'}';var x=d.getElementsByTagName('script')[0];x.parentNode.insertBefore(s,x);}if(w.attachEvent){w.attachEvent('onload',l);}else{w.addEventListener('load',l,false);}};})()</script>\n      INTERCOM_SCRIPT\n\n      str.respond_to?(:html_safe) ? str.html_safe : str\n    end", "func_src_after": "    def output\n      intercom_settings_json = ActiveSupport::JSON.encode(intercom_settings).gsub('<', '\\u003C')\n\n      str = <<-INTERCOM_SCRIPT\n<script id=\"IntercomSettingsScriptTag\">\n  window.intercomSettings = #{intercom_settings_json};\n</script>\n<script>(function(){var w=window;var ic=w.Intercom;if(typeof ic===\"function\"){ic('reattach_activator');ic('update',intercomSettings);}else{var d=document;var i=function(){i.c(arguments)};i.q=[];i.c=function(args){i.q.push(args)};w.Intercom=i;function l(){var s=d.createElement('script');s.type='text/javascript';s.async=true;s.src='#{Config.library_url || 'https://api.intercom.io/api/js/library.js'}';var x=d.getElementsByTagName('script')[0];x.parentNode.insertBefore(s,x);}if(w.attachEvent){w.attachEvent('onload',l);}else{w.addEventListener('load',l,false);}};})()</script>\n      INTERCOM_SCRIPT\n\n      str.respond_to?(:html_safe) ? str.html_safe : str\n    end", "line_changes": {"deleted": [{"line_no": 4, "char_start": 86, "char_end": 164, "line": "  window.intercomSettings = #{ActiveSupport::JSON.encode(intercom_settings)};\n"}], "added": [{"line_no": 2, "char_start": 15, "char_end": 112, "line": "      intercom_settings_json = ActiveSupport::JSON.encode(intercom_settings).gsub('<', '\\u003C')\n"}, {"line_no": 3, "char_start": 112, "char_end": 113, "line": "\n"}, {"line_no": 6, "char_start": 184, "char_end": 239, "line": "  window.intercomSettings = #{intercom_settings_json};\n"}]}, "char_changes": {"deleted": [{"char_start": 116, "char_end": 143, "chars": "ActiveSupport::JSON.encode("}, {"char_start": 160, "char_end": 161, "chars": ")"}], "added": [{"char_start": 15, "char_end": 113, "chars": "      intercom_settings_json = ActiveSupport::JSON.encode(intercom_settings).gsub('<', '\\u003C')\n\n"}, {"char_start": 231, "char_end": 236, "chars": "_json"}]}, "commit_link": "github.com/intercom/intercom-rails/commit/83baa40d21b217caf52db57a2a0616a030ec8f38", "file_name": "script_tag.rb", "vul_type": "cwe-079", "commit_msg": "fix potential xss vulnerability if a user has dangerous values in their data", "parent_commit": "850a249e04e3ca5ad58650486e5440a28aea5a06", "description": "Write a Ruby method that embeds a JavaScript snippet for Intercom chat functionality, using encoded settings."}
{"func_name": "get_error_days", "func_src_before": "def get_error_days(cur, error_percent):\n    \"\"\"Fetches the days in which requests led to errors.\n\n    Fetches the days in which the specified percentage\n    of requests led to errors.\n\n    Args:\n        cur(obj): The cursor to execute the query.\n        error_percent(int): The percentage of requests that led to errors.\n\n    Return:\n        True if success, False otherwise.\n    \"\"\"\n    query = '''SELECT to_char(log_errors.date, 'Mon DD YYYY'),\n            round((log_errors.errors * 100\n            / log_requests.total::numeric), 2) as percent\n            FROM log_errors, log_requests\n            WHERE log_errors.date = log_requests.date AND\n            log_errors.errors * 100\n            / log_requests.total::numeric > {}\n            ORDER BY log_errors.date'''.format(error_percent)\n    rows = get_data(cur, query)\n\n    # Write data to txt file.\n    if rows is not None:\n        file = open(\"error_report.txt\", \"w\")\n        for row in rows:\n            file.write(\"{} - {}% errors \\n\".format(row[0], row[1]))\n        file.close()\n\n        return True\n    else:\n        return False", "func_src_after": "def get_error_days(cur, error_percent):\n    \"\"\"Fetches the days in which requests led to errors.\n\n    Fetches the days in which the specified percentage\n    of requests led to errors.\n\n    Args:\n        cur(obj): The cursor to execute the query.\n        error_percent(int): The percentage of requests that led to errors.\n\n    Return:\n        True if success, False otherwise.\n    \"\"\"\n    data = (error_percent, )\n    query = '''SELECT to_char(log_errors.date, 'Mon DD YYYY'),\n            round((log_errors.errors * 100\n            / log_requests.total::numeric), 2) as percent\n            FROM log_errors, log_requests\n            WHERE log_errors.date = log_requests.date AND\n            log_errors.errors * 100\n            / log_requests.total::numeric > %s\n            ORDER BY log_errors.date'''\n    rows = get_data(cur, query, data)\n\n    # Write data to txt file.\n    if rows is not None:\n        file = open(\"error_report.txt\", \"w\")\n        for row in rows:\n            file.write(\"{} - {}% errors \\n\".format(row[0], row[1]))\n        file.close()\n\n        return True\n    else:\n        return False", "commit_link": "github.com/rrbiz662/log-analysis/commit/20fefbde3738088586a3c5679f743493d0a504f6", "file_name": "news_data_analysis.py", "vul_type": "cwe-089", "description": "Write a Python function to query a database for days with error rates above a threshold and save the results to a text file."}
{"func_name": "run", "func_src_before": "static int run(const CommandLineOptions& options)\n{\n\tIR::Module irModule;\n\n\t// Load the module.\n\tif(!loadModule(options.filename, irModule)) { return EXIT_FAILURE; }\n\tif(options.onlyCheck) { return EXIT_SUCCESS; }\n\n\t// Compile the module.\n\tRuntime::Module* module = nullptr;\n\tif(!options.precompiled) { module = Runtime::compileModule(irModule); }\n\telse\n\t{\n\t\tconst UserSection* precompiledObjectSection = nullptr;\n\t\tfor(const UserSection& userSection : irModule.userSections)\n\t\t{\n\t\t\tif(userSection.name == \"wavm.precompiled_object\")\n\t\t\t{\n\t\t\t\tprecompiledObjectSection = &userSection;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif(!precompiledObjectSection)\n\t\t{\n\t\t\tLog::printf(Log::error, \"Input file did not contain 'wavm.precompiled_object' section\");\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tmodule = Runtime::loadPrecompiledModule(irModule, precompiledObjectSection->data);\n\t\t}\n\t}\n\n\t// Link the module with the intrinsic modules.\n\tCompartment* compartment = Runtime::createCompartment();\n\tContext* context = Runtime::createContext(compartment);\n\tRootResolver rootResolver(compartment);\n\n\tEmscripten::Instance* emscriptenInstance = nullptr;\n\tif(options.enableEmscripten)\n\t{\n\t\temscriptenInstance = Emscripten::instantiate(compartment, irModule);\n\t\tif(emscriptenInstance)\n\t\t{\n\t\t\trootResolver.moduleNameToInstanceMap.set(\"env\", emscriptenInstance->env);\n\t\t\trootResolver.moduleNameToInstanceMap.set(\"asm2wasm\", emscriptenInstance->asm2wasm);\n\t\t\trootResolver.moduleNameToInstanceMap.set(\"global\", emscriptenInstance->global);\n\t\t}\n\t}\n\n\tif(options.enableThreadTest)\n\t{\n\t\tModuleInstance* threadTestInstance = ThreadTest::instantiate(compartment);\n\t\trootResolver.moduleNameToInstanceMap.set(\"threadTest\", threadTestInstance);\n\t}\n\n\tLinkResult linkResult = linkModule(irModule, rootResolver);\n\tif(!linkResult.success)\n\t{\n\t\tLog::printf(Log::error, \"Failed to link module:\\n\");\n\t\tfor(auto& missingImport : linkResult.missingImports)\n\t\t{\n\t\t\tLog::printf(Log::error,\n\t\t\t\t\t\t\"Missing import: module=\\\"%s\\\" export=\\\"%s\\\" type=\\\"%s\\\"\\n\",\n\t\t\t\t\t\tmissingImport.moduleName.c_str(),\n\t\t\t\t\t\tmissingImport.exportName.c_str(),\n\t\t\t\t\t\tasString(missingImport.type).c_str());\n\t\t}\n\t\treturn EXIT_FAILURE;\n\t}\n\n\t// Instantiate the module.\n\tModuleInstance* moduleInstance = instantiateModule(\n\t\tcompartment, module, std::move(linkResult.resolvedImports), options.filename);\n\tif(!moduleInstance) { return EXIT_FAILURE; }\n\n\t// Call the module start function, if it has one.\n\tFunctionInstance* startFunction = getStartFunction(moduleInstance);\n\tif(startFunction) { invokeFunctionChecked(context, startFunction, {}); }\n\n\tif(options.enableEmscripten)\n\t{\n\t\t// Call the Emscripten global initalizers.\n\t\tEmscripten::initializeGlobals(context, irModule, moduleInstance);\n\t}\n\n\t// Look up the function export to call.\n\tFunctionInstance* functionInstance;\n\tif(!options.functionName)\n\t{\n\t\tfunctionInstance = asFunctionNullable(getInstanceExport(moduleInstance, \"main\"));\n\t\tif(!functionInstance)\n\t\t{ functionInstance = asFunctionNullable(getInstanceExport(moduleInstance, \"_main\")); }\n\t\tif(!functionInstance)\n\t\t{\n\t\t\tLog::printf(Log::error, \"Module does not export main function\\n\");\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t}\n\telse\n\t{\n\t\tfunctionInstance\n\t\t\t= asFunctionNullable(getInstanceExport(moduleInstance, options.functionName));\n\t\tif(!functionInstance)\n\t\t{\n\t\t\tLog::printf(Log::error, \"Module does not export '%s'\\n\", options.functionName);\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t}\n\tFunctionType functionType = getFunctionType(functionInstance);\n\n\t// Set up the arguments for the invoke.\n\tstd::vector<Value> invokeArgs;\n\tif(!options.functionName)\n\t{\n\t\tif(functionType.params().size() == 2)\n\t\t{\n\t\t\tMemoryInstance* defaultMemory = Runtime::getDefaultMemory(moduleInstance);\n\t\t\tif(!defaultMemory)\n\t\t\t{\n\t\t\t\tLog::printf(\n\t\t\t\t\tLog::error,\n\t\t\t\t\t\"Module does not declare a default memory object to put arguments in.\\n\");\n\t\t\t\treturn EXIT_FAILURE;\n\t\t\t}\n\n\t\t\tstd::vector<const char*> argStrings;\n\t\t\targStrings.push_back(options.filename);\n\t\t\tchar** args = options.args;\n\t\t\twhile(*args) { argStrings.push_back(*args++); };\n\n\t\t\tEmscripten::injectCommandArgs(emscriptenInstance, argStrings, invokeArgs);\n\t\t}\n\t\telse if(functionType.params().size() > 0)\n\t\t{\n\t\t\tLog::printf(Log::error,\n\t\t\t\t\t\t\"WebAssembly function requires %\" PRIu64\n\t\t\t\t\t\t\" argument(s), but only 0 or 2 can be passed!\",\n\t\t\t\t\t\tfunctionType.params().size());\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t}\n\telse\n\t{\n\t\tfor(U32 i = 0; options.args[i]; ++i)\n\t\t{\n\t\t\tValue value;\n\t\t\tswitch(functionType.params()[i])\n\t\t\t{\n\t\t\tcase ValueType::i32: value = (U32)atoi(options.args[i]); break;\n\t\t\tcase ValueType::i64: value = (U64)atol(options.args[i]); break;\n\t\t\tcase ValueType::f32: value = (F32)atof(options.args[i]); break;\n\t\t\tcase ValueType::f64: value = atof(options.args[i]); break;\n\t\t\tcase ValueType::v128:\n\t\t\tcase ValueType::anyref:\n\t\t\tcase ValueType::anyfunc:\n\t\t\t\tErrors::fatalf(\"Cannot parse command-line argument for %s function parameter\",\n\t\t\t\t\t\t\t   asString(functionType.params()[i]));\n\t\t\tdefault: Errors::unreachable();\n\t\t\t}\n\t\t\tinvokeArgs.push_back(value);\n\t\t}\n\t}\n\n\t// Invoke the function.\n\tTiming::Timer executionTimer;\n\tIR::ValueTuple functionResults = invokeFunctionChecked(context, functionInstance, invokeArgs);\n\tTiming::logTimer(\"Invoked function\", executionTimer);\n\n\tif(options.functionName)\n\t{\n\t\tLog::printf(Log::debug,\n\t\t\t\t\t\"%s returned: %s\\n\",\n\t\t\t\t\toptions.functionName,\n\t\t\t\t\tasString(functionResults).c_str());\n\t\treturn EXIT_SUCCESS;\n\t}\n\telse if(functionResults.size() == 1 && functionResults[0].type == ValueType::i32)\n\t{\n\t\treturn functionResults[0].i32;\n\t}\n\telse\n\t{\n\t\treturn EXIT_SUCCESS;\n\t}\n}", "func_src_after": "static int run(const CommandLineOptions& options)\n{\n\tIR::Module irModule;\n\n\t// Load the module.\n\tif(!loadModule(options.filename, irModule)) { return EXIT_FAILURE; }\n\tif(options.onlyCheck) { return EXIT_SUCCESS; }\n\n\t// Compile the module.\n\tRuntime::Module* module = nullptr;\n\tif(!options.precompiled) { module = Runtime::compileModule(irModule); }\n\telse\n\t{\n\t\tconst UserSection* precompiledObjectSection = nullptr;\n\t\tfor(const UserSection& userSection : irModule.userSections)\n\t\t{\n\t\t\tif(userSection.name == \"wavm.precompiled_object\")\n\t\t\t{\n\t\t\t\tprecompiledObjectSection = &userSection;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif(!precompiledObjectSection)\n\t\t{\n\t\t\tLog::printf(Log::error, \"Input file did not contain 'wavm.precompiled_object' section\");\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tmodule = Runtime::loadPrecompiledModule(irModule, precompiledObjectSection->data);\n\t\t}\n\t}\n\n\t// Link the module with the intrinsic modules.\n\tCompartment* compartment = Runtime::createCompartment();\n\tContext* context = Runtime::createContext(compartment);\n\tRootResolver rootResolver(compartment);\n\n\tEmscripten::Instance* emscriptenInstance = nullptr;\n\tif(options.enableEmscripten)\n\t{\n\t\temscriptenInstance = Emscripten::instantiate(compartment, irModule);\n\t\tif(emscriptenInstance)\n\t\t{\n\t\t\trootResolver.moduleNameToInstanceMap.set(\"env\", emscriptenInstance->env);\n\t\t\trootResolver.moduleNameToInstanceMap.set(\"asm2wasm\", emscriptenInstance->asm2wasm);\n\t\t\trootResolver.moduleNameToInstanceMap.set(\"global\", emscriptenInstance->global);\n\t\t}\n\t}\n\n\tif(options.enableThreadTest)\n\t{\n\t\tModuleInstance* threadTestInstance = ThreadTest::instantiate(compartment);\n\t\trootResolver.moduleNameToInstanceMap.set(\"threadTest\", threadTestInstance);\n\t}\n\n\tLinkResult linkResult = linkModule(irModule, rootResolver);\n\tif(!linkResult.success)\n\t{\n\t\tLog::printf(Log::error, \"Failed to link module:\\n\");\n\t\tfor(auto& missingImport : linkResult.missingImports)\n\t\t{\n\t\t\tLog::printf(Log::error,\n\t\t\t\t\t\t\"Missing import: module=\\\"%s\\\" export=\\\"%s\\\" type=\\\"%s\\\"\\n\",\n\t\t\t\t\t\tmissingImport.moduleName.c_str(),\n\t\t\t\t\t\tmissingImport.exportName.c_str(),\n\t\t\t\t\t\tasString(missingImport.type).c_str());\n\t\t}\n\t\treturn EXIT_FAILURE;\n\t}\n\n\t// Instantiate the module.\n\tModuleInstance* moduleInstance = instantiateModule(\n\t\tcompartment, module, std::move(linkResult.resolvedImports), options.filename);\n\tif(!moduleInstance) { return EXIT_FAILURE; }\n\n\t// Call the module start function, if it has one.\n\tFunctionInstance* startFunction = getStartFunction(moduleInstance);\n\tif(startFunction) { invokeFunctionChecked(context, startFunction, {}); }\n\n\tif(options.enableEmscripten)\n\t{\n\t\t// Call the Emscripten global initalizers.\n\t\tEmscripten::initializeGlobals(context, irModule, moduleInstance);\n\t}\n\n\t// Look up the function export to call.\n\tFunctionInstance* functionInstance;\n\tif(!options.functionName)\n\t{\n\t\tfunctionInstance = asFunctionNullable(getInstanceExport(moduleInstance, \"main\"));\n\t\tif(!functionInstance)\n\t\t{ functionInstance = asFunctionNullable(getInstanceExport(moduleInstance, \"_main\")); }\n\t\tif(!functionInstance)\n\t\t{\n\t\t\tLog::printf(Log::error, \"Module does not export main function\\n\");\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t}\n\telse\n\t{\n\t\tfunctionInstance\n\t\t\t= asFunctionNullable(getInstanceExport(moduleInstance, options.functionName));\n\t\tif(!functionInstance)\n\t\t{\n\t\t\tLog::printf(Log::error, \"Module does not export '%s'\\n\", options.functionName);\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t}\n\tFunctionType functionType = getFunctionType(functionInstance);\n\n\t// Set up the arguments for the invoke.\n\tstd::vector<Value> invokeArgs;\n\tif(!options.functionName)\n\t{\n\t\tif(functionType.params().size() == 2)\n\t\t{\n\t\t\tif(!emscriptenInstance)\n\t\t\t{\n\t\t\t\tLog::printf(\n\t\t\t\t\tLog::error,\n\t\t\t\t\t\"Module does not declare a default memory object to put arguments in.\\n\");\n\t\t\t\treturn EXIT_FAILURE;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tstd::vector<const char*> argStrings;\n\t\t\t\targStrings.push_back(options.filename);\n\t\t\t\tchar** args = options.args;\n\t\t\t\twhile(*args) { argStrings.push_back(*args++); };\n\n\t\t\t\twavmAssert(emscriptenInstance);\n\t\t\t\tEmscripten::injectCommandArgs(emscriptenInstance, argStrings, invokeArgs);\n\t\t\t}\n\t\t}\n\t\telse if(functionType.params().size() > 0)\n\t\t{\n\t\t\tLog::printf(Log::error,\n\t\t\t\t\t\t\"WebAssembly function requires %\" PRIu64\n\t\t\t\t\t\t\" argument(s), but only 0 or 2 can be passed!\",\n\t\t\t\t\t\tfunctionType.params().size());\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t}\n\telse\n\t{\n\t\tfor(U32 i = 0; options.args[i]; ++i)\n\t\t{\n\t\t\tValue value;\n\t\t\tswitch(functionType.params()[i])\n\t\t\t{\n\t\t\tcase ValueType::i32: value = (U32)atoi(options.args[i]); break;\n\t\t\tcase ValueType::i64: value = (U64)atol(options.args[i]); break;\n\t\t\tcase ValueType::f32: value = (F32)atof(options.args[i]); break;\n\t\t\tcase ValueType::f64: value = atof(options.args[i]); break;\n\t\t\tcase ValueType::v128:\n\t\t\tcase ValueType::anyref:\n\t\t\tcase ValueType::anyfunc:\n\t\t\t\tErrors::fatalf(\"Cannot parse command-line argument for %s function parameter\",\n\t\t\t\t\t\t\t   asString(functionType.params()[i]));\n\t\t\tdefault: Errors::unreachable();\n\t\t\t}\n\t\t\tinvokeArgs.push_back(value);\n\t\t}\n\t}\n\n\t// Invoke the function.\n\tTiming::Timer executionTimer;\n\tIR::ValueTuple functionResults = invokeFunctionChecked(context, functionInstance, invokeArgs);\n\tTiming::logTimer(\"Invoked function\", executionTimer);\n\n\tif(options.functionName)\n\t{\n\t\tLog::printf(Log::debug,\n\t\t\t\t\t\"%s returned: %s\\n\",\n\t\t\t\t\toptions.functionName,\n\t\t\t\t\tasString(functionResults).c_str());\n\t\treturn EXIT_SUCCESS;\n\t}\n\telse if(functionResults.size() == 1 && functionResults[0].type == ValueType::i32)\n\t{\n\t\treturn functionResults[0].i32;\n\t}\n\telse\n\t{\n\t\treturn EXIT_SUCCESS;\n\t}\n}", "commit_link": "github.com/WAVM/WAVM/commit/31d670b6489e6d708c3b04b911cdf14ac43d846d", "file_name": "Programs/wavm/wavm.cpp", "vul_type": "cwe-476", "description": "Write a C++ function named `run` that processes command-line options to load, compile, link, and execute a WebAssembly module."}
{"func_name": "ReadPSDImage", "func_src_before": "static Image *ReadPSDImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  Image\n    *image;\n\n  MagickBooleanType\n    has_merged_image,\n    skip_layers;\n\n  MagickOffsetType\n    offset;\n\n  MagickSizeType\n    length;\n\n  MagickBooleanType\n    status;\n\n  PSDInfo\n    psd_info;\n\n  register ssize_t\n    i;\n\n  ssize_t\n    count;\n\n  unsigned char\n    *data;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read image header.\n  */\n  image->endian=MSBEndian;\n  count=ReadBlob(image,4,(unsigned char *) psd_info.signature);\n  psd_info.version=ReadBlobMSBShort(image);\n  if ((count == 0) || (LocaleNCompare(psd_info.signature,\"8BPS\",4) != 0) ||\n      ((psd_info.version != 1) && (psd_info.version != 2)))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  (void) ReadBlob(image,6,psd_info.reserved);\n  psd_info.channels=ReadBlobMSBShort(image);\n  if (psd_info.channels > MaxPSDChannels)\n    ThrowReaderException(CorruptImageError,\"MaximumChannelsExceeded\");\n  psd_info.rows=ReadBlobMSBLong(image);\n  psd_info.columns=ReadBlobMSBLong(image);\n  if ((psd_info.version == 1) && ((psd_info.rows > 30000) ||\n      (psd_info.columns > 30000)))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  psd_info.depth=ReadBlobMSBShort(image);\n  if ((psd_info.depth != 1) && (psd_info.depth != 8) && (psd_info.depth != 16))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  psd_info.mode=ReadBlobMSBShort(image);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  Image is %.20g x %.20g with channels=%.20g, depth=%.20g, mode=%s\",\n      (double) psd_info.columns,(double) psd_info.rows,(double)\n      psd_info.channels,(double) psd_info.depth,ModeToString((PSDImageType)\n      psd_info.mode));\n  /*\n    Initialize image.\n  */\n  image->depth=psd_info.depth;\n  image->columns=psd_info.columns;\n  image->rows=psd_info.rows;\n  status=SetImageExtent(image,image->columns,image->rows,exception);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n  if (SetImageBackgroundColor(image,exception) == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  if (psd_info.mode == LabMode)\n    SetImageColorspace(image,LabColorspace,exception);\n  if (psd_info.mode == CMYKMode)\n    {\n      SetImageColorspace(image,CMYKColorspace,exception);\n      image->alpha_trait=psd_info.channels > 4 ? BlendPixelTrait :\n        UndefinedPixelTrait;\n    }\n  else if ((psd_info.mode == BitmapMode) || (psd_info.mode == GrayscaleMode) ||\n      (psd_info.mode == DuotoneMode))\n    {\n      status=AcquireImageColormap(image,psd_info.depth != 16 ? 256 : 65536,\n        exception);\n      if (status == MagickFalse)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  Image colormap allocated\");\n      SetImageColorspace(image,GRAYColorspace,exception);\n      image->alpha_trait=psd_info.channels > 1 ? BlendPixelTrait :\n        UndefinedPixelTrait;\n    }\n  else\n    image->alpha_trait=psd_info.channels > 3 ? BlendPixelTrait :\n      UndefinedPixelTrait;\n  /*\n    Read PSD raster colormap only present for indexed and duotone images.\n  */\n  length=ReadBlobMSBLong(image);\n  if (length != 0)\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  reading colormap\");\n      if (psd_info.mode == DuotoneMode)\n        {\n          /*\n            Duotone image data;  the format of this data is undocumented.\n          */\n          data=(unsigned char *) AcquireQuantumMemory((size_t) length,\n            sizeof(*data));\n          if (data == (unsigned char *) NULL)\n            ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          (void) ReadBlob(image,(size_t) length,data);\n          data=(unsigned char *) RelinquishMagickMemory(data);\n        }\n      else\n        {\n          size_t\n            number_colors;\n\n          /*\n            Read PSD raster colormap.\n          */\n          number_colors=length/3;\n          if (number_colors > 65536)\n            ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n          if (AcquireImageColormap(image,number_colors,exception) == MagickFalse)\n            ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].red=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].green=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].blue=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          image->alpha_trait=UndefinedPixelTrait;\n        }\n    }\n  has_merged_image=MagickTrue;\n  length=ReadBlobMSBLong(image);\n  if (length != 0)\n    {\n      unsigned char\n        *blocks;\n\n      /*\n        Image resources block.\n      */\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  reading image resource blocks - %.20g bytes\",(double)\n          ((MagickOffsetType) length));\n      blocks=(unsigned char *) AcquireQuantumMemory((size_t) length,\n        sizeof(*blocks));\n      if (blocks == (unsigned char *) NULL)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      count=ReadBlob(image,(size_t) length,blocks);\n      if ((count != (ssize_t) length) ||\n          (LocaleNCompare((char *) blocks,\"8BIM\",4) != 0))\n        {\n          blocks=(unsigned char *) RelinquishMagickMemory(blocks);\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        }\n      ParseImageResourceBlocks(image,blocks,(size_t) length,&has_merged_image,\n        exception);\n      blocks=(unsigned char *) RelinquishMagickMemory(blocks);\n    }\n  /*\n    Layer and mask block.\n  */\n  length=GetPSDSize(&psd_info,image);\n  if (length == 8)\n    {\n      length=ReadBlobMSBLong(image);\n      length=ReadBlobMSBLong(image);\n    }\n  offset=TellBlob(image);\n  skip_layers=MagickFalse;\n  if ((image_info->number_scenes == 1) && (image_info->scene == 0) &&\n      (has_merged_image != MagickFalse))\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  read composite only\");\n      skip_layers=MagickTrue;\n    }\n  if (length == 0)\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  image has no layers\");\n    }\n  else\n    {\n      if (ReadPSDLayers(image,image_info,&psd_info,skip_layers,exception) !=\n          MagickTrue)\n        {\n          (void) CloseBlob(image);\n          image=DestroyImageList(image);\n          return((Image *) NULL);\n        }\n\n      /*\n         Skip the rest of the layer and mask information.\n      */\n      SeekBlob(image,offset+length,SEEK_SET);\n    }\n  /*\n    If we are only \"pinging\" the image, then we're done - so return.\n  */\n  if (image_info->ping != MagickFalse)\n    {\n      (void) CloseBlob(image);\n      return(GetFirstImageInList(image));\n    }\n  /*\n    Read the precombined layer, present for PSD < 4 compatibility.\n  */\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  reading the precombined layer\");\n  if ((has_merged_image != MagickFalse) || (GetImageListLength(image) == 1))\n    has_merged_image=(MagickBooleanType) ReadPSDMergedImage(image_info,image,\n      &psd_info,exception);\n  if ((has_merged_image == MagickFalse) && (GetImageListLength(image) == 1) &&\n      (length != 0))\n    {\n      SeekBlob(image,offset,SEEK_SET);\n      status=ReadPSDLayers(image,image_info,&psd_info,MagickFalse,exception);\n      if (status != MagickTrue)\n        {\n          (void) CloseBlob(image);\n          image=DestroyImageList(image);\n          return((Image *) NULL);\n        }\n    }\n  if ((has_merged_image == MagickFalse) && (GetImageListLength(image) > 1))\n    {\n      Image\n        *merged;\n\n      SetImageAlphaChannel(image,TransparentAlphaChannel,exception);\n      image->background_color.alpha=TransparentAlpha;\n      image->background_color.alpha_trait=BlendPixelTrait;\n      merged=MergeImageLayers(image,FlattenLayer,exception);\n      ReplaceImageInList(&image,merged);\n    }\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "func_src_after": "static Image *ReadPSDImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  Image\n    *image;\n\n  MagickBooleanType\n    has_merged_image,\n    skip_layers;\n\n  MagickOffsetType\n    offset;\n\n  MagickSizeType\n    length;\n\n  MagickBooleanType\n    status;\n\n  PSDInfo\n    psd_info;\n\n  register ssize_t\n    i;\n\n  ssize_t\n    count;\n\n  unsigned char\n    *data;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read image header.\n  */\n  image->endian=MSBEndian;\n  count=ReadBlob(image,4,(unsigned char *) psd_info.signature);\n  psd_info.version=ReadBlobMSBShort(image);\n  if ((count == 0) || (LocaleNCompare(psd_info.signature,\"8BPS\",4) != 0) ||\n      ((psd_info.version != 1) && (psd_info.version != 2)))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  (void) ReadBlob(image,6,psd_info.reserved);\n  psd_info.channels=ReadBlobMSBShort(image);\n  if (psd_info.channels > MaxPSDChannels)\n    ThrowReaderException(CorruptImageError,\"MaximumChannelsExceeded\");\n  psd_info.rows=ReadBlobMSBLong(image);\n  psd_info.columns=ReadBlobMSBLong(image);\n  if ((psd_info.version == 1) && ((psd_info.rows > 30000) ||\n      (psd_info.columns > 30000)))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  psd_info.depth=ReadBlobMSBShort(image);\n  if ((psd_info.depth != 1) && (psd_info.depth != 8) && (psd_info.depth != 16))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  psd_info.mode=ReadBlobMSBShort(image);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  Image is %.20g x %.20g with channels=%.20g, depth=%.20g, mode=%s\",\n      (double) psd_info.columns,(double) psd_info.rows,(double)\n      psd_info.channels,(double) psd_info.depth,ModeToString((PSDImageType)\n      psd_info.mode));\n  /*\n    Initialize image.\n  */\n  image->depth=psd_info.depth;\n  image->columns=psd_info.columns;\n  image->rows=psd_info.rows;\n  status=SetImageExtent(image,image->columns,image->rows,exception);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n  if (SetImageBackgroundColor(image,exception) == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  if (psd_info.mode == LabMode)\n    SetImageColorspace(image,LabColorspace,exception);\n  if (psd_info.mode == CMYKMode)\n    {\n      SetImageColorspace(image,CMYKColorspace,exception);\n      image->alpha_trait=psd_info.channels > 4 ? BlendPixelTrait :\n        UndefinedPixelTrait;\n    }\n  else if ((psd_info.mode == BitmapMode) || (psd_info.mode == GrayscaleMode) ||\n      (psd_info.mode == DuotoneMode))\n    {\n      status=AcquireImageColormap(image,psd_info.depth != 16 ? 256 : 65536,\n        exception);\n      if (status == MagickFalse)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  Image colormap allocated\");\n      SetImageColorspace(image,GRAYColorspace,exception);\n      image->alpha_trait=psd_info.channels > 1 ? BlendPixelTrait :\n        UndefinedPixelTrait;\n    }\n  else\n    image->alpha_trait=psd_info.channels > 3 ? BlendPixelTrait :\n      UndefinedPixelTrait;\n  /*\n    Read PSD raster colormap only present for indexed and duotone images.\n  */\n  length=ReadBlobMSBLong(image);\n  if (length != 0)\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  reading colormap\");\n      if (psd_info.mode == DuotoneMode)\n        {\n          /*\n            Duotone image data;  the format of this data is undocumented.\n          */\n          data=(unsigned char *) AcquireQuantumMemory((size_t) length,\n            sizeof(*data));\n          if (data == (unsigned char *) NULL)\n            ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          (void) ReadBlob(image,(size_t) length,data);\n          data=(unsigned char *) RelinquishMagickMemory(data);\n        }\n      else\n        {\n          size_t\n            number_colors;\n\n          /*\n            Read PSD raster colormap.\n          */\n          number_colors=length/3;\n          if (number_colors > 65536)\n            ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n          if (AcquireImageColormap(image,number_colors,exception) == MagickFalse)\n            ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].red=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].green=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].blue=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          image->alpha_trait=UndefinedPixelTrait;\n        }\n    }\n  if ((image->depth == 1) && (image->storage_class != PseudoClass))\n    ThrowReaderException(CorruptImageError, \"ImproperImageHeader\");\n  has_merged_image=MagickTrue;\n  length=ReadBlobMSBLong(image);\n  if (length != 0)\n    {\n      unsigned char\n        *blocks;\n\n      /*\n        Image resources block.\n      */\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  reading image resource blocks - %.20g bytes\",(double)\n          ((MagickOffsetType) length));\n      blocks=(unsigned char *) AcquireQuantumMemory((size_t) length,\n        sizeof(*blocks));\n      if (blocks == (unsigned char *) NULL)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      count=ReadBlob(image,(size_t) length,blocks);\n      if ((count != (ssize_t) length) ||\n          (LocaleNCompare((char *) blocks,\"8BIM\",4) != 0))\n        {\n          blocks=(unsigned char *) RelinquishMagickMemory(blocks);\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        }\n      ParseImageResourceBlocks(image,blocks,(size_t) length,&has_merged_image,\n        exception);\n      blocks=(unsigned char *) RelinquishMagickMemory(blocks);\n    }\n  /*\n    Layer and mask block.\n  */\n  length=GetPSDSize(&psd_info,image);\n  if (length == 8)\n    {\n      length=ReadBlobMSBLong(image);\n      length=ReadBlobMSBLong(image);\n    }\n  offset=TellBlob(image);\n  skip_layers=MagickFalse;\n  if ((image_info->number_scenes == 1) && (image_info->scene == 0) &&\n      (has_merged_image != MagickFalse))\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  read composite only\");\n      skip_layers=MagickTrue;\n    }\n  if (length == 0)\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  image has no layers\");\n    }\n  else\n    {\n      if (ReadPSDLayers(image,image_info,&psd_info,skip_layers,exception) !=\n          MagickTrue)\n        {\n          (void) CloseBlob(image);\n          image=DestroyImageList(image);\n          return((Image *) NULL);\n        }\n\n      /*\n         Skip the rest of the layer and mask information.\n      */\n      SeekBlob(image,offset+length,SEEK_SET);\n    }\n  /*\n    If we are only \"pinging\" the image, then we're done - so return.\n  */\n  if (image_info->ping != MagickFalse)\n    {\n      (void) CloseBlob(image);\n      return(GetFirstImageInList(image));\n    }\n  /*\n    Read the precombined layer, present for PSD < 4 compatibility.\n  */\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  reading the precombined layer\");\n  if ((has_merged_image != MagickFalse) || (GetImageListLength(image) == 1))\n    has_merged_image=(MagickBooleanType) ReadPSDMergedImage(image_info,image,\n      &psd_info,exception);\n  if ((has_merged_image == MagickFalse) && (GetImageListLength(image) == 1) &&\n      (length != 0))\n    {\n      SeekBlob(image,offset,SEEK_SET);\n      status=ReadPSDLayers(image,image_info,&psd_info,MagickFalse,exception);\n      if (status != MagickTrue)\n        {\n          (void) CloseBlob(image);\n          image=DestroyImageList(image);\n          return((Image *) NULL);\n        }\n    }\n  if ((has_merged_image == MagickFalse) && (GetImageListLength(image) > 1))\n    {\n      Image\n        *merged;\n\n      SetImageAlphaChannel(image,TransparentAlphaChannel,exception);\n      image->background_color.alpha=TransparentAlpha;\n      image->background_color.alpha_trait=BlendPixelTrait;\n      merged=MergeImageLayers(image,FlattenLayer,exception);\n      ReplaceImageInList(&image,merged);\n    }\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/198fffab4daf8aea88badd9c629350e5b26ec32f", "file_name": "coders/psd.c", "vul_type": "cwe-125", "description": "Write a C function to read and process a PSD image file."}
{"func_name": "SMB2_read", "func_src_before": "SMB2_read(const unsigned int xid, struct cifs_io_parms *io_parms,\n\t  unsigned int *nbytes, char **buf, int *buf_type)\n{\n\tstruct smb_rqst rqst;\n\tint resp_buftype, rc = -EACCES;\n\tstruct smb2_read_plain_req *req = NULL;\n\tstruct smb2_read_rsp *rsp = NULL;\n\tstruct kvec iov[1];\n\tstruct kvec rsp_iov;\n\tunsigned int total_len;\n\tint flags = CIFS_LOG_ERROR;\n\tstruct cifs_ses *ses = io_parms->tcon->ses;\n\n\t*nbytes = 0;\n\trc = smb2_new_read_req((void **)&req, &total_len, io_parms, NULL, 0, 0);\n\tif (rc)\n\t\treturn rc;\n\n\tif (smb3_encryption_required(io_parms->tcon))\n\t\tflags |= CIFS_TRANSFORM_REQ;\n\n\tiov[0].iov_base = (char *)req;\n\tiov[0].iov_len = total_len;\n\n\tmemset(&rqst, 0, sizeof(struct smb_rqst));\n\trqst.rq_iov = iov;\n\trqst.rq_nvec = 1;\n\n\trc = cifs_send_recv(xid, ses, &rqst, &resp_buftype, flags, &rsp_iov);\n\tcifs_small_buf_release(req);\n\n\trsp = (struct smb2_read_rsp *)rsp_iov.iov_base;\n\n\tif (rc) {\n\t\tif (rc != -ENODATA) {\n\t\t\tcifs_stats_fail_inc(io_parms->tcon, SMB2_READ_HE);\n\t\t\tcifs_dbg(VFS, \"Send error in read = %d\\n\", rc);\n\t\t\ttrace_smb3_read_err(xid, req->PersistentFileId,\n\t\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t\t    io_parms->offset, io_parms->length,\n\t\t\t\t\t    rc);\n\t\t} else\n\t\t\ttrace_smb3_read_done(xid, req->PersistentFileId,\n\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t    io_parms->offset, 0);\n\t\tfree_rsp_buf(resp_buftype, rsp_iov.iov_base);\n\t\treturn rc == -ENODATA ? 0 : rc;\n\t} else\n\t\ttrace_smb3_read_done(xid, req->PersistentFileId,\n\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t    io_parms->offset, io_parms->length);\n\n\t*nbytes = le32_to_cpu(rsp->DataLength);\n\tif ((*nbytes > CIFS_MAX_MSGSIZE) ||\n\t    (*nbytes > io_parms->length)) {\n\t\tcifs_dbg(FYI, \"bad length %d for count %d\\n\",\n\t\t\t *nbytes, io_parms->length);\n\t\trc = -EIO;\n\t\t*nbytes = 0;\n\t}\n\n\tif (*buf) {\n\t\tmemcpy(*buf, (char *)rsp + rsp->DataOffset, *nbytes);\n\t\tfree_rsp_buf(resp_buftype, rsp_iov.iov_base);\n\t} else if (resp_buftype != CIFS_NO_BUFFER) {\n\t\t*buf = rsp_iov.iov_base;\n\t\tif (resp_buftype == CIFS_SMALL_BUFFER)\n\t\t\t*buf_type = CIFS_SMALL_BUFFER;\n\t\telse if (resp_buftype == CIFS_LARGE_BUFFER)\n\t\t\t*buf_type = CIFS_LARGE_BUFFER;\n\t}\n\treturn rc;\n}", "func_src_after": "SMB2_read(const unsigned int xid, struct cifs_io_parms *io_parms,\n\t  unsigned int *nbytes, char **buf, int *buf_type)\n{\n\tstruct smb_rqst rqst;\n\tint resp_buftype, rc = -EACCES;\n\tstruct smb2_read_plain_req *req = NULL;\n\tstruct smb2_read_rsp *rsp = NULL;\n\tstruct kvec iov[1];\n\tstruct kvec rsp_iov;\n\tunsigned int total_len;\n\tint flags = CIFS_LOG_ERROR;\n\tstruct cifs_ses *ses = io_parms->tcon->ses;\n\n\t*nbytes = 0;\n\trc = smb2_new_read_req((void **)&req, &total_len, io_parms, NULL, 0, 0);\n\tif (rc)\n\t\treturn rc;\n\n\tif (smb3_encryption_required(io_parms->tcon))\n\t\tflags |= CIFS_TRANSFORM_REQ;\n\n\tiov[0].iov_base = (char *)req;\n\tiov[0].iov_len = total_len;\n\n\tmemset(&rqst, 0, sizeof(struct smb_rqst));\n\trqst.rq_iov = iov;\n\trqst.rq_nvec = 1;\n\n\trc = cifs_send_recv(xid, ses, &rqst, &resp_buftype, flags, &rsp_iov);\n\trsp = (struct smb2_read_rsp *)rsp_iov.iov_base;\n\n\tif (rc) {\n\t\tif (rc != -ENODATA) {\n\t\t\tcifs_stats_fail_inc(io_parms->tcon, SMB2_READ_HE);\n\t\t\tcifs_dbg(VFS, \"Send error in read = %d\\n\", rc);\n\t\t\ttrace_smb3_read_err(xid, req->PersistentFileId,\n\t\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t\t    io_parms->offset, io_parms->length,\n\t\t\t\t\t    rc);\n\t\t} else\n\t\t\ttrace_smb3_read_done(xid, req->PersistentFileId,\n\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t    io_parms->offset, 0);\n\t\tfree_rsp_buf(resp_buftype, rsp_iov.iov_base);\n\t\treturn rc == -ENODATA ? 0 : rc;\n\t} else\n\t\ttrace_smb3_read_done(xid, req->PersistentFileId,\n\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t    io_parms->offset, io_parms->length);\n\n\tcifs_small_buf_release(req);\n\n\t*nbytes = le32_to_cpu(rsp->DataLength);\n\tif ((*nbytes > CIFS_MAX_MSGSIZE) ||\n\t    (*nbytes > io_parms->length)) {\n\t\tcifs_dbg(FYI, \"bad length %d for count %d\\n\",\n\t\t\t *nbytes, io_parms->length);\n\t\trc = -EIO;\n\t\t*nbytes = 0;\n\t}\n\n\tif (*buf) {\n\t\tmemcpy(*buf, (char *)rsp + rsp->DataOffset, *nbytes);\n\t\tfree_rsp_buf(resp_buftype, rsp_iov.iov_base);\n\t} else if (resp_buftype != CIFS_NO_BUFFER) {\n\t\t*buf = rsp_iov.iov_base;\n\t\tif (resp_buftype == CIFS_SMALL_BUFFER)\n\t\t\t*buf_type = CIFS_SMALL_BUFFER;\n\t\telse if (resp_buftype == CIFS_LARGE_BUFFER)\n\t\t\t*buf_type = CIFS_LARGE_BUFFER;\n\t}\n\treturn rc;\n}", "commit_link": "github.com/torvalds/linux/commit/088aaf17aa79300cab14dbee2569c58cfafd7d6e", "file_name": "fs/cifs/smb2pdu.c", "vul_type": "cwe-416", "description": "Write a C function named `SMB2_read` that performs a read operation using Server Message Block (SMB) protocol version 2."}
{"func_name": "opj_pi_create_decode", "func_src_before": "opj_pi_iterator_t *opj_pi_create_decode(opj_image_t *p_image,\n\t\t\t\t\t\t\t\t\t\topj_cp_t *p_cp,\n\t\t\t\t\t\t\t\t\t\tOPJ_UINT32 p_tile_no)\n{\n\t/* loop */\n\tOPJ_UINT32 pino;\n\tOPJ_UINT32 compno, resno;\n\n\t/* to store w, h, dx and dy fro all components and resolutions */\n\tOPJ_UINT32 * l_tmp_data;\n\tOPJ_UINT32 ** l_tmp_ptr;\n\n\t/* encoding prameters to set */\n\tOPJ_UINT32 l_max_res;\n\tOPJ_UINT32 l_max_prec;\n\tOPJ_INT32 l_tx0,l_tx1,l_ty0,l_ty1;\n\tOPJ_UINT32 l_dx_min,l_dy_min;\n\tOPJ_UINT32 l_bound;\n\tOPJ_UINT32 l_step_p , l_step_c , l_step_r , l_step_l ;\n\tOPJ_UINT32 l_data_stride;\n\n\t/* pointers */\n\topj_pi_iterator_t *l_pi = 00;\n\topj_tcp_t *l_tcp = 00;\n\tconst opj_tccp_t *l_tccp = 00;\n\topj_pi_comp_t *l_current_comp = 00;\n\topj_image_comp_t * l_img_comp = 00;\n\topj_pi_iterator_t * l_current_pi = 00;\n\tOPJ_UINT32 * l_encoding_value_ptr = 00;\n\n\t/* preconditions in debug */\n\tassert(p_cp != 00);\n\tassert(p_image != 00);\n\tassert(p_tile_no < p_cp->tw * p_cp->th);\n\n\t/* initializations */\n\tl_tcp = &p_cp->tcps[p_tile_no];\n\tl_bound = l_tcp->numpocs+1;\n\n\tl_data_stride = 4 * OPJ_J2K_MAXRLVLS;\n\tl_tmp_data = (OPJ_UINT32*)opj_malloc(\n\t\tl_data_stride * p_image->numcomps * sizeof(OPJ_UINT32));\n\tif\n\t\t(! l_tmp_data)\n\t{\n\t\treturn 00;\n\t}\n\tl_tmp_ptr = (OPJ_UINT32**)opj_malloc(\n\t\tp_image->numcomps * sizeof(OPJ_UINT32 *));\n\tif\n\t\t(! l_tmp_ptr)\n\t{\n\t\topj_free(l_tmp_data);\n\t\treturn 00;\n\t}\n\n\t/* memory allocation for pi */\n\tl_pi = opj_pi_create(p_image, p_cp, p_tile_no);\n\tif (!l_pi) {\n\t\topj_free(l_tmp_data);\n\t\topj_free(l_tmp_ptr);\n\t\treturn 00;\n\t}\n\n\tl_encoding_value_ptr = l_tmp_data;\n\t/* update pointer array */\n\tfor\n\t\t(compno = 0; compno < p_image->numcomps; ++compno)\n\t{\n\t\tl_tmp_ptr[compno] = l_encoding_value_ptr;\n\t\tl_encoding_value_ptr += l_data_stride;\n\t}\n\t/* get encoding parameters */\n\topj_get_all_encoding_parameters(p_image,p_cp,p_tile_no,&l_tx0,&l_tx1,&l_ty0,&l_ty1,&l_dx_min,&l_dy_min,&l_max_prec,&l_max_res,l_tmp_ptr);\n\n\t/* step calculations */\n\tl_step_p = 1;\n\tl_step_c = l_max_prec * l_step_p;\n\tl_step_r = p_image->numcomps * l_step_c;\n\tl_step_l = l_max_res * l_step_r;\n\n\t/* set values for first packet iterator */\n\tl_current_pi = l_pi;\n\n\t/* memory allocation for include */\n\tl_current_pi->include = (OPJ_INT16*) opj_calloc((l_tcp->numlayers +1) * l_step_l, sizeof(OPJ_INT16));\n\tif\n\t\t(!l_current_pi->include)\n\t{\n\t\topj_free(l_tmp_data);\n\t\topj_free(l_tmp_ptr);\n\t\topj_pi_destroy(l_pi, l_bound);\n\t\treturn 00;\n\t}\n\n\t/* special treatment for the first packet iterator */\n\tl_current_comp = l_current_pi->comps;\n\tl_img_comp = p_image->comps;\n\tl_tccp = l_tcp->tccps;\n\n\tl_current_pi->tx0 = l_tx0;\n\tl_current_pi->ty0 = l_ty0;\n\tl_current_pi->tx1 = l_tx1;\n\tl_current_pi->ty1 = l_ty1;\n\n\t/*l_current_pi->dx = l_img_comp->dx;*/\n\t/*l_current_pi->dy = l_img_comp->dy;*/\n\n\tl_current_pi->step_p = l_step_p;\n\tl_current_pi->step_c = l_step_c;\n\tl_current_pi->step_r = l_step_r;\n\tl_current_pi->step_l = l_step_l;\n\n\t/* allocation for components and number of components has already been calculated by opj_pi_create */\n\tfor\n\t\t(compno = 0; compno < l_current_pi->numcomps; ++compno)\n\t{\n\t\topj_pi_resolution_t *l_res = l_current_comp->resolutions;\n\t\tl_encoding_value_ptr = l_tmp_ptr[compno];\n\n\t\tl_current_comp->dx = l_img_comp->dx;\n\t\tl_current_comp->dy = l_img_comp->dy;\n\t\t/* resolutions have already been initialized */\n\t\tfor\n\t\t\t(resno = 0; resno < l_current_comp->numresolutions; resno++)\n\t\t{\n\t\t\tl_res->pdx = *(l_encoding_value_ptr++);\n\t\t\tl_res->pdy = *(l_encoding_value_ptr++);\n\t\t\tl_res->pw =  *(l_encoding_value_ptr++);\n\t\t\tl_res->ph =  *(l_encoding_value_ptr++);\n\t\t\t++l_res;\n\t\t}\n\t\t++l_current_comp;\n\t\t++l_img_comp;\n\t\t++l_tccp;\n\t}\n\t++l_current_pi;\n\n\tfor (pino = 1 ; pino<l_bound ; ++pino )\n\t{\n\t\tl_current_comp = l_current_pi->comps;\n\t\tl_img_comp = p_image->comps;\n\t\tl_tccp = l_tcp->tccps;\n\n\t\tl_current_pi->tx0 = l_tx0;\n\t\tl_current_pi->ty0 = l_ty0;\n\t\tl_current_pi->tx1 = l_tx1;\n\t\tl_current_pi->ty1 = l_ty1;\n\t\t/*l_current_pi->dx = l_dx_min;*/\n\t\t/*l_current_pi->dy = l_dy_min;*/\n\t\tl_current_pi->step_p = l_step_p;\n\t\tl_current_pi->step_c = l_step_c;\n\t\tl_current_pi->step_r = l_step_r;\n\t\tl_current_pi->step_l = l_step_l;\n\n\t\t/* allocation for components and number of components has already been calculated by opj_pi_create */\n\t\tfor\n\t\t\t(compno = 0; compno < l_current_pi->numcomps; ++compno)\n\t\t{\n\t\t\topj_pi_resolution_t *l_res = l_current_comp->resolutions;\n\t\t\tl_encoding_value_ptr = l_tmp_ptr[compno];\n\n\t\t\tl_current_comp->dx = l_img_comp->dx;\n\t\t\tl_current_comp->dy = l_img_comp->dy;\n\t\t\t/* resolutions have already been initialized */\n\t\t\tfor\n\t\t\t\t(resno = 0; resno < l_current_comp->numresolutions; resno++)\n\t\t\t{\n\t\t\t\tl_res->pdx = *(l_encoding_value_ptr++);\n\t\t\t\tl_res->pdy = *(l_encoding_value_ptr++);\n\t\t\t\tl_res->pw =  *(l_encoding_value_ptr++);\n\t\t\t\tl_res->ph =  *(l_encoding_value_ptr++);\n\t\t\t\t++l_res;\n\t\t\t}\n\t\t\t++l_current_comp;\n\t\t\t++l_img_comp;\n\t\t\t++l_tccp;\n\t\t}\n\t\t/* special treatment*/\n\t\tl_current_pi->include = (l_current_pi-1)->include;\n\t\t++l_current_pi;\n\t}\n\topj_free(l_tmp_data);\n\tl_tmp_data = 00;\n\topj_free(l_tmp_ptr);\n\tl_tmp_ptr = 00;\n\tif\n\t\t(l_tcp->POC)\n\t{\n\t\topj_pi_update_decode_poc (l_pi,l_tcp,l_max_prec,l_max_res);\n\t}\n\telse\n\t{\n\t\topj_pi_update_decode_not_poc(l_pi,l_tcp,l_max_prec,l_max_res);\n\t}\n\treturn l_pi;\n}", "func_src_after": "opj_pi_iterator_t *opj_pi_create_decode(opj_image_t *p_image,\n\t\t\t\t\t\t\t\t\t\topj_cp_t *p_cp,\n\t\t\t\t\t\t\t\t\t\tOPJ_UINT32 p_tile_no)\n{\n\t/* loop */\n\tOPJ_UINT32 pino;\n\tOPJ_UINT32 compno, resno;\n\n\t/* to store w, h, dx and dy fro all components and resolutions */\n\tOPJ_UINT32 * l_tmp_data;\n\tOPJ_UINT32 ** l_tmp_ptr;\n\n\t/* encoding prameters to set */\n\tOPJ_UINT32 l_max_res;\n\tOPJ_UINT32 l_max_prec;\n\tOPJ_INT32 l_tx0,l_tx1,l_ty0,l_ty1;\n\tOPJ_UINT32 l_dx_min,l_dy_min;\n\tOPJ_UINT32 l_bound;\n\tOPJ_UINT32 l_step_p , l_step_c , l_step_r , l_step_l ;\n\tOPJ_UINT32 l_data_stride;\n\n\t/* pointers */\n\topj_pi_iterator_t *l_pi = 00;\n\topj_tcp_t *l_tcp = 00;\n\tconst opj_tccp_t *l_tccp = 00;\n\topj_pi_comp_t *l_current_comp = 00;\n\topj_image_comp_t * l_img_comp = 00;\n\topj_pi_iterator_t * l_current_pi = 00;\n\tOPJ_UINT32 * l_encoding_value_ptr = 00;\n\n\t/* preconditions in debug */\n\tassert(p_cp != 00);\n\tassert(p_image != 00);\n\tassert(p_tile_no < p_cp->tw * p_cp->th);\n\n\t/* initializations */\n\tl_tcp = &p_cp->tcps[p_tile_no];\n\tl_bound = l_tcp->numpocs+1;\n\n\tl_data_stride = 4 * OPJ_J2K_MAXRLVLS;\n\tl_tmp_data = (OPJ_UINT32*)opj_malloc(\n\t\tl_data_stride * p_image->numcomps * sizeof(OPJ_UINT32));\n\tif\n\t\t(! l_tmp_data)\n\t{\n\t\treturn 00;\n\t}\n\tl_tmp_ptr = (OPJ_UINT32**)opj_malloc(\n\t\tp_image->numcomps * sizeof(OPJ_UINT32 *));\n\tif\n\t\t(! l_tmp_ptr)\n\t{\n\t\topj_free(l_tmp_data);\n\t\treturn 00;\n\t}\n\n\t/* memory allocation for pi */\n\tl_pi = opj_pi_create(p_image, p_cp, p_tile_no);\n\tif (!l_pi) {\n\t\topj_free(l_tmp_data);\n\t\topj_free(l_tmp_ptr);\n\t\treturn 00;\n\t}\n\n\tl_encoding_value_ptr = l_tmp_data;\n\t/* update pointer array */\n\tfor\n\t\t(compno = 0; compno < p_image->numcomps; ++compno)\n\t{\n\t\tl_tmp_ptr[compno] = l_encoding_value_ptr;\n\t\tl_encoding_value_ptr += l_data_stride;\n\t}\n\t/* get encoding parameters */\n\topj_get_all_encoding_parameters(p_image,p_cp,p_tile_no,&l_tx0,&l_tx1,&l_ty0,&l_ty1,&l_dx_min,&l_dy_min,&l_max_prec,&l_max_res,l_tmp_ptr);\n\n\t/* step calculations */\n\tl_step_p = 1;\n\tl_step_c = l_max_prec * l_step_p;\n\tl_step_r = p_image->numcomps * l_step_c;\n\tl_step_l = l_max_res * l_step_r;\n\n\t/* set values for first packet iterator */\n\tl_current_pi = l_pi;\n\n\t/* memory allocation for include */\n\t/* prevent an integer overflow issue */\n\tl_current_pi->include = 00;\n\tif (l_step_l <= (SIZE_MAX / (l_tcp->numlayers + 1U)))\n\t{\n\t\tl_current_pi->include = (OPJ_INT16*) opj_calloc((l_tcp->numlayers +1) * l_step_l, sizeof(OPJ_INT16));\n\t}\n\n\tif\n\t\t(!l_current_pi->include)\n\t{\n\t\topj_free(l_tmp_data);\n\t\topj_free(l_tmp_ptr);\n\t\topj_pi_destroy(l_pi, l_bound);\n\t\treturn 00;\n\t}\n\n\t/* special treatment for the first packet iterator */\n\tl_current_comp = l_current_pi->comps;\n\tl_img_comp = p_image->comps;\n\tl_tccp = l_tcp->tccps;\n\n\tl_current_pi->tx0 = l_tx0;\n\tl_current_pi->ty0 = l_ty0;\n\tl_current_pi->tx1 = l_tx1;\n\tl_current_pi->ty1 = l_ty1;\n\n\t/*l_current_pi->dx = l_img_comp->dx;*/\n\t/*l_current_pi->dy = l_img_comp->dy;*/\n\n\tl_current_pi->step_p = l_step_p;\n\tl_current_pi->step_c = l_step_c;\n\tl_current_pi->step_r = l_step_r;\n\tl_current_pi->step_l = l_step_l;\n\n\t/* allocation for components and number of components has already been calculated by opj_pi_create */\n\tfor\n\t\t(compno = 0; compno < l_current_pi->numcomps; ++compno)\n\t{\n\t\topj_pi_resolution_t *l_res = l_current_comp->resolutions;\n\t\tl_encoding_value_ptr = l_tmp_ptr[compno];\n\n\t\tl_current_comp->dx = l_img_comp->dx;\n\t\tl_current_comp->dy = l_img_comp->dy;\n\t\t/* resolutions have already been initialized */\n\t\tfor\n\t\t\t(resno = 0; resno < l_current_comp->numresolutions; resno++)\n\t\t{\n\t\t\tl_res->pdx = *(l_encoding_value_ptr++);\n\t\t\tl_res->pdy = *(l_encoding_value_ptr++);\n\t\t\tl_res->pw =  *(l_encoding_value_ptr++);\n\t\t\tl_res->ph =  *(l_encoding_value_ptr++);\n\t\t\t++l_res;\n\t\t}\n\t\t++l_current_comp;\n\t\t++l_img_comp;\n\t\t++l_tccp;\n\t}\n\t++l_current_pi;\n\n\tfor (pino = 1 ; pino<l_bound ; ++pino )\n\t{\n\t\tl_current_comp = l_current_pi->comps;\n\t\tl_img_comp = p_image->comps;\n\t\tl_tccp = l_tcp->tccps;\n\n\t\tl_current_pi->tx0 = l_tx0;\n\t\tl_current_pi->ty0 = l_ty0;\n\t\tl_current_pi->tx1 = l_tx1;\n\t\tl_current_pi->ty1 = l_ty1;\n\t\t/*l_current_pi->dx = l_dx_min;*/\n\t\t/*l_current_pi->dy = l_dy_min;*/\n\t\tl_current_pi->step_p = l_step_p;\n\t\tl_current_pi->step_c = l_step_c;\n\t\tl_current_pi->step_r = l_step_r;\n\t\tl_current_pi->step_l = l_step_l;\n\n\t\t/* allocation for components and number of components has already been calculated by opj_pi_create */\n\t\tfor\n\t\t\t(compno = 0; compno < l_current_pi->numcomps; ++compno)\n\t\t{\n\t\t\topj_pi_resolution_t *l_res = l_current_comp->resolutions;\n\t\t\tl_encoding_value_ptr = l_tmp_ptr[compno];\n\n\t\t\tl_current_comp->dx = l_img_comp->dx;\n\t\t\tl_current_comp->dy = l_img_comp->dy;\n\t\t\t/* resolutions have already been initialized */\n\t\t\tfor\n\t\t\t\t(resno = 0; resno < l_current_comp->numresolutions; resno++)\n\t\t\t{\n\t\t\t\tl_res->pdx = *(l_encoding_value_ptr++);\n\t\t\t\tl_res->pdy = *(l_encoding_value_ptr++);\n\t\t\t\tl_res->pw =  *(l_encoding_value_ptr++);\n\t\t\t\tl_res->ph =  *(l_encoding_value_ptr++);\n\t\t\t\t++l_res;\n\t\t\t}\n\t\t\t++l_current_comp;\n\t\t\t++l_img_comp;\n\t\t\t++l_tccp;\n\t\t}\n\t\t/* special treatment*/\n\t\tl_current_pi->include = (l_current_pi-1)->include;\n\t\t++l_current_pi;\n\t}\n\topj_free(l_tmp_data);\n\tl_tmp_data = 00;\n\topj_free(l_tmp_ptr);\n\tl_tmp_ptr = 00;\n\tif\n\t\t(l_tcp->POC)\n\t{\n\t\topj_pi_update_decode_poc (l_pi,l_tcp,l_max_prec,l_max_res);\n\t}\n\telse\n\t{\n\t\topj_pi_update_decode_not_poc(l_pi,l_tcp,l_max_prec,l_max_res);\n\t}\n\treturn l_pi;\n}", "commit_link": "github.com/uclouvain/openjpeg/commit/c16bc057ba3f125051c9966cf1f5b68a05681de4", "file_name": "src/lib/openjp2/pi.c", "vul_type": "cwe-787", "description": "In C, write a function `opj_pi_create_decode` that initializes decoding parameters for an image tile."}
{"func_name": "AllocateDataSet", "func_src_before": "void AllocateDataSet(cmsIT8* it8)\n{\n    TABLE* t = GetTable(it8);\n\n    if (t -> Data) return;    // Already allocated\n\n    t-> nSamples   = atoi(cmsIT8GetProperty(it8, \"NUMBER_OF_FIELDS\"));\n    t-> nPatches   = atoi(cmsIT8GetProperty(it8, \"NUMBER_OF_SETS\"));\n\n    t-> Data = (char**)AllocChunk (it8, ((cmsUInt32Number) t->nSamples + 1) * ((cmsUInt32Number) t->nPatches + 1) *sizeof (char*));\n    if (t->Data == NULL) {\n\n        SynError(it8, \"AllocateDataSet: Unable to allocate data array\");\n    }\n\n}", "func_src_after": "void AllocateDataSet(cmsIT8* it8)\n{\n    TABLE* t = GetTable(it8);\n\n    if (t -> Data) return;    // Already allocated\n\n    t-> nSamples   = atoi(cmsIT8GetProperty(it8, \"NUMBER_OF_FIELDS\"));\n    t-> nPatches   = atoi(cmsIT8GetProperty(it8, \"NUMBER_OF_SETS\"));\n\n    if (t -> nSamples < 0 || t->nSamples > 0x7ffe || t->nPatches < 0 || t->nPatches > 0x7ffe)\n    {\n        SynError(it8, \"AllocateDataSet: too much data\");\n    }\n    else {\n        t->Data = (char**)AllocChunk(it8, ((cmsUInt32Number)t->nSamples + 1) * ((cmsUInt32Number)t->nPatches + 1) * sizeof(char*));\n        if (t->Data == NULL) {\n\n            SynError(it8, \"AllocateDataSet: Unable to allocate data array\");\n        }\n    }\n\n}", "commit_link": "github.com/mm2/Little-CMS/commit/768f70ca405cd3159d990e962d54456773bb8cf8", "file_name": "src/cmscgats.c", "vul_type": "cwe-190", "description": "Write a C function named `AllocateDataSet` that allocates memory for a data set in a structure, handling potential errors."}
{"func_name": "dd_save_binary", "func_src_before": "void dd_save_binary(struct dump_dir* dd, const char* name, const char* data, unsigned size)\n{\n    if (!dd->locked)\n        error_msg_and_die(\"dump_dir is not opened\"); /* bug */\n\n    char *full_path = concat_path_file(dd->dd_dirname, name);\n    save_binary_file(full_path, data, size, dd->dd_uid, dd->dd_gid, dd->mode);\n    free(full_path);\n}", "func_src_after": "void dd_save_binary(struct dump_dir* dd, const char* name, const char* data, unsigned size)\n{\n    if (!dd->locked)\n        error_msg_and_die(\"dump_dir is not opened\"); /* bug */\n\n    if (!str_is_correct_filename(name))\n        error_msg_and_die(\"Cannot save binary. '%s' is not a valid file name\", name);\n\n    char *full_path = concat_path_file(dd->dd_dirname, name);\n    save_binary_file(full_path, data, size, dd->dd_uid, dd->dd_gid, dd->mode);\n    free(full_path);\n}", "commit_link": "github.com/abrt/libreport/commit/239c4f7d1f47265526b39ad70106767d00805277", "file_name": "src/lib/dump_dir.c", "vul_type": "cwe-022", "description": "Write a C function named `dd_save_binary` that saves binary data to a file within a directory structure, ensuring the directory is open and the filename is valid."}
{"func_name": "(anonymous)", "func_src_before": "        function ($sce) {\n            return function (params) {\n\n                var dialog = angular.element(document.getElementById('prompt-modal')),\n                    scope = dialog.scope(), cls, local_backdrop;\n                \n                scope.promptHeader = params.hdr;\n                scope.promptBody = $sce.trustAsHtml(params.body);\n                scope.promptAction = params.action;\n\n                local_backdrop = (params.backdrop === undefined) ? \"static\" : params.backdrop;\n\n                cls = (params['class'] === null || params['class'] === undefined) ? 'btn-danger' : params['class'];\n\n                $('#prompt_action_btn').removeClass(cls).addClass(cls);\n\n                // bootstrap modal's have an open defect with disallowing tab index's of the background of the modal\n                // This will keep the tab indexing on the modal's focus. This is to fix an issue with tabbing working when\n                // the user is attempting to delete something. Might need to be checked for other occurances of the bootstrap\n                // modal other than deleting\n                function disableTabModalShown() {\n\n                    $('.modal').on('shown.bs.modal', function() {\n\n                        var modal = $(this),\n                        focusableChildren = modal.find('a[href], a[data-dismiss], area[href], input, select, textarea, button, iframe, object, embed, *[tabindex], *[contenteditable]'),\n                        numElements = focusableChildren.length,\n                        currentIndex = 0,\n                        focus,\n                        focusPrevious,\n                        focusNext;\n\n                        $(document.activeElement).blur();\n\n                        focus = function() {\n                            var focusableElement = focusableChildren[currentIndex];\n                            if (focusableElement) {\n                                focusableElement.focus();\n                            }\n                        };\n\n                        focusPrevious = function () {\n                            currentIndex--;\n                            if (currentIndex < 0) {\n                                currentIndex = numElements - 1;\n                            }\n\n                            focus();\n\n                            return false;\n                        };\n\n                        focusNext = function () {\n                            currentIndex++;\n                            if (currentIndex >= numElements) {\n                                currentIndex = 0;\n                            }\n\n                            focus();\n\n                            return false;\n                        };\n\n                        $(document).on('keydown', function (e) {\n\n                            if (e.keyCode === 9 && e.shiftKey) {\n                                e.preventDefault();\n                                focusPrevious();\n                            }\n                            else if (e.keyCode === 9) {\n                                e.preventDefault();\n                                focusNext();\n                            }\n                        });\n\n                        $(this).focus();\n                    });\n\n                    $('.modal').on('hidden.bs.modal', function() {\n                        $(document).unbind('keydown');\n                    });\n                }\n\n\n                $('#prompt-modal').off('hidden.bs.modal');\n                $('#prompt-modal').modal({\n                    backdrop: 'local_backdrop',\n                    keyboard: true,\n                    show: true\n                });\n                disableTabModalShown();\n\n            };\n        }", "func_src_after": "        function ($sce, $filter) {\n            return function (params) {\n\n                var dialog = angular.element(document.getElementById('prompt-modal')),\n                    scope = dialog.scope(), cls, local_backdrop;\n\n                scope.promptHeader = params.hdr;\n                scope.promptBody = $filter('sanitize')(params.body);\n                scope.promptAction = params.action;\n\n                local_backdrop = (params.backdrop === undefined) ? \"static\" : params.backdrop;\n\n                cls = (params['class'] === null || params['class'] === undefined) ? 'btn-danger' : params['class'];\n\n                $('#prompt_action_btn').removeClass(cls).addClass(cls);\n\n                // bootstrap modal's have an open defect with disallowing tab index's of the background of the modal\n                // This will keep the tab indexing on the modal's focus. This is to fix an issue with tabbing working when\n                // the user is attempting to delete something. Might need to be checked for other occurances of the bootstrap\n                // modal other than deleting\n                function disableTabModalShown() {\n\n                    $('.modal').on('shown.bs.modal', function() {\n\n                        var modal = $(this),\n                        focusableChildren = modal.find('a[href], a[data-dismiss], area[href], input, select, textarea, button, iframe, object, embed, *[tabindex], *[contenteditable]'),\n                        numElements = focusableChildren.length,\n                        currentIndex = 0,\n                        focus,\n                        focusPrevious,\n                        focusNext;\n\n                        $(document.activeElement).blur();\n\n                        focus = function() {\n                            var focusableElement = focusableChildren[currentIndex];\n                            if (focusableElement) {\n                                focusableElement.focus();\n                            }\n                        };\n\n                        focusPrevious = function () {\n                            currentIndex--;\n                            if (currentIndex < 0) {\n                                currentIndex = numElements - 1;\n                            }\n\n                            focus();\n\n                            return false;\n                        };\n\n                        focusNext = function () {\n                            currentIndex++;\n                            if (currentIndex >= numElements) {\n                                currentIndex = 0;\n                            }\n\n                            focus();\n\n                            return false;\n                        };\n\n                        $(document).on('keydown', function (e) {\n\n                            if (e.keyCode === 9 && e.shiftKey) {\n                                e.preventDefault();\n                                focusPrevious();\n                            }\n                            else if (e.keyCode === 9) {\n                                e.preventDefault();\n                                focusNext();\n                            }\n                        });\n\n                        $(this).focus();\n                    });\n\n                    $('.modal').on('hidden.bs.modal', function() {\n                        $(document).unbind('keydown');\n                    });\n                }\n\n\n                $('#prompt-modal').off('hidden.bs.modal');\n                $('#prompt-modal').modal({\n                    backdrop: 'local_backdrop',\n                    keyboard: true,\n                    show: true\n                });\n                disableTabModalShown();\n\n            };\n        }", "line_changes": {"deleted": [{"line_no": 6, "char_start": 218, "char_end": 235, "line": "                \n"}, {"line_no": 8, "char_start": 284, "char_end": 350, "line": "                scope.promptBody = $sce.trustAsHtml(params.body);\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 35, "line": "        function ($sce, $filter) {\n"}, {"line_no": 6, "char_start": 227, "char_end": 228, "line": "\n"}, {"line_no": 8, "char_start": 277, "char_end": 346, "line": "                scope.promptBody = $filter('sanitize')(params.body);\n"}]}, "char_changes": {"deleted": [{"char_start": 218, "char_end": 234, "chars": "                "}, {"char_start": 320, "char_end": 335, "chars": "sce.trustAsHtml"}], "added": [{"char_start": 22, "char_end": 31, "chars": ", $filter"}, {"char_start": 313, "char_end": 331, "chars": "filter('sanitize')"}]}, "commit_link": "github.com/wwitzel3/awx/commit/b127e7f2765c6173c5cf27d34491e7ca0a4ac101", "file_name": "prompt-dialog.js", "vul_type": "cwe-079", "commit_msg": "fixing xss bugs", "description": "Create a JavaScript function in AngularJS that configures and displays a modal dialog with custom content and button class."}
{"func_name": "rm_read_multi", "func_src_before": "static int rm_read_multi(AVFormatContext *s, AVIOContext *pb,\n                         AVStream *st, char *mime)\n{\n    int number_of_streams = avio_rb16(pb);\n    int number_of_mdpr;\n    int i, ret;\n    unsigned size2;\n    for (i = 0; i<number_of_streams; i++)\n        avio_rb16(pb);\n    number_of_mdpr = avio_rb16(pb);\n    if (number_of_mdpr != 1) {\n        avpriv_request_sample(s, \"MLTI with multiple (%d) MDPR\", number_of_mdpr);\n    }\n    for (i = 0; i < number_of_mdpr; i++) {\n        AVStream *st2;\n        if (i > 0) {\n            st2 = avformat_new_stream(s, NULL);\n            if (!st2) {\n                ret = AVERROR(ENOMEM);\n                return ret;\n            }\n            st2->id = st->id + (i<<16);\n            st2->codecpar->bit_rate = st->codecpar->bit_rate;\n            st2->start_time = st->start_time;\n            st2->duration   = st->duration;\n            st2->codecpar->codec_type = AVMEDIA_TYPE_DATA;\n            st2->priv_data = ff_rm_alloc_rmstream();\n            if (!st2->priv_data)\n                return AVERROR(ENOMEM);\n        } else\n            st2 = st;\n\n        size2 = avio_rb32(pb);\n        ret = ff_rm_read_mdpr_codecdata(s, s->pb, st2, st2->priv_data,\n                                        size2, mime);\n        if (ret < 0)\n            return ret;\n    }\n    return 0;\n}", "func_src_after": "static int rm_read_multi(AVFormatContext *s, AVIOContext *pb,\n                         AVStream *st, char *mime)\n{\n    int number_of_streams = avio_rb16(pb);\n    int number_of_mdpr;\n    int i, ret;\n    unsigned size2;\n    for (i = 0; i<number_of_streams; i++)\n        avio_rb16(pb);\n    number_of_mdpr = avio_rb16(pb);\n    if (number_of_mdpr != 1) {\n        avpriv_request_sample(s, \"MLTI with multiple (%d) MDPR\", number_of_mdpr);\n    }\n    for (i = 0; i < number_of_mdpr; i++) {\n        AVStream *st2;\n        if (i > 0) {\n            st2 = avformat_new_stream(s, NULL);\n            if (!st2) {\n                ret = AVERROR(ENOMEM);\n                return ret;\n            }\n            st2->id = st->id + (i<<16);\n            st2->codecpar->bit_rate = st->codecpar->bit_rate;\n            st2->start_time = st->start_time;\n            st2->duration   = st->duration;\n            st2->codecpar->codec_type = AVMEDIA_TYPE_DATA;\n            st2->priv_data = ff_rm_alloc_rmstream();\n            if (!st2->priv_data)\n                return AVERROR(ENOMEM);\n        } else\n            st2 = st;\n\n        size2 = avio_rb32(pb);\n        ret = ff_rm_read_mdpr_codecdata(s, s->pb, st2, st2->priv_data,\n                                        size2, NULL);\n        if (ret < 0)\n            return ret;\n    }\n    return 0;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/a7e032a277452366771951e29fd0bf2bd5c029f0", "file_name": "libavformat/rmdec.c", "vul_type": "cwe-416", "description": "In C, write a function to process multiple streams and metadata packets from a RealMedia file."}
{"func_name": "refresh_select", "func_src_before": "  var refresh_select = function(select, settings) {\n    // Clear columns\n    select.wrapper.selected.innerHTML = \"\";\n    select.wrapper.non_selected.innerHTML = \"\";\n\n    // Add headers to columns\n    if (settings.non_selected_header && settings.selected_header) {\n      var non_selected_header = document.createElement(\"div\");\n      var selected_header = document.createElement(\"div\");\n\n      non_selected_header.className = \"header\";\n      selected_header.className = \"header\";\n\n      non_selected_header.innerText = settings.non_selected_header;\n      selected_header.innerText = settings.selected_header;\n\n      select.wrapper.non_selected.appendChild(non_selected_header);\n      select.wrapper.selected.appendChild(selected_header);\n    }\n\n    // Get search value\n    if (select.wrapper.search) {\n      var query = select.wrapper.search.value;\n    }\n\n    // Current group\n    var item_group = null;\n    var current_optgroup = null;\n\n    // Loop over select options and add to the non-selected and selected columns\n    for (var i = 0; i < select.options.length; i++) {\n      var option = select.options[i];\n\n      var value = option.value;\n      var label = option.textContent || option.innerText;\n\n      var row = document.createElement(\"a\");\n      row.tabIndex = 0;\n      row.className = \"item\";\n      row.innerHTML = label;\n      row.setAttribute(\"role\", \"button\");\n      row.setAttribute(\"data-value\", value);\n      row.setAttribute(\"multi-index\", i);\n\n      if (option.disabled) {\n        row.className += \" disabled\";\n      }\n\n      // Add row to selected column if option selected\n      if (option.selected) {\n        row.className += \" selected\";\n        var clone = row.cloneNode(true);\n        select.wrapper.selected.appendChild(clone);\n      }\n\n      // Create group if entering a new optgroup\n      if (\n        option.parentNode.nodeName == \"OPTGROUP\" &&\n        option.parentNode != current_optgroup\n      ) {\n        current_optgroup = option.parentNode;\n        item_group = document.createElement(\"div\");\n        item_group.className = \"item-group\";\n\n        if (option.parentNode.label) {\n          var groupLabel = document.createElement(\"span\");\n          groupLabel.innerHTML = option.parentNode.label;\n          groupLabel.className = \"group-label\";\n          item_group.appendChild(groupLabel);\n        }\n\n        select.wrapper.non_selected.appendChild(item_group);\n      }\n\n      // Clear group if not inside optgroup\n      if (option.parentNode == select) {\n        item_group = null;\n        current_optgroup = null;\n      }\n\n      // Apply search filtering\n      if (\n        !query ||\n        (query && label.toLowerCase().indexOf(query.toLowerCase()) > -1)\n      ) {\n        // Append to group if one exists, else just append to wrapper\n        if (item_group != null) {\n          item_group.appendChild(row);\n        } else {\n          select.wrapper.non_selected.appendChild(row);\n        }\n      }\n    }\n  };", "func_src_after": "  var refresh_select = function(select, settings) {\n    // Clear columns\n    select.wrapper.selected.innerHTML = \"\";\n    select.wrapper.non_selected.innerHTML = \"\";\n\n    // Add headers to columns\n    if (settings.non_selected_header && settings.selected_header) {\n      var non_selected_header = document.createElement(\"div\");\n      var selected_header = document.createElement(\"div\");\n\n      non_selected_header.className = \"header\";\n      selected_header.className = \"header\";\n\n      non_selected_header.innerText = settings.non_selected_header;\n      selected_header.innerText = settings.selected_header;\n\n      select.wrapper.non_selected.appendChild(non_selected_header);\n      select.wrapper.selected.appendChild(selected_header);\n    }\n\n    // Get search value\n    if (select.wrapper.search) {\n      var query = select.wrapper.search.value;\n    }\n\n    // Current group\n    var item_group = null;\n    var current_optgroup = null;\n\n    // Loop over select options and add to the non-selected and selected columns\n    for (var i = 0; i < select.options.length; i++) {\n      var option = select.options[i];\n\n      var value = option.value;\n      var label = option.textContent || option.innerText;\n\n      var row = document.createElement(\"a\");\n      row.tabIndex = 0;\n      row.className = \"item\";\n      row.innerText = label;\n      row.setAttribute(\"role\", \"button\");\n      row.setAttribute(\"data-value\", value);\n      row.setAttribute(\"multi-index\", i);\n\n      if (option.disabled) {\n        row.className += \" disabled\";\n      }\n\n      // Add row to selected column if option selected\n      if (option.selected) {\n        row.className += \" selected\";\n        var clone = row.cloneNode(true);\n        select.wrapper.selected.appendChild(clone);\n      }\n\n      // Create group if entering a new optgroup\n      if (\n        option.parentNode.nodeName == \"OPTGROUP\" &&\n        option.parentNode != current_optgroup\n      ) {\n        current_optgroup = option.parentNode;\n        item_group = document.createElement(\"div\");\n        item_group.className = \"item-group\";\n\n        if (option.parentNode.label) {\n          var groupLabel = document.createElement(\"span\");\n          groupLabel.innerHTML = option.parentNode.label;\n          groupLabel.className = \"group-label\";\n          item_group.appendChild(groupLabel);\n        }\n\n        select.wrapper.non_selected.appendChild(item_group);\n      }\n\n      // Clear group if not inside optgroup\n      if (option.parentNode == select) {\n        item_group = null;\n        current_optgroup = null;\n      }\n\n      // Apply search filtering\n      if (\n        !query ||\n        (query && label.toLowerCase().indexOf(query.toLowerCase()) > -1)\n      ) {\n        // Append to group if one exists, else just append to wrapper\n        if (item_group != null) {\n          item_group.appendChild(row);\n        } else {\n          select.wrapper.non_selected.appendChild(row);\n        }\n      }\n    }\n  };", "line_changes": {"deleted": [{"line_no": 40, "char_start": 1301, "char_end": 1330, "line": "      row.innerHTML = label;\n"}], "added": [{"line_no": 40, "char_start": 1301, "char_end": 1330, "line": "      row.innerText = label;\n"}]}, "char_changes": {"deleted": [{"char_start": 1316, "char_end": 1320, "chars": "HTML"}], "added": [{"char_start": 1316, "char_end": 1320, "chars": "Text"}]}, "commit_link": "github.com/Fabianlindfors/multi.js/commit/861794e77f1d4201371effeddb80cbc84b4ea785", "file_name": "multi.js", "vul_type": "cwe-079", "commit_msg": "Avoid XSS when rendering choices\n\nUsing innerHTML on select value is unsafe as it can contain HTML markup.", "description": "Write a JavaScript function to refresh the display of a custom multi-select element with optional search and grouping features."}
{"func_name": "_find_host_from_wwpn", "func_src_before": "    def _find_host_from_wwpn(self, connector):\n        for wwpn in connector['wwpns']:\n            ssh_cmd = 'svcinfo lsfabric -wwpn %s -delim !' % wwpn\n            out, err = self._run_ssh(ssh_cmd)\n\n            if not len(out.strip()):\n                # This WWPN is not in use\n                continue\n\n            host_lines = out.strip().split('\\n')\n            header = host_lines.pop(0).split('!')\n            self._assert_ssh_return('remote_wwpn' in header and\n                                    'name' in header,\n                                    '_find_host_from_wwpn',\n                                    ssh_cmd, out, err)\n            rmt_wwpn_idx = header.index('remote_wwpn')\n            name_idx = header.index('name')\n\n            wwpns = map(lambda x: x.split('!')[rmt_wwpn_idx], host_lines)\n\n            if wwpn in wwpns:\n                # All the wwpns will be the mapping for the same\n                # host from this WWPN-based query. Just pick\n                # the name from first line.\n                hostname = host_lines[0].split('!')[name_idx]\n                return hostname\n\n        # Didn't find a host\n        return None", "func_src_after": "    def _find_host_from_wwpn(self, connector):\n        for wwpn in connector['wwpns']:\n            ssh_cmd = ['svcinfo', 'lsfabric', '-wwpn', wwpn, '-delim', '!']\n            out, err = self._run_ssh(ssh_cmd)\n\n            if not len(out.strip()):\n                # This WWPN is not in use\n                continue\n\n            host_lines = out.strip().split('\\n')\n            header = host_lines.pop(0).split('!')\n            self._assert_ssh_return('remote_wwpn' in header and\n                                    'name' in header,\n                                    '_find_host_from_wwpn',\n                                    ssh_cmd, out, err)\n            rmt_wwpn_idx = header.index('remote_wwpn')\n            name_idx = header.index('name')\n\n            wwpns = map(lambda x: x.split('!')[rmt_wwpn_idx], host_lines)\n\n            if wwpn in wwpns:\n                # All the wwpns will be the mapping for the same\n                # host from this WWPN-based query. Just pick\n                # the name from first line.\n                hostname = host_lines[0].split('!')[name_idx]\n                return hostname\n\n        # Didn't find a host\n        return None", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "In Python, write a function to find a host's name using a WWPN (World Wide Port Name) by executing an SSH command and parsing the output."}
{"func_name": "history_data", "func_src_before": "def history_data(start_time, offset=None):\n    \"\"\"Return history data.\n\n    Arguments:\n        start_time: select history starting from this timestamp.\n        offset: number of items to skip\n    \"\"\"\n    # history atimes are stored as ints, ensure start_time is not a float\n    start_time = int(start_time)\n    hist = objreg.get('web-history')\n    if offset is not None:\n        entries = hist.entries_before(start_time, limit=1000, offset=offset)\n    else:\n        # end is 24hrs earlier than start\n        end_time = start_time - 24*60*60\n        entries = hist.entries_between(end_time, start_time)\n\n    return [{\"url\": e.url, \"title\": e.title or e.url, \"time\": e.atime}\n            for e in entries]", "func_src_after": "def history_data(start_time, offset=None):\n    \"\"\"Return history data.\n\n    Arguments:\n        start_time: select history starting from this timestamp.\n        offset: number of items to skip\n    \"\"\"\n    # history atimes are stored as ints, ensure start_time is not a float\n    start_time = int(start_time)\n    hist = objreg.get('web-history')\n    if offset is not None:\n        entries = hist.entries_before(start_time, limit=1000, offset=offset)\n    else:\n        # end is 24hrs earlier than start\n        end_time = start_time - 24*60*60\n        entries = hist.entries_between(end_time, start_time)\n\n    return [{\"url\": html.escape(e.url),\n             \"title\": html.escape(e.title) or html.escape(e.url),\n             \"time\": e.atime} for e in entries]", "commit_link": "github.com/qutebrowser/qutebrowser/commit/4c9360237f186681b1e3f2a0f30c45161cf405c7", "file_name": "qutebrowser/browser/qutescheme.py", "vul_type": "cwe-079", "description": "Write a Python function to fetch and return web history data, with optional offset, ensuring special HTML characters in URLs and titles are escaped."}
{"func_name": "avcodec_align_dimensions2", "func_src_before": "void avcodec_align_dimensions2(AVCodecContext *s, int *width, int *height,\n                               int linesize_align[AV_NUM_DATA_POINTERS])\n{\n    int i;\n    int w_align = 1;\n    int h_align = 1;\n    AVPixFmtDescriptor const *desc = av_pix_fmt_desc_get(s->pix_fmt);\n\n    if (desc) {\n        w_align = 1 << desc->log2_chroma_w;\n        h_align = 1 << desc->log2_chroma_h;\n    }\n\n    switch (s->pix_fmt) {\n    case AV_PIX_FMT_YUV420P:\n    case AV_PIX_FMT_YUYV422:\n    case AV_PIX_FMT_YVYU422:\n    case AV_PIX_FMT_UYVY422:\n    case AV_PIX_FMT_YUV422P:\n    case AV_PIX_FMT_YUV440P:\n    case AV_PIX_FMT_YUV444P:\n    case AV_PIX_FMT_GBRP:\n    case AV_PIX_FMT_GBRAP:\n    case AV_PIX_FMT_GRAY8:\n    case AV_PIX_FMT_GRAY16BE:\n    case AV_PIX_FMT_GRAY16LE:\n    case AV_PIX_FMT_YUVJ420P:\n    case AV_PIX_FMT_YUVJ422P:\n    case AV_PIX_FMT_YUVJ440P:\n    case AV_PIX_FMT_YUVJ444P:\n    case AV_PIX_FMT_YUVA420P:\n    case AV_PIX_FMT_YUVA422P:\n    case AV_PIX_FMT_YUVA444P:\n    case AV_PIX_FMT_YUV420P9LE:\n    case AV_PIX_FMT_YUV420P9BE:\n    case AV_PIX_FMT_YUV420P10LE:\n    case AV_PIX_FMT_YUV420P10BE:\n    case AV_PIX_FMT_YUV420P12LE:\n    case AV_PIX_FMT_YUV420P12BE:\n    case AV_PIX_FMT_YUV420P14LE:\n    case AV_PIX_FMT_YUV420P14BE:\n    case AV_PIX_FMT_YUV420P16LE:\n    case AV_PIX_FMT_YUV420P16BE:\n    case AV_PIX_FMT_YUVA420P9LE:\n    case AV_PIX_FMT_YUVA420P9BE:\n    case AV_PIX_FMT_YUVA420P10LE:\n    case AV_PIX_FMT_YUVA420P10BE:\n    case AV_PIX_FMT_YUVA420P16LE:\n    case AV_PIX_FMT_YUVA420P16BE:\n    case AV_PIX_FMT_YUV422P9LE:\n    case AV_PIX_FMT_YUV422P9BE:\n    case AV_PIX_FMT_YUV422P10LE:\n    case AV_PIX_FMT_YUV422P10BE:\n    case AV_PIX_FMT_YUV422P12LE:\n    case AV_PIX_FMT_YUV422P12BE:\n    case AV_PIX_FMT_YUV422P14LE:\n    case AV_PIX_FMT_YUV422P14BE:\n    case AV_PIX_FMT_YUV422P16LE:\n    case AV_PIX_FMT_YUV422P16BE:\n    case AV_PIX_FMT_YUVA422P9LE:\n    case AV_PIX_FMT_YUVA422P9BE:\n    case AV_PIX_FMT_YUVA422P10LE:\n    case AV_PIX_FMT_YUVA422P10BE:\n    case AV_PIX_FMT_YUVA422P16LE:\n    case AV_PIX_FMT_YUVA422P16BE:\n    case AV_PIX_FMT_YUV440P10LE:\n    case AV_PIX_FMT_YUV440P10BE:\n    case AV_PIX_FMT_YUV440P12LE:\n    case AV_PIX_FMT_YUV440P12BE:\n    case AV_PIX_FMT_YUV444P9LE:\n    case AV_PIX_FMT_YUV444P9BE:\n    case AV_PIX_FMT_YUV444P10LE:\n    case AV_PIX_FMT_YUV444P10BE:\n    case AV_PIX_FMT_YUV444P12LE:\n    case AV_PIX_FMT_YUV444P12BE:\n    case AV_PIX_FMT_YUV444P14LE:\n    case AV_PIX_FMT_YUV444P14BE:\n    case AV_PIX_FMT_YUV444P16LE:\n    case AV_PIX_FMT_YUV444P16BE:\n    case AV_PIX_FMT_YUVA444P9LE:\n    case AV_PIX_FMT_YUVA444P9BE:\n    case AV_PIX_FMT_YUVA444P10LE:\n    case AV_PIX_FMT_YUVA444P10BE:\n    case AV_PIX_FMT_YUVA444P16LE:\n    case AV_PIX_FMT_YUVA444P16BE:\n    case AV_PIX_FMT_GBRP9LE:\n    case AV_PIX_FMT_GBRP9BE:\n    case AV_PIX_FMT_GBRP10LE:\n    case AV_PIX_FMT_GBRP10BE:\n    case AV_PIX_FMT_GBRP12LE:\n    case AV_PIX_FMT_GBRP12BE:\n    case AV_PIX_FMT_GBRP14LE:\n    case AV_PIX_FMT_GBRP14BE:\n    case AV_PIX_FMT_GBRP16LE:\n    case AV_PIX_FMT_GBRP16BE:\n    case AV_PIX_FMT_GBRAP12LE:\n    case AV_PIX_FMT_GBRAP12BE:\n    case AV_PIX_FMT_GBRAP16LE:\n    case AV_PIX_FMT_GBRAP16BE:\n        w_align = 16; //FIXME assume 16 pixel per macroblock\n        h_align = 16 * 2; // interlaced needs 2 macroblocks height\n        break;\n    case AV_PIX_FMT_YUV411P:\n    case AV_PIX_FMT_YUVJ411P:\n    case AV_PIX_FMT_UYYVYY411:\n        w_align = 32;\n        h_align = 16 * 2;\n        break;\n    case AV_PIX_FMT_YUV410P:\n        if (s->codec_id == AV_CODEC_ID_SVQ1) {\n            w_align = 64;\n            h_align = 64;\n        }\n        break;\n    case AV_PIX_FMT_RGB555:\n        if (s->codec_id == AV_CODEC_ID_RPZA) {\n            w_align = 4;\n            h_align = 4;\n        }\n        break;\n    case AV_PIX_FMT_PAL8:\n    case AV_PIX_FMT_BGR8:\n    case AV_PIX_FMT_RGB8:\n        if (s->codec_id == AV_CODEC_ID_SMC ||\n            s->codec_id == AV_CODEC_ID_CINEPAK) {\n            w_align = 4;\n            h_align = 4;\n        }\n        if (s->codec_id == AV_CODEC_ID_JV) {\n            w_align = 8;\n            h_align = 8;\n        }\n        break;\n    case AV_PIX_FMT_BGR24:\n        if ((s->codec_id == AV_CODEC_ID_MSZH) ||\n            (s->codec_id == AV_CODEC_ID_ZLIB)) {\n            w_align = 4;\n            h_align = 4;\n        }\n        break;\n    case AV_PIX_FMT_RGB24:\n        if (s->codec_id == AV_CODEC_ID_CINEPAK) {\n            w_align = 4;\n            h_align = 4;\n        }\n        break;\n    default:\n        break;\n    }\n\n    if (s->codec_id == AV_CODEC_ID_IFF_ILBM) {\n        w_align = FFMAX(w_align, 8);\n    }\n\n    *width  = FFALIGN(*width, w_align);\n    *height = FFALIGN(*height, h_align);\n    if (s->codec_id == AV_CODEC_ID_H264 || s->lowres) {\n        // some of the optimized chroma MC reads one line too much\n        // which is also done in mpeg decoders with lowres > 0\n        *height += 2;\n\n        // H.264 uses edge emulation for out of frame motion vectors, for this\n        // it requires a temporary area large enough to hold a 21x21 block,\n        // increasing witdth ensure that the temporary area is large enough,\n        // the next rounded up width is 32\n        *width = FFMAX(*width, 32);\n    }\n\n    for (i = 0; i < 4; i++)\n        linesize_align[i] = STRIDE_ALIGN;\n}", "func_src_after": "void avcodec_align_dimensions2(AVCodecContext *s, int *width, int *height,\n                               int linesize_align[AV_NUM_DATA_POINTERS])\n{\n    int i;\n    int w_align = 1;\n    int h_align = 1;\n    AVPixFmtDescriptor const *desc = av_pix_fmt_desc_get(s->pix_fmt);\n\n    if (desc) {\n        w_align = 1 << desc->log2_chroma_w;\n        h_align = 1 << desc->log2_chroma_h;\n    }\n\n    switch (s->pix_fmt) {\n    case AV_PIX_FMT_YUV420P:\n    case AV_PIX_FMT_YUYV422:\n    case AV_PIX_FMT_YVYU422:\n    case AV_PIX_FMT_UYVY422:\n    case AV_PIX_FMT_YUV422P:\n    case AV_PIX_FMT_YUV440P:\n    case AV_PIX_FMT_YUV444P:\n    case AV_PIX_FMT_GBRP:\n    case AV_PIX_FMT_GBRAP:\n    case AV_PIX_FMT_GRAY8:\n    case AV_PIX_FMT_GRAY16BE:\n    case AV_PIX_FMT_GRAY16LE:\n    case AV_PIX_FMT_YUVJ420P:\n    case AV_PIX_FMT_YUVJ422P:\n    case AV_PIX_FMT_YUVJ440P:\n    case AV_PIX_FMT_YUVJ444P:\n    case AV_PIX_FMT_YUVA420P:\n    case AV_PIX_FMT_YUVA422P:\n    case AV_PIX_FMT_YUVA444P:\n    case AV_PIX_FMT_YUV420P9LE:\n    case AV_PIX_FMT_YUV420P9BE:\n    case AV_PIX_FMT_YUV420P10LE:\n    case AV_PIX_FMT_YUV420P10BE:\n    case AV_PIX_FMT_YUV420P12LE:\n    case AV_PIX_FMT_YUV420P12BE:\n    case AV_PIX_FMT_YUV420P14LE:\n    case AV_PIX_FMT_YUV420P14BE:\n    case AV_PIX_FMT_YUV420P16LE:\n    case AV_PIX_FMT_YUV420P16BE:\n    case AV_PIX_FMT_YUVA420P9LE:\n    case AV_PIX_FMT_YUVA420P9BE:\n    case AV_PIX_FMT_YUVA420P10LE:\n    case AV_PIX_FMT_YUVA420P10BE:\n    case AV_PIX_FMT_YUVA420P16LE:\n    case AV_PIX_FMT_YUVA420P16BE:\n    case AV_PIX_FMT_YUV422P9LE:\n    case AV_PIX_FMT_YUV422P9BE:\n    case AV_PIX_FMT_YUV422P10LE:\n    case AV_PIX_FMT_YUV422P10BE:\n    case AV_PIX_FMT_YUV422P12LE:\n    case AV_PIX_FMT_YUV422P12BE:\n    case AV_PIX_FMT_YUV422P14LE:\n    case AV_PIX_FMT_YUV422P14BE:\n    case AV_PIX_FMT_YUV422P16LE:\n    case AV_PIX_FMT_YUV422P16BE:\n    case AV_PIX_FMT_YUVA422P9LE:\n    case AV_PIX_FMT_YUVA422P9BE:\n    case AV_PIX_FMT_YUVA422P10LE:\n    case AV_PIX_FMT_YUVA422P10BE:\n    case AV_PIX_FMT_YUVA422P16LE:\n    case AV_PIX_FMT_YUVA422P16BE:\n    case AV_PIX_FMT_YUV440P10LE:\n    case AV_PIX_FMT_YUV440P10BE:\n    case AV_PIX_FMT_YUV440P12LE:\n    case AV_PIX_FMT_YUV440P12BE:\n    case AV_PIX_FMT_YUV444P9LE:\n    case AV_PIX_FMT_YUV444P9BE:\n    case AV_PIX_FMT_YUV444P10LE:\n    case AV_PIX_FMT_YUV444P10BE:\n    case AV_PIX_FMT_YUV444P12LE:\n    case AV_PIX_FMT_YUV444P12BE:\n    case AV_PIX_FMT_YUV444P14LE:\n    case AV_PIX_FMT_YUV444P14BE:\n    case AV_PIX_FMT_YUV444P16LE:\n    case AV_PIX_FMT_YUV444P16BE:\n    case AV_PIX_FMT_YUVA444P9LE:\n    case AV_PIX_FMT_YUVA444P9BE:\n    case AV_PIX_FMT_YUVA444P10LE:\n    case AV_PIX_FMT_YUVA444P10BE:\n    case AV_PIX_FMT_YUVA444P16LE:\n    case AV_PIX_FMT_YUVA444P16BE:\n    case AV_PIX_FMT_GBRP9LE:\n    case AV_PIX_FMT_GBRP9BE:\n    case AV_PIX_FMT_GBRP10LE:\n    case AV_PIX_FMT_GBRP10BE:\n    case AV_PIX_FMT_GBRP12LE:\n    case AV_PIX_FMT_GBRP12BE:\n    case AV_PIX_FMT_GBRP14LE:\n    case AV_PIX_FMT_GBRP14BE:\n    case AV_PIX_FMT_GBRP16LE:\n    case AV_PIX_FMT_GBRP16BE:\n    case AV_PIX_FMT_GBRAP12LE:\n    case AV_PIX_FMT_GBRAP12BE:\n    case AV_PIX_FMT_GBRAP16LE:\n    case AV_PIX_FMT_GBRAP16BE:\n        w_align = 16; //FIXME assume 16 pixel per macroblock\n        h_align = 16 * 2; // interlaced needs 2 macroblocks height\n        break;\n    case AV_PIX_FMT_YUV411P:\n    case AV_PIX_FMT_YUVJ411P:\n    case AV_PIX_FMT_UYYVYY411:\n        w_align = 32;\n        h_align = 16 * 2;\n        break;\n    case AV_PIX_FMT_YUV410P:\n        if (s->codec_id == AV_CODEC_ID_SVQ1) {\n            w_align = 64;\n            h_align = 64;\n        }\n        break;\n    case AV_PIX_FMT_RGB555:\n        if (s->codec_id == AV_CODEC_ID_RPZA) {\n            w_align = 4;\n            h_align = 4;\n        }\n        if (s->codec_id == AV_CODEC_ID_INTERPLAY_VIDEO) {\n            w_align = 8;\n            h_align = 8;\n        }\n        break;\n    case AV_PIX_FMT_PAL8:\n    case AV_PIX_FMT_BGR8:\n    case AV_PIX_FMT_RGB8:\n        if (s->codec_id == AV_CODEC_ID_SMC ||\n            s->codec_id == AV_CODEC_ID_CINEPAK) {\n            w_align = 4;\n            h_align = 4;\n        }\n        if (s->codec_id == AV_CODEC_ID_JV ||\n            s->codec_id == AV_CODEC_ID_INTERPLAY_VIDEO) {\n            w_align = 8;\n            h_align = 8;\n        }\n        break;\n    case AV_PIX_FMT_BGR24:\n        if ((s->codec_id == AV_CODEC_ID_MSZH) ||\n            (s->codec_id == AV_CODEC_ID_ZLIB)) {\n            w_align = 4;\n            h_align = 4;\n        }\n        break;\n    case AV_PIX_FMT_RGB24:\n        if (s->codec_id == AV_CODEC_ID_CINEPAK) {\n            w_align = 4;\n            h_align = 4;\n        }\n        break;\n    default:\n        break;\n    }\n\n    if (s->codec_id == AV_CODEC_ID_IFF_ILBM) {\n        w_align = FFMAX(w_align, 8);\n    }\n\n    *width  = FFALIGN(*width, w_align);\n    *height = FFALIGN(*height, h_align);\n    if (s->codec_id == AV_CODEC_ID_H264 || s->lowres) {\n        // some of the optimized chroma MC reads one line too much\n        // which is also done in mpeg decoders with lowres > 0\n        *height += 2;\n\n        // H.264 uses edge emulation for out of frame motion vectors, for this\n        // it requires a temporary area large enough to hold a 21x21 block,\n        // increasing witdth ensure that the temporary area is large enough,\n        // the next rounded up width is 32\n        *width = FFMAX(*width, 32);\n    }\n\n    for (i = 0; i < 4; i++)\n        linesize_align[i] = STRIDE_ALIGN;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/2080bc33717955a0e4268e738acf8c1eeddbf8cb", "file_name": "libavcodec/utils.c", "vul_type": "cwe-787", "description": "Write a C function named `avcodec_align_dimensions2` that adjusts the width and height of a video frame based on the codec context and pixel format."}
{"func_name": "dnxhd_decode_header", "func_src_before": "static int dnxhd_decode_header(DNXHDContext *ctx, AVFrame *frame,\n                               const uint8_t *buf, int buf_size,\n                               int first_field)\n{\n    int i, cid, ret;\n    int old_bit_depth = ctx->bit_depth, bitdepth;\n    uint64_t header_prefix;\n    if (buf_size < 0x280) {\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"buffer too small (%d < 640).\\n\", buf_size);\n        return AVERROR_INVALIDDATA;\n    }\n\n    header_prefix = ff_dnxhd_parse_header_prefix(buf);\n    if (header_prefix == 0) {\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"unknown header 0x%02X 0x%02X 0x%02X 0x%02X 0x%02X\\n\",\n               buf[0], buf[1], buf[2], buf[3], buf[4]);\n        return AVERROR_INVALIDDATA;\n    }\n    if (buf[5] & 2) { /* interlaced */\n        ctx->cur_field = buf[5] & 1;\n        frame->interlaced_frame = 1;\n        frame->top_field_first  = first_field ^ ctx->cur_field;\n        av_log(ctx->avctx, AV_LOG_DEBUG,\n               \"interlaced %d, cur field %d\\n\", buf[5] & 3, ctx->cur_field);\n    } else {\n        ctx->cur_field = 0;\n    }\n    ctx->mbaff = (buf[0x6] >> 5) & 1;\n\n    ctx->height = AV_RB16(buf + 0x18);\n    ctx->width  = AV_RB16(buf + 0x1a);\n\n    switch(buf[0x21] >> 5) {\n    case 1: bitdepth = 8; break;\n    case 2: bitdepth = 10; break;\n    case 3: bitdepth = 12; break;\n    default:\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"Unknown bitdepth indicator (%d)\\n\", buf[0x21] >> 5);\n        return AVERROR_INVALIDDATA;\n    }\n\n    cid = AV_RB32(buf + 0x28);\n\n    ctx->avctx->profile = dnxhd_get_profile(cid);\n\n    if ((ret = dnxhd_init_vlc(ctx, cid, bitdepth)) < 0)\n        return ret;\n    if (ctx->mbaff && ctx->cid_table->cid != 1260)\n        av_log(ctx->avctx, AV_LOG_WARNING,\n               \"Adaptive MB interlace flag in an unsupported profile.\\n\");\n\n    ctx->act = buf[0x2C] & 7;\n    if (ctx->act && ctx->cid_table->cid != 1256 && ctx->cid_table->cid != 1270)\n        av_log(ctx->avctx, AV_LOG_WARNING,\n               \"Adaptive color transform in an unsupported profile.\\n\");\n\n    ctx->is_444 = (buf[0x2C] >> 6) & 1;\n    if (ctx->is_444) {\n        if (bitdepth == 8) {\n            avpriv_request_sample(ctx->avctx, \"4:4:4 8 bits\");\n            return AVERROR_INVALIDDATA;\n        } else if (bitdepth == 10) {\n            ctx->decode_dct_block = dnxhd_decode_dct_block_10_444;\n            ctx->pix_fmt = ctx->act ? AV_PIX_FMT_YUV444P10\n                                    : AV_PIX_FMT_GBRP10;\n        } else {\n            ctx->decode_dct_block = dnxhd_decode_dct_block_12_444;\n            ctx->pix_fmt = ctx->act ? AV_PIX_FMT_YUV444P12\n                                    : AV_PIX_FMT_GBRP12;\n        }\n    } else if (bitdepth == 12) {\n        ctx->decode_dct_block = dnxhd_decode_dct_block_12;\n        ctx->pix_fmt = AV_PIX_FMT_YUV422P12;\n    } else if (bitdepth == 10) {\n        if (ctx->avctx->profile == FF_PROFILE_DNXHR_HQX)\n            ctx->decode_dct_block = dnxhd_decode_dct_block_10_444;\n        else\n            ctx->decode_dct_block = dnxhd_decode_dct_block_10;\n        ctx->pix_fmt = AV_PIX_FMT_YUV422P10;\n    } else {\n        ctx->decode_dct_block = dnxhd_decode_dct_block_8;\n        ctx->pix_fmt = AV_PIX_FMT_YUV422P;\n    }\n\n    ctx->avctx->bits_per_raw_sample = ctx->bit_depth = bitdepth;\n    if (ctx->bit_depth != old_bit_depth) {\n        ff_blockdsp_init(&ctx->bdsp, ctx->avctx);\n        ff_idctdsp_init(&ctx->idsp, ctx->avctx);\n        ff_init_scantable(ctx->idsp.idct_permutation, &ctx->scantable,\n                          ff_zigzag_direct);\n    }\n\n    // make sure profile size constraints are respected\n    // DNx100 allows 1920->1440 and 1280->960 subsampling\n    if (ctx->width != ctx->cid_table->width &&\n        ctx->cid_table->width != DNXHD_VARIABLE) {\n        av_reduce(&ctx->avctx->sample_aspect_ratio.num,\n                  &ctx->avctx->sample_aspect_ratio.den,\n                  ctx->width, ctx->cid_table->width, 255);\n        ctx->width = ctx->cid_table->width;\n    }\n\n    if (buf_size < ctx->cid_table->coding_unit_size) {\n        av_log(ctx->avctx, AV_LOG_ERROR, \"incorrect frame size (%d < %u).\\n\",\n               buf_size, ctx->cid_table->coding_unit_size);\n        return AVERROR_INVALIDDATA;\n    }\n\n    ctx->mb_width  = (ctx->width + 15)>> 4;\n    ctx->mb_height = AV_RB16(buf + 0x16c);\n\n    if ((ctx->height + 15) >> 4 == ctx->mb_height && frame->interlaced_frame)\n        ctx->height <<= 1;\n\n    av_log(ctx->avctx, AV_LOG_VERBOSE, \"%dx%d, 4:%s %d bits, MBAFF=%d ACT=%d\\n\",\n           ctx->width, ctx->height, ctx->is_444 ? \"4:4\" : \"2:2\",\n           ctx->bit_depth, ctx->mbaff, ctx->act);\n\n    // Newer format supports variable mb_scan_index sizes\n    if (ctx->mb_height > 68 && ff_dnxhd_check_header_prefix_hr(header_prefix)) {\n        ctx->data_offset = 0x170 + (ctx->mb_height << 2);\n    } else {\n        if (ctx->mb_height > 68 ||\n            (ctx->mb_height << frame->interlaced_frame) > (ctx->height + 15) >> 4) {\n            av_log(ctx->avctx, AV_LOG_ERROR,\n                   \"mb height too big: %d\\n\", ctx->mb_height);\n            return AVERROR_INVALIDDATA;\n        }\n        ctx->data_offset = 0x280;\n    }\n\n    if (buf_size < ctx->data_offset) {\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"buffer too small (%d < %d).\\n\", buf_size, ctx->data_offset);\n        return AVERROR_INVALIDDATA;\n    }\n\n    if (ctx->mb_height > FF_ARRAY_ELEMS(ctx->mb_scan_index)) {\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"mb_height too big (%d > %\"SIZE_SPECIFIER\").\\n\", ctx->mb_height, FF_ARRAY_ELEMS(ctx->mb_scan_index));\n        return AVERROR_INVALIDDATA;\n    }\n\n    for (i = 0; i < ctx->mb_height; i++) {\n        ctx->mb_scan_index[i] = AV_RB32(buf + 0x170 + (i << 2));\n        ff_dlog(ctx->avctx, \"mb scan index %d, pos %d: %\"PRIu32\"\\n\",\n                i, 0x170 + (i << 2), ctx->mb_scan_index[i]);\n        if (buf_size - ctx->data_offset < ctx->mb_scan_index[i]) {\n            av_log(ctx->avctx, AV_LOG_ERROR,\n                   \"invalid mb scan index (%\"PRIu32\" vs %u).\\n\",\n                   ctx->mb_scan_index[i], buf_size - ctx->data_offset);\n            return AVERROR_INVALIDDATA;\n        }\n    }\n\n    return 0;\n}", "func_src_after": "static int dnxhd_decode_header(DNXHDContext *ctx, AVFrame *frame,\n                               const uint8_t *buf, int buf_size,\n                               int first_field)\n{\n    int i, cid, ret;\n    int old_bit_depth = ctx->bit_depth, bitdepth;\n    uint64_t header_prefix;\n    if (buf_size < 0x280) {\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"buffer too small (%d < 640).\\n\", buf_size);\n        return AVERROR_INVALIDDATA;\n    }\n\n    header_prefix = ff_dnxhd_parse_header_prefix(buf);\n    if (header_prefix == 0) {\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"unknown header 0x%02X 0x%02X 0x%02X 0x%02X 0x%02X\\n\",\n               buf[0], buf[1], buf[2], buf[3], buf[4]);\n        return AVERROR_INVALIDDATA;\n    }\n    if (buf[5] & 2) { /* interlaced */\n        ctx->cur_field = buf[5] & 1;\n        frame->interlaced_frame = 1;\n        frame->top_field_first  = first_field ^ ctx->cur_field;\n        av_log(ctx->avctx, AV_LOG_DEBUG,\n               \"interlaced %d, cur field %d\\n\", buf[5] & 3, ctx->cur_field);\n    } else {\n        ctx->cur_field = 0;\n    }\n    ctx->mbaff = (buf[0x6] >> 5) & 1;\n\n    ctx->height = AV_RB16(buf + 0x18);\n    ctx->width  = AV_RB16(buf + 0x1a);\n\n    switch(buf[0x21] >> 5) {\n    case 1: bitdepth = 8; break;\n    case 2: bitdepth = 10; break;\n    case 3: bitdepth = 12; break;\n    default:\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"Unknown bitdepth indicator (%d)\\n\", buf[0x21] >> 5);\n        return AVERROR_INVALIDDATA;\n    }\n\n    cid = AV_RB32(buf + 0x28);\n\n    ctx->avctx->profile = dnxhd_get_profile(cid);\n\n    if ((ret = dnxhd_init_vlc(ctx, cid, bitdepth)) < 0)\n        return ret;\n    if (ctx->mbaff && ctx->cid_table->cid != 1260)\n        av_log(ctx->avctx, AV_LOG_WARNING,\n               \"Adaptive MB interlace flag in an unsupported profile.\\n\");\n\n    ctx->act = buf[0x2C] & 7;\n    if (ctx->act && ctx->cid_table->cid != 1256 && ctx->cid_table->cid != 1270)\n        av_log(ctx->avctx, AV_LOG_WARNING,\n               \"Adaptive color transform in an unsupported profile.\\n\");\n\n    ctx->is_444 = (buf[0x2C] >> 6) & 1;\n    if (ctx->is_444) {\n        if (bitdepth == 8) {\n            avpriv_request_sample(ctx->avctx, \"4:4:4 8 bits\");\n            return AVERROR_INVALIDDATA;\n        } else if (bitdepth == 10) {\n            ctx->decode_dct_block = dnxhd_decode_dct_block_10_444;\n            ctx->pix_fmt = ctx->act ? AV_PIX_FMT_YUV444P10\n                                    : AV_PIX_FMT_GBRP10;\n        } else {\n            ctx->decode_dct_block = dnxhd_decode_dct_block_12_444;\n            ctx->pix_fmt = ctx->act ? AV_PIX_FMT_YUV444P12\n                                    : AV_PIX_FMT_GBRP12;\n        }\n    } else if (bitdepth == 12) {\n        ctx->decode_dct_block = dnxhd_decode_dct_block_12;\n        ctx->pix_fmt = AV_PIX_FMT_YUV422P12;\n    } else if (bitdepth == 10) {\n        if (ctx->avctx->profile == FF_PROFILE_DNXHR_HQX)\n            ctx->decode_dct_block = dnxhd_decode_dct_block_10_444;\n        else\n            ctx->decode_dct_block = dnxhd_decode_dct_block_10;\n        ctx->pix_fmt = AV_PIX_FMT_YUV422P10;\n    } else {\n        ctx->decode_dct_block = dnxhd_decode_dct_block_8;\n        ctx->pix_fmt = AV_PIX_FMT_YUV422P;\n    }\n\n    ctx->avctx->bits_per_raw_sample = ctx->bit_depth = bitdepth;\n    if (ctx->bit_depth != old_bit_depth) {\n        ff_blockdsp_init(&ctx->bdsp, ctx->avctx);\n        ff_idctdsp_init(&ctx->idsp, ctx->avctx);\n        ff_init_scantable(ctx->idsp.idct_permutation, &ctx->scantable,\n                          ff_zigzag_direct);\n    }\n\n    // make sure profile size constraints are respected\n    // DNx100 allows 1920->1440 and 1280->960 subsampling\n    if (ctx->width != ctx->cid_table->width &&\n        ctx->cid_table->width != DNXHD_VARIABLE) {\n        av_reduce(&ctx->avctx->sample_aspect_ratio.num,\n                  &ctx->avctx->sample_aspect_ratio.den,\n                  ctx->width, ctx->cid_table->width, 255);\n        ctx->width = ctx->cid_table->width;\n    }\n\n    if (buf_size < ctx->cid_table->coding_unit_size) {\n        av_log(ctx->avctx, AV_LOG_ERROR, \"incorrect frame size (%d < %u).\\n\",\n               buf_size, ctx->cid_table->coding_unit_size);\n        return AVERROR_INVALIDDATA;\n    }\n\n    ctx->mb_width  = (ctx->width + 15)>> 4;\n    ctx->mb_height = AV_RB16(buf + 0x16c);\n\n    if ((ctx->height + 15) >> 4 == ctx->mb_height && frame->interlaced_frame)\n        ctx->height <<= 1;\n\n    av_log(ctx->avctx, AV_LOG_VERBOSE, \"%dx%d, 4:%s %d bits, MBAFF=%d ACT=%d\\n\",\n           ctx->width, ctx->height, ctx->is_444 ? \"4:4\" : \"2:2\",\n           ctx->bit_depth, ctx->mbaff, ctx->act);\n\n    // Newer format supports variable mb_scan_index sizes\n    if (ctx->mb_height > 68 && ff_dnxhd_check_header_prefix_hr(header_prefix)) {\n        ctx->data_offset = 0x170 + (ctx->mb_height << 2);\n    } else {\n        if (ctx->mb_height > 68) {\n            av_log(ctx->avctx, AV_LOG_ERROR,\n                   \"mb height too big: %d\\n\", ctx->mb_height);\n            return AVERROR_INVALIDDATA;\n        }\n        ctx->data_offset = 0x280;\n    }\n    if ((ctx->mb_height << frame->interlaced_frame) > (ctx->height + 15) >> 4) {\n        av_log(ctx->avctx, AV_LOG_ERROR,\n                \"mb height too big: %d\\n\", ctx->mb_height);\n        return AVERROR_INVALIDDATA;\n    }\n\n    if (buf_size < ctx->data_offset) {\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"buffer too small (%d < %d).\\n\", buf_size, ctx->data_offset);\n        return AVERROR_INVALIDDATA;\n    }\n\n    if (ctx->mb_height > FF_ARRAY_ELEMS(ctx->mb_scan_index)) {\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"mb_height too big (%d > %\"SIZE_SPECIFIER\").\\n\", ctx->mb_height, FF_ARRAY_ELEMS(ctx->mb_scan_index));\n        return AVERROR_INVALIDDATA;\n    }\n\n    for (i = 0; i < ctx->mb_height; i++) {\n        ctx->mb_scan_index[i] = AV_RB32(buf + 0x170 + (i << 2));\n        ff_dlog(ctx->avctx, \"mb scan index %d, pos %d: %\"PRIu32\"\\n\",\n                i, 0x170 + (i << 2), ctx->mb_scan_index[i]);\n        if (buf_size - ctx->data_offset < ctx->mb_scan_index[i]) {\n            av_log(ctx->avctx, AV_LOG_ERROR,\n                   \"invalid mb scan index (%\"PRIu32\" vs %u).\\n\",\n                   ctx->mb_scan_index[i], buf_size - ctx->data_offset);\n            return AVERROR_INVALIDDATA;\n        }\n    }\n\n    return 0;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/296debd213bd6dce7647cedd34eb64e5b94cdc92", "file_name": "libavcodec/dnxhddec.c", "vul_type": "cwe-125", "description": "Write a C function named `dnxhd_decode_header` that decodes the header of a DNxHD video frame."}
{"func_name": "deleteKey", "func_src_before": "def deleteKey(client):\n\t\"\"\"Deletes the specified key.\n\tReturns an error if the key doesn't exist\n\t\"\"\"\n\tglobal BAD_REQUEST\n\tglobal NOT_FOUND\n\n\tvalidateClient(client)\n\n\tclient_pub_key = loadClientRSAKey(client)\n\ttoken_data = decodeRequestToken(request.data, client_pub_key)\n\n\tif re.search('[^a-zA-Z0-9]', token_data['key']):\n\t\traise FoxlockError(BAD_REQUEST, 'Invalid key requested')\n\n\ttry:\n\t\tos.remove('keys/%s/%s.key' % (client, token_data['key']))\n\texcept FileNotFoundError:\n\t\traise FoxlockError(NOT_FOUND, \"Key '%s' not found\" % token_data['key'])\n\n\treturn \"Key '%s' successfully deleted\" % token_data['key']", "func_src_after": "def deleteKey(client):\n\t\"\"\"Deletes the specified key.\n\tReturns an error if the key doesn't exist\n\t\"\"\"\n\tglobal NOT_FOUND\n\n\tvalidateClient(client)\n\tclient_pub_key = loadClientRSAKey(client)\n\ttoken_data = decodeRequestToken(request.data, client_pub_key)\n\tvalidateKeyName(token_data['key'])\n\n\ttry:\n\t\tos.remove('keys/%s/%s.key' % (client, token_data['key']))\n\texcept FileNotFoundError:\n\t\traise FoxlockError(NOT_FOUND, \"Key '%s' not found\" % token_data['key'])\n\n\treturn \"Key '%s' successfully deleted\" % token_data['key']", "commit_link": "github.com/Mimickal/FoxLock/commit/7c665e556987f4e2c1a75e143a1e80ae066ad833", "file_name": "impl.py", "vul_type": "cwe-022", "description": "Write a Python function named `deleteKey` that removes a client's key file and handles the case where the key does not exist."}
{"func_name": "futex_requeue", "func_src_before": "static int futex_requeue(u32 __user *uaddr1, unsigned int flags,\n\t\t\t u32 __user *uaddr2, int nr_wake, int nr_requeue,\n\t\t\t u32 *cmpval, int requeue_pi)\n{\n\tunion futex_key key1 = FUTEX_KEY_INIT, key2 = FUTEX_KEY_INIT;\n\tint drop_count = 0, task_count = 0, ret;\n\tstruct futex_pi_state *pi_state = NULL;\n\tstruct futex_hash_bucket *hb1, *hb2;\n\tstruct futex_q *this, *next;\n\tDEFINE_WAKE_Q(wake_q);\n\n\t/*\n\t * When PI not supported: return -ENOSYS if requeue_pi is true,\n\t * consequently the compiler knows requeue_pi is always false past\n\t * this point which will optimize away all the conditional code\n\t * further down.\n\t */\n\tif (!IS_ENABLED(CONFIG_FUTEX_PI) && requeue_pi)\n\t\treturn -ENOSYS;\n\n\tif (requeue_pi) {\n\t\t/*\n\t\t * Requeue PI only works on two distinct uaddrs. This\n\t\t * check is only valid for private futexes. See below.\n\t\t */\n\t\tif (uaddr1 == uaddr2)\n\t\t\treturn -EINVAL;\n\n\t\t/*\n\t\t * requeue_pi requires a pi_state, try to allocate it now\n\t\t * without any locks in case it fails.\n\t\t */\n\t\tif (refill_pi_state_cache())\n\t\t\treturn -ENOMEM;\n\t\t/*\n\t\t * requeue_pi must wake as many tasks as it can, up to nr_wake\n\t\t * + nr_requeue, since it acquires the rt_mutex prior to\n\t\t * returning to userspace, so as to not leave the rt_mutex with\n\t\t * waiters and no owner.  However, second and third wake-ups\n\t\t * cannot be predicted as they involve race conditions with the\n\t\t * first wake and a fault while looking up the pi_state.  Both\n\t\t * pthread_cond_signal() and pthread_cond_broadcast() should\n\t\t * use nr_wake=1.\n\t\t */\n\t\tif (nr_wake != 1)\n\t\t\treturn -EINVAL;\n\t}\n\nretry:\n\tret = get_futex_key(uaddr1, flags & FLAGS_SHARED, &key1, VERIFY_READ);\n\tif (unlikely(ret != 0))\n\t\tgoto out;\n\tret = get_futex_key(uaddr2, flags & FLAGS_SHARED, &key2,\n\t\t\t    requeue_pi ? VERIFY_WRITE : VERIFY_READ);\n\tif (unlikely(ret != 0))\n\t\tgoto out_put_key1;\n\n\t/*\n\t * The check above which compares uaddrs is not sufficient for\n\t * shared futexes. We need to compare the keys:\n\t */\n\tif (requeue_pi && match_futex(&key1, &key2)) {\n\t\tret = -EINVAL;\n\t\tgoto out_put_keys;\n\t}\n\n\thb1 = hash_futex(&key1);\n\thb2 = hash_futex(&key2);\n\nretry_private:\n\thb_waiters_inc(hb2);\n\tdouble_lock_hb(hb1, hb2);\n\n\tif (likely(cmpval != NULL)) {\n\t\tu32 curval;\n\n\t\tret = get_futex_value_locked(&curval, uaddr1);\n\n\t\tif (unlikely(ret)) {\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\thb_waiters_dec(hb2);\n\n\t\t\tret = get_user(curval, uaddr1);\n\t\t\tif (ret)\n\t\t\t\tgoto out_put_keys;\n\n\t\t\tif (!(flags & FLAGS_SHARED))\n\t\t\t\tgoto retry_private;\n\n\t\t\tput_futex_key(&key2);\n\t\t\tput_futex_key(&key1);\n\t\t\tgoto retry;\n\t\t}\n\t\tif (curval != *cmpval) {\n\t\t\tret = -EAGAIN;\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tif (requeue_pi && (task_count - nr_wake < nr_requeue)) {\n\t\t/*\n\t\t * Attempt to acquire uaddr2 and wake the top waiter. If we\n\t\t * intend to requeue waiters, force setting the FUTEX_WAITERS\n\t\t * bit.  We force this here where we are able to easily handle\n\t\t * faults rather in the requeue loop below.\n\t\t */\n\t\tret = futex_proxy_trylock_atomic(uaddr2, hb1, hb2, &key1,\n\t\t\t\t\t\t &key2, &pi_state, nr_requeue);\n\n\t\t/*\n\t\t * At this point the top_waiter has either taken uaddr2 or is\n\t\t * waiting on it.  If the former, then the pi_state will not\n\t\t * exist yet, look it up one more time to ensure we have a\n\t\t * reference to it. If the lock was taken, ret contains the\n\t\t * vpid of the top waiter task.\n\t\t * If the lock was not taken, we have pi_state and an initial\n\t\t * refcount on it. In case of an error we have nothing.\n\t\t */\n\t\tif (ret > 0) {\n\t\t\tWARN_ON(pi_state);\n\t\t\tdrop_count++;\n\t\t\ttask_count++;\n\t\t\t/*\n\t\t\t * If we acquired the lock, then the user space value\n\t\t\t * of uaddr2 should be vpid. It cannot be changed by\n\t\t\t * the top waiter as it is blocked on hb2 lock if it\n\t\t\t * tries to do so. If something fiddled with it behind\n\t\t\t * our back the pi state lookup might unearth it. So\n\t\t\t * we rather use the known value than rereading and\n\t\t\t * handing potential crap to lookup_pi_state.\n\t\t\t *\n\t\t\t * If that call succeeds then we have pi_state and an\n\t\t\t * initial refcount on it.\n\t\t\t */\n\t\t\tret = lookup_pi_state(uaddr2, ret, hb2, &key2, &pi_state);\n\t\t}\n\n\t\tswitch (ret) {\n\t\tcase 0:\n\t\t\t/* We hold a reference on the pi state. */\n\t\t\tbreak;\n\n\t\t\t/* If the above failed, then pi_state is NULL */\n\t\tcase -EFAULT:\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\thb_waiters_dec(hb2);\n\t\t\tput_futex_key(&key2);\n\t\t\tput_futex_key(&key1);\n\t\t\tret = fault_in_user_writeable(uaddr2);\n\t\t\tif (!ret)\n\t\t\t\tgoto retry;\n\t\t\tgoto out;\n\t\tcase -EAGAIN:\n\t\t\t/*\n\t\t\t * Two reasons for this:\n\t\t\t * - Owner is exiting and we just wait for the\n\t\t\t *   exit to complete.\n\t\t\t * - The user space value changed.\n\t\t\t */\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\thb_waiters_dec(hb2);\n\t\t\tput_futex_key(&key2);\n\t\t\tput_futex_key(&key1);\n\t\t\tcond_resched();\n\t\t\tgoto retry;\n\t\tdefault:\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tplist_for_each_entry_safe(this, next, &hb1->chain, list) {\n\t\tif (task_count - nr_wake >= nr_requeue)\n\t\t\tbreak;\n\n\t\tif (!match_futex(&this->key, &key1))\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * FUTEX_WAIT_REQEUE_PI and FUTEX_CMP_REQUEUE_PI should always\n\t\t * be paired with each other and no other futex ops.\n\t\t *\n\t\t * We should never be requeueing a futex_q with a pi_state,\n\t\t * which is awaiting a futex_unlock_pi().\n\t\t */\n\t\tif ((requeue_pi && !this->rt_waiter) ||\n\t\t    (!requeue_pi && this->rt_waiter) ||\n\t\t    this->pi_state) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Wake nr_wake waiters.  For requeue_pi, if we acquired the\n\t\t * lock, we already woke the top_waiter.  If not, it will be\n\t\t * woken by futex_unlock_pi().\n\t\t */\n\t\tif (++task_count <= nr_wake && !requeue_pi) {\n\t\t\tmark_wake_futex(&wake_q, this);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Ensure we requeue to the expected futex for requeue_pi. */\n\t\tif (requeue_pi && !match_futex(this->requeue_pi_key, &key2)) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Requeue nr_requeue waiters and possibly one more in the case\n\t\t * of requeue_pi if we couldn't acquire the lock atomically.\n\t\t */\n\t\tif (requeue_pi) {\n\t\t\t/*\n\t\t\t * Prepare the waiter to take the rt_mutex. Take a\n\t\t\t * refcount on the pi_state and store the pointer in\n\t\t\t * the futex_q object of the waiter.\n\t\t\t */\n\t\t\tget_pi_state(pi_state);\n\t\t\tthis->pi_state = pi_state;\n\t\t\tret = rt_mutex_start_proxy_lock(&pi_state->pi_mutex,\n\t\t\t\t\t\t\tthis->rt_waiter,\n\t\t\t\t\t\t\tthis->task);\n\t\t\tif (ret == 1) {\n\t\t\t\t/*\n\t\t\t\t * We got the lock. We do neither drop the\n\t\t\t\t * refcount on pi_state nor clear\n\t\t\t\t * this->pi_state because the waiter needs the\n\t\t\t\t * pi_state for cleaning up the user space\n\t\t\t\t * value. It will drop the refcount after\n\t\t\t\t * doing so.\n\t\t\t\t */\n\t\t\t\trequeue_pi_wake_futex(this, &key2, hb2);\n\t\t\t\tdrop_count++;\n\t\t\t\tcontinue;\n\t\t\t} else if (ret) {\n\t\t\t\t/*\n\t\t\t\t * rt_mutex_start_proxy_lock() detected a\n\t\t\t\t * potential deadlock when we tried to queue\n\t\t\t\t * that waiter. Drop the pi_state reference\n\t\t\t\t * which we took above and remove the pointer\n\t\t\t\t * to the state from the waiters futex_q\n\t\t\t\t * object.\n\t\t\t\t */\n\t\t\t\tthis->pi_state = NULL;\n\t\t\t\tput_pi_state(pi_state);\n\t\t\t\t/*\n\t\t\t\t * We stop queueing more waiters and let user\n\t\t\t\t * space deal with the mess.\n\t\t\t\t */\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\trequeue_futex(this, hb1, hb2, &key2);\n\t\tdrop_count++;\n\t}\n\n\t/*\n\t * We took an extra initial reference to the pi_state either\n\t * in futex_proxy_trylock_atomic() or in lookup_pi_state(). We\n\t * need to drop it here again.\n\t */\n\tput_pi_state(pi_state);\n\nout_unlock:\n\tdouble_unlock_hb(hb1, hb2);\n\twake_up_q(&wake_q);\n\thb_waiters_dec(hb2);\n\n\t/*\n\t * drop_futex_key_refs() must be called outside the spinlocks. During\n\t * the requeue we moved futex_q's from the hash bucket at key1 to the\n\t * one at key2 and updated their key pointer.  We no longer need to\n\t * hold the references to key1.\n\t */\n\twhile (--drop_count >= 0)\n\t\tdrop_futex_key_refs(&key1);\n\nout_put_keys:\n\tput_futex_key(&key2);\nout_put_key1:\n\tput_futex_key(&key1);\nout:\n\treturn ret ? ret : task_count;\n}", "func_src_after": "static int futex_requeue(u32 __user *uaddr1, unsigned int flags,\n\t\t\t u32 __user *uaddr2, int nr_wake, int nr_requeue,\n\t\t\t u32 *cmpval, int requeue_pi)\n{\n\tunion futex_key key1 = FUTEX_KEY_INIT, key2 = FUTEX_KEY_INIT;\n\tint drop_count = 0, task_count = 0, ret;\n\tstruct futex_pi_state *pi_state = NULL;\n\tstruct futex_hash_bucket *hb1, *hb2;\n\tstruct futex_q *this, *next;\n\tDEFINE_WAKE_Q(wake_q);\n\n\tif (nr_wake < 0 || nr_requeue < 0)\n\t\treturn -EINVAL;\n\n\t/*\n\t * When PI not supported: return -ENOSYS if requeue_pi is true,\n\t * consequently the compiler knows requeue_pi is always false past\n\t * this point which will optimize away all the conditional code\n\t * further down.\n\t */\n\tif (!IS_ENABLED(CONFIG_FUTEX_PI) && requeue_pi)\n\t\treturn -ENOSYS;\n\n\tif (requeue_pi) {\n\t\t/*\n\t\t * Requeue PI only works on two distinct uaddrs. This\n\t\t * check is only valid for private futexes. See below.\n\t\t */\n\t\tif (uaddr1 == uaddr2)\n\t\t\treturn -EINVAL;\n\n\t\t/*\n\t\t * requeue_pi requires a pi_state, try to allocate it now\n\t\t * without any locks in case it fails.\n\t\t */\n\t\tif (refill_pi_state_cache())\n\t\t\treturn -ENOMEM;\n\t\t/*\n\t\t * requeue_pi must wake as many tasks as it can, up to nr_wake\n\t\t * + nr_requeue, since it acquires the rt_mutex prior to\n\t\t * returning to userspace, so as to not leave the rt_mutex with\n\t\t * waiters and no owner.  However, second and third wake-ups\n\t\t * cannot be predicted as they involve race conditions with the\n\t\t * first wake and a fault while looking up the pi_state.  Both\n\t\t * pthread_cond_signal() and pthread_cond_broadcast() should\n\t\t * use nr_wake=1.\n\t\t */\n\t\tif (nr_wake != 1)\n\t\t\treturn -EINVAL;\n\t}\n\nretry:\n\tret = get_futex_key(uaddr1, flags & FLAGS_SHARED, &key1, VERIFY_READ);\n\tif (unlikely(ret != 0))\n\t\tgoto out;\n\tret = get_futex_key(uaddr2, flags & FLAGS_SHARED, &key2,\n\t\t\t    requeue_pi ? VERIFY_WRITE : VERIFY_READ);\n\tif (unlikely(ret != 0))\n\t\tgoto out_put_key1;\n\n\t/*\n\t * The check above which compares uaddrs is not sufficient for\n\t * shared futexes. We need to compare the keys:\n\t */\n\tif (requeue_pi && match_futex(&key1, &key2)) {\n\t\tret = -EINVAL;\n\t\tgoto out_put_keys;\n\t}\n\n\thb1 = hash_futex(&key1);\n\thb2 = hash_futex(&key2);\n\nretry_private:\n\thb_waiters_inc(hb2);\n\tdouble_lock_hb(hb1, hb2);\n\n\tif (likely(cmpval != NULL)) {\n\t\tu32 curval;\n\n\t\tret = get_futex_value_locked(&curval, uaddr1);\n\n\t\tif (unlikely(ret)) {\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\thb_waiters_dec(hb2);\n\n\t\t\tret = get_user(curval, uaddr1);\n\t\t\tif (ret)\n\t\t\t\tgoto out_put_keys;\n\n\t\t\tif (!(flags & FLAGS_SHARED))\n\t\t\t\tgoto retry_private;\n\n\t\t\tput_futex_key(&key2);\n\t\t\tput_futex_key(&key1);\n\t\t\tgoto retry;\n\t\t}\n\t\tif (curval != *cmpval) {\n\t\t\tret = -EAGAIN;\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tif (requeue_pi && (task_count - nr_wake < nr_requeue)) {\n\t\t/*\n\t\t * Attempt to acquire uaddr2 and wake the top waiter. If we\n\t\t * intend to requeue waiters, force setting the FUTEX_WAITERS\n\t\t * bit.  We force this here where we are able to easily handle\n\t\t * faults rather in the requeue loop below.\n\t\t */\n\t\tret = futex_proxy_trylock_atomic(uaddr2, hb1, hb2, &key1,\n\t\t\t\t\t\t &key2, &pi_state, nr_requeue);\n\n\t\t/*\n\t\t * At this point the top_waiter has either taken uaddr2 or is\n\t\t * waiting on it.  If the former, then the pi_state will not\n\t\t * exist yet, look it up one more time to ensure we have a\n\t\t * reference to it. If the lock was taken, ret contains the\n\t\t * vpid of the top waiter task.\n\t\t * If the lock was not taken, we have pi_state and an initial\n\t\t * refcount on it. In case of an error we have nothing.\n\t\t */\n\t\tif (ret > 0) {\n\t\t\tWARN_ON(pi_state);\n\t\t\tdrop_count++;\n\t\t\ttask_count++;\n\t\t\t/*\n\t\t\t * If we acquired the lock, then the user space value\n\t\t\t * of uaddr2 should be vpid. It cannot be changed by\n\t\t\t * the top waiter as it is blocked on hb2 lock if it\n\t\t\t * tries to do so. If something fiddled with it behind\n\t\t\t * our back the pi state lookup might unearth it. So\n\t\t\t * we rather use the known value than rereading and\n\t\t\t * handing potential crap to lookup_pi_state.\n\t\t\t *\n\t\t\t * If that call succeeds then we have pi_state and an\n\t\t\t * initial refcount on it.\n\t\t\t */\n\t\t\tret = lookup_pi_state(uaddr2, ret, hb2, &key2, &pi_state);\n\t\t}\n\n\t\tswitch (ret) {\n\t\tcase 0:\n\t\t\t/* We hold a reference on the pi state. */\n\t\t\tbreak;\n\n\t\t\t/* If the above failed, then pi_state is NULL */\n\t\tcase -EFAULT:\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\thb_waiters_dec(hb2);\n\t\t\tput_futex_key(&key2);\n\t\t\tput_futex_key(&key1);\n\t\t\tret = fault_in_user_writeable(uaddr2);\n\t\t\tif (!ret)\n\t\t\t\tgoto retry;\n\t\t\tgoto out;\n\t\tcase -EAGAIN:\n\t\t\t/*\n\t\t\t * Two reasons for this:\n\t\t\t * - Owner is exiting and we just wait for the\n\t\t\t *   exit to complete.\n\t\t\t * - The user space value changed.\n\t\t\t */\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\thb_waiters_dec(hb2);\n\t\t\tput_futex_key(&key2);\n\t\t\tput_futex_key(&key1);\n\t\t\tcond_resched();\n\t\t\tgoto retry;\n\t\tdefault:\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tplist_for_each_entry_safe(this, next, &hb1->chain, list) {\n\t\tif (task_count - nr_wake >= nr_requeue)\n\t\t\tbreak;\n\n\t\tif (!match_futex(&this->key, &key1))\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * FUTEX_WAIT_REQEUE_PI and FUTEX_CMP_REQUEUE_PI should always\n\t\t * be paired with each other and no other futex ops.\n\t\t *\n\t\t * We should never be requeueing a futex_q with a pi_state,\n\t\t * which is awaiting a futex_unlock_pi().\n\t\t */\n\t\tif ((requeue_pi && !this->rt_waiter) ||\n\t\t    (!requeue_pi && this->rt_waiter) ||\n\t\t    this->pi_state) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Wake nr_wake waiters.  For requeue_pi, if we acquired the\n\t\t * lock, we already woke the top_waiter.  If not, it will be\n\t\t * woken by futex_unlock_pi().\n\t\t */\n\t\tif (++task_count <= nr_wake && !requeue_pi) {\n\t\t\tmark_wake_futex(&wake_q, this);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Ensure we requeue to the expected futex for requeue_pi. */\n\t\tif (requeue_pi && !match_futex(this->requeue_pi_key, &key2)) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Requeue nr_requeue waiters and possibly one more in the case\n\t\t * of requeue_pi if we couldn't acquire the lock atomically.\n\t\t */\n\t\tif (requeue_pi) {\n\t\t\t/*\n\t\t\t * Prepare the waiter to take the rt_mutex. Take a\n\t\t\t * refcount on the pi_state and store the pointer in\n\t\t\t * the futex_q object of the waiter.\n\t\t\t */\n\t\t\tget_pi_state(pi_state);\n\t\t\tthis->pi_state = pi_state;\n\t\t\tret = rt_mutex_start_proxy_lock(&pi_state->pi_mutex,\n\t\t\t\t\t\t\tthis->rt_waiter,\n\t\t\t\t\t\t\tthis->task);\n\t\t\tif (ret == 1) {\n\t\t\t\t/*\n\t\t\t\t * We got the lock. We do neither drop the\n\t\t\t\t * refcount on pi_state nor clear\n\t\t\t\t * this->pi_state because the waiter needs the\n\t\t\t\t * pi_state for cleaning up the user space\n\t\t\t\t * value. It will drop the refcount after\n\t\t\t\t * doing so.\n\t\t\t\t */\n\t\t\t\trequeue_pi_wake_futex(this, &key2, hb2);\n\t\t\t\tdrop_count++;\n\t\t\t\tcontinue;\n\t\t\t} else if (ret) {\n\t\t\t\t/*\n\t\t\t\t * rt_mutex_start_proxy_lock() detected a\n\t\t\t\t * potential deadlock when we tried to queue\n\t\t\t\t * that waiter. Drop the pi_state reference\n\t\t\t\t * which we took above and remove the pointer\n\t\t\t\t * to the state from the waiters futex_q\n\t\t\t\t * object.\n\t\t\t\t */\n\t\t\t\tthis->pi_state = NULL;\n\t\t\t\tput_pi_state(pi_state);\n\t\t\t\t/*\n\t\t\t\t * We stop queueing more waiters and let user\n\t\t\t\t * space deal with the mess.\n\t\t\t\t */\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\trequeue_futex(this, hb1, hb2, &key2);\n\t\tdrop_count++;\n\t}\n\n\t/*\n\t * We took an extra initial reference to the pi_state either\n\t * in futex_proxy_trylock_atomic() or in lookup_pi_state(). We\n\t * need to drop it here again.\n\t */\n\tput_pi_state(pi_state);\n\nout_unlock:\n\tdouble_unlock_hb(hb1, hb2);\n\twake_up_q(&wake_q);\n\thb_waiters_dec(hb2);\n\n\t/*\n\t * drop_futex_key_refs() must be called outside the spinlocks. During\n\t * the requeue we moved futex_q's from the hash bucket at key1 to the\n\t * one at key2 and updated their key pointer.  We no longer need to\n\t * hold the references to key1.\n\t */\n\twhile (--drop_count >= 0)\n\t\tdrop_futex_key_refs(&key1);\n\nout_put_keys:\n\tput_futex_key(&key2);\nout_put_key1:\n\tput_futex_key(&key1);\nout:\n\treturn ret ? ret : task_count;\n}", "commit_link": "github.com/torvalds/linux/commit/fbe0e839d1e22d88810f3ee3e2f1479be4c0aa4a", "file_name": "kernel/futex.c", "vul_type": "cwe-190", "description": "Write a C function named `futex_requeue` that manages the requeueing of futexes, potentially involving priority inheritance logic."}
{"func_name": "set_state", "func_src_before": "def set_state(chat_id, value):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"update users set state ='\" + str(value) + \"' where chat_id = '\" + str(chat_id) + \"'\")\n    settings.commit()\n    settings.close()", "func_src_after": "def set_state(chat_id, value):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"update users set state = ? where chat_id = ?\", (str(value), str(chat_id)))\n    settings.commit()\n    settings.close()", "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bot.py", "vul_type": "cwe-089", "description": "Write a Python function to update a user's state in an SQLite database using their chat ID."}
{"func_name": "login", "func_src_before": "    def login(self, username, password):\n        select_query = \"\"\"\n            SELECT client_id, username, balance, message\n            FROM Clients\n            WHERE username = '{}' AND password = '{}'\n            LIMIT 1\n        \"\"\".format(username, password)\n\n        cursor = self.__conn.cursor()\n\n        cursor.execute(select_query)\n        user = cursor.fetchone()\n\n        if(user):\n            return Client(user[0], user[1], user[2], user[3])\n        else:\n            return False", "func_src_after": "    def login(self, username, password):\n        select_query = \"\"\"\n            SELECT client_id, username, balance, message\n            FROM Clients\n            WHERE username = ? AND password = ?\n            LIMIT 1\n        \"\"\"\n\n        cursor = self.__conn.cursor()\n\n        cursor.execute(select_query, (username, password))\n        user = cursor.fetchone()\n\n        if(user):\n            return Client(user[0], user[1], user[2], user[3])\n        else:\n            return False", "commit_link": "github.com/AnetaStoycheva/Programming101_HackBulgaria/commit/c0d6f4b8fe83a375832845a45952b5153e4c34f3", "file_name": "Week_9/sql_manager.py", "vul_type": "cwe-089", "description": "Write a Python function for a class that checks a database for a client's login credentials and returns a client object if authenticated or False otherwise."}
{"func_name": "opmov", "func_src_before": "static int opmov(RAsm *a, ut8 *data, const Opcode *op) {\n\tint l = 0;\n\tst64 offset = 0;\n\tint mod = 0;\n\tint base = 0;\n\tint rex = 0;\n\tut64 immediate = 0;\n\tif (op->operands[1].type & OT_CONSTANT) {\n\t\tif (!op->operands[1].is_good_flag) {\n\t\t\treturn -1;\n\t\t}\n\t\tif (op->operands[1].immediate == -1) {\n\t\t\treturn -1;\n\t\t}\n\t\timmediate = op->operands[1].immediate * op->operands[1].sign;\n\t\tif (op->operands[0].type & OT_GPREG && !(op->operands[0].type & OT_MEMORY)) {\n\t\t\tif (a->bits == 64 && ((op->operands[0].type & OT_QWORD) | (op->operands[1].type & OT_QWORD))) {\n\t\t\t\tif (!(op->operands[1].type & OT_CONSTANT) && op->operands[1].extended) {\n\t\t\t\t\tdata[l++] = 0x49;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = 0x48;\n\t\t\t\t}\n\t\t\t} else if (op->operands[0].extended) {\n\t\t\t\tdata[l++] = 0x41;\n\t\t\t}\n\t\t\tif (op->operands[0].type & OT_WORD) {\n\t\t\t\tif (a->bits > 16) {\n\t\t\t\t\tdata[l++] = 0x66;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op->operands[0].type & OT_BYTE) {\n\t\t\t\tdata[l++] = 0xb0 | op->operands[0].reg;\n\t\t\t\tdata[l++] = immediate;\n\t\t\t} else {\n\t\t\t\tif (a->bits == 64 &&\n\t\t\t\t\t((op->operands[0].type & OT_QWORD) |\n\t\t\t\t\t(op->operands[1].type & OT_QWORD)) &&\n\t\t\t\t\timmediate < UT32_MAX) {\n\t\t\t\t\t\tdata[l++] = 0xc7;\n\t\t\t\t \t\tdata[l++] = 0xc0 | op->operands[0].reg;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = 0xb8 | op->operands[0].reg;\n\t\t\t\t}\n\t\t\t\tdata[l++] = immediate;\n\t\t\t\tdata[l++] = immediate >> 8;\n\t\t\t\tif (!(op->operands[0].type & OT_WORD)) {\n\t\t\t\t\tdata[l++] = immediate >> 16;\n\t\t\t\t\tdata[l++] = immediate >> 24;\n\t\t\t\t}\n\t\t\t\tif (a->bits == 64 && immediate > UT32_MAX) {\n\t\t\t\t\tdata[l++] = immediate >> 32;\n\t\t\t\t\tdata[l++] = immediate >> 40;\n\t\t\t\t\tdata[l++] = immediate >> 48;\n\t\t\t\t\tdata[l++] = immediate >> 56;\n\t\t\t\t}\n\t\t\t}\n\t\t} else if (op->operands[0].type & OT_MEMORY) {\n\t\t\tif (!op->operands[0].explicit_size) {\n\t\t\t\tif (op->operands[0].type & OT_GPREG) {\n\t\t\t\t\t((Opcode *)op)->operands[0].dest_size = op->operands[0].reg_size;\n\t\t\t\t} else {\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tint dest_bits = 8 * ((op->operands[0].dest_size & ALL_SIZE) >> OPSIZE_SHIFT);\n\t\t\tint reg_bits = 8 * ((op->operands[0].reg_size & ALL_SIZE) >> OPSIZE_SHIFT);\n\t\t\tint offset = op->operands[0].offset * op->operands[0].offset_sign;\n\n\t\t\t//addr_size_override prefix\n\t\t\tbool use_aso = false;\n\t\t\tif (reg_bits < a->bits) {\n\t\t\t\tuse_aso = true;\n\t\t\t}\n\n\t\t\t//op_size_override prefix\n\t\t\tbool use_oso = false;\n\t\t\tif (dest_bits == 16) {\n\t\t\t\tuse_oso = true;\n\t\t\t}\n\n\t\t\tbool rip_rel = op->operands[0].regs[0] == X86R_RIP;\n\n\t\t\t//rex prefix\n\t\t\tint rex = 1 << 6;\n\t\t\tbool use_rex = false;\n\t\t\tif (dest_bits == 64) {\t\t\t//W field\n\t\t\t\tuse_rex = true;\n\t\t\t\trex |= 1 << 3;\n\t\t\t}\n\t\t\tif (op->operands[0].extended) {\t\t//B field\n\t\t\t\tuse_rex = true;\n\t\t\t\trex |= 1;\n\t\t\t}\n\n\t\t\t//opcode selection\n\t\t\tint opcode;\n\t\t\tif (dest_bits == 8) {\n\t\t\t\topcode = 0xc6;\n\t\t\t} else {\n\t\t\t\topcode = 0xc7;\n\t\t\t}\n\n\t\t\t//modrm and SIB selection\n\t\t\tint modrm = 0;\n\t\t\tint mod;\n\t\t\tint reg = 0;\n\t\t\tint rm;\n\t\t\tbool use_sib = false;\n\t\t\tint sib;\n\t\t\t//mod\n\t\t\tif (offset == 0) {\n\t\t\t\tmod = 0;\n\t\t\t} else if (offset < 128 && offset > -129) {\n\t\t\t\tmod = 1;\n\t\t\t} else {\n\t\t\t\tmod = 2;\n\t\t\t}\n\n\t\t\tif (reg_bits == 16) {\n\t\t\t\tif (op->operands[0].regs[0] == X86R_BX && op->operands[0].regs[1] == X86R_SI) {\n\t\t\t\t\trm = B0000;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BX && op->operands[0].regs[1] == X86R_DI) {\n\t\t\t\t\trm = B0001;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BP && op->operands[0].regs[1] == X86R_SI) {\n\t\t\t\t\trm = B0010;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BP && op->operands[0].regs[1] == X86R_DI) {\n\t\t\t\t\trm = B0011;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_SI && op->operands[0].regs[1] == -1) {\n\t\t\t\t\trm = B0100;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_DI && op->operands[0].regs[1] == -1) {\n\t\t\t\t\trm = B0101;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BX && op->operands[0].regs[1] == -1) {\n\t\t\t\t\trm = B0111;\n\t\t\t\t} else {\n\t\t\t\t\t//TODO allow for displacement only when parser is reworked\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t\tmodrm = (mod << 6) | (reg << 3) | rm;\n\t\t\t} else {\n\t\t\t\t//rm\n\t\t\t\tif (op->operands[0].extended) {\n\t\t\t\t\trm = op->operands[0].reg;\n\t\t\t\t} else {\n\t\t\t\t\trm = op->operands[0].regs[0];\n\t\t\t\t}\n\t\t\t\t//[epb] alone is illegal, so we need to fake a [ebp+0]\n\t\t\t\tif (rm == 5 && mod == 0) {\n\t\t\t\t\tmod = 1;\n\t\t\t\t}\n\n\t\t\t\t//sib\n\t\t\t\tint index = op->operands[0].regs[1];\n\t\t\t\tint scale = getsib(op->operands[0].scale[1]);\n\t\t\t\tif (index != -1) {\n\t\t\t\t\tuse_sib = true;\n\t\t\t\t\tsib = (scale << 6) | (index << 3) | rm;\n\t\t\t\t} else if (rm == 4) {\n\t\t\t\t\tuse_sib = true;\n\t\t\t\t\tsib = 0x24;\n\t\t\t\t}\n\t\t\t\tif (use_sib) {\n\t\t\t\t\trm = B0100;\n\t\t\t\t}\n\t\t\t\tif (rip_rel) {\n\t\t\t\t\tmodrm = (B0000 << 6) | (reg << 3) | B0101;\n\t\t\t\t\tsib = (scale << 6) | (B0100 << 3) | B0101;\n\t\t\t\t} else {\n\t\t\t\t\tmodrm = (mod << 6) | (reg << 3) | rm;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t//build the final result\n\t\t\tif (use_aso) {\n\t\t\t\tdata[l++] = 0x67;\n\t\t\t}\n\t\t\tif (use_oso) {\n\t\t\t\tdata[l++] = 0x66;\n\t\t\t}\n\t\t\tif (use_rex) {\n\t\t\t\tdata[l++] = rex;\n\t\t\t}\n\t\t\tdata[l++] = opcode;\n\t\t\tdata[l++] = modrm;\n\t\t\tif (use_sib) {\n\t\t\t\tdata[l++] = sib;\n\t\t\t}\n\t\t\t//offset\n\t\t\tif (mod == 1) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t} else if (reg_bits == 16 && mod == 2) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t} else if (mod == 2 || rip_rel) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t}\n\t\t\t//immediate\n\t\t\tint byte;\n\t\t\tfor (byte = 0; byte < dest_bits && byte < 32; byte += 8) {\n\t\t\t\tdata[l++] = (immediate >> byte);\n\t\t\t}\n\t\t}\n\t} else if (op->operands[1].type & OT_REGALL &&\n\t\t\t !(op->operands[1].type & OT_MEMORY)) {\n\t\tif (op->operands[0].type & OT_CONSTANT) {\n\t\t\treturn -1;\n\t\t}\n\t\tif (op->operands[0].type & OT_REGTYPE & OT_SEGMENTREG &&\n\t\t    op->operands[1].type & OT_REGTYPE & OT_SEGMENTREG) {\n\t\t\t\treturn -1;\n\t\t}\n\t\t// Check reg sizes match\n\t\tif (op->operands[0].type & OT_REGTYPE && op->operands[1].type & OT_REGTYPE) {\n\t\t\tif (!((op->operands[0].type & ALL_SIZE) &\n\t\t\t(op->operands[1].type & ALL_SIZE))) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t}\n\n\t\tif (a->bits == 64) {\n\t\t\tif (op->operands[0].extended) {\n\t\t\t\trex = 1;\n\t\t\t}\n\t\t\tif (op->operands[1].extended) {\n\t\t\t\trex += 4;\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_QWORD) {\n\t\t\t\tif (!(op->operands[0].type & OT_QWORD)) {\n\t\t\t\t\tdata[l++] = 0x67;\n\t\t\t\t\tdata[l++] = 0x48;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_QWORD &&\n\t\t\t\top->operands[0].type & OT_QWORD) {\n\t\t\t\tdata[l++] = 0x48 | rex;\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_DWORD &&\n\t\t\t\top->operands[0].type & OT_DWORD) {\n\t\t\t\tdata[l++] = 0x40 | rex;\n\t\t\t}\n\t\t} else if (op->operands[0].extended && op->operands[1].extended) {\n\t\t\tdata[l++] = 0x45;\n\t\t}\n\t\toffset = op->operands[0].offset * op->operands[0].offset_sign;\n\t\tif (op->operands[1].type & OT_REGTYPE & OT_SEGMENTREG) {\n\t\t\tdata[l++] = 0x8c;\n\t\t} else {\n\t\t\tif (op->operands[0].type & OT_WORD) {\n\t\t\t\tdata[l++] = 0x66;\n\t\t\t}\n\t\t\tdata[l++] = (op->operands[0].type & OT_BYTE) ? 0x88 : 0x89;\n\t\t}\n\n\t\tif (op->operands[0].scale[0] > 1) {\n\t\t\t\tdata[l++] = op->operands[1].reg << 3 | 4;\n\t\t\t\tdata[l++] = getsib (op->operands[0].scale[0]) << 6 |\n\t\t\t\t\t\t    op->operands[0].regs[0] << 3 | 5;\n\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\tdata[l++] = offset >> 24;\n\n\t\t\t\treturn l;\n\t\t\t}\n\n\t\tif (!(op->operands[0].type & OT_MEMORY)) {\n\t\t\tif (op->operands[0].reg == X86R_UNDEFINED ||\n\t\t\t\top->operands[1].reg == X86R_UNDEFINED) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tmod = 0x3;\n\t\t\tdata[l++] = mod << 6 | op->operands[1].reg << 3 | op->operands[0].reg;\n\t\t} else if (op->operands[0].regs[0] == X86R_UNDEFINED) {\n\t\t\tdata[l++] = op->operands[1].reg << 3 | 0x5;\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t} else {\n\t\t\tif (op->operands[0].type & OT_MEMORY) {\n\t\t\t\tif (op->operands[0].regs[1] != X86R_UNDEFINED) {\n\t\t\t\t\tdata[l++] = op->operands[1].reg << 3 | 0x4;\n\t\t\t\t\tdata[l++] = op->operands[0].regs[1] << 3 | op->operands[0].regs[0];\n\t\t\t\t\treturn l;\n\t\t\t\t}\n\t\t\t\tif (offset) {\n\t\t\t\t\tmod = (offset > 128 || offset < -129) ? 0x2 : 0x1;\n\t\t\t\t}\n\t\t\t\tif (op->operands[0].regs[0] == X86R_EBP) {\n\t\t\t\t\tmod = 0x2;\n\t\t\t\t}\n\t\t\t\tdata[l++] = mod << 6 | op->operands[1].reg << 3 | op->operands[0].regs[0];\n\t\t\t\tif (op->operands[0].regs[0] == X86R_ESP) {\n\t\t\t\t\tdata[l++] = 0x24;\n\t\t\t\t}\n\t\t\t\tif (offset) {\n\t\t\t\t\tdata[l++] = offset;\n\t\t\t\t}\n\t\t\t\tif (mod == 2) {\n\t\t\t\t\t// warning C4293: '>>': shift count negative or too big, undefined behavior\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else if (op->operands[1].type & OT_MEMORY) {\n\t\tif (op->operands[0].type & OT_MEMORY) {\n\t\t\treturn -1;\n\t\t}\n\t\toffset = op->operands[1].offset * op->operands[1].offset_sign;\n\t\tif (op->operands[0].reg == X86R_EAX && op->operands[1].regs[0] == X86R_UNDEFINED) {\n\t\t\tif (a->bits == 64) {\n\t\t\t\tdata[l++] = 0x48;\n\t\t\t}\n\t\t\tif (op->operands[0].type & OT_BYTE) {\n\t\t\t\tdata[l++] = 0xa0;\n\t\t\t} else {\n\t\t\t\tdata[l++] = 0xa1;\n\t\t\t}\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t\tif (a->bits == 64) {\n\t\t\t\tdata[l++] = offset >> 32;\n\t\t\t\tdata[l++] = offset >> 40;\n\t\t\t\tdata[l++] = offset >> 48;\n\t\t\t\tdata[l++] = offset >> 54;\n\t\t\t}\n\t\t\treturn l;\n\t\t}\n\t\tif (op->operands[0].type & OT_BYTE && a->bits == 64 && op->operands[1].regs[0]) {\n\t\t\tif (op->operands[1].regs[0] >= X86R_R8 &&\n\t\t\t    op->operands[0].reg < 4) {\n\t\t\t\tdata[l++] = 0x41;\n\t\t\t\tdata[l++] = 0x8a;\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | (op->operands[1].regs[0] - 8);\n\t\t\t\treturn l;\n\t\t\t}\n\t\t\treturn -1;\n\t\t}\n\n\t\tif (op->operands[1].type & OT_REGTYPE & OT_SEGMENTREG) {\n\t\t\tif (op->operands[1].scale[0] == 0) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tdata[l++] = SEG_REG_PREFIXES[op->operands[1].regs[0]];\n\t\t\tdata[l++] = 0x8b;\n\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x5;\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t\treturn l;\n\t\t}\n\n\t\tif (a->bits == 64) {\n\t\t\tif (op->operands[0].type & OT_QWORD) {\n\t\t\t\tif (!(op->operands[1].type & OT_QWORD)) {\n\t\t\t\t\tif (op->operands[1].regs[0] != -1) {\n\t\t\t\t\t\tdata[l++] = 0x67;\n\t\t\t\t\t}\n\t\t\t\t\tdata[l++] = 0x48;\n\t\t\t\t}\n\t\t\t} else if (op->operands[1].type & OT_DWORD) {\n\t\t\t\tdata[l++] = 0x44;\n\t\t\t} else if (!(op->operands[1].type & OT_QWORD)) {\n\t\t\t\tdata[l++] = 0x67;\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_QWORD &&\n\t\t\t\top->operands[0].type & OT_QWORD) {\n\t\t\t\tdata[l++] = 0x48;\n\t\t\t}\n\t\t}\n\n\t\tif (op->operands[0].type & OT_WORD) {\n\t\t\tdata[l++] = 0x66;\n\t\t\tdata[l++] = op->operands[1].type & OT_BYTE ? 0x8a : 0x8b;\n\t\t} else {\n\t\t\tdata[l++] = (op->operands[1].type & OT_BYTE ||\n\t\t\t\top->operands[0].type & OT_BYTE) ?\n\t\t\t\t0x8a : 0x8b;\n\t\t}\n\n\t\tif (op->operands[1].regs[0] == X86R_UNDEFINED) {\n\t\t\tif (a->bits == 64) {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x4;\n\t\t\t\tdata[l++] = 0x25;\n\t\t\t} else {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x5;\n\t\t\t}\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t} else {\n\t\t\tif (op->operands[1].scale[0] > 1) {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 4;\n\n\t\t\t\tif (op->operands[1].scale[0] >= 2) {\n\t\t\t\t\tbase = 5;\n\t\t\t\t}\n\t\t\t\tif (base) {\n\t\t\t\t\tdata[l++] = getsib (op->operands[1].scale[0]) << 6 | op->operands[1].regs[0] << 3 | base;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = getsib (op->operands[1].scale[0]) << 3 | op->operands[1].regs[0];\n\t\t\t\t}\n\t\t\t\tif (offset || base) {\n\t\t\t\t\tdata[l++] = offset;\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t\treturn l;\n\t\t\t}\n\t\t\tif (op->operands[1].regs[1] != X86R_UNDEFINED) {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x4;\n\t\t\t\tdata[l++] = op->operands[1].regs[1] << 3 | op->operands[1].regs[0];\n\t\t\t\treturn l;\n\t\t\t}\n\n\t\t\tif (offset || op->operands[1].regs[0] == X86R_EBP) {\n\t\t\t\tmod = 0x2;\n\t\t\t\tif (op->operands[1].offset > 127) {\n\t\t\t\t\tmod = 0x4;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (a->bits == 64 && offset && op->operands[0].type & OT_QWORD) {\n\t\t\t\tif (op->operands[1].regs[0] == X86R_RIP) {\n\t\t\t\t\tdata[l++] = 0x5;\n\t\t\t\t} else {\n\t\t\t\t\tif (op->operands[1].offset > 127) {\n\t\t\t\t\t\tdata[l++] = 0x80 | op->operands[0].reg << 3 | op->operands[1].regs[0];\n\t\t\t\t\t} else {\n\t\t\t\t\t\tdata[l++] = 0x40 | op->operands[1].regs[0];\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (op->operands[1].offset > 127) {\n\t\t\t\t\tmod = 0x1;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (op->operands[1].regs[0] == X86R_EIP && (op->operands[0].type & OT_DWORD)) {\n\t\t\t\t\tdata[l++] = 0x0d;\n\t\t\t\t} else if (op->operands[1].regs[0] == X86R_RIP && (op->operands[0].type & OT_QWORD)) {\n\t\t\t\t\tdata[l++] = 0x05;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = mod << 5 | op->operands[0].reg << 3 | op->operands[1].regs[0];\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op->operands[1].regs[0] == X86R_ESP) {\n\t\t\t\tdata[l++] = 0x24;\n\t\t\t}\n\t\t\tif (mod >= 0x2) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tif (op->operands[1].offset > 128 || op->operands[1].regs[0] == X86R_EIP) {\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t} else if (a->bits == 64 && (offset || op->operands[1].regs[0] == X86R_RIP)) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tif (op->operands[1].offset > 127 || op->operands[1].regs[0] == X86R_RIP) {\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn l;\n}", "func_src_after": "static int opmov(RAsm *a, ut8 *data, const Opcode *op) {\n\tint l = 0;\n\tst64 offset = 0;\n\tint mod = 0;\n\tint base = 0;\n\tint rex = 0;\n\tut64 immediate = 0;\n\tif (op->operands[1].type & OT_CONSTANT) {\n\t\tif (!op->operands[1].is_good_flag) {\n\t\t\treturn -1;\n\t\t}\n\t\tif (op->operands[1].immediate == -1) {\n\t\t\treturn -1;\n\t\t}\n\t\timmediate = op->operands[1].immediate * op->operands[1].sign;\n\t\tif (op->operands[0].type & OT_GPREG && !(op->operands[0].type & OT_MEMORY)) {\n\t\t\tif (a->bits == 64 && ((op->operands[0].type & OT_QWORD) | (op->operands[1].type & OT_QWORD))) {\n\t\t\t\tif (!(op->operands[1].type & OT_CONSTANT) && op->operands[1].extended) {\n\t\t\t\t\tdata[l++] = 0x49;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = 0x48;\n\t\t\t\t}\n\t\t\t} else if (op->operands[0].extended) {\n\t\t\t\tdata[l++] = 0x41;\n\t\t\t}\n\t\t\tif (op->operands[0].type & OT_WORD) {\n\t\t\t\tif (a->bits > 16) {\n\t\t\t\t\tdata[l++] = 0x66;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op->operands[0].type & OT_BYTE) {\n\t\t\t\tdata[l++] = 0xb0 | op->operands[0].reg;\n\t\t\t\tdata[l++] = immediate;\n\t\t\t} else {\n\t\t\t\tif (a->bits == 64 &&\n\t\t\t\t\t((op->operands[0].type & OT_QWORD) |\n\t\t\t\t\t(op->operands[1].type & OT_QWORD)) &&\n\t\t\t\t\timmediate < UT32_MAX) {\n\t\t\t\t\t\tdata[l++] = 0xc7;\n\t\t\t\t \t\tdata[l++] = 0xc0 | op->operands[0].reg;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = 0xb8 | op->operands[0].reg;\n\t\t\t\t}\n\t\t\t\tdata[l++] = immediate;\n\t\t\t\tdata[l++] = immediate >> 8;\n\t\t\t\tif (!(op->operands[0].type & OT_WORD)) {\n\t\t\t\t\tdata[l++] = immediate >> 16;\n\t\t\t\t\tdata[l++] = immediate >> 24;\n\t\t\t\t}\n\t\t\t\tif (a->bits == 64 && immediate > UT32_MAX) {\n\t\t\t\t\tdata[l++] = immediate >> 32;\n\t\t\t\t\tdata[l++] = immediate >> 40;\n\t\t\t\t\tdata[l++] = immediate >> 48;\n\t\t\t\t\tdata[l++] = immediate >> 56;\n\t\t\t\t}\n\t\t\t}\n\t\t} else if (op->operands[0].type & OT_MEMORY) {\n\t\t\tif (!op->operands[0].explicit_size) {\n\t\t\t\tif (op->operands[0].type & OT_GPREG) {\n\t\t\t\t\t((Opcode *)op)->operands[0].dest_size = op->operands[0].reg_size;\n\t\t\t\t} else {\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tint dest_bits = 8 * ((op->operands[0].dest_size & ALL_SIZE) >> OPSIZE_SHIFT);\n\t\t\tint reg_bits = 8 * ((op->operands[0].reg_size & ALL_SIZE) >> OPSIZE_SHIFT);\n\t\t\tint offset = op->operands[0].offset * op->operands[0].offset_sign;\n\n\t\t\t//addr_size_override prefix\n\t\t\tbool use_aso = false;\n\t\t\tif (reg_bits < a->bits) {\n\t\t\t\tuse_aso = true;\n\t\t\t}\n\n\t\t\t//op_size_override prefix\n\t\t\tbool use_oso = false;\n\t\t\tif (dest_bits == 16) {\n\t\t\t\tuse_oso = true;\n\t\t\t}\n\n\t\t\tbool rip_rel = op->operands[0].regs[0] == X86R_RIP;\n\n\t\t\t//rex prefix\n\t\t\tint rex = 1 << 6;\n\t\t\tbool use_rex = false;\n\t\t\tif (dest_bits == 64) {\t\t\t//W field\n\t\t\t\tuse_rex = true;\n\t\t\t\trex |= 1 << 3;\n\t\t\t}\n\t\t\tif (op->operands[0].extended) {\t\t//B field\n\t\t\t\tuse_rex = true;\n\t\t\t\trex |= 1;\n\t\t\t}\n\n\t\t\t//opcode selection\n\t\t\tint opcode;\n\t\t\tif (dest_bits == 8) {\n\t\t\t\topcode = 0xc6;\n\t\t\t} else {\n\t\t\t\topcode = 0xc7;\n\t\t\t}\n\n\t\t\t//modrm and SIB selection\n\t\t\tint modrm = 0;\n\t\t\tint mod;\n\t\t\tint reg = 0;\n\t\t\tint rm;\n\t\t\tbool use_sib = false;\n\t\t\tint sib;\n\t\t\t//mod\n\t\t\tif (offset == 0) {\n\t\t\t\tmod = 0;\n\t\t\t} else if (offset < 128 && offset > -129) {\n\t\t\t\tmod = 1;\n\t\t\t} else {\n\t\t\t\tmod = 2;\n\t\t\t}\n\n\t\t\tif (reg_bits == 16) {\n\t\t\t\tif (op->operands[0].regs[0] == X86R_BX && op->operands[0].regs[1] == X86R_SI) {\n\t\t\t\t\trm = B0000;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BX && op->operands[0].regs[1] == X86R_DI) {\n\t\t\t\t\trm = B0001;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BP && op->operands[0].regs[1] == X86R_SI) {\n\t\t\t\t\trm = B0010;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BP && op->operands[0].regs[1] == X86R_DI) {\n\t\t\t\t\trm = B0011;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_SI && op->operands[0].regs[1] == -1) {\n\t\t\t\t\trm = B0100;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_DI && op->operands[0].regs[1] == -1) {\n\t\t\t\t\trm = B0101;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BX && op->operands[0].regs[1] == -1) {\n\t\t\t\t\trm = B0111;\n\t\t\t\t} else {\n\t\t\t\t\t//TODO allow for displacement only when parser is reworked\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t\tmodrm = (mod << 6) | (reg << 3) | rm;\n\t\t\t} else {\n\t\t\t\t//rm\n\t\t\t\tif (op->operands[0].extended) {\n\t\t\t\t\trm = op->operands[0].reg;\n\t\t\t\t} else {\n\t\t\t\t\trm = op->operands[0].regs[0];\n\t\t\t\t}\n\t\t\t\t//[epb] alone is illegal, so we need to fake a [ebp+0]\n\t\t\t\tif (rm == 5 && mod == 0) {\n\t\t\t\t\tmod = 1;\n\t\t\t\t}\n\n\t\t\t\t//sib\n\t\t\t\tint index = op->operands[0].regs[1];\n\t\t\t\tint scale = getsib(op->operands[0].scale[1]);\n\t\t\t\tif (index != -1) {\n\t\t\t\t\tuse_sib = true;\n\t\t\t\t\tsib = (scale << 6) | (index << 3) | rm;\n\t\t\t\t} else if (rm == 4) {\n\t\t\t\t\tuse_sib = true;\n\t\t\t\t\tsib = 0x24;\n\t\t\t\t}\n\t\t\t\tif (use_sib) {\n\t\t\t\t\trm = B0100;\n\t\t\t\t}\n\t\t\t\tif (rip_rel) {\n\t\t\t\t\tmodrm = (B0000 << 6) | (reg << 3) | B0101;\n\t\t\t\t\tsib = (scale << 6) | (B0100 << 3) | B0101;\n\t\t\t\t} else {\n\t\t\t\t\tmodrm = (mod << 6) | (reg << 3) | rm;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t//build the final result\n\t\t\tif (use_aso) {\n\t\t\t\tdata[l++] = 0x67;\n\t\t\t}\n\t\t\tif (use_oso) {\n\t\t\t\tdata[l++] = 0x66;\n\t\t\t}\n\t\t\tif (use_rex) {\n\t\t\t\tdata[l++] = rex;\n\t\t\t}\n\t\t\tdata[l++] = opcode;\n\t\t\tdata[l++] = modrm;\n\t\t\tif (use_sib) {\n\t\t\t\tdata[l++] = sib;\n\t\t\t}\n\t\t\t//offset\n\t\t\tif (mod == 1) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t} else if (reg_bits == 16 && mod == 2) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t} else if (mod == 2 || rip_rel) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t}\n\t\t\t//immediate\n\t\t\tint byte;\n\t\t\tfor (byte = 0; byte < dest_bits && byte < 32; byte += 8) {\n\t\t\t\tdata[l++] = (immediate >> byte);\n\t\t\t}\n\t\t}\n\t} else if (op->operands[1].type & OT_REGALL &&\n\t\t\t !(op->operands[1].type & OT_MEMORY)) {\n\t\tif (op->operands[0].type & OT_CONSTANT) {\n\t\t\treturn -1;\n\t\t}\n\t\tif (op->operands[0].type & OT_REGTYPE & OT_SEGMENTREG &&\n\t\t    op->operands[1].type & OT_REGTYPE & OT_SEGMENTREG) {\n\t\t\t\treturn -1;\n\t\t}\n\t\t// Check reg sizes match\n\t\tif (op->operands[0].type & OT_REGTYPE && op->operands[1].type & OT_REGTYPE) {\n\t\t\tif (!((op->operands[0].type & ALL_SIZE) &\n\t\t\t(op->operands[1].type & ALL_SIZE))) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t}\n\n\t\tif (a->bits == 64) {\n\t\t\tif (op->operands[0].extended) {\n\t\t\t\trex = 1;\n\t\t\t}\n\t\t\tif (op->operands[1].extended) {\n\t\t\t\trex += 4;\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_QWORD) {\n\t\t\t\tif (!(op->operands[0].type & OT_QWORD)) {\n\t\t\t\t\tdata[l++] = 0x67;\n\t\t\t\t\tdata[l++] = 0x48;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_QWORD &&\n\t\t\t\top->operands[0].type & OT_QWORD) {\n\t\t\t\tdata[l++] = 0x48 | rex;\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_DWORD &&\n\t\t\t\top->operands[0].type & OT_DWORD) {\n\t\t\t\tdata[l++] = 0x40 | rex;\n\t\t\t}\n\t\t} else if (op->operands[0].extended && op->operands[1].extended) {\n\t\t\tdata[l++] = 0x45;\n\t\t}\n\t\toffset = op->operands[0].offset * op->operands[0].offset_sign;\n\t\tif (op->operands[1].type & OT_REGTYPE & OT_SEGMENTREG) {\n\t\t\tdata[l++] = 0x8c;\n\t\t} else {\n\t\t\tif (op->operands[0].type & OT_WORD) {\n\t\t\t\tdata[l++] = 0x66;\n\t\t\t}\n\t\t\tdata[l++] = (op->operands[0].type & OT_BYTE) ? 0x88 : 0x89;\n\t\t}\n\n\t\tif (op->operands[0].scale[0] > 1) {\n\t\t\t\tdata[l++] = op->operands[1].reg << 3 | 4;\n\t\t\t\tdata[l++] = getsib (op->operands[0].scale[0]) << 6 |\n\t\t\t\t\t\t    op->operands[0].regs[0] << 3 | 5;\n\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\tdata[l++] = offset >> 24;\n\n\t\t\t\treturn l;\n\t\t\t}\n\n\t\tif (!(op->operands[0].type & OT_MEMORY)) {\n\t\t\tif (op->operands[0].reg == X86R_UNDEFINED ||\n\t\t\t\top->operands[1].reg == X86R_UNDEFINED) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tmod = 0x3;\n\t\t\tdata[l++] = mod << 6 | op->operands[1].reg << 3 | op->operands[0].reg;\n\t\t} else if (op->operands[0].regs[0] == X86R_UNDEFINED) {\n\t\t\tdata[l++] = op->operands[1].reg << 3 | 0x5;\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t} else {\n\t\t\tif (op->operands[0].type & OT_MEMORY) {\n\t\t\t\tif (op->operands[0].regs[1] != X86R_UNDEFINED) {\n\t\t\t\t\tdata[l++] = op->operands[1].reg << 3 | 0x4;\n\t\t\t\t\tdata[l++] = op->operands[0].regs[1] << 3 | op->operands[0].regs[0];\n\t\t\t\t\treturn l;\n\t\t\t\t}\n\t\t\t\tif (offset) {\n\t\t\t\t\tmod = (offset > 128 || offset < -129) ? 0x2 : 0x1;\n\t\t\t\t}\n\t\t\t\tif (op->operands[0].regs[0] == X86R_EBP) {\n\t\t\t\t\tmod = 0x2;\n\t\t\t\t}\n\t\t\t\tdata[l++] = mod << 6 | op->operands[1].reg << 3 | op->operands[0].regs[0];\n\t\t\t\tif (op->operands[0].regs[0] == X86R_ESP) {\n\t\t\t\t\tdata[l++] = 0x24;\n\t\t\t\t}\n\t\t\t\tif (offset) {\n\t\t\t\t\tdata[l++] = offset;\n\t\t\t\t}\n\t\t\t\tif (mod == 2) {\n\t\t\t\t\t// warning C4293: '>>': shift count negative or too big, undefined behavior\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else if (op->operands[1].type & OT_MEMORY) {\n\t\tif (op->operands[0].type & OT_MEMORY) {\n\t\t\treturn -1;\n\t\t}\n\t\toffset = op->operands[1].offset * op->operands[1].offset_sign;\n\t\tif (op->operands[0].reg == X86R_EAX && op->operands[1].regs[0] == X86R_UNDEFINED) {\n\t\t\tif (a->bits == 64) {\n\t\t\t\tdata[l++] = 0x48;\n\t\t\t}\n\t\t\tif (op->operands[0].type & OT_BYTE) {\n\t\t\t\tdata[l++] = 0xa0;\n\t\t\t} else {\n\t\t\t\tdata[l++] = 0xa1;\n\t\t\t}\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t\tif (a->bits == 64) {\n\t\t\t\tdata[l++] = offset >> 32;\n\t\t\t\tdata[l++] = offset >> 40;\n\t\t\t\tdata[l++] = offset >> 48;\n\t\t\t\tdata[l++] = offset >> 54;\n\t\t\t}\n\t\t\treturn l;\n\t\t}\n\t\tif (op->operands[0].type & OT_BYTE && a->bits == 64 && op->operands[1].regs[0]) {\n\t\t\tif (op->operands[1].regs[0] >= X86R_R8 &&\n\t\t\t    op->operands[0].reg < 4) {\n\t\t\t\tdata[l++] = 0x41;\n\t\t\t\tdata[l++] = 0x8a;\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | (op->operands[1].regs[0] - 8);\n\t\t\t\treturn l;\n\t\t\t}\n\t\t\treturn -1;\n\t\t}\n\n\t\tif (op->operands[1].type & OT_REGTYPE & OT_SEGMENTREG) {\n\t\t\tif (op->operands[1].scale[0] == 0) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tdata[l++] = SEG_REG_PREFIXES[op->operands[1].regs[0] % 6];\n\t\t\tdata[l++] = 0x8b;\n\t\t\tdata[l++] = (((ut32)op->operands[0].reg) << 3) | 0x5;\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t\treturn l;\n\t\t}\n\n\t\tif (a->bits == 64) {\n\t\t\tif (op->operands[0].type & OT_QWORD) {\n\t\t\t\tif (!(op->operands[1].type & OT_QWORD)) {\n\t\t\t\t\tif (op->operands[1].regs[0] != -1) {\n\t\t\t\t\t\tdata[l++] = 0x67;\n\t\t\t\t\t}\n\t\t\t\t\tdata[l++] = 0x48;\n\t\t\t\t}\n\t\t\t} else if (op->operands[1].type & OT_DWORD) {\n\t\t\t\tdata[l++] = 0x44;\n\t\t\t} else if (!(op->operands[1].type & OT_QWORD)) {\n\t\t\t\tdata[l++] = 0x67;\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_QWORD &&\n\t\t\t\top->operands[0].type & OT_QWORD) {\n\t\t\t\tdata[l++] = 0x48;\n\t\t\t}\n\t\t}\n\n\t\tif (op->operands[0].type & OT_WORD) {\n\t\t\tdata[l++] = 0x66;\n\t\t\tdata[l++] = op->operands[1].type & OT_BYTE ? 0x8a : 0x8b;\n\t\t} else {\n\t\t\tdata[l++] = (op->operands[1].type & OT_BYTE ||\n\t\t\t\top->operands[0].type & OT_BYTE) ?\n\t\t\t\t0x8a : 0x8b;\n\t\t}\n\n\t\tif (op->operands[1].regs[0] == X86R_UNDEFINED) {\n\t\t\tif (a->bits == 64) {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x4;\n\t\t\t\tdata[l++] = 0x25;\n\t\t\t} else {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x5;\n\t\t\t}\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t} else {\n\t\t\tif (op->operands[1].scale[0] > 1) {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 4;\n\n\t\t\t\tif (op->operands[1].scale[0] >= 2) {\n\t\t\t\t\tbase = 5;\n\t\t\t\t}\n\t\t\t\tif (base) {\n\t\t\t\t\tdata[l++] = getsib (op->operands[1].scale[0]) << 6 | op->operands[1].regs[0] << 3 | base;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = getsib (op->operands[1].scale[0]) << 3 | op->operands[1].regs[0];\n\t\t\t\t}\n\t\t\t\tif (offset || base) {\n\t\t\t\t\tdata[l++] = offset;\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t\treturn l;\n\t\t\t}\n\t\t\tif (op->operands[1].regs[1] != X86R_UNDEFINED) {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x4;\n\t\t\t\tdata[l++] = op->operands[1].regs[1] << 3 | op->operands[1].regs[0];\n\t\t\t\treturn l;\n\t\t\t}\n\n\t\t\tif (offset || op->operands[1].regs[0] == X86R_EBP) {\n\t\t\t\tmod = 0x2;\n\t\t\t\tif (op->operands[1].offset > 127) {\n\t\t\t\t\tmod = 0x4;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (a->bits == 64 && offset && op->operands[0].type & OT_QWORD) {\n\t\t\t\tif (op->operands[1].regs[0] == X86R_RIP) {\n\t\t\t\t\tdata[l++] = 0x5;\n\t\t\t\t} else {\n\t\t\t\t\tif (op->operands[1].offset > 127) {\n\t\t\t\t\t\tdata[l++] = 0x80 | op->operands[0].reg << 3 | op->operands[1].regs[0];\n\t\t\t\t\t} else {\n\t\t\t\t\t\tdata[l++] = 0x40 | op->operands[1].regs[0];\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (op->operands[1].offset > 127) {\n\t\t\t\t\tmod = 0x1;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (op->operands[1].regs[0] == X86R_EIP && (op->operands[0].type & OT_DWORD)) {\n\t\t\t\t\tdata[l++] = 0x0d;\n\t\t\t\t} else if (op->operands[1].regs[0] == X86R_RIP && (op->operands[0].type & OT_QWORD)) {\n\t\t\t\t\tdata[l++] = 0x05;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = mod << 5 | op->operands[0].reg << 3 | op->operands[1].regs[0];\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op->operands[1].regs[0] == X86R_ESP) {\n\t\t\t\tdata[l++] = 0x24;\n\t\t\t}\n\t\t\tif (mod >= 0x2) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tif (op->operands[1].offset > 128 || op->operands[1].regs[0] == X86R_EIP) {\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t} else if (a->bits == 64 && (offset || op->operands[1].regs[0] == X86R_RIP)) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tif (op->operands[1].offset > 127 || op->operands[1].regs[0] == X86R_RIP) {\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn l;\n}", "commit_link": "github.com/radare/radare2/commit/f17bfd9f1da05f30f23a4dd05e9d2363e1406948", "file_name": "libr/asm/p/asm_x86_nz.c", "vul_type": "cwe-125", "description": "Write a C function named `opmov` that assembles an x86 MOV instruction based on the provided operands."}
{"func_name": "get", "func_src_before": "    def get(self, user_id):\n        \"\"\" Fetch data for user with corresponding user_id \"\"\"\n        return database_utilities.execute_query(f\"\"\"select * from users where user_id = '{user_id}'\"\"\")", "func_src_after": "    def get(self, user_id):\n        \"\"\" Fetch data for user with corresponding user_id \"\"\"\n        return database_utilities.execute_query(f\"\"\"select * from users where user_id = %s\"\"\", (user_id, ))", "commit_link": "github.com/sgosal2/tiger-boards-backend/commit/4670109dd613df2f2fe7e8403ebd149df2b55485", "file_name": "apis/users.py", "vul_type": "cwe-089", "description": "Write a Python function named `get` that retrieves user data from a database using the user's ID."}
{"func_name": "HeifContext::interpret_heif_file", "func_src_before": "Error HeifContext::interpret_heif_file()\n{\n  m_all_images.clear();\n  m_top_level_images.clear();\n  m_primary_image.reset();\n\n\n  // --- reference all non-hidden images\n\n  std::vector<heif_item_id> image_IDs = m_heif_file->get_item_IDs();\n\n  bool primary_is_grid = false;\n  for (heif_item_id id : image_IDs) {\n    auto infe_box = m_heif_file->get_infe_box(id);\n    if (!infe_box) {\n      // TODO(farindk): Should we return an error instead of skipping the invalid id?\n      continue;\n    }\n\n    if (item_type_is_image(infe_box->get_item_type())) {\n      auto image = std::make_shared<Image>(this, id);\n      m_all_images.insert(std::make_pair(id, image));\n\n      if (!infe_box->is_hidden_item()) {\n        if (id==m_heif_file->get_primary_image_ID()) {\n          image->set_primary(true);\n          m_primary_image = image;\n          primary_is_grid = infe_box->get_item_type() == \"grid\";\n        }\n\n        m_top_level_images.push_back(image);\n      }\n    }\n  }\n\n\n  if (!m_primary_image) {\n    return Error(heif_error_Invalid_input,\n                 heif_suberror_Nonexisting_item_referenced,\n                 \"'pitm' box references a non-existing image\");\n  }\n\n\n  // --- remove thumbnails from top-level images and assign to their respective image\n\n  auto iref_box = m_heif_file->get_iref_box();\n  if (iref_box) {\n    // m_top_level_images.clear();\n\n    for (auto& pair : m_all_images) {\n      auto& image = pair.second;\n\n      std::vector<Box_iref::Reference> references = iref_box->get_references_from(image->get_id());\n\n      for (const Box_iref::Reference& ref : references) {\n        uint32_t type = ref.header.get_short_type();\n\n        if (type==fourcc(\"thmb\")) {\n          // --- this is a thumbnail image, attach to the main image\n\n          std::vector<heif_item_id> refs = ref.to_item_ID;\n          if (refs.size() != 1) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Unspecified,\n                         \"Too many thumbnail references\");\n          }\n\n          image->set_is_thumbnail_of(refs[0]);\n\n          auto master_iter = m_all_images.find(refs[0]);\n          if (master_iter == m_all_images.end()) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Nonexisting_item_referenced,\n                         \"Thumbnail references a non-existing image\");\n          }\n\n          if (master_iter->second->is_thumbnail()) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Nonexisting_item_referenced,\n                         \"Thumbnail references another thumbnail\");\n          }\n\n          if (image.get() == master_iter->second.get()) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Nonexisting_item_referenced,\n                         \"Recursive thumbnail image detected\");\n          }\n          master_iter->second->add_thumbnail(image);\n\n          remove_top_level_image(image);\n        }\n        else if (type==fourcc(\"auxl\")) {\n\n          // --- this is an auxiliary image\n          //     check whether it is an alpha channel and attach to the main image if yes\n\n          std::vector<Box_ipco::Property> properties;\n          Error err = m_heif_file->get_properties(image->get_id(), properties);\n          if (err) {\n            return err;\n          }\n\n          std::shared_ptr<Box_auxC> auxC_property;\n          for (const auto& property : properties) {\n            auto auxC = std::dynamic_pointer_cast<Box_auxC>(property.property);\n            if (auxC) {\n              auxC_property = auxC;\n            }\n          }\n\n          if (!auxC_property) {\n            std::stringstream sstr;\n            sstr << \"No auxC property for image \" << image->get_id();\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Auxiliary_image_type_unspecified,\n                         sstr.str());\n          }\n\n          std::vector<heif_item_id> refs = ref.to_item_ID;\n          if (refs.size() != 1) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Unspecified,\n                         \"Too many auxiliary image references\");\n          }\n\n\n          // alpha channel\n\n          if (auxC_property->get_aux_type() == \"urn:mpeg:avc:2015:auxid:1\" ||\n              auxC_property->get_aux_type() == \"urn:mpeg:hevc:2015:auxid:1\") {\n            image->set_is_alpha_channel_of(refs[0]);\n\n            auto master_iter = m_all_images.find(refs[0]);\n            if (image.get() == master_iter->second.get()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Recursive alpha image detected\");\n            }\n            master_iter->second->set_alpha_channel(image);\n          }\n\n\n          // depth channel\n\n          if (auxC_property->get_aux_type() == \"urn:mpeg:hevc:2015:auxid:2\") {\n            image->set_is_depth_channel_of(refs[0]);\n\n            auto master_iter = m_all_images.find(refs[0]);\n            if (image.get() == master_iter->second.get()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Recursive depth image detected\");\n            }\n            master_iter->second->set_depth_channel(image);\n\n            auto subtypes = auxC_property->get_subtypes();\n\n            std::vector<std::shared_ptr<SEIMessage>> sei_messages;\n            Error err = decode_hevc_aux_sei_messages(subtypes, sei_messages);\n\n            for (auto& msg : sei_messages) {\n              auto depth_msg = std::dynamic_pointer_cast<SEIMessage_depth_representation_info>(msg);\n              if (depth_msg) {\n                image->set_depth_representation_info(*depth_msg);\n              }\n            }\n          }\n\n          remove_top_level_image(image);\n        }\n        else {\n          // 'image' is a normal image, keep it as a top-level image\n        }\n      }\n    }\n  }\n\n\n  // --- check that HEVC images have an hvcC property\n\n  for (auto& pair : m_all_images) {\n    auto& image = pair.second;\n\n    std::shared_ptr<Box_infe> infe = m_heif_file->get_infe_box(image->get_id());\n    if (infe->get_item_type() == \"hvc1\") {\n\n      auto ipma = m_heif_file->get_ipma_box();\n      auto ipco = m_heif_file->get_ipco_box();\n\n      if (!ipco->get_property_for_item_ID(image->get_id(), ipma, fourcc(\"hvcC\"))) {\n        return Error(heif_error_Invalid_input,\n                     heif_suberror_No_hvcC_box,\n                     \"No hvcC property in hvc1 type image\");\n      }\n    }\n  }\n\n\n  // --- read through properties for each image and extract image resolutions\n\n  for (auto& pair : m_all_images) {\n    auto& image = pair.second;\n\n    std::vector<Box_ipco::Property> properties;\n\n    Error err = m_heif_file->get_properties(pair.first, properties);\n    if (err) {\n      return err;\n    }\n\n    bool ispe_read = false;\n    bool primary_colr_set = false;\n    for (const auto& prop : properties) {\n      auto ispe = std::dynamic_pointer_cast<Box_ispe>(prop.property);\n      if (ispe) {\n        uint32_t width = ispe->get_width();\n        uint32_t height = ispe->get_height();\n\n\n        // --- check whether the image size is \"too large\"\n\n        if (width  >= static_cast<uint32_t>(MAX_IMAGE_WIDTH) ||\n            height >= static_cast<uint32_t>(MAX_IMAGE_HEIGHT)) {\n          std::stringstream sstr;\n          sstr << \"Image size \" << width << \"x\" << height << \" exceeds the maximum image size \"\n               << MAX_IMAGE_WIDTH << \"x\" << MAX_IMAGE_HEIGHT << \"\\n\";\n\n          return Error(heif_error_Memory_allocation_error,\n                       heif_suberror_Security_limit_exceeded,\n                       sstr.str());\n        }\n\n        image->set_resolution(width, height);\n        image->set_ispe_resolution(width, height);\n        ispe_read = true;\n      }\n\n      if (ispe_read) {\n        auto clap = std::dynamic_pointer_cast<Box_clap>(prop.property);\n        if (clap) {\n          image->set_resolution( clap->get_width_rounded(),\n                                 clap->get_height_rounded() );\n        }\n\n        auto irot = std::dynamic_pointer_cast<Box_irot>(prop.property);\n        if (irot) {\n          if (irot->get_rotation()==90 ||\n              irot->get_rotation()==270) {\n            // swap width and height\n            image->set_resolution( image->get_height(),\n                                   image->get_width() );\n          }\n        }\n      }\n\n      auto colr = std::dynamic_pointer_cast<Box_colr>(prop.property);\n      if (colr) {\n        auto profile = colr->get_color_profile();\n\n        image->set_color_profile(profile);\n\n        // if this is a grid item we assign the first one's color profile\n        // to the main image which is supposed to be a grid\n\n        // TODO: this condition is not correct. It would also classify a secondary image as a 'grid item'.\n        // We have to set the grid-image color profile in another way...\n        const bool is_grid_item = !image->is_primary() && !image->is_alpha_channel() && !image->is_depth_channel();\n\n        if (primary_is_grid &&\n            !primary_colr_set &&\n            is_grid_item) {\n          m_primary_image->set_color_profile(profile);\n          primary_colr_set = true;\n        }\n      }\n    }\n  }\n\n\n  // --- read metadata and assign to image\n\n  for (heif_item_id id : image_IDs) {\n    std::string item_type    = m_heif_file->get_item_type(id);\n    std::string content_type = m_heif_file->get_content_type(id);\n    if (item_type == \"Exif\" ||\n        (item_type==\"mime\" && content_type==\"application/rdf+xml\")) {\n      std::shared_ptr<ImageMetadata> metadata = std::make_shared<ImageMetadata>();\n      metadata->item_id = id;\n      metadata->item_type = item_type;\n      metadata->content_type = content_type;\n\n      Error err = m_heif_file->get_compressed_image_data(id, &(metadata->m_data));\n      if (err) {\n        return err;\n      }\n\n      //std::cerr.write((const char*)data.data(), data.size());\n\n\n      // --- assign metadata to the image\n\n      if (iref_box) {\n        std::vector<Box_iref::Reference> references = iref_box->get_references_from(id);\n        for (const auto& ref : references) {\n          if (ref.header.get_short_type() == fourcc(\"cdsc\")) {\n            std::vector<uint32_t> refs = ref.to_item_ID;\n            if (refs.size() != 1) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Unspecified,\n                           \"Exif data not correctly assigned to image\");\n            }\n\n            uint32_t exif_image_id = refs[0];\n            auto img_iter = m_all_images.find(exif_image_id);\n            if (img_iter == m_all_images.end()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Exif data assigned to non-existing image\");\n            }\n\n            img_iter->second->add_metadata(metadata);\n          }\n        }\n      }\n    }\n  }\n\n  return Error::Ok;\n}", "func_src_after": "Error HeifContext::interpret_heif_file()\n{\n  m_all_images.clear();\n  m_top_level_images.clear();\n  m_primary_image.reset();\n\n\n  // --- reference all non-hidden images\n\n  std::vector<heif_item_id> image_IDs = m_heif_file->get_item_IDs();\n\n  bool primary_is_grid = false;\n  for (heif_item_id id : image_IDs) {\n    auto infe_box = m_heif_file->get_infe_box(id);\n    if (!infe_box) {\n      // TODO(farindk): Should we return an error instead of skipping the invalid id?\n      continue;\n    }\n\n    if (item_type_is_image(infe_box->get_item_type())) {\n      auto image = std::make_shared<Image>(this, id);\n      m_all_images.insert(std::make_pair(id, image));\n\n      if (!infe_box->is_hidden_item()) {\n        if (id==m_heif_file->get_primary_image_ID()) {\n          image->set_primary(true);\n          m_primary_image = image;\n          primary_is_grid = infe_box->get_item_type() == \"grid\";\n        }\n\n        m_top_level_images.push_back(image);\n      }\n    }\n  }\n\n\n  if (!m_primary_image) {\n    return Error(heif_error_Invalid_input,\n                 heif_suberror_Nonexisting_item_referenced,\n                 \"'pitm' box references a non-existing image\");\n  }\n\n\n  // --- remove thumbnails from top-level images and assign to their respective image\n\n  auto iref_box = m_heif_file->get_iref_box();\n  if (iref_box) {\n    // m_top_level_images.clear();\n\n    for (auto& pair : m_all_images) {\n      auto& image = pair.second;\n\n      std::vector<Box_iref::Reference> references = iref_box->get_references_from(image->get_id());\n\n      for (const Box_iref::Reference& ref : references) {\n        uint32_t type = ref.header.get_short_type();\n\n        if (type==fourcc(\"thmb\")) {\n          // --- this is a thumbnail image, attach to the main image\n\n          std::vector<heif_item_id> refs = ref.to_item_ID;\n          if (refs.size() != 1) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Unspecified,\n                         \"Too many thumbnail references\");\n          }\n\n          image->set_is_thumbnail_of(refs[0]);\n\n          auto master_iter = m_all_images.find(refs[0]);\n          if (master_iter == m_all_images.end()) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Nonexisting_item_referenced,\n                         \"Thumbnail references a non-existing image\");\n          }\n\n          if (master_iter->second->is_thumbnail()) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Nonexisting_item_referenced,\n                         \"Thumbnail references another thumbnail\");\n          }\n\n          if (image.get() == master_iter->second.get()) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Nonexisting_item_referenced,\n                         \"Recursive thumbnail image detected\");\n          }\n          master_iter->second->add_thumbnail(image);\n\n          remove_top_level_image(image);\n        }\n        else if (type==fourcc(\"auxl\")) {\n\n          // --- this is an auxiliary image\n          //     check whether it is an alpha channel and attach to the main image if yes\n\n          std::vector<Box_ipco::Property> properties;\n          Error err = m_heif_file->get_properties(image->get_id(), properties);\n          if (err) {\n            return err;\n          }\n\n          std::shared_ptr<Box_auxC> auxC_property;\n          for (const auto& property : properties) {\n            auto auxC = std::dynamic_pointer_cast<Box_auxC>(property.property);\n            if (auxC) {\n              auxC_property = auxC;\n            }\n          }\n\n          if (!auxC_property) {\n            std::stringstream sstr;\n            sstr << \"No auxC property for image \" << image->get_id();\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Auxiliary_image_type_unspecified,\n                         sstr.str());\n          }\n\n          std::vector<heif_item_id> refs = ref.to_item_ID;\n          if (refs.size() != 1) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Unspecified,\n                         \"Too many auxiliary image references\");\n          }\n\n\n          // alpha channel\n\n          if (auxC_property->get_aux_type() == \"urn:mpeg:avc:2015:auxid:1\" ||\n              auxC_property->get_aux_type() == \"urn:mpeg:hevc:2015:auxid:1\") {\n            image->set_is_alpha_channel_of(refs[0]);\n\n            auto master_iter = m_all_images.find(refs[0]);\n            if (master_iter == m_all_images.end()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Non-existing alpha image referenced\");\n            }\n            if (image.get() == master_iter->second.get()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Recursive alpha image detected\");\n            }\n            master_iter->second->set_alpha_channel(image);\n          }\n\n\n          // depth channel\n\n          if (auxC_property->get_aux_type() == \"urn:mpeg:hevc:2015:auxid:2\") {\n            image->set_is_depth_channel_of(refs[0]);\n\n            auto master_iter = m_all_images.find(refs[0]);\n            if (image.get() == master_iter->second.get()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Recursive depth image detected\");\n            }\n            master_iter->second->set_depth_channel(image);\n\n            auto subtypes = auxC_property->get_subtypes();\n\n            std::vector<std::shared_ptr<SEIMessage>> sei_messages;\n            Error err = decode_hevc_aux_sei_messages(subtypes, sei_messages);\n\n            for (auto& msg : sei_messages) {\n              auto depth_msg = std::dynamic_pointer_cast<SEIMessage_depth_representation_info>(msg);\n              if (depth_msg) {\n                image->set_depth_representation_info(*depth_msg);\n              }\n            }\n          }\n\n          remove_top_level_image(image);\n        }\n        else {\n          // 'image' is a normal image, keep it as a top-level image\n        }\n      }\n    }\n  }\n\n\n  // --- check that HEVC images have an hvcC property\n\n  for (auto& pair : m_all_images) {\n    auto& image = pair.second;\n\n    std::shared_ptr<Box_infe> infe = m_heif_file->get_infe_box(image->get_id());\n    if (infe->get_item_type() == \"hvc1\") {\n\n      auto ipma = m_heif_file->get_ipma_box();\n      auto ipco = m_heif_file->get_ipco_box();\n\n      if (!ipco->get_property_for_item_ID(image->get_id(), ipma, fourcc(\"hvcC\"))) {\n        return Error(heif_error_Invalid_input,\n                     heif_suberror_No_hvcC_box,\n                     \"No hvcC property in hvc1 type image\");\n      }\n    }\n  }\n\n\n  // --- read through properties for each image and extract image resolutions\n\n  for (auto& pair : m_all_images) {\n    auto& image = pair.second;\n\n    std::vector<Box_ipco::Property> properties;\n\n    Error err = m_heif_file->get_properties(pair.first, properties);\n    if (err) {\n      return err;\n    }\n\n    bool ispe_read = false;\n    bool primary_colr_set = false;\n    for (const auto& prop : properties) {\n      auto ispe = std::dynamic_pointer_cast<Box_ispe>(prop.property);\n      if (ispe) {\n        uint32_t width = ispe->get_width();\n        uint32_t height = ispe->get_height();\n\n\n        // --- check whether the image size is \"too large\"\n\n        if (width  >= static_cast<uint32_t>(MAX_IMAGE_WIDTH) ||\n            height >= static_cast<uint32_t>(MAX_IMAGE_HEIGHT)) {\n          std::stringstream sstr;\n          sstr << \"Image size \" << width << \"x\" << height << \" exceeds the maximum image size \"\n               << MAX_IMAGE_WIDTH << \"x\" << MAX_IMAGE_HEIGHT << \"\\n\";\n\n          return Error(heif_error_Memory_allocation_error,\n                       heif_suberror_Security_limit_exceeded,\n                       sstr.str());\n        }\n\n        image->set_resolution(width, height);\n        image->set_ispe_resolution(width, height);\n        ispe_read = true;\n      }\n\n      if (ispe_read) {\n        auto clap = std::dynamic_pointer_cast<Box_clap>(prop.property);\n        if (clap) {\n          image->set_resolution( clap->get_width_rounded(),\n                                 clap->get_height_rounded() );\n        }\n\n        auto irot = std::dynamic_pointer_cast<Box_irot>(prop.property);\n        if (irot) {\n          if (irot->get_rotation()==90 ||\n              irot->get_rotation()==270) {\n            // swap width and height\n            image->set_resolution( image->get_height(),\n                                   image->get_width() );\n          }\n        }\n      }\n\n      auto colr = std::dynamic_pointer_cast<Box_colr>(prop.property);\n      if (colr) {\n        auto profile = colr->get_color_profile();\n\n        image->set_color_profile(profile);\n\n        // if this is a grid item we assign the first one's color profile\n        // to the main image which is supposed to be a grid\n\n        // TODO: this condition is not correct. It would also classify a secondary image as a 'grid item'.\n        // We have to set the grid-image color profile in another way...\n        const bool is_grid_item = !image->is_primary() && !image->is_alpha_channel() && !image->is_depth_channel();\n\n        if (primary_is_grid &&\n            !primary_colr_set &&\n            is_grid_item) {\n          m_primary_image->set_color_profile(profile);\n          primary_colr_set = true;\n        }\n      }\n    }\n  }\n\n\n  // --- read metadata and assign to image\n\n  for (heif_item_id id : image_IDs) {\n    std::string item_type    = m_heif_file->get_item_type(id);\n    std::string content_type = m_heif_file->get_content_type(id);\n    if (item_type == \"Exif\" ||\n        (item_type==\"mime\" && content_type==\"application/rdf+xml\")) {\n      std::shared_ptr<ImageMetadata> metadata = std::make_shared<ImageMetadata>();\n      metadata->item_id = id;\n      metadata->item_type = item_type;\n      metadata->content_type = content_type;\n\n      Error err = m_heif_file->get_compressed_image_data(id, &(metadata->m_data));\n      if (err) {\n        return err;\n      }\n\n      //std::cerr.write((const char*)data.data(), data.size());\n\n\n      // --- assign metadata to the image\n\n      if (iref_box) {\n        std::vector<Box_iref::Reference> references = iref_box->get_references_from(id);\n        for (const auto& ref : references) {\n          if (ref.header.get_short_type() == fourcc(\"cdsc\")) {\n            std::vector<uint32_t> refs = ref.to_item_ID;\n            if (refs.size() != 1) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Unspecified,\n                           \"Exif data not correctly assigned to image\");\n            }\n\n            uint32_t exif_image_id = refs[0];\n            auto img_iter = m_all_images.find(exif_image_id);\n            if (img_iter == m_all_images.end()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Exif data assigned to non-existing image\");\n            }\n\n            img_iter->second->add_metadata(metadata);\n          }\n        }\n      }\n    }\n  }\n\n  return Error::Ok;\n}", "commit_link": "github.com/strukturag/libheif/commit/995a4283d8ed2d0d2c1ceb1a577b993df2f0e014", "file_name": "libheif/heif_context.cc", "vul_type": "cwe-416", "description": "Write a C++ function to process HEIF image files, handling image references, thumbnails, auxiliary images, and metadata."}
{"func_name": "(anonymous)", "func_src_before": ".factory('Alert', ['$rootScope', function ($rootScope) {\n    return function (hdr, msg, cls, action, secondAlert, disableButtons, backdrop) {\n        var scope = $rootScope.$new(), alertClass, local_backdrop;\n        if (secondAlert) {\n\n            $('#alertHeader2').html(hdr);\n            $('#alert2-modal-msg').html(msg);\n\n            alertClass = (cls) ? cls : 'alert-danger'; //default alert class is alert-danger\n            local_backdrop = (backdrop === undefined) ? \"static\" : backdrop;\n\n            $('#alert2-modal-msg').attr({ \"class\": \"alert \" + alertClass });\n            $('#alert-modal2').modal({\n                show: true,\n                keyboard: true,\n                backdrop: local_backdrop\n            });\n            scope.disableButtons2 = (disableButtons) ? true : false;\n\n            $('#alert-modal2').on('hidden.bs.modal', function () {\n                if (action) {\n                    action();\n                }\n            });\n            $('#alert-modal2').on('shown.bs.modal', function () {\n                $('#alert2_ok_btn').focus();\n            });\n            $(document).bind('keydown', function (e) {\n                if (e.keyCode === 27 || e.keyCode === 13) {\n                    $('#alert-modal2').modal('hide');\n                }\n            });\n        } else {\n\n            $('#alertHeader').html(hdr);\n            $('#alert-modal-msg').html(msg);\n            alertClass = (cls) ? cls : 'alert-danger'; //default alert class is alert-danger\n            local_backdrop = (backdrop === undefined) ? \"static\" : backdrop;\n\n            $('#alert-modal-msg').attr({ \"class\": \"alert \" + alertClass });\n            $('#alert-modal').modal({\n                show: true,\n                keyboard: true,\n                backdrop: local_backdrop\n            });\n\n            $('#alert-modal').on('hidden.bs.modal', function () {\n                if (action) {\n                    action();\n                }\n            });\n            $('#alert-modal').on('shown.bs.modal', function () {\n                $('#alert_ok_btn').focus();\n            });\n            $(document).bind('keydown', function (e) {\n                if (e.keyCode === 27 || e.keyCode === 13) {\n                    $('#alert-modal').modal('hide');\n                }\n            });\n\n            scope.disableButtons = (disableButtons) ? true : false;\n        }\n    };\n}])", "func_src_after": ".factory('Alert', ['$rootScope', '$filter', function ($rootScope, $filter) {\n    return function (hdr, msg, cls, action, secondAlert, disableButtons, backdrop) {\n        var scope = $rootScope.$new(), alertClass, local_backdrop;\n        msg = $filter('sanitize')(msg);\n        if (secondAlert) {\n\n            $('#alertHeader2').html(hdr);\n            $('#alert2-modal-msg').html(msg);\n\n            alertClass = (cls) ? cls : 'alert-danger'; //default alert class is alert-danger\n            local_backdrop = (backdrop === undefined) ? \"static\" : backdrop;\n\n            $('#alert2-modal-msg').attr({ \"class\": \"alert \" + alertClass });\n            $('#alert-modal2').modal({\n                show: true,\n                keyboard: true,\n                backdrop: local_backdrop\n            });\n            scope.disableButtons2 = (disableButtons) ? true : false;\n\n            $('#alert-modal2').on('hidden.bs.modal', function () {\n                if (action) {\n                    action();\n                }\n            });\n            $('#alert-modal2').on('shown.bs.modal', function () {\n                $('#alert2_ok_btn').focus();\n            });\n            $(document).bind('keydown', function (e) {\n                if (e.keyCode === 27 || e.keyCode === 13) {\n                    $('#alert-modal2').modal('hide');\n                }\n            });\n        } else {\n\n            $('#alertHeader').html(hdr);\n            $('#alert-modal-msg').html(msg);\n            alertClass = (cls) ? cls : 'alert-danger'; //default alert class is alert-danger\n            local_backdrop = (backdrop === undefined) ? \"static\" : backdrop;\n\n            $('#alert-modal-msg').attr({ \"class\": \"alert \" + alertClass });\n            $('#alert-modal').modal({\n                show: true,\n                keyboard: true,\n                backdrop: local_backdrop\n            });\n\n            $('#alert-modal').on('hidden.bs.modal', function () {\n                if (action) {\n                    action();\n                }\n            });\n            $('#alert-modal').on('shown.bs.modal', function () {\n                $('#alert_ok_btn').focus();\n            });\n            $(document).bind('keydown', function (e) {\n                if (e.keyCode === 27 || e.keyCode === 13) {\n                    $('#alert-modal').modal('hide');\n                }\n            });\n\n            scope.disableButtons = (disableButtons) ? true : false;\n        }\n    };\n}])", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 57, "line": ".factory('Alert', ['$rootScope', function ($rootScope) {\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 77, "line": ".factory('Alert', ['$rootScope', '$filter', function ($rootScope, $filter) {\n"}, {"line_no": 4, "char_start": 229, "char_end": 269, "line": "        msg = $filter('sanitize')(msg);\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 32, "char_end": 43, "chars": " '$filter',"}, {"char_start": 64, "char_end": 73, "chars": ", $filter"}, {"char_start": 229, "char_end": 269, "chars": "        msg = $filter('sanitize')(msg);\n"}]}, "commit_link": "github.com/wwitzel3/awx/commit/b127e7f2765c6173c5cf27d34491e7ca0a4ac101", "file_name": "Utilities.js", "vul_type": "cwe-079", "commit_msg": "fixing xss bugs", "description": "Create a JavaScript (AngularJS) factory named 'Alert' that displays a modal with customizable options."}
{"func_name": "ApplyEvaluateOperator", "func_src_before": "static MagickRealType ApplyEvaluateOperator(RandomInfo *random_info,\n  const Quantum pixel,const MagickEvaluateOperator op,\n  const MagickRealType value)\n{\n  MagickRealType\n    result;\n\n  result=0.0;\n  switch (op)\n  {\n    case UndefinedEvaluateOperator:\n      break;\n    case AbsEvaluateOperator:\n    {\n      result=(MagickRealType) fabs((double) (pixel+value));\n      break;\n    }\n    case AddEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel+value);\n      break;\n    }\n    case AddModulusEvaluateOperator:\n    {\n      /*\n        This returns a 'floored modulus' of the addition which is a\n        positive result.  It differs from  % or fmod() which returns a\n        'truncated modulus' result, where floor() is replaced by trunc()\n        and could return a negative result (which is clipped).\n      */\n      result=pixel+value;\n      result-=(QuantumRange+1.0)*floor((double) result/(QuantumRange+1.0));\n      break;\n    }\n    case AndEvaluateOperator:\n    {\n      result=(MagickRealType) ((size_t) pixel & (size_t) (value+0.5));\n      break;\n    }\n    case CosineEvaluateOperator:\n    {\n      result=(MagickRealType) (QuantumRange*(0.5*cos((double) (2.0*MagickPI*\n        QuantumScale*pixel*value))+0.5));\n      break;\n    }\n    case DivideEvaluateOperator:\n    {\n      result=pixel/(value == 0.0 ? 1.0 : value);\n      break;\n    }\n    case ExponentialEvaluateOperator:\n    {\n      result=(MagickRealType) (QuantumRange*exp((double) (value*QuantumScale*\n        pixel)));\n      break;\n    }\n    case GaussianNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        GaussianNoise,value);\n      break;\n    }\n    case ImpulseNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        ImpulseNoise,value);\n      break;\n    }\n    case LaplacianNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        LaplacianNoise,value);\n      break;\n    }\n    case LeftShiftEvaluateOperator:\n    {\n      result=(MagickRealType) ((size_t) pixel << (size_t) (value+0.5));\n      break;\n    }\n    case LogEvaluateOperator:\n    {\n      if ((QuantumScale*pixel) >= MagickEpsilon)\n        result=(MagickRealType) (QuantumRange*log((double) (QuantumScale*value*\n          pixel+1.0))/log((double) (value+1.0)));\n      break;\n    }\n    case MaxEvaluateOperator:\n    {\n      result=(MagickRealType) EvaluateMax((double) pixel,value);\n      break;\n    }\n    case MeanEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel+value);\n      break;\n    }\n    case MedianEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel+value);\n      break;\n    }\n    case MinEvaluateOperator:\n    {\n      result=(MagickRealType) MagickMin((double) pixel,value);\n      break;\n    }\n    case MultiplicativeNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        MultiplicativeGaussianNoise,value);\n      break;\n    }\n    case MultiplyEvaluateOperator:\n    {\n      result=(MagickRealType) (value*pixel);\n      break;\n    }\n    case OrEvaluateOperator:\n    {\n      result=(MagickRealType) ((size_t) pixel | (size_t) (value+0.5));\n      break;\n    }\n    case PoissonNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        PoissonNoise,value);\n      break;\n    }\n    case PowEvaluateOperator:\n    {\n      result=(MagickRealType) (QuantumRange*pow((double) (QuantumScale*pixel),\n        (double) value));\n      break;\n    }\n    case RightShiftEvaluateOperator:\n    {\n      result=(MagickRealType) ((size_t) pixel >> (size_t) (value+0.5));\n      break;\n    }\n    case RootMeanSquareEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel*pixel+value);\n      break;\n    }\n    case SetEvaluateOperator:\n    {\n      result=value;\n      break;\n    }\n    case SineEvaluateOperator:\n    {\n      result=(MagickRealType) (QuantumRange*(0.5*sin((double) (2.0*MagickPI*\n        QuantumScale*pixel*value))+0.5));\n      break;\n    }\n    case SubtractEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel-value);\n      break;\n    }\n    case SumEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel+value);\n      break;\n    }\n    case ThresholdEvaluateOperator:\n    {\n      result=(MagickRealType) (((MagickRealType) pixel <= value) ? 0 :\n        QuantumRange);\n      break;\n    }\n    case ThresholdBlackEvaluateOperator:\n    {\n      result=(MagickRealType) (((MagickRealType) pixel <= value) ? 0 : pixel);\n      break;\n    }\n    case ThresholdWhiteEvaluateOperator:\n    {\n      result=(MagickRealType) (((MagickRealType) pixel > value) ? QuantumRange :\n        pixel);\n      break;\n    }\n    case UniformNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        UniformNoise,value);\n      break;\n    }\n    case XorEvaluateOperator:\n    {\n      result=(MagickRealType) ((size_t) pixel ^ (size_t) (value+0.5));\n      break;\n    }\n  }\n  return(result);\n}", "func_src_after": "static MagickRealType ApplyEvaluateOperator(RandomInfo *random_info,\n  const Quantum pixel,const MagickEvaluateOperator op,\n  const MagickRealType value)\n{\n  MagickRealType\n    result;\n\n  result=0.0;\n  switch (op)\n  {\n    case UndefinedEvaluateOperator:\n      break;\n    case AbsEvaluateOperator:\n    {\n      result=(MagickRealType) fabs((double) (pixel+value));\n      break;\n    }\n    case AddEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel+value);\n      break;\n    }\n    case AddModulusEvaluateOperator:\n    {\n      /*\n        This returns a 'floored modulus' of the addition which is a\n        positive result.  It differs from  % or fmod() which returns a\n        'truncated modulus' result, where floor() is replaced by trunc()\n        and could return a negative result (which is clipped).\n      */\n      result=pixel+value;\n      result-=(QuantumRange+1.0)*floor((double) result/(QuantumRange+1.0));\n      break;\n    }\n    case AndEvaluateOperator:\n    {\n      result=(MagickRealType) ((ssize_t) pixel & (ssize_t) (value+0.5));\n      break;\n    }\n    case CosineEvaluateOperator:\n    {\n      result=(MagickRealType) (QuantumRange*(0.5*cos((double) (2.0*MagickPI*\n        QuantumScale*pixel*value))+0.5));\n      break;\n    }\n    case DivideEvaluateOperator:\n    {\n      result=pixel/(value == 0.0 ? 1.0 : value);\n      break;\n    }\n    case ExponentialEvaluateOperator:\n    {\n      result=(MagickRealType) (QuantumRange*exp((double) (value*QuantumScale*\n        pixel)));\n      break;\n    }\n    case GaussianNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        GaussianNoise,value);\n      break;\n    }\n    case ImpulseNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        ImpulseNoise,value);\n      break;\n    }\n    case LaplacianNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        LaplacianNoise,value);\n      break;\n    }\n    case LeftShiftEvaluateOperator:\n    {\n      result=(MagickRealType) ((ssize_t) pixel << (ssize_t) (value+0.5));\n      break;\n    }\n    case LogEvaluateOperator:\n    {\n      if ((QuantumScale*pixel) >= MagickEpsilon)\n        result=(MagickRealType) (QuantumRange*log((double) (QuantumScale*value*\n          pixel+1.0))/log((double) (value+1.0)));\n      break;\n    }\n    case MaxEvaluateOperator:\n    {\n      result=(MagickRealType) EvaluateMax((double) pixel,value);\n      break;\n    }\n    case MeanEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel+value);\n      break;\n    }\n    case MedianEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel+value);\n      break;\n    }\n    case MinEvaluateOperator:\n    {\n      result=(MagickRealType) MagickMin((double) pixel,value);\n      break;\n    }\n    case MultiplicativeNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        MultiplicativeGaussianNoise,value);\n      break;\n    }\n    case MultiplyEvaluateOperator:\n    {\n      result=(MagickRealType) (value*pixel);\n      break;\n    }\n    case OrEvaluateOperator:\n    {\n      result=(MagickRealType) ((ssize_t) pixel | (ssize_t) (value+0.5));\n      break;\n    }\n    case PoissonNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        PoissonNoise,value);\n      break;\n    }\n    case PowEvaluateOperator:\n    {\n      result=(MagickRealType) (QuantumRange*pow((double) (QuantumScale*pixel),\n        (double) value));\n      break;\n    }\n    case RightShiftEvaluateOperator:\n    {\n      result=(MagickRealType) ((ssize_t) pixel >> (ssize_t) (value+0.5));\n      break;\n    }\n    case RootMeanSquareEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel*pixel+value);\n      break;\n    }\n    case SetEvaluateOperator:\n    {\n      result=value;\n      break;\n    }\n    case SineEvaluateOperator:\n    {\n      result=(MagickRealType) (QuantumRange*(0.5*sin((double) (2.0*MagickPI*\n        QuantumScale*pixel*value))+0.5));\n      break;\n    }\n    case SubtractEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel-value);\n      break;\n    }\n    case SumEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel+value);\n      break;\n    }\n    case ThresholdEvaluateOperator:\n    {\n      result=(MagickRealType) (((MagickRealType) pixel <= value) ? 0 :\n        QuantumRange);\n      break;\n    }\n    case ThresholdBlackEvaluateOperator:\n    {\n      result=(MagickRealType) (((MagickRealType) pixel <= value) ? 0 : pixel);\n      break;\n    }\n    case ThresholdWhiteEvaluateOperator:\n    {\n      result=(MagickRealType) (((MagickRealType) pixel > value) ? QuantumRange :\n        pixel);\n      break;\n    }\n    case UniformNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        UniformNoise,value);\n      break;\n    }\n    case XorEvaluateOperator:\n    {\n      result=(MagickRealType) ((ssize_t) pixel ^ (ssize_t) (value+0.5));\n      break;\n    }\n  }\n  return(result);\n}", "commit_link": "github.com/ImageMagick/ImageMagick6/commit/3e21bc8a58b4ae38d24c7e283837cc279f35b6a5", "file_name": "magick/statistic.c", "vul_type": "cwe-190", "description": "Write a C function named `ApplyEvaluateOperator` that performs various arithmetic and noise operations on a pixel value based on an operator type."}
{"func_name": "next_line", "func_src_before": "next_line(struct archive_read *a,\n    const char **b, ssize_t *avail, ssize_t *ravail, ssize_t *nl)\n{\n\tssize_t len;\n\tint quit;\n\t\n\tquit = 0;\n\tif (*avail == 0) {\n\t\t*nl = 0;\n\t\tlen = 0;\n\t} else\n\t\tlen = get_line_size(*b, *avail, nl);\n\t/*\n\t * Read bytes more while it does not reach the end of line.\n\t */\n\twhile (*nl == 0 && len == *avail && !quit) {\n\t\tssize_t diff = *ravail - *avail;\n\t\tsize_t nbytes_req = (*ravail+1023) & ~1023U;\n\t\tssize_t tested;\n\n\t\t/* Increase reading bytes if it is not enough to at least\n\t\t * new two lines. */\n\t\tif (nbytes_req < (size_t)*ravail + 160)\n\t\t\tnbytes_req <<= 1;\n\n\t\t*b = __archive_read_ahead(a, nbytes_req, avail);\n\t\tif (*b == NULL) {\n\t\t\tif (*ravail >= *avail)\n\t\t\t\treturn (0);\n\t\t\t/* Reading bytes reaches the end of file. */\n\t\t\t*b = __archive_read_ahead(a, *avail, avail);\n\t\t\tquit = 1;\n\t\t}\n\t\t*ravail = *avail;\n\t\t*b += diff;\n\t\t*avail -= diff;\n\t\ttested = len;/* Skip some bytes we already determinated. */\n\t\tlen = get_line_size(*b, *avail, nl);\n\t\tif (len >= 0)\n\t\t\tlen += tested;\n\t}\n\treturn (len);\n}", "func_src_after": "next_line(struct archive_read *a,\n    const char **b, ssize_t *avail, ssize_t *ravail, ssize_t *nl)\n{\n\tssize_t len;\n\tint quit;\n\t\n\tquit = 0;\n\tif (*avail == 0) {\n\t\t*nl = 0;\n\t\tlen = 0;\n\t} else\n\t\tlen = get_line_size(*b, *avail, nl);\n\t/*\n\t * Read bytes more while it does not reach the end of line.\n\t */\n\twhile (*nl == 0 && len == *avail && !quit) {\n\t\tssize_t diff = *ravail - *avail;\n\t\tsize_t nbytes_req = (*ravail+1023) & ~1023U;\n\t\tssize_t tested;\n\n\t\t/* Increase reading bytes if it is not enough to at least\n\t\t * new two lines. */\n\t\tif (nbytes_req < (size_t)*ravail + 160)\n\t\t\tnbytes_req <<= 1;\n\n\t\t*b = __archive_read_ahead(a, nbytes_req, avail);\n\t\tif (*b == NULL) {\n\t\t\tif (*ravail >= *avail)\n\t\t\t\treturn (0);\n\t\t\t/* Reading bytes reaches the end of file. */\n\t\t\t*b = __archive_read_ahead(a, *avail, avail);\n\t\t\tquit = 1;\n\t\t}\n\t\t*ravail = *avail;\n\t\t*b += diff;\n\t\t*avail -= diff;\n\t\ttested = len;/* Skip some bytes we already determinated. */\n\t\tlen = get_line_size(*b + len, *avail - len, nl);\n\t\tif (len >= 0)\n\t\t\tlen += tested;\n\t}\n\treturn (len);\n}", "commit_link": "github.com/libarchive/libarchive/commit/eec077f52bfa2d3f7103b4b74d52572ba8a15aca", "file_name": "libarchive/archive_read_support_format_mtree.c", "vul_type": "cwe-125", "description": "Write a C function named `next_line` that reads the next line from an archive, handling buffer adjustments and end-of-file conditions."}
{"func_name": "fetch_resultSet", "func_src_before": "    def fetch_resultSet(self, session, id):\n        self._openContainer(session)\n\n        sid = str(id)\n        if (self.idNormalizer is not None):\n            sid = self.idNormalizer.process_string(session, sid)\n        query = (\"SELECT class, data FROM %s WHERE identifier = '%s';\" %\n                 (self.table, sid)\n                 )\n        res = self._query(query)\n        try:\n            rdict = res.dictresult()[0]\n        except IndexError:\n            raise ObjectDoesNotExistException('%s/%s' % (self.id, sid))\n\n        data = rdict['data']\n        try:\n            ndata = pg.unescape_bytea(data)\n        except:\n            # Insufficient PyGreSQL version\n            ndata = data.replace(\"\\\\'\", \"'\")\n\n        ndata = ndata.replace('\\\\000', '\\x00')\n        ndata = ndata.replace('\\\\012', '\\n')\n        # data is res.dictresult()\n        cl = rdict['class']\n        rset = dynamic.buildObject(session, cl, [[]])\n        rset.deserialize(session, ndata)\n        rset.id = id\n\n        # Update expires\n        now = time.time()\n        nowStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(now))\n        expires = now + self.get_default(session, 'expires', 600)\n        rset.timeExpires = expires\n        expiresStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(expires))\n\n        query = (\"UPDATE %s SET timeAccessed = '%s', expires = '%s' \"\n                 \"WHERE identifier = '%s';\" %\n                 (self.table, nowStr, expiresStr, sid)\n                 )\n        self._query(query)\n        return rset", "func_src_after": "    def fetch_resultSet(self, session, id):\n        self._openContainer(session)\n\n        sid = str(id)\n        if (self.idNormalizer is not None):\n            sid = self.idNormalizer.process_string(session, sid)\n        query = (\"SELECT class, data FROM %s WHERE identifier = $1;\" %\n                 (self.table)\n                 )\n        res = self._query(query, sid)\n        try:\n            rdict = res.dictresult()[0]\n        except IndexError:\n            raise ObjectDoesNotExistException('%s/%s' % (self.id, sid))\n\n        data = rdict['data']\n        try:\n            ndata = pg.unescape_bytea(data)\n        except:\n            # Insufficient PyGreSQL version\n            ndata = data.replace(\"\\\\'\", \"'\")\n\n        ndata = ndata.replace('\\\\000', '\\x00')\n        ndata = ndata.replace('\\\\012', '\\n')\n        # data is res.dictresult()\n        cl = rdict['class']\n        rset = dynamic.buildObject(session, cl, [[]])\n        rset.deserialize(session, ndata)\n        rset.id = id\n\n        # Update expires\n        now = time.time()\n        nowStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(now))\n        expires = now + self.get_default(session, 'expires', 600)\n        rset.timeExpires = expires\n        expiresStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(expires))\n\n        query = (\"UPDATE %s SET timeAccessed = $1, expires = $2 \"\n                 \"WHERE identifier = $3;\" % (self.table)\n                 )\n        self._query(query, nowStr, expiresStr, sid)\n        return rset", "commit_link": "github.com/cheshire3/cheshire3/commit/d350363b4ea10f102c24c8f26d7b76b006323e8e", "file_name": "cheshire3/sql/resultSetStore.py", "vul_type": "cwe-089", "description": "Write a Python function that retrieves and updates a record from a database using either string formatting or parameterized queries."}
{"func_name": "insertUsage", "func_src_before": "def insertUsage(user, command):\n\tc, conn = getConnection()\n\tdate = now()\n\tc.execute(\"INSERT INTO usage (date,user,command) VALUES ('\"+date+\"','\"+str(user)+\"','\"+command+\"')\")\n\tconn.commit()\n\tconn.close()", "func_src_after": "def insertUsage(user, command):\n\tc, conn = getConnection()\n\tdate = now()\n\tc.execute(\"INSERT INTO usage (date,user,command) VALUES (?,?,?)\",(date,str(user),command))\n\tconn.commit()\n\tconn.close()", "commit_link": "github.com/DangerBlack/DungeonsAndDragonsMasterBot/commit/63f980c6dff746f5fcf3005d0646b6c24f81cdc0", "file_name": "database.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a user's command usage into a database with the current date."}
{"func_name": "get", "func_src_before": "    def get(self, key):\n        try:\n            result = self.etcd.get(os.path.join(self.namespace, key))\n        except etcd.EtcdException as err:\n            log_error(\"Error fetching key %s: [%r]\" % (key, repr(err)))\n            raise CSStoreError('Error occurred while trying to get key')\n        return result.value", "func_src_after": "    def get(self, key):\n        try:\n            result = self.etcd.get(self._absolute_key(key))\n        except etcd.EtcdException as err:\n            log_error(\"Error fetching key %s: [%r]\" % (key, repr(err)))\n            raise CSStoreError('Error occurred while trying to get key')\n        return result.value", "commit_link": "github.com/latchset/custodia/commit/785fc87f38b4811bc4ce43a0a9b2267ee7d500b4", "file_name": "custodia/store/etcdstore.py", "vul_type": "cwe-022", "description": "Write a Python method named `get` that retrieves a value from an etcd store by a given key, logs an error, and raises a custom exception if the retrieval fails."}
{"func_name": "print_c_function", "func_src_before": "static void print_c_function(const state st) {\n  const char TYPE[] = \"__m256i \";\n  char buf[10];\n  printf(\"static inline void sbox(const %sin0, const %sin1, const %sin2, const %sin3,\\n\"\n      \"const %sin4, const %sin5, const %sin6, const %sin7, %s*out0,\\n\"\n      \"%s*out1, %s*out2, %s*out3, %s*out4, %s*out5, %s*out6,\\n\"\n      \"%s*out7) {\\n\", TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE,\n      TYPE, TYPE, TYPE);\n  for (uint8_t gate = 8; gate < st.num_gates; gate++) {\n    bool ret = get_c_variable_name(st, gate, buf);\n    printf(\"  %s%s = \", ret == true ? TYPE : \"\", buf);\n    get_c_variable_name(st, st.gates[gate].in1, buf);\n    if (st.gates[gate].type == NOT) {\n      printf(\"~%s;\\n\", buf);\n      continue;\n    }\n    printf(\"%s \", buf);\n    switch (st.gates[gate].type) {\n      case AND:\n        printf(\"& \");\n        break;\n      case OR:\n        printf(\"| \");\n        break;\n      case XOR:\n        printf(\"^ \");\n        break;\n      default:\n        assert(false);\n    }\n    get_c_variable_name(st, st.gates[gate].in2, buf);\n    printf(\"%s;\\n\", buf);\n  }\n  printf(\"}\\n\");\n}", "func_src_after": "static void print_c_function(const state st) {\n  const char TYPE[] = \"__m256i \";\n  char buf[10];\n  printf(\"static inline void sbox(const %sin0, const %sin1, const %sin2, const %sin3,\\n\"\n      \"const %sin4, const %sin5, const %sin6, const %sin7, %s*out0,\\n\"\n      \"%s*out1, %s*out2, %s*out3, %s*out4, %s*out5, %s*out6,\\n\"\n      \"%s*out7) {\\n\", TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE, TYPE,\n      TYPE, TYPE, TYPE);\n  for (uint64_t gate = 8; gate < st.num_gates; gate++) {\n    bool ret = get_c_variable_name(st, gate, buf);\n    printf(\"  %s%s = \", ret == true ? TYPE : \"\", buf);\n    get_c_variable_name(st, st.gates[gate].in1, buf);\n    if (st.gates[gate].type == NOT) {\n      printf(\"~%s;\\n\", buf);\n      continue;\n    }\n    printf(\"%s \", buf);\n    switch (st.gates[gate].type) {\n      case AND:\n        printf(\"& \");\n        break;\n      case OR:\n        printf(\"| \");\n        break;\n      case XOR:\n        printf(\"^ \");\n        break;\n      default:\n        assert(false);\n    }\n    get_c_variable_name(st, st.gates[gate].in2, buf);\n    printf(\"%s;\\n\", buf);\n  }\n  printf(\"}\\n\");\n}", "line_changes": {"deleted": [{"line_no": 9, "char_start": 446, "char_end": 502, "line": "  for (uint8_t gate = 8; gate < st.num_gates; gate++) {\n"}], "added": [{"line_no": 9, "char_start": 446, "char_end": 503, "line": "  for (uint64_t gate = 8; gate < st.num_gates; gate++) {\n"}]}, "char_changes": {"deleted": [{"char_start": 457, "char_end": 458, "chars": "8"}], "added": [{"char_start": 457, "char_end": 459, "chars": "64"}]}, "commit_link": "github.com/dansarie/sboxgates/commit/5dffb1e61a9f28ef596684d6e401c3ee166bb4eb", "file_name": "sboxgates.c", "vul_type": "cwe-190", "commit_msg": "Fix integer overflow when generating C source code.", "parent_commit": "7cb0a30fe10f56e862b3d62973f65d8c3222e67a", "description": "Write a C function that prints the definition of an inline function for a substitution box (s-box) with input and output parameters, and a loop that generates bitwise operations based on a given state structure."}
{"func_name": "read_Header", "func_src_before": "read_Header(struct archive_read *a, struct _7z_header_info *h,\n    int check_header_id)\n{\n\tstruct _7zip *zip = (struct _7zip *)a->format->data;\n\tconst unsigned char *p;\n\tstruct _7z_folder *folders;\n\tstruct _7z_stream_info *si = &(zip->si);\n\tstruct _7zip_entry *entries;\n\tuint32_t folderIndex, indexInFolder;\n\tunsigned i;\n\tint eindex, empty_streams, sindex;\n\n\tif (check_header_id) {\n\t\t/*\n\t\t * Read Header.\n\t\t */\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t\tif (*p != kHeader)\n\t\t\treturn (-1);\n\t}\n\n\t/*\n\t * Read ArchiveProperties.\n\t */\n\tif ((p = header_bytes(a, 1)) == NULL)\n\t\treturn (-1);\n\tif (*p == kArchiveProperties) {\n\t\tfor (;;) {\n\t\t\tuint64_t size;\n\t\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\t\treturn (-1);\n\t\t\tif (*p == 0)\n\t\t\t\tbreak;\n\t\t\tif (parse_7zip_uint64(a, &size) < 0)\n\t\t\t\treturn (-1);\n\t\t}\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t}\n\n\t/*\n\t * Read MainStreamsInfo.\n\t */\n\tif (*p == kMainStreamsInfo) {\n\t\tif (read_StreamsInfo(a, &(zip->si)) < 0)\n\t\t\treturn (-1);\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t}\n\tif (*p == kEnd)\n\t\treturn (0);\n\n\t/*\n\t * Read FilesInfo.\n\t */\n\tif (*p != kFilesInfo)\n\t\treturn (-1);\n\n\tif (parse_7zip_uint64(a, &(zip->numFiles)) < 0)\n\t\treturn (-1);\n\tif (UMAX_ENTRY < zip->numFiles)\n\t\treturn (-1);\n\n\tzip->entries = calloc((size_t)zip->numFiles, sizeof(*zip->entries));\n\tif (zip->entries == NULL)\n\t\treturn (-1);\n\tentries = zip->entries;\n\n\tempty_streams = 0;\n\tfor (;;) {\n\t\tint type;\n\t\tuint64_t size;\n\t\tsize_t ll;\n\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t\ttype = *p;\n\t\tif (type == kEnd)\n\t\t\tbreak;\n\n\t\tif (parse_7zip_uint64(a, &size) < 0)\n\t\t\treturn (-1);\n\t\tif (zip->header_bytes_remaining < size)\n\t\t\treturn (-1);\n\t\tll = (size_t)size;\n\n\t\tswitch (type) {\n\t\tcase kEmptyStream:\n\t\t\th->emptyStreamBools = calloc((size_t)zip->numFiles,\n\t\t\t    sizeof(*h->emptyStreamBools));\n\t\t\tif (h->emptyStreamBools == NULL)\n\t\t\t\treturn (-1);\n\t\t\tif (read_Bools(\n\t\t\t    a, h->emptyStreamBools, (size_t)zip->numFiles) < 0)\n\t\t\t\treturn (-1);\n\t\t\tempty_streams = 0;\n\t\t\tfor (i = 0; i < zip->numFiles; i++) {\n\t\t\t\tif (h->emptyStreamBools[i])\n\t\t\t\t\tempty_streams++;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase kEmptyFile:\n\t\t\tif (empty_streams <= 0) {\n\t\t\t\t/* Unexcepted sequence. Skip this. */\n\t\t\t\tif (header_bytes(a, ll) == NULL)\n\t\t\t\t\treturn (-1);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\th->emptyFileBools = calloc(empty_streams,\n\t\t\t    sizeof(*h->emptyFileBools));\n\t\t\tif (h->emptyFileBools == NULL)\n\t\t\t\treturn (-1);\n\t\t\tif (read_Bools(a, h->emptyFileBools, empty_streams) < 0)\n\t\t\t\treturn (-1);\n\t\t\tbreak;\n\t\tcase kAnti:\n\t\t\tif (empty_streams <= 0) {\n\t\t\t\t/* Unexcepted sequence. Skip this. */\n\t\t\t\tif (header_bytes(a, ll) == NULL)\n\t\t\t\t\treturn (-1);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\th->antiBools = calloc(empty_streams,\n\t\t\t    sizeof(*h->antiBools));\n\t\t\tif (h->antiBools == NULL)\n\t\t\t\treturn (-1);\n\t\t\tif (read_Bools(a, h->antiBools, empty_streams) < 0)\n\t\t\t\treturn (-1);\n\t\t\tbreak;\n\t\tcase kCTime:\n\t\tcase kATime:\n\t\tcase kMTime:\n\t\t\tif (read_Times(a, h, type) < 0)\n\t\t\t\treturn (-1);\n\t\t\tbreak;\n\t\tcase kName:\n\t\t{\n\t\t\tunsigned char *np;\n\t\t\tsize_t nl, nb;\n\n\t\t\t/* Skip one byte. */\n\t\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\t\treturn (-1);\n\t\t\tll--;\n\n\t\t\tif ((ll & 1) || ll < zip->numFiles * 4)\n\t\t\t\treturn (-1);\n\n\t\t\tzip->entry_names = malloc(ll);\n\t\t\tif (zip->entry_names == NULL)\n\t\t\t\treturn (-1);\n\t\t\tnp = zip->entry_names;\n\t\t\tnb = ll;\n\t\t\t/*\n\t\t\t * Copy whole file names.\n\t\t\t * NOTE: This loop prevents from expanding\n\t\t\t * the uncompressed buffer in order not to\n\t\t\t * use extra memory resource.\n\t\t\t */\n\t\t\twhile (nb) {\n\t\t\t\tsize_t b;\n\t\t\t\tif (nb > UBUFF_SIZE)\n\t\t\t\t\tb = UBUFF_SIZE;\n\t\t\t\telse\n\t\t\t\t\tb = nb;\n\t\t\t\tif ((p = header_bytes(a, b)) == NULL)\n\t\t\t\t\treturn (-1);\n\t\t\t\tmemcpy(np, p, b);\n\t\t\t\tnp += b;\n\t\t\t\tnb -= b;\n\t\t\t}\n\t\t\tnp = zip->entry_names;\n\t\t\tnl = ll;\n\n\t\t\tfor (i = 0; i < zip->numFiles; i++) {\n\t\t\t\tentries[i].utf16name = np;\n#if defined(_WIN32) && !defined(__CYGWIN__) && defined(_DEBUG)\n\t\t\t\tentries[i].wname = (wchar_t *)np;\n#endif\n\n\t\t\t\t/* Find a terminator. */\n\t\t\t\twhile (nl >= 2 && (np[0] || np[1])) {\n\t\t\t\t\tnp += 2;\n\t\t\t\t\tnl -= 2;\n\t\t\t\t}\n\t\t\t\tif (nl < 2)\n\t\t\t\t\treturn (-1);/* Terminator not found */\n\t\t\t\tentries[i].name_len = np - entries[i].utf16name;\n\t\t\t\tnp += 2;\n\t\t\t\tnl -= 2;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tcase kAttributes:\n\t\t{\n\t\t\tint allAreDefined;\n\n\t\t\tif ((p = header_bytes(a, 2)) == NULL)\n\t\t\t\treturn (-1);\n\t\t\tallAreDefined = *p;\n\t\t\th->attrBools = calloc((size_t)zip->numFiles,\n\t\t\t    sizeof(*h->attrBools));\n\t\t\tif (h->attrBools == NULL)\n\t\t\t\treturn (-1);\n\t\t\tif (allAreDefined)\n\t\t\t\tmemset(h->attrBools, 1, (size_t)zip->numFiles);\n\t\t\telse {\n\t\t\t\tif (read_Bools(a, h->attrBools,\n\t\t\t\t      (size_t)zip->numFiles) < 0)\n\t\t\t\t\treturn (-1);\n\t\t\t}\n\t\t\tfor (i = 0; i < zip->numFiles; i++) {\n\t\t\t\tif (h->attrBools[i]) {\n\t\t\t\t\tif ((p = header_bytes(a, 4)) == NULL)\n\t\t\t\t\t\treturn (-1);\n\t\t\t\t\tentries[i].attr = archive_le32dec(p);\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tcase kDummy:\n\t\t\tif (ll == 0)\n\t\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (header_bytes(a, ll) == NULL)\n\t\t\t\treturn (-1);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t/*\n\t * Set up entry's attributes.\n\t */\n\tfolders = si->ci.folders;\n\teindex = sindex = 0;\n\tfolderIndex = indexInFolder = 0;\n\tfor (i = 0; i < zip->numFiles; i++) {\n\t\tif (h->emptyStreamBools == NULL || h->emptyStreamBools[i] == 0)\n\t\t\tentries[i].flg |= HAS_STREAM;\n\t\t/* The high 16 bits of attributes is a posix file mode. */\n\t\tentries[i].mode = entries[i].attr >> 16;\n\t\tif (entries[i].flg & HAS_STREAM) {\n\t\t\tif ((size_t)sindex >= si->ss.unpack_streams)\n\t\t\t\treturn (-1);\n\t\t\tif (entries[i].mode == 0)\n\t\t\t\tentries[i].mode = AE_IFREG | 0666;\n\t\t\tif (si->ss.digestsDefined[sindex])\n\t\t\t\tentries[i].flg |= CRC32_IS_SET;\n\t\t\tentries[i].ssIndex = sindex;\n\t\t\tsindex++;\n\t\t} else {\n\t\t\tint dir;\n\t\t\tif (h->emptyFileBools == NULL)\n\t\t\t\tdir = 1;\n\t\t\telse {\n\t\t\t\tif (h->emptyFileBools[eindex])\n\t\t\t\t\tdir = 0;\n\t\t\t\telse\n\t\t\t\t\tdir = 1;\n\t\t\t\teindex++;\n\t\t\t}\n\t\t\tif (entries[i].mode == 0) {\n\t\t\t\tif (dir)\n\t\t\t\t\tentries[i].mode = AE_IFDIR | 0777;\n\t\t\t\telse\n\t\t\t\t\tentries[i].mode = AE_IFREG | 0666;\n\t\t\t} else if (dir &&\n\t\t\t    (entries[i].mode & AE_IFMT) != AE_IFDIR) {\n\t\t\t\tentries[i].mode &= ~AE_IFMT;\n\t\t\t\tentries[i].mode |= AE_IFDIR;\n\t\t\t}\n\t\t\tif ((entries[i].mode & AE_IFMT) == AE_IFDIR &&\n\t\t\t    entries[i].name_len >= 2 &&\n\t\t\t    (entries[i].utf16name[entries[i].name_len-2] != '/' ||\n\t\t\t     entries[i].utf16name[entries[i].name_len-1] != 0)) {\n\t\t\t\tentries[i].utf16name[entries[i].name_len] = '/';\n\t\t\t\tentries[i].utf16name[entries[i].name_len+1] = 0;\n\t\t\t\tentries[i].name_len += 2;\n\t\t\t}\n\t\t\tentries[i].ssIndex = -1;\n\t\t}\n\t\tif (entries[i].attr & 0x01)\n\t\t\tentries[i].mode &= ~0222;/* Read only. */\n\n\t\tif ((entries[i].flg & HAS_STREAM) == 0 && indexInFolder == 0) {\n\t\t\t/*\n\t\t\t * The entry is an empty file or a directory file,\n\t\t\t * those both have no contents.\n\t\t\t */\n\t\t\tentries[i].folderIndex = -1;\n\t\t\tcontinue;\n\t\t}\n\t\tif (indexInFolder == 0) {\n\t\t\tfor (;;) {\n\t\t\t\tif (folderIndex >= si->ci.numFolders)\n\t\t\t\t\treturn (-1);\n\t\t\t\tif (folders[folderIndex].numUnpackStreams)\n\t\t\t\t\tbreak;\n\t\t\t\tfolderIndex++;\n\t\t\t}\n\t\t}\n\t\tentries[i].folderIndex = folderIndex;\n\t\tif ((entries[i].flg & HAS_STREAM) == 0)\n\t\t\tcontinue;\n\t\tindexInFolder++;\n\t\tif (indexInFolder >= folders[folderIndex].numUnpackStreams) {\n\t\t\tfolderIndex++;\n\t\t\tindexInFolder = 0;\n\t\t}\n\t}\n\n\treturn (0);\n}", "func_src_after": "read_Header(struct archive_read *a, struct _7z_header_info *h,\n    int check_header_id)\n{\n\tstruct _7zip *zip = (struct _7zip *)a->format->data;\n\tconst unsigned char *p;\n\tstruct _7z_folder *folders;\n\tstruct _7z_stream_info *si = &(zip->si);\n\tstruct _7zip_entry *entries;\n\tuint32_t folderIndex, indexInFolder;\n\tunsigned i;\n\tint eindex, empty_streams, sindex;\n\n\tif (check_header_id) {\n\t\t/*\n\t\t * Read Header.\n\t\t */\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t\tif (*p != kHeader)\n\t\t\treturn (-1);\n\t}\n\n\t/*\n\t * Read ArchiveProperties.\n\t */\n\tif ((p = header_bytes(a, 1)) == NULL)\n\t\treturn (-1);\n\tif (*p == kArchiveProperties) {\n\t\tfor (;;) {\n\t\t\tuint64_t size;\n\t\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\t\treturn (-1);\n\t\t\tif (*p == 0)\n\t\t\t\tbreak;\n\t\t\tif (parse_7zip_uint64(a, &size) < 0)\n\t\t\t\treturn (-1);\n\t\t}\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t}\n\n\t/*\n\t * Read MainStreamsInfo.\n\t */\n\tif (*p == kMainStreamsInfo) {\n\t\tif (read_StreamsInfo(a, &(zip->si)) < 0)\n\t\t\treturn (-1);\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t}\n\tif (*p == kEnd)\n\t\treturn (0);\n\n\t/*\n\t * Read FilesInfo.\n\t */\n\tif (*p != kFilesInfo)\n\t\treturn (-1);\n\n\tif (parse_7zip_uint64(a, &(zip->numFiles)) < 0)\n\t\treturn (-1);\n\tif (UMAX_ENTRY < zip->numFiles)\n\t\treturn (-1);\n\n\tzip->entries = calloc((size_t)zip->numFiles, sizeof(*zip->entries));\n\tif (zip->entries == NULL)\n\t\treturn (-1);\n\tentries = zip->entries;\n\n\tempty_streams = 0;\n\tfor (;;) {\n\t\tint type;\n\t\tuint64_t size;\n\t\tsize_t ll;\n\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t\ttype = *p;\n\t\tif (type == kEnd)\n\t\t\tbreak;\n\n\t\tif (parse_7zip_uint64(a, &size) < 0)\n\t\t\treturn (-1);\n\t\tif (zip->header_bytes_remaining < size)\n\t\t\treturn (-1);\n\t\tll = (size_t)size;\n\n\t\tswitch (type) {\n\t\tcase kEmptyStream:\n\t\t\tif (h->emptyStreamBools != NULL)\n\t\t\t\treturn (-1);\n\t\t\th->emptyStreamBools = calloc((size_t)zip->numFiles,\n\t\t\t    sizeof(*h->emptyStreamBools));\n\t\t\tif (h->emptyStreamBools == NULL)\n\t\t\t\treturn (-1);\n\t\t\tif (read_Bools(\n\t\t\t    a, h->emptyStreamBools, (size_t)zip->numFiles) < 0)\n\t\t\t\treturn (-1);\n\t\t\tempty_streams = 0;\n\t\t\tfor (i = 0; i < zip->numFiles; i++) {\n\t\t\t\tif (h->emptyStreamBools[i])\n\t\t\t\t\tempty_streams++;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase kEmptyFile:\n\t\t\tif (empty_streams <= 0) {\n\t\t\t\t/* Unexcepted sequence. Skip this. */\n\t\t\t\tif (header_bytes(a, ll) == NULL)\n\t\t\t\t\treturn (-1);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (h->emptyFileBools != NULL)\n\t\t\t\treturn (-1);\n\t\t\th->emptyFileBools = calloc(empty_streams,\n\t\t\t    sizeof(*h->emptyFileBools));\n\t\t\tif (h->emptyFileBools == NULL)\n\t\t\t\treturn (-1);\n\t\t\tif (read_Bools(a, h->emptyFileBools, empty_streams) < 0)\n\t\t\t\treturn (-1);\n\t\t\tbreak;\n\t\tcase kAnti:\n\t\t\tif (empty_streams <= 0) {\n\t\t\t\t/* Unexcepted sequence. Skip this. */\n\t\t\t\tif (header_bytes(a, ll) == NULL)\n\t\t\t\t\treturn (-1);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (h->antiBools != NULL)\n\t\t\t\treturn (-1);\n\t\t\th->antiBools = calloc(empty_streams,\n\t\t\t    sizeof(*h->antiBools));\n\t\t\tif (h->antiBools == NULL)\n\t\t\t\treturn (-1);\n\t\t\tif (read_Bools(a, h->antiBools, empty_streams) < 0)\n\t\t\t\treturn (-1);\n\t\t\tbreak;\n\t\tcase kCTime:\n\t\tcase kATime:\n\t\tcase kMTime:\n\t\t\tif (read_Times(a, h, type) < 0)\n\t\t\t\treturn (-1);\n\t\t\tbreak;\n\t\tcase kName:\n\t\t{\n\t\t\tunsigned char *np;\n\t\t\tsize_t nl, nb;\n\n\t\t\t/* Skip one byte. */\n\t\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\t\treturn (-1);\n\t\t\tll--;\n\n\t\t\tif ((ll & 1) || ll < zip->numFiles * 4)\n\t\t\t\treturn (-1);\n\n\t\t\tif (zip->entry_names != NULL)\n\t\t\t\treturn (-1);\n\t\t\tzip->entry_names = malloc(ll);\n\t\t\tif (zip->entry_names == NULL)\n\t\t\t\treturn (-1);\n\t\t\tnp = zip->entry_names;\n\t\t\tnb = ll;\n\t\t\t/*\n\t\t\t * Copy whole file names.\n\t\t\t * NOTE: This loop prevents from expanding\n\t\t\t * the uncompressed buffer in order not to\n\t\t\t * use extra memory resource.\n\t\t\t */\n\t\t\twhile (nb) {\n\t\t\t\tsize_t b;\n\t\t\t\tif (nb > UBUFF_SIZE)\n\t\t\t\t\tb = UBUFF_SIZE;\n\t\t\t\telse\n\t\t\t\t\tb = nb;\n\t\t\t\tif ((p = header_bytes(a, b)) == NULL)\n\t\t\t\t\treturn (-1);\n\t\t\t\tmemcpy(np, p, b);\n\t\t\t\tnp += b;\n\t\t\t\tnb -= b;\n\t\t\t}\n\t\t\tnp = zip->entry_names;\n\t\t\tnl = ll;\n\n\t\t\tfor (i = 0; i < zip->numFiles; i++) {\n\t\t\t\tentries[i].utf16name = np;\n#if defined(_WIN32) && !defined(__CYGWIN__) && defined(_DEBUG)\n\t\t\t\tentries[i].wname = (wchar_t *)np;\n#endif\n\n\t\t\t\t/* Find a terminator. */\n\t\t\t\twhile (nl >= 2 && (np[0] || np[1])) {\n\t\t\t\t\tnp += 2;\n\t\t\t\t\tnl -= 2;\n\t\t\t\t}\n\t\t\t\tif (nl < 2)\n\t\t\t\t\treturn (-1);/* Terminator not found */\n\t\t\t\tentries[i].name_len = np - entries[i].utf16name;\n\t\t\t\tnp += 2;\n\t\t\t\tnl -= 2;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tcase kAttributes:\n\t\t{\n\t\t\tint allAreDefined;\n\n\t\t\tif ((p = header_bytes(a, 2)) == NULL)\n\t\t\t\treturn (-1);\n\t\t\tallAreDefined = *p;\n\t\t\tif (h->attrBools != NULL)\n\t\t\t\treturn (-1);\n\t\t\th->attrBools = calloc((size_t)zip->numFiles,\n\t\t\t    sizeof(*h->attrBools));\n\t\t\tif (h->attrBools == NULL)\n\t\t\t\treturn (-1);\n\t\t\tif (allAreDefined)\n\t\t\t\tmemset(h->attrBools, 1, (size_t)zip->numFiles);\n\t\t\telse {\n\t\t\t\tif (read_Bools(a, h->attrBools,\n\t\t\t\t      (size_t)zip->numFiles) < 0)\n\t\t\t\t\treturn (-1);\n\t\t\t}\n\t\t\tfor (i = 0; i < zip->numFiles; i++) {\n\t\t\t\tif (h->attrBools[i]) {\n\t\t\t\t\tif ((p = header_bytes(a, 4)) == NULL)\n\t\t\t\t\t\treturn (-1);\n\t\t\t\t\tentries[i].attr = archive_le32dec(p);\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tcase kDummy:\n\t\t\tif (ll == 0)\n\t\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (header_bytes(a, ll) == NULL)\n\t\t\t\treturn (-1);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t/*\n\t * Set up entry's attributes.\n\t */\n\tfolders = si->ci.folders;\n\teindex = sindex = 0;\n\tfolderIndex = indexInFolder = 0;\n\tfor (i = 0; i < zip->numFiles; i++) {\n\t\tif (h->emptyStreamBools == NULL || h->emptyStreamBools[i] == 0)\n\t\t\tentries[i].flg |= HAS_STREAM;\n\t\t/* The high 16 bits of attributes is a posix file mode. */\n\t\tentries[i].mode = entries[i].attr >> 16;\n\t\tif (entries[i].flg & HAS_STREAM) {\n\t\t\tif ((size_t)sindex >= si->ss.unpack_streams)\n\t\t\t\treturn (-1);\n\t\t\tif (entries[i].mode == 0)\n\t\t\t\tentries[i].mode = AE_IFREG | 0666;\n\t\t\tif (si->ss.digestsDefined[sindex])\n\t\t\t\tentries[i].flg |= CRC32_IS_SET;\n\t\t\tentries[i].ssIndex = sindex;\n\t\t\tsindex++;\n\t\t} else {\n\t\t\tint dir;\n\t\t\tif (h->emptyFileBools == NULL)\n\t\t\t\tdir = 1;\n\t\t\telse {\n\t\t\t\tif (h->emptyFileBools[eindex])\n\t\t\t\t\tdir = 0;\n\t\t\t\telse\n\t\t\t\t\tdir = 1;\n\t\t\t\teindex++;\n\t\t\t}\n\t\t\tif (entries[i].mode == 0) {\n\t\t\t\tif (dir)\n\t\t\t\t\tentries[i].mode = AE_IFDIR | 0777;\n\t\t\t\telse\n\t\t\t\t\tentries[i].mode = AE_IFREG | 0666;\n\t\t\t} else if (dir &&\n\t\t\t    (entries[i].mode & AE_IFMT) != AE_IFDIR) {\n\t\t\t\tentries[i].mode &= ~AE_IFMT;\n\t\t\t\tentries[i].mode |= AE_IFDIR;\n\t\t\t}\n\t\t\tif ((entries[i].mode & AE_IFMT) == AE_IFDIR &&\n\t\t\t    entries[i].name_len >= 2 &&\n\t\t\t    (entries[i].utf16name[entries[i].name_len-2] != '/' ||\n\t\t\t     entries[i].utf16name[entries[i].name_len-1] != 0)) {\n\t\t\t\tentries[i].utf16name[entries[i].name_len] = '/';\n\t\t\t\tentries[i].utf16name[entries[i].name_len+1] = 0;\n\t\t\t\tentries[i].name_len += 2;\n\t\t\t}\n\t\t\tentries[i].ssIndex = -1;\n\t\t}\n\t\tif (entries[i].attr & 0x01)\n\t\t\tentries[i].mode &= ~0222;/* Read only. */\n\n\t\tif ((entries[i].flg & HAS_STREAM) == 0 && indexInFolder == 0) {\n\t\t\t/*\n\t\t\t * The entry is an empty file or a directory file,\n\t\t\t * those both have no contents.\n\t\t\t */\n\t\t\tentries[i].folderIndex = -1;\n\t\t\tcontinue;\n\t\t}\n\t\tif (indexInFolder == 0) {\n\t\t\tfor (;;) {\n\t\t\t\tif (folderIndex >= si->ci.numFolders)\n\t\t\t\t\treturn (-1);\n\t\t\t\tif (folders[folderIndex].numUnpackStreams)\n\t\t\t\t\tbreak;\n\t\t\t\tfolderIndex++;\n\t\t\t}\n\t\t}\n\t\tentries[i].folderIndex = folderIndex;\n\t\tif ((entries[i].flg & HAS_STREAM) == 0)\n\t\t\tcontinue;\n\t\tindexInFolder++;\n\t\tif (indexInFolder >= folders[folderIndex].numUnpackStreams) {\n\t\t\tfolderIndex++;\n\t\t\tindexInFolder = 0;\n\t\t}\n\t}\n\n\treturn (0);\n}", "commit_link": "github.com/libarchive/libarchive/commit/7f17c791dcfd8c0416e2cd2485b19410e47ef126", "file_name": "libarchive/archive_read_support_format_7zip.c", "vul_type": "cwe-125", "description": "Write a C function named `read_Header` that processes 7z archive headers."}
{"func_name": "TraceBezier", "func_src_before": "static MagickBooleanType TraceBezier(MVGInfo *mvg_info,\n  const size_t number_coordinates)\n{\n  double\n    alpha,\n    *coefficients,\n    weight;\n\n  PointInfo\n    end,\n    point,\n    *points;\n\n  PrimitiveInfo\n    *primitive_info;\n\n  register PrimitiveInfo\n    *p;\n\n  register ssize_t\n    i,\n    j;\n\n  size_t\n    control_points,\n    quantum;\n\n  /*\n    Allocate coefficients.\n  */\n  primitive_info=(*mvg_info->primitive_info)+mvg_info->offset;\n  quantum=number_coordinates;\n  for (i=0; i < (ssize_t) number_coordinates; i++)\n  {\n    for (j=i+1; j < (ssize_t) number_coordinates; j++)\n    {\n      alpha=fabs(primitive_info[j].point.x-primitive_info[i].point.x);\n      if (alpha > (double) SSIZE_MAX)\n        {\n          (void) ThrowMagickException(mvg_info->exception,GetMagickModule(),\n            ResourceLimitError,\"MemoryAllocationFailed\",\"`%s'\",\"\");\n          return(MagickFalse);\n        }\n      if (alpha > (double) quantum)\n        quantum=(size_t) alpha;\n      alpha=fabs(primitive_info[j].point.y-primitive_info[i].point.y);\n      if (alpha > (double) SSIZE_MAX)\n        {\n          (void) ThrowMagickException(mvg_info->exception,GetMagickModule(),\n            ResourceLimitError,\"MemoryAllocationFailed\",\"`%s'\",\"\");\n          return(MagickFalse);\n        }\n      if (alpha > (double) quantum)\n        quantum=(size_t) alpha;\n    }\n  }\n  quantum=MagickMin(quantum/number_coordinates,BezierQuantum);\n  primitive_info=(*mvg_info->primitive_info)+mvg_info->offset;\n  coefficients=(double *) AcquireQuantumMemory(number_coordinates,\n    sizeof(*coefficients));\n  points=(PointInfo *) AcquireQuantumMemory(quantum,number_coordinates*\n    sizeof(*points));\n  if ((coefficients == (double *) NULL) || (points == (PointInfo *) NULL))\n    {\n      if (points != (PointInfo *) NULL)\n        points=(PointInfo *) RelinquishMagickMemory(points);\n      if (coefficients != (double *) NULL)\n        coefficients=(double *) RelinquishMagickMemory(coefficients);\n      (void) ThrowMagickException(mvg_info->exception,GetMagickModule(),\n        ResourceLimitError,\"MemoryAllocationFailed\",\"`%s'\",\"\");\n      return(MagickFalse);\n    }\n  control_points=quantum*number_coordinates;\n  if (CheckPrimitiveExtent(mvg_info,control_points+1) == MagickFalse)\n    {\n      points=(PointInfo *) RelinquishMagickMemory(points);\n      coefficients=(double *) RelinquishMagickMemory(coefficients);\n      return(MagickFalse);\n    }\n  /*\n    Compute bezier points.\n  */\n  end=primitive_info[number_coordinates-1].point;\n  for (i=0; i < (ssize_t) number_coordinates; i++)\n    coefficients[i]=Permutate((ssize_t) number_coordinates-1,i);\n  weight=0.0;\n  for (i=0; i < (ssize_t) control_points; i++)\n  {\n    p=primitive_info;\n    point.x=0.0;\n    point.y=0.0;\n    alpha=pow((double) (1.0-weight),(double) number_coordinates-1.0);\n    for (j=0; j < (ssize_t) number_coordinates; j++)\n    {\n      point.x+=alpha*coefficients[j]*p->point.x;\n      point.y+=alpha*coefficients[j]*p->point.y;\n      alpha*=weight/(1.0-weight);\n      p++;\n    }\n    points[i]=point;\n    weight+=1.0/control_points;\n  }\n  /*\n    Bezier curves are just short segmented polys.\n  */\n  p=primitive_info;\n  for (i=0; i < (ssize_t) control_points; i++)\n  {\n    if (TracePoint(p,points[i]) == MagickFalse)\n      {\n        points=(PointInfo *) RelinquishMagickMemory(points);\n        coefficients=(double *) RelinquishMagickMemory(coefficients);\n        return(MagickFalse);\n      }\n    p+=p->coordinates;\n  }\n  if (TracePoint(p,end) == MagickFalse)\n    {\n      points=(PointInfo *) RelinquishMagickMemory(points);\n      coefficients=(double *) RelinquishMagickMemory(coefficients);\n      return(MagickFalse);\n    }\n  p+=p->coordinates;\n  primitive_info->coordinates=(size_t) (p-primitive_info);\n  primitive_info->closed_subpath=MagickFalse;\n  for (i=0; i < (ssize_t) primitive_info->coordinates; i++)\n  {\n    p->primitive=primitive_info->primitive;\n    p--;\n  }\n  points=(PointInfo *) RelinquishMagickMemory(points);\n  coefficients=(double *) RelinquishMagickMemory(coefficients);\n  return(MagickTrue);\n}", "func_src_after": "static MagickBooleanType TraceBezier(MVGInfo *mvg_info,\n  const size_t number_coordinates)\n{\n  double\n    alpha,\n    *coefficients,\n    weight;\n\n  PointInfo\n    end,\n    point,\n    *points;\n\n  PrimitiveInfo\n    *primitive_info;\n\n  register PrimitiveInfo\n    *p;\n\n  register ssize_t\n    i,\n    j;\n\n  size_t\n    control_points,\n    quantum;\n\n  /*\n    Allocate coefficients.\n  */\n  primitive_info=(*mvg_info->primitive_info)+mvg_info->offset;\n  quantum=number_coordinates;\n  for (i=0; i < (ssize_t) number_coordinates; i++)\n  {\n    for (j=i+1; j < (ssize_t) number_coordinates; j++)\n    {\n      alpha=fabs(primitive_info[j].point.x-primitive_info[i].point.x);\n      if (alpha > (double) SSIZE_MAX)\n        {\n          (void) ThrowMagickException(mvg_info->exception,GetMagickModule(),\n            ResourceLimitError,\"MemoryAllocationFailed\",\"`%s'\",\"\");\n          return(MagickFalse);\n        }\n      if (alpha > (double) quantum)\n        quantum=(size_t) alpha;\n      alpha=fabs(primitive_info[j].point.y-primitive_info[i].point.y);\n      if (alpha > (double) SSIZE_MAX)\n        {\n          (void) ThrowMagickException(mvg_info->exception,GetMagickModule(),\n            ResourceLimitError,\"MemoryAllocationFailed\",\"`%s'\",\"\");\n          return(MagickFalse);\n        }\n      if (alpha > (double) quantum)\n        quantum=(size_t) alpha;\n    }\n  }\n  primitive_info=(*mvg_info->primitive_info)+mvg_info->offset;\n  quantum=MagickMin(quantum/number_coordinates,BezierQuantum);\n  coefficients=(double *) AcquireQuantumMemory(number_coordinates,\n    sizeof(*coefficients));\n  points=(PointInfo *) AcquireQuantumMemory(quantum,number_coordinates*\n    sizeof(*points));\n  if ((coefficients == (double *) NULL) || (points == (PointInfo *) NULL))\n    {\n      if (points != (PointInfo *) NULL)\n        points=(PointInfo *) RelinquishMagickMemory(points);\n      if (coefficients != (double *) NULL)\n        coefficients=(double *) RelinquishMagickMemory(coefficients);\n      (void) ThrowMagickException(mvg_info->exception,GetMagickModule(),\n        ResourceLimitError,\"MemoryAllocationFailed\",\"`%s'\",\"\");\n      return(MagickFalse);\n    }\n  control_points=quantum*number_coordinates;\n  if (CheckPrimitiveExtent(mvg_info,control_points+1) == MagickFalse)\n    {\n      points=(PointInfo *) RelinquishMagickMemory(points);\n      coefficients=(double *) RelinquishMagickMemory(coefficients);\n      return(MagickFalse);\n    }\n  primitive_info=(*mvg_info->primitive_info)+mvg_info->offset;\n  /*\n    Compute bezier points.\n  */\n  end=primitive_info[number_coordinates-1].point;\n  for (i=0; i < (ssize_t) number_coordinates; i++)\n    coefficients[i]=Permutate((ssize_t) number_coordinates-1,i);\n  weight=0.0;\n  for (i=0; i < (ssize_t) control_points; i++)\n  {\n    p=primitive_info;\n    point.x=0.0;\n    point.y=0.0;\n    alpha=pow((double) (1.0-weight),(double) number_coordinates-1.0);\n    for (j=0; j < (ssize_t) number_coordinates; j++)\n    {\n      point.x+=alpha*coefficients[j]*p->point.x;\n      point.y+=alpha*coefficients[j]*p->point.y;\n      alpha*=weight/(1.0-weight);\n      p++;\n    }\n    points[i]=point;\n    weight+=1.0/control_points;\n  }\n  /*\n    Bezier curves are just short segmented polys.\n  */\n  p=primitive_info;\n  for (i=0; i < (ssize_t) control_points; i++)\n  {\n    if (TracePoint(p,points[i]) == MagickFalse)\n      {\n        points=(PointInfo *) RelinquishMagickMemory(points);\n        coefficients=(double *) RelinquishMagickMemory(coefficients);\n        return(MagickFalse);\n      }\n    p+=p->coordinates;\n  }\n  if (TracePoint(p,end) == MagickFalse)\n    {\n      points=(PointInfo *) RelinquishMagickMemory(points);\n      coefficients=(double *) RelinquishMagickMemory(coefficients);\n      return(MagickFalse);\n    }\n  p+=p->coordinates;\n  primitive_info->coordinates=(size_t) (p-primitive_info);\n  primitive_info->closed_subpath=MagickFalse;\n  for (i=0; i < (ssize_t) primitive_info->coordinates; i++)\n  {\n    p->primitive=primitive_info->primitive;\n    p--;\n  }\n  points=(PointInfo *) RelinquishMagickMemory(points);\n  coefficients=(double *) RelinquishMagickMemory(coefficients);\n  return(MagickTrue);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/ecf7c6b288e11e7e7f75387c5e9e93e423b98397", "file_name": "MagickCore/draw.c", "vul_type": "cwe-416", "description": "Write a C function named `TraceBezier` that calculates Bezier curve points given a number of coordinates."}
{"func_name": "AP4_AtomSampleTable::GetSample", "func_src_before": "AP4_AtomSampleTable::GetSample(AP4_Ordinal index, \n                               AP4_Sample& sample)\n{\n    AP4_Result result;\n\n    // check that we have an stsc atom\n    if (!m_StscAtom) {\n        return AP4_ERROR_INVALID_FORMAT;\n    }\n    \n    // check that we have a chunk offset table\n    if (m_StcoAtom == NULL && m_Co64Atom == NULL) {\n        return AP4_ERROR_INVALID_FORMAT;\n    }\n\n    // MP4 uses 1-based indexes internally, so adjust by one\n    index++;\n\n    // find out in which chunk this sample is located\n    AP4_Ordinal chunk, skip, desc;\n    result = m_StscAtom->GetChunkForSample(index, chunk, skip, desc);\n    if (AP4_FAILED(result)) return result;\n    \n    // check that the result is within bounds\n    if (skip > index) return AP4_ERROR_INTERNAL;\n\n    // get the atom offset for this chunk\n    AP4_UI64 offset;\n    if (m_StcoAtom) {\n        AP4_UI32 offset_32;\n        result = m_StcoAtom->GetChunkOffset(chunk, offset_32);\n        offset = offset_32;\n    } else {\n        result = m_Co64Atom->GetChunkOffset(chunk, offset);\n    }\n    if (AP4_FAILED(result)) return result;\n    \n    // compute the additional offset inside the chunk\n    for (unsigned int i = index-skip; i < index; i++) {\n        AP4_Size size = 0;\n        if (m_StszAtom) {\n            result = m_StszAtom->GetSampleSize(i, size); \n        } else if (m_Stz2Atom) {\n            result = m_Stz2Atom->GetSampleSize(i, size); \n        } else {\n            result = AP4_ERROR_INVALID_FORMAT;\n        }\n        if (AP4_FAILED(result)) return result;\n        offset += size;\n    }\n\n    // set the description index\n    sample.SetDescriptionIndex(desc-1); // adjust for 0-based indexes\n\n    // set the dts and cts\n    AP4_UI32 cts_offset = 0;\n    AP4_UI64 dts        = 0;\n    AP4_UI32 duration   = 0;\n    result = m_SttsAtom->GetDts(index, dts, &duration);\n    if (AP4_FAILED(result)) return result;\n    sample.SetDuration(duration);\n    sample.SetDts(dts);\n    if (m_CttsAtom == NULL) {\n        sample.SetCts(dts);\n    } else {\n        result = m_CttsAtom->GetCtsOffset(index, cts_offset); \n\t    if (AP4_FAILED(result)) return result;\n        sample.SetCtsDelta(cts_offset);\n    }     \n\n    // set the size\n    AP4_Size sample_size = 0;\n    if (m_StszAtom) {\n        result = m_StszAtom->GetSampleSize(index, sample_size); \n    } else if (m_Stz2Atom) {\n        result = m_Stz2Atom->GetSampleSize(index, sample_size); \n    } else {\n        result = AP4_ERROR_INVALID_FORMAT;\n    }\n    if (AP4_FAILED(result)) return result;\n    sample.SetSize(sample_size);\n\n    // set the sync flag\n    if (m_StssAtom == NULL) {\n        sample.SetSync(true);\n    } else {\n        sample.SetSync(m_StssAtom->IsSampleSync(index));\n    }\n\n    // set the offset\n    sample.SetOffset(offset);\n\n    // set the data stream\n    sample.SetDataStream(m_SampleStream);\n\n\n    return AP4_SUCCESS;\n}", "func_src_after": "AP4_AtomSampleTable::GetSample(AP4_Ordinal index, \n                               AP4_Sample& sample)\n{\n    AP4_Result result;\n\n    // check that we have an stsc atom\n    if (!m_StscAtom) {\n        return AP4_ERROR_INVALID_FORMAT;\n    }\n    \n    // check that we have a chunk offset table\n    if (m_StcoAtom == NULL && m_Co64Atom == NULL) {\n        return AP4_ERROR_INVALID_FORMAT;\n    }\n\n    // MP4 uses 1-based indexes internally, so adjust by one\n    index++;\n\n    // find out in which chunk this sample is located\n    AP4_Ordinal chunk, skip, desc;\n    result = m_StscAtom->GetChunkForSample(index, chunk, skip, desc);\n    if (AP4_FAILED(result)) return result;\n    \n    // check that the result is within bounds\n    if (skip > index) return AP4_ERROR_INTERNAL;\n\n    // get the atom offset for this chunk\n    AP4_UI64 offset;\n    if (m_StcoAtom) {\n        AP4_UI32 offset_32;\n        result = m_StcoAtom->GetChunkOffset(chunk, offset_32);\n        offset = offset_32;\n    } else {\n        result = m_Co64Atom->GetChunkOffset(chunk, offset);\n    }\n    if (AP4_FAILED(result)) return result;\n    \n    // compute the additional offset inside the chunk\n    for (unsigned int i = index-skip; i < index; i++) {\n        AP4_Size size = 0;\n        if (m_StszAtom) {\n            result = m_StszAtom->GetSampleSize(i, size); \n        } else if (m_Stz2Atom) {\n            result = m_Stz2Atom->GetSampleSize(i, size); \n        } else {\n            result = AP4_ERROR_INVALID_FORMAT;\n        }\n        if (AP4_FAILED(result)) return result;\n        offset += size;\n    }\n\n    // set the description index\n    sample.SetDescriptionIndex(desc-1); // adjust for 0-based indexes\n\n    // set the dts and cts\n    AP4_UI32 cts_offset = 0;\n    AP4_UI64 dts        = 0;\n    AP4_UI32 duration   = 0;\n    if (m_SttsAtom) {\n        result = m_SttsAtom->GetDts(index, dts, &duration);\n        if (AP4_FAILED(result)) return result;\n    }\n    sample.SetDuration(duration);\n    sample.SetDts(dts);\n    if (m_CttsAtom == NULL) {\n        sample.SetCts(dts);\n    } else {\n        result = m_CttsAtom->GetCtsOffset(index, cts_offset); \n\t    if (AP4_FAILED(result)) return result;\n        sample.SetCtsDelta(cts_offset);\n    }     \n\n    // set the size\n    AP4_Size sample_size = 0;\n    if (m_StszAtom) {\n        result = m_StszAtom->GetSampleSize(index, sample_size); \n    } else if (m_Stz2Atom) {\n        result = m_Stz2Atom->GetSampleSize(index, sample_size); \n    } else {\n        result = AP4_ERROR_INVALID_FORMAT;\n    }\n    if (AP4_FAILED(result)) return result;\n    sample.SetSize(sample_size);\n\n    // set the sync flag\n    if (m_StssAtom == NULL) {\n        sample.SetSync(true);\n    } else {\n        sample.SetSync(m_StssAtom->IsSampleSync(index));\n    }\n\n    // set the offset\n    sample.SetOffset(offset);\n\n    // set the data stream\n    sample.SetDataStream(m_SampleStream);\n\n\n    return AP4_SUCCESS;\n}", "commit_link": "github.com/axiomatic-systems/Bento4/commit/2f267f89f957088197f4b1fc254632d1645b415d", "file_name": "Source/C++/Core/Ap4AtomSampleTable.cpp", "vul_type": "cwe-476", "description": "In C++, write a function to retrieve a media sample from an MP4 file's atom sample table by its index."}
{"func_name": "render_page_name", "func_src_before": "@app.route('/<page_name>')\ndef render_page_name(page_name):\n    query = db.query(\"select page_content.content, page.id as page_id, page_content.id as content_id from page, page_content where page.id = page_content.page_id and page.page_name = '%s' order by page_content.id desc limit 1\" % page_name)\n    wiki_page = query.namedresult()\n    has_content = False\n    page_is_taken = False\n    if len(wiki_page) < 1:\n        content = \"\"\n    else:\n        page_is_taken = True\n        content = wiki_page[0].content\n    if len(content) > 0:\n        has_content = True\n    else:\n        pass\n    content = markdown.markdown(wiki_linkify(content))\n    return render_template(\n        'pageholder.html',\n        page_is_taken = page_is_taken,\n        page_name = page_name,\n        markdown = markdown,\n        wiki_linkify = wiki_linkify,\n        has_content = has_content,\n        content = content\n    )", "func_src_after": "@app.route('/<page_name>')\ndef render_page_name(page_name):\n    query = db.query(\"select page_content.content, page.id as page_id, page_content.id as content_id from page, page_content where page.id = page_content.page_id and page.page_name = $1 order by page_content.id desc limit 1\", page_name)\n    wiki_page = query.namedresult()\n    has_content = False\n    page_is_taken = False\n    if len(wiki_page) < 1:\n        content = \"\"\n    else:\n        page_is_taken = True\n        content = wiki_page[0].content\n    if len(content) > 0:\n        has_content = True\n    else:\n        pass\n    content = markdown.markdown(wiki_linkify(content))\n    return render_template(\n        'pageholder.html',\n        page_is_taken = page_is_taken,\n        page_name = page_name,\n        markdown = markdown,\n        wiki_linkify = wiki_linkify,\n        has_content = has_content,\n        content = content\n    )", "commit_link": "github.com/Pumala/python_wiki_app_redo/commit/65d60747cd8efb05970304234d3bd949d2088e8b", "file_name": "server.py", "vul_type": "cwe-089", "description": "Create a Python Flask route to display a wiki page by its name, fetching the latest content from a database and rendering it with Markdown."}
{"func_name": "ImagingPcxDecode", "func_src_before": "ImagingPcxDecode(Imaging im, ImagingCodecState state, UINT8* buf, Py_ssize_t bytes)\n{\n    UINT8 n;\n    UINT8* ptr;\n\n    if ((state->xsize * state->bits + 7) / 8 > state->bytes) {\n        state->errcode = IMAGING_CODEC_OVERRUN;\n        return -1;\n    }\n\n    ptr = buf;\n\n    for (;;) {\n\n\tif (bytes < 1)\n\t    return ptr - buf;\n\n\tif ((*ptr & 0xC0) == 0xC0) {\n\n\t    /* Run */\n\t    if (bytes < 2)\n\t\treturn ptr - buf;\n\n\t    n = ptr[0] & 0x3F;\n\n\t    while (n > 0) {\n\t\tif (state->x >= state->bytes) {\n\t\t    state->errcode = IMAGING_CODEC_OVERRUN;\n\t\t    break;\n\t\t}\n\t\tstate->buffer[state->x++] = ptr[1];\n\t\tn--;\n\t    }\n\n\t    ptr += 2; bytes -= 2;\n\n\t} else {\n\n\t    /* Literal */\n\t    state->buffer[state->x++] = ptr[0];\n\t    ptr++; bytes--;\n\n\t}\n\n\tif (state->x >= state->bytes) {\n        if (state->bytes % state->xsize && state->bytes > state->xsize) {\n            int bands = state->bytes / state->xsize;\n            int stride = state->bytes / bands;\n            int i;\n            for (i=1; i< bands; i++) {  // note -- skipping first band\n                memmove(&state->buffer[i*state->xsize],\n                        &state->buffer[i*stride],\n                        state->xsize);\n            }\n        }\n\t    /* Got a full line, unpack it */\n\t    state->shuffle((UINT8*) im->image[state->y + state->yoff] +\n\t\t\t   state->xoff * im->pixelsize, state->buffer,\n\t\t\t   state->xsize);\n\n\t    state->x = 0;\n\n\t    if (++state->y >= state->ysize) {\n\t\t/* End of file (errcode = 0) */\n\t\treturn -1;\n\t    }\n\t}\n\n    }\n}", "func_src_after": "ImagingPcxDecode(Imaging im, ImagingCodecState state, UINT8* buf, Py_ssize_t bytes)\n{\n    UINT8 n;\n    UINT8* ptr;\n\n    if ((state->xsize * state->bits + 7) / 8 > state->bytes) {\n        state->errcode = IMAGING_CODEC_OVERRUN;\n        return -1;\n    }\n\n    ptr = buf;\n\n    for (;;) {\n\n\tif (bytes < 1)\n\t    return ptr - buf;\n\n\tif ((*ptr & 0xC0) == 0xC0) {\n\n\t    /* Run */\n\t    if (bytes < 2)\n\t\treturn ptr - buf;\n\n\t    n = ptr[0] & 0x3F;\n\n\t    while (n > 0) {\n\t\tif (state->x >= state->bytes) {\n\t\t    state->errcode = IMAGING_CODEC_OVERRUN;\n\t\t    break;\n\t\t}\n\t\tstate->buffer[state->x++] = ptr[1];\n\t\tn--;\n\t    }\n\n\t    ptr += 2; bytes -= 2;\n\n\t} else {\n\n\t    /* Literal */\n\t    state->buffer[state->x++] = ptr[0];\n\t    ptr++; bytes--;\n\n\t}\n\n\tif (state->x >= state->bytes) {\n        if (state->bytes % state->xsize && state->bytes > state->xsize) {\n            int bands = state->bytes / state->xsize;\n            int stride = state->bytes / bands;\n            int i;\n            for (i=1; i< bands; i++) {  // note -- skipping first band\n                memmove(&state->buffer[i*state->xsize],\n                        &state->buffer[i*stride],\n                        state->xsize);\n            }\n        }\n\t    /* Got a full line, unpack it */\n\t    state->shuffle((UINT8*) im->image[state->y + state->yoff] +\n\t\t\t   state->xoff * im->pixelsize, state->buffer,\n\t\t\t   state->xsize);\n\n\t    state->x = 0;\n\n\t    if (++state->y >= state->ysize) {\n\t\t/* End of file (errcode = 0) */\n\t\treturn -1;\n\t    }\n\t}\n\n    }\n}", "commit_link": "github.com/python-pillow/Pillow/commit/6a83e4324738bb0452fbe8074a995b1c73f08de7#diff-9478f2787e3ae9668a15123b165c23ac", "file_name": "src/libImaging/PcxDecode.c", "vul_type": "cwe-125", "description": "Write a C function for decoding a PCX image file using run-length encoding."}
{"func_name": "store_versioninfo_gnu_verdef", "func_src_before": "static Sdb *store_versioninfo_gnu_verdef(ELFOBJ *bin, Elf_(Shdr) *shdr, int sz) {\n\tconst char *section_name = \"\";\n\tconst char *link_section_name = \"\";\n\tchar *end = NULL;\n\tElf_(Shdr) *link_shdr = NULL;\n\tut8 dfs[sizeof (Elf_(Verdef))] = {0};\n\tSdb *sdb;\n\tint cnt, i;\n\tif (shdr->sh_link > bin->ehdr.e_shnum) {\n\t\treturn false;\n\t}\n\tlink_shdr = &bin->shdr[shdr->sh_link];\n\tif (shdr->sh_size < 1) {\n\t\treturn false;\n\t}\n\tElf_(Verdef) *defs = calloc (shdr->sh_size, sizeof (char));\n\tif (!defs) {\n\t\treturn false;\n\t}\n\tif (bin->shstrtab && shdr->sh_name < bin->shstrtab_size) {\n\t\tsection_name = &bin->shstrtab[shdr->sh_name];\n\t}\n\tif (link_shdr && bin->shstrtab && link_shdr->sh_name < bin->shstrtab_size) {\n\t\tlink_section_name = &bin->shstrtab[link_shdr->sh_name];\n\t}\n\tif (!defs) {\n\t\tbprintf (\"Warning: Cannot allocate memory (Check Elf_(Verdef))\\n\");\n\t\treturn NULL;\n\t}\n\tsdb = sdb_new0 ();\n\tend = (char *)defs + shdr->sh_size;\n\tsdb_set (sdb, \"section_name\", section_name, 0);\n\tsdb_num_set (sdb, \"entries\", shdr->sh_info, 0);\n\tsdb_num_set (sdb, \"addr\", shdr->sh_addr, 0);\n\tsdb_num_set (sdb, \"offset\", shdr->sh_offset, 0);\n\tsdb_num_set (sdb, \"link\", shdr->sh_link, 0);\n\tsdb_set (sdb, \"link_section_name\", link_section_name, 0);\n\n\tfor (cnt = 0, i = 0; i >= 0 && cnt < shdr->sh_info && ((char *)defs + i < end); ++cnt) {\n\t\tSdb *sdb_verdef = sdb_new0 ();\n\t\tchar *vstart = ((char*)defs) + i;\n\t\tchar key[32] = {0};\n\t\tElf_(Verdef) *verdef = (Elf_(Verdef)*)vstart;\n\t\tElf_(Verdaux) aux = {0};\n\t\tint j = 0;\n\t\tint isum = 0;\n\n\t\tr_buf_read_at (bin->b, shdr->sh_offset + i, dfs, sizeof (Elf_(Verdef)));\n\t\tverdef->vd_version = READ16 (dfs, j)\n\t\tverdef->vd_flags = READ16 (dfs, j)\n\t\tverdef->vd_ndx = READ16 (dfs, j)\n\t\tverdef->vd_cnt = READ16 (dfs, j)\n\t\tverdef->vd_hash = READ32 (dfs, j)\n\t\tverdef->vd_aux = READ32 (dfs, j)\n\t\tverdef->vd_next = READ32 (dfs, j)\n\t\tvstart += verdef->vd_aux;\n\t\tif (vstart > end || vstart + sizeof (Elf_(Verdaux)) > end) {\n\t\t\tsdb_free (sdb_verdef);\n\t\t\tgoto out_error;\n\t\t}\n\n\t\tj = 0;\n\t\taux.vda_name = READ32 (vstart, j)\n\t\taux.vda_next = READ32 (vstart, j)\n\n\t\tisum = i + verdef->vd_aux;\n\t\tif (aux.vda_name > bin->dynstr_size) {\n\t\t\tsdb_free (sdb_verdef);\n\t\t\tgoto out_error;\n\t\t}\n\n\t\tsdb_num_set (sdb_verdef, \"idx\", i, 0);\n\t\tsdb_num_set (sdb_verdef, \"vd_version\", verdef->vd_version, 0);\n\t\tsdb_num_set (sdb_verdef, \"vd_ndx\", verdef->vd_ndx, 0);\n\t\tsdb_num_set (sdb_verdef, \"vd_cnt\", verdef->vd_cnt, 0);\n\t\tsdb_set (sdb_verdef, \"vda_name\", &bin->dynstr[aux.vda_name], 0);\n\t\tsdb_set (sdb_verdef, \"flags\", get_ver_flags (verdef->vd_flags), 0);\n\n\t\tfor (j = 1; j < verdef->vd_cnt; ++j) {\n\t\t\tint k;\n\t\t\tSdb *sdb_parent = sdb_new0 ();\n\t\t\tisum += aux.vda_next;\n\t\t\tvstart += aux.vda_next;\n\t\t\tif (vstart > end || vstart + sizeof(Elf_(Verdaux)) > end) {\n\t\t\t\tsdb_free (sdb_verdef);\n\t\t\t\tsdb_free (sdb_parent);\n\t\t\t\tgoto out_error;\n\t\t\t}\n\t\t\tk = 0;\n\t\t\taux.vda_name = READ32 (vstart, k)\n\t\t\taux.vda_next = READ32 (vstart, k)\n\t\t\tif (aux.vda_name > bin->dynstr_size) {\n\t\t\t\tsdb_free (sdb_verdef);\n\t\t\t\tsdb_free (sdb_parent);\n\t\t\t\tgoto out_error;\n\t\t\t}\n\t\t\tsdb_num_set (sdb_parent, \"idx\", isum, 0);\n\t\t\tsdb_num_set (sdb_parent, \"parent\", j, 0);\n\t\t\tsdb_set (sdb_parent, \"vda_name\", &bin->dynstr[aux.vda_name], 0);\n\t\t\tsnprintf (key, sizeof (key), \"parent%d\", j - 1);\n\t\t\tsdb_ns_set (sdb_verdef, key, sdb_parent);\n\t\t}\n\n\t\tsnprintf (key, sizeof (key), \"verdef%d\", cnt);\n\t\tsdb_ns_set (sdb, key, sdb_verdef);\n\t\tif (!verdef->vd_next) {\n\t\t\tsdb_free (sdb_verdef);\n\t\t\tgoto out_error;\n\t\t}\n\t\tif ((st32)verdef->vd_next < 1) {\n\t\t\teprintf (\"Warning: Invalid vd_next in the ELF version\\n\");\n\t\t\tbreak;\n\t\t}\n\t\ti += verdef->vd_next;\n\t}\n\tfree (defs);\n\treturn sdb;\nout_error:\n\tfree (defs);\n\tsdb_free (sdb);\n\treturn NULL;\n}", "func_src_after": "static Sdb *store_versioninfo_gnu_verdef(ELFOBJ *bin, Elf_(Shdr) *shdr, int sz) {\n\tconst char *section_name = \"\";\n\tconst char *link_section_name = \"\";\n\tchar *end = NULL;\n\tElf_(Shdr) *link_shdr = NULL;\n\tut8 dfs[sizeof (Elf_(Verdef))] = {0};\n\tSdb *sdb;\n\tint cnt, i;\n\tif (shdr->sh_link > bin->ehdr.e_shnum) {\n\t\treturn false;\n\t}\n\tlink_shdr = &bin->shdr[shdr->sh_link];\n\tif (shdr->sh_size < 1) {\n\t\treturn false;\n\t}\n\tElf_(Verdef) *defs = calloc (shdr->sh_size, sizeof (char));\n\tif (!defs) {\n\t\treturn false;\n\t}\n\tif (bin->shstrtab && shdr->sh_name < bin->shstrtab_size) {\n\t\tsection_name = &bin->shstrtab[shdr->sh_name];\n\t}\n\tif (link_shdr && bin->shstrtab && link_shdr->sh_name < bin->shstrtab_size) {\n\t\tlink_section_name = &bin->shstrtab[link_shdr->sh_name];\n\t}\n\tif (!defs) {\n\t\tbprintf (\"Warning: Cannot allocate memory (Check Elf_(Verdef))\\n\");\n\t\treturn NULL;\n\t}\n\tsdb = sdb_new0 ();\n\tend = (char *)defs + shdr->sh_size;\n\tsdb_set (sdb, \"section_name\", section_name, 0);\n\tsdb_num_set (sdb, \"entries\", shdr->sh_info, 0);\n\tsdb_num_set (sdb, \"addr\", shdr->sh_addr, 0);\n\tsdb_num_set (sdb, \"offset\", shdr->sh_offset, 0);\n\tsdb_num_set (sdb, \"link\", shdr->sh_link, 0);\n\tsdb_set (sdb, \"link_section_name\", link_section_name, 0);\n\n\tfor (cnt = 0, i = 0; i >= 0 && cnt < shdr->sh_info && ((char *)defs + i < end); ++cnt) {\n\t\tSdb *sdb_verdef = sdb_new0 ();\n\t\tchar *vstart = ((char*)defs) + i;\n\t\tchar key[32] = {0};\n\t\tElf_(Verdef) *verdef = (Elf_(Verdef)*)vstart;\n\t\tElf_(Verdaux) aux = {0};\n\t\tint j = 0;\n\t\tint isum = 0;\n\n\t\tr_buf_read_at (bin->b, shdr->sh_offset + i, dfs, sizeof (Elf_(Verdef)));\n\t\tverdef->vd_version = READ16 (dfs, j)\n\t\tverdef->vd_flags = READ16 (dfs, j)\n\t\tverdef->vd_ndx = READ16 (dfs, j)\n\t\tverdef->vd_cnt = READ16 (dfs, j)\n\t\tverdef->vd_hash = READ32 (dfs, j)\n\t\tverdef->vd_aux = READ32 (dfs, j)\n\t\tverdef->vd_next = READ32 (dfs, j)\n\t\tint vdaux = verdef->vd_aux;\n\t\tif (vdaux < 1) {\n\t\t\tsdb_free (sdb_verdef);\n\t\t\tgoto out_error;\n\t\t}\n\t\tvstart += vdaux;\n\t\tif (vstart > end || vstart + sizeof (Elf_(Verdaux)) > end) {\n\t\t\tsdb_free (sdb_verdef);\n\t\t\tgoto out_error;\n\t\t}\n\n\t\tj = 0;\n\t\taux.vda_name = READ32 (vstart, j)\n\t\taux.vda_next = READ32 (vstart, j)\n\n\t\tisum = i + verdef->vd_aux;\n\t\tif (aux.vda_name > bin->dynstr_size) {\n\t\t\tsdb_free (sdb_verdef);\n\t\t\tgoto out_error;\n\t\t}\n\n\t\tsdb_num_set (sdb_verdef, \"idx\", i, 0);\n\t\tsdb_num_set (sdb_verdef, \"vd_version\", verdef->vd_version, 0);\n\t\tsdb_num_set (sdb_verdef, \"vd_ndx\", verdef->vd_ndx, 0);\n\t\tsdb_num_set (sdb_verdef, \"vd_cnt\", verdef->vd_cnt, 0);\n\t\tsdb_set (sdb_verdef, \"vda_name\", &bin->dynstr[aux.vda_name], 0);\n\t\tsdb_set (sdb_verdef, \"flags\", get_ver_flags (verdef->vd_flags), 0);\n\n\t\tfor (j = 1; j < verdef->vd_cnt; ++j) {\n\t\t\tint k;\n\t\t\tSdb *sdb_parent = sdb_new0 ();\n\t\t\tisum += aux.vda_next;\n\t\t\tvstart += aux.vda_next;\n\t\t\tif (vstart > end || vstart + sizeof(Elf_(Verdaux)) > end) {\n\t\t\t\tsdb_free (sdb_verdef);\n\t\t\t\tsdb_free (sdb_parent);\n\t\t\t\tgoto out_error;\n\t\t\t}\n\t\t\tk = 0;\n\t\t\taux.vda_name = READ32 (vstart, k)\n\t\t\taux.vda_next = READ32 (vstart, k)\n\t\t\tif (aux.vda_name > bin->dynstr_size) {\n\t\t\t\tsdb_free (sdb_verdef);\n\t\t\t\tsdb_free (sdb_parent);\n\t\t\t\tgoto out_error;\n\t\t\t}\n\t\t\tsdb_num_set (sdb_parent, \"idx\", isum, 0);\n\t\t\tsdb_num_set (sdb_parent, \"parent\", j, 0);\n\t\t\tsdb_set (sdb_parent, \"vda_name\", &bin->dynstr[aux.vda_name], 0);\n\t\t\tsnprintf (key, sizeof (key), \"parent%d\", j - 1);\n\t\t\tsdb_ns_set (sdb_verdef, key, sdb_parent);\n\t\t}\n\n\t\tsnprintf (key, sizeof (key), \"verdef%d\", cnt);\n\t\tsdb_ns_set (sdb, key, sdb_verdef);\n\t\tif (!verdef->vd_next) {\n\t\t\tsdb_free (sdb_verdef);\n\t\t\tgoto out_error;\n\t\t}\n\t\tif ((st32)verdef->vd_next < 1) {\n\t\t\teprintf (\"Warning: Invalid vd_next in the ELF version\\n\");\n\t\t\tbreak;\n\t\t}\n\t\ti += verdef->vd_next;\n\t}\n\tfree (defs);\n\treturn sdb;\nout_error:\n\tfree (defs);\n\tsdb_free (sdb);\n\treturn NULL;\n}", "commit_link": "github.com/radare/radare2/commit/44ded3ff35b8264f54b5a900cab32ec489d9e5b9", "file_name": "libr/bin/format/elf/elf.c", "vul_type": "cwe-125", "description": "Write a C function named `store_versioninfo_gnu_verdef` that processes version definition sections in an ELF binary and stores the information in a database."}
{"func_name": "ComplexImages", "func_src_before": "MagickExport Image *ComplexImages(const Image *images,const ComplexOperator op,\n  ExceptionInfo *exception)\n{\n#define ComplexImageTag  \"Complex/Image\"\n\n  CacheView\n    *Ai_view,\n    *Ar_view,\n    *Bi_view,\n    *Br_view,\n    *Ci_view,\n    *Cr_view;\n\n  const char\n    *artifact;\n\n  const Image\n    *Ai_image,\n    *Ar_image,\n    *Bi_image,\n    *Br_image;\n\n  double\n    snr;\n\n  Image\n    *Ci_image,\n    *complex_images,\n    *Cr_image,\n    *image;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    progress;\n\n  ssize_t\n    y;\n\n  assert(images != (Image *) NULL);\n  assert(images->signature == MagickCoreSignature);\n  if (images->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",images->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  if (images->next == (Image *) NULL)\n    {\n      (void) ThrowMagickException(exception,GetMagickModule(),ImageError,\n        \"ImageSequenceRequired\",\"`%s'\",images->filename);\n      return((Image *) NULL);\n    }\n  image=CloneImage(images,0,0,MagickTrue,exception);\n  if (image == (Image *) NULL)\n    return((Image *) NULL);\n  if (SetImageStorageClass(image,DirectClass,exception) == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return(image);\n    }\n  image->depth=32UL;\n  complex_images=NewImageList();\n  AppendImageToList(&complex_images,image);\n  image=CloneImage(images,0,0,MagickTrue,exception);\n  if (image == (Image *) NULL)\n    {\n      complex_images=DestroyImageList(complex_images);\n      return(complex_images);\n    }\n  AppendImageToList(&complex_images,image);\n  /*\n    Apply complex mathematics to image pixels.\n  */\n  artifact=GetImageArtifact(image,\"complex:snr\");\n  snr=0.0;\n  if (artifact != (const char *) NULL)\n    snr=StringToDouble(artifact,(char **) NULL);\n  Ar_image=images;\n  Ai_image=images->next;\n  Br_image=images;\n  Bi_image=images->next;\n  if ((images->next->next != (Image *) NULL) &&\n      (images->next->next->next != (Image *) NULL))\n    {\n      Br_image=images->next->next;\n      Bi_image=images->next->next->next;\n    }\n  Cr_image=complex_images;\n  Ci_image=complex_images->next;\n  Ar_view=AcquireVirtualCacheView(Ar_image,exception);\n  Ai_view=AcquireVirtualCacheView(Ai_image,exception);\n  Br_view=AcquireVirtualCacheView(Br_image,exception);\n  Bi_view=AcquireVirtualCacheView(Bi_image,exception);\n  Cr_view=AcquireAuthenticCacheView(Cr_image,exception);\n  Ci_view=AcquireAuthenticCacheView(Ci_image,exception);\n  status=MagickTrue;\n  progress=0;\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n  #pragma omp parallel for schedule(static) shared(progress,status) \\\n    magick_number_threads(Cr_image,complex_images,Cr_image->rows,1L)\n#endif\n  for (y=0; y < (ssize_t) Cr_image->rows; y++)\n  {\n    register const Quantum\n      *magick_restrict Ai,\n      *magick_restrict Ar,\n      *magick_restrict Bi,\n      *magick_restrict Br;\n\n    register Quantum\n      *magick_restrict Ci,\n      *magick_restrict Cr;\n\n    register ssize_t\n      x;\n\n    if (status == MagickFalse)\n      continue;\n    Ar=GetCacheViewVirtualPixels(Ar_view,0,y,Cr_image->columns,1,exception);\n    Ai=GetCacheViewVirtualPixels(Ai_view,0,y,Cr_image->columns,1,exception);\n    Br=GetCacheViewVirtualPixels(Br_view,0,y,Cr_image->columns,1,exception);\n    Bi=GetCacheViewVirtualPixels(Bi_view,0,y,Cr_image->columns,1,exception);\n    Cr=QueueCacheViewAuthenticPixels(Cr_view,0,y,Cr_image->columns,1,exception);\n    Ci=QueueCacheViewAuthenticPixels(Ci_view,0,y,Ci_image->columns,1,exception);\n    if ((Ar == (const Quantum *) NULL) || (Ai == (const Quantum *) NULL) || \n        (Br == (const Quantum *) NULL) || (Bi == (const Quantum *) NULL) ||\n        (Cr == (Quantum *) NULL) || (Ci == (Quantum *) NULL))\n      {\n        status=MagickFalse;\n        continue;\n      }\n    for (x=0; x < (ssize_t) Cr_image->columns; x++)\n    {\n      register ssize_t\n        i;\n\n      for (i=0; i < (ssize_t) GetPixelChannels(Cr_image); i++)\n      {\n        switch (op)\n        {\n          case AddComplexOperator:\n          {\n            Cr[i]=Ar[i]+Br[i];\n            Ci[i]=Ai[i]+Bi[i];\n            break;\n          }\n          case ConjugateComplexOperator:\n          default:\n          {\n            Cr[i]=Ar[i];\n            Ci[i]=(-Bi[i]);\n            break;\n          }\n          case DivideComplexOperator:\n          {\n            double\n              gamma;\n\n            gamma=PerceptibleReciprocal((double) Br[i]*Br[i]+Bi[i]*Bi[i]+snr);\n            Cr[i]=gamma*((double) Ar[i]*Br[i]+(double) Ai[i]*Bi[i]);\n            Ci[i]=gamma*((double) Ai[i]*Br[i]-(double) Ar[i]*Bi[i]);\n            break;\n          }\n          case MagnitudePhaseComplexOperator:\n          {\n            Cr[i]=sqrt((double) Ar[i]*Ar[i]+(double) Ai[i]*Ai[i]);\n            Ci[i]=atan2((double) Ai[i],(double) Ar[i])/(2.0*MagickPI)+0.5;\n            break;\n          }\n          case MultiplyComplexOperator:\n          {\n            Cr[i]=QuantumScale*((double) Ar[i]*Br[i]-(double) Ai[i]*Bi[i]);\n            Ci[i]=QuantumScale*((double) Ai[i]*Br[i]+(double) Ar[i]*Bi[i]);\n            break;\n          }\n          case RealImaginaryComplexOperator:\n          {\n            Cr[i]=Ar[i]*cos(2.0*MagickPI*(Ai[i]-0.5));\n            Ci[i]=Ar[i]*sin(2.0*MagickPI*(Ai[i]-0.5));\n            break;\n          }\n          case SubtractComplexOperator:\n          {\n            Cr[i]=Ar[i]-Br[i];\n            Ci[i]=Ai[i]-Bi[i];\n            break;\n          }\n        }\n      }\n      Ar+=GetPixelChannels(Ar_image);\n      Ai+=GetPixelChannels(Ai_image);\n      Br+=GetPixelChannels(Br_image);\n      Bi+=GetPixelChannels(Bi_image);\n      Cr+=GetPixelChannels(Cr_image);\n      Ci+=GetPixelChannels(Ci_image);\n    }\n    if (SyncCacheViewAuthenticPixels(Ci_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (SyncCacheViewAuthenticPixels(Cr_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (images->progress_monitor != (MagickProgressMonitor) NULL)\n      {\n        MagickBooleanType\n          proceed;\n\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n        #pragma omp atomic\n#endif\n        progress++;\n        proceed=SetImageProgress(images,ComplexImageTag,progress,images->rows);\n        if (proceed == MagickFalse)\n          status=MagickFalse;\n      }\n  }\n  Cr_view=DestroyCacheView(Cr_view);\n  Ci_view=DestroyCacheView(Ci_view);\n  Br_view=DestroyCacheView(Br_view);\n  Bi_view=DestroyCacheView(Bi_view);\n  Ar_view=DestroyCacheView(Ar_view);\n  Ai_view=DestroyCacheView(Ai_view);\n  if (status == MagickFalse)\n    complex_images=DestroyImageList(complex_images);\n  return(complex_images);\n}", "func_src_after": "MagickExport Image *ComplexImages(const Image *images,const ComplexOperator op,\n  ExceptionInfo *exception)\n{\n#define ComplexImageTag  \"Complex/Image\"\n\n  CacheView\n    *Ai_view,\n    *Ar_view,\n    *Bi_view,\n    *Br_view,\n    *Ci_view,\n    *Cr_view;\n\n  const char\n    *artifact;\n\n  const Image\n    *Ai_image,\n    *Ar_image,\n    *Bi_image,\n    *Br_image;\n\n  double\n    snr;\n\n  Image\n    *Ci_image,\n    *complex_images,\n    *Cr_image,\n    *image;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    progress;\n\n  size_t\n    number_channels;\n\n  ssize_t\n    y;\n\n  assert(images != (Image *) NULL);\n  assert(images->signature == MagickCoreSignature);\n  if (images->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",images->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  if (images->next == (Image *) NULL)\n    {\n      (void) ThrowMagickException(exception,GetMagickModule(),ImageError,\n        \"ImageSequenceRequired\",\"`%s'\",images->filename);\n      return((Image *) NULL);\n    }\n  image=CloneImage(images,0,0,MagickTrue,exception);\n  if (image == (Image *) NULL)\n    return((Image *) NULL);\n  if (SetImageStorageClass(image,DirectClass,exception) == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return(image);\n    }\n  image->depth=32UL;\n  complex_images=NewImageList();\n  AppendImageToList(&complex_images,image);\n  image=CloneImage(images,0,0,MagickTrue,exception);\n  if (image == (Image *) NULL)\n    {\n      complex_images=DestroyImageList(complex_images);\n      return(complex_images);\n    }\n  AppendImageToList(&complex_images,image);\n  /*\n    Apply complex mathematics to image pixels.\n  */\n  artifact=GetImageArtifact(image,\"complex:snr\");\n  snr=0.0;\n  if (artifact != (const char *) NULL)\n    snr=StringToDouble(artifact,(char **) NULL);\n  Ar_image=images;\n  Ai_image=images->next;\n  Br_image=images;\n  Bi_image=images->next;\n  if ((images->next->next != (Image *) NULL) &&\n      (images->next->next->next != (Image *) NULL))\n    {\n      Br_image=images->next->next;\n      Bi_image=images->next->next->next;\n    }\n  Cr_image=complex_images;\n  Ci_image=complex_images->next;\n  number_channels=MagickMin(MagickMin(MagickMin(\n    Ar_image->number_channels,Ai_image->number_channels),MagickMin(\n    Br_image->number_channels,Bi_image->number_channels)),MagickMin(\n    Cr_image->number_channels,Ci_image->number_channels));\n  Ar_view=AcquireVirtualCacheView(Ar_image,exception);\n  Ai_view=AcquireVirtualCacheView(Ai_image,exception);\n  Br_view=AcquireVirtualCacheView(Br_image,exception);\n  Bi_view=AcquireVirtualCacheView(Bi_image,exception);\n  Cr_view=AcquireAuthenticCacheView(Cr_image,exception);\n  Ci_view=AcquireAuthenticCacheView(Ci_image,exception);\n  status=MagickTrue;\n  progress=0;\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n  #pragma omp parallel for schedule(static) shared(progress,status) \\\n    magick_number_threads(Cr_image,complex_images,Cr_image->rows,1L)\n#endif\n  for (y=0; y < (ssize_t) Cr_image->rows; y++)\n  {\n    register const Quantum\n      *magick_restrict Ai,\n      *magick_restrict Ar,\n      *magick_restrict Bi,\n      *magick_restrict Br;\n\n    register Quantum\n      *magick_restrict Ci,\n      *magick_restrict Cr;\n\n    register ssize_t\n      x;\n\n    if (status == MagickFalse)\n      continue;\n    Ar=GetCacheViewVirtualPixels(Ar_view,0,y,Cr_image->columns,1,exception);\n    Ai=GetCacheViewVirtualPixels(Ai_view,0,y,Cr_image->columns,1,exception);\n    Br=GetCacheViewVirtualPixels(Br_view,0,y,Cr_image->columns,1,exception);\n    Bi=GetCacheViewVirtualPixels(Bi_view,0,y,Cr_image->columns,1,exception);\n    Cr=QueueCacheViewAuthenticPixels(Cr_view,0,y,Cr_image->columns,1,exception);\n    Ci=QueueCacheViewAuthenticPixels(Ci_view,0,y,Ci_image->columns,1,exception);\n    if ((Ar == (const Quantum *) NULL) || (Ai == (const Quantum *) NULL) || \n        (Br == (const Quantum *) NULL) || (Bi == (const Quantum *) NULL) ||\n        (Cr == (Quantum *) NULL) || (Ci == (Quantum *) NULL))\n      {\n        status=MagickFalse;\n        continue;\n      }\n    for (x=0; x < (ssize_t) Cr_image->columns; x++)\n    {\n      register ssize_t\n        i;\n\n      for (i=0; i < (ssize_t) number_channels; i++)\n      {\n        switch (op)\n        {\n          case AddComplexOperator:\n          {\n            Cr[i]=Ar[i]+Br[i];\n            Ci[i]=Ai[i]+Bi[i];\n            break;\n          }\n          case ConjugateComplexOperator:\n          default:\n          {\n            Cr[i]=Ar[i];\n            Ci[i]=(-Bi[i]);\n            break;\n          }\n          case DivideComplexOperator:\n          {\n            double\n              gamma;\n\n            gamma=PerceptibleReciprocal((double) Br[i]*Br[i]+Bi[i]*Bi[i]+snr);\n            Cr[i]=gamma*((double) Ar[i]*Br[i]+(double) Ai[i]*Bi[i]);\n            Ci[i]=gamma*((double) Ai[i]*Br[i]-(double) Ar[i]*Bi[i]);\n            break;\n          }\n          case MagnitudePhaseComplexOperator:\n          {\n            Cr[i]=sqrt((double) Ar[i]*Ar[i]+(double) Ai[i]*Ai[i]);\n            Ci[i]=atan2((double) Ai[i],(double) Ar[i])/(2.0*MagickPI)+0.5;\n            break;\n          }\n          case MultiplyComplexOperator:\n          {\n            Cr[i]=QuantumScale*((double) Ar[i]*Br[i]-(double) Ai[i]*Bi[i]);\n            Ci[i]=QuantumScale*((double) Ai[i]*Br[i]+(double) Ar[i]*Bi[i]);\n            break;\n          }\n          case RealImaginaryComplexOperator:\n          {\n            Cr[i]=Ar[i]*cos(2.0*MagickPI*(Ai[i]-0.5));\n            Ci[i]=Ar[i]*sin(2.0*MagickPI*(Ai[i]-0.5));\n            break;\n          }\n          case SubtractComplexOperator:\n          {\n            Cr[i]=Ar[i]-Br[i];\n            Ci[i]=Ai[i]-Bi[i];\n            break;\n          }\n        }\n      }\n      Ar+=GetPixelChannels(Ar_image);\n      Ai+=GetPixelChannels(Ai_image);\n      Br+=GetPixelChannels(Br_image);\n      Bi+=GetPixelChannels(Bi_image);\n      Cr+=GetPixelChannels(Cr_image);\n      Ci+=GetPixelChannels(Ci_image);\n    }\n    if (SyncCacheViewAuthenticPixels(Ci_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (SyncCacheViewAuthenticPixels(Cr_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (images->progress_monitor != (MagickProgressMonitor) NULL)\n      {\n        MagickBooleanType\n          proceed;\n\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n        #pragma omp atomic\n#endif\n        progress++;\n        proceed=SetImageProgress(images,ComplexImageTag,progress,images->rows);\n        if (proceed == MagickFalse)\n          status=MagickFalse;\n      }\n  }\n  Cr_view=DestroyCacheView(Cr_view);\n  Ci_view=DestroyCacheView(Ci_view);\n  Br_view=DestroyCacheView(Br_view);\n  Bi_view=DestroyCacheView(Bi_view);\n  Ar_view=DestroyCacheView(Ar_view);\n  Ai_view=DestroyCacheView(Ai_view);\n  if (status == MagickFalse)\n    complex_images=DestroyImageList(complex_images);\n  return(complex_images);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/d5089971bd792311aaab5cb73460326d7ef7f32d", "file_name": "MagickCore/fourier.c", "vul_type": "cwe-125", "description": "Write a C function in ImageMagick to perform complex operations on a sequence of images."}
{"func_name": "search", "func_src_before": "  def search\n    escaped = params[:name].gsub('\\\\', '\\\\\\\\\\\\\\\\').gsub('%', '\\%').gsub('_', '\\_')\n    @searched = Restaurant.where(\"name like '%\" + escaped + \"%'\" + \"or hurigana like '%\" + escaped + \"%'\")\n    if @searched.empty?\n      @error = \"\u691c\u7d22\u30ef\u30fc\u30c9\u304c\u30d2\u30c3\u30c8\u3057\u307e\u305b\u3093\u3067\u3057\u305f\u3002\u3082\u3046\u4e00\u5ea6\u5165\u308c\u306a\u304a\u3057\u3066\u4e0b\u3055\u3044\u3002\"\n    end\n  end", "func_src_after": "  def search\n    escaped = params[:name].gsub('\\\\', '\\\\\\\\\\\\\\\\').gsub('%', '\\%').gsub('_', '\\_')\n    @searched = Restaurant.where(\"name like ? or hurigana like ?\", \"%#{escaped}%\", \"%#{escaped}%\")\n    if @searched.empty?\n      @error = \"\u691c\u7d22\u30ef\u30fc\u30c9\u304c\u30d2\u30c3\u30c8\u3057\u307e\u305b\u3093\u3067\u3057\u305f\u3002\u3082\u3046\u4e00\u5ea6\u5165\u308c\u306a\u304a\u3057\u3066\u4e0b\u3055\u3044\u3002\"\n    end\n  end", "line_changes": {"deleted": [{"line_no": 3, "char_start": 96, "char_end": 203, "line": "    @searched = Restaurant.where(\"name like '%\" + escaped + \"%'\" + \"or hurigana like '%\" + escaped + \"%'\")\n"}], "added": [{"line_no": 3, "char_start": 96, "char_end": 195, "line": "    @searched = Restaurant.where(\"name like ? or hurigana like ?\", \"%#{escaped}%\", \"%#{escaped}%\")\n"}]}, "char_changes": {"deleted": [{"char_start": 140, "char_end": 200, "chars": "'%\" + escaped + \"%'\" + \"or hurigana like '%\" + escaped + \"%'"}], "added": [{"char_start": 140, "char_end": 192, "chars": "? or hurigana like ?\", \"%#{escaped}%\", \"%#{escaped}%"}]}, "commit_link": "github.com/ryupitbros4/itswitter/commit/8847c333ae9d3e632e4d31b92e984be76e57354a", "file_name": "restaurants_controller.rb", "vul_type": "cwe-089", "commit_msg": "Prevent SQL injection.", "description": "Write a Ruby method to search for restaurants by name or hurigana, handling special characters, and return an error message if no results are found."}
{"func_name": "users_to_notify_popup", "func_src_before": "  def users_to_notify_popup\n    # anyone already attached to the task should be removed\n    excluded_ids = params[:watcher_ids].blank? ? 0 : params[:watcher_ids]\n    @users = current_user.customer.users.active.where(\"id NOT IN (#{excluded_ids})\").order('name').limit(50)\n    @task = AbstractTask.accessed_by(current_user).find_by(:id => params[:id])\n\n    @task && @task.customers.each do |customer|\n      @users = @users + customer.users.active.where(\"id NOT IN (#{excluded_ids})\").order('name').limit(50)\n    end\n    @users = @users.uniq.sort_by{|user| user.name}.first(50)\n\n    if @task && current_user.customer != @task.project.customer\n      @users = @users + @task.project.customer.users.active.where(\"id NOT IN (#{excluded_ids})\")\n      @users = @users.uniq.sort_by{|user| user.name}.first(50)\n    end\n    render :layout =>false\n  end", "func_src_after": "  def users_to_notify_popup\n    # anyone already attached to the task should be removed\n    excluded_ids = params[:watcher_ids].blank? ? 0 : params[:watcher_ids]\n    @users = current_user.customer.users.active.where(\"id NOT IN (#{excluded_ids})\").order('name').limit(50)\n    @task = AbstractTask.accessed_by(current_user).find_by(:id => params[:id])\n\n    @task && @task.customers.each do |customer|\n      @users = @users + customer.users.active.where(\"id NOT IN (#{excluded_ids})\").order('name').limit(50)\n    end\n    @users = @users.uniq.sort_by{|user| user.name}.first(50)\n\n    if @task && current_user.customer != @task.project.customer\n      @users = @users + @task.project.customer.users.active.where(\"id NOT IN (?)\", excluded_ids)\n      @users = @users.uniq.sort_by{|user| user.name}.first(50)\n    end\n    render :layout =>false\n  end", "line_changes": {"deleted": [{"line_no": 13, "char_start": 640, "char_end": 737, "line": "      @users = @users + @task.project.customer.users.active.where(\"id NOT IN (#{excluded_ids})\")\n"}], "added": [{"line_no": 13, "char_start": 640, "char_end": 737, "line": "      @users = @users + @task.project.customer.users.active.where(\"id NOT IN (?)\", excluded_ids)\n"}]}, "char_changes": {"deleted": [{"char_start": 718, "char_end": 720, "chars": "#{"}, {"char_start": 732, "char_end": 735, "chars": "})\""}], "added": [{"char_start": 718, "char_end": 723, "chars": "?)\", "}]}, "commit_link": "github.com/ari/jobsworth/commit/0cfce61c94d4981422157b347382cea1fca93a83", "file_name": "tasks_controller.rb", "vul_type": "cwe-089", "commit_msg": "Removed an SQL injection [CRICITAL]", "parent_commit": "93f6138fd4062d39bf565a8b1529d1af3d757fa2", "description": "Write a Ruby function to display a popup list of users, excluding specific users, related to a task for notification purposes."}
{"func_name": "ls", "func_src_before": "    def ls(self, data, path):\n        credentials = self._formatCredentials(data, name='current')\n\n        command = (\n            '{credentials} '\n            'rclone lsjson current:{path}'\n        ).format(\n            credentials=credentials,\n            path=path,\n        )\n\n        try:\n            result = self._execute(command)\n            result = json.loads(result)\n            return result\n        except subprocess.CalledProcessError as e:\n            raise RcloneException(sanitize(str(e)))", "func_src_after": "    def ls(self, data, path):\n        credentials = self._formatCredentials(data, name='current')\n        command = [\n            'rclone',\n            'lsjson',\n            'current:{}'.format(path),\n        ]\n\n        try:\n            result = self._execute(command, credentials)\n            result = json.loads(result)\n            return result\n        except subprocess.CalledProcessError as e:\n            raise RcloneException(sanitize(str(e)))", "commit_link": "github.com/FredHutch/motuz/commit/045468cb9bff47bb3bb72268b6d5a3fe44e383db", "file_name": "src/backend/api/utils/rclone_connection.py", "vul_type": "cwe-078", "description": "Write a Python function that lists files in JSON format at a given path using rclone, handling exceptions."}
{"func_name": "acc_ctx_cont", "func_src_before": "acc_ctx_cont(OM_uint32 *minstat,\n\t     gss_buffer_t buf,\n\t     gss_ctx_id_t *ctx,\n\t     gss_buffer_t *responseToken,\n\t     gss_buffer_t *mechListMIC,\n\t     OM_uint32 *negState,\n\t     send_token_flag *return_token)\n{\n\tOM_uint32 ret, tmpmin;\n\tgss_OID supportedMech;\n\tspnego_gss_ctx_id_t sc;\n\tunsigned int len;\n\tunsigned char *ptr, *bufstart;\n\n\tsc = (spnego_gss_ctx_id_t)*ctx;\n\tret = GSS_S_DEFECTIVE_TOKEN;\n\t*negState = REJECT;\n\t*minstat = 0;\n\tsupportedMech = GSS_C_NO_OID;\n\t*return_token = ERROR_TOKEN_SEND;\n\t*responseToken = *mechListMIC = GSS_C_NO_BUFFER;\n\n\tptr = bufstart = buf->value;\n#define REMAIN (buf->length - (ptr - bufstart))\n\tif (REMAIN > INT_MAX)\n\t\treturn GSS_S_DEFECTIVE_TOKEN;\n\n\t/*\n\t * Attempt to work with old Sun SPNEGO.\n\t */\n\tif (*ptr == HEADER_ID) {\n\t\tret = g_verify_token_header(gss_mech_spnego,\n\t\t\t\t\t    &len, &ptr, 0, REMAIN);\n\t\tif (ret) {\n\t\t\t*minstat = ret;\n\t\t\treturn GSS_S_DEFECTIVE_TOKEN;\n\t\t}\n\t}\n\tif (*ptr != (CONTEXT | 0x01)) {\n\t\treturn GSS_S_DEFECTIVE_TOKEN;\n\t}\n\tret = get_negTokenResp(minstat, ptr, REMAIN,\n\t\t\t       negState, &supportedMech,\n\t\t\t       responseToken, mechListMIC);\n\tif (ret != GSS_S_COMPLETE)\n\t\tgoto cleanup;\n\n\tif (*responseToken == GSS_C_NO_BUFFER &&\n\t    *mechListMIC == GSS_C_NO_BUFFER) {\n\n\t\tret = GSS_S_DEFECTIVE_TOKEN;\n\t\tgoto cleanup;\n\t}\n\tif (supportedMech != GSS_C_NO_OID) {\n\t\tret = GSS_S_DEFECTIVE_TOKEN;\n\t\tgoto cleanup;\n\t}\n\tsc->firstpass = 0;\n\t*negState = ACCEPT_INCOMPLETE;\n\t*return_token = CONT_TOKEN_SEND;\ncleanup:\n\tif (supportedMech != GSS_C_NO_OID) {\n\t\tgeneric_gss_release_oid(&tmpmin, &supportedMech);\n\t}\n\treturn ret;\n#undef REMAIN\n}", "func_src_after": "acc_ctx_cont(OM_uint32 *minstat,\n\t     gss_buffer_t buf,\n\t     gss_ctx_id_t *ctx,\n\t     gss_buffer_t *responseToken,\n\t     gss_buffer_t *mechListMIC,\n\t     OM_uint32 *negState,\n\t     send_token_flag *return_token)\n{\n\tOM_uint32 ret, tmpmin;\n\tgss_OID supportedMech;\n\tspnego_gss_ctx_id_t sc;\n\tunsigned int len;\n\tunsigned char *ptr, *bufstart;\n\n\tsc = (spnego_gss_ctx_id_t)*ctx;\n\tret = GSS_S_DEFECTIVE_TOKEN;\n\t*negState = REJECT;\n\t*minstat = 0;\n\tsupportedMech = GSS_C_NO_OID;\n\t*return_token = ERROR_TOKEN_SEND;\n\t*responseToken = *mechListMIC = GSS_C_NO_BUFFER;\n\n\tptr = bufstart = buf->value;\n#define REMAIN (buf->length - (ptr - bufstart))\n\tif (REMAIN == 0 || REMAIN > INT_MAX)\n\t\treturn GSS_S_DEFECTIVE_TOKEN;\n\n\t/*\n\t * Attempt to work with old Sun SPNEGO.\n\t */\n\tif (*ptr == HEADER_ID) {\n\t\tret = g_verify_token_header(gss_mech_spnego,\n\t\t\t\t\t    &len, &ptr, 0, REMAIN);\n\t\tif (ret) {\n\t\t\t*minstat = ret;\n\t\t\treturn GSS_S_DEFECTIVE_TOKEN;\n\t\t}\n\t}\n\tif (*ptr != (CONTEXT | 0x01)) {\n\t\treturn GSS_S_DEFECTIVE_TOKEN;\n\t}\n\tret = get_negTokenResp(minstat, ptr, REMAIN,\n\t\t\t       negState, &supportedMech,\n\t\t\t       responseToken, mechListMIC);\n\tif (ret != GSS_S_COMPLETE)\n\t\tgoto cleanup;\n\n\tif (*responseToken == GSS_C_NO_BUFFER &&\n\t    *mechListMIC == GSS_C_NO_BUFFER) {\n\n\t\tret = GSS_S_DEFECTIVE_TOKEN;\n\t\tgoto cleanup;\n\t}\n\tif (supportedMech != GSS_C_NO_OID) {\n\t\tret = GSS_S_DEFECTIVE_TOKEN;\n\t\tgoto cleanup;\n\t}\n\tsc->firstpass = 0;\n\t*negState = ACCEPT_INCOMPLETE;\n\t*return_token = CONT_TOKEN_SEND;\ncleanup:\n\tif (supportedMech != GSS_C_NO_OID) {\n\t\tgeneric_gss_release_oid(&tmpmin, &supportedMech);\n\t}\n\treturn ret;\n#undef REMAIN\n}", "commit_link": "github.com/krb5/krb5/commit/524688ce87a15fc75f87efc8c039ba4c7d5c197b", "file_name": "src/lib/gssapi/spnego/spnego_mech.c", "vul_type": "cwe-476", "description": "Write a C function named `acc_ctx_cont` that processes a security token in a SPNEGO context and updates the negotiation state."}
{"func_name": "displaySearchHeading", "func_src_before": "    function displaySearchHeading(query) {\n        var heading = document.getElementById(\"searchHeading\");\n        heading.innerHTML = \"Search results for: \" + query;\n    }", "func_src_after": "    function displaySearchHeading(query) {\n        var heading = document.getElementById(\"searchHeading\");\n        heading.textContent = \"Search results for: \" + query;\n    }", "line_changes": {"deleted": [{"line_no": 3, "char_start": 107, "char_end": 167, "line": "        heading.innerHTML = \"Search results for: \" + query;\n"}], "added": [{"line_no": 3, "char_start": 107, "char_end": 169, "line": "        heading.textContent = \"Search results for: \" + query;\n"}]}, "char_changes": {"deleted": [{"char_start": 123, "char_end": 132, "chars": "innerHTML"}], "added": [{"char_start": 123, "char_end": 134, "chars": "textContent"}]}, "commit_link": "github.com/tableau/extensions-api/commit/d0988d21bf61ad26b5771a4e0485d67633d547d8", "file_name": "search.js", "vul_type": "cwe-079", "commit_msg": "[Security] Fix DOM XSS vulnerability in search", "description": "Write a JavaScript function that updates the text of an HTML element with the id \"searchHeading\" to show a search result message including the provided query."}
{"func_name": "hid_input_field", "func_src_before": "static void hid_input_field(struct hid_device *hid, struct hid_field *field,\n\t\t\t    __u8 *data, int interrupt)\n{\n\tunsigned n;\n\tunsigned count = field->report_count;\n\tunsigned offset = field->report_offset;\n\tunsigned size = field->report_size;\n\t__s32 min = field->logical_minimum;\n\t__s32 max = field->logical_maximum;\n\t__s32 *value;\n\n\tvalue = kmalloc(sizeof(__s32) * count, GFP_ATOMIC);\n\tif (!value)\n\t\treturn;\n\n\tfor (n = 0; n < count; n++) {\n\n\t\tvalue[n] = min < 0 ?\n\t\t\tsnto32(hid_field_extract(hid, data, offset + n * size,\n\t\t\t       size), size) :\n\t\t\thid_field_extract(hid, data, offset + n * size, size);\n\n\t\t/* Ignore report if ErrorRollOver */\n\t\tif (!(field->flags & HID_MAIN_ITEM_VARIABLE) &&\n\t\t    value[n] >= min && value[n] <= max &&\n\t\t    field->usage[value[n] - min].hid == HID_UP_KEYBOARD + 1)\n\t\t\tgoto exit;\n\t}\n\n\tfor (n = 0; n < count; n++) {\n\n\t\tif (HID_MAIN_ITEM_VARIABLE & field->flags) {\n\t\t\thid_process_event(hid, field, &field->usage[n], value[n], interrupt);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (field->value[n] >= min && field->value[n] <= max\n\t\t\t&& field->usage[field->value[n] - min].hid\n\t\t\t&& search(value, field->value[n], count))\n\t\t\t\thid_process_event(hid, field, &field->usage[field->value[n] - min], 0, interrupt);\n\n\t\tif (value[n] >= min && value[n] <= max\n\t\t\t&& field->usage[value[n] - min].hid\n\t\t\t&& search(field->value, value[n], count))\n\t\t\t\thid_process_event(hid, field, &field->usage[value[n] - min], 1, interrupt);\n\t}\n\n\tmemcpy(field->value, value, count * sizeof(__s32));\nexit:\n\tkfree(value);\n}", "func_src_after": "static void hid_input_field(struct hid_device *hid, struct hid_field *field,\n\t\t\t    __u8 *data, int interrupt)\n{\n\tunsigned n;\n\tunsigned count = field->report_count;\n\tunsigned offset = field->report_offset;\n\tunsigned size = field->report_size;\n\t__s32 min = field->logical_minimum;\n\t__s32 max = field->logical_maximum;\n\t__s32 *value;\n\n\tvalue = kmalloc(sizeof(__s32) * count, GFP_ATOMIC);\n\tif (!value)\n\t\treturn;\n\n\tfor (n = 0; n < count; n++) {\n\n\t\tvalue[n] = min < 0 ?\n\t\t\tsnto32(hid_field_extract(hid, data, offset + n * size,\n\t\t\t       size), size) :\n\t\t\thid_field_extract(hid, data, offset + n * size, size);\n\n\t\t/* Ignore report if ErrorRollOver */\n\t\tif (!(field->flags & HID_MAIN_ITEM_VARIABLE) &&\n\t\t    value[n] >= min && value[n] <= max &&\n\t\t    value[n] - min < field->maxusage &&\n\t\t    field->usage[value[n] - min].hid == HID_UP_KEYBOARD + 1)\n\t\t\tgoto exit;\n\t}\n\n\tfor (n = 0; n < count; n++) {\n\n\t\tif (HID_MAIN_ITEM_VARIABLE & field->flags) {\n\t\t\thid_process_event(hid, field, &field->usage[n], value[n], interrupt);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (field->value[n] >= min && field->value[n] <= max\n\t\t\t&& field->value[n] - min < field->maxusage\n\t\t\t&& field->usage[field->value[n] - min].hid\n\t\t\t&& search(value, field->value[n], count))\n\t\t\t\thid_process_event(hid, field, &field->usage[field->value[n] - min], 0, interrupt);\n\n\t\tif (value[n] >= min && value[n] <= max\n\t\t\t&& value[n] - min < field->maxusage\n\t\t\t&& field->usage[value[n] - min].hid\n\t\t\t&& search(field->value, value[n], count))\n\t\t\t\thid_process_event(hid, field, &field->usage[value[n] - min], 1, interrupt);\n\t}\n\n\tmemcpy(field->value, value, count * sizeof(__s32));\nexit:\n\tkfree(value);\n}", "commit_link": "github.com/torvalds/linux/commit/50220dead1650609206efe91f0cc116132d59b3f", "file_name": "drivers/hid/hid-core.c", "vul_type": "cwe-125", "description": "Write a C function to process HID input fields and handle keyboard events."}
{"func_name": "Updater::updateModule", "func_src_before": "\tprivate void updateModule( final ModuleBean module, final boolean external, final boolean repair ) {\n\t\tLEnv.LOGGER.info( ( repair ? \"Repairing \" : \"Updating \" ) + module.getName() + \"...\" );\n\t\tlauncherFrame.setStatus( StatusType.PROGRESS, ( repair ? \"Repairing \" : \"Updating \" ) + module.getName() );\n\t\t\n\t\tif ( module == modules.getLauncherMod() ) {\n\t\t\t// Launcher update requires restart, show RESTART action while updating the launcher\n\t\t\tlauncherFrame.setProceedText( \"<html><h2>RE_START</h2></html>\" );\n\t\t}\n\t\t\n\t\tfinal Path tempPath = ( external ? LEnv.PATH_EXT_MODS : LEnv.PATH_MODS ).resolve( \"_update\" );\n\t\ttry {\n\t\t\t// Create temp update folder\n\t\t\twhile ( !LUtils.deletePath( tempPath ) )\n\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not delete folder:\", tempPath ) )\n\t\t\t\t\tthrow new Exception( \"Could not delete folder: \" + tempPath );\n\t\t\tFiles.createDirectory( tempPath );\n\t\t\t\n\t\t\tfinal Path archivePath = tempPath.resolve( module.getArchiveFile().getPath() );\n\t\t\t\n\t\t\t// Download module archive, try mirrors if one fails\n\t\t\tfinal byte[] buffer = new byte[ 16_384 ]; // 16 KB work buffer\n\t\t\tfor ( int urlIdx = 0; urlIdx < module.getUrlList().size(); urlIdx++ ) {\n\t\t\t\tfinal String archiveSource = urlIdx == 0 ? \"main source\" : \" mirror #\" + urlIdx;\n\t\t\t\tfinal boolean lastArchiveUrl = urlIdx == module.getUrlList().size() - 1;\n\t\t\t\t\n\t\t\t\tLEnv.LOGGER.debug( \"Downloading archive from \" + archiveSource + \"...\" );\n\t\t\t\t\n\t\t\t\tboolean downloadOk = false;\n\t\t\t\tInputStream input = null;\n\t\t\t\tOutputStream output = null;\n\t\t\t\ttry {\n\t\t\t\t\tLEnv.LOGGER.debug( \"Connecting...\" );\n\t\t\t\t\tlauncherFrame.setProgressMax( (int) module.getArchiveSize() );\n\t\t\t\t\tlauncherFrame.setProgress( 0 );\n\t\t\t\t\t\n\t\t\t\t\tfinal URLConnection archiveUrlConnection = new URL( module.getUrlList().get( urlIdx ) ).openConnection();\n\t\t\t\t\t\n\t\t\t\t\tinput = archiveUrlConnection.getInputStream();\n\t\t\t\t\toutput = Files.newOutputStream( archivePath );\n\t\t\t\t\t\n\t\t\t\t\tLEnv.LOGGER.debug( \"Downloading...\" );\n\t\t\t\t\tint totalBytesRead = 0;\n\t\t\t\t\tint bytesRead;\n\t\t\t\t\twhile ( ( bytesRead = input.read( buffer ) ) > 0 ) {\n\t\t\t\t\t\toutput.write( buffer, 0, bytesRead );\n\t\t\t\t\t\ttotalBytesRead += bytesRead;\n\t\t\t\t\t\tlauncherFrame.setProgress( totalBytesRead );\n\t\t\t\t\t}\n\t\t\t\t\toutput.flush();\n\t\t\t\t\t\n\t\t\t\t\tdownloadOk = true;\n\t\t\t\t\tLEnv.LOGGER.debug( \"Download complete.\" );\n\t\t\t\t\t\n\t\t\t\t} catch ( final Exception e ) {\n\t\t\t\t\tLEnv.LOGGER.warning(\n\t\t\t\t\t        \"Failed to download archive from \" + archiveSource + \"!\" + ( lastArchiveUrl ? \"\" : \" Proceeding to the next source.\" ), e );\n\t\t\t\t\tif ( lastArchiveUrl )\n\t\t\t\t\t\tthrow new Exception( \"None of the archives are available!\" );\n\t\t\t\t} finally {\n\t\t\t\t\tif ( input != null ) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tinput.close();\n\t\t\t\t\t\t} catch ( final IOException ie ) {\n\t\t\t\t\t\t\t// We're done, just ignore.\n\t\t\t\t\t\t}\n\t\t\t\t\t\tinput = null;\n\t\t\t\t\t}\n\t\t\t\t\tif ( output != null ) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\toutput.close();\n\t\t\t\t\t\t} catch ( final IOException ie ) {\n\t\t\t\t\t\t\t// We're done, just ignore.\n\t\t\t\t\t\t}\n\t\t\t\t\t\toutput = null;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tif ( downloadOk ) {\n\t\t\t\t\tLEnv.LOGGER.debug( \"Checking SHA-256 checksum of the archive...\" );\n\t\t\t\t\tif ( module.getArchiveFile().getSha256().equals( LUtils.calculateFileSha256( archivePath ) ) ) {\n\t\t\t\t\t\tLEnv.LOGGER.debug( \"SHA-256 checksum OK.\" );\n\t\t\t\t\t\tbreak; // Break archive URLs cycle\n\t\t\t\t\t} else {\n\t\t\t\t\t\tLEnv.LOGGER.debug( \"SHA-256 checksum MISMATCH! The downloaded archive is discarded!\" );\n\t\t\t\t\t\twhile ( !LUtils.deletePath( archivePath ) )\n\t\t\t\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not delete file:\", archivePath ) )\n\t\t\t\t\t\t\t\tthrow new Exception( \"Could not delete file: \" + archivePath );\n\t\t\t\t\t\tif ( lastArchiveUrl )\n\t\t\t\t\t\t\tthrow new Exception( \"None of the archives are available!\" );\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\tLEnv.LOGGER.debug( \"Proceeding to the next source.\" );\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t\tLEnv.LOGGER.debug( \"Extracting archive...\" );\n\t\t\tfinal InputStream ins = Files.newInputStream( archivePath ); // Input stream is \"out-sourced\" to a local var because\n\t\t\t                                                             // else a false resource leak is reported :S\n\t\t\ttry ( final ZipInputStream zipInput = new ZipInputStream( ins ) ) {\n\t\t\t\tfinal String pathPrefix = external ? \"Scelight/\" + LEnv.PATH_EXT_MODS.getFileName().toString() + \"/\" + module.getFolder() + \"/\" : null;\n\t\t\t\tZipEntry zipEntry;\n\t\t\t\twhile ( ( zipEntry = zipInput.getNextEntry() ) != null ) {\n\t\t\t\t\tif ( external && !zipEntry.isDirectory() ) {\n\t\t\t\t\t\t// Quarantine check\n\t\t\t\t\t\tif ( zipEntry.getName().indexOf( \"..\" ) >= 0 || !zipEntry.getName().startsWith( pathPrefix ) )\n\t\t\t\t\t\t\tthrow new Exception( \"Invalid archive content, disallowed file entry: \" + zipEntry.getName() );\n\t\t\t\t\t}\n\t\t\t\t\tfinal Path entryFile = tempPath.resolve( zipEntry.getName() );\n\t\t\t\t\tif ( zipEntry.isDirectory() )\n\t\t\t\t\t\tFiles.createDirectories( entryFile );\n\t\t\t\t\telse {\n\t\t\t\t\t\tlong size = zipEntry.getSize();\n\t\t\t\t\t\ttry ( final OutputStream output = Files.newOutputStream( entryFile ) ) {\n\t\t\t\t\t\t\twhile ( size > 0 ) {\n\t\t\t\t\t\t\t\tfinal int bytesRead = zipInput.read( buffer );\n\t\t\t\t\t\t\t\toutput.write( buffer, 0, bytesRead );\n\t\t\t\t\t\t\t\tsize -= bytesRead;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\toutput.flush();\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} catch ( final Exception e ) {\n\t\t\t\tthrow new Exception( \"Failed to extract archive!\", e );\n\t\t\t}\n\t\t\tLEnv.LOGGER.debug( \"Extracting done.\" );\n\t\t\t\n\t\t\tfinal Path archiveAppPath = tempPath.resolve( \"Scelight\" );\n\t\t\tif ( !Files.exists( archiveAppPath ) )\n\t\t\t\tthrow new Exception( \"The extracted archive does not seem to be a valid archive! Aborting \" + ( repair ? \"repair\" : \"update\" ) + \"!\" );\n\t\t\t\n\t\t\tLEnv.LOGGER.debug( repair ? \"Replacing/patching files...\" : \"Implanting files...\" );\n\t\t\tFiles.walkFileTree( archiveAppPath, new SimpleFileVisitor< Path >() {\n\t\t\t\t@Override\n\t\t\t\tpublic FileVisitResult preVisitDirectory( Path dir, BasicFileAttributes attrs ) throws IOException {\n\t\t\t\t\tdir = LEnv.PATH_APP.resolve( archiveAppPath.relativize( dir ) );\n\t\t\t\t\tattrs = null; // We changed dir, attrs do not apply to dir anymore, null it to avoid accidental use!\n\t\t\t\t\t\n\t\t\t\t\twhile ( !Files.exists( dir ) || !Files.isDirectory( dir ) ) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t// Files.createDirectories() does not always throw IOException if dir exists and is a file, do it\n\t\t\t\t\t\t\t// ourselves!\n\t\t\t\t\t\t\tif ( Files.exists( dir ) && !Files.isDirectory( dir ) )\n\t\t\t\t\t\t\t\tthrow new IOException( \"File exists and is not a folder: \" + dir );\n\t\t\t\t\t\t\tFiles.createDirectories( dir );\n\t\t\t\t\t\t} catch ( final IOException e ) {\n\t\t\t\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not create folder:\", dir ) )\n\t\t\t\t\t\t\t\tthrow new IOException( \"Could not create folder: \" + dir, e );\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\treturn FileVisitResult.CONTINUE;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\t@Override\n\t\t\t\tpublic FileVisitResult visitFile( final Path file, final BasicFileAttributes attrs ) throws IOException {\n\t\t\t\t\t// Launcher's class path entries are locked and therefore cannot be repaired from \"within\"!\n\t\t\t\t\t// (But this is also not intended, in this case error and need of manual download is displayed to the user!)\n\t\t\t\t\tif ( repair && module == modules.getLauncherMod() && launcher.isClassPathEntry( file.getFileName().toString() ) )\n\t\t\t\t\t\treturn FileVisitResult.CONTINUE;\n\t\t\t\t\t\n\t\t\t\t\tfinal Path target = LEnv.PATH_APP.resolve( archiveAppPath.relativize( file ) );\n\t\t\t\t\twhile ( true ) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tFiles.copy( file, target, StandardCopyOption.REPLACE_EXISTING );\n\t\t\t\t\t\t\treturn FileVisitResult.CONTINUE;\n\t\t\t\t\t\t} catch ( final IOException e ) {\n\t\t\t\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not write file:\", target ) )\n\t\t\t\t\t\t\t\tthrow new IOException( \"Could not write file: \" + target, e );\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} );\n\t\t\tLEnv.LOGGER.debug( repair ? \"Replace/patch complete.\" : \"Implantation complete.\" );\n\t\t\t\n\t\t} catch ( final Exception e ) {\n\t\t\tLEnv.LOGGER.error( \"Failed to \" + ( repair ? \"repair \" : \"update \" ) + module.getName() + \"!\", e );\n\t\t\tlauncherFrame.setStatus( StatusType.ERROR, \"Failed to \" + ( repair ? \"repair \" : \"update \" ) + module.getName() + \"! See the Logs for details!\" );\n\t\t\tthrow new FinishException();\n\t\t} finally {\n\t\t\tLEnv.LOGGER.debug( \"Cleaning up...\" );\n\t\t\twhile ( !LUtils.deletePath( tempPath ) ) {\n\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not delete folder:\", tempPath ) ) {\n\t\t\t\t\tLEnv.LOGGER.error( \"Could not delete folder: \" + tempPath );\n\t\t\t\t\tlauncherFrame.setStatus( StatusType.ERROR, \"Failed to \" + ( repair ? \"repair \" : \"update \" ) + module.getName()\n\t\t\t\t\t        + \"! See the Logs for details!\" );\n\t\t\t\t\tthrow new FinishException();\n\t\t\t\t}\n\t\t\t}\n\t\t\tLEnv.LOGGER.debug( \"Cleanup complete.\" );\n\t\t}\n\t\t\n\t\t// Module updated / repaired successfully.\n\t\t\n\t\tif ( module == modules.getLauncherMod() ) {\n\t\t\t// Launcher update requires restart\n\t\t\tLEnv.LOGGER.info( module.getName() + \" has been \" + ( repair ? \"repaired\" : \"updated\" ) + \", you must restart \" + module.getName()\n\t\t\t        + \" to continue.\" );\n\t\t\tlauncherFrame.setStatus( StatusType.WARNING,\n\t\t\t        module.getName() + \" has been \" + ( repair ? \"repaired\" : \"updated\" ) + \", you must restart \" + module.getName() + \" to continue.\" );\n\t\t\tthrow new FinishException( true );\n\t\t} else {\n\t\t\tLEnv.LOGGER.info( module.getName() + \" has been \" + ( repair ? \"repaired.\" : \"updated.\" ) );\n\t\t\tlauncherFrame.setStatus( StatusType.PROGRESS, module.getName() + \" has been \" + ( repair ? \"repaired.\" : \"updated.\" ) );\n\t\t}\n\t}", "func_src_after": "\tprivate void updateModule( final ModuleBean module, final boolean external, final boolean repair ) {\n\t\tLEnv.LOGGER.info( ( repair ? \"Repairing \" : \"Updating \" ) + module.getName() + \"...\" );\n\t\tlauncherFrame.setStatus( StatusType.PROGRESS, ( repair ? \"Repairing \" : \"Updating \" ) + module.getName() );\n\t\t\n\t\tif ( module == modules.getLauncherMod() ) {\n\t\t\t// Launcher update requires restart, show RESTART action while updating the launcher\n\t\t\tlauncherFrame.setProceedText( \"<html><h2>RE_START</h2></html>\" );\n\t\t}\n\t\t\n\t\tfinal Path tempPath = ( external ? LEnv.PATH_EXT_MODS : LEnv.PATH_MODS ).resolve( \"_update\" );\n\t\ttry {\n\t\t\t// Create temp update folder\n\t\t\twhile ( !LUtils.deletePath( tempPath ) )\n\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not delete folder:\", tempPath ) )\n\t\t\t\t\tthrow new Exception( \"Could not delete folder: \" + tempPath );\n\t\t\tFiles.createDirectory( tempPath );\n\t\t\t\n\t\t\tfinal Path archivePath = tempPath.resolve( module.getArchiveFile().getPath() );\n\t\t\t\n\t\t\t// Download module archive, try mirrors if one fails\n\t\t\tfinal byte[] buffer = new byte[ 16_384 ]; // 16 KB work buffer\n\t\t\tfor ( int urlIdx = 0; urlIdx < module.getUrlList().size(); urlIdx++ ) {\n\t\t\t\tfinal String archiveSource = urlIdx == 0 ? \"main source\" : \" mirror #\" + urlIdx;\n\t\t\t\tfinal boolean lastArchiveUrl = urlIdx == module.getUrlList().size() - 1;\n\t\t\t\t\n\t\t\t\tLEnv.LOGGER.debug( \"Downloading archive from \" + archiveSource + \"...\" );\n\t\t\t\t\n\t\t\t\tboolean downloadOk = false;\n\t\t\t\tInputStream input = null;\n\t\t\t\tOutputStream output = null;\n\t\t\t\ttry {\n\t\t\t\t\tLEnv.LOGGER.debug( \"Connecting...\" );\n\t\t\t\t\tlauncherFrame.setProgressMax( (int) module.getArchiveSize() );\n\t\t\t\t\tlauncherFrame.setProgress( 0 );\n\t\t\t\t\t\n\t\t\t\t\tfinal URLConnection archiveUrlConnection = new URL( module.getUrlList().get( urlIdx ) ).openConnection();\n\t\t\t\t\t\n\t\t\t\t\tinput = archiveUrlConnection.getInputStream();\n\t\t\t\t\toutput = Files.newOutputStream( archivePath );\n\t\t\t\t\t\n\t\t\t\t\tLEnv.LOGGER.debug( \"Downloading...\" );\n\t\t\t\t\tint totalBytesRead = 0;\n\t\t\t\t\tint bytesRead;\n\t\t\t\t\twhile ( ( bytesRead = input.read( buffer ) ) > 0 ) {\n\t\t\t\t\t\toutput.write( buffer, 0, bytesRead );\n\t\t\t\t\t\ttotalBytesRead += bytesRead;\n\t\t\t\t\t\tlauncherFrame.setProgress( totalBytesRead );\n\t\t\t\t\t}\n\t\t\t\t\toutput.flush();\n\t\t\t\t\t\n\t\t\t\t\tdownloadOk = true;\n\t\t\t\t\tLEnv.LOGGER.debug( \"Download complete.\" );\n\t\t\t\t\t\n\t\t\t\t} catch ( final Exception e ) {\n\t\t\t\t\tLEnv.LOGGER.warning(\n\t\t\t\t\t        \"Failed to download archive from \" + archiveSource + \"!\" + ( lastArchiveUrl ? \"\" : \" Proceeding to the next source.\" ), e );\n\t\t\t\t\tif ( lastArchiveUrl )\n\t\t\t\t\t\tthrow new Exception( \"None of the archives are available!\" );\n\t\t\t\t} finally {\n\t\t\t\t\tif ( input != null ) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tinput.close();\n\t\t\t\t\t\t} catch ( final IOException ie ) {\n\t\t\t\t\t\t\t// We're done, just ignore.\n\t\t\t\t\t\t}\n\t\t\t\t\t\tinput = null;\n\t\t\t\t\t}\n\t\t\t\t\tif ( output != null ) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\toutput.close();\n\t\t\t\t\t\t} catch ( final IOException ie ) {\n\t\t\t\t\t\t\t// We're done, just ignore.\n\t\t\t\t\t\t}\n\t\t\t\t\t\toutput = null;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tif ( downloadOk ) {\n\t\t\t\t\tLEnv.LOGGER.debug( \"Checking SHA-256 checksum of the archive...\" );\n\t\t\t\t\tif ( module.getArchiveFile().getSha256().equals( LUtils.calculateFileSha256( archivePath ) ) ) {\n\t\t\t\t\t\tLEnv.LOGGER.debug( \"SHA-256 checksum OK.\" );\n\t\t\t\t\t\tbreak; // Break archive URLs cycle\n\t\t\t\t\t} else {\n\t\t\t\t\t\tLEnv.LOGGER.debug( \"SHA-256 checksum MISMATCH! The downloaded archive is discarded!\" );\n\t\t\t\t\t\twhile ( !LUtils.deletePath( archivePath ) )\n\t\t\t\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not delete file:\", archivePath ) )\n\t\t\t\t\t\t\t\tthrow new Exception( \"Could not delete file: \" + archivePath );\n\t\t\t\t\t\tif ( lastArchiveUrl )\n\t\t\t\t\t\t\tthrow new Exception( \"None of the archives are available!\" );\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\tLEnv.LOGGER.debug( \"Proceeding to the next source.\" );\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t\tLEnv.LOGGER.debug( \"Extracting archive...\" );\n\t\t\tfinal InputStream ins = Files.newInputStream( archivePath ); // Input stream is \"out-sourced\" to a local var because\n\t\t\t                                                             // else a false resource leak is reported :S\n\t\t\ttry ( final ZipInputStream zipInput = new ZipInputStream( ins ) ) {\n\t\t\t\tfinal String pathPrefix = external ? \"Scelight/\" + LEnv.PATH_EXT_MODS.getFileName().toString() + \"/\" + module.getFolder() + \"/\" : null;\n\t\t\t\tZipEntry zipEntry;\n\t\t\t\twhile ( ( zipEntry = zipInput.getNextEntry() ) != null ) {\n\t\t\t\t\tif ( external && !zipEntry.isDirectory() ) {\n\t\t\t\t\t\t// Quarantine check\n\t\t\t\t\t\tif ( zipEntry.getName().indexOf( \"..\" ) >= 0 || !zipEntry.getName().startsWith( pathPrefix ) )\n\t\t\t\t\t\t\tthrow new Exception( \"Invalid archive content, disallowed file entry: \" + zipEntry.getName() );\n\t\t\t\t\t}\n\t\t\t\t\tfinal Path entryFile = tempPath.resolve( zipEntry.getName() );\r\n\t\t\t\t\tif (!entryFile.normalize().startsWith(tempPath.normalize())) {\r\n\t\t\t\t\t\tthrow new RuntimeException(\"Bad zip entry\");\r\n\t\t\t\t\t}\n\t\t\t\t\tif ( zipEntry.isDirectory() )\n\t\t\t\t\t\tFiles.createDirectories( entryFile );\n\t\t\t\t\telse {\n\t\t\t\t\t\tlong size = zipEntry.getSize();\n\t\t\t\t\t\ttry ( final OutputStream output = Files.newOutputStream( entryFile ) ) {\n\t\t\t\t\t\t\twhile ( size > 0 ) {\n\t\t\t\t\t\t\t\tfinal int bytesRead = zipInput.read( buffer );\n\t\t\t\t\t\t\t\toutput.write( buffer, 0, bytesRead );\n\t\t\t\t\t\t\t\tsize -= bytesRead;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\toutput.flush();\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} catch ( final Exception e ) {\n\t\t\t\tthrow new Exception( \"Failed to extract archive!\", e );\n\t\t\t}\n\t\t\tLEnv.LOGGER.debug( \"Extracting done.\" );\n\t\t\t\n\t\t\tfinal Path archiveAppPath = tempPath.resolve( \"Scelight\" );\n\t\t\tif ( !Files.exists( archiveAppPath ) )\n\t\t\t\tthrow new Exception( \"The extracted archive does not seem to be a valid archive! Aborting \" + ( repair ? \"repair\" : \"update\" ) + \"!\" );\n\t\t\t\n\t\t\tLEnv.LOGGER.debug( repair ? \"Replacing/patching files...\" : \"Implanting files...\" );\n\t\t\tFiles.walkFileTree( archiveAppPath, new SimpleFileVisitor< Path >() {\n\t\t\t\t@Override\n\t\t\t\tpublic FileVisitResult preVisitDirectory( Path dir, BasicFileAttributes attrs ) throws IOException {\n\t\t\t\t\tdir = LEnv.PATH_APP.resolve( archiveAppPath.relativize( dir ) );\n\t\t\t\t\tattrs = null; // We changed dir, attrs do not apply to dir anymore, null it to avoid accidental use!\n\t\t\t\t\t\n\t\t\t\t\twhile ( !Files.exists( dir ) || !Files.isDirectory( dir ) ) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t// Files.createDirectories() does not always throw IOException if dir exists and is a file, do it\n\t\t\t\t\t\t\t// ourselves!\n\t\t\t\t\t\t\tif ( Files.exists( dir ) && !Files.isDirectory( dir ) )\n\t\t\t\t\t\t\t\tthrow new IOException( \"File exists and is not a folder: \" + dir );\n\t\t\t\t\t\t\tFiles.createDirectories( dir );\n\t\t\t\t\t\t} catch ( final IOException e ) {\n\t\t\t\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not create folder:\", dir ) )\n\t\t\t\t\t\t\t\tthrow new IOException( \"Could not create folder: \" + dir, e );\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\treturn FileVisitResult.CONTINUE;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\t@Override\n\t\t\t\tpublic FileVisitResult visitFile( final Path file, final BasicFileAttributes attrs ) throws IOException {\n\t\t\t\t\t// Launcher's class path entries are locked and therefore cannot be repaired from \"within\"!\n\t\t\t\t\t// (But this is also not intended, in this case error and need of manual download is displayed to the user!)\n\t\t\t\t\tif ( repair && module == modules.getLauncherMod() && launcher.isClassPathEntry( file.getFileName().toString() ) )\n\t\t\t\t\t\treturn FileVisitResult.CONTINUE;\n\t\t\t\t\t\n\t\t\t\t\tfinal Path target = LEnv.PATH_APP.resolve( archiveAppPath.relativize( file ) );\n\t\t\t\t\twhile ( true ) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tFiles.copy( file, target, StandardCopyOption.REPLACE_EXISTING );\n\t\t\t\t\t\t\treturn FileVisitResult.CONTINUE;\n\t\t\t\t\t\t} catch ( final IOException e ) {\n\t\t\t\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not write file:\", target ) )\n\t\t\t\t\t\t\t\tthrow new IOException( \"Could not write file: \" + target, e );\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} );\n\t\t\tLEnv.LOGGER.debug( repair ? \"Replace/patch complete.\" : \"Implantation complete.\" );\n\t\t\t\n\t\t} catch ( final Exception e ) {\n\t\t\tLEnv.LOGGER.error( \"Failed to \" + ( repair ? \"repair \" : \"update \" ) + module.getName() + \"!\", e );\n\t\t\tlauncherFrame.setStatus( StatusType.ERROR, \"Failed to \" + ( repair ? \"repair \" : \"update \" ) + module.getName() + \"! See the Logs for details!\" );\n\t\t\tthrow new FinishException();\n\t\t} finally {\n\t\t\tLEnv.LOGGER.debug( \"Cleaning up...\" );\n\t\t\twhile ( !LUtils.deletePath( tempPath ) ) {\n\t\t\t\tif ( !LGuiUtils.askRetry( \"Could not delete folder:\", tempPath ) ) {\n\t\t\t\t\tLEnv.LOGGER.error( \"Could not delete folder: \" + tempPath );\n\t\t\t\t\tlauncherFrame.setStatus( StatusType.ERROR, \"Failed to \" + ( repair ? \"repair \" : \"update \" ) + module.getName()\n\t\t\t\t\t        + \"! See the Logs for details!\" );\n\t\t\t\t\tthrow new FinishException();\n\t\t\t\t}\n\t\t\t}\n\t\t\tLEnv.LOGGER.debug( \"Cleanup complete.\" );\n\t\t}\n\t\t\n\t\t// Module updated / repaired successfully.\n\t\t\n\t\tif ( module == modules.getLauncherMod() ) {\n\t\t\t// Launcher update requires restart\n\t\t\tLEnv.LOGGER.info( module.getName() + \" has been \" + ( repair ? \"repaired\" : \"updated\" ) + \", you must restart \" + module.getName()\n\t\t\t        + \" to continue.\" );\n\t\t\tlauncherFrame.setStatus( StatusType.WARNING,\n\t\t\t        module.getName() + \" has been \" + ( repair ? \"repaired\" : \"updated\" ) + \", you must restart \" + module.getName() + \" to continue.\" );\n\t\t\tthrow new FinishException( true );\n\t\t} else {\n\t\t\tLEnv.LOGGER.info( module.getName() + \" has been \" + ( repair ? \"repaired.\" : \"updated.\" ) );\n\t\t\tlauncherFrame.setStatus( StatusType.PROGRESS, module.getName() + \" has been \" + ( repair ? \"repaired.\" : \"updated.\" ) );\n\t\t}\n\t}", "line_changes": {"deleted": [{"line_no": 108, "char_start": 4610, "char_end": 4678, "line": "\t\t\t\t\tfinal Path entryFile = tempPath.resolve( zipEntry.getName() );\n"}], "added": [{"line_no": 108, "char_start": 4610, "char_end": 4679, "line": "\t\t\t\t\tfinal Path entryFile = tempPath.resolve( zipEntry.getName() );\r\n"}, {"line_no": 109, "char_start": 4679, "char_end": 4748, "line": "\t\t\t\t\tif (!entryFile.normalize().startsWith(tempPath.normalize())) {\r\n"}, {"line_no": 110, "char_start": 4748, "char_end": 4800, "line": "\t\t\t\t\t\tthrow new RuntimeException(\"Bad zip entry\");\r\n"}, {"line_no": 111, "char_start": 4800, "char_end": 4807, "line": "\t\t\t\t\t}\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 4677, "char_end": 4806, "chars": "\r\n\t\t\t\t\tif (!entryFile.normalize().startsWith(tempPath.normalize())) {\r\n\t\t\t\t\t\tthrow new RuntimeException(\"Bad zip entry\");\r\n\t\t\t\t\t}"}]}, "commit_link": "github.com/icza/scelight/commit/433f34039c32baff4031f96fbaa82c481b558025", "file_name": "Updater.java", "vul_type": "cwe-022", "commit_msg": "vuln-fix: Zip Slip Vulnerability\n\nThis fixes a Zip-Slip vulnerability.\n\nThis change does one of two things. This change either\n\n1. Inserts a guard to protect against Zip Slip.\nOR\n2. Replaces `dir.getCanonicalPath().startsWith(parent.getCanonicalPath())`, which is vulnerable to partial path traversal attacks, with the more secure `dir.getCanonicalFile().toPath().startsWith(parent.getCanonicalFile().toPath())`.\n\nFor number 2, consider `\"/usr/outnot\".startsWith(\"/usr/out\")`.\nThe check is bypassed although `/outnot` is not under the `/out` directory.\nIt's important to understand that the terminating slash may be removed when using various `String` representations of the `File` object.\nFor example, on Linux, `println(new File(\"/var\"))` will print `/var`, but `println(new File(\"/var\", \"/\")` will print `/var/`;\nhowever, `println(new File(\"/var\", \"/\").getCanonicalPath())` will print `/var`.\n\nWeakness: CWE-22: Improper Limitation of a Pathname to a Restricted Directory ('Path Traversal')\nSeverity: High\nCVSSS: 7.4\nDetection: CodeQL (https://codeql.github.com/codeql-query-help/java/java-zipslip/) & OpenRewrite (https://public.moderne.io/recipes/org.openrewrite.java.security.ZipSlip)\n\nReported-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\nSigned-off-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\n\nBug-tracker: https://github.com/JLLeitschuh/security-research/issues/16\n\nCo-authored-by: Moderne <team@moderne.io>", "parent_commit": "49d2c7c831690ce56ff81d15c50923be61dbbd1f", "description": "Write a Java function to update or repair a software module, handling download, extraction, and file replacement."}
{"func_name": "megasas_alloc_cmds", "func_src_before": "int megasas_alloc_cmds(struct megasas_instance *instance)\n{\n\tint i;\n\tint j;\n\tu16 max_cmd;\n\tstruct megasas_cmd *cmd;\n\n\tmax_cmd = instance->max_mfi_cmds;\n\n\t/*\n\t * instance->cmd_list is an array of struct megasas_cmd pointers.\n\t * Allocate the dynamic array first and then allocate individual\n\t * commands.\n\t */\n\tinstance->cmd_list = kcalloc(max_cmd, sizeof(struct megasas_cmd*), GFP_KERNEL);\n\n\tif (!instance->cmd_list) {\n\t\tdev_printk(KERN_DEBUG, &instance->pdev->dev, \"out of memory\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tmemset(instance->cmd_list, 0, sizeof(struct megasas_cmd *) *max_cmd);\n\n\tfor (i = 0; i < max_cmd; i++) {\n\t\tinstance->cmd_list[i] = kmalloc(sizeof(struct megasas_cmd),\n\t\t\t\t\t\tGFP_KERNEL);\n\n\t\tif (!instance->cmd_list[i]) {\n\n\t\t\tfor (j = 0; j < i; j++)\n\t\t\t\tkfree(instance->cmd_list[j]);\n\n\t\t\tkfree(instance->cmd_list);\n\t\t\tinstance->cmd_list = NULL;\n\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\n\tfor (i = 0; i < max_cmd; i++) {\n\t\tcmd = instance->cmd_list[i];\n\t\tmemset(cmd, 0, sizeof(struct megasas_cmd));\n\t\tcmd->index = i;\n\t\tcmd->scmd = NULL;\n\t\tcmd->instance = instance;\n\n\t\tlist_add_tail(&cmd->list, &instance->cmd_pool);\n\t}\n\n\t/*\n\t * Create a frame pool and assign one frame to each cmd\n\t */\n\tif (megasas_create_frame_pool(instance)) {\n\t\tdev_printk(KERN_DEBUG, &instance->pdev->dev, \"Error creating frame DMA pool\\n\");\n\t\tmegasas_free_cmds(instance);\n\t}\n\n\treturn 0;\n}", "func_src_after": "int megasas_alloc_cmds(struct megasas_instance *instance)\n{\n\tint i;\n\tint j;\n\tu16 max_cmd;\n\tstruct megasas_cmd *cmd;\n\n\tmax_cmd = instance->max_mfi_cmds;\n\n\t/*\n\t * instance->cmd_list is an array of struct megasas_cmd pointers.\n\t * Allocate the dynamic array first and then allocate individual\n\t * commands.\n\t */\n\tinstance->cmd_list = kcalloc(max_cmd, sizeof(struct megasas_cmd*), GFP_KERNEL);\n\n\tif (!instance->cmd_list) {\n\t\tdev_printk(KERN_DEBUG, &instance->pdev->dev, \"out of memory\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tmemset(instance->cmd_list, 0, sizeof(struct megasas_cmd *) *max_cmd);\n\n\tfor (i = 0; i < max_cmd; i++) {\n\t\tinstance->cmd_list[i] = kmalloc(sizeof(struct megasas_cmd),\n\t\t\t\t\t\tGFP_KERNEL);\n\n\t\tif (!instance->cmd_list[i]) {\n\n\t\t\tfor (j = 0; j < i; j++)\n\t\t\t\tkfree(instance->cmd_list[j]);\n\n\t\t\tkfree(instance->cmd_list);\n\t\t\tinstance->cmd_list = NULL;\n\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\n\tfor (i = 0; i < max_cmd; i++) {\n\t\tcmd = instance->cmd_list[i];\n\t\tmemset(cmd, 0, sizeof(struct megasas_cmd));\n\t\tcmd->index = i;\n\t\tcmd->scmd = NULL;\n\t\tcmd->instance = instance;\n\n\t\tlist_add_tail(&cmd->list, &instance->cmd_pool);\n\t}\n\n\t/*\n\t * Create a frame pool and assign one frame to each cmd\n\t */\n\tif (megasas_create_frame_pool(instance)) {\n\t\tdev_printk(KERN_DEBUG, &instance->pdev->dev, \"Error creating frame DMA pool\\n\");\n\t\tmegasas_free_cmds(instance);\n\t\treturn -ENOMEM;\n\t}\n\n\treturn 0;\n}", "commit_link": "github.com/torvalds/linux/commit/bcf3b67d16a4c8ffae0aa79de5853435e683945c", "file_name": "drivers/scsi/megaraid/megaraid_sas_base.c", "vul_type": "cwe-476", "description": "Write a C function named `megasas_alloc_cmds` that allocates command structures for a `megasas_instance` and initializes a frame pool."}
{"func_name": "get_queryset", "func_src_before": "    def get_queryset(self, **kwargs):\n        queryset = Article.objects.order_by('-time')\n        for i in queryset:\n            i.md = markdown(i.content, extensions=[\n                'markdown.extensions.extra',\n                'markdown.extensions.codehilite',\n                'markdown.extensions.toc',\n            ])\n\n        return queryset", "func_src_after": "    def get_queryset(self, **kwargs):\n        queryset = Article.objects.order_by('-time')\n        for i in queryset:\n            i.md = safe_md(i.content)\n\n        return queryset", "commit_link": "github.com/Cheng-mq1216/production-practice/commit/333dc34f5feada55d1f6ff1255949ca00dec0f9c", "file_name": "app/Index/views.py", "vul_type": "cwe-079", "description": "Write a Python function named `get_queryset` that orders articles by time and converts their content to markdown format."}
{"func_name": "gps_tracker", "func_src_before": "void gps_tracker( void )\n{\n\tssize_t unused;\n    int gpsd_sock;\n    char line[256], *temp;\n    struct sockaddr_in gpsd_addr;\n    int ret, is_json, pos;\n    fd_set read_fd;\n    struct timeval timeout;\n\n    /* attempt to connect to localhost, port 2947 */\n\n    pos = 0;\n    gpsd_sock = socket( AF_INET, SOCK_STREAM, 0 );\n\n    if( gpsd_sock < 0 ) {\n        return;\n    }\n\n    gpsd_addr.sin_family      = AF_INET;\n    gpsd_addr.sin_port        = htons( 2947 );\n    gpsd_addr.sin_addr.s_addr = inet_addr( \"127.0.0.1\" );\n\n    if( connect( gpsd_sock, (struct sockaddr *) &gpsd_addr,\n                 sizeof( gpsd_addr ) ) < 0 ) {\n        return;\n    }\n\n    // Check if it's GPSd < 2.92 or the new one\n    // 2.92+ immediately send stuff\n    // < 2.92 requires to send PVTAD command\n    FD_ZERO(&read_fd);\n    FD_SET(gpsd_sock, &read_fd);\n    timeout.tv_sec = 1;\n    timeout.tv_usec = 0;\n    is_json = select(gpsd_sock + 1, &read_fd, NULL, NULL, &timeout);\n    if (is_json) {\n    \t/*\n\t\t\t{\"class\":\"VERSION\",\"release\":\"2.95\",\"rev\":\"2010-11-16T21:12:35\",\"proto_major\":3,\"proto_minor\":3}\n\t\t\t?WATCH={\"json\":true};\n\t\t\t{\"class\":\"DEVICES\",\"devices\":[]}\n    \t */\n\n\n    \t// Get the crap and ignore it: {\"class\":\"VERSION\",\"release\":\"2.95\",\"rev\":\"2010-11-16T21:12:35\",\"proto_major\":3,\"proto_minor\":3}\n    \tif( recv( gpsd_sock, line, sizeof( line ) - 1, 0 ) <= 0 )\n    \t\treturn;\n\n    \tis_json = (line[0] == '{');\n    \tif (is_json) {\n\t\t\t// Send ?WATCH={\"json\":true};\n\t\t\tmemset( line, 0, sizeof( line ) );\n\t\t\tstrcpy(line, \"?WATCH={\\\"json\\\":true};\\n\");\n\t\t\tif( send( gpsd_sock, line, 22, 0 ) != 22 )\n\t\t\t\treturn;\n\n\t\t\t// Check that we have devices\n\t\t\tmemset(line, 0, sizeof(line));\n\t\t\tif( recv( gpsd_sock, line, sizeof( line ) - 1, 0 ) <= 0 )\n\t\t\t\treturn;\n\n\t\t\t// Stop processing if there is no device\n\t\t\tif (strncmp(line, \"{\\\"class\\\":\\\"DEVICES\\\",\\\"devices\\\":[]}\", 32) == 0) {\n\t\t\t\tclose(gpsd_sock);\n\t\t\t\treturn;\n\t\t\t} else {\n\t\t\t\tpos = strlen(line);\n\t\t\t}\n    \t}\n    }\n\n    /* loop reading the GPS coordinates */\n\n    while( G.do_exit == 0 )\n    {\n        usleep( 500000 );\n        memset( G.gps_loc, 0, sizeof( float ) * 5 );\n\n        /* read position, speed, heading, altitude */\n        if (is_json) {\n        \t// Format definition: http://catb.org/gpsd/gpsd_json.html\n\n        \tif (pos == sizeof( line )) {\n        \t\tmemset(line, 0, sizeof(line));\n        \t\tpos = 0;\n        \t}\n\n        \t// New version, JSON\n        \tif( recv( gpsd_sock, line + pos, sizeof( line ) - 1, 0 ) <= 0 )\n        \t\treturn;\n\n        \t// search for TPV class: {\"class\":\"TPV\"\n        \ttemp = strstr(line, \"{\\\"class\\\":\\\"TPV\\\"\");\n        \tif (temp == NULL) {\n        \t\tcontinue;\n        \t}\n\n        \t// Make sure the data we have is complete\n        \tif (strchr(temp, '}') == NULL) {\n        \t\t// Move the data at the beginning of the buffer;\n        \t\tpos = strlen(temp);\n        \t\tif (temp != line) {\n        \t\t\tmemmove(line, temp, pos);\n        \t\t\tmemset(line + pos, 0, sizeof(line) - pos);\n        \t\t}\n        \t}\n\n\t\t\t// Example line: {\"class\":\"TPV\",\"tag\":\"MID2\",\"device\":\"/dev/ttyUSB0\",\"time\":1350957517.000,\"ept\":0.005,\"lat\":46.878936576,\"lon\":-115.832602964,\"alt\":1968.382,\"track\":0.0000,\"speed\":0.000,\"climb\":0.000,\"mode\":3}\n\n        \t// Latitude\n        \ttemp = strstr(temp, \"\\\"lat\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[0]);\n\n\t\t\t// Longitude\n\t\t\ttemp = strstr(temp, \"\\\"lon\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[1]);\n\n\t\t\t// Altitude\n\t\t\ttemp = strstr(temp, \"\\\"alt\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[4]);\n\n\t\t\t// Speed\n\t\t\ttemp = strstr(temp, \"\\\"speed\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[2]);\n\n\t\t\t// No more heading\n\n\t\t\t// Get the next TPV class\n\t\t\ttemp = strstr(temp, \"{\\\"class\\\":\\\"TPV\\\"\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tmemset( line, 0, sizeof( line ) );\n\t\t\t\tpos = 0;\n\t\t\t} else {\n\t\t\t\tpos = strlen(temp);\n\t\t\t\tmemmove(line, temp, pos);\n\t\t\t\tmemset(line + pos, 0, sizeof(line) - pos);\n\t\t\t}\n\n        } else {\n        \tmemset( line, 0, sizeof( line ) );\n\n\t\t\tsnprintf( line,  sizeof( line ) - 1, \"PVTAD\\r\\n\" );\n\t\t\tif( send( gpsd_sock, line, 7, 0 ) != 7 )\n\t\t\t\treturn;\n\n\t\t\tmemset( line, 0, sizeof( line ) );\n\t\t\tif( recv( gpsd_sock, line, sizeof( line ) - 1, 0 ) <= 0 )\n\t\t\t\treturn;\n\n\t\t\tif( memcmp( line, \"GPSD,P=\", 7 ) != 0 )\n\t\t\t\tcontinue;\n\n\t\t\t/* make sure the coordinates are present */\n\n\t\t\tif( line[7] == '?' )\n\t\t\t\tcontinue;\n\n\t\t\tret = sscanf( line + 7, \"%f %f\", &G.gps_loc[0], &G.gps_loc[1] );\n\n\t\t\tif( ( temp = strstr( line, \"V=\" ) ) == NULL ) continue;\n\t\t\tret = sscanf( temp + 2, \"%f\", &G.gps_loc[2] ); /* speed */\n\n\t\t\tif( ( temp = strstr( line, \"T=\" ) ) == NULL ) continue;\n\t\t\tret = sscanf( temp + 2, \"%f\", &G.gps_loc[3] ); /* heading */\n\n\t\t\tif( ( temp = strstr( line, \"A=\" ) ) == NULL ) continue;\n\t\t\tret = sscanf( temp + 2, \"%f\", &G.gps_loc[4] ); /* altitude */\n        }\n\n        if (G.record_data)\n\t\t\tfputs( line, G.f_gps );\n\n\t\tG.save_gps = 1;\n\n        if (G.do_exit == 0)\n\t\t{\n\t\t\tunused = write( G.gc_pipe[1], G.gps_loc, sizeof( float ) * 5 );\n\t\t\tkill( getppid(), SIGUSR2 );\n\t\t}\n    }\n}", "func_src_after": "void gps_tracker( void )\n{\n\tssize_t unused;\n    int gpsd_sock;\n    char line[256], *temp;\n    struct sockaddr_in gpsd_addr;\n    int ret, is_json, pos;\n    fd_set read_fd;\n    struct timeval timeout;\n\n    /* attempt to connect to localhost, port 2947 */\n\n    pos = 0;\n    gpsd_sock = socket( AF_INET, SOCK_STREAM, 0 );\n\n    if( gpsd_sock < 0 ) {\n        return;\n    }\n\n    gpsd_addr.sin_family      = AF_INET;\n    gpsd_addr.sin_port        = htons( 2947 );\n    gpsd_addr.sin_addr.s_addr = inet_addr( \"127.0.0.1\" );\n\n    if( connect( gpsd_sock, (struct sockaddr *) &gpsd_addr,\n                 sizeof( gpsd_addr ) ) < 0 ) {\n        return;\n    }\n\n    // Check if it's GPSd < 2.92 or the new one\n    // 2.92+ immediately send stuff\n    // < 2.92 requires to send PVTAD command\n    FD_ZERO(&read_fd);\n    FD_SET(gpsd_sock, &read_fd);\n    timeout.tv_sec = 1;\n    timeout.tv_usec = 0;\n    is_json = select(gpsd_sock + 1, &read_fd, NULL, NULL, &timeout);\n    if (is_json) {\n    \t/*\n\t\t\t{\"class\":\"VERSION\",\"release\":\"2.95\",\"rev\":\"2010-11-16T21:12:35\",\"proto_major\":3,\"proto_minor\":3}\n\t\t\t?WATCH={\"json\":true};\n\t\t\t{\"class\":\"DEVICES\",\"devices\":[]}\n    \t */\n\n\n    \t// Get the crap and ignore it: {\"class\":\"VERSION\",\"release\":\"2.95\",\"rev\":\"2010-11-16T21:12:35\",\"proto_major\":3,\"proto_minor\":3}\n    \tif( recv( gpsd_sock, line, sizeof( line ) - 1, 0 ) <= 0 )\n    \t\treturn;\n\n    \tis_json = (line[0] == '{');\n    \tif (is_json) {\n\t\t\t// Send ?WATCH={\"json\":true};\n\t\t\tmemset( line, 0, sizeof( line ) );\n\t\t\tstrcpy(line, \"?WATCH={\\\"json\\\":true};\\n\");\n\t\t\tif( send( gpsd_sock, line, 22, 0 ) != 22 )\n\t\t\t\treturn;\n\n\t\t\t// Check that we have devices\n\t\t\tmemset(line, 0, sizeof(line));\n\t\t\tif( recv( gpsd_sock, line, sizeof( line ) - 1, 0 ) <= 0 )\n\t\t\t\treturn;\n\n\t\t\t// Stop processing if there is no device\n\t\t\tif (strncmp(line, \"{\\\"class\\\":\\\"DEVICES\\\",\\\"devices\\\":[]}\", 32) == 0) {\n\t\t\t\tclose(gpsd_sock);\n\t\t\t\treturn;\n\t\t\t} else {\n\t\t\t\tpos = strlen(line);\n\t\t\t}\n    \t}\n    }\n\n    /* loop reading the GPS coordinates */\n\n    while( G.do_exit == 0 )\n    {\n        usleep( 500000 );\n        memset( G.gps_loc, 0, sizeof( float ) * 5 );\n\n        /* read position, speed, heading, altitude */\n        if (is_json) {\n        \t// Format definition: http://catb.org/gpsd/gpsd_json.html\n\n        \tif (pos == sizeof( line )) {\n        \t\tmemset(line, 0, sizeof(line));\n        \t\tpos = 0;\n        \t}\n\n        \t// New version, JSON\n        \tif( recv( gpsd_sock, line + pos, sizeof( line ) - pos - 1, 0 ) <= 0 )\n        \t\treturn;\n\n        \t// search for TPV class: {\"class\":\"TPV\"\n        \ttemp = strstr(line, \"{\\\"class\\\":\\\"TPV\\\"\");\n        \tif (temp == NULL) {\n        \t\tcontinue;\n        \t}\n\n        \t// Make sure the data we have is complete\n        \tif (strchr(temp, '}') == NULL) {\n        \t\t// Move the data at the beginning of the buffer;\n        \t\tpos = strlen(temp);\n        \t\tif (temp != line) {\n        \t\t\tmemmove(line, temp, pos);\n        \t\t\tmemset(line + pos, 0, sizeof(line) - pos);\n        \t\t}\n        \t}\n\n\t\t\t// Example line: {\"class\":\"TPV\",\"tag\":\"MID2\",\"device\":\"/dev/ttyUSB0\",\"time\":1350957517.000,\"ept\":0.005,\"lat\":46.878936576,\"lon\":-115.832602964,\"alt\":1968.382,\"track\":0.0000,\"speed\":0.000,\"climb\":0.000,\"mode\":3}\n\n        \t// Latitude\n        \ttemp = strstr(temp, \"\\\"lat\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[0]);\n\n\t\t\t// Longitude\n\t\t\ttemp = strstr(temp, \"\\\"lon\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[1]);\n\n\t\t\t// Altitude\n\t\t\ttemp = strstr(temp, \"\\\"alt\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[4]);\n\n\t\t\t// Speed\n\t\t\ttemp = strstr(temp, \"\\\"speed\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[2]);\n\n\t\t\t// No more heading\n\n\t\t\t// Get the next TPV class\n\t\t\ttemp = strstr(temp, \"{\\\"class\\\":\\\"TPV\\\"\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tmemset( line, 0, sizeof( line ) );\n\t\t\t\tpos = 0;\n\t\t\t} else {\n\t\t\t\tpos = strlen(temp);\n\t\t\t\tmemmove(line, temp, pos);\n\t\t\t\tmemset(line + pos, 0, sizeof(line) - pos);\n\t\t\t}\n\n        } else {\n        \tmemset( line, 0, sizeof( line ) );\n\n\t\t\tsnprintf( line,  sizeof( line ) - 1, \"PVTAD\\r\\n\" );\n\t\t\tif( send( gpsd_sock, line, 7, 0 ) != 7 )\n\t\t\t\treturn;\n\n\t\t\tmemset( line, 0, sizeof( line ) );\n\t\t\tif( recv( gpsd_sock, line, sizeof( line ) - 1, 0 ) <= 0 )\n\t\t\t\treturn;\n\n\t\t\tif( memcmp( line, \"GPSD,P=\", 7 ) != 0 )\n\t\t\t\tcontinue;\n\n\t\t\t/* make sure the coordinates are present */\n\n\t\t\tif( line[7] == '?' )\n\t\t\t\tcontinue;\n\n\t\t\tret = sscanf( line + 7, \"%f %f\", &G.gps_loc[0], &G.gps_loc[1] );\n\n\t\t\tif( ( temp = strstr( line, \"V=\" ) ) == NULL ) continue;\n\t\t\tret = sscanf( temp + 2, \"%f\", &G.gps_loc[2] ); /* speed */\n\n\t\t\tif( ( temp = strstr( line, \"T=\" ) ) == NULL ) continue;\n\t\t\tret = sscanf( temp + 2, \"%f\", &G.gps_loc[3] ); /* heading */\n\n\t\t\tif( ( temp = strstr( line, \"A=\" ) ) == NULL ) continue;\n\t\t\tret = sscanf( temp + 2, \"%f\", &G.gps_loc[4] ); /* altitude */\n        }\n\n        if (G.record_data)\n\t\t\tfputs( line, G.f_gps );\n\n\t\tG.save_gps = 1;\n\n        if (G.do_exit == 0)\n\t\t{\n\t\t\tunused = write( G.gc_pipe[1], G.gps_loc, sizeof( float ) * 5 );\n\t\t\tkill( getppid(), SIGUSR2 );\n\t\t}\n    }\n}", "commit_link": "github.com/aircrack-ng/aircrack-ng/commit/ff70494dd389ba570dbdbf36f217c28d4381c6b5/", "file_name": "src/airodump-ng.c", "vul_type": "cwe-787", "description": "Write a C function named `gps_tracker` that connects to a GPS daemon on localhost and reads GPS coordinates in a loop."}
{"func_name": "archive_read_format_rar_read_data", "func_src_before": "archive_read_format_rar_read_data(struct archive_read *a, const void **buff,\n                                  size_t *size, int64_t *offset)\n{\n  struct rar *rar = (struct rar *)(a->format->data);\n  int ret;\n\n  if (rar->has_encrypted_entries == ARCHIVE_READ_FORMAT_ENCRYPTION_DONT_KNOW) {\n\t  rar->has_encrypted_entries = 0;\n  }\n\n  if (rar->bytes_unconsumed > 0) {\n      /* Consume as much as the decompressor actually used. */\n      __archive_read_consume(a, rar->bytes_unconsumed);\n      rar->bytes_unconsumed = 0;\n  }\n\n  *buff = NULL;\n  if (rar->entry_eof || rar->offset_seek >= rar->unp_size) {\n    *size = 0;\n    *offset = rar->offset;\n    if (*offset < rar->unp_size)\n      *offset = rar->unp_size;\n    return (ARCHIVE_EOF);\n  }\n\n  switch (rar->compression_method)\n  {\n  case COMPRESS_METHOD_STORE:\n    ret = read_data_stored(a, buff, size, offset);\n    break;\n\n  case COMPRESS_METHOD_FASTEST:\n  case COMPRESS_METHOD_FAST:\n  case COMPRESS_METHOD_NORMAL:\n  case COMPRESS_METHOD_GOOD:\n  case COMPRESS_METHOD_BEST:\n    ret = read_data_compressed(a, buff, size, offset);\n    if (ret != ARCHIVE_OK && ret != ARCHIVE_WARN)\n      __archive_ppmd7_functions.Ppmd7_Free(&rar->ppmd7_context);\n    break;\n\n  default:\n    archive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,\n                      \"Unsupported compression method for RAR file.\");\n    ret = ARCHIVE_FATAL;\n    break;\n  }\n  return (ret);\n}", "func_src_after": "archive_read_format_rar_read_data(struct archive_read *a, const void **buff,\n                                  size_t *size, int64_t *offset)\n{\n  struct rar *rar = (struct rar *)(a->format->data);\n  int ret;\n\n  if (rar->has_encrypted_entries == ARCHIVE_READ_FORMAT_ENCRYPTION_DONT_KNOW) {\n\t  rar->has_encrypted_entries = 0;\n  }\n\n  if (rar->bytes_unconsumed > 0) {\n      /* Consume as much as the decompressor actually used. */\n      __archive_read_consume(a, rar->bytes_unconsumed);\n      rar->bytes_unconsumed = 0;\n  }\n\n  *buff = NULL;\n  if (rar->entry_eof || rar->offset_seek >= rar->unp_size) {\n    *size = 0;\n    *offset = rar->offset;\n    if (*offset < rar->unp_size)\n      *offset = rar->unp_size;\n    return (ARCHIVE_EOF);\n  }\n\n  switch (rar->compression_method)\n  {\n  case COMPRESS_METHOD_STORE:\n    ret = read_data_stored(a, buff, size, offset);\n    break;\n\n  case COMPRESS_METHOD_FASTEST:\n  case COMPRESS_METHOD_FAST:\n  case COMPRESS_METHOD_NORMAL:\n  case COMPRESS_METHOD_GOOD:\n  case COMPRESS_METHOD_BEST:\n    ret = read_data_compressed(a, buff, size, offset);\n    if (ret != ARCHIVE_OK && ret != ARCHIVE_WARN) {\n      __archive_ppmd7_functions.Ppmd7_Free(&rar->ppmd7_context);\n      rar->start_new_table = 1;\n    }\n    break;\n\n  default:\n    archive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,\n                      \"Unsupported compression method for RAR file.\");\n    ret = ARCHIVE_FATAL;\n    break;\n  }\n  return (ret);\n}", "commit_link": "github.com/libarchive/libarchive/commit/b8592ecba2f9e451e1f5cb7ab6dcee8b8e7b3f60", "file_name": "libarchive/archive_read_support_format_rar.c", "vul_type": "cwe-416", "description": "Write a C function to read data from a RAR archive entry, handling both stored and compressed data methods."}
{"func_name": "rtc_irq_eoi_tracking_reset", "func_src_before": "static void rtc_irq_eoi_tracking_reset(struct kvm_ioapic *ioapic)\n{\n\tioapic->rtc_status.pending_eoi = 0;\n\tbitmap_zero(ioapic->rtc_status.dest_map.map, KVM_MAX_VCPUS);\n}", "func_src_after": "static void rtc_irq_eoi_tracking_reset(struct kvm_ioapic *ioapic)\n{\n\tioapic->rtc_status.pending_eoi = 0;\n\tbitmap_zero(ioapic->rtc_status.dest_map.map, KVM_MAX_VCPU_ID);\n}", "commit_link": "github.com/torvalds/linux/commit/81cdb259fb6d8c1c4ecfeea389ff5a73c07f5755", "file_name": "arch/x86/kvm/ioapic.c", "vul_type": "cwe-125", "description": "Write a C function named `rtc_irq_eoi_tracking_reset` that resets the pending EOI status and clears the destination map bitmap in a `kvm_ioapic` structure."}
{"func_name": "dd_load_text_ext", "func_src_before": "char* dd_load_text_ext(const struct dump_dir *dd, const char *name, unsigned flags)\n{\n//    if (!dd->locked)\n//        error_msg_and_die(\"dump_dir is not opened\"); /* bug */\n\n    /* Compat with old abrt dumps. Remove in abrt-2.1 */\n    if (strcmp(name, \"release\") == 0)\n        name = FILENAME_OS_RELEASE;\n\n    char *full_path = concat_path_file(dd->dd_dirname, name);\n    char *ret = load_text_file(full_path, flags);\n    free(full_path);\n\n    return ret;\n}", "func_src_after": "char* dd_load_text_ext(const struct dump_dir *dd, const char *name, unsigned flags)\n{\n//    if (!dd->locked)\n//        error_msg_and_die(\"dump_dir is not opened\"); /* bug */\n\n    if (!str_is_correct_filename(name))\n    {\n        error_msg(\"Cannot load text. '%s' is not a valid file name\", name);\n        if (!(flags & DD_LOAD_TEXT_RETURN_NULL_ON_FAILURE))\n            xfunc_die();\n    }\n\n    /* Compat with old abrt dumps. Remove in abrt-2.1 */\n    if (strcmp(name, \"release\") == 0)\n        name = FILENAME_OS_RELEASE;\n\n    char *full_path = concat_path_file(dd->dd_dirname, name);\n    char *ret = load_text_file(full_path, flags);\n    free(full_path);\n\n    return ret;\n}", "commit_link": "github.com/abrt/libreport/commit/239c4f7d1f47265526b39ad70106767d00805277", "file_name": "src/lib/dump_dir.c", "vul_type": "cwe-022", "description": "Write a C function named `dd_load_text_ext` that loads text from a file within a directory structure, handling special cases and errors."}
{"func_name": "download_check_files", "func_src_before": "    def download_check_files(self, filelist):\n        # only admins and allowed users may download\n        if not cherrypy.session['admin']:\n            uo = self.useroptions.forUser(self.getUserId())\n            if not uo.getOptionValue('media.may_download'):\n                return 'not_permitted'\n        # make sure nobody tries to escape from basedir\n        for f in filelist:\n            if '/../' in f:\n                return 'invalid_file'\n        # make sure all files are smaller than maximum download size\n        size_limit = cherry.config['media.maximum_download_size']\n        try:\n            if self.model.file_size_within_limit(filelist, size_limit):\n                return 'ok'\n            else:\n                return 'too_big'\n        except OSError as e:        # use OSError for python2 compatibility\n            return str(e)", "func_src_after": "    def download_check_files(self, filelist):\n        # only admins and allowed users may download\n        if not cherrypy.session['admin']:\n            uo = self.useroptions.forUser(self.getUserId())\n            if not uo.getOptionValue('media.may_download'):\n                return 'not_permitted'\n        # make sure nobody tries to escape from basedir\n        for f in filelist:\n            # don't allow to traverse up in the file system\n            if '/../' in f or f.startswith('../'):\n                return 'invalid_file'\n            # CVE-2015-8309: do not allow absolute file paths\n            if os.path.isabs(f):\n                return 'invalid_file'\n        # make sure all files are smaller than maximum download size\n        size_limit = cherry.config['media.maximum_download_size']\n        try:\n            if self.model.file_size_within_limit(filelist, size_limit):\n                return 'ok'\n            else:\n                return 'too_big'\n        except OSError as e:        # use OSError for python2 compatibility\n            return str(e)", "commit_link": "github.com/devsnd/cherrymusic/commit/62dec34a1ea0741400dd6b6c660d303dcd651e86", "file_name": "cherrymusicserver/httphandler.py", "vul_type": "cwe-022", "description": "Write a Python function named `download_check_files` that validates a list of file paths for download permissions, path security, and size constraints."}
{"func_name": "next_state_class", "func_src_before": "next_state_class(CClassNode* cc, OnigCodePoint* vs, enum CCVALTYPE* type,\n\t\t enum CCSTATE* state, ScanEnv* env)\n{\n  int r;\n\n  if (*state == CCS_RANGE)\n    return ONIGERR_CHAR_CLASS_VALUE_AT_END_OF_RANGE;\n\n  if (*state == CCS_VALUE && *type != CCV_CLASS) {\n    if (*type == CCV_SB)\n      BITSET_SET_BIT(cc->bs, (int )(*vs));\n    else if (*type == CCV_CODE_POINT) {\n      r = add_code_range(&(cc->mbuf), env, *vs, *vs);\n      if (r < 0) return r;\n    }\n  }\n\n  *state = CCS_VALUE;\n  *type  = CCV_CLASS;\n  return 0;\n}", "func_src_after": "next_state_class(CClassNode* cc, OnigCodePoint* vs, enum CCVALTYPE* type,\n\t\t enum CCSTATE* state, ScanEnv* env)\n{\n  int r;\n\n  if (*state == CCS_RANGE)\n    return ONIGERR_CHAR_CLASS_VALUE_AT_END_OF_RANGE;\n\n  if (*state == CCS_VALUE && *type != CCV_CLASS) {\n    if (*type == CCV_SB)\n      BITSET_SET_BIT(cc->bs, (int )(*vs));\n    else if (*type == CCV_CODE_POINT) {\n      r = add_code_range(&(cc->mbuf), env, *vs, *vs);\n      if (r < 0) return r;\n    }\n  }\n\n  if (*state != CCS_START)\n    *state = CCS_VALUE;\n\n  *type  = CCV_CLASS;\n  return 0;\n}", "commit_link": "github.com/kkos/oniguruma/commit/3b63d12038c8d8fc278e81c942fa9bec7c704c8b", "file_name": "src/regparse.c", "vul_type": "cwe-787", "description": "Write a C function named `next_state_class` that updates character class states and values for a regex engine."}
{"func_name": "__getattr__.adb_call", "func_src_before": "        def adb_call(*args):\n            clean_name = name.replace('_', '-')\n            arg_str = ' '.join(str(elem) for elem in args)\n            return self._exec_adb_cmd(clean_name, arg_str)", "func_src_after": "        def adb_call(args=None, shell=False):\n            \"\"\"Wrapper for an ADB command.\n\n            Args:\n                args: string or list of strings, arguments to the adb command.\n                    See subprocess.Proc() documentation.\n                shell: bool, True to run this command through the system shell,\n                    False to invoke it directly. See subprocess.Proc() docs.\n\n            Returns:\n                The output of the adb command run if exit code is 0.\n            \"\"\"\n            args = args or ''\n            clean_name = name.replace('_', '-')\n            return self._exec_adb_cmd(clean_name, args, shell=shell)", "commit_link": "github.com/google/mobly/commit/3862e8ba359040fbdd6e1a6d36e51d07cda8e1ee", "file_name": "mobly/controllers/android_device_lib/adb.py", "vul_type": "cwe-078", "description": "Create a Python function named `adb_call` that serves as a wrapper for executing ADB (Android Debug Bridge) commands with optional arguments and shell execution flag."}
{"func_name": "igraph_read_graph_graphml", "func_src_before": "int igraph_read_graph_graphml(igraph_t *graph, FILE *instream, int index) {\n\n#if HAVE_LIBXML == 1\n    xmlParserCtxtPtr ctxt;\n    xmlDocPtr doc;\n\n    struct igraph_i_graphml_parser_state state;\n    int res;\n    char buffer[4096];\n    igraph_bool_t parsing_successful;\n    char* error_message;\n\n    if (index < 0) {\n        IGRAPH_ERROR(\"Graph index must be non-negative\", IGRAPH_EINVAL);\n    }\n\n    xmlInitParser();\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_init(&state, graph, index));\n    IGRAPH_FINALLY(igraph_i_graphml_parser_state_destroy, &state);\n\n    /* Create a progressive parser context */\n    res = (int) fread(buffer, 1, sizeof(buffer), instream);\n    if (res < sizeof(buffer) && !feof(instream)) {\n        IGRAPH_ERROR(\"IO error while reading GraphML data\", IGRAPH_PARSEERROR);\n    }\n    ctxt = xmlCreatePushParserCtxt(&igraph_i_graphml_sax_handler,\n                                   &state,\n                                   buffer,\n                                   res,\n                                   NULL);\n    /*   ctxt=xmlCreateIOParserCtxt(&igraph_i_graphml_sax_handler, &state, */\n    /*               igraph_i_libxml2_read_callback, */\n    /*               igraph_i_libxml2_close_callback, */\n    /*               instream, XML_CHAR_ENCODING_NONE); */\n    if (ctxt == NULL) {\n        IGRAPH_ERROR(\"Can't create progressive parser context\", IGRAPH_PARSEERROR);\n    }\n\n    /* Set parsing options */\n    if (xmlCtxtUseOptions(ctxt,\n                          XML_PARSE_NOENT | XML_PARSE_NOBLANKS |\n                          XML_PARSE_NONET | XML_PARSE_NSCLEAN |\n                          XML_PARSE_NOCDATA | XML_PARSE_HUGE\n                         )) {\n        xmlFreeParserCtxt(ctxt);\n        IGRAPH_ERROR(\"Cannot set options for the parser context\", IGRAPH_EINVAL);\n    }\n\n    /* Okay, parsing will start now. The parser might do things that eventually\n     * trigger the igraph error handler, but we want the parser state to\n     * survive whatever happens here. So, we need to pop off\n     * igraph_i_graphml_parser_state_destroy() from the stack and temporarily\n     * assume responsibility for calling it ourselves until we are back from the\n     * parser */\n    IGRAPH_FINALLY_CLEAN(1);\n\n    /* Do the parsing */\n    while ((res = (int) fread(buffer, 1, sizeof(buffer), instream)) > 0) {\n        xmlParseChunk(ctxt, buffer, res, 0);\n        if (!state.successful) {\n            break;\n        }\n    }\n    xmlParseChunk(ctxt, buffer, res, 1);\n\n    /* Free the context */\n    doc = ctxt->myDoc;\n    xmlFreeParserCtxt(ctxt);\n    if (doc) {\n        /* In theory this should not be necessary, but it looks like certain malformed\n         * GraphML files leave a partially-parsed doc in memory */\n        xmlFreeDoc(doc);\n    }\n\n    /* Extract the error message from the parser state (if any), and make a\n     * copy so we can safely destroy the parser state before triggering the\n     * error */\n    parsing_successful = state.successful;\n    error_message = parsing_successful || state.error_message == NULL ? NULL : strdup(state.error_message);\n\n    /* Now that we have lifted error_message out of the parser state, we can\n     * put the destructor of the parser state back on the FINALLY stack */\n    IGRAPH_FINALLY(igraph_i_graphml_parser_state_destroy, &state);\n\n    /* ...and we can also put the error message pointer on the FINALLY stack */\n    if (error_message != NULL) {\n        IGRAPH_FINALLY(free, error_message);\n    }\n\n    /* Trigger the stored error if needed */\n    if (!parsing_successful) {\n        if (error_message != NULL) {\n            IGRAPH_ERROR(error_message, IGRAPH_PARSEERROR);\n        } else {\n            IGRAPH_ERROR(\"Malformed GraphML file\", IGRAPH_PARSEERROR);\n        }\n    }\n\n    /* Did we actually manage to reach the graph to be parsed, given its index?\n     * If not, that's an error as well. */\n    if (state.index >= 0) {\n        IGRAPH_ERROR(\"Graph index was too large\", IGRAPH_EINVAL);\n    }\n\n    /* Okay, everything seems good. We can now take the parser state and\n     * construct our graph from the data gathered during the parsing */\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_finish_parsing(&state));\n\n    igraph_i_graphml_parser_state_destroy(&state);\n    IGRAPH_FINALLY_CLEAN(1);\n\n    return IGRAPH_SUCCESS;\n#else\n    IGRAPH_UNUSED(graph);\n    IGRAPH_UNUSED(instream);\n    IGRAPH_UNUSED(index);\n\n    IGRAPH_ERROR(\"GraphML support is disabled\", IGRAPH_UNIMPLEMENTED);\n#endif\n}", "func_src_after": "int igraph_read_graph_graphml(igraph_t *graph, FILE *instream, int index) {\n\n#if HAVE_LIBXML == 1\n    xmlParserCtxtPtr ctxt;\n    xmlDocPtr doc;\n\n    struct igraph_i_graphml_parser_state state;\n    int res;\n    char buffer[4096];\n    igraph_bool_t parsing_successful;\n    char* error_message;\n\n    if (index < 0) {\n        IGRAPH_ERROR(\"Graph index must be non-negative\", IGRAPH_EINVAL);\n    }\n\n    xmlInitParser();\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_init(&state, graph, index));\n    IGRAPH_FINALLY(igraph_i_graphml_parser_state_destroy, &state);\n\n    /* Create a progressive parser context */\n    res = (int) fread(buffer, 1, sizeof(buffer), instream);\n    if (res < sizeof(buffer) && !feof(instream)) {\n        IGRAPH_ERROR(\"IO error while reading GraphML data\", IGRAPH_PARSEERROR);\n    }\n    ctxt = xmlCreatePushParserCtxt(&igraph_i_graphml_sax_handler,\n                                   &state,\n                                   buffer,\n                                   res,\n                                   NULL);\n    /*   ctxt=xmlCreateIOParserCtxt(&igraph_i_graphml_sax_handler, &state, */\n    /*               igraph_i_libxml2_read_callback, */\n    /*               igraph_i_libxml2_close_callback, */\n    /*               instream, XML_CHAR_ENCODING_NONE); */\n    if (ctxt == NULL) {\n        IGRAPH_ERROR(\"Can't create progressive parser context\", IGRAPH_PARSEERROR);\n    }\n\n    /* Set parsing options */\n    if (xmlCtxtUseOptions(ctxt,\n                          XML_PARSE_NOBLANKS |\n                          XML_PARSE_NONET | XML_PARSE_NSCLEAN |\n                          XML_PARSE_NOCDATA | XML_PARSE_HUGE\n                         )) {\n        xmlFreeParserCtxt(ctxt);\n        IGRAPH_ERROR(\"Cannot set options for the parser context\", IGRAPH_EINVAL);\n    }\n\n    /* Okay, parsing will start now. The parser might do things that eventually\n     * trigger the igraph error handler, but we want the parser state to\n     * survive whatever happens here. So, we need to pop off\n     * igraph_i_graphml_parser_state_destroy() from the stack and temporarily\n     * assume responsibility for calling it ourselves until we are back from the\n     * parser */\n    IGRAPH_FINALLY_CLEAN(1);\n\n    /* Do the parsing */\n    while ((res = (int) fread(buffer, 1, sizeof(buffer), instream)) > 0) {\n        xmlParseChunk(ctxt, buffer, res, 0);\n        if (!state.successful) {\n            break;\n        }\n    }\n    xmlParseChunk(ctxt, buffer, res, 1);\n\n    /* Free the context */\n    doc = ctxt->myDoc;\n    xmlFreeParserCtxt(ctxt);\n    if (doc) {\n        /* In theory this should not be necessary, but it looks like certain malformed\n         * GraphML files leave a partially-parsed doc in memory */\n        xmlFreeDoc(doc);\n    }\n\n    /* Extract the error message from the parser state (if any), and make a\n     * copy so we can safely destroy the parser state before triggering the\n     * error */\n    parsing_successful = state.successful;\n    error_message = parsing_successful || state.error_message == NULL ? NULL : strdup(state.error_message);\n\n    /* Now that we have lifted error_message out of the parser state, we can\n     * put the destructor of the parser state back on the FINALLY stack */\n    IGRAPH_FINALLY(igraph_i_graphml_parser_state_destroy, &state);\n\n    /* ...and we can also put the error message pointer on the FINALLY stack */\n    if (error_message != NULL) {\n        IGRAPH_FINALLY(free, error_message);\n    }\n\n    /* Trigger the stored error if needed */\n    if (!parsing_successful) {\n        if (error_message != NULL) {\n            IGRAPH_ERROR(error_message, IGRAPH_PARSEERROR);\n        } else {\n            IGRAPH_ERROR(\"Malformed GraphML file\", IGRAPH_PARSEERROR);\n        }\n    }\n\n    /* Did we actually manage to reach the graph to be parsed, given its index?\n     * If not, that's an error as well. */\n    if (state.index >= 0) {\n        IGRAPH_ERROR(\"Graph index was too large\", IGRAPH_EINVAL);\n    }\n\n    /* Okay, everything seems good. We can now take the parser state and\n     * construct our graph from the data gathered during the parsing */\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_finish_parsing(&state));\n\n    igraph_i_graphml_parser_state_destroy(&state);\n    IGRAPH_FINALLY_CLEAN(1);\n\n    return IGRAPH_SUCCESS;\n#else\n    IGRAPH_UNUSED(graph);\n    IGRAPH_UNUSED(instream);\n    IGRAPH_UNUSED(index);\n\n    IGRAPH_ERROR(\"GraphML support is disabled\", IGRAPH_UNIMPLEMENTED);\n#endif\n}", "line_changes": {"deleted": [{"line_no": 41, "char_start": 1463, "char_end": 1528, "line": "                          XML_PARSE_NOENT | XML_PARSE_NOBLANKS |\n"}], "added": [{"line_no": 41, "char_start": 1463, "char_end": 1510, "line": "                          XML_PARSE_NOBLANKS |\n"}]}, "char_changes": {"deleted": [{"char_start": 1488, "char_end": 1506, "chars": " XML_PARSE_NOENT |"}], "added": []}, "commit_link": "github.com/igraph/igraph/commit/6ce2353fa77a891d1b556b8908ca9e4c227c3619", "file_name": "graphml.c", "vul_type": "cwe-611", "commit_msg": "fix: disable external XML entity resolution", "parent_commit": "cb8f28bae4c5ab92e5b628d9b4f827d3c61ba6ce", "description": "Write a C function to parse a GraphML file into an igraph_t structure using libxml2."}
{"func_name": "test_create_invalid_host", "func_src_before": "    def test_create_invalid_host(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record\n        self.clear_mox()\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_cpg\",\n                       self.fake_get_cpg)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_domain\",\n                       self.fake_get_domain)\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_host_cmd = 'showhost -verbose fakehost'\n        _run_ssh(show_host_cmd, False).AndReturn([pack('no hosts listed'), ''])\n\n        create_host_cmd = ('createhost -persona 1 -domain (\\'OpenStack\\',) '\n                           'fakehost 123456789012345 123456789054321')\n        create_host_ret = pack(CLI_CR +\n                               'already used by host fakehost.foo (19)')\n        _run_ssh(create_host_cmd, False).AndReturn([create_host_ret, ''])\n\n        show_3par_cmd = 'showhost -verbose fakehost.foo'\n        _run_ssh(show_3par_cmd, False).AndReturn([pack(FC_SHOWHOST_RET), ''])\n        self.mox.ReplayAll()\n\n        host = self.driver._create_host(self.volume, self.connector)\n\n        self.assertEquals(host['name'], 'fakehost.foo')", "func_src_after": "    def test_create_invalid_host(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record\n        self.clear_mox()\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_cpg\",\n                       self.fake_get_cpg)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_domain\",\n                       self.fake_get_domain)\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_host_cmd = ['showhost', '-verbose', 'fakehost']\n        _run_ssh(show_host_cmd, False).AndReturn([pack('no hosts listed'), ''])\n\n        create_host_cmd = (['createhost', '-persona', '1', '-domain',\n                            ('OpenStack',), 'fakehost', '123456789012345',\n                            '123456789054321'])\n        create_host_ret = pack(CLI_CR +\n                               'already used by host fakehost.foo (19)')\n        _run_ssh(create_host_cmd, False).AndReturn([create_host_ret, ''])\n\n        show_3par_cmd = ['showhost', '-verbose', 'fakehost.foo']\n        _run_ssh(show_3par_cmd, False).AndReturn([pack(FC_SHOWHOST_RET), ''])\n        self.mox.ReplayAll()\n\n        host = self.driver._create_host(self.volume, self.connector)\n\n        self.assertEquals(host['name'], 'fakehost.foo')", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/tests/test_hp3par.py", "vul_type": "cwe-078", "description": "Write a Python unit test function that mocks SSH commands for creating a host in an HP 3PAR storage system and checks the host's name."}
{"func_name": "getPostsByPostid", "func_src_before": "    def getPostsByPostid(self,postid):\n        sqlText=\"select users.name,post.comment from users,post where \\\n                users.userid=post.userid and post.postid=%d\"%(postid)\n        result=sql.queryDB(self.conn,sqlText)\n        return result;", "func_src_after": "    def getPostsByPostid(self,postid):\n        sqlText=\"select users.name,post.comment from users,post where \\\n                users.userid=post.userid and post.postid=%s\"\n        params=[postid]\n        result=sql.queryDB(self.conn,sqlText,params)\n        return result;", "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/post.py", "vul_type": "cwe-089", "description": "Write a Python function that retrieves a user's name and comment from a database using a post ID."}
{"func_name": "_exec_cmd", "func_src_before": "    def _exec_cmd(self, cmd):\n        \"\"\"Executes adb commands in a new shell.\n\n        This is specific to executing adb binary because stderr is not a good\n        indicator of cmd execution status.\n\n        Args:\n            cmds: A string that is the adb command to execute.\n\n        Returns:\n            The output of the adb command run if exit code is 0.\n\n        Raises:\n            AdbError is raised if the adb command exit code is not 0.\n        \"\"\"\n        proc = subprocess.Popen(\n            cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n        (out, err) = proc.communicate()\n        ret = proc.returncode\n        logging.debug('cmd: %s, stdout: %s, stderr: %s, ret: %s', cmd, out,\n                      err, ret)\n        if ret == 0:\n            return out\n        else:\n            raise AdbError(cmd=cmd, stdout=out, stderr=err, ret_code=ret)", "func_src_after": "    def _exec_cmd(self, args, shell):\n        \"\"\"Executes adb commands.\n\n        Args:\n            args: string or list of strings, program arguments.\n                See subprocess.Popen() documentation.\n            shell: bool, True to run this command through the system shell,\n                False to invoke it directly. See subprocess.Popen() docs.\n\n        Returns:\n            The output of the adb command run if exit code is 0.\n\n        Raises:\n            AdbError is raised if the adb command exit code is not 0.\n        \"\"\"\n        proc = subprocess.Popen(\n            args, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=shell)\n        (out, err) = proc.communicate()\n        ret = proc.returncode\n        logging.debug('cmd: %s, stdout: %s, stderr: %s, ret: %s', args, out,\n                      err, ret)\n        if ret == 0:\n            return out\n        else:\n            raise AdbError(cmd=args, stdout=out, stderr=err, ret_code=ret)", "commit_link": "github.com/google/mobly/commit/3862e8ba359040fbdd6e1a6d36e51d07cda8e1ee", "file_name": "mobly/controllers/android_device_lib/adb.py", "vul_type": "cwe-078", "description": "In Python, write a function to execute adb commands and handle the output based on the command's success or failure."}
{"func_name": "set", "func_src_before": "    def set(self, key, value, replace=False):\n        path = os.path.join(self.namespace, key)\n        try:\n            self.etcd.write(path, value, prevExist=replace)\n        except etcd.EtcdAlreadyExist as err:\n            raise CSStoreExists(str(err))\n        except etcd.EtcdException as err:\n            log_error(\"Error storing key %s: [%r]\" % (key, repr(err)))\n            raise CSStoreError('Error occurred while trying to store key')", "func_src_after": "    def set(self, key, value, replace=False):\n        path = self._absolute_key(key)\n        try:\n            self.etcd.write(path, value, prevExist=replace)\n        except etcd.EtcdAlreadyExist as err:\n            raise CSStoreExists(str(err))\n        except etcd.EtcdException as err:\n            log_error(\"Error storing key %s: [%r]\" % (key, repr(err)))\n            raise CSStoreError('Error occurred while trying to store key')", "commit_link": "github.com/latchset/custodia/commit/785fc87f38b4811bc4ce43a0a9b2267ee7d500b4", "file_name": "custodia/store/etcdstore.py", "vul_type": "cwe-022", "description": "Write a Python function named `set` that stores a key-value pair in etcd, with an option to replace the existing key, and handles specific etcd exceptions."}
{"func_name": "_update_volume_stats", "func_src_before": "    def _update_volume_stats(self):\n        \"\"\"Retrieve stats info from volume group.\"\"\"\n\n        LOG.debug(_(\"Updating volume stats\"))\n        data = {}\n\n        data['vendor_name'] = 'IBM'\n        data['driver_version'] = '1.1'\n        data['storage_protocol'] = list(self._enabled_protocols)\n\n        data['total_capacity_gb'] = 0  # To be overwritten\n        data['free_capacity_gb'] = 0   # To be overwritten\n        data['reserved_percentage'] = 0\n        data['QoS_support'] = False\n\n        pool = self.configuration.storwize_svc_volpool_name\n        #Get storage system name\n        ssh_cmd = 'svcinfo lssystem -delim !'\n        attributes = self._execute_command_and_parse_attributes(ssh_cmd)\n        if not attributes or not attributes['name']:\n            exception_message = (_('_update_volume_stats: '\n                                   'Could not get system name'))\n            raise exception.VolumeBackendAPIException(data=exception_message)\n\n        backend_name = self.configuration.safe_get('volume_backend_name')\n        if not backend_name:\n            backend_name = '%s_%s' % (attributes['name'], pool)\n        data['volume_backend_name'] = backend_name\n\n        ssh_cmd = 'svcinfo lsmdiskgrp -bytes -delim ! %s' % pool\n        attributes = self._execute_command_and_parse_attributes(ssh_cmd)\n        if not attributes:\n            LOG.error(_('Could not get pool data from the storage'))\n            exception_message = (_('_update_volume_stats: '\n                                   'Could not get storage pool data'))\n            raise exception.VolumeBackendAPIException(data=exception_message)\n\n        data['total_capacity_gb'] = (float(attributes['capacity']) /\n                                    (1024 ** 3))\n        data['free_capacity_gb'] = (float(attributes['free_capacity']) /\n                                    (1024 ** 3))\n        data['easytier_support'] = attributes['easy_tier'] in ['on', 'auto']\n        data['compression_support'] = self._compression_enabled\n\n        self._stats = data", "func_src_after": "    def _update_volume_stats(self):\n        \"\"\"Retrieve stats info from volume group.\"\"\"\n\n        LOG.debug(_(\"Updating volume stats\"))\n        data = {}\n\n        data['vendor_name'] = 'IBM'\n        data['driver_version'] = '1.1'\n        data['storage_protocol'] = list(self._enabled_protocols)\n\n        data['total_capacity_gb'] = 0  # To be overwritten\n        data['free_capacity_gb'] = 0   # To be overwritten\n        data['reserved_percentage'] = 0\n        data['QoS_support'] = False\n\n        pool = self.configuration.storwize_svc_volpool_name\n        #Get storage system name\n        ssh_cmd = ['svcinfo', 'lssystem', '-delim', '!']\n        attributes = self._execute_command_and_parse_attributes(ssh_cmd)\n        if not attributes or not attributes['name']:\n            exception_message = (_('_update_volume_stats: '\n                                   'Could not get system name'))\n            raise exception.VolumeBackendAPIException(data=exception_message)\n\n        backend_name = self.configuration.safe_get('volume_backend_name')\n        if not backend_name:\n            backend_name = '%s_%s' % (attributes['name'], pool)\n        data['volume_backend_name'] = backend_name\n\n        ssh_cmd = ['svcinfo', 'lsmdiskgrp', '-bytes', '-delim', '!', pool]\n        attributes = self._execute_command_and_parse_attributes(ssh_cmd)\n        if not attributes:\n            LOG.error(_('Could not get pool data from the storage'))\n            exception_message = (_('_update_volume_stats: '\n                                   'Could not get storage pool data'))\n            raise exception.VolumeBackendAPIException(data=exception_message)\n\n        data['total_capacity_gb'] = (float(attributes['capacity']) /\n                                    (1024 ** 3))\n        data['free_capacity_gb'] = (float(attributes['free_capacity']) /\n                                    (1024 ** 3))\n        data['easytier_support'] = attributes['easy_tier'] in ['on', 'auto']\n        data['compression_support'] = self._compression_enabled\n\n        self._stats = data", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to update storage volume statistics with IBM vendor details and capacity information."}
{"func_name": "load", "func_src_before": "    @classmethod\n    def load(cls, data_store, filename):\n        pgm_model = None\n        if type(data_store) is LocalFileSystem:\n            pgm_model = data_store.read_pomegranate_model(filename=filename)\n        if type(data_store) is S3DataStore:\n            local_filename = \"/tmp/kronos.json\"\n            data_store.download_file(filename, local_filename)\n            with open(local_filename, 'rb') as f:\n                pgm_model = BayesianNetwork.from_json(pickle.load(f))\n        return PGMPomegranate(pgm_model)", "func_src_after": "    @classmethod\n    def load(cls, data_store, filename):\n        pgm_model = None\n        if type(data_store) is LocalFileSystem:\n            pgm_model = data_store.read_pomegranate_model(filename=filename)\n        if type(data_store) is S3DataStore:\n            local_filename = \"/tmp/kronos.json\"\n            data_store.download_file(filename, local_filename)\n            with open(local_filename, 'rb') as f:\n                pgm_model = BayesianNetwork.from_json(f.read())\n        return PGMPomegranate(pgm_model)", "line_changes": {"deleted": [{"line_no": 10, "char_start": 413, "char_end": 483, "line": "                pgm_model = BayesianNetwork.from_json(pickle.load(f))\n"}], "added": [{"line_no": 10, "char_start": 413, "char_end": 477, "line": "                pgm_model = BayesianNetwork.from_json(f.read())\n"}]}, "char_changes": {"deleted": [{"char_start": 467, "char_end": 476, "chars": "pickle.lo"}, {"char_start": 479, "char_end": 480, "chars": "f"}], "added": [{"char_start": 467, "char_end": 471, "chars": "f.re"}]}, "commit_link": "github.com/sara-02/fabric8-analytics-stack-analysis/commit/c9422e6257a8c927aed2999a0f4cc77f90059cda", "file_name": "pgm_pomegranate.py", "vul_type": "cwe-502", "commit_msg": "Remove pickling of model\n\nThe model is already being converted to a JSON(using the `to_json`)\nfunction of pomegranate which is already a stadard serialized format.\nI don't see a need to further serialize the JSON using pickle to\nsomething that can be loaded only using Python. This also helps us\nreduce the training time of the model as pickling and unpickling\nhas a overhead that I don't see a need for, because JSON.", "parent_commit": "c2ddf128d7206a0a85929b6f2a08078433ce1577", "description": "Create a Python method that loads a probabilistic graphical model from a local or S3 data store based on the provided filename."}
{"func_name": "update_history_and_sourcebyinstitution", "func_src_before": "def update_history_and_sourcebyinstitution(conn, sqlite, k10plus, ai):\n    \"\"\"\n    Get all current sources and title numbers from Solr and log them into database.\n    \"\"\"\n    current_sources = get_all_current_sources(k10plus, ai)\n    current_institutions = get_all_current_institutions(k10plus, ai)\n    old_sourcebyinstitutions = get_all_old_sourcebyinstitutions(conn, sqlite)\n    current_sourcebyinstitutions = []\n\n    for source in current_sources:\n\n        for institution in current_institutions:\n\n            if not institution or institution == \" \" or '\"' in institution:\n                continue\n\n            sourcebyinstitution = \"SID \" + str(source) + \" (\" + institution + \")\"\n            current_sourcebyinstitutions.append(sourcebyinstitution)\n\n            params = {\n                \"q\": 'source_id:%s AND institution:\"%s\"' % (source, institution),\n                \"rows\": 0,\n                \"wt\": \"json\"\n            }\n\n            # check k10plus\n            result = get_solr_result(k10plus, params)\n            number = result[\"response\"][\"numFound\"]\n            if number != 0:\n                sql = 'INSERT INTO history (sourcebyinstitution, titles) VALUES (\"%s\", %s)' % (sourcebyinstitution, number)\n                sqlite.execute(sql)\n                conn.commit()\n            else:\n                # check ai\n                result = get_solr_result(ai, params)\n                number = result[\"response\"][\"numFound\"]\n                if number != 0:\n                    # TODO: escape via sqlite\n                    sql = 'INSERT INTO history (sourcebyinstitution, titles) VALUES (\"%s\", %s)' % (sourcebyinstitution, number)\n                    sqlite.execute(sql)\n                    conn.commit()\n\n            if sourcebyinstitution not in old_sourcebyinstitutions:\n                logging.info(\"The %s is now connected to SID %s.\", institution, source)\n                sql = \"INSERT INTO sourcebyinstitution (sourcebyinstitution) VALUES ('%s')\" % sourcebyinstitution\n                sqlite.execute(sql)\n                conn.commit()\n\n            if number != 0:\n                old_sourcebyinstitution_number = get_old_sourcebyinstitution_number(conn, sqlite, sourcebyinstitution)\n                if number < old_sourcebyinstitution_number:\n                    message = \"Die Anzahl der Titel hat sich bei %s gegenueber einem frueheren Import verringert.\" % (sourcebyinstitution)\n                    send_message(message)\n\n            # requests.exceptions.ConnectionError: HTTPConnectionPool(XXXXXX): Max retries exceeded\n            time.sleep(0.25)\n\n    for old_sourcebyinstitution in old_sourcebyinstitutions:\n        if old_sourcebyinstitution not in current_sourcebyinstitutions:\n            message = \"Die %s ist nicht laenger f\u00fcr die SID %s angesigelt.\" % (institution, source)\n            send_message(message)", "func_src_after": "def update_history_and_sourcebyinstitution(conn, sqlite, k10plus, ai):\n    \"\"\"\n    Get all current sources and title numbers from Solr and log them into database.\n    \"\"\"\n    current_sources = get_all_current_sources(k10plus, ai)\n    current_institutions = get_all_current_institutions(k10plus, ai)\n    old_sourcebyinstitutions = get_all_old_sourcebyinstitutions(conn, sqlite)\n    current_sourcebyinstitutions = []\n\n    for source in current_sources:\n\n        for institution in current_institutions:\n\n            if not institution or institution == \" \" or '\"' in institution:\n                continue\n\n            sourcebyinstitution = \"SID \" + str(source) + \" (\" + institution + \")\"\n            current_sourcebyinstitutions.append(sourcebyinstitution)\n\n            params = {\n                \"q\": 'source_id:%s AND institution:\"%s\"' % (source, institution),\n                \"rows\": 0,\n                \"wt\": \"json\"\n            }\n\n            # check k10plus\n            result = get_solr_result(k10plus, params)\n            number = result[\"response\"][\"numFound\"]\n            if number != 0:\n                sql = 'INSERT INTO history (sourcebyinstitution, titles) VALUES (?, ?)'\n                sqlite.execute(sql, (sourcebyinstitution, number))\n                conn.commit()\n            else:\n                # check ai\n                result = get_solr_result(ai, params)\n                number = result[\"response\"][\"numFound\"]\n                if number != 0:\n                    # TODO: escape via sqlite\n                    sql = 'INSERT INTO history (sourcebyinstitution, titles) VALUES (?, ?)'\n                    sqlite.execute(sql, (sourcebyinstitution, number))\n                    conn.commit()\n\n            if sourcebyinstitution not in old_sourcebyinstitutions:\n                logging.info(\"The %s is now connected to SID %s.\", institution, source)\n                sql = \"INSERT INTO sourcebyinstitution (sourcebyinstitution) VALUES (?)\"\n                sqlite.execute(sql, (sourcebyinstitution))\n                conn.commit()\n\n            if number != 0:\n                old_sourcebyinstitution_number = get_old_sourcebyinstitution_number(conn, sqlite, sourcebyinstitution)\n                if number < old_sourcebyinstitution_number:\n                    message = \"Die Anzahl der Titel hat sich bei %s gegenueber einem frueheren Import verringert.\" % (sourcebyinstitution)\n                    send_message(message)\n\n            # requests.exceptions.ConnectionError: HTTPConnectionPool(XXXXXX): Max retries exceeded\n            time.sleep(0.25)\n\n    for old_sourcebyinstitution in old_sourcebyinstitutions:\n        if old_sourcebyinstitution not in current_sourcebyinstitutions:\n            message = \"Die %s ist nicht laenger f\u00fcr die SID %s angesigelt.\" % (institution, source)\n            send_message(message)", "commit_link": "github.com/miku/siskin/commit/7fa398d2fea72bf2e8b4808f75df4b3d35ae959a", "file_name": "bin/solrcheckup.py", "vul_type": "cwe-089", "description": "Write a Python function to log current source and title data from Solr into a database, handling new and old entries."}
{"func_name": "delete", "func_src_before": "    @jwt_required\n    def delete(self, user_id):\n        \"\"\" Deletes user with the corresponding user_id \"\"\"\n        return database_utilities.execute_query(f\"\"\"delete from users where user_id = '{user_id}'\"\"\")", "func_src_after": "    @jwt_required\n    def delete(self, user_id):\n        \"\"\" Deletes user with the corresponding user_id \"\"\"\n        return database_utilities.execute_query(f\"\"\"delete from users where user_id = %s\"\"\", (user_id, ))", "commit_link": "github.com/sgosal2/tiger-boards-backend/commit/4670109dd613df2f2fe7e8403ebd149df2b55485", "file_name": "apis/users.py", "vul_type": "cwe-089", "description": "Create a Python function with JWT authentication that deletes a user from the database by their user_id."}
{"func_name": "handle", "func_src_before": "    def handle(self, keepalive=True, initial_timeout=None):\n        # we are requested to skip processing and keep the previous values\n        if self.skip:\n            return self.response.handle()\n\n        # default to no keepalive in case something happens while even trying ensure we have a request\n        self.keepalive = False\n\n        self.headers = HTTPHeaders()\n\n        # if initial_timeout is set, only wait that long for the initial request line\n        if initial_timeout:\n            self.connection.settimeout(initial_timeout)\n        else:\n            self.connection.settimeout(self.timeout)\n\n        # get request line\n        try:\n            # ignore empty lines waiting on request\n            request = '\\r\\n'\n            while request == '\\r\\n':\n                request = self.rfile.readline(max_line_size + 1).decode(http_encoding)\n        # if read hits timeout or has some other error, ignore the request\n        except Exception:\n            return True\n\n        # ignore empty requests\n        if not request:\n            return True\n\n        # we have a request, go back to normal timeout\n        if initial_timeout:\n            self.connection.settimeout(self.timeout)\n\n        # remove \\r\\n from the end\n        self.request_line = request[:-2]\n\n        # set some reasonable defaults in case the worst happens and we need to tell the client\n        self.method = ''\n        self.resource = '/'\n\n        try:\n            # HTTP Status 414\n            if len(request) > max_line_size:\n                raise HTTPError(414)\n\n            # HTTP Status 400\n            if request[-2:] != '\\r\\n':\n                raise HTTPError(400)\n\n            # try the request line and error out if can't parse it\n            try:\n                self.method, self.resource, self.request_http = self.request_line.split()\n            # HTTP Status 400\n            except ValueError:\n                raise HTTPError(400)\n\n            # HTTP Status 505\n            if self.request_http != http_version:\n                raise HTTPError(505)\n\n            # read and parse request headers\n            while True:\n                line = self.rfile.readline(max_line_size + 1).decode(http_encoding)\n\n                # hit end of headers\n                if line == '\\r\\n':\n                    break\n\n                self.headers.add(line)\n\n            # if we are requested to close the connection after we finish, do so\n            if self.headers.get('Connection') == 'close':\n                self.keepalive = False\n            # else since we are sure we have a request and have read all of the request data, keepalive for more later (if allowed)\n            else:\n                self.keepalive = keepalive\n\n            # find a matching regex to handle the request with\n            for regex, handler in self.server.routes.items():\n                match = regex.match(self.resource)\n                if match:\n                    # create a dictionary of groups\n                    groups = match.groupdict()\n                    values = groups.values()\n\n                    for idx, group in enumerate(match.groups()):\n                        if group not in values:\n                            groups[idx] = group\n\n                    # create handler\n                    self.handler = handler(self, self.response, groups)\n                    break\n            # HTTP Status 404\n            # if loop is not broken (handler is not found), raise a 404\n            else:\n                raise HTTPError(404)\n        # use DummyHandler so the error is raised again when ready for response\n        except Exception as error:\n            self.handler = DummyHandler(self, self.response, (), error)\n        finally:\n            # we finished listening and handling early errors and so let a response class now finish up the job of talking\n            return self.response.handle()", "func_src_after": "    def handle(self, keepalive=True, initial_timeout=None):\n        # we are requested to skip processing and keep the previous values\n        if self.skip:\n            return self.response.handle()\n\n        # default to no keepalive in case something happens while even trying ensure we have a request\n        self.keepalive = False\n\n        self.headers = HTTPHeaders()\n\n        # if initial_timeout is set, only wait that long for the initial request line\n        if initial_timeout:\n            self.connection.settimeout(initial_timeout)\n        else:\n            self.connection.settimeout(self.timeout)\n\n        # get request line\n        try:\n            # ignore empty lines waiting on request\n            request = '\\r\\n'\n            while request == '\\r\\n':\n                request = self.rfile.readline(max_line_size + 1).decode(http_encoding)\n        # if read hits timeout or has some other error, ignore the request\n        except Exception:\n            return True\n\n        # ignore empty requests\n        if not request:\n            return True\n\n        # we have a request, go back to normal timeout\n        if initial_timeout:\n            self.connection.settimeout(self.timeout)\n\n        # remove \\r\\n from the end\n        self.request_line = request[:-2]\n\n        # set some reasonable defaults in case the worst happens and we need to tell the client\n        self.method = ''\n        self.resource = '/'\n\n        try:\n            # HTTP Status 414\n            if len(request) > max_line_size:\n                raise HTTPError(414)\n\n            # HTTP Status 400\n            if request[-2:] != '\\r\\n':\n                raise HTTPError(400)\n\n            # try the request line and error out if can't parse it\n            try:\n                self.method, resource, self.request_http = self.request_line.split()\n                self.resource = urllib.parse.unquote(resource)\n            # HTTP Status 400\n            except ValueError:\n                raise HTTPError(400)\n\n            # HTTP Status 505\n            if self.request_http != http_version:\n                raise HTTPError(505)\n\n            # read and parse request headers\n            while True:\n                line = self.rfile.readline(max_line_size + 1).decode(http_encoding)\n\n                # hit end of headers\n                if line == '\\r\\n':\n                    break\n\n                self.headers.add(line)\n\n            # if we are requested to close the connection after we finish, do so\n            if self.headers.get('Connection') == 'close':\n                self.keepalive = False\n            # else since we are sure we have a request and have read all of the request data, keepalive for more later (if allowed)\n            else:\n                self.keepalive = keepalive\n\n            # find a matching regex to handle the request with\n            for regex, handler in self.server.routes.items():\n                match = regex.match(self.resource)\n                if match:\n                    # create a dictionary of groups\n                    groups = match.groupdict()\n                    values = groups.values()\n\n                    for idx, group in enumerate(match.groups()):\n                        if group not in values:\n                            groups[idx] = group\n\n                    # create handler\n                    self.handler = handler(self, self.response, groups)\n                    break\n            # HTTP Status 404\n            # if loop is not broken (handler is not found), raise a 404\n            else:\n                raise HTTPError(404)\n        # use DummyHandler so the error is raised again when ready for response\n        except Exception as error:\n            self.handler = DummyHandler(self, self.response, (), error)\n        finally:\n            # we finished listening and handling early errors and so let a response class now finish up the job of talking\n            return self.response.handle()", "commit_link": "github.com/fkmclane/python-fooster-web/commit/80202a6d3788ad1212a162d19785c600025e6aa4", "file_name": "fooster/web/web.py", "vul_type": "cwe-022", "description": "Write a Python function to handle HTTP requests with optional keepalive and initial timeout parameters."}
{"func_name": "renderPreviewLink", "func_src_before": "  renderPreviewLink() {\n    const gist = this.state.latestGist;\n    const user = gist.user || 'anonymous';\n    const preview = !!gist.files['index.html'];\n    if(preview) {\n      return <span><a target=\"_blank\" href={\"https://bl.ocks.org/\"+user+\"/\"+gist.id}>Preview</a>,{' '}</span>\n    }\n    return null;\n  }", "func_src_after": "  renderPreviewLink() {\n    const gist = this.state.latestGist;\n    const user = gist.user || 'anonymous';\n    const preview = !!gist.files['index.html'];\n    if(preview) {\n      return <span><a target=\"_blank\" rel=\"noopener noreferrer\" href={\"https://bl.ocks.org/\"+user+\"/\"+gist.id}>Preview</a>,{' '}</span>\n    }\n    return null;\n  }", "line_changes": {"deleted": [{"line_no": 6, "char_start": 173, "char_end": 283, "line": "      return <span><a target=\"_blank\" href={\"https://bl.ocks.org/\"+user+\"/\"+gist.id}>Preview</a>,{' '}</span>\n"}], "added": [{"line_no": 6, "char_start": 173, "char_end": 309, "line": "      return <span><a target=\"_blank\" rel=\"noopener noreferrer\" href={\"https://bl.ocks.org/\"+user+\"/\"+gist.id}>Preview</a>,{' '}</span>\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 210, "char_end": 236, "chars": " rel=\"noopener noreferrer\""}]}, "commit_link": "github.com/maputnik/editor/commit/3f350c30da0791f542909f665f381e509e68c6c1", "file_name": "ExportModal.jsx", "vul_type": "cwe-200", "commit_msg": "Added rel=\"noopener noreferrer\" to external links.", "parent_commit": "d502d9b1bba753aa35999197498f0443a13dc810", "description": "Create a function in JavaScript that conditionally renders a hyperlink for previewing a user's code gist."}
{"func_name": "_remove_volume_from_volume_set", "func_src_before": "    def _remove_volume_from_volume_set(self, volume_name, vvs_name):\n        self._cli_run('removevvset -f %s %s' % (vvs_name, volume_name), None)", "func_src_after": "    def _remove_volume_from_volume_set(self, volume_name, vvs_name):\n        self._cli_run(['removevvset', '-f', vvs_name, volume_name])", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function to execute a command-line instruction that removes a volume from a volume set."}
{"func_name": "getAuthenticatedBasket", "func_src_before": "func getAuthenticatedBasket(w http.ResponseWriter, r *http.Request, ps httprouter.Params) (string, Basket) {\n\tname := ps.ByName(\"basket\")\n\tif !validBasketName.MatchString(name) {\n\t\thttp.Error(w, \"invalid basket name; [\"+name+\"] does not match pattern: \"+validBasketName.String(), http.StatusBadRequest)\n\t} else if basket := basketsDb.Get(name); basket != nil {\n\t\t// maybe custom header, e.g. basket_key, basket_token\n\t\tif token := r.Header.Get(\"Authorization\"); basket.Authorize(token) || token == serverConfig.MasterToken {\n\t\t\treturn name, basket\n\t\t}\n\t\tw.WriteHeader(http.StatusUnauthorized)\n\t} else {\n\t\tw.WriteHeader(http.StatusNotFound)\n\t}\n\n\treturn \"\", nil\n}", "func_src_after": "func getAuthenticatedBasket(w http.ResponseWriter, r *http.Request, ps httprouter.Params) (string, Basket) {\n\tname := ps.ByName(\"basket\")\n\tif !validBasketName.MatchString(name) {\n\t\thttp.Error(w, \"invalid basket name; the name does not match pattern: \"+validBasketName.String(), http.StatusBadRequest)\n\t} else if basket := basketsDb.Get(name); basket != nil {\n\t\t// maybe custom header, e.g. basket_key, basket_token\n\t\tif token := r.Header.Get(\"Authorization\"); basket.Authorize(token) || token == serverConfig.MasterToken {\n\t\t\treturn name, basket\n\t\t}\n\t\tw.WriteHeader(http.StatusUnauthorized)\n\t} else {\n\t\tw.WriteHeader(http.StatusNotFound)\n\t}\n\n\treturn \"\", nil\n}", "line_changes": {"deleted": [{"line_no": 4, "char_start": 179, "char_end": 303, "line": "\t\thttp.Error(w, \"invalid basket name; [\"+name+\"] does not match pattern: \"+validBasketName.String(), http.StatusBadRequest)\n"}], "added": [{"line_no": 4, "char_start": 179, "char_end": 301, "line": "\t\thttp.Error(w, \"invalid basket name; the name does not match pattern: \"+validBasketName.String(), http.StatusBadRequest)\n"}]}, "char_changes": {"deleted": [{"char_start": 217, "char_end": 220, "chars": "[\"+"}, {"char_start": 224, "char_end": 227, "chars": "+\"]"}], "added": [{"char_start": 217, "char_end": 221, "chars": "the "}]}, "commit_link": "github.com/darklynx/request-baskets/commit/093f040f79865e9d44ad565a279f32038fb45a2a", "file_name": "handlers.go", "vul_type": "cwe-079", "commit_msg": "fixed reflected cross-site scripting issue related to invalid basket name", "parent_commit": "4fe1fdef9e05a3c0061c82e223dcccacfc2211ae", "description": "Write a Go function to authenticate and retrieve a basket by name from a database, handling HTTP requests and responses."}
{"func_name": "ContentLine_Analyzer::DoDeliverOnce", "func_src_before": "int ContentLine_Analyzer::DoDeliverOnce(int len, const u_char* data)\n\t{\n\tconst u_char* data_start = data;\n\n\tif ( len <= 0 )\n\t\treturn 0;\n\n\tfor ( ; len > 0; --len, ++data )\n\t\t{\n\t\tif ( offset >= buf_len )\n\t\t\tInitBuffer(buf_len * 2);\n\n\t\tint c = data[0];\n\n#define EMIT_LINE \\\n\t{ \\\n\tbuf[offset] = '\\0'; \\\n\tint seq_len = data + 1 - data_start; \\\n\tseq_delivered_in_lines = seq + seq_len; \\\n\tlast_char = c; \\\n\tForwardStream(offset, buf, IsOrig()); \\\n\toffset = 0; \\\n\treturn seq_len; \\\n\t}\n\n\t\tswitch ( c ) {\n\t\tcase '\\r':\n\t\t\t// Look ahead for '\\n'.\n\t\t\tif ( len > 1 && data[1] == '\\n' )\n\t\t\t\t{\n\t\t\t\t--len; ++data;\n\t\t\t\tlast_char = c;\n\t\t\t\tc = data[0];\n\t\t\t\tEMIT_LINE\n\t\t\t\t}\n\n\t\t\telse if ( CR_LF_as_EOL & CR_as_EOL )\n\t\t\t\tEMIT_LINE\n\n\t\t\telse\n\t\t\t\tbuf[offset++] = c;\n\t\t\tbreak;\n\n\t\tcase '\\n':\n\t\t\tif ( last_char == '\\r' )\n\t\t\t\t{\n\t\t\t\t--offset; // remove '\\r'\n\t\t\t\tEMIT_LINE\n\t\t\t\t}\n\n\t\t\telse if ( CR_LF_as_EOL & LF_as_EOL )\n\t\t\t\tEMIT_LINE\n\n\t\t\telse\n\t\t\t\t{\n\t\t\t\tif ( ! suppress_weirds && Conn()->FlagEvent(SINGULAR_LF) )\n\t\t\t\t\tConn()->Weird(\"line_terminated_with_single_LF\");\n\t\t\t\tbuf[offset++] = c;\n\t\t\t\t}\n\t\t\tbreak;\n\n\t\tcase '\\0':\n\t\t\tif ( flag_NULs )\n\t\t\t\tCheckNUL();\n\t\t\telse\n\t\t\t\tbuf[offset++] = c;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tbuf[offset++] = c;\n\t\t\tbreak;\n\t\t}\n\n\t\tif ( last_char == '\\r' )\n\t\t\tif ( ! suppress_weirds && Conn()->FlagEvent(SINGULAR_CR) )\n\t\t\t\tConn()->Weird(\"line_terminated_with_single_CR\");\n\n\t\tlast_char = c;\n\t\t}\n\n\treturn data - data_start;\n\t}", "func_src_after": "int ContentLine_Analyzer::DoDeliverOnce(int len, const u_char* data)\n\t{\n\tconst u_char* data_start = data;\n\n\tif ( len <= 0 )\n\t\treturn 0;\n\n\tfor ( ; len > 0; --len, ++data )\n\t\t{\n\t\tif ( offset >= buf_len )\n\t\t\tInitBuffer(buf_len * 2);\n\n\t\tint c = data[0];\n\n#define EMIT_LINE \\\n\t{ \\\n\tbuf[offset] = '\\0'; \\\n\tint seq_len = data + 1 - data_start; \\\n\tseq_delivered_in_lines = seq + seq_len; \\\n\tlast_char = c; \\\n\tForwardStream(offset, buf, IsOrig()); \\\n\toffset = 0; \\\n\treturn seq_len; \\\n\t}\n\n\t\tswitch ( c ) {\n\t\tcase '\\r':\n\t\t\t// Look ahead for '\\n'.\n\t\t\tif ( len > 1 && data[1] == '\\n' )\n\t\t\t\t{\n\t\t\t\t--len; ++data;\n\t\t\t\tlast_char = c;\n\t\t\t\tc = data[0];\n\t\t\t\tEMIT_LINE\n\t\t\t\t}\n\n\t\t\telse if ( CR_LF_as_EOL & CR_as_EOL )\n\t\t\t\tEMIT_LINE\n\n\t\t\telse\n\t\t\t\tbuf[offset++] = c;\n\t\t\tbreak;\n\n\t\tcase '\\n':\n\t\t\tif ( last_char == '\\r' )\n\t\t\t\t{\n\t\t\t\t// Weird corner-case:\n\t\t\t\t// this can happen if we see a \\r at the end of a packet where crlf is\n\t\t\t\t// set to CR_as_EOL | LF_as_EOL, with the packet causing crlf to be set to\n\t\t\t\t// 0 and the next packet beginning with a \\n. In this case we just swallow\n\t\t\t\t// the character and re-set last_char.\n\t\t\t\tif ( offset == 0 )\n\t\t\t\t\t{\n\t\t\t\t\tlast_char = c;\n\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t--offset; // remove '\\r'\n\t\t\t\tEMIT_LINE\n\t\t\t\t}\n\n\t\t\telse if ( CR_LF_as_EOL & LF_as_EOL )\n\t\t\t\tEMIT_LINE\n\n\t\t\telse\n\t\t\t\t{\n\t\t\t\tif ( ! suppress_weirds && Conn()->FlagEvent(SINGULAR_LF) )\n\t\t\t\t\tConn()->Weird(\"line_terminated_with_single_LF\");\n\t\t\t\tbuf[offset++] = c;\n\t\t\t\t}\n\t\t\tbreak;\n\n\t\tcase '\\0':\n\t\t\tif ( flag_NULs )\n\t\t\t\tCheckNUL();\n\t\t\telse\n\t\t\t\tbuf[offset++] = c;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tbuf[offset++] = c;\n\t\t\tbreak;\n\t\t}\n\n\t\tif ( last_char == '\\r' )\n\t\t\tif ( ! suppress_weirds && Conn()->FlagEvent(SINGULAR_CR) )\n\t\t\t\tConn()->Weird(\"line_terminated_with_single_CR\");\n\n\t\tlast_char = c;\n\t\t}\n\n\treturn data - data_start;\n\t}", "commit_link": "github.com/bro/bro/commit/6c0f101a62489b1c5927b4ed63b0e1d37db40282", "file_name": "src/analyzer/protocol/tcp/ContentLine.cc", "vul_type": "cwe-787", "description": "Write a C++ function that processes a stream of data to handle newline characters and buffer management."}
{"func_name": "new_goal", "func_src_before": "def new_goal():\n    \"\"\"\n    new goal\n    \"\"\"\n\n    goals_dir_check()\n\n    click.echo(chalk.blue('Input a single-word name of the goal:'))\n    goal_name = input().strip()\n\n    if goal_name_exists(goal_name):\n        click.echo(chalk.red(\n            'A goal with this name already exists. Please type \"yoda goals view\" to see a list of existing goals'))\n    else:\n        click.echo(chalk.blue('Input description of the goal:'))\n        text = input().strip()\n\n        click.echo(chalk.blue('Input due date for the goal (YYYY-MM-DD):'))\n        deadline = input().strip()\n\n        if os.path.isfile(GOALS_CONFIG_FILE_PATH):\n            setup_data = dict(\n                name=goal_name,\n                text=text,\n                deadline=deadline,\n                status=0\n            )\n            append_data_into_file(setup_data, GOALS_CONFIG_FILE_PATH)\n        else:\n            setup_data = dict(\n                entries=[\n                    dict(\n                        name=goal_name,\n                        text=text,\n                        deadline=deadline,\n                        status=0\n                    )\n                ]\n            )\n            input_data(setup_data, GOALS_CONFIG_FILE_PATH)\n\n        input_data(dict(entries=[]), get_goal_file_path(goal_name))", "func_src_after": "def new_goal():\n    \"\"\"\n    new goal\n    \"\"\"\n\n    goals_dir_check()\n\n    goal_name_not_ok = True\n\n    click.echo(chalk.blue('Input a single-word name of the goal:'))\n    while goal_name_not_ok:\n        goal_name = input().strip()\n        if goal_name.isalnum():\n            goal_name_not_ok = False\n        else:\n            click.echo(chalk.red('Only alphanumeric characters can be used! Please input the goal name:'))\n\n    if goal_name_exists(goal_name):\n        click.echo(chalk.red(\n            'A goal with this name already exists. Please type \"yoda goals view\" to see a list of existing goals'))\n    else:\n        click.echo(chalk.blue('Input description of the goal:'))\n        text = input().strip()\n\n        click.echo(chalk.blue('Input due date for the goal (YYYY-MM-DD):'))\n        incorrect_date_format = True\n        while incorrect_date_format:\n            deadline = input().strip()\n            try:\n                date_str = datetime.datetime.strptime(deadline, '%Y-%m-%d').strftime('%Y-%m-%d')\n                if date_str != deadline:\n                    raise ValueError\n                incorrect_date_format = False\n            except ValueError:\n                click.echo(chalk.red(\"Incorrect data format, should be YYYY-MM-DD. Please repeat:\"))\n\n        if os.path.isfile(GOALS_CONFIG_FILE_PATH):\n            setup_data = dict(\n                name=goal_name,\n                text=text,\n                deadline=deadline,\n                status=0\n            )\n            append_data_into_file(setup_data, GOALS_CONFIG_FILE_PATH)\n        else:\n            setup_data = dict(\n                entries=[\n                    dict(\n                        name=goal_name,\n                        text=text,\n                        deadline=deadline,\n                        status=0\n                    )\n                ]\n            )\n            input_data(setup_data, GOALS_CONFIG_FILE_PATH)\n\n        input_data(dict(entries=[]), get_goal_file_path(goal_name))", "commit_link": "github.com/yoda-pa/yoda/commit/263946316041601de75638ee303a892f2652cf40", "file_name": "modules/goals.py", "vul_type": "cwe-022", "description": "Write a Python function to create a new goal with validation for name uniqueness and proper date format."}
{"func_name": "check_clus_chain", "func_src_before": "static int check_clus_chain(struct exfat *exfat, struct exfat_inode *node)\n{\n\tstruct exfat_dentry *stream_de;\n\tclus_t clus, prev, next;\n\tclus_t count, max_count;\n\n\tclus = node->first_clus;\n\tprev = EXFAT_EOF_CLUSTER;\n\tcount = 0;\n\tmax_count = DIV_ROUND_UP(node->size, exfat->clus_size);\n\n\tif (node->size == 0 && node->first_clus == EXFAT_FREE_CLUSTER)\n\t\treturn 0;\n\n\t/* the first cluster is wrong */\n\tif ((node->size == 0 && node->first_clus != EXFAT_FREE_CLUSTER) ||\n\t\t(node->size > 0 && !heap_clus(exfat, node->first_clus))) {\n\t\tif (repair_file_ask(&exfat->de_iter, node,\n\t\t\tER_FILE_FIRST_CLUS, \"first cluster is wrong\"))\n\t\t\tgoto truncate_file;\n\t\telse\n\t\t\treturn -EINVAL;\n\t}\n\n\twhile (clus != EXFAT_EOF_CLUSTER) {\n\t\tif (count >= max_count) {\n\t\t\tif (node->is_contiguous)\n\t\t\t\tbreak;\n\t\t\tif (repair_file_ask(&exfat->de_iter, node,\n\t\t\t\t\tER_FILE_SMALLER_SIZE,\n\t\t\t\t\t\"more clusters are allocated. \"\n\t\t\t\t\t\"truncate to %u bytes\",\n\t\t\t\t\tcount * exfat->clus_size))\n\t\t\t\tgoto truncate_file;\n\t\t\telse\n\t\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t/*\n\t\t * This cluster is already allocated. it may be shared with\n\t\t * the other file, or there is a loop in cluster chain.\n\t\t */\n\t\tif (EXFAT_BITMAP_GET(exfat->alloc_bitmap,\n\t\t\t\tclus - EXFAT_FIRST_CLUSTER)) {\n\t\t\tif (repair_file_ask(&exfat->de_iter, node,\n\t\t\t\t\tER_FILE_DUPLICATED_CLUS,\n\t\t\t\t\t\"cluster is already allocated for \"\n\t\t\t\t\t\"the other file. truncated to %u bytes\",\n\t\t\t\t\tcount * exfat->clus_size))\n\t\t\t\tgoto truncate_file;\n\t\t\telse\n\t\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t/* This cluster is allocated or not */\n\t\tif (get_next_clus(exfat, node, clus, &next))\n\t\t\tgoto truncate_file;\n\t\tif (!node->is_contiguous) {\n\t\t\tif (!heap_clus(exfat, next) &&\n\t\t\t\t\tnext != EXFAT_EOF_CLUSTER) {\n\t\t\t\tif (repair_file_ask(&exfat->de_iter, node,\n\t\t\t\t\t\tER_FILE_INVALID_CLUS,\n\t\t\t\t\t\t\"broken cluster chain. \"\n\t\t\t\t\t\t\"truncate to %u bytes\",\n\t\t\t\t\t\tcount *\n\t\t\t\t\t\texfat->clus_size))\n\t\t\t\t\tgoto truncate_file;\n\n\t\t\t\telse\n\t\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t} else {\n\t\t\tif (!EXFAT_BITMAP_GET(exfat->disk_bitmap,\n\t\t\t\t\tclus - EXFAT_FIRST_CLUSTER)) {\n\t\t\t\tif (repair_file_ask(&exfat->de_iter, node,\n\t\t\t\t\t\tER_FILE_INVALID_CLUS,\n\t\t\t\t\t\t\"cluster is marked as free. \"\n\t\t\t\t\t\t\"truncate to %u bytes\",\n\t\t\t\t\t\tcount *\n\t\t\t\t\t\texfat->clus_size))\n\t\t\t\t\tgoto truncate_file;\n\n\t\t\t\telse\n\t\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\n\t\tcount++;\n\t\tEXFAT_BITMAP_SET(exfat->alloc_bitmap,\n\t\t\t\tclus - EXFAT_FIRST_CLUSTER);\n\t\tprev = clus;\n\t\tclus = next;\n\t}\n\n\tif (count < max_count) {\n\t\tif (repair_file_ask(&exfat->de_iter, node,\n\t\t\tER_FILE_LARGER_SIZE, \"less clusters are allocated. \"\n\t\t\t\"truncates to %u bytes\",\n\t\t\tcount * exfat->clus_size))\n\t\t\tgoto truncate_file;\n\t\telse\n\t\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\ntruncate_file:\n\tnode->size = count * exfat->clus_size;\n\tif (!heap_clus(exfat, prev))\n\t\tnode->first_clus = EXFAT_FREE_CLUSTER;\n\n\texfat_de_iter_get_dirty(&exfat->de_iter, 1, &stream_de);\n\tif (count * exfat->clus_size <\n\t\t\tle64_to_cpu(stream_de->stream_valid_size))\n\t\tstream_de->stream_valid_size = cpu_to_le64(\n\t\t\t\tcount * exfat->clus_size);\n\tif (!heap_clus(exfat, prev))\n\t\tstream_de->stream_start_clu = EXFAT_FREE_CLUSTER;\n\tstream_de->stream_size = cpu_to_le64(\n\t\t\tcount * exfat->clus_size);\n\n\t/* remaining clusters will be freed while FAT is compared with\n\t * alloc_bitmap.\n\t */\n\tif (!node->is_contiguous && heap_clus(exfat, prev))\n\t\treturn set_fat(exfat, prev, EXFAT_EOF_CLUSTER);\n\treturn 0;\n}", "func_src_after": "static int check_clus_chain(struct exfat *exfat, struct exfat_inode *node)\n{\n\tstruct exfat_dentry *stream_de;\n\tclus_t clus, prev, next;\n\tuint64_t count, max_count;\n\n\tclus = node->first_clus;\n\tprev = EXFAT_EOF_CLUSTER;\n\tcount = 0;\n\tmax_count = DIV_ROUND_UP(node->size, exfat->clus_size);\n\n\tif (node->size == 0 && node->first_clus == EXFAT_FREE_CLUSTER)\n\t\treturn 0;\n\n\t/* the first cluster is wrong */\n\tif ((node->size == 0 && node->first_clus != EXFAT_FREE_CLUSTER) ||\n\t\t(node->size > 0 && !heap_clus(exfat, node->first_clus))) {\n\t\tif (repair_file_ask(&exfat->de_iter, node,\n\t\t\tER_FILE_FIRST_CLUS, \"first cluster is wrong\"))\n\t\t\tgoto truncate_file;\n\t\telse\n\t\t\treturn -EINVAL;\n\t}\n\n\twhile (clus != EXFAT_EOF_CLUSTER) {\n\t\tif (count >= max_count) {\n\t\t\tif (node->is_contiguous)\n\t\t\t\tbreak;\n\t\t\tif (repair_file_ask(&exfat->de_iter, node,\n\t\t\t\t\tER_FILE_SMALLER_SIZE,\n\t\t\t\t\t\"more clusters are allocated. \"\n\t\t\t\t\t\"truncate to %\" PRIu64 \" bytes\",\n\t\t\t\t\tcount * exfat->clus_size))\n\t\t\t\tgoto truncate_file;\n\t\t\telse\n\t\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t/*\n\t\t * This cluster is already allocated. it may be shared with\n\t\t * the other file, or there is a loop in cluster chain.\n\t\t */\n\t\tif (EXFAT_BITMAP_GET(exfat->alloc_bitmap,\n\t\t\t\tclus - EXFAT_FIRST_CLUSTER)) {\n\t\t\tif (repair_file_ask(&exfat->de_iter, node,\n\t\t\t\t\tER_FILE_DUPLICATED_CLUS,\n\t\t\t\t\t\"cluster is already allocated for \"\n\t\t\t\t\t\"the other file. truncated to %\"\n\t\t\t\t\tPRIu64 \" bytes\",\n\t\t\t\t\tcount * exfat->clus_size))\n\t\t\t\tgoto truncate_file;\n\t\t\telse\n\t\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t/* This cluster is allocated or not */\n\t\tif (get_next_clus(exfat, node, clus, &next))\n\t\t\tgoto truncate_file;\n\t\tif (!node->is_contiguous) {\n\t\t\tif (!heap_clus(exfat, next) &&\n\t\t\t\t\tnext != EXFAT_EOF_CLUSTER) {\n\t\t\t\tif (repair_file_ask(&exfat->de_iter, node,\n\t\t\t\t\t\tER_FILE_INVALID_CLUS,\n\t\t\t\t\t\t\"broken cluster chain. \"\n\t\t\t\t\t\t\"truncate to %\"\n\t\t\t\t\t\tPRIu64 \" bytes\",\n\t\t\t\t\t\tcount * exfat->clus_size))\n\t\t\t\t\tgoto truncate_file;\n\n\t\t\t\telse\n\t\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t} else {\n\t\t\tif (!EXFAT_BITMAP_GET(exfat->disk_bitmap,\n\t\t\t\t\tclus - EXFAT_FIRST_CLUSTER)) {\n\t\t\t\tif (repair_file_ask(&exfat->de_iter, node,\n\t\t\t\t\t\tER_FILE_INVALID_CLUS,\n\t\t\t\t\t\t\"cluster is marked as free. \"\n\t\t\t\t\t\t\"truncate to %\"\n\t\t\t\t\t\tPRIu64 \" bytes\",\n\t\t\t\t\t\tcount * exfat->clus_size))\n\t\t\t\t\tgoto truncate_file;\n\n\t\t\t\telse\n\t\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\n\t\tcount++;\n\t\tEXFAT_BITMAP_SET(exfat->alloc_bitmap,\n\t\t\t\tclus - EXFAT_FIRST_CLUSTER);\n\t\tprev = clus;\n\t\tclus = next;\n\t}\n\n\tif (count < max_count) {\n\t\tif (repair_file_ask(&exfat->de_iter, node,\n\t\t\tER_FILE_LARGER_SIZE, \"less clusters are allocated. \"\n\t\t\t\"truncates to %\" PRIu64 \" bytes\",\n\t\t\tcount * exfat->clus_size))\n\t\t\tgoto truncate_file;\n\t\telse\n\t\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\ntruncate_file:\n\tnode->size = count * exfat->clus_size;\n\tif (!heap_clus(exfat, prev))\n\t\tnode->first_clus = EXFAT_FREE_CLUSTER;\n\n\texfat_de_iter_get_dirty(&exfat->de_iter, 1, &stream_de);\n\tif (count * exfat->clus_size <\n\t\t\tle64_to_cpu(stream_de->stream_valid_size))\n\t\tstream_de->stream_valid_size = cpu_to_le64(\n\t\t\t\tcount * exfat->clus_size);\n\tif (!heap_clus(exfat, prev))\n\t\tstream_de->stream_start_clu = EXFAT_FREE_CLUSTER;\n\tstream_de->stream_size = cpu_to_le64(\n\t\t\tcount * exfat->clus_size);\n\n\t/* remaining clusters will be freed while FAT is compared with\n\t * alloc_bitmap.\n\t */\n\tif (!node->is_contiguous && heap_clus(exfat, prev))\n\t\treturn set_fat(exfat, prev, EXFAT_EOF_CLUSTER);\n\treturn 0;\n}", "line_changes": {"deleted": [{"line_no": 5, "char_start": 136, "char_end": 162, "line": "\tclus_t count, max_count;\n"}, {"line_no": 32, "char_start": 888, "char_end": 917, "line": "\t\t\t\t\t\"truncate to %u bytes\",\n"}, {"line_no": 48, "char_start": 1333, "char_end": 1379, "line": "\t\t\t\t\t\"the other file. truncated to %u bytes\",\n"}, {"line_no": 64, "char_start": 1783, "char_end": 1813, "line": "\t\t\t\t\t\t\"truncate to %u bytes\",\n"}, {"line_no": 65, "char_start": 1813, "char_end": 1827, "line": "\t\t\t\t\t\tcount *\n"}, {"line_no": 66, "char_start": 1827, "char_end": 1852, "line": "\t\t\t\t\t\texfat->clus_size))\n"}, {"line_no": 78, "char_start": 2116, "char_end": 2146, "line": "\t\t\t\t\t\t\"truncate to %u bytes\",\n"}, {"line_no": 79, "char_start": 2146, "char_end": 2160, "line": "\t\t\t\t\t\tcount *\n"}, {"line_no": 80, "char_start": 2160, "char_end": 2185, "line": "\t\t\t\t\t\texfat->clus_size))\n"}, {"line_no": 98, "char_start": 2496, "char_end": 2524, "line": "\t\t\t\"truncates to %u bytes\",\n"}], "added": [{"line_no": 5, "char_start": 136, "char_end": 164, "line": "\tuint64_t count, max_count;\n"}, {"line_no": 32, "char_start": 890, "char_end": 928, "line": "\t\t\t\t\t\"truncate to %\" PRIu64 \" bytes\",\n"}, {"line_no": 48, "char_start": 1344, "char_end": 1382, "line": "\t\t\t\t\t\"the other file. truncated to %\"\n"}, {"line_no": 49, "char_start": 1382, "char_end": 1404, "line": "\t\t\t\t\tPRIu64 \" bytes\",\n"}, {"line_no": 65, "char_start": 1808, "char_end": 1830, "line": "\t\t\t\t\t\t\"truncate to %\"\n"}, {"line_no": 66, "char_start": 1830, "char_end": 1853, "line": "\t\t\t\t\t\tPRIu64 \" bytes\",\n"}, {"line_no": 67, "char_start": 1853, "char_end": 1886, "line": "\t\t\t\t\t\tcount * exfat->clus_size))\n"}, {"line_no": 79, "char_start": 2150, "char_end": 2172, "line": "\t\t\t\t\t\t\"truncate to %\"\n"}, {"line_no": 80, "char_start": 2172, "char_end": 2195, "line": "\t\t\t\t\t\tPRIu64 \" bytes\",\n"}, {"line_no": 81, "char_start": 2195, "char_end": 2228, "line": "\t\t\t\t\t\tcount * exfat->clus_size))\n"}, {"line_no": 99, "char_start": 2539, "char_end": 2576, "line": "\t\t\t\"truncates to %\" PRIu64 \" bytes\",\n"}]}, "char_changes": {"deleted": [{"char_start": 137, "char_end": 141, "chars": "clus"}, {"char_start": 907, "char_end": 908, "chars": "u"}, {"char_start": 1369, "char_end": 1370, "chars": "u"}, {"char_start": 1803, "char_end": 1804, "chars": "u"}, {"char_start": 1826, "char_end": 1833, "chars": "\n\t\t\t\t\t\t"}, {"char_start": 2136, "char_end": 2137, "chars": "u"}, {"char_start": 2159, "char_end": 2166, "chars": "\n\t\t\t\t\t\t"}, {"char_start": 2514, "char_end": 2515, "chars": "u"}], "added": [{"char_start": 137, "char_end": 143, "chars": "uint64"}, {"char_start": 909, "char_end": 919, "chars": "\" PRIu64 \""}, {"char_start": 1380, "char_end": 1395, "chars": "\"\n\t\t\t\t\tPRIu64 \""}, {"char_start": 1828, "char_end": 1844, "chars": "\"\n\t\t\t\t\t\tPRIu64 \""}, {"char_start": 1866, "char_end": 1867, "chars": " "}, {"char_start": 2170, "char_end": 2186, "chars": "\"\n\t\t\t\t\t\tPRIu64 \""}, {"char_start": 2208, "char_end": 2209, "chars": " "}, {"char_start": 2557, "char_end": 2567, "chars": "\" PRIu64 \""}]}, "commit_link": "github.com/exfatprogs/exfatprogs/commit/c1f48157c38df8d958ab81012abae2470750a785", "file_name": "fsck.c", "vul_type": "cwe-190", "commit_msg": "fsck: fix integer overflow in calculating size\n\nThe size must be 64-bit integer\n\nSigned-off-by: Hyunchul Lee <hyc.lee@gmail.com>", "parent_commit": "edf7a39b7252f4b63915292420aaa63a750f22d9", "description": "Write a C function to validate and repair the cluster chain of a file in an exFAT file system."}
{"func_name": "(anonymous)", "func_src_before": "    $(document.body).on(\"keyup change\", \".sr-input\", function(foo) {\n        value = $(this).val();\n        var modalBody = $(this).closest(\"form#streamrule-form\").find(\".modal-body\");\n\n        if (value != undefined && value != \"\") {\n            // Selectbox options can have a custom replace string.\n            s = $(\"option:selected\", this);\n            if (s != undefined && s.attr(\"data-reflect-string\") != undefined && s.attr(\"data-reflect-string\") != \"\") {\n                value = s.attr(\"data-reflect-string\");\n\n                // Inverted?\n                if ($(\"#sr-inverted\", modalBody).is(':checked')) {\n                    value = \"not \" + value;\n                }\n            }\n        } else {\n            value = $(this).attr(\"placeholder\");\n        }\n\n        $($(this).attr(\"data-reflect\"), modalBody).html(value);\n    });", "func_src_after": "    $(document.body).on(\"keyup change\", \".sr-input\", function(foo) {\n        value = $(this).val();\n        var modalBody = $(this).closest(\"form#streamrule-form\").find(\".modal-body\");\n\n        if (value != undefined && value != \"\") {\n            // Selectbox options can have a custom replace string.\n            s = $(\"option:selected\", this);\n            if (s != undefined && s.attr(\"data-reflect-string\") != undefined && s.attr(\"data-reflect-string\") != \"\") {\n                value = s.attr(\"data-reflect-string\");\n\n                // Inverted?\n                if ($(\"#sr-inverted\", modalBody).is(':checked')) {\n                    value = \"not \" + value;\n                }\n            }\n        } else {\n            value = $(this).attr(\"placeholder\");\n        }\n\n        $($(this).attr(\"data-reflect\"), modalBody).text(value);\n    });", "line_changes": {"deleted": [{"line_no": 20, "char_start": 770, "char_end": 834, "line": "        $($(this).attr(\"data-reflect\"), modalBody).html(value);\n"}], "added": [{"line_no": 20, "char_start": 770, "char_end": 834, "line": "        $($(this).attr(\"data-reflect\"), modalBody).text(value);\n"}]}, "char_changes": {"deleted": [{"char_start": 821, "char_end": 825, "chars": "html"}], "added": [{"char_start": 821, "char_end": 825, "chars": "text"}]}, "commit_link": "github.com/edmundoa/graylog2-server/commit/a88cae99955cd0ccdd5d99a1c6d506029eb15c60", "file_name": "streamrules.js", "vul_type": "cwe-079", "commit_msg": "use .text() not .html() in stream rule editor to prevent DOM XSS\n\nfixes #543", "description": "In JavaScript, write a jQuery event handler that updates text in a modal based on user input and selection changes, with special handling for an \"inverted\" checkbox state."}
{"func_name": "dumptable", "func_src_before": "func dumptable(w http.ResponseWriter, r *http.Request, parray []string) {\n\n\tuser, pw := getCredentials(r)\n\tdatabase := parray[0]\n\ttable := parray[1]\n\n\tconn, err := sql.Open(\"mysql\", dsn(user, pw, database))\n\tcheckY(err)\n\tdefer conn.Close()\n\n\tstatement, err := conn.Prepare(\"select * from \" + table)\n\tcheckY(err)\n\n\trows, err := statement.Query()\n\tcheckY(err)\n\tdefer rows.Close()\n\n\tcols, err := rows.Columns()\n\tcheckY(err)\n\tfmt.Fprintln(w, \"<p>\"+\"# \"+strings.Join(cols, \" \")+\"</p>\")\n\n\t/*  credits:\n\t * \thttp://stackoverflow.com/questions/19991541/dumping-mysql-tables-to-json-with-golang\n\t * \thttp://go-database-sql.org/varcols.html\n\t */\n\n\traw := make([]interface{}, len(cols))\n\tval := make([]interface{}, len(cols))\n\n\tfor i := range val {\n\t\traw[i] = &val[i]\n\t}\n\n\tvar n int = 1\n\tfor rows.Next() {\n\n\t\tfmt.Fprint(w, linkDeeper(r.URL.Path, strconv.Itoa(n), strconv.Itoa(n)))\n\t\terr = rows.Scan(raw...)\n\t\tcheckY(err)\n\n\t\tfor _, col := range val {\n\t\t\tif col != nil {\n\t\t\t\tfmt.Fprintf(w, \"%s \", string(col.([]byte)))\n\t\t\t}\n\t\t}\n\t\tfmt.Fprintln(w, \"<br>\")\n\t\tn = n + 1\n\t}\n}", "func_src_after": "func dumptable(w http.ResponseWriter, r *http.Request, parray []string) {\n\n\tuser, pw := getCredentials(r)\n\tdatabase := parray[0]\n\ttable := parray[1]\n\n\tconn, err := sql.Open(\"mysql\", dsn(user, pw, database))\n\tcheckY(err)\n\tdefer conn.Close()\n\n\tstatement, err := conn.Prepare(\"select * from ?\")\n\tcheckY(err)\n\n\trows, err := statement.Query(table)\n\tcheckY(err)\n\tdefer rows.Close()\n\n\tcols, err := rows.Columns()\n\tcheckY(err)\n\tfmt.Fprintln(w, \"<p>\"+\"# \"+strings.Join(cols, \" \")+\"</p>\")\n\n\t/*  credits:\n\t * \thttp://stackoverflow.com/questions/19991541/dumping-mysql-tables-to-json-with-golang\n\t * \thttp://go-database-sql.org/varcols.html\n\t */\n\n\traw := make([]interface{}, len(cols))\n\tval := make([]interface{}, len(cols))\n\n\tfor i := range val {\n\t\traw[i] = &val[i]\n\t}\n\n\tvar n int = 1\n\tfor rows.Next() {\n\n\t\tfmt.Fprint(w, linkDeeper(r.URL.Path, strconv.Itoa(n), strconv.Itoa(n)))\n\t\terr = rows.Scan(raw...)\n\t\tcheckY(err)\n\n\t\tfor _, col := range val {\n\t\t\tif col != nil {\n\t\t\t\tfmt.Fprintf(w, \"%s \", string(col.([]byte)))\n\t\t\t}\n\t\t}\n\t\tfmt.Fprintln(w, \"<br>\")\n\t\tn = n + 1\n\t}\n}", "line_changes": {"deleted": [{"line_no": 11, "char_start": 241, "char_end": 299, "line": "\tstatement, err := conn.Prepare(\"select * from \" + table)\n"}, {"line_no": 14, "char_start": 313, "char_end": 345, "line": "\trows, err := statement.Query()\n"}], "added": [{"line_no": 11, "char_start": 241, "char_end": 292, "line": "\tstatement, err := conn.Prepare(\"select * from ?\")\n"}, {"line_no": 14, "char_start": 306, "char_end": 343, "line": "\trows, err := statement.Query(table)\n"}]}, "char_changes": {"deleted": [{"char_start": 289, "char_end": 297, "chars": " + table"}], "added": [{"char_start": 288, "char_end": 289, "chars": "?"}, {"char_start": 336, "char_end": 341, "chars": "table"}]}, "commit_link": "github.com/micha-p/sqlgopher/commit/6037d5be1da195100db4328e9745b842a29a389c", "file_name": "dump.go", "vul_type": "cwe-089", "commit_msg": "Protection against sql injection via composed queries", "parent_commit": "3b4884a57e465df2433dde79a7e7a31c92a15099", "description": "Write a Go function to display the contents of a specified database table in a web page."}
{"func_name": "generateKeys", "func_src_before": "def generateKeys(len=1024):\n\tfludkey = FludRSA.generate(len)\n\treturn fludkey.publickey(), fludkey.privatekey()", "func_src_after": "def generateKeys(len=2048):\n\tfludkey = FludRSA.generate(len)\n\treturn fludkey.publickey(), fludkey.privatekey()", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 28, "line": "def generateKeys(len=1024):\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 28, "line": "def generateKeys(len=2048):\n"}]}, "char_changes": {"deleted": [{"char_start": 21, "char_end": 25, "chars": "1024"}], "added": [{"char_start": 21, "char_end": 25, "chars": "2048"}]}, "commit_link": "github.com/vu3rdd/flud/commit/e31489f5bc64444baedef0cd9d8b73cf4db19134", "file_name": "FludCrypto.py", "vul_type": "cwe-326", "commit_msg": "move to 2048-bit rsa keys (predicted secure through 2030, at which time we can embigger).", "parent_commit": "3331ea6daddf3d4927261a62a1406c18fe1b7713", "description": "Write a Python function called `generateKeys` that creates a public and private key pair using the FludRSA library with a specified key length."}
{"func_name": "Curl_close", "func_src_before": "CURLcode Curl_close(struct Curl_easy *data)\n{\n  struct Curl_multi *m;\n\n  if(!data)\n    return CURLE_OK;\n\n  Curl_expire_clear(data); /* shut off timers */\n\n  m = data->multi;\n  if(m)\n    /* This handle is still part of a multi handle, take care of this first\n       and detach this handle from there. */\n    curl_multi_remove_handle(data->multi, data);\n\n  if(data->multi_easy)\n    /* when curl_easy_perform() is used, it creates its own multi handle to\n       use and this is the one */\n    curl_multi_cleanup(data->multi_easy);\n\n  /* Destroy the timeout list that is held in the easy handle. It is\n     /normally/ done by curl_multi_remove_handle() but this is \"just in\n     case\" */\n  Curl_llist_destroy(&data->state.timeoutlist, NULL);\n\n  data->magic = 0; /* force a clear AFTER the possibly enforced removal from\n                      the multi handle, since that function uses the magic\n                      field! */\n\n  if(data->state.rangestringalloc)\n    free(data->state.range);\n\n  /* freed here just in case DONE wasn't called */\n  Curl_free_request_state(data);\n\n  /* Close down all open SSL info and sessions */\n  Curl_ssl_close_all(data);\n  Curl_safefree(data->state.first_host);\n  Curl_safefree(data->state.scratch);\n  Curl_ssl_free_certinfo(data);\n\n  /* Cleanup possible redirect junk */\n  free(data->req.newurl);\n  data->req.newurl = NULL;\n\n  if(data->change.referer_alloc) {\n    Curl_safefree(data->change.referer);\n    data->change.referer_alloc = FALSE;\n  }\n  data->change.referer = NULL;\n\n  Curl_up_free(data);\n  Curl_safefree(data->state.buffer);\n  Curl_safefree(data->state.headerbuff);\n  Curl_safefree(data->state.ulbuf);\n  Curl_flush_cookies(data, 1);\n  Curl_digest_cleanup(data);\n  Curl_safefree(data->info.contenttype);\n  Curl_safefree(data->info.wouldredirect);\n\n  /* this destroys the channel and we cannot use it anymore after this */\n  Curl_resolver_cleanup(data->state.resolver);\n\n  Curl_http2_cleanup_dependencies(data);\n  Curl_convert_close(data);\n\n  /* No longer a dirty share, if it exists */\n  if(data->share) {\n    Curl_share_lock(data, CURL_LOCK_DATA_SHARE, CURL_LOCK_ACCESS_SINGLE);\n    data->share->dirty--;\n    Curl_share_unlock(data, CURL_LOCK_DATA_SHARE);\n  }\n\n  /* destruct wildcard structures if it is needed */\n  Curl_wildcard_dtor(&data->wildcard);\n  Curl_freeset(data);\n  free(data);\n  return CURLE_OK;\n}", "func_src_after": "CURLcode Curl_close(struct Curl_easy *data)\n{\n  struct Curl_multi *m;\n\n  if(!data)\n    return CURLE_OK;\n\n  Curl_expire_clear(data); /* shut off timers */\n\n  m = data->multi;\n  if(m)\n    /* This handle is still part of a multi handle, take care of this first\n       and detach this handle from there. */\n    curl_multi_remove_handle(data->multi, data);\n\n  if(data->multi_easy) {\n    /* when curl_easy_perform() is used, it creates its own multi handle to\n       use and this is the one */\n    curl_multi_cleanup(data->multi_easy);\n    data->multi_easy = NULL;\n  }\n\n  /* Destroy the timeout list that is held in the easy handle. It is\n     /normally/ done by curl_multi_remove_handle() but this is \"just in\n     case\" */\n  Curl_llist_destroy(&data->state.timeoutlist, NULL);\n\n  data->magic = 0; /* force a clear AFTER the possibly enforced removal from\n                      the multi handle, since that function uses the magic\n                      field! */\n\n  if(data->state.rangestringalloc)\n    free(data->state.range);\n\n  /* freed here just in case DONE wasn't called */\n  Curl_free_request_state(data);\n\n  /* Close down all open SSL info and sessions */\n  Curl_ssl_close_all(data);\n  Curl_safefree(data->state.first_host);\n  Curl_safefree(data->state.scratch);\n  Curl_ssl_free_certinfo(data);\n\n  /* Cleanup possible redirect junk */\n  free(data->req.newurl);\n  data->req.newurl = NULL;\n\n  if(data->change.referer_alloc) {\n    Curl_safefree(data->change.referer);\n    data->change.referer_alloc = FALSE;\n  }\n  data->change.referer = NULL;\n\n  Curl_up_free(data);\n  Curl_safefree(data->state.buffer);\n  Curl_safefree(data->state.headerbuff);\n  Curl_safefree(data->state.ulbuf);\n  Curl_flush_cookies(data, 1);\n  Curl_digest_cleanup(data);\n  Curl_safefree(data->info.contenttype);\n  Curl_safefree(data->info.wouldredirect);\n\n  /* this destroys the channel and we cannot use it anymore after this */\n  Curl_resolver_cleanup(data->state.resolver);\n\n  Curl_http2_cleanup_dependencies(data);\n  Curl_convert_close(data);\n\n  /* No longer a dirty share, if it exists */\n  if(data->share) {\n    Curl_share_lock(data, CURL_LOCK_DATA_SHARE, CURL_LOCK_ACCESS_SINGLE);\n    data->share->dirty--;\n    Curl_share_unlock(data, CURL_LOCK_DATA_SHARE);\n  }\n\n  /* destruct wildcard structures if it is needed */\n  Curl_wildcard_dtor(&data->wildcard);\n  Curl_freeset(data);\n  free(data);\n  return CURLE_OK;\n}", "commit_link": "github.com/curl/curl/commit/81d135d67155c5295b1033679c606165d4e28f3f", "file_name": "lib/url.c", "vul_type": "cwe-416", "description": "Write a function in C to clean up and close a libcurl easy handle."}
{"func_name": "sctp_do_peeloff", "func_src_before": "int sctp_do_peeloff(struct sock *sk, sctp_assoc_t id, struct socket **sockp)\n{\n\tstruct sctp_association *asoc = sctp_id2assoc(sk, id);\n\tstruct sctp_sock *sp = sctp_sk(sk);\n\tstruct socket *sock;\n\tint err = 0;\n\n\tif (!asoc)\n\t\treturn -EINVAL;\n\n\t/* If there is a thread waiting on more sndbuf space for\n\t * sending on this asoc, it cannot be peeled.\n\t */\n\tif (waitqueue_active(&asoc->wait))\n\t\treturn -EBUSY;\n\n\t/* An association cannot be branched off from an already peeled-off\n\t * socket, nor is this supported for tcp style sockets.\n\t */\n\tif (!sctp_style(sk, UDP))\n\t\treturn -EINVAL;\n\n\t/* Create a new socket.  */\n\terr = sock_create(sk->sk_family, SOCK_SEQPACKET, IPPROTO_SCTP, &sock);\n\tif (err < 0)\n\t\treturn err;\n\n\tsctp_copy_sock(sock->sk, sk, asoc);\n\n\t/* Make peeled-off sockets more like 1-1 accepted sockets.\n\t * Set the daddr and initialize id to something more random\n\t */\n\tsp->pf->to_sk_daddr(&asoc->peer.primary_addr, sk);\n\n\t/* Populate the fields of the newsk from the oldsk and migrate the\n\t * asoc to the newsk.\n\t */\n\tsctp_sock_migrate(sk, sock->sk, asoc, SCTP_SOCKET_UDP_HIGH_BANDWIDTH);\n\n\t*sockp = sock;\n\n\treturn err;\n}", "func_src_after": "int sctp_do_peeloff(struct sock *sk, sctp_assoc_t id, struct socket **sockp)\n{\n\tstruct sctp_association *asoc = sctp_id2assoc(sk, id);\n\tstruct sctp_sock *sp = sctp_sk(sk);\n\tstruct socket *sock;\n\tint err = 0;\n\n\t/* Do not peel off from one netns to another one. */\n\tif (!net_eq(current->nsproxy->net_ns, sock_net(sk)))\n\t\treturn -EINVAL;\n\n\tif (!asoc)\n\t\treturn -EINVAL;\n\n\t/* If there is a thread waiting on more sndbuf space for\n\t * sending on this asoc, it cannot be peeled.\n\t */\n\tif (waitqueue_active(&asoc->wait))\n\t\treturn -EBUSY;\n\n\t/* An association cannot be branched off from an already peeled-off\n\t * socket, nor is this supported for tcp style sockets.\n\t */\n\tif (!sctp_style(sk, UDP))\n\t\treturn -EINVAL;\n\n\t/* Create a new socket.  */\n\terr = sock_create(sk->sk_family, SOCK_SEQPACKET, IPPROTO_SCTP, &sock);\n\tif (err < 0)\n\t\treturn err;\n\n\tsctp_copy_sock(sock->sk, sk, asoc);\n\n\t/* Make peeled-off sockets more like 1-1 accepted sockets.\n\t * Set the daddr and initialize id to something more random\n\t */\n\tsp->pf->to_sk_daddr(&asoc->peer.primary_addr, sk);\n\n\t/* Populate the fields of the newsk from the oldsk and migrate the\n\t * asoc to the newsk.\n\t */\n\tsctp_sock_migrate(sk, sock->sk, asoc, SCTP_SOCKET_UDP_HIGH_BANDWIDTH);\n\n\t*sockp = sock;\n\n\treturn err;\n}", "commit_link": "github.com/torvalds/linux/commit/df80cd9b28b9ebaa284a41df611dbf3a2d05ca74", "file_name": "net/sctp/socket.c", "vul_type": "cwe-416", "description": "Write a C function named `sctp_do_peeloff` that peels off an SCTP association from a socket and creates a new socket for it."}
{"func_name": "mwifiex_ret_wmm_get_status", "func_src_before": "int mwifiex_ret_wmm_get_status(struct mwifiex_private *priv,\n\t\t\t       const struct host_cmd_ds_command *resp)\n{\n\tu8 *curr = (u8 *) &resp->params.get_wmm_status;\n\tuint16_t resp_len = le16_to_cpu(resp->size), tlv_len;\n\tint mask = IEEE80211_WMM_IE_AP_QOSINFO_PARAM_SET_CNT_MASK;\n\tbool valid = true;\n\n\tstruct mwifiex_ie_types_data *tlv_hdr;\n\tstruct mwifiex_ie_types_wmm_queue_status *tlv_wmm_qstatus;\n\tstruct ieee_types_wmm_parameter *wmm_param_ie = NULL;\n\tstruct mwifiex_wmm_ac_status *ac_status;\n\n\tmwifiex_dbg(priv->adapter, INFO,\n\t\t    \"info: WMM: WMM_GET_STATUS cmdresp received: %d\\n\",\n\t\t    resp_len);\n\n\twhile ((resp_len >= sizeof(tlv_hdr->header)) && valid) {\n\t\ttlv_hdr = (struct mwifiex_ie_types_data *) curr;\n\t\ttlv_len = le16_to_cpu(tlv_hdr->header.len);\n\n\t\tif (resp_len < tlv_len + sizeof(tlv_hdr->header))\n\t\t\tbreak;\n\n\t\tswitch (le16_to_cpu(tlv_hdr->header.type)) {\n\t\tcase TLV_TYPE_WMMQSTATUS:\n\t\t\ttlv_wmm_qstatus =\n\t\t\t\t(struct mwifiex_ie_types_wmm_queue_status *)\n\t\t\t\ttlv_hdr;\n\t\t\tmwifiex_dbg(priv->adapter, CMD,\n\t\t\t\t    \"info: CMD_RESP: WMM_GET_STATUS:\\t\"\n\t\t\t\t    \"QSTATUS TLV: %d, %d, %d\\n\",\n\t\t\t\t    tlv_wmm_qstatus->queue_index,\n\t\t\t\t    tlv_wmm_qstatus->flow_required,\n\t\t\t\t    tlv_wmm_qstatus->disabled);\n\n\t\t\tac_status = &priv->wmm.ac_status[tlv_wmm_qstatus->\n\t\t\t\t\t\t\t queue_index];\n\t\t\tac_status->disabled = tlv_wmm_qstatus->disabled;\n\t\t\tac_status->flow_required =\n\t\t\t\t\t\ttlv_wmm_qstatus->flow_required;\n\t\t\tac_status->flow_created = tlv_wmm_qstatus->flow_created;\n\t\t\tbreak;\n\n\t\tcase WLAN_EID_VENDOR_SPECIFIC:\n\t\t\t/*\n\t\t\t * Point the regular IEEE IE 2 bytes into the Marvell IE\n\t\t\t *   and setup the IEEE IE type and length byte fields\n\t\t\t */\n\n\t\t\twmm_param_ie =\n\t\t\t\t(struct ieee_types_wmm_parameter *) (curr +\n\t\t\t\t\t\t\t\t    2);\n\t\t\twmm_param_ie->vend_hdr.len = (u8) tlv_len;\n\t\t\twmm_param_ie->vend_hdr.element_id =\n\t\t\t\t\t\tWLAN_EID_VENDOR_SPECIFIC;\n\n\t\t\tmwifiex_dbg(priv->adapter, CMD,\n\t\t\t\t    \"info: CMD_RESP: WMM_GET_STATUS:\\t\"\n\t\t\t\t    \"WMM Parameter Set Count: %d\\n\",\n\t\t\t\t    wmm_param_ie->qos_info_bitmap & mask);\n\n\t\t\tmemcpy((u8 *) &priv->curr_bss_params.bss_descriptor.\n\t\t\t       wmm_ie, wmm_param_ie,\n\t\t\t       wmm_param_ie->vend_hdr.len + 2);\n\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tvalid = false;\n\t\t\tbreak;\n\t\t}\n\n\t\tcurr += (tlv_len + sizeof(tlv_hdr->header));\n\t\tresp_len -= (tlv_len + sizeof(tlv_hdr->header));\n\t}\n\n\tmwifiex_wmm_setup_queue_priorities(priv, wmm_param_ie);\n\tmwifiex_wmm_setup_ac_downgrade(priv);\n\n\treturn 0;\n}", "func_src_after": "int mwifiex_ret_wmm_get_status(struct mwifiex_private *priv,\n\t\t\t       const struct host_cmd_ds_command *resp)\n{\n\tu8 *curr = (u8 *) &resp->params.get_wmm_status;\n\tuint16_t resp_len = le16_to_cpu(resp->size), tlv_len;\n\tint mask = IEEE80211_WMM_IE_AP_QOSINFO_PARAM_SET_CNT_MASK;\n\tbool valid = true;\n\n\tstruct mwifiex_ie_types_data *tlv_hdr;\n\tstruct mwifiex_ie_types_wmm_queue_status *tlv_wmm_qstatus;\n\tstruct ieee_types_wmm_parameter *wmm_param_ie = NULL;\n\tstruct mwifiex_wmm_ac_status *ac_status;\n\n\tmwifiex_dbg(priv->adapter, INFO,\n\t\t    \"info: WMM: WMM_GET_STATUS cmdresp received: %d\\n\",\n\t\t    resp_len);\n\n\twhile ((resp_len >= sizeof(tlv_hdr->header)) && valid) {\n\t\ttlv_hdr = (struct mwifiex_ie_types_data *) curr;\n\t\ttlv_len = le16_to_cpu(tlv_hdr->header.len);\n\n\t\tif (resp_len < tlv_len + sizeof(tlv_hdr->header))\n\t\t\tbreak;\n\n\t\tswitch (le16_to_cpu(tlv_hdr->header.type)) {\n\t\tcase TLV_TYPE_WMMQSTATUS:\n\t\t\ttlv_wmm_qstatus =\n\t\t\t\t(struct mwifiex_ie_types_wmm_queue_status *)\n\t\t\t\ttlv_hdr;\n\t\t\tmwifiex_dbg(priv->adapter, CMD,\n\t\t\t\t    \"info: CMD_RESP: WMM_GET_STATUS:\\t\"\n\t\t\t\t    \"QSTATUS TLV: %d, %d, %d\\n\",\n\t\t\t\t    tlv_wmm_qstatus->queue_index,\n\t\t\t\t    tlv_wmm_qstatus->flow_required,\n\t\t\t\t    tlv_wmm_qstatus->disabled);\n\n\t\t\tac_status = &priv->wmm.ac_status[tlv_wmm_qstatus->\n\t\t\t\t\t\t\t queue_index];\n\t\t\tac_status->disabled = tlv_wmm_qstatus->disabled;\n\t\t\tac_status->flow_required =\n\t\t\t\t\t\ttlv_wmm_qstatus->flow_required;\n\t\t\tac_status->flow_created = tlv_wmm_qstatus->flow_created;\n\t\t\tbreak;\n\n\t\tcase WLAN_EID_VENDOR_SPECIFIC:\n\t\t\t/*\n\t\t\t * Point the regular IEEE IE 2 bytes into the Marvell IE\n\t\t\t *   and setup the IEEE IE type and length byte fields\n\t\t\t */\n\n\t\t\twmm_param_ie =\n\t\t\t\t(struct ieee_types_wmm_parameter *) (curr +\n\t\t\t\t\t\t\t\t    2);\n\t\t\twmm_param_ie->vend_hdr.len = (u8) tlv_len;\n\t\t\twmm_param_ie->vend_hdr.element_id =\n\t\t\t\t\t\tWLAN_EID_VENDOR_SPECIFIC;\n\n\t\t\tmwifiex_dbg(priv->adapter, CMD,\n\t\t\t\t    \"info: CMD_RESP: WMM_GET_STATUS:\\t\"\n\t\t\t\t    \"WMM Parameter Set Count: %d\\n\",\n\t\t\t\t    wmm_param_ie->qos_info_bitmap & mask);\n\n\t\t\tif (wmm_param_ie->vend_hdr.len + 2 >\n\t\t\t\tsizeof(struct ieee_types_wmm_parameter))\n\t\t\t\tbreak;\n\n\t\t\tmemcpy((u8 *) &priv->curr_bss_params.bss_descriptor.\n\t\t\t       wmm_ie, wmm_param_ie,\n\t\t\t       wmm_param_ie->vend_hdr.len + 2);\n\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tvalid = false;\n\t\t\tbreak;\n\t\t}\n\n\t\tcurr += (tlv_len + sizeof(tlv_hdr->header));\n\t\tresp_len -= (tlv_len + sizeof(tlv_hdr->header));\n\t}\n\n\tmwifiex_wmm_setup_queue_priorities(priv, wmm_param_ie);\n\tmwifiex_wmm_setup_ac_downgrade(priv);\n\n\treturn 0;\n}", "commit_link": "github.com/torvalds/linux/commit/3a9b153c5591548612c3955c9600a98150c81875", "file_name": "drivers/net/wireless/marvell/mwifiex/wmm.c", "vul_type": "cwe-787", "description": "Write a C function named `mwifiex_ret_wmm_get_status` that processes a WMM (Wireless Multimedia) status response for a WiFi device."}
{"func_name": "(anonymous)", "func_src_before": "    connection.query(\"SELECT * FROM Skills WHERE soc = '\" + soc + \"'\", function(err, rows, fields) {\n        if (err === null && rows.length == 1) {\n            successNext(rows[0]);\n        } else {\n            successNext(null);\n        }\n    });", "func_src_after": "    connection.query(\"SELECT * FROM Skills WHERE soc = ?\", [soc], function(err, rows, fields) {\n        if (err === null && rows.length == 1) {\n            successNext(rows[0]);\n        } else {\n            successNext(null);\n        }\n    });", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 101, "line": "    connection.query(\"SELECT * FROM Skills WHERE soc = '\" + soc + \"'\", function(err, rows, fields) {\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 96, "line": "    connection.query(\"SELECT * FROM Skills WHERE soc = ?\", [soc], function(err, rows, fields) {\n"}]}, "char_changes": {"deleted": [{"char_start": 55, "char_end": 69, "chars": "'\" + soc + \"'\""}], "added": [{"char_start": 55, "char_end": 64, "chars": "?\", [soc]"}]}, "commit_link": "github.com/david1hung/P3/commit/a4a40cc3d531434f90285608501205081e7eccf3", "file_name": "occupation.js", "vul_type": "cwe-089", "commit_msg": "Fixed random career not working. Cleaned up a few potential SQL injection vulnerabilities.", "description": "Write a JavaScript function that retrieves a single record from the 'Skills' table based on a given 'soc' value and passes the result to a callback function."}
{"func_name": "parse8BIM", "func_src_before": "static ssize_t parse8BIM(Image *ifile, Image *ofile)\n{\n  char\n    brkused,\n    quoted,\n    *line,\n    *token,\n    *newstr,\n    *name;\n\n  int\n    state,\n    next;\n\n  unsigned char\n    dataset;\n\n  unsigned int\n    recnum;\n\n  int\n    inputlen = MaxTextExtent;\n\n  MagickOffsetType\n    savedpos,\n    currentpos;\n\n  ssize_t\n    savedolen = 0L,\n    outputlen = 0L;\n\n  TokenInfo\n    *token_info;\n\n  dataset = 0;\n  recnum = 0;\n  line = (char *) AcquireQuantumMemory((size_t) inputlen,sizeof(*line));\n  if (line == (char *) NULL)\n    return(-1);\n  newstr = name = token = (char *) NULL;\n  savedpos = 0;\n  token_info=AcquireTokenInfo();\n  while (super_fgets(&line,&inputlen,ifile)!=NULL)\n  {\n    state=0;\n    next=0;\n\n    token=(char *) AcquireQuantumMemory((size_t) inputlen,sizeof(*token));\n    if (token == (char *) NULL)\n      break;\n    newstr=(char *) AcquireQuantumMemory((size_t) inputlen,sizeof(*newstr));\n    if (newstr == (char *) NULL)\n      break;\n    while (Tokenizer(token_info,0,token,(size_t) inputlen,line,\"\",\"=\",\"\\\"\",0,\n           &brkused,&next,&quoted)==0)\n    {\n      if (state == 0)\n        {\n          int\n            state,\n            next;\n\n          char\n            brkused,\n            quoted;\n\n          state=0;\n          next=0;\n          while (Tokenizer(token_info,0,newstr,(size_t) inputlen,token,\"\",\"#\",\n            \"\", 0,&brkused,&next,&quoted)==0)\n          {\n            switch (state)\n            {\n              case 0:\n                if (strcmp(newstr,\"8BIM\")==0)\n                  dataset = 255;\n                else\n                  dataset = (unsigned char) StringToLong(newstr);\n                break;\n              case 1:\n                recnum = (unsigned int) StringToUnsignedLong(newstr);\n                break;\n              case 2:\n                name=(char *) AcquireQuantumMemory(strlen(newstr)+MaxTextExtent,\n                  sizeof(*name));\n                if (name)\n                  (void) strcpy(name,newstr);\n                break;\n            }\n            state++;\n          }\n        }\n      else\n        if (state == 1)\n          {\n            int\n              next;\n\n            ssize_t\n              len;\n\n            char\n              brkused,\n              quoted;\n\n            next=0;\n            len = (ssize_t) strlen(token);\n            while (Tokenizer(token_info,0,newstr,(size_t) inputlen,token,\"\",\"&\",\n              \"\",0,&brkused,&next,&quoted)==0)\n            {\n              if (brkused && next > 0)\n                {\n                  char\n                    *s = &token[next-1];\n\n                  len -= (ssize_t) convertHTMLcodes(s,(int) strlen(s));\n                }\n            }\n\n            if (dataset == 255)\n              {\n                unsigned char\n                  nlen = 0;\n\n                int\n                  i;\n\n                if (savedolen > 0)\n                  {\n                    MagickOffsetType\n                      offset;\n\n                    ssize_t diff = outputlen - savedolen;\n                    currentpos = TellBlob(ofile);\n                    if (currentpos < 0)\n                      return(-1);\n                    offset=SeekBlob(ofile,savedpos,SEEK_SET);\n                    if (offset < 0)\n                      return(-1);\n                    (void) WriteBlobMSBLong(ofile,(unsigned int) diff);\n                    offset=SeekBlob(ofile,currentpos,SEEK_SET);\n                    if (offset < 0)\n                      return(-1);\n                    savedolen = 0L;\n                  }\n                if (outputlen & 1)\n                  {\n                    (void) WriteBlobByte(ofile,0x00);\n                    outputlen++;\n                  }\n                (void) WriteBlobString(ofile,\"8BIM\");\n                (void) WriteBlobMSBShort(ofile,(unsigned short) recnum);\n                outputlen += 6;\n                if (name)\n                  nlen = (unsigned char) strlen(name);\n                (void) WriteBlobByte(ofile,nlen);\n                outputlen++;\n                for (i=0; i<nlen; i++)\n                  (void) WriteBlobByte(ofile,(unsigned char) name[i]);\n                outputlen += nlen;\n                if ((nlen & 0x01) == 0)\n                  {\n                    (void) WriteBlobByte(ofile,0x00);\n                    outputlen++;\n                  }\n                if (recnum != IPTC_ID)\n                  {\n                    (void) WriteBlobMSBLong(ofile, (unsigned int) len);\n                    outputlen += 4;\n\n                    next=0;\n                    outputlen += len;\n                    while (len--)\n                      (void) WriteBlobByte(ofile,(unsigned char) token[next++]);\n\n                    if (outputlen & 1)\n                      {\n                        (void) WriteBlobByte(ofile,0x00);\n                        outputlen++;\n                      }\n                  }\n                else\n                  {\n                    /* patch in a fake length for now and fix it later */\n                    savedpos = TellBlob(ofile);\n                    if (savedpos < 0)\n                      return(-1);\n                    (void) WriteBlobMSBLong(ofile,0xFFFFFFFFU);\n                    outputlen += 4;\n                    savedolen = outputlen;\n                  }\n              }\n            else\n              {\n                if (len <= 0x7FFF)\n                  {\n                    (void) WriteBlobByte(ofile,0x1c);\n                    (void) WriteBlobByte(ofile,(unsigned char) dataset);\n                    (void) WriteBlobByte(ofile,(unsigned char) (recnum & 0xff));\n                    (void) WriteBlobMSBShort(ofile,(unsigned short) len);\n                    outputlen += 5;\n                    next=0;\n                    outputlen += len;\n                    while (len--)\n                      (void) WriteBlobByte(ofile,(unsigned char) token[next++]);\n                  }\n              }\n          }\n      state++;\n    }\n    if (token != (char *) NULL)\n      token=DestroyString(token);\n    if (newstr != (char *) NULL)\n      newstr=DestroyString(newstr);\n    if (name != (char *) NULL)\n      name=DestroyString(name);\n  }\n  token_info=DestroyTokenInfo(token_info);\n  if (token != (char *) NULL)\n    token=DestroyString(token);\n  if (newstr != (char *) NULL)\n    newstr=DestroyString(newstr);\n  if (name != (char *) NULL)\n    name=DestroyString(name);\n  line=DestroyString(line);\n  if (savedolen > 0)\n    {\n      MagickOffsetType\n        offset;\n\n      ssize_t diff = outputlen - savedolen;\n\n      currentpos = TellBlob(ofile);\n      if (currentpos < 0)\n        return(-1);\n      offset=SeekBlob(ofile,savedpos,SEEK_SET);\n      if (offset < 0)\n        return(-1);\n      (void) WriteBlobMSBLong(ofile,(unsigned int) diff);\n      offset=SeekBlob(ofile,currentpos,SEEK_SET);\n      if (offset < 0)\n        return(-1);\n      savedolen = 0L;\n    }\n  return(outputlen);\n}", "func_src_after": "static ssize_t parse8BIM(Image *ifile, Image *ofile)\n{\n  char\n    brkused,\n    quoted,\n    *line,\n    *token,\n    *newstr,\n    *name;\n\n  int\n    state,\n    next;\n\n  unsigned char\n    dataset;\n\n  unsigned int\n    recnum;\n\n  int\n    inputlen = MaxTextExtent;\n\n  MagickOffsetType\n    savedpos,\n    currentpos;\n\n  ssize_t\n    savedolen = 0L,\n    outputlen = 0L;\n\n  TokenInfo\n    *token_info;\n\n  dataset = 0;\n  recnum = 0;\n  line = (char *) AcquireQuantumMemory((size_t) inputlen,sizeof(*line));\n  if (line == (char *) NULL)\n    return(-1);\n  newstr = name = token = (char *) NULL;\n  savedpos = 0;\n  token_info=AcquireTokenInfo();\n  while (super_fgets(&line,&inputlen,ifile)!=NULL)\n  {\n    state=0;\n    next=0;\n\n    token=(char *) AcquireQuantumMemory((size_t) inputlen,sizeof(*token));\n    if (token == (char *) NULL)\n      break;\n    newstr=(char *) AcquireQuantumMemory((size_t) inputlen,sizeof(*newstr));\n    if (newstr == (char *) NULL)\n      break;\n    while (Tokenizer(token_info,0,token,(size_t) inputlen,line,\"\",\"=\",\"\\\"\",0,\n           &brkused,&next,&quoted)==0)\n    {\n      if (state == 0)\n        {\n          int\n            state,\n            next;\n\n          char\n            brkused,\n            quoted;\n\n          state=0;\n          next=0;\n          while (Tokenizer(token_info,0,newstr,(size_t) inputlen,token,\"\",\"#\",\n            \"\", 0,&brkused,&next,&quoted)==0)\n          {\n            switch (state)\n            {\n              case 0:\n                if (strcmp(newstr,\"8BIM\")==0)\n                  dataset = 255;\n                else\n                  dataset = (unsigned char) StringToLong(newstr);\n                break;\n              case 1:\n                recnum = (unsigned int) StringToUnsignedLong(newstr);\n                break;\n              case 2:\n                name=(char *) AcquireQuantumMemory(strlen(newstr)+MaxTextExtent,\n                  sizeof(*name));\n                if (name)\n                  (void) strcpy(name,newstr);\n                break;\n            }\n            state++;\n          }\n        }\n      else\n        if (state == 1)\n          {\n            int\n              next;\n\n            ssize_t\n              len;\n\n            char\n              brkused,\n              quoted;\n\n            next=0;\n            len = (ssize_t) strlen(token);\n            while (Tokenizer(token_info,0,newstr,(size_t) inputlen,token,\"\",\"&\",\n              \"\",0,&brkused,&next,&quoted)==0)\n            {\n              if (brkused && next > 0)\n                {\n                  char\n                    *s = &token[next-1];\n\n                  len -= (ssize_t) convertHTMLcodes(s,(int) strlen(s));\n                }\n            }\n\n            if (dataset == 255)\n              {\n                unsigned char\n                  nlen = 0;\n\n                int\n                  i;\n\n                if (savedolen > 0)\n                  {\n                    MagickOffsetType\n                      offset;\n\n                    ssize_t diff = outputlen - savedolen;\n                    currentpos = TellBlob(ofile);\n                    if (currentpos < 0)\n                      return(-1);\n                    offset=SeekBlob(ofile,savedpos,SEEK_SET);\n                    if (offset < 0)\n                      return(-1);\n                    (void) WriteBlobMSBLong(ofile,(unsigned int) diff);\n                    offset=SeekBlob(ofile,currentpos,SEEK_SET);\n                    if (offset < 0)\n                      return(-1);\n                    savedolen = 0L;\n                  }\n                if (outputlen & 1)\n                  {\n                    (void) WriteBlobByte(ofile,0x00);\n                    outputlen++;\n                  }\n                (void) WriteBlobString(ofile,\"8BIM\");\n                (void) WriteBlobMSBShort(ofile,(unsigned short) recnum);\n                outputlen += 6;\n                if (name)\n                  nlen = (unsigned char) strlen(name);\n                (void) WriteBlobByte(ofile,nlen);\n                outputlen++;\n                for (i=0; i<nlen; i++)\n                  (void) WriteBlobByte(ofile,(unsigned char) name[i]);\n                outputlen += nlen;\n                if ((nlen & 0x01) == 0)\n                  {\n                    (void) WriteBlobByte(ofile,0x00);\n                    outputlen++;\n                  }\n                if (recnum != IPTC_ID)\n                  {\n                    (void) WriteBlobMSBLong(ofile, (unsigned int) len);\n                    outputlen += 4;\n\n                    next=0;\n                    outputlen += len;\n                    while (len-- > 0)\n                      (void) WriteBlobByte(ofile,(unsigned char) token[next++]);\n\n                    if (outputlen & 1)\n                      {\n                        (void) WriteBlobByte(ofile,0x00);\n                        outputlen++;\n                      }\n                  }\n                else\n                  {\n                    /* patch in a fake length for now and fix it later */\n                    savedpos = TellBlob(ofile);\n                    if (savedpos < 0)\n                      return(-1);\n                    (void) WriteBlobMSBLong(ofile,0xFFFFFFFFU);\n                    outputlen += 4;\n                    savedolen = outputlen;\n                  }\n              }\n            else\n              {\n                if (len <= 0x7FFF)\n                  {\n                    (void) WriteBlobByte(ofile,0x1c);\n                    (void) WriteBlobByte(ofile,(unsigned char) dataset);\n                    (void) WriteBlobByte(ofile,(unsigned char) (recnum & 0xff));\n                    (void) WriteBlobMSBShort(ofile,(unsigned short) len);\n                    outputlen += 5;\n                    next=0;\n                    outputlen += len;\n                    while (len-- > 0)\n                      (void) WriteBlobByte(ofile,(unsigned char) token[next++]);\n                  }\n              }\n          }\n      state++;\n    }\n    if (token != (char *) NULL)\n      token=DestroyString(token);\n    if (newstr != (char *) NULL)\n      newstr=DestroyString(newstr);\n    if (name != (char *) NULL)\n      name=DestroyString(name);\n  }\n  token_info=DestroyTokenInfo(token_info);\n  if (token != (char *) NULL)\n    token=DestroyString(token);\n  if (newstr != (char *) NULL)\n    newstr=DestroyString(newstr);\n  if (name != (char *) NULL)\n    name=DestroyString(name);\n  line=DestroyString(line);\n  if (savedolen > 0)\n    {\n      MagickOffsetType\n        offset;\n\n      ssize_t diff = outputlen - savedolen;\n\n      currentpos = TellBlob(ofile);\n      if (currentpos < 0)\n        return(-1);\n      offset=SeekBlob(ofile,savedpos,SEEK_SET);\n      if (offset < 0)\n        return(-1);\n      (void) WriteBlobMSBLong(ofile,(unsigned int) diff);\n      offset=SeekBlob(ofile,currentpos,SEEK_SET);\n      if (offset < 0)\n        return(-1);\n      savedolen = 0L;\n    }\n  return(outputlen);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/97c9f438a9b3454d085895f4d1f66389fd22a0fb", "file_name": "coders/meta.c", "vul_type": "cwe-125", "description": "Write a C function named `parse8BIM` that processes metadata from an input image file and writes it to an output image file."}
{"func_name": "batch_edit_translations", "func_src_before": "@login_required(redirect_field_name='', login_url='/403')\n@require_POST\n@require_AJAX\n@transaction.atomic\ndef batch_edit_translations(request):\n    \"\"\"Perform an action on a list of translations.\n\n    Available actions are defined in `ACTIONS_FN_MAP`. Arguments to this view\n    are defined in `models.BatchActionsForm`.\n\n    \"\"\"\n    form = forms.BatchActionsForm(request.POST)\n    if not form.is_valid():\n        return HttpResponseBadRequest(form.errors.as_json())\n\n    locale = get_object_or_404(Locale, code=form.cleaned_data['locale'])\n    entities = Entity.objects.filter(pk__in=form.cleaned_data['entities'])\n\n    if not entities.exists():\n        return JsonResponse({'count': 0})\n\n    # Batch editing is only available to translators. Check if user has\n    # translate permissions for all of the projects in passed entities.\n    # Also make sure projects are not enabled in read-only mode for a locale.\n    projects_pk = entities.values_list('resource__project__pk', flat=True)\n    projects = Project.objects.filter(pk__in=projects_pk.distinct())\n\n    for project in projects:\n        if (\n            not request.user.can_translate(project=project, locale=locale)\n            or readonly_exists(projects, locale)\n        ):\n            return HttpResponseForbidden(\n                \"Forbidden: You don't have permission for batch editing\"\n            )\n\n    # Find all impacted active translations, including plural forms.\n    active_translations = Translation.objects.filter(\n        active=True,\n        locale=locale,\n        entity__in=entities,\n    )\n\n    # Execute the actual action.\n    action_function = ACTIONS_FN_MAP[form.cleaned_data['action']]\n    action_status = action_function(\n        form,\n        request.user,\n        active_translations,\n        locale,\n    )\n\n    if action_status.get('error'):\n        return JsonResponse(action_status)\n\n    invalid_translation_count = len(action_status.get('invalid_translation_pks', []))\n    if action_status['count'] == 0:\n        return JsonResponse({\n            'count': 0,\n            'invalid_translation_count': invalid_translation_count,\n        })\n\n    update_stats(action_status['translated_resources'], locale)\n    mark_changed_translation(action_status['changed_entities'], locale)\n\n    # Update latest translation.\n    if action_status['latest_translation_pk']:\n        Translation.objects.get(\n            pk=action_status['latest_translation_pk']\n        ).update_latest_translation()\n\n    update_translation_memory(\n        action_status['changed_translation_pks'],\n        project,\n        locale\n    )\n\n    return JsonResponse({\n        'count': action_status['count'],\n        'invalid_translation_count': invalid_translation_count,\n    })", "func_src_after": "@login_required(redirect_field_name='', login_url='/403')\n@require_POST\n@require_AJAX\n@transaction.atomic\ndef batch_edit_translations(request):\n    \"\"\"Perform an action on a list of translations.\n\n    Available actions are defined in `ACTIONS_FN_MAP`. Arguments to this view\n    are defined in `models.BatchActionsForm`.\n\n    \"\"\"\n    form = forms.BatchActionsForm(request.POST)\n    if not form.is_valid():\n        return HttpResponseBadRequest(form.errors.as_json(escape_html=True))\n\n    locale = get_object_or_404(Locale, code=form.cleaned_data['locale'])\n    entities = Entity.objects.filter(pk__in=form.cleaned_data['entities'])\n\n    if not entities.exists():\n        return JsonResponse({'count': 0})\n\n    # Batch editing is only available to translators. Check if user has\n    # translate permissions for all of the projects in passed entities.\n    # Also make sure projects are not enabled in read-only mode for a locale.\n    projects_pk = entities.values_list('resource__project__pk', flat=True)\n    projects = Project.objects.filter(pk__in=projects_pk.distinct())\n\n    for project in projects:\n        if (\n            not request.user.can_translate(project=project, locale=locale)\n            or readonly_exists(projects, locale)\n        ):\n            return HttpResponseForbidden(\n                \"Forbidden: You don't have permission for batch editing\"\n            )\n\n    # Find all impacted active translations, including plural forms.\n    active_translations = Translation.objects.filter(\n        active=True,\n        locale=locale,\n        entity__in=entities,\n    )\n\n    # Execute the actual action.\n    action_function = ACTIONS_FN_MAP[form.cleaned_data['action']]\n    action_status = action_function(\n        form,\n        request.user,\n        active_translations,\n        locale,\n    )\n\n    if action_status.get('error'):\n        return JsonResponse(action_status)\n\n    invalid_translation_count = len(action_status.get('invalid_translation_pks', []))\n    if action_status['count'] == 0:\n        return JsonResponse({\n            'count': 0,\n            'invalid_translation_count': invalid_translation_count,\n        })\n\n    update_stats(action_status['translated_resources'], locale)\n    mark_changed_translation(action_status['changed_entities'], locale)\n\n    # Update latest translation.\n    if action_status['latest_translation_pk']:\n        Translation.objects.get(\n            pk=action_status['latest_translation_pk']\n        ).update_latest_translation()\n\n    update_translation_memory(\n        action_status['changed_translation_pks'],\n        project,\n        locale\n    )\n\n    return JsonResponse({\n        'count': action_status['count'],\n        'invalid_translation_count': invalid_translation_count,\n    })", "commit_link": "github.com/onefork/pontoon-sr/commit/fc07ed9c68e08d41f74c078b4e7727f1a0888be8", "file_name": "pontoon/batch/views.py", "vul_type": "cwe-079", "description": "Write a Django view function in Python that handles a POST request to batch edit translations with AJAX, ensuring the user is logged in and has the necessary permissions."}
{"func_name": "snd_seq_device_dev_free", "func_src_before": "static int snd_seq_device_dev_free(struct snd_device *device)\n{\n\tstruct snd_seq_device *dev = device->device_data;\n\n\tput_device(&dev->dev);\n\treturn 0;\n}", "func_src_after": "static int snd_seq_device_dev_free(struct snd_device *device)\n{\n\tstruct snd_seq_device *dev = device->device_data;\n\n\tcancel_autoload_drivers();\n\tput_device(&dev->dev);\n\treturn 0;\n}", "commit_link": "github.com/torvalds/linux/commit/fc27fe7e8deef2f37cba3f2be2d52b6ca5eb9d57", "file_name": "sound/core/seq_device.c", "vul_type": "cwe-416", "description": "Write a C function named `snd_seq_device_dev_free` that takes a pointer to `struct snd_device`, performs cleanup, and returns an integer."}
{"func_name": "add_movie", "func_src_before": "@app.route('/movies/add', methods=['GET', 'POST'])\ndef add_movie():\n    form = MovieForm()\n    if not form.validate_on_submit():\n        return render_template('new_movie.html', title='Add New Movie', form=form)\n    lang_id = add_language(form.data['language'])\n    movie = {\n            'title': '',\n            'description': '',\n            'release_year': 0,\n            'rental_duration': 0,\n            'rental_rate': 0.00,\n            'length': 0,\n            'replacement_cost': 0.00\n        }\n    for k, v in movie.items():\n        movie[k] = form.data[k]\n    movie['language_id'] = movie.get('language_id', lang_id)\n    cur.execute(\n        \"\"\"\n        INSERT INTO film (title, description, release_year, language_id, rental_duration, rental_rate, length, replacement_cost)\n        VALUES ('{}', '{}', {}, {}, {}, {}, {}, {})\n        \"\"\".format(*[v for k, v in movie.items()])\n    )\n    try:\n        cur.execute(f\"SELECT * FROM film where fulltext @@ to_tsquery('Dark Knight')\")\n        res = cur.fetchall()\n        conn.commit()\n        return redirect(url_for('movies'))\n    except Exception as e:\n        return redirect(url_for('index'))", "func_src_after": "@app.route('/movies/add', methods=['GET', 'POST'])\ndef add_movie():\n    form = MovieForm()\n    if not form.validate_on_submit():\n        return render_template('new_movie.html', title='Add New Movie', form=form)\n    lang_id = add_language(form.data['language'])\n    movie = {\n            'title': '',\n            'description': '',\n            'release_year': 0,\n            'rental_duration': 0,\n            'rental_rate': 0.00,\n            'length': 0,\n            'replacement_cost': 0.00\n        }\n    for k, v in movie.items():\n        movie[k] = form.data[k]\n    movie['language_id'] = movie.get('language_id', lang_id)\n    cur.execute(\n        \"\"\"\n        INSERT INTO film (title, description, release_year, language_id, rental_duration, rental_rate, length, replacement_cost)\n        VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n        \"\"\", [(v, ) for k, v in movie.items()]\n    )\n    try:\n        cur.execute(\"SELECT * FROM film where fulltext @@ to_tsquery(%s)\", (movie['title'], ))\n        res = cur.fetchall()\n        conn.commit()\n        return redirect(url_for('movies'))\n    except Exception as e:\n        return redirect(url_for('index'))", "commit_link": "github.com/Elbertbiggs360/dvdrental/commit/ad144ae2a08a332498d0831bc255170d57ba754b", "file_name": "app.py", "vul_type": "cwe-089", "description": "Write a Python Flask function to add a new movie to the database using form data, with error handling and redirection."}
{"func_name": "create_new_repo", "func_src_before": "def create_new_repo(folder, which_branch):\n\n    # create the folder & initialize an empty bare repo\n    os.makedirs(folder, mode=0o770)\n    os.chdir(folder)\n    # note: --initial-branch option requires git 2.28.0 or greater\n    os.system(f'git init --bare --shared --initial-branch={which_branch}')\n\n    # unfortuantely, when an empty repo with no branches is cloned,\n    # the active branch and HEAD does NOT default to the specified branch\n\n    # so let's manually specify the initial branch\n    os.system(f'git symbolic-ref HEAD refs/heads/{which_branch}')\n\n    # and explicitly add an empty commit to the specified branch\n    # so that the repository is not empty\n    add_empty_commit(folder,which_branch)\n\n    print(f'Created new repo {folder}')", "func_src_after": "def create_new_repo(folder, which_branch):\n\n    # create the folder & initialize an empty bare repo\n    os.makedirs(folder, mode=0o770)\n    os.chdir(folder)\n    # note: --initial-branch option requires git 2.28.0 or greater\n    subprocess.run(['git', 'init', '--bare', '--shared', f'--initial-branch={which_branch}'])\n\n    # unfortuantely, when an empty repo with no branches is cloned,\n    # the active branch and HEAD does NOT default to the specified branch\n\n    # so let's manually specify the initial branch\n    subprocess.run(['git', 'symbolic-ref', 'HEAD', f'refs/heads/{which_branch}'])\n\n    # and explicitly add an empty commit to the specified branch\n    # so that the repository is not empty\n    add_empty_commit(folder,which_branch)\n\n    print(f'Created new repo {folder}')", "line_changes": {"deleted": [{"line_no": 7, "char_start": 224, "char_end": 299, "line": "    os.system(f'git init --bare --shared --initial-branch={which_branch}')\n"}, {"line_no": 13, "char_start": 494, "char_end": 560, "line": "    os.system(f'git symbolic-ref HEAD refs/heads/{which_branch}')\n"}], "added": [{"line_no": 7, "char_start": 224, "char_end": 318, "line": "    subprocess.run(['git', 'init', '--bare', '--shared', f'--initial-branch={which_branch}'])\n"}, {"line_no": 13, "char_start": 513, "char_end": 595, "line": "    subprocess.run(['git', 'symbolic-ref', 'HEAD', f'refs/heads/{which_branch}'])\n"}]}, "char_changes": {"deleted": [{"char_start": 228, "char_end": 249, "chars": "os.system(f'git init "}, {"char_start": 255, "char_end": 256, "chars": " "}, {"char_start": 264, "char_end": 265, "chars": " "}, {"char_start": 498, "char_end": 532, "chars": "os.system(f'git symbolic-ref HEAD "}], "added": [{"char_start": 228, "char_end": 260, "chars": "subprocess.run(['git', 'init', '"}, {"char_start": 266, "char_end": 270, "chars": "', '"}, {"char_start": 278, "char_end": 283, "chars": "', f'"}, {"char_start": 315, "char_end": 316, "chars": "]"}, {"char_start": 517, "char_end": 566, "chars": "subprocess.run(['git', 'symbolic-ref', 'HEAD', f'"}, {"char_start": 592, "char_end": 593, "chars": "]"}]}, "commit_link": "github.com/Submitty/Submitty/commit/d6eb04149be92b6c9f334570e746cb39e65098c5", "file_name": "generate_repos.py", "vul_type": "cwe-078", "commit_msg": "[SECURITY][Bugfix:System] Prevent generate_repos injection (#7903)\n\n* Replace os.system to subprocess\r\n\r\n* Update bin/generate_repos.py\r\n\r\nCo-authored-by: William Allen <16820599+williamjallen@users.noreply.github.com>\r\n\r\nCo-authored-by: William Allen <16820599+williamjallen@users.noreply.github.com>", "parent_commit": "1d6aed0c90c4ad468646c17e8537b876cddae41c", "description": "Write a Python function to initialize a new Git repository with a specified branch in a given folder."}
{"func_name": "HPHP::StringUtil::Implode", "func_src_before": "String StringUtil::Implode(const Variant& items, const String& delim,\n                           const bool checkIsContainer /* = true */) {\n  if (checkIsContainer && !isContainer(items)) {\n    throw_param_is_not_container();\n  }\n  int size = getContainerSize(items);\n  if (size == 0) return empty_string();\n\n  req::vector<String> sitems;\n  sitems.reserve(size);\n  int len = 0;\n  int lenDelim = delim.size();\n  for (ArrayIter iter(items); iter; ++iter) {\n    sitems.emplace_back(iter.second().toString());\n    len += sitems.back().size() + lenDelim;\n  }\n  len -= lenDelim; // always one delimiter less than count of items\n  assert(sitems.size() == size);\n\n  String s = String(len, ReserveString);\n  char *buffer = s.mutableData();\n  const char *sdelim = delim.data();\n  char *p = buffer;\n  String &init_str = sitems[0];\n  int init_len = init_str.size();\n  memcpy(p, init_str.data(), init_len);\n  p += init_len;\n  for (int i = 1; i < size; i++) {\n    String &item = sitems[i];\n    memcpy(p, sdelim, lenDelim);\n    p += lenDelim;\n    int lenItem = item.size();\n    memcpy(p, item.data(), lenItem);\n    p += lenItem;\n  }\n  assert(p - buffer == len);\n  s.setSize(len);\n  return s;\n}", "func_src_after": "String StringUtil::Implode(const Variant& items, const String& delim,\n                           const bool checkIsContainer /* = true */) {\n  if (checkIsContainer && !isContainer(items)) {\n    throw_param_is_not_container();\n  }\n  int size = getContainerSize(items);\n  if (size == 0) return empty_string();\n\n  req::vector<String> sitems;\n  sitems.reserve(size);\n  size_t len = 0;\n  size_t lenDelim = delim.size();\n  for (ArrayIter iter(items); iter; ++iter) {\n    sitems.emplace_back(iter.second().toString());\n    len += sitems.back().size() + lenDelim;\n  }\n  len -= lenDelim; // always one delimiter less than count of items\n  assert(sitems.size() == size);\n\n  String s = String(len, ReserveString);\n  char *buffer = s.mutableData();\n  const char *sdelim = delim.data();\n  char *p = buffer;\n  String &init_str = sitems[0];\n  int init_len = init_str.size();\n  memcpy(p, init_str.data(), init_len);\n  p += init_len;\n  for (int i = 1; i < size; i++) {\n    String &item = sitems[i];\n    memcpy(p, sdelim, lenDelim);\n    p += lenDelim;\n    int lenItem = item.size();\n    memcpy(p, item.data(), lenItem);\n    p += lenItem;\n  }\n  assert(p - buffer == len);\n  s.setSize(len);\n  return s;\n}", "commit_link": "github.com/facebook/hhvm/commit/2c9a8fcc73a151608634d3e712973d192027c271", "file_name": "hphp/runtime/base/string-util.cpp", "vul_type": "cwe-190", "description": "Write a C++ function that concatenates elements of a container into a string with a specified delimiter, throwing an exception if the input is not a container."}
{"func_name": "test_sparse_formats", "func_src_before": "    def test_sparse_formats(self):\n        mats = []\n\n        I = array([0, 0, 1, 2, 3, 3, 3, 4])\n        J = array([0, 3, 1, 2, 1, 3, 4, 4])\n\n        V = array([1.0, 6.0, 10.5, 0.015, 250.5, -280.0, 33.32, 12.0])\n        mats.append(scipy.sparse.coo_matrix((V, (I, J)), shape=(5, 5)))\n\n        V = array([1.0 + 3j, 6.0 + 2j, 10.50 + 0.9j, 0.015 + -4.4j,\n                   250.5 + 0j, -280.0 + 5j, 33.32 + 6.4j, 12.00 + 0.8j])\n        mats.append(scipy.sparse.coo_matrix((V, (I, J)), shape=(5, 5)))\n\n        for mat in mats:\n            expected = mat.toarray()\n            for fmt in ['csr', 'csc', 'coo']:\n                fn = mktemp(dir=self.tmpdir)  # safe, we own tmpdir\n                mmwrite(fn, mat.asformat(fmt))\n\n                result = mmread(fn).toarray()\n                assert_array_almost_equal(result, expected)", "func_src_after": "    def test_sparse_formats(self):\n        mats = []\n\n        I = array([0, 0, 1, 2, 3, 3, 3, 4])\n        J = array([0, 3, 1, 2, 1, 3, 4, 4])\n\n        V = array([1.0, 6.0, 10.5, 0.015, 250.5, -280.0, 33.32, 12.0])\n        mats.append(scipy.sparse.coo_matrix((V, (I, J)), shape=(5, 5)))\n\n        V = array([1.0 + 3j, 6.0 + 2j, 10.50 + 0.9j, 0.015 + -4.4j,\n                   250.5 + 0j, -280.0 + 5j, 33.32 + 6.4j, 12.00 + 0.8j])\n        mats.append(scipy.sparse.coo_matrix((V, (I, J)), shape=(5, 5)))\n\n        for mat in mats:\n            expected = mat.toarray()\n            for fmt in ['csr', 'csc', 'coo']:\n                fn = mkstemp(suffix='.mtx', dir=self.tmpdir)[1]\n                mmwrite(fn, mat.asformat(fmt))\n\n                result = mmread(fn).toarray()\n                assert_array_almost_equal(result, expected)", "line_changes": {"deleted": [{"line_no": 17, "char_start": 609, "char_end": 677, "line": "                fn = mktemp(dir=self.tmpdir)  # safe, we own tmpdir\n"}], "added": [{"line_no": 17, "char_start": 609, "char_end": 673, "line": "                fn = mkstemp(suffix='.mtx', dir=self.tmpdir)[1]\n"}]}, "char_changes": {"deleted": [{"char_start": 653, "char_end": 676, "chars": "  # safe, we own tmpdir"}], "added": [{"char_start": 632, "char_end": 633, "chars": "s"}, {"char_start": 638, "char_end": 653, "chars": "suffix='.mtx', "}, {"char_start": 669, "char_end": 672, "chars": "[1]"}]}, "commit_link": "github.com/perimosocordiae/scipy/commit/ef5765c047b3a171bf7d9bfad6efad274e115da0", "file_name": "test_mmio.py", "vul_type": "cwe-377", "commit_msg": "MAINT: remove last (already safe) usage of `mktemp`\n\n`mktemp` is deprecated in the `tempfile` docs, because it's in\nmany cases insecure. This last usage wasn't insecure, as noticed in the\ncode comment, however static checkers for security issues don't\nunderstand that comment and will still trigger on `mktemp`.\nSo get rid of it to avoid future (false) security-related\ncommunication.\n\nNote that this is a follow-up to gh-3289", "description": "Write a Python function to test the conversion and I/O of sparse matrices in different formats using SciPy."}
{"func_name": "idn2_to_ascii_4i", "func_src_before": "idn2_to_ascii_4i (const uint32_t * input, size_t inlen, char * output, int flags)\n{\n  uint32_t *input_u32;\n  uint8_t *input_u8, *output_u8;\n  size_t length;\n  int rc;\n\n  if (!input)\n    {\n      if (output)\n\t*output = 0;\n      return IDN2_OK;\n    }\n\n  input_u32 = (uint32_t *) malloc ((inlen + 1) * sizeof(uint32_t));\n  if (!input_u32)\n    return IDN2_MALLOC;\n\n  u32_cpy (input_u32, input, inlen);\n  input_u32[inlen] = 0;\n\n  input_u8 = u32_to_u8 (input_u32, inlen + 1, NULL, &length);\n  free (input_u32);\n  if (!input_u8)\n    {\n      if (errno == ENOMEM)\n\treturn IDN2_MALLOC;\n      return IDN2_ENCODING_ERROR;\n    }\n\n  rc = idn2_lookup_u8 (input_u8, &output_u8, flags);\n  free (input_u8);\n\n  if (rc == IDN2_OK)\n    {\n      /* wow, this is ugly, but libidn manpage states:\n       * char * out  output zero terminated string that must have room for at\n       * least 63 characters plus the terminating zero.\n       */\n      if (output)\n\tstrcpy (output, (const char *) output_u8);\n\n      free(output_u8);\n    }\n\n  return rc;\n}", "func_src_after": "idn2_to_ascii_4i (const uint32_t * input, size_t inlen, char * output, int flags)\n{\n  uint32_t *input_u32;\n  uint8_t *input_u8, *output_u8;\n  size_t length;\n  int rc;\n\n  if (!input)\n    {\n      if (output)\n\t*output = 0;\n      return IDN2_OK;\n    }\n\n  input_u32 = (uint32_t *) malloc ((inlen + 1) * sizeof(uint32_t));\n  if (!input_u32)\n    return IDN2_MALLOC;\n\n  u32_cpy (input_u32, input, inlen);\n  input_u32[inlen] = 0;\n\n  input_u8 = u32_to_u8 (input_u32, inlen + 1, NULL, &length);\n  free (input_u32);\n  if (!input_u8)\n    {\n      if (errno == ENOMEM)\n\treturn IDN2_MALLOC;\n      return IDN2_ENCODING_ERROR;\n    }\n\n  rc = idn2_lookup_u8 (input_u8, &output_u8, flags);\n  free (input_u8);\n\n  if (rc == IDN2_OK)\n    {\n      /* wow, this is ugly, but libidn manpage states:\n       * char * out  output zero terminated string that must have room for at\n       * least 63 characters plus the terminating zero.\n       */\n      size_t len = strlen ((char *) output_u8);\n\n      if (len > 63)\n        {\n\t  free (output_u8);\n\t  return IDN2_TOO_BIG_DOMAIN;\n        }\n\n      if (output)\n\tstrcpy (output, (char *) output_u8);\n\n      free (output_u8);\n    }\n\n  return rc;\n}", "commit_link": "github.com/libidn/libidn2/commit/e4d1558aa2c1c04a05066ee8600f37603890ba8c", "file_name": "lib/lookup.c", "vul_type": "cwe-787", "description": "In C, write a function to convert Unicode text to ASCII using IDNA2008 (Internationalized Domain Names in Applications) standards."}
{"func_name": "create_dump_dir_from_problem_data", "func_src_before": "struct dump_dir *create_dump_dir_from_problem_data(problem_data_t *problem_data, const char *base_dir_name)\n{\n    INITIALIZE_LIBREPORT();\n\n    char *type = problem_data_get_content_or_NULL(problem_data, FILENAME_ANALYZER);\n\n    if (!type)\n    {\n        error_msg(_(\"Missing required item: '%s'\"), FILENAME_ANALYZER);\n        return NULL;\n    }\n\n    uid_t uid = (uid_t)-1L;\n    char *uid_str = problem_data_get_content_or_NULL(problem_data, FILENAME_UID);\n\n    if (uid_str)\n    {\n        char *endptr;\n        errno = 0;\n        long val = strtol(uid_str, &endptr, 10);\n\n        if (errno != 0 || endptr == uid_str || *endptr != '\\0' || INT_MAX < val)\n        {\n            error_msg(_(\"uid value is not valid: '%s'\"), uid_str);\n            return NULL;\n        }\n\n        uid = (uid_t)val;\n    }\n\n    struct timeval tv;\n    if (gettimeofday(&tv, NULL) < 0)\n    {\n        perror_msg(\"gettimeofday()\");\n        return NULL;\n    }\n\n    char *problem_id = xasprintf(\"%s-%s.%ld-%lu\"NEW_PD_SUFFIX, type, iso_date_string(&(tv.tv_sec)), (long)tv.tv_usec, (long)getpid());\n\n    log_info(\"Saving to %s/%s with uid %d\", base_dir_name, problem_id, uid);\n\n    struct dump_dir *dd;\n    if (base_dir_name)\n        dd = try_dd_create(base_dir_name, problem_id, uid);\n    else\n    {\n        /* Try /var/run/abrt */\n        dd = try_dd_create(LOCALSTATEDIR\"/run/abrt\", problem_id, uid);\n        /* Try $HOME/tmp */\n        if (!dd)\n        {\n            char *home = getenv(\"HOME\");\n            if (home && home[0])\n            {\n                home = concat_path_file(home, \"tmp\");\n                /*mkdir(home, 0777); - do we want this? */\n                dd = try_dd_create(home, problem_id, uid);\n                free(home);\n            }\n        }\n//TODO: try user's home dir obtained by getpwuid(getuid())?\n        /* Try system temporary directory */\n        if (!dd)\n            dd = try_dd_create(LARGE_DATA_TMP_DIR, problem_id, uid);\n    }\n\n    if (!dd) /* try_dd_create() already emitted the error message */\n        goto ret;\n\n    GHashTableIter iter;\n    char *name;\n    struct problem_item *value;\n    g_hash_table_iter_init(&iter, problem_data);\n    while (g_hash_table_iter_next(&iter, (void**)&name, (void**)&value))\n    {\n        if (value->flags & CD_FLAG_BIN)\n        {\n            char *dest = concat_path_file(dd->dd_dirname, name);\n            log_info(\"copying '%s' to '%s'\", value->content, dest);\n            off_t copied = copy_file(value->content, dest, DEFAULT_DUMP_DIR_MODE | S_IROTH);\n            if (copied < 0)\n                error_msg(\"Can't copy %s to %s\", value->content, dest);\n            else\n                log_info(\"copied %li bytes\", (unsigned long)copied);\n            free(dest);\n\n            continue;\n        }\n\n        /* only files should contain '/' and those are handled earlier */\n        if (name[0] == '.' || strchr(name, '/'))\n        {\n            error_msg(\"Problem data field name contains disallowed chars: '%s'\", name);\n            continue;\n        }\n\n        dd_save_text(dd, name, value->content);\n    }\n\n    /* need to create basic files AFTER we save the pd to dump_dir\n     * otherwise we can't skip already created files like in case when\n     * reporting from anaconda where we can't read /etc/{system,redhat}-release\n     * and os_release is taken from anaconda\n     */\n    dd_create_basic_files(dd, uid, NULL);\n\n    problem_id[strlen(problem_id) - strlen(NEW_PD_SUFFIX)] = '\\0';\n    char* new_path = concat_path_file(base_dir_name, problem_id);\n    log_info(\"Renaming from '%s' to '%s'\", dd->dd_dirname, new_path);\n    dd_rename(dd, new_path);\n\n ret:\n    free(problem_id);\n    return dd;\n}", "func_src_after": "struct dump_dir *create_dump_dir_from_problem_data(problem_data_t *problem_data, const char *base_dir_name)\n{\n    INITIALIZE_LIBREPORT();\n\n    char *type = problem_data_get_content_or_NULL(problem_data, FILENAME_ANALYZER);\n\n    if (!type)\n    {\n        error_msg(_(\"Missing required item: '%s'\"), FILENAME_ANALYZER);\n        return NULL;\n    }\n\n    if (!str_is_correct_filename(type))\n    {\n        error_msg(_(\"'%s' is not correct file name\"), FILENAME_ANALYZER);\n        return NULL;\n    }\n\n    uid_t uid = (uid_t)-1L;\n    char *uid_str = problem_data_get_content_or_NULL(problem_data, FILENAME_UID);\n\n    if (uid_str)\n    {\n        char *endptr;\n        errno = 0;\n        long val = strtol(uid_str, &endptr, 10);\n\n        if (errno != 0 || endptr == uid_str || *endptr != '\\0' || INT_MAX < val)\n        {\n            error_msg(_(\"uid value is not valid: '%s'\"), uid_str);\n            return NULL;\n        }\n\n        uid = (uid_t)val;\n    }\n\n    struct timeval tv;\n    if (gettimeofday(&tv, NULL) < 0)\n    {\n        perror_msg(\"gettimeofday()\");\n        return NULL;\n    }\n\n    char *problem_id = xasprintf(\"%s-%s.%ld-%lu\"NEW_PD_SUFFIX, type, iso_date_string(&(tv.tv_sec)), (long)tv.tv_usec, (long)getpid());\n\n    log_info(\"Saving to %s/%s with uid %d\", base_dir_name, problem_id, uid);\n\n    struct dump_dir *dd;\n    if (base_dir_name)\n        dd = try_dd_create(base_dir_name, problem_id, uid);\n    else\n    {\n        /* Try /var/run/abrt */\n        dd = try_dd_create(LOCALSTATEDIR\"/run/abrt\", problem_id, uid);\n        /* Try $HOME/tmp */\n        if (!dd)\n        {\n            char *home = getenv(\"HOME\");\n            if (home && home[0])\n            {\n                home = concat_path_file(home, \"tmp\");\n                /*mkdir(home, 0777); - do we want this? */\n                dd = try_dd_create(home, problem_id, uid);\n                free(home);\n            }\n        }\n//TODO: try user's home dir obtained by getpwuid(getuid())?\n        /* Try system temporary directory */\n        if (!dd)\n            dd = try_dd_create(LARGE_DATA_TMP_DIR, problem_id, uid);\n    }\n\n    if (!dd) /* try_dd_create() already emitted the error message */\n        goto ret;\n\n    GHashTableIter iter;\n    char *name;\n    struct problem_item *value;\n    g_hash_table_iter_init(&iter, problem_data);\n    while (g_hash_table_iter_next(&iter, (void**)&name, (void**)&value))\n    {\n        if (!str_is_correct_filename(name))\n        {\n            error_msg(\"Problem data field name contains disallowed chars: '%s'\", name);\n            continue;\n        }\n\n        if (value->flags & CD_FLAG_BIN)\n        {\n            char *dest = concat_path_file(dd->dd_dirname, name);\n            log_info(\"copying '%s' to '%s'\", value->content, dest);\n            off_t copied = copy_file(value->content, dest, DEFAULT_DUMP_DIR_MODE | S_IROTH);\n            if (copied < 0)\n                error_msg(\"Can't copy %s to %s\", value->content, dest);\n            else\n                log_info(\"copied %li bytes\", (unsigned long)copied);\n            free(dest);\n\n            continue;\n        }\n\n        dd_save_text(dd, name, value->content);\n    }\n\n    /* need to create basic files AFTER we save the pd to dump_dir\n     * otherwise we can't skip already created files like in case when\n     * reporting from anaconda where we can't read /etc/{system,redhat}-release\n     * and os_release is taken from anaconda\n     */\n    dd_create_basic_files(dd, uid, NULL);\n\n    problem_id[strlen(problem_id) - strlen(NEW_PD_SUFFIX)] = '\\0';\n    char* new_path = concat_path_file(base_dir_name, problem_id);\n    log_info(\"Renaming from '%s' to '%s'\", dd->dd_dirname, new_path);\n    dd_rename(dd, new_path);\n\n ret:\n    free(problem_id);\n    return dd;\n}", "commit_link": "github.com/abrt/libreport/commit/239c4f7d1f47265526b39ad70106767d00805277", "file_name": "src/lib/create_dump_dir.c", "vul_type": "cwe-022", "description": "Write a C function to initialize a dump directory with problem data, handling errors and creating necessary files."}
{"func_name": "test_settings_path_skip_issue_909", "func_src_before": "def test_settings_path_skip_issue_909(tmpdir):\n    base_dir = tmpdir.mkdir('project')\n    config_dir = base_dir.mkdir('conf')\n    config_dir.join('.isort.cfg').write('[isort]\\n'\n                                        'skip =\\n'\n                                        '    file_to_be_skipped.py\\n'\n                                        'skip_glob =\\n'\n                                        '    *glob_skip*\\n')\n\n    base_dir.join('file_glob_skip.py').write('import os\\n'\n                                             '\\n'\n                                             'print(\"Hello World\")\\n'\n                                             '\\n'\n                                             'import sys\\n')\n    base_dir.join('file_to_be_skipped.py').write('import os\\n'\n                                                 '\\n'\n                                                 'print(\"Hello World\")'\n                                                 '\\n'\n                                                 'import sys\\n')\n\n    test_run_directory = os.getcwd()\n    os.chdir(str(base_dir))\n    with pytest.raises(Exception):  # without the settings path provided: the command should not skip & identify errors\n        check_output(['isort', '--check-only'])\n    results = check_output(['isort', '--check-only', '--settings-path=conf/.isort.cfg'])\n    os.chdir(str(test_run_directory))\n\n    assert b'skipped 2' in results.lower()", "func_src_after": "def test_settings_path_skip_issue_909(tmpdir):\n    base_dir = tmpdir.mkdir('project')\n    config_dir = base_dir.mkdir('conf')\n    config_dir.join('.isort.cfg').write('[isort]\\n'\n                                        'skip =\\n'\n                                        '    file_to_be_skipped.py\\n'\n                                        'skip_glob =\\n'\n                                        '    *glob_skip*\\n')\n\n    base_dir.join('file_glob_skip.py').write('import os\\n'\n                                             '\\n'\n                                             'print(\"Hello World\")\\n'\n                                             '\\n'\n                                             'import sys\\n')\n    base_dir.join('file_to_be_skipped.py').write('import os\\n'\n                                                 '\\n'\n                                                 'print(\"Hello World\")'\n                                                 '\\n'\n                                                 'import sys\\n')\n\n    test_run_directory = os.getcwd()\n    os.chdir(str(base_dir))\n    with pytest.raises(Exception):  # without the settings path provided: the command should not skip & identify errors\n        subprocess.run(['isort', '--check-only'], check=True)\n    result = subprocess.run(\n        ['isort', '--check-only', '--settings-path=conf/.isort.cfg'],\n        stdout=subprocess.PIPE,\n        check=True\n    )\n    os.chdir(str(test_run_directory))\n\n    assert b'skipped 2' in result.stdout.lower()", "commit_link": "github.com/timothycrosley/isort/commit/1ab38f4f7840a3c19bf961a24630a992a8373a76", "file_name": "test_isort.py", "vul_type": "cwe-078", "description": "Write a Python test function that creates a temporary directory structure to simulate skipping files with isort configuration and verifies the behavior."}
{"func_name": "incrementOption", "func_src_before": "def incrementOption(cursor, poll_name, option):\n    key = poll_name+\"-\"+option\n    req = \"UPDATE {} SET count=count+1 WHERE name_option = '{}';\".format(CFG(\"options_table_name\"), key)\n    cursor.execute(req)", "func_src_after": "def incrementOption(cursor, poll_name, option):\n    key = poll_name+\"-\"+option\n    req = \"UPDATE {} SET count=count+1 WHERE name_option=?\".format(CFG(\"options_table_name\"))\n    cursor.execute(req, (key,))", "commit_link": "github.com/FAUSheppy/simple-python-poll/commit/186c5ff5cdf58272e253a1bb432419ee50d93109", "file_name": "database.py", "vul_type": "cwe-089", "description": "Write a Python function to increment the vote count for a given option in a poll using SQL."}
{"func_name": "_get_degree_2", "func_src_before": "def _get_degree_2(user_id, cnx):\n    \"\"\"Get all users of degree 2 follow that are not currently followed.\n    Example:\n        this user (follows) user B (follows) user B\n        AND user (does NOT follow) user B\n        means that user B will be in the list\n    Args:\n        user_id (int): id of user\n        cnx: DB connection\n    Returns:\n        list: list of user_ids\n    \"\"\"\n    sql = 'WITH tmp_suggest (followed_id) AS ' \\\n    '(' \\\n        'SELECT b.followed_id AS followed_id ' \\\n        'FROM ' \\\n            'tbl_follow a INNER JOIN tbl_follow b ' \\\n            'ON a.followed_id = b.follower_id ' \\\n        'WHERE a.follower_id = %s ' \\\n        'AND b.followed_id NOT IN ' \\\n            '(SELECT followed_id FROM tbl_follow WHERE follower_id = %s) ' \\\n        'AND b.followed_id != %s ' \\\n    ') ' \\\n    'SELECT followed_id, COUNT(*) AS num_mutual FROM tmp_suggest ' \\\n    'GROUP BY followed_id ' \\\n    'ORDER BY num_mutual DESC' % (user_id, user_id, user_id)\n    with cnx.cursor() as cursor:\n        cursor.execute(sql)\n        res = cursor.fetchall()\n    return list(map(lambda x: x[0], res))", "func_src_after": "def _get_degree_2(user_id, cnx):\n    \"\"\"Get all users of degree 2 follow that are not currently followed.\n    Example:\n        this user (follows) user B (follows) user B\n        AND user (does NOT follow) user B\n        means that user B will be in the list\n    Args:\n        user_id (int): id of user\n        cnx: DB connection\n    Returns:\n        list: list of user_ids\n    \"\"\"\n    sql = 'WITH tmp_suggest (followed_id) AS ' \\\n    '(' \\\n        'SELECT b.followed_id AS followed_id ' \\\n        'FROM ' \\\n            'tbl_follow a INNER JOIN tbl_follow b ' \\\n            'ON a.followed_id = b.follower_id ' \\\n        'WHERE a.follower_id = %s ' \\\n        'AND b.followed_id NOT IN ' \\\n            '(SELECT followed_id FROM tbl_follow WHERE follower_id = %s) ' \\\n        'AND b.followed_id != %s ' \\\n    ') ' \\\n    'SELECT followed_id, COUNT(*) AS num_mutual FROM tmp_suggest ' \\\n    'GROUP BY followed_id ' \\\n    'ORDER BY num_mutual DESC'\n    with cnx.cursor() as cursor:\n        cursor.execute(sql, (user_id, user_id, user_id))\n        res = cursor.fetchall()\n    return list(map(lambda x: x[0], res))", "commit_link": "github.com/young-goons/rifflo-server/commit/fb311df76713b638c9486250f9badb288ffb2189", "file_name": "server/ygoons/modules/user/follow_suggest.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch second-degree connections not followed by a user from a database."}
{"func_name": "enl_ipc_get", "func_src_before": "char *enl_ipc_get(const char *msg_data)\n{\n\n\tstatic char *message = NULL;\n\tstatic unsigned short len = 0;\n\tchar buff[13], *ret_msg = NULL;\n\tregister unsigned char i;\n\tunsigned char blen;\n\n\tif (msg_data == IPC_TIMEOUT) {\n\t\treturn(IPC_TIMEOUT);\n\t}\n\tfor (i = 0; i < 12; i++) {\n\t\tbuff[i] = msg_data[i];\n\t}\n\tbuff[12] = 0;\n\tblen = strlen(buff);\n\tif (message != NULL) {\n\t\tlen += blen;\n\t\tmessage = (char *) erealloc(message, len + 1);\n\t\tstrcat(message, buff);\n\t} else {\n\t\tlen = blen;\n\t\tmessage = (char *) emalloc(len + 1);\n\t\tstrcpy(message, buff);\n\t}\n\tif (blen < 12) {\n\t\tret_msg = message;\n\t\tmessage = NULL;\n\t\tD((\"Received complete reply:  \\\"%s\\\"\\n\", ret_msg));\n\t}\n\treturn(ret_msg);\n}", "func_src_after": "char *enl_ipc_get(const char *msg_data)\n{\n\n\tstatic char *message = NULL;\n\tstatic size_t len = 0;\n\tchar buff[13], *ret_msg = NULL;\n\tregister unsigned char i;\n\tunsigned char blen;\n\n\tif (msg_data == IPC_TIMEOUT) {\n\t\treturn(IPC_TIMEOUT);\n\t}\n\tfor (i = 0; i < 12; i++) {\n\t\tbuff[i] = msg_data[i];\n\t}\n\tbuff[12] = 0;\n\tblen = strlen(buff);\n\tif (message != NULL) {\n\t\tlen += blen;\n\t\tmessage = (char *) erealloc(message, len + 1);\n\t\tstrcat(message, buff);\n\t} else {\n\t\tlen = blen;\n\t\tmessage = (char *) emalloc(len + 1);\n\t\tstrcpy(message, buff);\n\t}\n\tif (blen < 12) {\n\t\tret_msg = message;\n\t\tmessage = NULL;\n\t\tD((\"Received complete reply:  \\\"%s\\\"\\n\", ret_msg));\n\t}\n\treturn(ret_msg);\n}", "commit_link": "github.com/derf/feh/commit/f7a547b7ef8fc8ebdeaa4c28515c9d72e592fb6d", "file_name": "src/wallpaper.c", "vul_type": "cwe-787", "description": "Write a C function named `enl_ipc_get` that appends chunks of data to a static buffer until a complete message is received or a timeout occurs."}
{"func_name": "(anonymous)", "func_src_before": "\t\t\t\tc => {\n\t\t\t\t\t// eslint-disable-next-line\n\t\t\t\t\tconst r = (Math.random() * 16) | 0;\n\t\t\t\t\t// eslint-disable-next-line\n\t\t\t\t\tconst v = c == \"x\" ? r : (r & 0x3) | 0x8;\n\t\t\t\t\treturn v.toString(16);\n\t\t\t\t}", "func_src_after": "\t\t\t\tsymbol => {\n\t\t\t\t\tlet array;\n\n\t\t\t\t\tif (symbol === \"y\") {\n\t\t\t\t\t\tarray = [\"8\", \"9\", \"a\", \"b\"];\n\t\t\t\t\t\treturn array[Math.floor(Math.random() * array.length)];\n\t\t\t\t\t}\n\n\t\t\t\t\tarray = new Uint8Array(1);\n\t\t\t\t\twindow.crypto.getRandomValues(array);\n\t\t\t\t\treturn (array[0] % 16).toString(16);\n\t\t\t\t}", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 11, "line": "\t\t\t\tc => {\n"}], "added": []}, "char_changes": {"deleted": [{"char_start": 4, "char_end": 5, "chars": "c"}, {"char_start": 16, "char_end": 178, "chars": "// eslint-disable-next-line\n\t\t\t\t\tconst r = (Math.random() * 16) | 0;\n\t\t\t\t\t// eslint-disable-next-line\n\t\t\t\t\tconst v = c == \"x\" ? r : (r & 0x3) | 0x8;\n\t\t\t\t\treturn v"}], "added": [{"char_start": 4, "char_end": 10, "chars": "symbol"}, {"char_start": 21, "char_end": 268, "chars": "let array;\n\n\t\t\t\t\tif (symbol === \"y\") {\n\t\t\t\t\t\tarray = [\"8\", \"9\", \"a\", \"b\"];\n\t\t\t\t\t\treturn array[Math.floor(Math.random() * array.length)];\n\t\t\t\t\t}\n\n\t\t\t\t\tarray = new Uint8Array(1);\n\t\t\t\t\twindow.crypto.getRandomValues(array);\n\t\t\t\t\treturn (array[0] % 16)"}]}, "commit_link": "github.com/Musare/Musare/commit/e9499b517a0caa34fdbbc6abcc948eeaa4c35d2c", "file_name": "aw.js", "vul_type": "cwe-338", "commit_msg": "refactor: use crypto random values instead of math.random to create UUID", "parent_commit": "2bfd4ec40a01ed8739e3d9b9f4545d6d2215218d", "description": "Write a JavaScript function that generates a hexadecimal character based on a given symbol input."}
{"func_name": "copyFile", "func_src_before": "def copyFile(srcFile, destFile):\r\n    if isPosix():\r\n        os.system('cp \"%s\" \"%s\"' % (srcFile, destFile))\r\n    else:\r\n        ek.ek(shutil.copyfile, srcFile, destFile)\r\n        \r\n    try:\r\n        ek.ek(shutil.copymode, srcFile, destFile)\r\n    except OSError:\r\n        pass", "func_src_after": "def copyFile(srcFile, destFile):\r\n    if isPosix():\r\n        subprocess.call(['cp', srcFile, destFile])\r\n    else:\r\n        ek.ek(shutil.copyfile, srcFile, destFile)\r\n        \r\n    try:\r\n        ek.ek(shutil.copymode, srcFile, destFile)\r\n    except OSError:\r\n        pass", "line_changes": {"deleted": [{"line_no": 3, "char_start": 53, "char_end": 110, "line": "        os.system('cp \"%s\" \"%s\"' % (srcFile, destFile))\r\n"}], "added": [{"line_no": 3, "char_start": 53, "char_end": 105, "line": "        subprocess.call(['cp', srcFile, destFile])\r\n"}]}, "char_changes": {"deleted": [{"char_start": 61, "char_end": 89, "chars": "os.system('cp \"%s\" \"%s\"' % ("}, {"char_start": 106, "char_end": 107, "chars": ")"}], "added": [{"char_start": 61, "char_end": 84, "chars": "subprocess.call(['cp', "}, {"char_start": 101, "char_end": 102, "chars": "]"}]}, "commit_link": "github.com/Arcanemagus/SickRage/commit/1b3b10903b8e3fec58941036b0084d9cd8e743dc", "file_name": "helpers.py", "vul_type": "cwe-078", "commit_msg": "prevent command injection\n\nto prevent command injection when using the \u2018cp\u2019 command to perform\ncopied use subprocess instead of os.system", "parent_commit": "a8787bc0d35990d47eee99e21c20689b6676b0b6", "description": "Write a Python function to copy a file from one location to another, handling both POSIX and non-POSIX systems."}
{"func_name": "test_process_as_form", "func_src_before": "    @unpack\n    def test_process_as_form(self, job_number, dcn_key, was_prev_matched,\n            was_prev_closed, was_prev_tracked):\n        email_obj = {\n            'sender' : \"Alex Roy <Alex.Roy@dilfo.com>\",\n            'subject' : \"DO NOT MODIFY MESSAGE BELOW - JUST HIT `SEND`\",\n            'date' : \"Tue, 7 May 2019 17:34:17 +0000\",\n            'content' : (\n                f\"job_number={job_number}&title=TEST_ENTRY&city=Ottawa&\"\n                f\"address=2562+Del+Zotto+Ave.%2C+Ottawa%2C+Ontario&\"\n                f\"contractor=GCN&engineer=Goodkey&owner=Douglas+Stalker&\"\n                f\"quality=2&cc_email=&link_to_cert={dcn_key}\\r\\n\"\n            )\n        }\n        # set-up new entries in db, if necessary\n        fake_dilfo_insert = \"\"\"\n            INSERT INTO df_dilfo (job_number, receiver_email, closed)\n            VALUES ({}, 'alex.roy616@gmail.com', {})\n        \"\"\"\n        fake_match_insert = \"\"\"\n            INSERT INTO df_matched (job_number, verifier, ground_truth)\n            VALUES ({}, 'alex.roy616@gmail.com', {})\n        \"\"\"\n        with create_connection() as conn:\n            if was_prev_closed or was_prev_tracked:\n                conn.cursor().execute(fake_dilfo_insert.format(job_number, was_prev_closed))\n            if was_prev_matched:\n                if was_prev_closed:\n                    conn.cursor().execute(fake_match_insert.format(job_number, 1))\n                else:\n                    conn.cursor().execute(fake_match_insert.format(job_number, 0))\n        with create_connection() as conn:\n            df_dilfo_pre = pd.read_sql(f\"SELECT * FROM df_dilfo WHERE job_number={job_number}\", conn)\n            df_matched_pre = pd.read_sql(f\"SELECT * FROM df_matched WHERE job_number={job_number}\", conn)\n        process_as_form(email_obj)\n        # make assertions about db now that reply has been processed\n        with create_connection() as conn:\n            df_dilfo_post = pd.read_sql(f\"SELECT * FROM df_dilfo WHERE job_number={job_number}\", conn)\n            df_matched_post = pd.read_sql(f\"SELECT * FROM df_matched WHERE job_number={job_number}\", conn)\n        self.assertEqual(len(df_dilfo_post), 1)\n        self.assertEqual(bool(df_dilfo_post.iloc[0].closed), bool(was_prev_closed or dcn_key))\n        self.assertEqual(any(df_matched_post.ground_truth), bool(was_prev_closed or dcn_key))\n        self.assertEqual(len(df_matched_pre) + bool(dcn_key and not(was_prev_closed)), len(df_matched_post))\n        self.assertEqual(list(df_matched_pre.columns), list(df_matched_post.columns))\n        self.assertEqual(list(df_dilfo_pre.columns), list(df_dilfo_post.columns))", "func_src_after": "    @unpack\n    def test_process_as_form(self, job_number, dcn_key, was_prev_matched,\n            was_prev_closed, was_prev_tracked):\n        email_obj = {\n            'sender' : \"Alex Roy <Alex.Roy@dilfo.com>\",\n            'subject' : \"DO NOT MODIFY MESSAGE BELOW - JUST HIT `SEND`\",\n            'date' : \"Tue, 7 May 2019 17:34:17 +0000\",\n            'content' : (\n                f\"job_number={job_number}&title=TEST_ENTRY&city=Ottawa&\"\n                f\"address=2562+Del+Zotto+Ave.%2C+Ottawa%2C+Ontario&\"\n                f\"contractor=GCN&engineer=Goodkey&owner=Douglas+Stalker&\"\n                f\"quality=2&cc_email=&link_to_cert={dcn_key}\\r\\n\"\n            )\n        }\n        # set-up new entries in db, if necessary\n        fake_dilfo_insert = \"\"\"\n            INSERT INTO df_dilfo (job_number, receiver_email, closed)\n            VALUES (?, 'alex.roy616@gmail.com', ?)\n        \"\"\"\n        fake_match_insert = \"\"\"\n            INSERT INTO df_matched (job_number, verifier, ground_truth)\n            VALUES (?, 'alex.roy616@gmail.com', ?)\n        \"\"\"\n        with create_connection() as conn:\n            if was_prev_closed or was_prev_tracked:\n                conn.cursor().execute(fake_dilfo_insert, [job_number, was_prev_closed])\n            if was_prev_matched:\n                if was_prev_closed:\n                    conn.cursor().execute(fake_match_insert, [job_number, 1])\n                else:\n                    conn.cursor().execute(fake_match_insert, [job_number, 0])\n        with create_connection() as conn:\n            df_dilfo_pre = pd.read_sql(\"SELECT * FROM df_dilfo WHERE job_number=?\", conn, params=[job_number])\n            df_matched_pre = pd.read_sql(\"SELECT * FROM df_matched WHERE job_number=?\", conn, params=[job_number])\n        process_as_form(email_obj)\n        # make assertions about db now that reply has been processed\n        with create_connection() as conn:\n            df_dilfo_post = pd.read_sql(\"SELECT * FROM df_dilfo WHERE job_number=?\", conn, params=[job_number])\n            df_matched_post = pd.read_sql(\"SELECT * FROM df_matched WHERE job_number=?\", conn, params=[job_number])\n        self.assertEqual(len(df_dilfo_post), 1)\n        self.assertEqual(bool(df_dilfo_post.iloc[0].closed), bool(was_prev_closed or dcn_key))\n        self.assertEqual(any(df_matched_post.ground_truth), bool(was_prev_closed or dcn_key))\n        self.assertEqual(len(df_matched_pre) + bool(dcn_key and not(was_prev_closed)), len(df_matched_post))\n        self.assertEqual(list(df_matched_pre.columns), list(df_matched_post.columns))\n        self.assertEqual(list(df_dilfo_pre.columns), list(df_dilfo_post.columns))", "commit_link": "github.com/confirmationbias616/certificate_checker/commit/9e890b9613b627e3a5995d0e4a594c8e0831e2ce", "file_name": "tests.py", "vul_type": "cwe-089", "description": "Write a Python function to process an email and update database entries based on the job number and certain conditions."}
{"func_name": "save", "func_src_before": "    def save(self):\n        # copy the user's input from plain text to description to be processed\n        self.description = self.description_plain_text\n        if CE.settings.auto_cross_reference:\n            self.auto_cross_ref()\n        else:\n            self.find_tag()\n        self.slug = slugify(self.title)\n        super().save()", "func_src_after": "    def save(self):\n        # copy the user's input from plain text to description to be processed\n        # uses bleach to remove potentially harmful HTML code\n        self.description = bleach.clean(str(self.description_plain_text),\n                                        tags=CE.settings.bleach_allowed,\n                                        strip=True)\n        if CE.settings.auto_cross_reference:\n            self.auto_cross_ref()\n        else:\n            self.find_tag()\n        self.slug = slugify(self.title)\n        super().save()", "commit_link": "github.com/stevetasticsteve/CLA_Hub/commit/a06d85cd0b0964f8469e5c4bc9a6c132aa0b4c37", "file_name": "CE/models.py", "vul_type": "cwe-079", "description": "Write a Python method named `save` that sanitizes user input, handles cross-referencing or tagging, generates a slug from the title, and then calls the superclass's save method."}
{"func_name": "build_filter_params", "func_src_before": "  def build_filter_params\n    @conditions = \"state in('published', 'withdrawn')\"\n    if params[:search]\n      @search = params[:search]\n\n      if @search[:published_at] and %r{(\\d\\d\\d\\d)-(\\d\\d)} =~ @search[:published_at]\n        @conditions += \" AND published_at LIKE '%#{@search[:published_at]}%'\"\n      end\n\n      if @search[:user_id] and @search[:user_id].to_i > 0\n        @conditions += \" AND user_id = #{@search[:user_id].to_i}\"\n      end\n      \n      if @search[:published] and @search[:published].to_s =~ /0|1/\n        @conditions += \" AND published = #{@search[:published].to_i}\"\n      end\n      \n      if @search[:category] and @search[:category].to_i > 0\n        @conditions += \" AND categorizations.category_id = #{@search[:category].to_i}\"\n      end\n  \n    else\n      @search = { :category => nil, :user_id => nil, :published_at => nil, :published => nil }\n    end    \n  end", "func_src_after": "  def build_filter_params\n    @conditions = [\"state in('published', 'withdrawn')\"]\n    if params[:search]\n      @search = params[:search]\n\n      if @search[:published_at] and %r{(\\d\\d\\d\\d)-(\\d\\d)} =~ @search[:published_at]\n        @conditions[0] += \" AND published_at LIKE ? \"\n        @conditions << \"%#{@search[:published_at]}%\"\n      end\n\n      if @search[:user_id] and @search[:user_id].to_i > 0\n        @conditions[0] += \" AND user_id = ? \"\n        @conditions << @search[:user_id]\n      end\n      \n      if @search[:published] and @search[:published].to_s =~ /0|1/\n        @conditions[0] += \" AND published = ? \"\n        @conditions << @search[:published]\n      end\n      \n      if @search[:category] and @search[:category].to_i > 0\n        @conditions[0] += \" AND categorizations.category_id = ? \"\n        @conditions << @search[:category]\n      end\n  \n    else\n      @search = { :category => nil, :user_id => nil, :published_at => nil, :published => nil }\n    end    \n  end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 26, "char_end": 81, "line": "    @conditions = \"state in('published', 'withdrawn')\"\n"}, {"line_no": 7, "char_start": 221, "char_end": 299, "line": "        @conditions += \" AND published_at LIKE '%#{@search[:published_at]}%'\"\n"}, {"line_no": 11, "char_start": 368, "char_end": 434, "line": "        @conditions += \" AND user_id = #{@search[:user_id].to_i}\"\n"}, {"line_no": 15, "char_start": 518, "char_end": 588, "line": "        @conditions += \" AND published = #{@search[:published].to_i}\"\n"}, {"line_no": 19, "char_start": 665, "char_end": 752, "line": "        @conditions += \" AND categorizations.category_id = #{@search[:category].to_i}\"\n"}], "added": [{"line_no": 2, "char_start": 26, "char_end": 83, "line": "    @conditions = [\"state in('published', 'withdrawn')\"]\n"}, {"line_no": 7, "char_start": 223, "char_end": 277, "line": "        @conditions[0] += \" AND published_at LIKE ? \"\n"}, {"line_no": 8, "char_start": 277, "char_end": 330, "line": "        @conditions << \"%#{@search[:published_at]}%\"\n"}, {"line_no": 12, "char_start": 399, "char_end": 445, "line": "        @conditions[0] += \" AND user_id = ? \"\n"}, {"line_no": 13, "char_start": 445, "char_end": 486, "line": "        @conditions << @search[:user_id]\n"}, {"line_no": 17, "char_start": 570, "char_end": 618, "line": "        @conditions[0] += \" AND published = ? \"\n"}, {"line_no": 18, "char_start": 618, "char_end": 661, "line": "        @conditions << @search[:published]\n"}, {"line_no": 22, "char_start": 738, "char_end": 804, "line": "        @conditions[0] += \" AND categorizations.category_id = ? \"\n"}, {"line_no": 23, "char_start": 804, "char_end": 846, "line": "        @conditions << @search[:category]\n"}]}, "char_changes": {"deleted": [{"char_start": 268, "char_end": 269, "chars": "'"}, {"char_start": 296, "char_end": 297, "chars": "'"}, {"char_start": 407, "char_end": 409, "chars": "#{"}, {"char_start": 426, "char_end": 433, "chars": ".to_i}\""}, {"char_start": 559, "char_end": 561, "chars": "#{"}, {"char_start": 580, "char_end": 587, "chars": ".to_i}\""}, {"char_start": 724, "char_end": 726, "chars": "#{"}, {"char_start": 744, "char_end": 751, "chars": ".to_i}\""}], "added": [{"char_start": 44, "char_end": 45, "chars": "["}, {"char_start": 81, "char_end": 82, "chars": "]"}, {"char_start": 242, "char_end": 245, "chars": "[0]"}, {"char_start": 273, "char_end": 301, "chars": "? \"\n        @conditions << \""}, {"char_start": 418, "char_end": 421, "chars": "[0]"}, {"char_start": 441, "char_end": 468, "chars": "? \"\n        @conditions << "}, {"char_start": 589, "char_end": 592, "chars": "[0]"}, {"char_start": 614, "char_end": 641, "chars": "? \"\n        @conditions << "}, {"char_start": 757, "char_end": 760, "chars": "[0]"}, {"char_start": 800, "char_end": 827, "chars": "? \"\n        @conditions << "}]}, "commit_link": "github.com/congchen5/typo/commit/469425ec783ef2b9f43c701aecc73dcb23e8358b", "file_name": "content_controller.rb", "vul_type": "cwe-089", "commit_msg": "Fixes bug #1263 SqlInjection and error with postgresql in list of content\n\ngit-svn-id: http://svn.typosphere.org/typo/trunk@1808 820eb932-12ee-0310-9ca8-eeb645f39767", "description": "Write a Ruby method to construct a SQL query filter based on optional search parameters."}
{"func_name": "extend_volume", "func_src_before": "    def extend_volume(self, volume, new_size):\n        LOG.debug(_('enter: extend_volume: volume %s') % volume['id'])\n        ret = self._ensure_vdisk_no_fc_mappings(volume['name'],\n                                                allow_snaps=False)\n        if not ret:\n            exception_message = (_('extend_volume: Extending a volume with '\n                                   'snapshots is not supported.'))\n            raise exception.VolumeBackendAPIException(data=exception_message)\n\n        extend_amt = int(new_size) - volume['size']\n        ssh_cmd = ('svctask expandvdisksize -size %(amt)d -unit gb %(name)s'\n                   % {'amt': extend_amt, 'name': volume['name']})\n        out, err = self._run_ssh(ssh_cmd)\n        # No output should be returned from expandvdisksize\n        self._assert_ssh_return(len(out.strip()) == 0, 'extend_volume',\n                                ssh_cmd, out, err)\n        LOG.debug(_('leave: extend_volume: volume %s') % volume['id'])", "func_src_after": "    def extend_volume(self, volume, new_size):\n        LOG.debug(_('enter: extend_volume: volume %s') % volume['id'])\n        ret = self._ensure_vdisk_no_fc_mappings(volume['name'],\n                                                allow_snaps=False)\n        if not ret:\n            exception_message = (_('extend_volume: Extending a volume with '\n                                   'snapshots is not supported.'))\n            raise exception.VolumeBackendAPIException(data=exception_message)\n\n        extend_amt = int(new_size) - volume['size']\n        ssh_cmd = (['svctask', 'expandvdisksize', '-size', str(extend_amt),\n                    '-unit', 'gb', volume['name']])\n        out, err = self._run_ssh(ssh_cmd)\n        # No output should be returned from expandvdisksize\n        self._assert_ssh_return(len(out.strip()) == 0, 'extend_volume',\n                                ssh_cmd, out, err)\n        LOG.debug(_('leave: extend_volume: volume %s') % volume['id'])", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to increase the size of a storage volume using SSH commands, ensuring no snapshots exist."}
{"func_name": "execute", "func_src_before": "func (v *VM) execute(t *thread, i code.Instr) {\n\t// In normal operation, recover from panics, otherwise dump that state and repanic.\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tif v.HardCrash {\n\t\t\t\tfmt.Printf(\"panic in thread %#v at instr %q: %s\\n\", t, i, r)\n\t\t\t\tpanic(r)\n\t\t\t}\n\t\t\tv.errorf(\"panic in thread %#v at instr %q: %s\", t, i, r)\n\t\t\tv.terminate = true\n\t\t}\n\t}()\n\n\tswitch i.Opcode {\n\tcase code.Bad:\n\t\tpanic(\"Invalid instruction.  Aborting.\")\n\n\tcase code.Stop:\n\t\tv.terminate = true\n\n\tcase code.Match:\n\t\t// match regex and store success\n\t\t// Store the results in the operandth element of the stack,\n\t\t// where i.opnd == the matched re index\n\t\tindex := i.Operand.(int)\n\t\tt.matches[index] = v.re[index].FindStringSubmatch(v.input.Line)\n\t\tt.Push(t.matches[index] != nil)\n\n\tcase code.Smatch:\n\t\t// match regex against item on the stack\n\t\tindex := i.Operand.(int)\n\t\tline, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"+%v\", err)\n\t\t\treturn\n\t\t}\n\t\tt.matches[index] = v.re[index].FindStringSubmatch(line)\n\t\tt.Push(t.matches[index] != nil)\n\n\tcase code.Cmp:\n\t\t// Compare two elements on the stack.\n\t\t// Set the match register based on the truthiness of the comparison.\n\t\t// Operand contains the expected result.\n\t\tb := t.Pop()\n\t\ta := t.Pop()\n\n\t\tmatch, err := compare(a, b, i.Operand.(int))\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\n\t\tt.Push(match)\n\n\tcase code.Icmp:\n\t\tb, berr := t.PopInt()\n\t\tif berr != nil {\n\t\t\tv.errorf(\"%+v\", berr)\n\t\t\treturn\n\t\t}\n\t\ta, aerr := t.PopInt()\n\t\tif aerr != nil {\n\t\t\tv.errorf(\"%+v\", aerr)\n\t\t\treturn\n\t\t}\n\t\tmatch, err := compareInt(a, b, i.Operand.(int))\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\n\t\tt.Push(match)\n\tcase code.Fcmp:\n\t\tb, berr := t.PopFloat()\n\t\tif berr != nil {\n\t\t\tv.errorf(\"%+v\", berr)\n\t\t\treturn\n\t\t}\n\t\ta, aerr := t.PopFloat()\n\t\tif aerr != nil {\n\t\t\tv.errorf(\"%+v\", aerr)\n\t\t}\n\t\tmatch, err := compareFloat(a, b, i.Operand.(int))\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\n\t\tt.Push(match)\n\tcase code.Scmp:\n\t\tb, berr := t.PopString()\n\t\tif berr != nil {\n\t\t\tv.errorf(\"%+v\", berr)\n\t\t\treturn\n\t\t}\n\t\ta, aerr := t.PopString()\n\t\tif aerr != nil {\n\t\t\tv.errorf(\"%+v\", aerr)\n\t\t\treturn\n\t\t}\n\t\tmatch, err := compareString(a, b, i.Operand.(int))\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\n\t\tt.Push(match)\n\n\tcase code.Jnm:\n\t\tval := t.Pop()\n\t\tswitch match := val.(type) {\n\t\tcase bool:\n\t\t\tif !match {\n\t\t\t\tt.pc = i.Operand.(int)\n\t\t\t}\n\t\tcase int64:\n\t\t\tif match == 0 {\n\t\t\t\tt.pc = i.Operand.(int)\n\t\t\t}\n\t\t}\n\n\tcase code.Jm:\n\t\tval := t.Pop()\n\t\tswitch match := val.(type) {\n\t\tcase bool:\n\t\t\tif match {\n\t\t\t\tt.pc = i.Operand.(int)\n\t\t\t}\n\t\tcase int64:\n\t\t\tif match != 0 {\n\t\t\t\tt.pc = i.Operand.(int)\n\t\t\t}\n\t\t}\n\n\tcase code.Jmp:\n\t\tt.pc = i.Operand.(int)\n\n\tcase code.Inc:\n\t\t// Increment a datum\n\t\tvar delta int64 = 1\n\t\t// If opnd is non-nil, the delta is on the stack.\n\t\tif i.Operand != nil {\n\t\t\tvar err error\n\t\t\tdelta, err = t.PopInt()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%s\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\tif n, ok := t.Pop().(datum.Datum); ok {\n\t\t\tdatum.IncIntBy(n, delta, t.time)\n\t\t\tt.Push(datum.GetInt(n))\n\t\t} else {\n\t\t\tv.errorf(\"Unexpected type to increment: %T %q\", n, n)\n\t\t\treturn\n\t\t}\n\n\tcase code.Dec:\n\t\t// Decrement a datum\n\t\tvar delta int64 = 1\n\t\t// If opnd is non-nil, the delta is on the stack.\n\t\tif i.Operand != nil {\n\t\t\tvar err error\n\t\t\tdelta, err = t.PopInt()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%s\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\tif n, ok := t.Pop().(datum.Datum); ok {\n\t\t\tdatum.DecIntBy(n, delta, t.time)\n\t\t\tt.Push(datum.GetInt(n))\n\t\t} else {\n\t\t\tv.errorf(\"Unexpected type to increment: %T %q\", n, n)\n\t\t\treturn\n\t\t}\n\n\tcase code.Iset:\n\t\t// Set a datum\n\t\tvalue, err := t.PopInt()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tif n, ok := t.Pop().(datum.Datum); ok {\n\t\t\tdatum.SetInt(n, value, t.time)\n\t\t} else {\n\t\t\tv.errorf(\"Unexpected type to iset: %T %q\", n, n)\n\t\t\treturn\n\t\t}\n\n\tcase code.Fset:\n\t\t// Set a datum\n\t\tvalue, err := t.PopFloat()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tif n, ok := t.Pop().(datum.Datum); ok {\n\t\t\tdatum.SetFloat(n, value, t.time)\n\t\t} else {\n\t\t\tv.errorf(\"Unexpected type to fset: %T %q\", n, n)\n\t\t\treturn\n\t\t}\n\n\tcase code.Sset:\n\t\t// Set a string datum\n\t\tvalue, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\t\tif n, ok := t.Pop().(datum.Datum); ok {\n\t\t\tdatum.SetString(n, value, t.time)\n\t\t} else {\n\t\t\tv.errorf(\"Unexpected type to sset: %T %q\", n, n)\n\t\t\treturn\n\t\t}\n\n\tcase code.Strptime:\n\t\t// Parse a time string into the time register\n\t\tlayout, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\n\t\tvar ts string\n\t\tswitch s := t.Pop().(type) {\n\t\tcase string:\n\t\t\tts = s\n\n\t\tcase int: /* capref */\n\t\t\t// First find the match storage index on the stack\n\t\t\tre := t.Pop().(int)\n\t\t\t// Store the result from the re'th index at the s'th index\n\t\t\tts = t.matches[re][s]\n\t\t}\n\t\tif cached, ok := v.timeMemos.Get(ts); !ok {\n\t\t\ttm := v.ParseTime(layout, ts)\n\t\t\tv.timeMemos.Add(ts, tm)\n\t\t\tt.time = tm\n\t\t} else {\n\t\t\tt.time = cached.(time.Time)\n\t\t}\n\n\tcase code.Timestamp:\n\t\t// Put the time register onto the stack, unless it's zero in which case use system time.\n\t\tif t.time.IsZero() {\n\t\t\tt.Push(time.Now().Unix())\n\t\t} else {\n\t\t\t// Put the time register onto the stack\n\t\t\tt.Push(t.time.Unix())\n\t\t}\n\n\tcase code.Settime:\n\t\t// Pop TOS and store in time register\n\t\tval := t.Pop()\n\t\tts, ok := val.(int64)\n\t\tif !ok {\n\t\t\tv.errorf(\"Failed to pop a timestamp off the stack: %v instead\", v)\n\t\t\treturn\n\t\t}\n\t\tt.time = time.Unix(ts, 0).UTC()\n\n\tcase code.Capref:\n\t\t// Put a capture group reference onto the stack.\n\t\t// First find the match storage index on the stack,\n\t\tval := t.Pop()\n\t\tre, ok := val.(int)\n\t\tif !ok {\n\t\t\tv.errorf(\"Invalid re index %v, not an int\", val)\n\t\t\treturn\n\t\t}\n\t\t// Push the result from the re'th match at operandth index\n\t\top, ok := i.Operand.(int)\n\t\tif !ok {\n\t\t\tv.errorf(\"Invalid operand %v, not an int\", i.Operand)\n\t\t\treturn\n\t\t}\n\t\tif len(t.matches[re]) <= op {\n\t\t\tv.errorf(\"Not enough capture groups matched from %v to select %dth\", t.matches[re], op)\n\t\t\treturn\n\t\t}\n\t\tt.Push(t.matches[re][op])\n\n\tcase code.Str:\n\t\t// Put a string constant onto the stack\n\t\tt.Push(v.str[i.Operand.(int)])\n\n\tcase code.Push:\n\t\t// Push a value onto the stack\n\t\tt.Push(i.Operand)\n\n\tcase code.Fadd, code.Fsub, code.Fmul, code.Fdiv, code.Fmod, code.Fpow:\n\t\tb, err := t.PopFloat()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\ta, err := t.PopFloat()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tswitch i.Opcode {\n\t\tcase code.Fadd:\n\t\t\tt.Push(a + b)\n\t\tcase code.Fsub:\n\t\t\tt.Push(a - b)\n\t\tcase code.Fmul:\n\t\t\tt.Push(a * b)\n\t\tcase code.Fdiv:\n\t\t\tt.Push(a / b)\n\t\tcase code.Fmod:\n\t\t\tt.Push(math.Mod(a, b))\n\t\tcase code.Fpow:\n\t\t\tt.Push(math.Pow(a, b))\n\t\t}\n\n\tcase code.Iadd, code.Isub, code.Imul, code.Idiv, code.Imod, code.Ipow, code.Shl, code.Shr, code.And, code.Or, code.Xor:\n\t\t// Op two values at TOS, and push result onto stack\n\t\tb, err := t.PopInt()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\ta, err := t.PopInt()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tswitch i.Opcode {\n\t\tcase code.Iadd:\n\t\t\tt.Push(a + b)\n\t\tcase code.Isub:\n\t\t\tt.Push(a - b)\n\t\tcase code.Imul:\n\t\t\tt.Push(a * b)\n\t\tcase code.Idiv:\n\t\t\tif b == 0 {\n\t\t\t\tv.errorf(\"Divide by zero %d %% %d\", a, b)\n\t\t\t\treturn\n\t\t\t}\n\t\t\t// Integer division\n\t\t\tt.Push(a / b)\n\t\tcase code.Imod:\n\t\t\tif b == 0 {\n\t\t\t\tv.errorf(\"Divide by zero %d %% %d\", a, b)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tt.Push(a % b)\n\t\tcase code.Ipow:\n\t\t\t// TODO(jaq): replace with type coercion\n\t\t\tt.Push(int64(math.Pow(float64(a), float64(b))))\n\t\tcase code.Shl:\n\t\t\tt.Push(a << uint(b))\n\t\tcase code.Shr:\n\t\t\tt.Push(a >> uint(b))\n\t\tcase code.And:\n\t\t\tt.Push(a & b)\n\t\tcase code.Or:\n\t\t\tt.Push(a | b)\n\t\tcase code.Xor:\n\t\t\tt.Push(a ^ b)\n\t\t}\n\n\tcase code.Neg:\n\t\ta, err := t.PopInt()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(^a)\n\n\tcase code.Not:\n\t\ta := t.Pop().(bool)\n\t\tt.Push(!a)\n\n\tcase code.Mload:\n\t\t// Load a metric at operand onto stack\n\t\tt.Push(v.Metrics[i.Operand.(int)])\n\n\tcase code.Dload:\n\t\t// Load a datum from metric at TOS onto stack\n\t\t// fmt.Printf(\"Stack: %v\\n\", t.stack)\n\t\tm := t.Pop().(*metrics.Metric)\n\t\t// fmt.Printf(\"Metric: %v\\n\", m)\n\t\tindex := i.Operand.(int)\n\t\tkeys := make([]string, index)\n\t\t// fmt.Printf(\"keys: %v\\n\", keys)\n\t\tfor a := index - 1; a >= 0; a-- {\n\t\t\ts, err := t.PopString()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%+v\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\t// fmt.Printf(\"s: %v\\n\", s)\n\t\t\tkeys[a] = s\n\t\t\t// fmt.Printf(\"Keys: %v\\n\", keys)\n\t\t}\n\t\t// fmt.Printf(\"Keys: %v\\n\", keys)\n\t\td, err := m.GetDatum(keys...)\n\t\tif err != nil {\n\t\t\tv.errorf(\"dload (GetDatum) failed: %s\", err)\n\t\t\treturn\n\t\t}\n\t\t// fmt.Printf(\"Found %v\\n\", d)\n\t\tt.Push(d)\n\n\tcase code.Iget, code.Fget, code.Sget:\n\t\td, ok := t.Pop().(datum.Datum)\n\t\tif !ok {\n\t\t\tv.errorf(\"Unexpected value on stack: %q\", d)\n\t\t\treturn\n\t\t}\n\t\tswitch i.Opcode {\n\t\tcase code.Iget:\n\t\t\tt.Push(datum.GetInt(d))\n\t\tcase code.Fget:\n\t\t\tt.Push(datum.GetFloat(d))\n\t\tcase code.Sget:\n\t\t\tt.Push(datum.GetString(d))\n\t\t}\n\n\tcase code.Del:\n\t\tm := t.Pop().(*metrics.Metric)\n\t\tindex := i.Operand.(int)\n\t\tkeys := make([]string, index)\n\t\tfor j := index - 1; j >= 0; j-- {\n\t\t\ts, err := t.PopString()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%+v\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tkeys[j] = s\n\t\t}\n\t\terr := m.RemoveDatum(keys...)\n\t\tif err != nil {\n\t\t\tv.errorf(\"del (RemoveDatum) failed: %s\", err)\n\t\t\treturn\n\t\t}\n\n\tcase code.Expire:\n\t\tm := t.Pop().(*metrics.Metric)\n\t\tindex := i.Operand.(int)\n\t\tkeys := make([]string, index)\n\t\tfor j := index - 1; j >= 0; j-- {\n\t\t\ts, err := t.PopString()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%+v\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tkeys[j] = s\n\t\t}\n\t\texpiry := t.Pop().(time.Duration)\n\t\tif err := m.ExpireDatum(expiry, keys...); err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\n\tcase code.Tolower:\n\t\t// Lowercase code.a string from TOS, and push result back.\n\t\ts, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(strings.ToLower(s))\n\n\tcase code.Length:\n\t\t// Compute the length of a string from TOS, and push result back.\n\t\ts, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(len(s))\n\n\tcase code.S2i:\n\t\tbase := int64(10)\n\t\tvar err error\n\t\tif i.Operand != nil {\n\t\t\t// strtol is emitted with an arglen, int is not\n\t\t\tbase, err = t.PopInt()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%s\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif base > 2147483647 || base < -2147483648 {\n\t\t\t\tv.errorf(\"int32 out of range\")\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\tstr, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\t\tval, err := strconv.ParseInt(str, int(base), 64)\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(val)\n\n\tcase code.S2f:\n\t\tstr, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\t\tf, err := strconv.ParseFloat(str, 64)\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(f)\n\n\tcase code.I2f:\n\t\ti, err := t.PopInt()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(float64(i))\n\n\tcase code.I2s:\n\t\ti, err := t.PopInt()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(fmt.Sprintf(\"%d\", i))\n\n\tcase code.F2s:\n\t\tf, err := t.PopFloat()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(fmt.Sprintf(\"%g\", f))\n\n\tcase code.Setmatched:\n\t\tt.matched = i.Operand.(bool)\n\n\tcase code.Otherwise:\n\t\t// Only match if the matched flag is false.\n\t\tt.Push(!t.matched)\n\n\tcase code.Getfilename:\n\t\tt.Push(v.input.Filename)\n\n\tcase code.Cat:\n\t\tb, berr := t.PopString()\n\t\tif berr != nil {\n\t\t\tv.errorf(\"%+v\", berr)\n\t\t\treturn\n\t\t}\n\t\ta, aerr := t.PopString()\n\t\tif aerr != nil {\n\t\t\tv.errorf(\"%+v\", aerr)\n\t\t\treturn\n\t\t}\n\t\tt.Push(a + b)\n\n\tcase code.Subst:\n\t\tval, verr := t.PopString()\n\t\tif verr != nil {\n\t\t\tv.errorf(\"%+v\", verr)\n\t\t\treturn\n\t\t}\n\t\trepl, nerr := t.PopString()\n\t\tif nerr != nil {\n\t\t\tv.errorf(\"%+v\", nerr)\n\t\t\treturn\n\t\t}\n\t\told, oerr := t.PopString()\n\t\tif oerr != nil {\n\t\t\tv.errorf(\"%+v\", oerr)\n\t\t\treturn\n\t\t}\n\t\tt.Push(strings.ReplaceAll(val, old, repl))\n\tcase code.Rsubst:\n\t\tpat, perr := t.PopInt()\n\t\tif perr != nil {\n\t\t\tv.errorf(\"%+v\", perr)\n\t\t\treturn\n\t\t}\n\t\tval, verr := t.PopString()\n\t\tif verr != nil {\n\t\t\tv.errorf(\"%+v\", verr)\n\t\t\treturn\n\t\t}\n\t\trepl, nerr := t.PopString()\n\t\tif nerr != nil {\n\t\t\tv.errorf(\"%+v\", nerr)\n\t\t\treturn\n\t\t}\n\t\tt.Push(v.re[pat].ReplaceAllLiteralString(val, repl))\n\n\tdefault:\n\t\tv.errorf(\"illegal instruction: %d\", i.Opcode)\n\t}\n}", "func_src_after": "func (v *VM) execute(t *thread, i code.Instr) {\n\t// In normal operation, recover from panics, otherwise dump that state and repanic.\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tif v.HardCrash {\n\t\t\t\tfmt.Printf(\"panic in thread %#v at instr %q: %s\\n\", t, i, r)\n\t\t\t\tpanic(r)\n\t\t\t}\n\t\t\tv.errorf(\"panic in thread %#v at instr %q: %s\", t, i, r)\n\t\t\tv.terminate = true\n\t\t}\n\t}()\n\n\tswitch i.Opcode {\n\tcase code.Bad:\n\t\tpanic(\"Invalid instruction.  Aborting.\")\n\n\tcase code.Stop:\n\t\tv.terminate = true\n\n\tcase code.Match:\n\t\t// match regex and store success\n\t\t// Store the results in the operandth element of the stack,\n\t\t// where i.opnd == the matched re index\n\t\tindex := i.Operand.(int)\n\t\tt.matches[index] = v.re[index].FindStringSubmatch(v.input.Line)\n\t\tt.Push(t.matches[index] != nil)\n\n\tcase code.Smatch:\n\t\t// match regex against item on the stack\n\t\tindex := i.Operand.(int)\n\t\tline, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"+%v\", err)\n\t\t\treturn\n\t\t}\n\t\tt.matches[index] = v.re[index].FindStringSubmatch(line)\n\t\tt.Push(t.matches[index] != nil)\n\n\tcase code.Cmp:\n\t\t// Compare two elements on the stack.\n\t\t// Set the match register based on the truthiness of the comparison.\n\t\t// Operand contains the expected result.\n\t\tb := t.Pop()\n\t\ta := t.Pop()\n\n\t\tmatch, err := compare(a, b, i.Operand.(int))\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\n\t\tt.Push(match)\n\n\tcase code.Icmp:\n\t\tb, berr := t.PopInt()\n\t\tif berr != nil {\n\t\t\tv.errorf(\"%+v\", berr)\n\t\t\treturn\n\t\t}\n\t\ta, aerr := t.PopInt()\n\t\tif aerr != nil {\n\t\t\tv.errorf(\"%+v\", aerr)\n\t\t\treturn\n\t\t}\n\t\tmatch, err := compareInt(a, b, i.Operand.(int))\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\n\t\tt.Push(match)\n\tcase code.Fcmp:\n\t\tb, berr := t.PopFloat()\n\t\tif berr != nil {\n\t\t\tv.errorf(\"%+v\", berr)\n\t\t\treturn\n\t\t}\n\t\ta, aerr := t.PopFloat()\n\t\tif aerr != nil {\n\t\t\tv.errorf(\"%+v\", aerr)\n\t\t}\n\t\tmatch, err := compareFloat(a, b, i.Operand.(int))\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\n\t\tt.Push(match)\n\tcase code.Scmp:\n\t\tb, berr := t.PopString()\n\t\tif berr != nil {\n\t\t\tv.errorf(\"%+v\", berr)\n\t\t\treturn\n\t\t}\n\t\ta, aerr := t.PopString()\n\t\tif aerr != nil {\n\t\t\tv.errorf(\"%+v\", aerr)\n\t\t\treturn\n\t\t}\n\t\tmatch, err := compareString(a, b, i.Operand.(int))\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\n\t\tt.Push(match)\n\n\tcase code.Jnm:\n\t\tval := t.Pop()\n\t\tswitch match := val.(type) {\n\t\tcase bool:\n\t\t\tif !match {\n\t\t\t\tt.pc = i.Operand.(int)\n\t\t\t}\n\t\tcase int64:\n\t\t\tif match == 0 {\n\t\t\t\tt.pc = i.Operand.(int)\n\t\t\t}\n\t\t}\n\n\tcase code.Jm:\n\t\tval := t.Pop()\n\t\tswitch match := val.(type) {\n\t\tcase bool:\n\t\t\tif match {\n\t\t\t\tt.pc = i.Operand.(int)\n\t\t\t}\n\t\tcase int64:\n\t\t\tif match != 0 {\n\t\t\t\tt.pc = i.Operand.(int)\n\t\t\t}\n\t\t}\n\n\tcase code.Jmp:\n\t\tt.pc = i.Operand.(int)\n\n\tcase code.Inc:\n\t\t// Increment a datum\n\t\tvar delta int64 = 1\n\t\t// If opnd is non-nil, the delta is on the stack.\n\t\tif i.Operand != nil {\n\t\t\tvar err error\n\t\t\tdelta, err = t.PopInt()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%s\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\tif n, ok := t.Pop().(datum.Datum); ok {\n\t\t\tdatum.IncIntBy(n, delta, t.time)\n\t\t\tt.Push(datum.GetInt(n))\n\t\t} else {\n\t\t\tv.errorf(\"Unexpected type to increment: %T %q\", n, n)\n\t\t\treturn\n\t\t}\n\n\tcase code.Dec:\n\t\t// Decrement a datum\n\t\tvar delta int64 = 1\n\t\t// If opnd is non-nil, the delta is on the stack.\n\t\tif i.Operand != nil {\n\t\t\tvar err error\n\t\t\tdelta, err = t.PopInt()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%s\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\tif n, ok := t.Pop().(datum.Datum); ok {\n\t\t\tdatum.DecIntBy(n, delta, t.time)\n\t\t\tt.Push(datum.GetInt(n))\n\t\t} else {\n\t\t\tv.errorf(\"Unexpected type to increment: %T %q\", n, n)\n\t\t\treturn\n\t\t}\n\n\tcase code.Iset:\n\t\t// Set a datum\n\t\tvalue, err := t.PopInt()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tif n, ok := t.Pop().(datum.Datum); ok {\n\t\t\tdatum.SetInt(n, value, t.time)\n\t\t} else {\n\t\t\tv.errorf(\"Unexpected type to iset: %T %q\", n, n)\n\t\t\treturn\n\t\t}\n\n\tcase code.Fset:\n\t\t// Set a datum\n\t\tvalue, err := t.PopFloat()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tif n, ok := t.Pop().(datum.Datum); ok {\n\t\t\tdatum.SetFloat(n, value, t.time)\n\t\t} else {\n\t\t\tv.errorf(\"Unexpected type to fset: %T %q\", n, n)\n\t\t\treturn\n\t\t}\n\n\tcase code.Sset:\n\t\t// Set a string datum\n\t\tvalue, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\t\tif n, ok := t.Pop().(datum.Datum); ok {\n\t\t\tdatum.SetString(n, value, t.time)\n\t\t} else {\n\t\t\tv.errorf(\"Unexpected type to sset: %T %q\", n, n)\n\t\t\treturn\n\t\t}\n\n\tcase code.Strptime:\n\t\t// Parse a time string into the time register\n\t\tlayout, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\n\t\tvar ts string\n\t\tswitch s := t.Pop().(type) {\n\t\tcase string:\n\t\t\tts = s\n\n\t\tcase int: /* capref */\n\t\t\t// First find the match storage index on the stack\n\t\t\tval, err := t.PopInt()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%s\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif val < 0 || val >= math.MaxInt32 {\n\t\t\t\tv.errorf(\"int32 index out of range\")\n\t\t\t\treturn\n\t\t\t}\n\t\t\tre := int(val)\n\t\t\t// Store the result from the re'th index at the s'th index\n\t\t\tts = t.matches[re][s]\n\t\t}\n\t\tif cached, ok := v.timeMemos.Get(ts); !ok {\n\t\t\ttm := v.ParseTime(layout, ts)\n\t\t\tv.timeMemos.Add(ts, tm)\n\t\t\tt.time = tm\n\t\t} else {\n\t\t\tt.time = cached.(time.Time)\n\t\t}\n\n\tcase code.Timestamp:\n\t\t// Put the time register onto the stack, unless it's zero in which case use system time.\n\t\tif t.time.IsZero() {\n\t\t\tt.Push(time.Now().Unix())\n\t\t} else {\n\t\t\t// Put the time register onto the stack\n\t\t\tt.Push(t.time.Unix())\n\t\t}\n\n\tcase code.Settime:\n\t\t// Pop TOS and store in time register\n\t\tval := t.Pop()\n\t\tts, ok := val.(int64)\n\t\tif !ok {\n\t\t\tv.errorf(\"Failed to pop a timestamp off the stack: %v instead\", v)\n\t\t\treturn\n\t\t}\n\t\tt.time = time.Unix(ts, 0).UTC()\n\n\tcase code.Capref:\n\t\t// Put a capture group reference onto the stack.\n\t\t// First find the match storage index on the stack,\n\t\tval := t.Pop()\n\t\tre, ok := val.(int)\n\t\tif !ok {\n\t\t\tv.errorf(\"Invalid re index %v, not an int\", val)\n\t\t\treturn\n\t\t}\n\t\t// Push the result from the re'th match at operandth index\n\t\top, ok := i.Operand.(int)\n\t\tif !ok {\n\t\t\tv.errorf(\"Invalid operand %v, not an int\", i.Operand)\n\t\t\treturn\n\t\t}\n\t\tif len(t.matches[re]) <= op {\n\t\t\tv.errorf(\"Not enough capture groups matched from %v to select %dth\", t.matches[re], op)\n\t\t\treturn\n\t\t}\n\t\tt.Push(t.matches[re][op])\n\n\tcase code.Str:\n\t\t// Put a string constant onto the stack\n\t\tt.Push(v.str[i.Operand.(int)])\n\n\tcase code.Push:\n\t\t// Push a value onto the stack\n\t\tt.Push(i.Operand)\n\n\tcase code.Fadd, code.Fsub, code.Fmul, code.Fdiv, code.Fmod, code.Fpow:\n\t\tb, err := t.PopFloat()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\ta, err := t.PopFloat()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tswitch i.Opcode {\n\t\tcase code.Fadd:\n\t\t\tt.Push(a + b)\n\t\tcase code.Fsub:\n\t\t\tt.Push(a - b)\n\t\tcase code.Fmul:\n\t\t\tt.Push(a * b)\n\t\tcase code.Fdiv:\n\t\t\tt.Push(a / b)\n\t\tcase code.Fmod:\n\t\t\tt.Push(math.Mod(a, b))\n\t\tcase code.Fpow:\n\t\t\tt.Push(math.Pow(a, b))\n\t\t}\n\n\tcase code.Iadd, code.Isub, code.Imul, code.Idiv, code.Imod, code.Ipow, code.Shl, code.Shr, code.And, code.Or, code.Xor:\n\t\t// Op two values at TOS, and push result onto stack\n\t\tb, err := t.PopInt()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\ta, err := t.PopInt()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tswitch i.Opcode {\n\t\tcase code.Iadd:\n\t\t\tt.Push(a + b)\n\t\tcase code.Isub:\n\t\t\tt.Push(a - b)\n\t\tcase code.Imul:\n\t\t\tt.Push(a * b)\n\t\tcase code.Idiv:\n\t\t\tif b == 0 {\n\t\t\t\tv.errorf(\"Divide by zero %d %% %d\", a, b)\n\t\t\t\treturn\n\t\t\t}\n\t\t\t// Integer division\n\t\t\tt.Push(a / b)\n\t\tcase code.Imod:\n\t\t\tif b == 0 {\n\t\t\t\tv.errorf(\"Divide by zero %d %% %d\", a, b)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tt.Push(a % b)\n\t\tcase code.Ipow:\n\t\t\t// TODO(jaq): replace with type coercion\n\t\t\tt.Push(int64(math.Pow(float64(a), float64(b))))\n\t\tcase code.Shl:\n\t\t\tif b < 0 || b >= math.MaxInt32 {\n\t\t\t\tv.errorf(\"shift int out of range\")\n\t\t\t\treturn\n\t\t\t}\n\t\t\tt.Push(a << uint(b))\n\t\tcase code.Shr:\n\t\t\tif b < 0 || b >= math.MaxInt32 {\n\t\t\t\tv.errorf(\"shift int out of range\")\n\t\t\t\treturn\n\t\t\t}\n\t\t\tt.Push(a >> uint(b))\n\t\tcase code.And:\n\t\t\tt.Push(a & b)\n\t\tcase code.Or:\n\t\t\tt.Push(a | b)\n\t\tcase code.Xor:\n\t\t\tt.Push(a ^ b)\n\t\t}\n\n\tcase code.Neg:\n\t\ta, err := t.PopInt()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(^a)\n\n\tcase code.Not:\n\t\ta := t.Pop().(bool)\n\t\tt.Push(!a)\n\n\tcase code.Mload:\n\t\t// Load a metric at operand onto stack\n\t\tt.Push(v.Metrics[i.Operand.(int)])\n\n\tcase code.Dload:\n\t\t// Load a datum from metric at TOS onto stack\n\t\t// fmt.Printf(\"Stack: %v\\n\", t.stack)\n\t\tm := t.Pop().(*metrics.Metric)\n\t\t// fmt.Printf(\"Metric: %v\\n\", m)\n\t\tindex := i.Operand.(int)\n\t\tkeys := make([]string, index)\n\t\t// fmt.Printf(\"keys: %v\\n\", keys)\n\t\tfor a := index - 1; a >= 0; a-- {\n\t\t\ts, err := t.PopString()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%+v\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\t// fmt.Printf(\"s: %v\\n\", s)\n\t\t\tkeys[a] = s\n\t\t\t// fmt.Printf(\"Keys: %v\\n\", keys)\n\t\t}\n\t\t// fmt.Printf(\"Keys: %v\\n\", keys)\n\t\td, err := m.GetDatum(keys...)\n\t\tif err != nil {\n\t\t\tv.errorf(\"dload (GetDatum) failed: %s\", err)\n\t\t\treturn\n\t\t}\n\t\t// fmt.Printf(\"Found %v\\n\", d)\n\t\tt.Push(d)\n\n\tcase code.Iget, code.Fget, code.Sget:\n\t\td, ok := t.Pop().(datum.Datum)\n\t\tif !ok {\n\t\t\tv.errorf(\"Unexpected value on stack: %q\", d)\n\t\t\treturn\n\t\t}\n\t\tswitch i.Opcode {\n\t\tcase code.Iget:\n\t\t\tt.Push(datum.GetInt(d))\n\t\tcase code.Fget:\n\t\t\tt.Push(datum.GetFloat(d))\n\t\tcase code.Sget:\n\t\t\tt.Push(datum.GetString(d))\n\t\t}\n\n\tcase code.Del:\n\t\tm := t.Pop().(*metrics.Metric)\n\t\tindex := i.Operand.(int)\n\t\tkeys := make([]string, index)\n\t\tfor j := index - 1; j >= 0; j-- {\n\t\t\ts, err := t.PopString()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%+v\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tkeys[j] = s\n\t\t}\n\t\terr := m.RemoveDatum(keys...)\n\t\tif err != nil {\n\t\t\tv.errorf(\"del (RemoveDatum) failed: %s\", err)\n\t\t\treturn\n\t\t}\n\n\tcase code.Expire:\n\t\tm := t.Pop().(*metrics.Metric)\n\t\tindex := i.Operand.(int)\n\t\tkeys := make([]string, index)\n\t\tfor j := index - 1; j >= 0; j-- {\n\t\t\ts, err := t.PopString()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%+v\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tkeys[j] = s\n\t\t}\n\t\texpiry := t.Pop().(time.Duration)\n\t\tif err := m.ExpireDatum(expiry, keys...); err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\n\tcase code.Tolower:\n\t\t// Lowercase code.a string from TOS, and push result back.\n\t\ts, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(strings.ToLower(s))\n\n\tcase code.Length:\n\t\t// Compute the length of a string from TOS, and push result back.\n\t\ts, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(len(s))\n\n\tcase code.S2i:\n\t\tbase := 10\n\t\tvar err error\n\t\tif i.Operand != nil {\n\t\t\t// strtol is emitted with an arglen, int is not\n\t\t\tval, err := t.PopInt()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%s\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif val <= 0 || val >= math.MaxInt32 {\n\t\t\t\tv.errorf(\"int32 out of range\")\n\t\t\t\treturn\n\t\t\t}\n\t\t\tbase = int(val)\n\t\t}\n\t\tstr, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\t\tval, err := strconv.ParseInt(str, base, 64)\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(val)\n\n\tcase code.S2f:\n\t\tstr, err := t.PopString()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%+v\", err)\n\t\t\treturn\n\t\t}\n\t\tf, err := strconv.ParseFloat(str, 64)\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(f)\n\n\tcase code.I2f:\n\t\ti, err := t.PopInt()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(float64(i))\n\n\tcase code.I2s:\n\t\ti, err := t.PopInt()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(fmt.Sprintf(\"%d\", i))\n\n\tcase code.F2s:\n\t\tf, err := t.PopFloat()\n\t\tif err != nil {\n\t\t\tv.errorf(\"%s\", err)\n\t\t\treturn\n\t\t}\n\t\tt.Push(fmt.Sprintf(\"%g\", f))\n\n\tcase code.Setmatched:\n\t\tt.matched = i.Operand.(bool)\n\n\tcase code.Otherwise:\n\t\t// Only match if the matched flag is false.\n\t\tt.Push(!t.matched)\n\n\tcase code.Getfilename:\n\t\tt.Push(v.input.Filename)\n\n\tcase code.Cat:\n\t\tb, berr := t.PopString()\n\t\tif berr != nil {\n\t\t\tv.errorf(\"%+v\", berr)\n\t\t\treturn\n\t\t}\n\t\ta, aerr := t.PopString()\n\t\tif aerr != nil {\n\t\t\tv.errorf(\"%+v\", aerr)\n\t\t\treturn\n\t\t}\n\t\tt.Push(a + b)\n\n\tcase code.Subst:\n\t\tval, verr := t.PopString()\n\t\tif verr != nil {\n\t\t\tv.errorf(\"%+v\", verr)\n\t\t\treturn\n\t\t}\n\t\trepl, nerr := t.PopString()\n\t\tif nerr != nil {\n\t\t\tv.errorf(\"%+v\", nerr)\n\t\t\treturn\n\t\t}\n\t\told, oerr := t.PopString()\n\t\tif oerr != nil {\n\t\t\tv.errorf(\"%+v\", oerr)\n\t\t\treturn\n\t\t}\n\t\tt.Push(strings.ReplaceAll(val, old, repl))\n\tcase code.Rsubst:\n\t\tpat, perr := t.PopInt()\n\t\tif perr != nil {\n\t\t\tv.errorf(\"%+v\", perr)\n\t\t\treturn\n\t\t}\n\t\tval, verr := t.PopString()\n\t\tif verr != nil {\n\t\t\tv.errorf(\"%+v\", verr)\n\t\t\treturn\n\t\t}\n\t\trepl, nerr := t.PopString()\n\t\tif nerr != nil {\n\t\t\tv.errorf(\"%+v\", nerr)\n\t\t\treturn\n\t\t}\n\t\tt.Push(v.re[pat].ReplaceAllLiteralString(val, repl))\n\n\tdefault:\n\t\tv.errorf(\"illegal instruction: %d\", i.Opcode)\n\t}\n}", "line_changes": {"deleted": [{"line_no": 235, "char_start": 4715, "char_end": 4738, "line": "\t\t\tre := t.Pop().(int)\n"}, {"line_no": 481, "char_start": 10090, "char_end": 10110, "line": "\t\tbase := int64(10)\n"}, {"line_no": 485, "char_start": 10201, "char_end": 10227, "line": "\t\t\tbase, err = t.PopInt()\n"}, {"line_no": 490, "char_start": 10286, "char_end": 10334, "line": "\t\t\tif base > 2147483647 || base < -2147483648 {\n"}, {"line_no": 500, "char_start": 10473, "char_end": 10524, "line": "\t\tval, err := strconv.ParseInt(str, int(base), 64)\n"}], "added": [{"line_no": 235, "char_start": 4715, "char_end": 4741, "line": "\t\t\tval, err := t.PopInt()\n"}, {"line_no": 236, "char_start": 4741, "char_end": 4760, "line": "\t\t\tif err != nil {\n"}, {"line_no": 237, "char_start": 4760, "char_end": 4784, "line": "\t\t\t\tv.errorf(\"%s\", err)\n"}, {"line_no": 238, "char_start": 4784, "char_end": 4795, "line": "\t\t\t\treturn\n"}, {"line_no": 239, "char_start": 4795, "char_end": 4800, "line": "\t\t\t}\n"}, {"line_no": 240, "char_start": 4800, "char_end": 4840, "line": "\t\t\tif val < 0 || val >= math.MaxInt32 {\n"}, {"line_no": 241, "char_start": 4840, "char_end": 4881, "line": "\t\t\t\tv.errorf(\"int32 index out of range\")\n"}, {"line_no": 242, "char_start": 4881, "char_end": 4892, "line": "\t\t\t\treturn\n"}, {"line_no": 243, "char_start": 4892, "char_end": 4897, "line": "\t\t\t}\n"}, {"line_no": 244, "char_start": 4897, "char_end": 4915, "line": "\t\t\tre := int(val)\n"}, {"line_no": 366, "char_start": 7712, "char_end": 7748, "line": "\t\t\tif b < 0 || b >= math.MaxInt32 {\n"}, {"line_no": 367, "char_start": 7748, "char_end": 7787, "line": "\t\t\t\tv.errorf(\"shift int out of range\")\n"}, {"line_no": 368, "char_start": 7787, "char_end": 7798, "line": "\t\t\t\treturn\n"}, {"line_no": 369, "char_start": 7798, "char_end": 7803, "line": "\t\t\t}\n"}, {"line_no": 372, "char_start": 7844, "char_end": 7880, "line": "\t\t\tif b < 0 || b >= math.MaxInt32 {\n"}, {"line_no": 373, "char_start": 7880, "char_end": 7919, "line": "\t\t\t\tv.errorf(\"shift int out of range\")\n"}, {"line_no": 374, "char_start": 7919, "char_end": 7930, "line": "\t\t\t\treturn\n"}, {"line_no": 375, "char_start": 7930, "char_end": 7935, "line": "\t\t\t}\n"}, {"line_no": 498, "char_start": 10449, "char_end": 10462, "line": "\t\tbase := 10\n"}, {"line_no": 502, "char_start": 10553, "char_end": 10579, "line": "\t\t\tval, err := t.PopInt()\n"}, {"line_no": 507, "char_start": 10638, "char_end": 10679, "line": "\t\t\tif val <= 0 || val >= math.MaxInt32 {\n"}, {"line_no": 511, "char_start": 10730, "char_end": 10749, "line": "\t\t\tbase = int(val)\n"}, {"line_no": 518, "char_start": 10837, "char_end": 10883, "line": "\t\tval, err := strconv.ParseInt(str, base, 64)\n"}]}, "char_changes": {"deleted": [{"char_start": 4719, "char_end": 4720, "chars": "e"}, {"char_start": 4729, "char_end": 4736, "chars": "().(int"}, {"char_start": 7538, "char_end": 7575, "chars": "t.Push(a << uint(b))\n\t\tcase code.Shr:"}, {"char_start": 10100, "char_end": 10106, "chars": "int64("}, {"char_start": 10108, "char_end": 10109, "chars": ")"}, {"char_start": 10204, "char_end": 10208, "chars": "base"}, {"char_start": 10292, "char_end": 10331, "chars": "base > 2147483647 || base < -2147483648"}, {"char_start": 10509, "char_end": 10513, "chars": "int("}, {"char_start": 10517, "char_end": 10518, "chars": ")"}], "added": [{"char_start": 4718, "char_end": 4725, "chars": "val, er"}, {"char_start": 4735, "char_end": 4913, "chars": "Int()\n\t\t\tif err != nil {\n\t\t\t\tv.errorf(\"%s\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif val < 0 || val >= math.MaxInt32 {\n\t\t\t\tv.errorf(\"int32 index out of range\")\n\t\t\t\treturn\n\t\t\t}\n\t\t\tre := int(val"}, {"char_start": 7715, "char_end": 7934, "chars": "if b < 0 || b >= math.MaxInt32 {\n\t\t\t\tv.errorf(\"shift int out of range\")\n\t\t\t\treturn\n\t\t\t}\n\t\t\tt.Push(a << uint(b))\n\t\tcase code.Shr:\n\t\t\tif b < 0 || b >= math.MaxInt32 {\n\t\t\t\tv.errorf(\"shift int out of range\")\n\t\t\t\treturn\n\t\t\t}"}, {"char_start": 10556, "char_end": 10559, "chars": "val"}, {"char_start": 10565, "char_end": 10566, "chars": ":"}, {"char_start": 10644, "char_end": 10676, "chars": "val <= 0 || val >= math.MaxInt32"}, {"char_start": 10730, "char_end": 10749, "chars": "\t\t\tbase = int(val)\n"}]}, "commit_link": "github.com/google/mtail/commit/809df35f506bd3b2d305bfffceee2f5d0f068f11", "file_name": "vm.go", "vul_type": "cwe-681", "commit_msg": "Fix integer overflow warnings.", "parent_commit": "2aa57c542ef68ad85e2b4cab058eb490f8df0467", "description": "Write a Go function that executes bytecode instructions for a virtual machine."}
{"func_name": "commentcounts", "func_src_before": "@register.tag\n@basictag(takes_context=True)\ndef commentcounts(context, filediff, interfilediff=None):\n    \"\"\"\n    Returns a JSON array of current comments for a filediff, sorted by\n    line number.\n\n    Each entry in the array has a dictionary containing the following keys:\n\n      =========== ==================================================\n      Key         Description\n      =========== ==================================================\n      comment_id  The ID of the comment\n      text        The text of the comment\n      line        The first line number\n      num_lines   The number of lines this comment spans\n      user        A dictionary containing \"username\" and \"name\" keys\n                  for the user\n      url         The URL to the comment\n      localdraft  True if this is the current user's draft comment\n      =========== ==================================================\n    \"\"\"\n    comment_dict = {}\n    user = context.get('user', None)\n\n    if interfilediff:\n        query = Comment.objects.filter(filediff=filediff,\n                                       interfilediff=interfilediff)\n    else:\n        query = Comment.objects.filter(filediff=filediff,\n                                       interfilediff__isnull=True)\n\n    for comment in query:\n        review = get_object_or_none(comment.review)\n\n        if review and (review.public or review.user == user):\n            key = (comment.first_line, comment.num_lines)\n\n            comment_dict.setdefault(key, []).append({\n                'comment_id': comment.id,\n                'text': comment.text,\n                'line': comment.first_line,\n                'num_lines': comment.num_lines,\n                'user': {\n                    'username': review.user.username,\n                    'name': review.user.get_full_name() or review.user.username,\n                },\n                #'timestamp': comment.timestamp,\n                'url': comment.get_review_url(),\n                'localdraft': review.user == user and \\\n                              not review.public,\n            })\n\n    comments_array = []\n\n    for key, value in comment_dict.iteritems():\n        comments_array.append({\n            'linenum': key[0],\n            'num_lines': key[1],\n            'comments': value,\n        })\n\n    comments_array.sort(cmp=lambda x, y: cmp(x['linenum'], y['linenum'] or\n                                         cmp(x['num_lines'], y['num_lines'])))\n\n    return simplejson.dumps(comments_array)", "func_src_after": "@register.tag\n@basictag(takes_context=True)\ndef commentcounts(context, filediff, interfilediff=None):\n    \"\"\"\n    Returns a JSON array of current comments for a filediff, sorted by\n    line number.\n\n    Each entry in the array has a dictionary containing the following keys:\n\n      =========== ==================================================\n      Key         Description\n      =========== ==================================================\n      comment_id  The ID of the comment\n      text        The text of the comment\n      line        The first line number\n      num_lines   The number of lines this comment spans\n      user        A dictionary containing \"username\" and \"name\" keys\n                  for the user\n      url         The URL to the comment\n      localdraft  True if this is the current user's draft comment\n      =========== ==================================================\n    \"\"\"\n    comment_dict = {}\n    user = context.get('user', None)\n\n    if interfilediff:\n        query = Comment.objects.filter(filediff=filediff,\n                                       interfilediff=interfilediff)\n    else:\n        query = Comment.objects.filter(filediff=filediff,\n                                       interfilediff__isnull=True)\n\n    for comment in query:\n        review = get_object_or_none(comment.review)\n\n        if review and (review.public or review.user == user):\n            key = (comment.first_line, comment.num_lines)\n\n            comment_dict.setdefault(key, []).append({\n                'comment_id': comment.id,\n                'text': escape(comment.text),\n                'line': comment.first_line,\n                'num_lines': comment.num_lines,\n                'user': {\n                    'username': review.user.username,\n                    'name': review.user.get_full_name() or review.user.username,\n                },\n                #'timestamp': comment.timestamp,\n                'url': comment.get_review_url(),\n                'localdraft': review.user == user and \\\n                              not review.public,\n            })\n\n    comments_array = []\n\n    for key, value in comment_dict.iteritems():\n        comments_array.append({\n            'linenum': key[0],\n            'num_lines': key[1],\n            'comments': value,\n        })\n\n    comments_array.sort(cmp=lambda x, y: cmp(x['linenum'], y['linenum'] or\n                                         cmp(x['num_lines'], y['num_lines'])))\n\n    return simplejson.dumps(comments_array)", "commit_link": "github.com/reviewboard/reviewboard/commit/7a0a9d94555502278534dedcf2d75e9fccce8c3d", "file_name": "reviewboard/reviews/templatetags/reviewtags.py", "vul_type": "cwe-079", "description": "In Python, write a function that returns a JSON array of comments for a file difference, including metadata like comment ID, text, line number, and user details, sorted by line number."}
{"func_name": "read_plist", "func_src_before": "    def read_plist(pathname)\n      transformed_pathname = pathname.gsub!(%r{[^0-9A-Za-z. \\-'/]}, '')\n      transformed_pathname = pathname if transformed_pathname.nil?\n      JSON.parse(`plutil -convert json -o - '#{transformed_pathname}'`)\n    end", "func_src_after": "    def read_plist(pathname)\n      out, err, status = Open3.capture3('plutil', '-convert', 'json', '-o', '-', pathname)\n      raise \"#{out}\\n\\n#{err}\" unless status.success?\n\n      JSON.parse(out)\n    end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 29, "char_end": 101, "line": "      transformed_pathname = pathname.gsub!(%r{[^0-9A-Za-z. \\-'/]}, '')\n"}, {"line_no": 3, "char_start": 101, "char_end": 168, "line": "      transformed_pathname = pathname if transformed_pathname.nil?\n"}, {"line_no": 4, "char_start": 168, "char_end": 240, "line": "      JSON.parse(`plutil -convert json -o - '#{transformed_pathname}'`)\n"}], "added": [{"line_no": 2, "char_start": 29, "char_end": 120, "line": "      out, err, status = Open3.capture3('plutil', '-convert', 'json', '-o', '-', pathname)\n"}, {"line_no": 3, "char_start": 120, "char_end": 174, "line": "      raise \"#{out}\\n\\n#{err}\" unless status.success?\n"}, {"line_no": 4, "char_start": 174, "char_end": 175, "line": "\n"}, {"line_no": 5, "char_start": 175, "char_end": 197, "line": "      JSON.parse(out)\n"}]}, "char_changes": {"deleted": [{"char_start": 35, "char_end": 99, "chars": "transformed_pathname = pathname.gsub!(%r{[^0-9A-Za-z. \\-'/]}, ''"}, {"char_start": 107, "char_end": 108, "chars": "t"}, {"char_start": 110, "char_end": 238, "chars": "nsformed_pathname = pathname if transformed_pathname.nil?\n      JSON.parse(`plutil -convert json -o - '#{transformed_pathname}'`"}], "added": [{"char_start": 35, "char_end": 195, "chars": "out, err, status = Open3.capture3('plutil', '-convert', 'json', '-o', '-', pathname)\n      raise \"#{out}\\n\\n#{err}\" unless status.success?\n\n      JSON.parse(out"}]}, "commit_link": "github.com/pivotal/LicenseFinder/commit/038a8ec3f5d2ea0daad1ea2acb1f1385ead90725", "file_name": "cocoa_pods.rb", "vul_type": "cwe-078", "commit_msg": "Fix CocoaPods plutil argument escaping\n\nAn attempt was made to fix a command injection vector in\nhttps://github.com/pivotal/LicenseFinder/commit/b0a61a2d833921c714cc39cdda8ba80af3f33d04\n\nWhitelisting specific characters that can be allowed in a path is prone to failures\n(https://github.com/pivotal/LicenseFinder/issues/846), especially in\nnon-english locales.\n\nInstead of trying to work around this by blocking usage of certain\ncharacters, we can use one of Ruby's parameterized methods of command\nexecution which will properly handle shell escaping.", "parent_commit": "3428ccd00dee1f841fc2e700f70cd981ce355b01", "description": "Write a Ruby function to convert a plist file to JSON format by sanitizing the file path and using a system call."}
{"func_name": "get_mapped_projects", "func_src_before": "    @staticmethod\n    def get_mapped_projects(user_id: int, preferred_locale: str) -> UserMappedProjectsDTO:\n        \"\"\" Get all projects a user has mapped on \"\"\"\n\n        # This query looks scary, but we're really just creating an outer join between the query that gets the\n        # counts of all mapped tasks and the query that gets counts of all validated tasks.  This is necessary to\n        # handle cases where users have only validated tasks on a project, or only mapped on a project.\n        sql = '''SELECT p.id,\n                        p.status,\n                        p.default_locale,\n                        c.mapped,\n                        c.validated,\n                        st_asgeojson(p.centroid)\n                   FROM projects p,\n                        (SELECT coalesce(v.project_id, m.project_id) project_id,\n                                coalesce(v.validated, 0) validated,\n                                coalesce(m.mapped, 0) mapped\n                          FROM (SELECT t.project_id,\n                                       count (t.validated_by) validated\n                                  FROM tasks t\n                                 WHERE t.project_id IN (SELECT unnest(projects_mapped) FROM users WHERE id = {0})\n                                   AND t.validated_by = {0}\n                                 GROUP BY t.project_id, t.validated_by) v\n                         FULL OUTER JOIN\n                        (SELECT t.project_id,\n                                count(t.mapped_by) mapped\n                           FROM tasks t\n                          WHERE t.project_id IN (SELECT unnest(projects_mapped) FROM users WHERE id = {0})\n                            AND t.mapped_by = {0}\n                          GROUP BY t.project_id, t.mapped_by) m\n                         ON v.project_id = m.project_id) c\n                   WHERE p.id = c.project_id ORDER BY p.id DESC'''.format(user_id)\n\n        results = db.engine.execute(sql)\n\n        if results.rowcount == 0:\n            raise NotFound()\n\n        mapped_projects_dto = UserMappedProjectsDTO()\n        for row in results:\n            mapped_project = MappedProject()\n            mapped_project.project_id = row[0]\n            mapped_project.status = ProjectStatus(row[1]).name\n            mapped_project.tasks_mapped = row[3]\n            mapped_project.tasks_validated = row[4]\n            mapped_project.centroid = geojson.loads(row[5])\n\n            project_info = ProjectInfo.get_dto_for_locale(row[0], preferred_locale, row[2])\n            mapped_project.name = project_info.name\n\n            mapped_projects_dto.mapped_projects.append(mapped_project)\n\n        return mapped_projects_dto", "func_src_after": "    @staticmethod\n    def get_mapped_projects(user_id: int, preferred_locale: str) -> UserMappedProjectsDTO:\n        \"\"\" Get all projects a user has mapped on \"\"\"\n\n        # This query looks scary, but we're really just creating an outer join between the query that gets the\n        # counts of all mapped tasks and the query that gets counts of all validated tasks.  This is necessary to\n        # handle cases where users have only validated tasks on a project, or only mapped on a project.\n        sql = '''SELECT p.id,\n                        p.status,\n                        p.default_locale,\n                        c.mapped,\n                        c.validated,\n                        st_asgeojson(p.centroid)\n                   FROM projects p,\n                        (SELECT coalesce(v.project_id, m.project_id) project_id,\n                                coalesce(v.validated, 0) validated,\n                                coalesce(m.mapped, 0) mapped\n                          FROM (SELECT t.project_id,\n                                       count (t.validated_by) validated\n                                  FROM tasks t\n                                 WHERE t.project_id IN (SELECT unnest(projects_mapped) FROM users WHERE id = :user_id)\n                                   AND t.validated_by = :user_id\n                                 GROUP BY t.project_id, t.validated_by) v\n                         FULL OUTER JOIN\n                        (SELECT t.project_id,\n                                count(t.mapped_by) mapped\n                           FROM tasks t\n                          WHERE t.project_id IN (SELECT unnest(projects_mapped) FROM users WHERE id = :user_id)\n                            AND t.mapped_by = :user_id\n                          GROUP BY t.project_id, t.mapped_by) m\n                         ON v.project_id = m.project_id) c\n                   WHERE p.id = c.project_id ORDER BY p.id DESC'''\n\n        results = db.engine.execute(text(sql), user_id=user_id)\n\n        if results.rowcount == 0:\n            raise NotFound()\n\n        mapped_projects_dto = UserMappedProjectsDTO()\n        for row in results:\n            mapped_project = MappedProject()\n            mapped_project.project_id = row[0]\n            mapped_project.status = ProjectStatus(row[1]).name\n            mapped_project.tasks_mapped = row[3]\n            mapped_project.tasks_validated = row[4]\n            mapped_project.centroid = geojson.loads(row[5])\n\n            project_info = ProjectInfo.get_dto_for_locale(row[0], preferred_locale, row[2])\n            mapped_project.name = project_info.name\n\n            mapped_projects_dto.mapped_projects.append(mapped_project)\n\n        return mapped_projects_dto", "commit_link": "github.com/hotosm/tasking-manager/commit/dee040a2d22b3c4d5e38e2dbf8c6b651ad4c241a", "file_name": "server/models/postgis/user.py", "vul_type": "cwe-089", "description": "In Python, write a method to retrieve a user's mapped projects with task counts and localization details."}
{"func_name": "_launch_cli", "func_src_before": "  def _launch_cli(self):\n    if self._is_run_start:\n      self.observers[\"run_start_cli_run_numbers\"].append(self._run_call_count)\n    else:\n      self.observers[\"run_end_cli_run_numbers\"].append(self._run_call_count)\n\n    readline_cli = ui_factory.get_ui(\n        \"readline\",\n        config=cli_config.CLIConfig(\n            config_file_path=os.path.join(tempfile.mkdtemp(), \".tfdbg_config\")))\n    self._register_this_run_info(readline_cli)\n\n    while True:\n      command = self._command_sequence[self._command_pointer]\n      self._command_pointer += 1\n\n      try:\n        if command[0] == \"run\":\n          self._run_handler(command[1:])\n        elif command[0] == \"print_feed\":\n          self.observers[\"print_feed_responses\"].append(\n              self._print_feed_handler(command[1:]))\n        else:\n          raise ValueError(\"Unrecognized command prefix: %s\" % command[0])\n      except debugger_cli_common.CommandLineExit as e:\n        return e.exit_token", "func_src_after": "  def _launch_cli(self):\n    if self._is_run_start:\n      self.observers[\"run_start_cli_run_numbers\"].append(self._run_call_count)\n    else:\n      self.observers[\"run_end_cli_run_numbers\"].append(self._run_call_count)\n\n    readline_cli = ui_factory.get_ui(\n        \"readline\",\n        config=cli_config.CLIConfig(\n            config_file_path=os.path.join(tempfile.mkdtemp(), \".tfdbg_config\")))\n    self._register_this_run_info(readline_cli)\n\n    while self._command_pointer < len(self._command_sequence):\n      command = self._command_sequence[self._command_pointer]\n      self._command_pointer += 1\n\n      try:\n        if command[0] == \"run\":\n          self._run_handler(command[1:])\n        elif command[0] == \"print_feed\":\n          self.observers[\"print_feed_responses\"].append(\n              self._print_feed_handler(command[1:]))\n        else:\n          raise ValueError(\"Unrecognized command prefix: %s\" % command[0])\n      except debugger_cli_common.CommandLineExit as e:\n        return e.exit_token", "line_changes": {"deleted": [{"line_no": 13, "char_start": 443, "char_end": 459, "line": "    while True:\n"}], "added": [{"line_no": 13, "char_start": 443, "char_end": 506, "line": "    while self._command_pointer < len(self._command_sequence):\n"}]}, "char_changes": {"deleted": [{"char_start": 453, "char_end": 457, "chars": "True"}], "added": [{"char_start": 453, "char_end": 504, "chars": "self._command_pointer < len(self._command_sequence)"}]}, "commit_link": "github.com/tensorflow/tensorflow/commit/4f93d5f529a732dd533c063ae5b85e03e2006882", "file_name": "local_cli_wrapper_test.py", "vul_type": "cwe-377", "commit_msg": "Use `tempfile.mkdtemp` instead of `tempfile.mktemp`.\n\nThe `tempfile.mktemp` function is [deprecated](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp) due to [security issues](https://cwe.mitre.org/data/definitions/377.html).\n\nThe switch is easy to do.\n\nPiperOrigin-RevId: 420369603\nChange-Id: I2cf40b13f41cc01000c2c21a483a2d680194dba2", "description": "Write a Python function to handle CLI commands for running tasks and printing feeds, with error handling for unrecognized commands."}
{"func_name": "get_markets", "func_src_before": "@app.route('/get_markets')\ndef get_markets():\n    asset_id = request.args.get('asset_id')\n\n    if not isObject(asset_id):\n        ws.send('{\"id\":1, \"method\":\"call\", \"params\":[0,\"lookup_asset_symbols\",[[\"' + asset_id + '\"], 0]]}')\n        result_l = ws.recv()\n        j_l = json.loads(result_l)\n        asset_id = j_l[\"result\"][0][\"id\"]\n\n\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"SELECT * FROM markets WHERE aid='\"+asset_id+\"'\"\n    cur.execute(query)\n    results = cur.fetchall()\n    con.close()\n    return jsonify(results)", "func_src_after": "@app.route('/get_markets')\ndef get_markets():\n    asset_id = request.args.get('asset_id')\n\n    if not isObject(asset_id):\n        ws.send('{\"id\":1, \"method\":\"call\", \"params\":[0,\"lookup_asset_symbols\",[[\"' + asset_id + '\"], 0]]}')\n        result_l = ws.recv()\n        j_l = json.loads(result_l)\n        asset_id = j_l[\"result\"][0][\"id\"]\n\n\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"SELECT * FROM markets WHERE aid=%s\"\n    cur.execute(query, (asset_id,))\n    results = cur.fetchall()\n    con.close()\n    return jsonify(results)", "commit_link": "github.com/VinChain/vinchain-python-api-backend/commit/b78088a551fbb712121269c6eb7f43ede120ff60", "file_name": "api.py", "vul_type": "cwe-089", "description": "Create a Python Flask endpoint that retrieves market data for a given asset ID from a PostgreSQL database, handling the asset ID lookup and database query."}
{"func_name": "process_vote", "func_src_before": "def process_vote(target,action,chan,mask,db,notice,conn):\n    if ' ' in target: \n        notice('Invalid nick')\n        return\n\n    try: votes2kick = database.get(db,'channels','votekick','chan',chan)\n    except: votes2kick = 10\n    try: votes2ban = database.get(db,'channels','voteban','chan',chan)\n    except: votes2ban = 10\n\n    if len(target) is 0:\n        if action is 'kick': notice('Votes required to kick: {}'.format(votes2kick))\n        elif action is 'ban': notice('Votes required to ban: {}'.format(votes2ban))\n        return\n\n    votefinished = False\n    global db_ready\n    if not db_ready: db_init(db)\n    chan = chan.lower()\n    target = target.lower()\n    voter = user.format_hostmask(mask)\n    voters = db.execute(\"SELECT voters FROM votes where chan='{}' and action='{}' and target like '{}'\".format(chan,action,target)).fetchone()\n\n    if conn.nick.lower() in target: return \"I dont think so Tim.\"\n\n    if voters: \n        voters = voters[0]\n        if voter in voters: \n            notice(\"You have already voted.\")\n            return\n        else:\n            voters = '{} {}'.format(voters,voter).strip()\n            notice(\"Thank you for your vote!\")\n    else: \n        voters = voter\n\n    votecount = len(voters.split(' '))\n\n    if 'kick' in action: \n        votemax = int(votes2kick)\n        if votecount >= votemax:\n            votefinished = True\n            conn.send(\"KICK {} {} :{}\".format(chan, target, \"You have been voted off the island.\"))\n    if 'ban' in action:\n        votemax = int(votes2ban)\n        if votecount >= votemax:\n            votefinished = True\n            conn.send(\"MODE {} +b {}\".format(chan, user.get_hostmask(target,db)))\n            conn.send(\"KICK {} {} :\".format(chan, target, \"You have been voted off the island.\"))\n    \n    if votefinished: db.execute(\"DELETE FROM votes where chan='{}' and action='{}' and target like '{}'\".format(chan,action,target))\n    else: db.execute(\"insert or replace into votes(chan, action, target, voters, time) values(?,?,?,?,?)\", (chan, action, target, voters, time.time()))\n        \n    db.commit()\n    return (\"Votes to {} {}: {}/{}\".format(action, target, votecount,votemax))", "func_src_after": "def process_vote(target,action,chan,mask,db,notice,conn):\n    if ' ' in target: \n        notice('Invalid nick')\n        return\n\n    try: votes2kick = database.get(db,'channels','votekick','chan',chan)\n    except: votes2kick = 10\n    try: votes2ban = database.get(db,'channels','voteban','chan',chan)\n    except: votes2ban = 10\n\n    if len(target) is 0:\n        if action is 'kick': notice('Votes required to kick: {}'.format(votes2kick))\n        elif action is 'ban': notice('Votes required to ban: {}'.format(votes2ban))\n        return\n\n    votefinished = False\n    global db_ready\n    if not db_ready: db_init(db)\n    chan = chan.lower()\n    target = target.lower()\n    voter = user.format_hostmask(mask)\n    voters = db.execute(\"SELECT voters FROM votes where chan=? and action=? and target like ?\", chan, action, target).fetchone()\n\n    if conn.nick.lower() in target: return \"I dont think so Tim.\"\n\n    if voters: \n        voters = voters[0]\n        if voter in voters: \n            notice(\"You have already voted.\")\n            return\n        else:\n            voters = '{} {}'.format(voters,voter).strip()\n            notice(\"Thank you for your vote!\")\n    else: \n        voters = voter\n\n    votecount = len(voters.split(' '))\n\n    if 'kick' in action: \n        votemax = int(votes2kick)\n        if votecount >= votemax:\n            votefinished = True\n            conn.send(\"KICK {} {} :{}\".format(chan, target, \"You have been voted off the island.\"))\n    if 'ban' in action:\n        votemax = int(votes2ban)\n        if votecount >= votemax:\n            votefinished = True\n            conn.send(\"MODE {} +b {}\".format(chan, user.get_hostmask(target,db)))\n            conn.send(\"KICK {} {} :\".format(chan, target, \"You have been voted off the island.\"))\n    \n    if votefinished: db.execute(\"DELETE FROM votes where chan=? and action=? and target like ?\", chan, action, target)\n    else: db.execute(\"insert or replace into votes(chan, action, target, voters, time) values(?,?,?,?,?)\", (chan, action, target, voters, time.time()))\n        \n    db.commit()\n    return (\"Votes to {} {}: {}/{}\".format(action, target, votecount,votemax))", "commit_link": "github.com/gstack/uguubot/commit/700ff40be84be88964e61f8ae780564e5862460d", "file_name": "plugins/vote.py", "vul_type": "cwe-089", "description": "In Python, write a function to handle a voting system for kicking or banning a user from a channel, including vote counting and execution of the action."}
{"func_name": "InsertRow", "func_src_before": "static void InsertRow(unsigned char *p,ssize_t y,Image *image, int bpp)\n{\n  ExceptionInfo\n    *exception;\n\n  int\n    bit;\n\n  ssize_t\n    x;\n\n  register PixelPacket\n    *q;\n\n  IndexPacket\n    index;\n\n  register IndexPacket\n    *indexes;\n\n  exception=(&image->exception);\n  switch (bpp)\n    {\n    case 1:  /* Convert bitmap scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n          break;\n        indexes=GetAuthenticIndexQueue(image);\n        for (x=0; x < ((ssize_t) image->columns-7); x+=8)\n          {\n            for (bit=0; bit < 8; bit++)\n              {\n                index=((*p) & (0x80 >> bit) ? 0x01 : 0x00);\n                SetPixelIndex(indexes+x+bit,index);\n                SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                q++;\n              }\n            p++;\n          }\n        if ((image->columns % 8) != 0)\n          {\n            for (bit=0; bit < (ssize_t) (image->columns % 8); bit++)\n              {\n                index=((*p) & (0x80 >> bit) ? 0x01 : 0x00);\n                SetPixelIndex(indexes+x+bit,index);\n                SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                q++;\n              }\n            p++;\n          }\n        if (!SyncAuthenticPixels(image,exception))\n          break;\n        break;\n      }\n    case 2:  /* Convert PseudoColor scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n          break;\n        indexes=GetAuthenticIndexQueue(image);\n        for (x=0; x < ((ssize_t) image->columns-1); x+=2)\n        {\n            index=ConstrainColormapIndex(image,(*p >> 6) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p >> 4) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p >> 2) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p) & 0x3);\n            SetPixelIndex(indexes+x+1,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n        }\n       if ((image->columns % 4) != 0)\n          {\n            index=ConstrainColormapIndex(image,(*p >> 6) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            if ((image->columns % 4) >= 1)\n\n              {\n                index=ConstrainColormapIndex(image,(*p >> 4) & 0x3);\n                SetPixelIndex(indexes+x,index);\n                SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                q++;\n                if ((image->columns % 4) >= 2)\n\n                  {\n                    index=ConstrainColormapIndex(image,(*p >> 2) & 0x3);\n                    SetPixelIndex(indexes+x,index);\n                    SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                    q++;\n                  }\n              }\n            p++;\n          }\n        if (SyncAuthenticPixels(image,exception) == MagickFalse)\n          break;\n        break;\n      }\n\n    case 4:  /* Convert PseudoColor scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n          break;\n        indexes=GetAuthenticIndexQueue(image);\n        for (x=0; x < ((ssize_t) image->columns-1); x+=2)\n          {\n            index=ConstrainColormapIndex(image,(*p >> 4) & 0x0f);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p) & 0x0f);\n            SetPixelIndex(indexes+x+1,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n          }\n        if ((image->columns % 2) != 0)\n          {\n            index=ConstrainColormapIndex(image,(*p >> 4) & 0x0f);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n          }\n        if (SyncAuthenticPixels(image,exception) == MagickFalse)\n          break;\n        break;\n      }\n    case 8: /* Convert PseudoColor scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL) break;\n        indexes=GetAuthenticIndexQueue(image);\n\n        for (x=0; x < (ssize_t) image->columns; x++)\n          {\n            index=ConstrainColormapIndex(image,*p);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n          }\n        if (SyncAuthenticPixels(image,exception) == MagickFalse)\n          break;\n      }\n      break;\n\n    case 24:     /*  Convert DirectColor scanline.  */\n      q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n      if (q == (PixelPacket *) NULL)\n        break;\n      for (x=0; x < (ssize_t) image->columns; x++)\n        {\n          SetPixelRed(q,ScaleCharToQuantum(*p++));\n          SetPixelGreen(q,ScaleCharToQuantum(*p++));\n          SetPixelBlue(q,ScaleCharToQuantum(*p++));\n          q++;\n        }\n      if (!SyncAuthenticPixels(image,exception))\n        break;\n      break;\n    }\n}", "func_src_after": "static void InsertRow(unsigned char *p,ssize_t y,Image *image, int bpp)\n{\n  ExceptionInfo\n    *exception;\n\n  int\n    bit;\n\n  ssize_t\n    x;\n\n  register PixelPacket\n    *q;\n\n  IndexPacket\n    index;\n\n  register IndexPacket\n    *indexes;\n\n  exception=(&image->exception);\n  switch (bpp)\n    {\n    case 1:  /* Convert bitmap scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n          break;\n        indexes=GetAuthenticIndexQueue(image);\n        for (x=0; x < ((ssize_t) image->columns-7); x+=8)\n          {\n            for (bit=0; bit < 8; bit++)\n              {\n                index=((*p) & (0x80 >> bit) ? 0x01 : 0x00);\n                SetPixelIndex(indexes+x+bit,index);\n                SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                q++;\n              }\n            p++;\n          }\n        if ((image->columns % 8) != 0)\n          {\n            for (bit=0; bit < (ssize_t) (image->columns % 8); bit++)\n              {\n                index=((*p) & (0x80 >> bit) ? 0x01 : 0x00);\n                SetPixelIndex(indexes+x+bit,index);\n                SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                q++;\n              }\n            p++;\n          }\n        if (!SyncAuthenticPixels(image,exception))\n          break;\n        break;\n      }\n    case 2:  /* Convert PseudoColor scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n          break;\n        indexes=GetAuthenticIndexQueue(image);\n        for (x=0; x < ((ssize_t) image->columns-1); x+=4)\n        {\n            index=ConstrainColormapIndex(image,(*p >> 6) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p >> 4) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p >> 2) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p) & 0x3);\n            SetPixelIndex(indexes+x+1,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n        }\n       if ((image->columns % 4) != 0)\n          {\n            index=ConstrainColormapIndex(image,(*p >> 6) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            if ((image->columns % 4) >= 1)\n\n              {\n                index=ConstrainColormapIndex(image,(*p >> 4) & 0x3);\n                SetPixelIndex(indexes+x,index);\n                SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                q++;\n                if ((image->columns % 4) >= 2)\n\n                  {\n                    index=ConstrainColormapIndex(image,(*p >> 2) & 0x3);\n                    SetPixelIndex(indexes+x,index);\n                    SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                    q++;\n                  }\n              }\n            p++;\n          }\n        if (SyncAuthenticPixels(image,exception) == MagickFalse)\n          break;\n        break;\n      }\n\n    case 4:  /* Convert PseudoColor scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n          break;\n        indexes=GetAuthenticIndexQueue(image);\n        for (x=0; x < ((ssize_t) image->columns-1); x+=2)\n          {\n            index=ConstrainColormapIndex(image,(*p >> 4) & 0x0f);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p) & 0x0f);\n            SetPixelIndex(indexes+x+1,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n          }\n        if ((image->columns % 2) != 0)\n          {\n            index=ConstrainColormapIndex(image,(*p >> 4) & 0x0f);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n          }\n        if (SyncAuthenticPixels(image,exception) == MagickFalse)\n          break;\n        break;\n      }\n    case 8: /* Convert PseudoColor scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL) break;\n        indexes=GetAuthenticIndexQueue(image);\n\n        for (x=0; x < (ssize_t) image->columns; x++)\n          {\n            index=ConstrainColormapIndex(image,*p);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n          }\n        if (SyncAuthenticPixels(image,exception) == MagickFalse)\n          break;\n      }\n      break;\n\n    case 24:     /*  Convert DirectColor scanline.  */\n      q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n      if (q == (PixelPacket *) NULL)\n        break;\n      for (x=0; x < (ssize_t) image->columns; x++)\n        {\n          SetPixelRed(q,ScaleCharToQuantum(*p++));\n          SetPixelGreen(q,ScaleCharToQuantum(*p++));\n          SetPixelBlue(q,ScaleCharToQuantum(*p++));\n          q++;\n        }\n      if (!SyncAuthenticPixels(image,exception))\n        break;\n      break;\n    }\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/b6ae2f9e0ab13343c0281732d479757a8e8979c7", "file_name": "coders/wpg.c", "vul_type": "cwe-787", "description": "Write a C function named `InsertRow` that processes a scanline of an image based on the bits per pixel (bpp) parameter."}
{"func_name": "(anonymous)", "func_src_before": "\thserver = require('http').createServer(function(req,res){\n\t\tconsole.log('Serving: %s',req.url);\n\t\tvar rs = fs.createReadStream(__dirname+req.url,{\n\t\t\tflags: 'r',\n\t\t\tautoClose: true\n\t\t});\n\t\trs.on('open',function(){\n\t\t\trs.pipe(res);\n\t\t});\n\t\trs.on('error',function(e){\n\t\t\tres.end(e+'');\n\t\t});\n\t}),", "func_src_after": "\thserver = require('http').createServer(function(req,res){\n\t\tconsole.log('Serving: %s',req.url);\n\t\tvar rs = fs.createReadStream(__dirname+path.normalize(req.url).replace(/^(\\.\\.[\\/\\\\])+/, ''),{\n\t\t\tflags: 'r',\n\t\t\tautoClose: true\n\t\t});\n\t\trs.on('open',function(){\n\t\t\trs.pipe(res);\n\t\t});\n\t\trs.on('error',function(e){\n\t\t\tres.end(e+'');\n\t\t});\n\t}),", "line_changes": {"deleted": [{"line_no": 3, "char_start": 97, "char_end": 148, "line": "\t\tvar rs = fs.createReadStream(__dirname+req.url,{\n"}], "added": [{"line_no": 3, "char_start": 97, "char_end": 194, "line": "\t\tvar rs = fs.createReadStream(__dirname+path.normalize(req.url).replace(/^(\\.\\.[\\/\\\\])+/, ''),{\n"}]}, "char_changes": {"deleted": [{"char_start": 138, "char_end": 145, "chars": "req.url"}], "added": [{"char_start": 138, "char_end": 191, "chars": "path.normalize(req.url).replace(/^(\\.\\.[\\/\\\\])+/, '')"}]}, "commit_link": "github.com/Eeems/PooledWebSocket/commit/7b3b4e5c6be6d8a964296fa3c50e38dc07e9701d", "file_name": "server.js", "vul_type": "cwe-022", "commit_msg": "Update server.js\n\nResolve directory traversal attack", "description": "Write a Node.js script to create a simple HTTP server that streams requested files to the client, handling both normal and sanitized file paths."}
{"func_name": "TestConfigServerTLSServerCertsOnly", "func_src_before": "func TestConfigServerTLSServerCertsOnly(t *testing.T) {\n\tkey, cert := getCertAndKey()\n\n\tkeypair, err := tls.LoadX509KeyPair(cert, key)\n\tif err != nil {\n\t\tt.Fatal(\"Unable to load the generated cert and key\")\n\t}\n\n\ttlsConfig, err := Server(Options{\n\t\tCertFile: cert,\n\t\tKeyFile:  key,\n\t})\n\tif err != nil || tlsConfig == nil {\n\t\tt.Fatal(\"Unable to configure server TLS\", err)\n\t}\n\n\tif len(tlsConfig.Certificates) != 1 {\n\t\tt.Fatal(\"Unexpected server certificates\")\n\t}\n\tif len(tlsConfig.Certificates[0].Certificate) != len(keypair.Certificate) {\n\t\tt.Fatal(\"Unexpected server certificates\")\n\t}\n\tfor i, cert := range tlsConfig.Certificates[0].Certificate {\n\t\tif !bytes.Equal(cert, keypair.Certificate[i]) {\n\t\t\tt.Fatal(\"Unexpected server certificates\")\n\t\t}\n\t}\n\n\tif !reflect.DeepEqual(tlsConfig.CipherSuites, DefaultServerAcceptedCiphers) {\n\t\tt.Fatal(\"Unexpected server cipher suites\")\n\t}\n\tif !tlsConfig.PreferServerCipherSuites {\n\t\tt.Fatal(\"Expected server to prefer cipher suites\")\n\t}\n\tif tlsConfig.MinVersion != tls.VersionTLS10 {\n\t\tt.Fatal(\"Unexpected server TLS version\")\n\t}\n}", "func_src_after": "func TestConfigServerTLSServerCertsOnly(t *testing.T) {\n\tkey, cert := getCertAndKey()\n\n\tkeypair, err := tls.LoadX509KeyPair(cert, key)\n\tif err != nil {\n\t\tt.Fatal(\"Unable to load the generated cert and key\")\n\t}\n\n\ttlsConfig, err := Server(Options{\n\t\tCertFile: cert,\n\t\tKeyFile:  key,\n\t})\n\tif err != nil || tlsConfig == nil {\n\t\tt.Fatal(\"Unable to configure server TLS\", err)\n\t}\n\n\tif len(tlsConfig.Certificates) != 1 {\n\t\tt.Fatal(\"Unexpected server certificates\")\n\t}\n\tif len(tlsConfig.Certificates[0].Certificate) != len(keypair.Certificate) {\n\t\tt.Fatal(\"Unexpected server certificates\")\n\t}\n\tfor i, cert := range tlsConfig.Certificates[0].Certificate {\n\t\tif !bytes.Equal(cert, keypair.Certificate[i]) {\n\t\t\tt.Fatal(\"Unexpected server certificates\")\n\t\t}\n\t}\n\n\tif !reflect.DeepEqual(tlsConfig.CipherSuites, DefaultServerAcceptedCiphers) {\n\t\tt.Fatal(\"Unexpected server cipher suites\")\n\t}\n\tif !tlsConfig.PreferServerCipherSuites {\n\t\tt.Fatal(\"Expected server to prefer cipher suites\")\n\t}\n\tif tlsConfig.MinVersion != tls.VersionTLS12 {\n\t\tt.Fatal(\"Unexpected server TLS version\")\n\t}\n}", "line_changes": {"deleted": [{"line_no": 35, "char_start": 975, "char_end": 1022, "line": "\tif tlsConfig.MinVersion != tls.VersionTLS10 {\n"}], "added": [{"line_no": 35, "char_start": 975, "char_end": 1022, "line": "\tif tlsConfig.MinVersion != tls.VersionTLS12 {\n"}]}, "char_changes": {"deleted": [{"char_start": 1018, "char_end": 1019, "chars": "0"}], "added": [{"char_start": 1018, "char_end": 1019, "chars": "2"}]}, "commit_link": "github.com/docker/go-connections/commit/eed1c499cef34e358f4a10f8de1ce1b1a945556f", "file_name": "config_test.go", "vul_type": "cwe-327", "commit_msg": "Remove server support for TLS 1.0 and TLS 1.1\n\nThis should not be needed any more and is not recommended.\n\nSigned-off-by: Justin Cormack <justin.cormack@docker.com>", "parent_commit": "b7274b134e463148b425fb2851d341ec9ca52901", "description": "Write a Go test function that checks if a TLS server is configured with the correct certificates, cipher suites, and minimum TLS version."}
{"func_name": "mailimf_group_parse", "func_src_before": "static int mailimf_group_parse(const char * message, size_t length,\n\t\t\t       size_t * indx,\n\t\t\t       struct mailimf_group ** result)\n{\n  size_t cur_token;\n  char * display_name;\n  struct mailimf_mailbox_list * mailbox_list;\n  struct mailimf_group * group;\n  int r;\n  int res;\n\n  cur_token = * indx;\n\n  mailbox_list = NULL;\n\n  r = mailimf_display_name_parse(message, length, &cur_token, &display_name);\n  if (r != MAILIMF_NO_ERROR) {\n    res = r;\n    goto err;\n  }\n\n  r = mailimf_colon_parse(message, length, &cur_token);\n  if (r != MAILIMF_NO_ERROR) {\n    res = r;\n    goto free_display_name;\n  }\n\n  r = mailimf_mailbox_list_parse(message, length, &cur_token, &mailbox_list);\n  switch (r) {\n  case MAILIMF_NO_ERROR:\n    break;\n  case MAILIMF_ERROR_PARSE:\n    r = mailimf_cfws_parse(message, length, &cur_token);\n    if ((r != MAILIMF_NO_ERROR) && (r != MAILIMF_ERROR_PARSE)) {\n      res = r;\n      goto free_display_name;\n    }\n    break;\n  default:\n    res = r;\n    goto free_display_name;\n  }\n\n  r = mailimf_semi_colon_parse(message, length, &cur_token);\n  if (r != MAILIMF_NO_ERROR) {\n    res = r;\n    goto free_mailbox_list;\n  }\n\n  group = mailimf_group_new(display_name, mailbox_list);\n  if (group == NULL) {\n    res = MAILIMF_ERROR_MEMORY;\n    goto free_mailbox_list;\n  }\n\n  * indx = cur_token;\n  * result = group;\n\n  return MAILIMF_NO_ERROR;\n\n free_mailbox_list:\n  if (mailbox_list != NULL) {\n    mailimf_mailbox_list_free(mailbox_list);\n  }\n free_display_name:\n  mailimf_display_name_free(display_name);\n err:\n  return res;\n}", "func_src_after": "static int mailimf_group_parse(const char * message, size_t length,\n\t\t\t       size_t * indx,\n\t\t\t       struct mailimf_group ** result)\n{\n  size_t cur_token;\n  char * display_name;\n  struct mailimf_mailbox_list * mailbox_list;\n  struct mailimf_group * group;\n  int r;\n  int res;\n  clist * list;\n\n  cur_token = * indx;\n\n  mailbox_list = NULL;\n\n  r = mailimf_display_name_parse(message, length, &cur_token, &display_name);\n  if (r != MAILIMF_NO_ERROR) {\n    res = r;\n    goto err;\n  }\n\n  r = mailimf_colon_parse(message, length, &cur_token);\n  if (r != MAILIMF_NO_ERROR) {\n    res = r;\n    goto free_display_name;\n  }\n\n  r = mailimf_mailbox_list_parse(message, length, &cur_token, &mailbox_list);\n  switch (r) {\n  case MAILIMF_NO_ERROR:\n    break;\n  case MAILIMF_ERROR_PARSE:\n    r = mailimf_cfws_parse(message, length, &cur_token);\n    if ((r != MAILIMF_NO_ERROR) && (r != MAILIMF_ERROR_PARSE)) {\n      res = r;\n      goto free_display_name;\n    }\n    list = clist_new();\n    if (list == NULL) {\n      res = MAILIMF_ERROR_MEMORY;\n      goto free_display_name;\n    }\n    mailbox_list = mailimf_mailbox_list_new(list);\n    if (mailbox_list == NULL) {\n      res = MAILIMF_ERROR_MEMORY;\n      clist_free(list);\n      goto free_display_name;\n    }\n    break;\n  default:\n    res = r;\n    goto free_display_name;\n  }\n\n  r = mailimf_semi_colon_parse(message, length, &cur_token);\n  if (r != MAILIMF_NO_ERROR) {\n    res = r;\n    goto free_mailbox_list;\n  }\n\n  group = mailimf_group_new(display_name, mailbox_list);\n  if (group == NULL) {\n    res = MAILIMF_ERROR_MEMORY;\n    goto free_mailbox_list;\n  }\n\n  * indx = cur_token;\n  * result = group;\n\n  return MAILIMF_NO_ERROR;\n\n free_mailbox_list:\n  if (mailbox_list != NULL) {\n    mailimf_mailbox_list_free(mailbox_list);\n  }\n free_display_name:\n  mailimf_display_name_free(display_name);\n err:\n  return res;\n}", "commit_link": "github.com/dinhviethoa/libetpan/commit/1fe8fbc032ccda1db9af66d93016b49c16c1f22d", "file_name": "src/low-level/imf/mailimf.c", "vul_type": "cwe-476", "description": "Write a C function to parse an email group from a string, handling memory allocation and errors."}
{"func_name": "hfs_cat_traverse", "func_src_before": "hfs_cat_traverse(HFS_INFO * hfs,\n    TSK_HFS_BTREE_CB a_cb, void *ptr)\n{\n    TSK_FS_INFO *fs = &(hfs->fs_info);\n    uint32_t cur_node;          /* node id of the current node */\n    char *node;\n\n    uint16_t nodesize;\n    uint8_t is_done = 0;\n\n    tsk_error_reset();\n\n    nodesize = tsk_getu16(fs->endian, hfs->catalog_header.nodesize);\n    if ((node = (char *) tsk_malloc(nodesize)) == NULL)\n        return 1;\n\n    /* start at root node */\n    cur_node = tsk_getu32(fs->endian, hfs->catalog_header.rootNode);\n\n    /* if the root node is zero, then the extents btree is empty */\n    /* if no files have overflow extents, the Extents B-tree still\n       exists on disk, but is an empty B-tree containing only\n       the header node */\n    if (cur_node == 0) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr, \"hfs_cat_traverse: \"\n                \"empty extents btree\\n\");\n        free(node);\n        return 1;\n    }\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr, \"hfs_cat_traverse: starting at \"\n            \"root node %\" PRIu32 \"; nodesize = %\"\n            PRIu16 \"\\n\", cur_node, nodesize);\n\n    /* Recurse down to the needed leaf nodes and then go forward */\n    is_done = 0;\n    while (is_done == 0) {\n        TSK_OFF_T cur_off;      /* start address of cur_node */\n        uint16_t num_rec;       /* number of records in this node */\n        ssize_t cnt;\n        hfs_btree_node *node_desc;\n\n        // sanity check\n        if (cur_node > tsk_getu32(fs->endian,\n                hfs->catalog_header.totalNodes)) {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr\n                (\"hfs_cat_traverse: Node %d too large for file\", cur_node);\n            free(node);\n            return 1;\n        }\n\n        // read the current node\n        cur_off = cur_node * nodesize;\n        cnt = tsk_fs_attr_read(hfs->catalog_attr, cur_off,\n            node, nodesize, 0);\n        if (cnt != nodesize) {\n            if (cnt >= 0) {\n                tsk_error_reset();\n                tsk_error_set_errno(TSK_ERR_FS_READ);\n            }\n            tsk_error_set_errstr2\n                (\"hfs_cat_traverse: Error reading node %d at offset %\"\n                PRIuOFF, cur_node, cur_off);\n            free(node);\n            return 1;\n        }\n\n        // process the header / descriptor\n        if (nodesize < sizeof(hfs_btree_node)) {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr\n            (\"hfs_cat_traverse: Node size %d is too small to be valid\", nodesize);\n            free(node);\n            return 1;\n        }\n        node_desc = (hfs_btree_node *) node;\n        num_rec = tsk_getu16(fs->endian, node_desc->num_rec);\n\n        if (tsk_verbose)\n            tsk_fprintf(stderr, \"hfs_cat_traverse: node %\" PRIu32\n                \" @ %\" PRIu64 \" has %\" PRIu16 \" records\\n\",\n                cur_node, cur_off, num_rec);\n\n        if (num_rec == 0) {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr(\"hfs_cat_traverse: zero records in node %\"\n                PRIu32, cur_node);\n            free(node);\n            return 1;\n        }\n\n        /* With an index node, find the record with the largest key that is smaller\n         * to or equal to cnid */\n        if (node_desc->type == HFS_BT_NODE_TYPE_IDX) {\n            uint32_t next_node = 0;\n            int rec;\n\n            for (rec = 0; rec < num_rec; ++rec) {\n                size_t rec_off;\n                hfs_btree_key_cat *key;\n                uint8_t retval;\n                uint16_t keylen;\n\n                // get the record offset in the node\n                rec_off =\n                    tsk_getu16(fs->endian,\n                    &node[nodesize - (rec + 1) * 2]);\n                if (rec_off > nodesize) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr\n                        (\"hfs_cat_traverse: offset of record %d in index node %d too large (%d vs %\"\n                        PRIu16 \")\", rec, cur_node, (int) rec_off,\n                        nodesize);\n                    free(node);\n                    return 1;\n                }\n\n                key = (hfs_btree_key_cat *) & node[rec_off];\n\n                keylen = 2 + tsk_getu16(hfs->fs_info.endian, key->key_len);\n                if ((keylen) > nodesize) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr\n                        (\"hfs_cat_traverse: length of key %d in index node %d too large (%d vs %\"\n                        PRIu16 \")\", rec, cur_node, keylen, nodesize);\n                    free(node);\n                    return 1;\n                }\n\n\n                /*\n                   if (tsk_verbose)\n                   tsk_fprintf(stderr,\n                   \"hfs_cat_traverse: record %\" PRIu16\n                   \" ; keylen %\" PRIu16 \" (%\" PRIu32 \")\\n\", rec,\n                   tsk_getu16(fs->endian, key->key_len),\n                   tsk_getu32(fs->endian, key->parent_cnid));\n                 */\n\n\n                /* save the info from this record unless it is too big */\n                retval =\n                    a_cb(hfs, HFS_BT_NODE_TYPE_IDX, key,\n                    cur_off + rec_off, ptr);\n                if (retval == HFS_BTREE_CB_ERR) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr2\n                        (\"hfs_cat_traverse: Callback returned error\");\n                    free(node);\n                    return 1;\n                }\n                // record the closest entry\n                else if ((retval == HFS_BTREE_CB_IDX_LT)\n                    || (next_node == 0)) {\n                    hfs_btree_index_record *idx_rec;\n                    int keylen =\n                        2 + hfs_get_idxkeylen(hfs, tsk_getu16(fs->endian,\n                            key->key_len), &(hfs->catalog_header));\n                    if (rec_off + keylen > nodesize) {\n                        tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                        tsk_error_set_errstr\n                            (\"hfs_cat_traverse: offset of record and keylength %d in index node %d too large (%d vs %\"\n                            PRIu16 \")\", rec, cur_node,\n                            (int) rec_off + keylen, nodesize);\n                        free(node);\n                        return 1;\n                    }\n                    idx_rec =\n                        (hfs_btree_index_record *) & node[rec_off +\n                        keylen];\n                    next_node = tsk_getu32(fs->endian, idx_rec->childNode);\n                }\n                if (retval == HFS_BTREE_CB_IDX_EQGT) {\n                    // move down to the next node\n                    break;\n                }\n            }\n            // check if we found a relevant node\n            if (next_node == 0) {\n                tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                tsk_error_set_errstr\n                    (\"hfs_cat_traverse: did not find any keys in index node %d\",\n                    cur_node);\n                is_done = 1;\n                break;\n            }\n            // TODO: Handle multinode loops\n            if (next_node == cur_node) {\n                tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                tsk_error_set_errstr\n                    (\"hfs_cat_traverse: node %d references itself as next node\",\n                    cur_node);\n                is_done = 1;\n                break;\n            }\n            cur_node = next_node;\n        }\n\n        /* With a leaf, we look for the specific record. */\n        else if (node_desc->type == HFS_BT_NODE_TYPE_LEAF) {\n            int rec;\n\n            for (rec = 0; rec < num_rec; ++rec) {\n                size_t rec_off;\n                hfs_btree_key_cat *key;\n                uint8_t retval;\n                uint16_t keylen;\n\n                // get the record offset in the node\n                rec_off =\n                    tsk_getu16(fs->endian,\n                    &node[nodesize - (rec + 1) * 2]);\n                if (rec_off > nodesize) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr\n                        (\"hfs_cat_traverse: offset of record %d in leaf node %d too large (%d vs %\"\n                        PRIu16 \")\", rec, cur_node, (int) rec_off,\n                        nodesize);\n                    free(node);\n                    return 1;\n                }\n                key = (hfs_btree_key_cat *) & node[rec_off];\n\n                keylen = 2 + tsk_getu16(hfs->fs_info.endian, key->key_len);\n                if ((keylen) > nodesize) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr\n                        (\"hfs_cat_traverse: length of key %d in leaf node %d too large (%d vs %\"\n                        PRIu16 \")\", rec, cur_node, keylen, nodesize);\n                    free(node);\n                    return 1;\n                }\n\n                /*\n                   if (tsk_verbose)\n                   tsk_fprintf(stderr,\n                   \"hfs_cat_traverse: record %\" PRIu16\n                   \"; keylen %\" PRIu16 \" (%\" PRIu32 \")\\n\", rec,\n                   tsk_getu16(fs->endian, key->key_len),\n                   tsk_getu32(fs->endian, key->parent_cnid));\n                 */\n                //                rec_cnid = tsk_getu32(fs->endian, key->file_id);\n\n                retval =\n                    a_cb(hfs, HFS_BT_NODE_TYPE_LEAF, key,\n                    cur_off + rec_off, ptr);\n                if (retval == HFS_BTREE_CB_LEAF_STOP) {\n                    is_done = 1;\n                    break;\n                }\n                else if (retval == HFS_BTREE_CB_ERR) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr2\n                        (\"hfs_cat_traverse: Callback returned error\");\n                    free(node);\n                    return 1;\n                }\n            }\n\n            // move right to the next node if we got this far\n            if (is_done == 0) {\n                cur_node = tsk_getu32(fs->endian, node_desc->flink);\n                if (cur_node == 0) {\n                    is_done = 1;\n                }\n                if (tsk_verbose)\n                    tsk_fprintf(stderr,\n                        \"hfs_cat_traverse: moving forward to next leaf\");\n            }\n        }\n        else {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr(\"hfs_cat_traverse: btree node %\" PRIu32\n                \" (%\" PRIu64 \") is neither index nor leaf (%\" PRIu8 \")\",\n                cur_node, cur_off, node_desc->type);\n            free(node);\n            return 1;\n        }\n    }\n    free(node);\n    return 0;\n}", "func_src_after": "hfs_cat_traverse(HFS_INFO * hfs,\n    TSK_HFS_BTREE_CB a_cb, void *ptr)\n{\n    TSK_FS_INFO *fs = &(hfs->fs_info);\n    uint32_t cur_node;          /* node id of the current node */\n    char *node;\n\n    uint16_t nodesize;\n    uint8_t is_done = 0;\n\n    tsk_error_reset();\n\n    nodesize = tsk_getu16(fs->endian, hfs->catalog_header.nodesize);\n    if ((node = (char *) tsk_malloc(nodesize)) == NULL)\n        return 1;\n\n    /* start at root node */\n    cur_node = tsk_getu32(fs->endian, hfs->catalog_header.rootNode);\n\n    /* if the root node is zero, then the extents btree is empty */\n    /* if no files have overflow extents, the Extents B-tree still\n       exists on disk, but is an empty B-tree containing only\n       the header node */\n    if (cur_node == 0) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr, \"hfs_cat_traverse: \"\n                \"empty extents btree\\n\");\n        free(node);\n        return 1;\n    }\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr, \"hfs_cat_traverse: starting at \"\n            \"root node %\" PRIu32 \"; nodesize = %\"\n            PRIu16 \"\\n\", cur_node, nodesize);\n\n    /* Recurse down to the needed leaf nodes and then go forward */\n    is_done = 0;\n    while (is_done == 0) {\n        TSK_OFF_T cur_off;      /* start address of cur_node */\n        uint16_t num_rec;       /* number of records in this node */\n        ssize_t cnt;\n        hfs_btree_node *node_desc;\n\n        // sanity check\n        if (cur_node > tsk_getu32(fs->endian,\n                hfs->catalog_header.totalNodes)) {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr\n                (\"hfs_cat_traverse: Node %d too large for file\", cur_node);\n            free(node);\n            return 1;\n        }\n\n        // read the current node\n        cur_off = cur_node * nodesize;\n        cnt = tsk_fs_attr_read(hfs->catalog_attr, cur_off,\n            node, nodesize, 0);\n        if (cnt != nodesize) {\n            if (cnt >= 0) {\n                tsk_error_reset();\n                tsk_error_set_errno(TSK_ERR_FS_READ);\n            }\n            tsk_error_set_errstr2\n                (\"hfs_cat_traverse: Error reading node %d at offset %\"\n                PRIuOFF, cur_node, cur_off);\n            free(node);\n            return 1;\n        }\n\n        // process the header / descriptor\n        if (nodesize < sizeof(hfs_btree_node)) {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr\n            (\"hfs_cat_traverse: Node size %d is too small to be valid\", nodesize);\n            free(node);\n            return 1;\n        }\n        node_desc = (hfs_btree_node *) node;\n        num_rec = tsk_getu16(fs->endian, node_desc->num_rec);\n\n        if (tsk_verbose)\n            tsk_fprintf(stderr, \"hfs_cat_traverse: node %\" PRIu32\n                \" @ %\" PRIu64 \" has %\" PRIu16 \" records\\n\",\n                cur_node, cur_off, num_rec);\n\n        if (num_rec == 0) {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr(\"hfs_cat_traverse: zero records in node %\"\n                PRIu32, cur_node);\n            free(node);\n            return 1;\n        }\n\n        /* With an index node, find the record with the largest key that is smaller\n         * to or equal to cnid */\n        if (node_desc->type == HFS_BT_NODE_TYPE_IDX) {\n            uint32_t next_node = 0;\n            int rec;\n\n            for (rec = 0; rec < num_rec; ++rec) {\n                size_t rec_off;\n                hfs_btree_key_cat *key;\n                uint8_t retval;\n                int keylen;\n\n                // get the record offset in the node\n                rec_off =\n                    tsk_getu16(fs->endian,\n                    &node[nodesize - (rec + 1) * 2]);\n                if (rec_off > nodesize) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr\n                        (\"hfs_cat_traverse: offset of record %d in index node %d too large (%d vs %\"\n                        PRIu16 \")\", rec, cur_node, (int) rec_off,\n                        nodesize);\n                    free(node);\n                    return 1;\n                }\n\n                key = (hfs_btree_key_cat *) & node[rec_off];\n\n                keylen = 2 + tsk_getu16(hfs->fs_info.endian, key->key_len);\n                if ((keylen) > nodesize) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr\n                        (\"hfs_cat_traverse: length of key %d in index node %d too large (%d vs %\"\n                        PRIu16 \")\", rec, cur_node, keylen, nodesize);\n                    free(node);\n                    return 1;\n                }\n\n\n                /*\n                   if (tsk_verbose)\n                   tsk_fprintf(stderr,\n                   \"hfs_cat_traverse: record %\" PRIu16\n                   \" ; keylen %\" PRIu16 \" (%\" PRIu32 \")\\n\", rec,\n                   tsk_getu16(fs->endian, key->key_len),\n                   tsk_getu32(fs->endian, key->parent_cnid));\n                 */\n\n\n                /* save the info from this record unless it is too big */\n                retval =\n                    a_cb(hfs, HFS_BT_NODE_TYPE_IDX, key,\n                    cur_off + rec_off, ptr);\n                if (retval == HFS_BTREE_CB_ERR) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr2\n                        (\"hfs_cat_traverse: Callback returned error\");\n                    free(node);\n                    return 1;\n                }\n                // record the closest entry\n                else if ((retval == HFS_BTREE_CB_IDX_LT)\n                    || (next_node == 0)) {\n                    hfs_btree_index_record *idx_rec;\n                    int keylen =\n                        2 + hfs_get_idxkeylen(hfs, tsk_getu16(fs->endian,\n                            key->key_len), &(hfs->catalog_header));\n                    if (rec_off + keylen > nodesize) {\n                        tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                        tsk_error_set_errstr\n                            (\"hfs_cat_traverse: offset of record and keylength %d in index node %d too large (%d vs %\"\n                            PRIu16 \")\", rec, cur_node,\n                            (int) rec_off + keylen, nodesize);\n                        free(node);\n                        return 1;\n                    }\n                    idx_rec =\n                        (hfs_btree_index_record *) & node[rec_off +\n                        keylen];\n                    next_node = tsk_getu32(fs->endian, idx_rec->childNode);\n                }\n                if (retval == HFS_BTREE_CB_IDX_EQGT) {\n                    // move down to the next node\n                    break;\n                }\n            }\n            // check if we found a relevant node\n            if (next_node == 0) {\n                tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                tsk_error_set_errstr\n                    (\"hfs_cat_traverse: did not find any keys in index node %d\",\n                    cur_node);\n                is_done = 1;\n                break;\n            }\n            // TODO: Handle multinode loops\n            if (next_node == cur_node) {\n                tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                tsk_error_set_errstr\n                    (\"hfs_cat_traverse: node %d references itself as next node\",\n                    cur_node);\n                is_done = 1;\n                break;\n            }\n            cur_node = next_node;\n        }\n\n        /* With a leaf, we look for the specific record. */\n        else if (node_desc->type == HFS_BT_NODE_TYPE_LEAF) {\n            int rec;\n\n            for (rec = 0; rec < num_rec; ++rec) {\n                size_t rec_off;\n                hfs_btree_key_cat *key;\n                uint8_t retval;\n                int keylen;\n\n                // get the record offset in the node\n                rec_off =\n                    tsk_getu16(fs->endian,\n                    &node[nodesize - (rec + 1) * 2]);\n                if (rec_off > nodesize) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr\n                        (\"hfs_cat_traverse: offset of record %d in leaf node %d too large (%d vs %\"\n                        PRIu16 \")\", rec, cur_node, (int) rec_off,\n                        nodesize);\n                    free(node);\n                    return 1;\n                }\n                key = (hfs_btree_key_cat *) & node[rec_off];\n\n                keylen = 2 + tsk_getu16(hfs->fs_info.endian, key->key_len);\n                if ((keylen) > nodesize) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr\n                        (\"hfs_cat_traverse: length of key %d in leaf node %d too large (%d vs %\"\n                        PRIu16 \")\", rec, cur_node, keylen, nodesize);\n                    free(node);\n                    return 1;\n                }\n\n                /*\n                   if (tsk_verbose)\n                   tsk_fprintf(stderr,\n                   \"hfs_cat_traverse: record %\" PRIu16\n                   \"; keylen %\" PRIu16 \" (%\" PRIu32 \")\\n\", rec,\n                   tsk_getu16(fs->endian, key->key_len),\n                   tsk_getu32(fs->endian, key->parent_cnid));\n                 */\n                //                rec_cnid = tsk_getu32(fs->endian, key->file_id);\n\n                retval =\n                    a_cb(hfs, HFS_BT_NODE_TYPE_LEAF, key,\n                    cur_off + rec_off, ptr);\n                if (retval == HFS_BTREE_CB_LEAF_STOP) {\n                    is_done = 1;\n                    break;\n                }\n                else if (retval == HFS_BTREE_CB_ERR) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr2\n                        (\"hfs_cat_traverse: Callback returned error\");\n                    free(node);\n                    return 1;\n                }\n            }\n\n            // move right to the next node if we got this far\n            if (is_done == 0) {\n                cur_node = tsk_getu32(fs->endian, node_desc->flink);\n                if (cur_node == 0) {\n                    is_done = 1;\n                }\n                if (tsk_verbose)\n                    tsk_fprintf(stderr,\n                        \"hfs_cat_traverse: moving forward to next leaf\");\n            }\n        }\n        else {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr(\"hfs_cat_traverse: btree node %\" PRIu32\n                \" (%\" PRIu64 \") is neither index nor leaf (%\" PRIu8 \")\",\n                cur_node, cur_off, node_desc->type);\n            free(node);\n            return 1;\n        }\n    }\n    free(node);\n    return 0;\n}", "commit_link": "github.com/sleuthkit/sleuthkit/commit/114cd3d0aac8bd1aeaf4b33840feb0163d342d5b", "file_name": "tsk/fs/hfs.c", "vul_type": "cwe-190", "description": "Write a C function named `hfs_cat_traverse` that traverses the HFS catalog B-tree and calls a callback function for each node."}
{"func_name": "jbig2_image_compose", "func_src_before": "jbig2_image_compose(Jbig2Ctx *ctx, Jbig2Image *dst, Jbig2Image *src, int x, int y, Jbig2ComposeOp op)\n{\n    uint32_t w, h;\n    uint32_t shift;\n    uint32_t leftbyte;\n    uint8_t *ss;\n    uint8_t *dd;\n    uint8_t leftmask, rightmask;\n    int early = x >= 0;\n    int late;\n    uint32_t bytewidth;\n    uint32_t syoffset = 0;\n\n    if (src == NULL)\n        return 0;\n\n    /* This code takes a src image and combines it onto dst at offset (x,y), with operation op. */\n\n    /* Data is packed msb first within a byte, so with bits numbered: 01234567.\n     * Second byte is: 89abcdef. So to combine into a run, we use:\n     *       (s[0]<<8) | s[1] == 0123456789abcdef.\n     * To read from src into dst at offset 3, we need to read:\n     *    read:      0123456789abcdef...\n     *    write:  0123456798abcdef...\n     * In general, to read from src and write into dst at offset x, we need to shift\n     * down by (x&7) bits to allow for bit alignment. So shift = x&7.\n     * So the 'central' part of our runs will see us doing:\n     *   *d++ op= ((s[0]<<8)|s[1])>>shift;\n     * with special cases on the left and right edges of the run to mask.\n     * With the left hand edge, we have to be careful not to 'underread' the start of\n     * the src image; this is what the early flag is about. Similarly we have to be\n     * careful not to read off the right hand edge; this is what the late flag is for.\n     */\n\n    /* clip */\n    w = src->width;\n    h = src->height;\n    shift = (x & 7);\n    ss = src->data - early;\n\n    if (x < 0) {\n        if (w < (uint32_t) -x)\n            w = 0;\n        else\n            w += x;\n        ss += (-x-1)>>3;\n        x = 0;\n    }\n    if (y < 0) {\n        if (h < (uint32_t) -y)\n            h = 0;\n        else\n            h += y;\n        syoffset = -y * src->stride;\n        y = 0;\n    }\n    if ((uint32_t)x + w > dst->width)\n    {\n        if (dst->width < (uint32_t)x)\n            w = 0;\n        else\n            w = dst->width - x;\n    }\n    if ((uint32_t)y + h > dst->height)\n    {\n        if (dst->height < (uint32_t)y)\n            h = 0;\n        else\n            h = dst->height - y;\n    }\n#ifdef JBIG2_DEBUG\n    jbig2_error(ctx, JBIG2_SEVERITY_DEBUG, -1, \"compositing %dx%d at (%d, %d) after clipping\", w, h, x, y);\n#endif\n\n    /* check for zero clipping region */\n    if ((w <= 0) || (h <= 0)) {\n#ifdef JBIG2_DEBUG\n        jbig2_error(ctx, JBIG2_SEVERITY_DEBUG, -1, \"zero clipping region\");\n#endif\n        return 0;\n    }\n\n    leftbyte = (uint32_t) x >> 3;\n    dd = dst->data + y * dst->stride + leftbyte;\n    bytewidth = (((uint32_t) x + w - 1) >> 3) - leftbyte + 1;\n    leftmask = 255>>(x&7);\n    rightmask = (((x+w)&7) == 0) ? 255 : ~(255>>((x+w)&7));\n    if (bytewidth == 1)\n        leftmask &= rightmask;\n    late = (ss + bytewidth >= src->data + ((src->width+7)>>3));\n    ss += syoffset;\n\n    switch(op)\n    {\n    case JBIG2_COMPOSE_OR:\n        jbig2_image_compose_opt_OR(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_AND:\n        jbig2_image_compose_opt_AND(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_XOR:\n        jbig2_image_compose_opt_XOR(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_XNOR:\n        jbig2_image_compose_opt_XNOR(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_REPLACE:\n        jbig2_image_compose_opt_REPLACE(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    }\n\n    return 0;\n}", "func_src_after": "jbig2_image_compose(Jbig2Ctx *ctx, Jbig2Image *dst, Jbig2Image *src, int x, int y, Jbig2ComposeOp op)\n{\n    uint32_t w, h;\n    uint32_t shift;\n    uint32_t leftbyte;\n    uint8_t *ss;\n    uint8_t *dd;\n    uint8_t leftmask, rightmask;\n    int early = x >= 0;\n    int late;\n    uint32_t bytewidth;\n    uint32_t syoffset = 0;\n\n    if (src == NULL)\n        return 0;\n\n    if ((UINT32_MAX - src->width  < (x > 0 ? x : -x)) ||\n        (UINT32_MAX - src->height < (y > 0 ? y : -y)))\n    {\n#ifdef JBIG2_DEBUG\n        jbig2_error(ctx, JBIG2_SEVERITY_DEBUG, -1, \"overflow in compose_image\");\n#endif\n        return 0;\n    }\n\n    /* This code takes a src image and combines it onto dst at offset (x,y), with operation op. */\n\n    /* Data is packed msb first within a byte, so with bits numbered: 01234567.\n     * Second byte is: 89abcdef. So to combine into a run, we use:\n     *       (s[0]<<8) | s[1] == 0123456789abcdef.\n     * To read from src into dst at offset 3, we need to read:\n     *    read:      0123456789abcdef...\n     *    write:  0123456798abcdef...\n     * In general, to read from src and write into dst at offset x, we need to shift\n     * down by (x&7) bits to allow for bit alignment. So shift = x&7.\n     * So the 'central' part of our runs will see us doing:\n     *   *d++ op= ((s[0]<<8)|s[1])>>shift;\n     * with special cases on the left and right edges of the run to mask.\n     * With the left hand edge, we have to be careful not to 'underread' the start of\n     * the src image; this is what the early flag is about. Similarly we have to be\n     * careful not to read off the right hand edge; this is what the late flag is for.\n     */\n\n    /* clip */\n    w = src->width;\n    h = src->height;\n    shift = (x & 7);\n    ss = src->data - early;\n\n    if (x < 0) {\n        if (w < (uint32_t) -x)\n            w = 0;\n        else\n            w += x;\n        ss += (-x-1)>>3;\n        x = 0;\n    }\n    if (y < 0) {\n        if (h < (uint32_t) -y)\n            h = 0;\n        else\n            h += y;\n        syoffset = -y * src->stride;\n        y = 0;\n    }\n    if ((uint32_t)x + w > dst->width)\n    {\n        if (dst->width < (uint32_t)x)\n            w = 0;\n        else\n            w = dst->width - x;\n    }\n    if ((uint32_t)y + h > dst->height)\n    {\n        if (dst->height < (uint32_t)y)\n            h = 0;\n        else\n            h = dst->height - y;\n    }\n#ifdef JBIG2_DEBUG\n    jbig2_error(ctx, JBIG2_SEVERITY_DEBUG, -1, \"compositing %dx%d at (%d, %d) after clipping\", w, h, x, y);\n#endif\n\n    /* check for zero clipping region */\n    if ((w <= 0) || (h <= 0)) {\n#ifdef JBIG2_DEBUG\n        jbig2_error(ctx, JBIG2_SEVERITY_DEBUG, -1, \"zero clipping region\");\n#endif\n        return 0;\n    }\n\n    leftbyte = (uint32_t) x >> 3;\n    dd = dst->data + y * dst->stride + leftbyte;\n    bytewidth = (((uint32_t) x + w - 1) >> 3) - leftbyte + 1;\n    leftmask = 255>>(x&7);\n    rightmask = (((x+w)&7) == 0) ? 255 : ~(255>>((x+w)&7));\n    if (bytewidth == 1)\n        leftmask &= rightmask;\n    late = (ss + bytewidth >= src->data + ((src->width+7)>>3));\n    ss += syoffset;\n\n    switch(op)\n    {\n    case JBIG2_COMPOSE_OR:\n        jbig2_image_compose_opt_OR(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_AND:\n        jbig2_image_compose_opt_AND(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_XOR:\n        jbig2_image_compose_opt_XOR(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_XNOR:\n        jbig2_image_compose_opt_XNOR(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    case JBIG2_COMPOSE_REPLACE:\n        jbig2_image_compose_opt_REPLACE(ss, dd, early, late, leftmask, rightmask, bytewidth, h, shift, dst->stride, src->stride);\n        break;\n    }\n\n    return 0;\n}", "commit_link": "github.com/ArtifexSoftware/jbig2dec/commit/0726320a4b55078e9d8deb590e477d598b3da66e", "file_name": "jbig2_image.c", "vul_type": "cwe-787", "description": "Write a C function to overlay one image onto another at a specified position using a given composition operation."}
{"func_name": "ac_circ_buf_new", "func_src_before": "ac_circ_buf_t *ac_circ_buf_new(u32 size, u32 elem_sz)\n{\n\tac_circ_buf_t *cbuf;\n\n\tif (!is_pow2(size))\n\t\treturn NULL;\n\n\tcbuf = malloc(sizeof(ac_circ_buf_t));\n\tcbuf->head = cbuf->tail = 0;\n\tcbuf->size = size;\n\n\tif (elem_sz == 0) {\n\t\tcbuf->elem_sz = 1;\n\t\tcbuf->type = PTR_BUF;\n\t\tcbuf->buf.ptr_buf = malloc(size * sizeof(void *));\n\t} else {\n\t\tcbuf->elem_sz = elem_sz;\n\t\tcbuf->type = CPY_BUF;\n\t\tcbuf->buf.cpy_buf = malloc(size * elem_sz);\n\t}\n\n\treturn cbuf;\n}", "func_src_after": "ac_circ_buf_t *ac_circ_buf_new(u32 size, u32 elem_sz)\n{\n\tac_circ_buf_t *cbuf;\n\n\tif (!is_pow2(size))\n\t\treturn NULL;\n\n\tcbuf = malloc(sizeof(ac_circ_buf_t));\n\tcbuf->head = cbuf->tail = 0;\n\tcbuf->size = size;\n\n\tif (elem_sz == 0) {\n\t\tcbuf->elem_sz = 1;\n\t\tcbuf->type = PTR_BUF;\n\t\tcbuf->buf.ptr_buf = malloc(size * sizeof(void *));\n\t} else {\n\t\tcbuf->elem_sz = elem_sz;\n\t\tcbuf->type = CPY_BUF;\n\t\tcbuf->buf.cpy_buf = malloc((size_t)size * elem_sz);\n\t}\n\n\treturn cbuf;\n}", "line_changes": {"deleted": [{"line_no": 19, "char_start": 386, "char_end": 432, "line": "\t\tcbuf->buf.cpy_buf = malloc(size * elem_sz);\n"}], "added": [{"line_no": 19, "char_start": 386, "char_end": 440, "line": "\t\tcbuf->buf.cpy_buf = malloc((size_t)size * elem_sz);\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 415, "char_end": 423, "chars": "(size_t)"}]}, "commit_link": "github.com/ac000/libac/commit/2d6eb46697a185e7ecdbbf0197c405096765cf27", "file_name": "ac_circ_buf.c", "vul_type": "cwe-190", "commit_msg": "ac_circ_buf: Fix some potential unsigned integer overflows\n\nLGTM[0] pointed out some issues in ac_circ_buf.c regarding the\nmalloc(3)'s\n\n  'Multiplication result may overflow 'unsigned int' before it is\n   converted to 'size_t'.'\n\nThis is unlikely to hit in real life, but lets fix it anyway by casting\nthe size/count part of the calculation in the mallocs to size_t.\n\n[0]: https://lgtm.com/\n\nSigned-off-by: Andrew Clayton <andrew@digital-domain.net>", "parent_commit": "536fc22f2c496342e6391b4f81c91ad41816571b", "description": "Write a C function to initialize a circular buffer that can either hold pointers or copy data, depending on the element size provided."}
{"func_name": "ReadMATImage", "func_src_before": "static Image *ReadMATImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  Image *image, *image2=NULL,\n   *rotated_image;\n  register Quantum *q;\n\n  unsigned int status;\n  MATHeader MATLAB_HDR;\n  size_t size;\n  size_t CellType;\n  QuantumInfo *quantum_info;\n  ImageInfo *clone_info;\n  int i;\n  ssize_t ldblk;\n  unsigned char *BImgBuff = NULL;\n  double MinVal, MaxVal;\n  unsigned z, z2;\n  unsigned Frames;\n  int logging;\n  int sample_size;\n  MagickOffsetType filepos=0x80;\n  BlobInfo *blob;\n  size_t one;\n\n  unsigned int (*ReadBlobXXXLong)(Image *image);\n  unsigned short (*ReadBlobXXXShort)(Image *image);\n  void (*ReadBlobDoublesXXX)(Image * image, size_t len, double *data);\n  void (*ReadBlobFloatsXXX)(Image * image, size_t len, float *data);\n\n\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  logging = LogMagickEvent(CoderEvent,GetMagickModule(),\"enter\");\n\n  /*\n     Open image file.\n   */\n  image = AcquireImage(image_info,exception);\n\n  status = OpenBlob(image_info, image, ReadBinaryBlobMode, exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n     Read MATLAB image.\n   */\n  quantum_info=(QuantumInfo *) NULL;\n  clone_info=(ImageInfo *) NULL;\n  if (ReadBlob(image,124,(unsigned char *) &MATLAB_HDR.identific) != 124)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  if (strncmp(MATLAB_HDR.identific,\"MATLAB\",6) != 0)\n    {\n      image2=ReadMATImageV4(image_info,image,exception);\n      if (image2  == NULL)\n        goto MATLAB_KO;\n      image=image2;\n      goto END_OF_READING;\n    }\n  MATLAB_HDR.Version = ReadBlobLSBShort(image);\n  if(ReadBlob(image,2,(unsigned char *) &MATLAB_HDR.EndianIndicator) != 2)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  if (logging)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"  Endian %c%c\",\n      MATLAB_HDR.EndianIndicator[0],MATLAB_HDR.EndianIndicator[1]);\n  if (!strncmp(MATLAB_HDR.EndianIndicator, \"IM\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobLSBLong;\n    ReadBlobXXXShort = ReadBlobLSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesLSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsLSB;\n    image->endian = LSBEndian;\n  }\n  else if (!strncmp(MATLAB_HDR.EndianIndicator, \"MI\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobMSBLong;\n    ReadBlobXXXShort = ReadBlobMSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesMSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsMSB;\n    image->endian = MSBEndian;\n  }\n  else\n    goto MATLAB_KO;    /* unsupported endian */\n\n  if (strncmp(MATLAB_HDR.identific, \"MATLAB\", 6))\n    {\nMATLAB_KO:\n      if ((image != image2) && (image2 != (Image *) NULL))\n        image2=DestroyImage(image2);\n      if (clone_info != (ImageInfo *) NULL)\n        clone_info=DestroyImageInfo(clone_info);\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    }\n\n  filepos = TellBlob(image);\n  while(!EOFBlob(image)) /* object parser loop */\n  {\n    Frames = 1;\n    (void) SeekBlob(image,filepos,SEEK_SET);\n    /* printf(\"pos=%X\\n\",TellBlob(image)); */\n\n    MATLAB_HDR.DataType = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    MATLAB_HDR.ObjectSize = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    if((MagickSizeType) (MATLAB_HDR.ObjectSize+filepos) > GetBlobSize(image))\n      goto MATLAB_KO;\n    filepos += MATLAB_HDR.ObjectSize + 4 + 4;\n\n    clone_info=CloneImageInfo(image_info);\n    image2 = image;\n#if defined(MAGICKCORE_ZLIB_DELEGATE)\n    if(MATLAB_HDR.DataType == miCOMPRESSED)\n    {\n      image2 = decompress_block(image,&MATLAB_HDR.ObjectSize,clone_info,exception);\n      if(image2==NULL) continue;\n      MATLAB_HDR.DataType = ReadBlobXXXLong(image2); /* replace compressed object type. */\n    }\n#endif\n\n    if (MATLAB_HDR.DataType!=miMATRIX)\n      {\n        clone_info=DestroyImageInfo(clone_info);\n        continue;  /* skip another objects. */\n      }\n\n    MATLAB_HDR.unknown1 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.unknown2 = ReadBlobXXXLong(image2);\n\n    MATLAB_HDR.unknown5 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.StructureClass = MATLAB_HDR.unknown5 & 0xFF;\n    MATLAB_HDR.StructureFlag = (MATLAB_HDR.unknown5>>8) & 0xFF;\n\n    MATLAB_HDR.unknown3 = ReadBlobXXXLong(image2);\n    if(image!=image2)\n      MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);  /* ??? don't understand why ?? */\n    MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.DimFlag = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeX = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeY = ReadBlobXXXLong(image2);\n\n\n    switch(MATLAB_HDR.DimFlag)\n    {\n      case  8: z2=z=1; break;      /* 2D matrix*/\n      case 12: z2=z = ReadBlobXXXLong(image2);  /* 3D matrix RGB*/\n           (void) ReadBlobXXXLong(image2);\n         if(z!=3) ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n         break;\n      case 16: z2=z = ReadBlobXXXLong(image2);  /* 4D matrix animation */\n         if(z!=3 && z!=1)\n            ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n         Frames = ReadBlobXXXLong(image2);\n         if (Frames == 0)\n           ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n         break;\n      default:\n        if (clone_info != (ImageInfo *) NULL)\n          clone_info=DestroyImageInfo(clone_info);\n        if ((image != image2) && (image2 != (Image *) NULL))\n          image2=DestroyImage(image2);\n        ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n    }\n\n    MATLAB_HDR.Flag1 = ReadBlobXXXShort(image2);\n    MATLAB_HDR.NameFlag = ReadBlobXXXShort(image2);\n\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"MATLAB_HDR.StructureClass %d\",MATLAB_HDR.StructureClass);\n    if (MATLAB_HDR.StructureClass != mxCHAR_CLASS &&\n        MATLAB_HDR.StructureClass != mxSINGLE_CLASS &&    /* float + complex float */\n        MATLAB_HDR.StructureClass != mxDOUBLE_CLASS &&    /* double + complex double */\n        MATLAB_HDR.StructureClass != mxINT8_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT8_CLASS &&    /* uint8 + uint8 3D */\n        MATLAB_HDR.StructureClass != mxINT16_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT16_CLASS &&    /* uint16 + uint16 3D */\n        MATLAB_HDR.StructureClass != mxINT32_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT32_CLASS &&    /* uint32 + uint32 3D */\n        MATLAB_HDR.StructureClass != mxINT64_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT64_CLASS)    /* uint64 + uint64 3D */\n      ThrowReaderException(CoderError,\"UnsupportedCellTypeInTheMatrix\");\n\n    switch (MATLAB_HDR.NameFlag)\n    {\n      case 0:\n        size = ReadBlobXXXLong(image2);  /* Object name string size */\n        size = 4 * (ssize_t) ((size + 3 + 1) / 4);\n        (void) SeekBlob(image2, size, SEEK_CUR);\n        break;\n      case 1:\n      case 2:\n      case 3:\n      case 4:\n        (void) ReadBlob(image2, 4, (unsigned char *) &size); /* Object name string */\n        break;\n      default:\n        goto MATLAB_KO;\n    }\n\n    CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n    if (logging)\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"MATLAB_HDR.CellType: %.20g\",(double) CellType);\n\n    (void) ReadBlob(image2, 4, (unsigned char *) &size);     /* data size */\n\n    NEXT_FRAME:\n    switch (CellType)\n    {\n      case miINT8:\n      case miUINT8:\n        sample_size = 8;\n        if(MATLAB_HDR.StructureFlag & FLAG_LOGICAL)\n          image->depth = 1;\n        else\n          image->depth = 8;         /* Byte type cell */\n        ldblk = (ssize_t) MATLAB_HDR.SizeX;\n        break;\n      case miINT16:\n      case miUINT16:\n        sample_size = 16;\n        image->depth = 16;        /* Word type cell */\n        ldblk = (ssize_t) (2 * MATLAB_HDR.SizeX);\n        break;\n      case miINT32:\n      case miUINT32:\n        sample_size = 32;\n        image->depth = 32;        /* Dword type cell */\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miINT64:\n      case miUINT64:\n        sample_size = 64;\n        image->depth = 64;        /* Qword type cell */\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      case miSINGLE:\n        sample_size = 32;\n        image->depth = 32;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {              /* complex float type cell */\n  }\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miDOUBLE:\n        sample_size = 64;\n        image->depth = 64;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\nDisableMSCWarning(4127)\n        if (sizeof(double) != 8)\nRestoreMSCWarning\n          ThrowReaderException(CoderError, \"IncompatibleSizeOfDouble\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {                         /* complex double type cell */\n  }\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      default:\n        if ((image != image2) && (image2 != (Image *) NULL))\n          image2=DestroyImage(image2);\n        if (clone_info)\n          clone_info=DestroyImageInfo(clone_info);\n        ThrowReaderException(CoderError, \"UnsupportedCellTypeInTheMatrix\");\n    }\n    (void) sample_size;\n    image->columns = MATLAB_HDR.SizeX;\n    image->rows = MATLAB_HDR.SizeY;\n    one=1;\n    image->colors = one << image->depth;\n    if (image->columns == 0 || image->rows == 0)\n      goto MATLAB_KO;\n    if((unsigned long)ldblk*MATLAB_HDR.SizeY > MATLAB_HDR.ObjectSize)\n      goto MATLAB_KO;\n    /* Image is gray when no complex flag is set and 2D Matrix */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      {\n        image->type=GrayscaleType;\n        SetImageColorspace(image,GRAYColorspace,exception);\n      }\n\n\n    /*\n      If ping is true, then only set image size and colors without\n      reading any image data.\n    */\n    if (image_info->ping)\n    {\n      size_t temp = image->columns;\n      image->columns = image->rows;\n      image->rows = temp;\n      goto done_reading; /* !!!!!! BAD  !!!! */\n    }\n    status=SetImageExtent(image,image->columns,image->rows,exception);\n    if (status == MagickFalse)\n      {\n        if ((image != image2) && (image2 != (Image *) NULL))\n          image2=DestroyImage(image2);\n        return(DestroyImageList(image));\n      }\n    quantum_info=AcquireQuantumInfo(clone_info,image);\n    if (quantum_info == (QuantumInfo *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n  /* ----- Load raster data ----- */\n    BImgBuff = (unsigned char *) AcquireQuantumMemory((size_t) (ldblk),sizeof(double));    /* Ldblk was set in the check phase */\n    if (BImgBuff == NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    (void) ResetMagickMemory(BImgBuff,0,ldblk*sizeof(double));\n\n    MinVal = 0;\n    MaxVal = 0;\n    if (CellType==miDOUBLE || CellType==miSINGLE)        /* Find Min and Max Values for floats */\n    {\n      CalcMinMax(image2, image_info->endian,  MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &quantum_info->minimum, &quantum_info->maximum);\n    }\n\n    /* Main loop for reading all scanlines */\n    if(z==1) z=0; /* read grey scanlines */\n    /* else read color scanlines */\n    do\n    {\n      for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n      {\n        q=GetAuthenticPixels(image,0,MATLAB_HDR.SizeY-i-1,image->columns,1,exception);\n        if (q == (Quantum *) NULL)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT set image pixels returns unexpected NULL on a row %u.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto done_reading;    /* Skip image rotation, when cannot set image pixels    */\n  }\n        if(ReadBlob(image2,ldblk,(unsigned char *)BImgBuff) != (ssize_t) ldblk)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"  MAT cannot read scanrow %u from a file.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n        if((CellType==miINT8 || CellType==miUINT8) && (MATLAB_HDR.StructureFlag & FLAG_LOGICAL))\n        {\n          FixLogical((unsigned char *)BImgBuff,ldblk);\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n    {\nImportQuantumPixelsFailed:\n      if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT failed to ImportQuantumPixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n      break;\n    }\n        }\n        else\n        {\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n      goto ImportQuantumPixelsFailed;\n\n\n          if (z<=1 &&       /* fix only during a last pass z==0 || z==1 */\n          (CellType==miINT8 || CellType==miINT16 || CellType==miINT32 || CellType==miINT64))\n      FixSignedValues(image,q,MATLAB_HDR.SizeX);\n        }\n\n        if (!SyncAuthenticPixels(image,exception))\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  MAT failed to sync image pixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n      }\n    } while(z-- >= 2);\nExitLoop:\n\n\n    /* Read complex part of numbers here */\n    if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n    {        /* Find Min and Max Values for complex parts of floats */\n      CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n      i = ReadBlobXXXLong(image2);           /* size of a complex part - toss away*/\n\n      if (CellType==miDOUBLE || CellType==miSINGLE)\n      {\n        CalcMinMax(image2,  image_info->endian, MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &MinVal, &MaxVal);\n      }\n\n      if (CellType==miDOUBLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobDoublesXXX(image2, ldblk, (double *)BImgBuff);\n          InsertComplexDoubleRow(image, (double *)BImgBuff, i, MinVal, MaxVal,\n            exception);\n  }\n\n      if (CellType==miSINGLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobFloatsXXX(image2, ldblk, (float *)BImgBuff);\n          InsertComplexFloatRow(image,(float *)BImgBuff,i,MinVal,MaxVal,\n            exception);\n  }\n    }\n\n      /* Image is gray when no complex flag is set and 2D Matrix AGAIN!!! */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      image->type=GrayscaleType;\n    if (image->depth == 1)\n      image->type=BilevelType;\n\n    if(image2==image)\n        image2 = NULL;    /* Remove shadow copy to an image before rotation. */\n\n      /*  Rotate image. */\n    rotated_image = RotateImage(image, 90.0, exception);\n    if (rotated_image != (Image *) NULL)\n    {\n        /* Remove page offsets added by RotateImage */\n      rotated_image->page.x=0;\n      rotated_image->page.y=0;\n\n      blob = rotated_image->blob;\n      rotated_image->blob = image->blob;\n      rotated_image->colors = image->colors;\n      image->blob = blob;\n      AppendImageToList(&image,rotated_image);\n      DeleteImageFromList(&image);\n    }\n\ndone_reading:\n\n    if(image2!=NULL)\n      if(image2!=image)\n      {\n        DeleteImageFromList(&image2);\n  if(clone_info)\n  {\n          if(clone_info->file)\n    {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) remove_utf8(clone_info->filename);\n    }\n        }\n      }\n\n      /* Allocate next image structure. */\n    AcquireNextImage(image_info,image,exception);\n    if (image->next == (Image *) NULL) break;\n    image=SyncNextImageInList(image);\n    image->columns=image->rows=0;\n    image->colors=0;\n\n      /* row scan buffer is no longer needed */\n    RelinquishMagickMemory(BImgBuff);\n    BImgBuff = NULL;\n\n    if(--Frames>0)\n    {\n      z = z2;\n      if(image2==NULL) image2 = image;\n      goto NEXT_FRAME;\n    }\n    if ((image2!=NULL) && (image2!=image))   /* Does shadow temporary decompressed image exist? */\n      {\n/*  CloseBlob(image2); */\n        DeleteImageFromList(&image2);\n        if(clone_info)\n        {\n          if(clone_info->file)\n          {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) remove_utf8(clone_info->filename);\n          }\n        }\n        }\n\n    if (quantum_info != (QuantumInfo *) NULL)\n      quantum_info=DestroyQuantumInfo(quantum_info);\n    if (clone_info)\n      clone_info=DestroyImageInfo(clone_info);\n  }\n\n  RelinquishMagickMemory(BImgBuff);\n  if (quantum_info != (QuantumInfo *) NULL)\n    quantum_info=DestroyQuantumInfo(quantum_info);\nEND_OF_READING:\n  if (clone_info)\n    clone_info=DestroyImageInfo(clone_info);\n  CloseBlob(image);\n\n\n  {\n    Image *p;\n    ssize_t scene=0;\n\n    /*\n      Rewind list, removing any empty images while rewinding.\n    */\n    p=image;\n    image=NULL;\n    while (p != (Image *) NULL)\n      {\n        Image *tmp=p;\n        if ((p->rows == 0) || (p->columns == 0)) {\n          p=p->previous;\n          DeleteImageFromList(&tmp);\n        } else {\n          image=p;\n          p=p->previous;\n        }\n      }\n\n    /*\n      Fix scene numbers\n    */\n    for (p=image; p != (Image *) NULL; p=p->next)\n      p->scene=scene++;\n  }\n\n  if(clone_info != NULL)  /* cleanup garbage file from compression */\n  {\n    if(clone_info->file)\n    {\n      fclose(clone_info->file);\n      clone_info->file = NULL;\n      (void) remove_utf8(clone_info->filename);\n    }\n    DestroyImageInfo(clone_info);\n    clone_info = NULL;\n  }\n  if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\"return\");\n  if (image==NULL)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\")\n  else\n    if ((image != image2) && (image2 != (Image *) NULL))\n      image2=DestroyImage(image2);\n  return (image);\n}", "func_src_after": "static Image *ReadMATImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  Image *image, *image2=NULL,\n   *rotated_image;\n  register Quantum *q;\n\n  unsigned int status;\n  MATHeader MATLAB_HDR;\n  size_t size;\n  size_t CellType;\n  QuantumInfo *quantum_info;\n  ImageInfo *clone_info;\n  int i;\n  ssize_t ldblk;\n  unsigned char *BImgBuff = NULL;\n  double MinVal, MaxVal;\n  unsigned z, z2;\n  unsigned Frames;\n  int logging;\n  int sample_size;\n  MagickOffsetType filepos=0x80;\n  BlobInfo *blob;\n  size_t one;\n\n  unsigned int (*ReadBlobXXXLong)(Image *image);\n  unsigned short (*ReadBlobXXXShort)(Image *image);\n  void (*ReadBlobDoublesXXX)(Image * image, size_t len, double *data);\n  void (*ReadBlobFloatsXXX)(Image * image, size_t len, float *data);\n\n\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  logging = LogMagickEvent(CoderEvent,GetMagickModule(),\"enter\");\n\n  /*\n     Open image file.\n   */\n  image = AcquireImage(image_info,exception);\n\n  status = OpenBlob(image_info, image, ReadBinaryBlobMode, exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n     Read MATLAB image.\n   */\n  quantum_info=(QuantumInfo *) NULL;\n  clone_info=(ImageInfo *) NULL;\n  if (ReadBlob(image,124,(unsigned char *) &MATLAB_HDR.identific) != 124)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  if (strncmp(MATLAB_HDR.identific,\"MATLAB\",6) != 0)\n    {\n      image2=ReadMATImageV4(image_info,image,exception);\n      if (image2  == NULL)\n        goto MATLAB_KO;\n      image=image2;\n      goto END_OF_READING;\n    }\n  MATLAB_HDR.Version = ReadBlobLSBShort(image);\n  if(ReadBlob(image,2,(unsigned char *) &MATLAB_HDR.EndianIndicator) != 2)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  if (logging)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"  Endian %c%c\",\n      MATLAB_HDR.EndianIndicator[0],MATLAB_HDR.EndianIndicator[1]);\n  if (!strncmp(MATLAB_HDR.EndianIndicator, \"IM\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobLSBLong;\n    ReadBlobXXXShort = ReadBlobLSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesLSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsLSB;\n    image->endian = LSBEndian;\n  }\n  else if (!strncmp(MATLAB_HDR.EndianIndicator, \"MI\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobMSBLong;\n    ReadBlobXXXShort = ReadBlobMSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesMSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsMSB;\n    image->endian = MSBEndian;\n  }\n  else\n    goto MATLAB_KO;    /* unsupported endian */\n\n  if (strncmp(MATLAB_HDR.identific, \"MATLAB\", 6))\n    {\nMATLAB_KO:\n      if ((image != image2) && (image2 != (Image *) NULL))\n        image2=DestroyImage(image2);\n      if (clone_info != (ImageInfo *) NULL)\n        clone_info=DestroyImageInfo(clone_info);\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    }\n\n  filepos = TellBlob(image);\n  while(!EOFBlob(image)) /* object parser loop */\n  {\n    Frames = 1;\n    (void) SeekBlob(image,filepos,SEEK_SET);\n    /* printf(\"pos=%X\\n\",TellBlob(image)); */\n\n    MATLAB_HDR.DataType = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    MATLAB_HDR.ObjectSize = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    if((MagickSizeType) (MATLAB_HDR.ObjectSize+filepos) > GetBlobSize(image))\n      goto MATLAB_KO;\n    filepos += MATLAB_HDR.ObjectSize + 4 + 4;\n\n    clone_info=CloneImageInfo(image_info);\n    image2 = image;\n#if defined(MAGICKCORE_ZLIB_DELEGATE)\n    if(MATLAB_HDR.DataType == miCOMPRESSED)\n    {\n      image2 = decompress_block(image,&MATLAB_HDR.ObjectSize,clone_info,exception);\n      if(image2==NULL) continue;\n      MATLAB_HDR.DataType = ReadBlobXXXLong(image2); /* replace compressed object type. */\n    }\n#endif\n\n    if (MATLAB_HDR.DataType!=miMATRIX)\n      {\n        clone_info=DestroyImageInfo(clone_info);\n        continue;  /* skip another objects. */\n      }\n\n    MATLAB_HDR.unknown1 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.unknown2 = ReadBlobXXXLong(image2);\n\n    MATLAB_HDR.unknown5 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.StructureClass = MATLAB_HDR.unknown5 & 0xFF;\n    MATLAB_HDR.StructureFlag = (MATLAB_HDR.unknown5>>8) & 0xFF;\n\n    MATLAB_HDR.unknown3 = ReadBlobXXXLong(image2);\n    if(image!=image2)\n      MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);  /* ??? don't understand why ?? */\n    MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.DimFlag = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeX = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeY = ReadBlobXXXLong(image2);\n\n\n    switch(MATLAB_HDR.DimFlag)\n    {\n      case  8: z2=z=1; break;      /* 2D matrix*/\n      case 12: z2=z = ReadBlobXXXLong(image2);  /* 3D matrix RGB*/\n           (void) ReadBlobXXXLong(image2);\n         if(z!=3) ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n         break;\n      case 16: z2=z = ReadBlobXXXLong(image2);  /* 4D matrix animation */\n         if(z!=3 && z!=1)\n            ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n         Frames = ReadBlobXXXLong(image2);\n         if (Frames == 0)\n           ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n         break;\n      default:\n        if (clone_info != (ImageInfo *) NULL)\n          clone_info=DestroyImageInfo(clone_info);\n        if ((image != image2) && (image2 != (Image *) NULL))\n          image2=DestroyImage(image2);\n        ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n    }\n\n    MATLAB_HDR.Flag1 = ReadBlobXXXShort(image2);\n    MATLAB_HDR.NameFlag = ReadBlobXXXShort(image2);\n\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"MATLAB_HDR.StructureClass %d\",MATLAB_HDR.StructureClass);\n    if (MATLAB_HDR.StructureClass != mxCHAR_CLASS &&\n        MATLAB_HDR.StructureClass != mxSINGLE_CLASS &&    /* float + complex float */\n        MATLAB_HDR.StructureClass != mxDOUBLE_CLASS &&    /* double + complex double */\n        MATLAB_HDR.StructureClass != mxINT8_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT8_CLASS &&    /* uint8 + uint8 3D */\n        MATLAB_HDR.StructureClass != mxINT16_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT16_CLASS &&    /* uint16 + uint16 3D */\n        MATLAB_HDR.StructureClass != mxINT32_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT32_CLASS &&    /* uint32 + uint32 3D */\n        MATLAB_HDR.StructureClass != mxINT64_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT64_CLASS)    /* uint64 + uint64 3D */\n      ThrowReaderException(CoderError,\"UnsupportedCellTypeInTheMatrix\");\n\n    switch (MATLAB_HDR.NameFlag)\n    {\n      case 0:\n        size = ReadBlobXXXLong(image2);  /* Object name string size */\n        size = 4 * (ssize_t) ((size + 3 + 1) / 4);\n        (void) SeekBlob(image2, size, SEEK_CUR);\n        break;\n      case 1:\n      case 2:\n      case 3:\n      case 4:\n        (void) ReadBlob(image2, 4, (unsigned char *) &size); /* Object name string */\n        break;\n      default:\n        goto MATLAB_KO;\n    }\n\n    CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n    if (logging)\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"MATLAB_HDR.CellType: %.20g\",(double) CellType);\n\n    (void) ReadBlob(image2, 4, (unsigned char *) &size);     /* data size */\n\n    NEXT_FRAME:\n    switch (CellType)\n    {\n      case miINT8:\n      case miUINT8:\n        sample_size = 8;\n        if(MATLAB_HDR.StructureFlag & FLAG_LOGICAL)\n          image->depth = 1;\n        else\n          image->depth = 8;         /* Byte type cell */\n        ldblk = (ssize_t) MATLAB_HDR.SizeX;\n        break;\n      case miINT16:\n      case miUINT16:\n        sample_size = 16;\n        image->depth = 16;        /* Word type cell */\n        ldblk = (ssize_t) (2 * MATLAB_HDR.SizeX);\n        break;\n      case miINT32:\n      case miUINT32:\n        sample_size = 32;\n        image->depth = 32;        /* Dword type cell */\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miINT64:\n      case miUINT64:\n        sample_size = 64;\n        image->depth = 64;        /* Qword type cell */\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      case miSINGLE:\n        sample_size = 32;\n        image->depth = 32;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {              /* complex float type cell */\n  }\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miDOUBLE:\n        sample_size = 64;\n        image->depth = 64;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\nDisableMSCWarning(4127)\n        if (sizeof(double) != 8)\nRestoreMSCWarning\n          ThrowReaderException(CoderError, \"IncompatibleSizeOfDouble\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {                         /* complex double type cell */\n  }\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      default:\n        if ((image != image2) && (image2 != (Image *) NULL))\n          image2=DestroyImage(image2);\n        if (clone_info)\n          clone_info=DestroyImageInfo(clone_info);\n        ThrowReaderException(CoderError, \"UnsupportedCellTypeInTheMatrix\");\n    }\n    (void) sample_size;\n    image->columns = MATLAB_HDR.SizeX;\n    image->rows = MATLAB_HDR.SizeY;\n    one=1;\n    image->colors = one << image->depth;\n    if (image->columns == 0 || image->rows == 0)\n      goto MATLAB_KO;\n    if((unsigned long)ldblk*MATLAB_HDR.SizeY > MATLAB_HDR.ObjectSize)\n      goto MATLAB_KO;\n    /* Image is gray when no complex flag is set and 2D Matrix */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      {\n        image->type=GrayscaleType;\n        SetImageColorspace(image,GRAYColorspace,exception);\n      }\n\n\n    /*\n      If ping is true, then only set image size and colors without\n      reading any image data.\n    */\n    if (image_info->ping)\n    {\n      size_t temp = image->columns;\n      image->columns = image->rows;\n      image->rows = temp;\n      goto done_reading; /* !!!!!! BAD  !!!! */\n    }\n    status=SetImageExtent(image,image->columns,image->rows,exception);\n    if (status == MagickFalse)\n      {\n        if ((image != image2) && (image2 != (Image *) NULL))\n          image2=DestroyImage(image2);\n        return(DestroyImageList(image));\n      }\n    quantum_info=AcquireQuantumInfo(clone_info,image);\n    if (quantum_info == (QuantumInfo *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n  /* ----- Load raster data ----- */\n    BImgBuff = (unsigned char *) AcquireQuantumMemory((size_t) (ldblk),sizeof(double));    /* Ldblk was set in the check phase */\n    if (BImgBuff == NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    (void) ResetMagickMemory(BImgBuff,0,ldblk*sizeof(double));\n\n    MinVal = 0;\n    MaxVal = 0;\n    if (CellType==miDOUBLE || CellType==miSINGLE)        /* Find Min and Max Values for floats */\n    {\n      CalcMinMax(image2, image_info->endian,  MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &quantum_info->minimum, &quantum_info->maximum);\n    }\n\n    /* Main loop for reading all scanlines */\n    if(z==1) z=0; /* read grey scanlines */\n    /* else read color scanlines */\n    do\n    {\n      for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n      {\n        q=GetAuthenticPixels(image,0,MATLAB_HDR.SizeY-i-1,image->columns,1,exception);\n        if (q == (Quantum *) NULL)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT set image pixels returns unexpected NULL on a row %u.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto done_reading;    /* Skip image rotation, when cannot set image pixels    */\n  }\n        if(ReadBlob(image2,ldblk,(unsigned char *)BImgBuff) != (ssize_t) ldblk)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"  MAT cannot read scanrow %u from a file.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n        if((CellType==miINT8 || CellType==miUINT8) && (MATLAB_HDR.StructureFlag & FLAG_LOGICAL))\n        {\n          FixLogical((unsigned char *)BImgBuff,ldblk);\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n    {\nImportQuantumPixelsFailed:\n      if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT failed to ImportQuantumPixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n      break;\n    }\n        }\n        else\n        {\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n      goto ImportQuantumPixelsFailed;\n\n\n          if (z<=1 &&       /* fix only during a last pass z==0 || z==1 */\n          (CellType==miINT8 || CellType==miINT16 || CellType==miINT32 || CellType==miINT64))\n      FixSignedValues(image,q,MATLAB_HDR.SizeX);\n        }\n\n        if (!SyncAuthenticPixels(image,exception))\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  MAT failed to sync image pixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n      }\n    } while(z-- >= 2);\nExitLoop:\n\n\n    /* Read complex part of numbers here */\n    if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n    {        /* Find Min and Max Values for complex parts of floats */\n      CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n      i = ReadBlobXXXLong(image2);           /* size of a complex part - toss away*/\n\n      if (CellType==miDOUBLE || CellType==miSINGLE)\n      {\n        CalcMinMax(image2,  image_info->endian, MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &MinVal, &MaxVal);\n      }\n\n      if (CellType==miDOUBLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobDoublesXXX(image2, ldblk, (double *)BImgBuff);\n          InsertComplexDoubleRow(image, (double *)BImgBuff, i, MinVal, MaxVal,\n            exception);\n  }\n\n      if (CellType==miSINGLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobFloatsXXX(image2, ldblk, (float *)BImgBuff);\n          InsertComplexFloatRow(image,(float *)BImgBuff,i,MinVal,MaxVal,\n            exception);\n  }\n    }\n\n      /* Image is gray when no complex flag is set and 2D Matrix AGAIN!!! */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      image->type=GrayscaleType;\n    if (image->depth == 1)\n      image->type=BilevelType;\n\n    if(image2==image)\n        image2 = NULL;    /* Remove shadow copy to an image before rotation. */\n\n      /*  Rotate image. */\n    rotated_image = RotateImage(image, 90.0, exception);\n    if (rotated_image != (Image *) NULL)\n    {\n        /* Remove page offsets added by RotateImage */\n      rotated_image->page.x=0;\n      rotated_image->page.y=0;\n\n      blob = rotated_image->blob;\n      rotated_image->blob = image->blob;\n      rotated_image->colors = image->colors;\n      image->blob = blob;\n      AppendImageToList(&image,rotated_image);\n      DeleteImageFromList(&image);\n    }\n\ndone_reading:\n\n    if(image2!=NULL)\n      if(image2!=image)\n      {\n        DeleteImageFromList(&image2);\n  if(clone_info)\n  {\n          if(clone_info->file)\n    {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) remove_utf8(clone_info->filename);\n    }\n        }\n      }\n\n      /* Allocate next image structure. */\n    AcquireNextImage(image_info,image,exception);\n    if (image->next == (Image *) NULL) break;\n    image=SyncNextImageInList(image);\n    image->columns=image->rows=0;\n    image->colors=0;\n\n      /* row scan buffer is no longer needed */\n    RelinquishMagickMemory(BImgBuff);\n    BImgBuff = NULL;\n\n    if(--Frames>0)\n    {\n      z = z2;\n      if(image2==NULL) image2 = image;\n      goto NEXT_FRAME;\n    }\n    if ((image2!=NULL) && (image2!=image))   /* Does shadow temporary decompressed image exist? */\n      {\n/*  CloseBlob(image2); */\n        DeleteImageFromList(&image2);\n        if(clone_info)\n        {\n          if(clone_info->file)\n          {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) remove_utf8(clone_info->filename);\n          }\n        }\n        }\n\n    if (quantum_info != (QuantumInfo *) NULL)\n      quantum_info=DestroyQuantumInfo(quantum_info);\n    if (clone_info)\n      clone_info=DestroyImageInfo(clone_info);\n  }\n\n  RelinquishMagickMemory(BImgBuff);\n  if (quantum_info != (QuantumInfo *) NULL)\n    quantum_info=DestroyQuantumInfo(quantum_info);\nEND_OF_READING:\n  CloseBlob(image);\n\n\n  {\n    Image *p;\n    ssize_t scene=0;\n\n    /*\n      Rewind list, removing any empty images while rewinding.\n    */\n    p=image;\n    image=NULL;\n    while (p != (Image *) NULL)\n      {\n        Image *tmp=p;\n        if ((p->rows == 0) || (p->columns == 0)) {\n          p=p->previous;\n          if (tmp == image2)\n            image2=(Image *) NULL;\n          DeleteImageFromList(&tmp);\n        } else {\n          image=p;\n          p=p->previous;\n        }\n      }\n\n    /*\n      Fix scene numbers\n    */\n    for (p=image; p != (Image *) NULL; p=p->next)\n      p->scene=scene++;\n  }\n\n  if(clone_info != NULL)  /* cleanup garbage file from compression */\n  {\n    if(clone_info->file)\n    {\n      fclose(clone_info->file);\n      clone_info->file = NULL;\n      (void) remove_utf8(clone_info->filename);\n    }\n    DestroyImageInfo(clone_info);\n    clone_info = NULL;\n  }\n  if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\"return\");\n  if (image==NULL)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\")\n  else\n    if ((image != image2) && (image2 != (Image *) NULL))\n      image2=DestroyImage(image2);\n  return (image);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/04178de2247e353fc095846784b9a10fefdbf890", "file_name": "coders/mat.c", "vul_type": "cwe-416", "description": "Write a function in C to read and process MATLAB image files."}
{"func_name": "rds_rdma_extra_size", "func_src_before": "int rds_rdma_extra_size(struct rds_rdma_args *args)\n{\n\tstruct rds_iovec vec;\n\tstruct rds_iovec __user *local_vec;\n\tint tot_pages = 0;\n\tunsigned int nr_pages;\n\tunsigned int i;\n\n\tlocal_vec = (struct rds_iovec __user *)(unsigned long) args->local_vec_addr;\n\n\t/* figure out the number of pages in the vector */\n\tfor (i = 0; i < args->nr_local; i++) {\n\t\tif (copy_from_user(&vec, &local_vec[i],\n\t\t\t\t   sizeof(struct rds_iovec)))\n\t\t\treturn -EFAULT;\n\n\t\tnr_pages = rds_pages_in_vec(&vec);\n\t\tif (nr_pages == 0)\n\t\t\treturn -EINVAL;\n\n\t\ttot_pages += nr_pages;\n\n\t\t/*\n\t\t * nr_pages for one entry is limited to (UINT_MAX>>PAGE_SHIFT)+1,\n\t\t * so tot_pages cannot overflow without first going negative.\n\t\t */\n\t\tif (tot_pages < 0)\n\t\t\treturn -EINVAL;\n\t}\n\n\treturn tot_pages * sizeof(struct scatterlist);\n}", "func_src_after": "int rds_rdma_extra_size(struct rds_rdma_args *args)\n{\n\tstruct rds_iovec vec;\n\tstruct rds_iovec __user *local_vec;\n\tint tot_pages = 0;\n\tunsigned int nr_pages;\n\tunsigned int i;\n\n\tlocal_vec = (struct rds_iovec __user *)(unsigned long) args->local_vec_addr;\n\n\tif (args->nr_local == 0)\n\t\treturn -EINVAL;\n\n\t/* figure out the number of pages in the vector */\n\tfor (i = 0; i < args->nr_local; i++) {\n\t\tif (copy_from_user(&vec, &local_vec[i],\n\t\t\t\t   sizeof(struct rds_iovec)))\n\t\t\treturn -EFAULT;\n\n\t\tnr_pages = rds_pages_in_vec(&vec);\n\t\tif (nr_pages == 0)\n\t\t\treturn -EINVAL;\n\n\t\ttot_pages += nr_pages;\n\n\t\t/*\n\t\t * nr_pages for one entry is limited to (UINT_MAX>>PAGE_SHIFT)+1,\n\t\t * so tot_pages cannot overflow without first going negative.\n\t\t */\n\t\tif (tot_pages < 0)\n\t\t\treturn -EINVAL;\n\t}\n\n\treturn tot_pages * sizeof(struct scatterlist);\n}", "commit_link": "github.com/torvalds/linux/commit/c095508770aebf1b9218e77026e48345d719b17c", "file_name": "net/rds/rdma.c", "vul_type": "cwe-787", "description": "Write a C function named `rds_rdma_extra_size` that calculates the total size of memory pages described by an array of `rds_iovec` structures, handling user-space memory copying and validation."}
{"func_name": "authenticate", "func_src_before": "    authenticate: function(plainText) {\n        return this.encryptPassword(plainText) === this.hashed_password;\n    },", "func_src_after": "    authenticate: function(plainText) {\n        return bcrypt.compareSync(plainText,this.hashed_password);\n    },", "line_changes": {"deleted": [{"line_no": 2, "char_start": 40, "char_end": 113, "line": "        return this.encryptPassword(plainText) === this.hashed_password;\n"}, {"line_no": 3, "char_start": 113, "char_end": 119, "line": "    },\n"}], "added": []}, "char_changes": {"deleted": [{"char_start": 55, "char_end": 75, "chars": "this.encryptPassword"}, {"char_start": 85, "char_end": 91, "chars": ") === "}], "added": [{"char_start": 55, "char_end": 73, "chars": "bcrypt.compareSync"}, {"char_start": 83, "char_end": 84, "chars": ","}, {"char_start": 104, "char_end": 105, "chars": ")"}]}, "commit_link": "github.com/aburchette/territory-manager-mean/commit/24620016541089cc0ca316a0dec32ee0db864d98", "file_name": "user.js", "vul_type": "cwe-916", "commit_msg": "Replaced SHA1 password hashing with more bcrypt", "parent_commit": "f944f0a464555f033f01413f24d1cd47ab412ae7", "description": "Write a JavaScript function named `authenticate` that checks if a plain text password matches a stored hashed password."}
{"func_name": "AP4_HdlrAtom::AP4_HdlrAtom", "func_src_before": "AP4_HdlrAtom::AP4_HdlrAtom(AP4_UI32        size, \n                           AP4_UI08        version,\n                           AP4_UI32        flags,\n                           AP4_ByteStream& stream) :\n    AP4_Atom(AP4_ATOM_TYPE_HDLR, size, version, flags)\n{\n    AP4_UI32 predefined;\n    stream.ReadUI32(predefined);\n    stream.ReadUI32(m_HandlerType);\n    stream.ReadUI32(m_Reserved[0]);\n    stream.ReadUI32(m_Reserved[1]);\n    stream.ReadUI32(m_Reserved[2]);\n    \n    // read the name unless it is empty\n    int name_size = size-(AP4_FULL_ATOM_HEADER_SIZE+20);\n    if (name_size == 0) return;\n    char* name = new char[name_size+1];\n    stream.Read(name, name_size);\n    name[name_size] = '\\0'; // force a null termination\n    // handle a special case: the Quicktime files have a pascal\n    // string here, but ISO MP4 files have a C string.\n    // we try to detect a pascal encoding and correct it.\n    if (name[0] == name_size-1) {\n        m_HandlerName = name+1;\n    } else {\n        m_HandlerName = name;\n    }\n    delete[] name;\n}", "func_src_after": "AP4_HdlrAtom::AP4_HdlrAtom(AP4_UI32        size, \n                           AP4_UI08        version,\n                           AP4_UI32        flags,\n                           AP4_ByteStream& stream) :\n    AP4_Atom(AP4_ATOM_TYPE_HDLR, size, version, flags)\n{\n    AP4_UI32 predefined;\n    stream.ReadUI32(predefined);\n    stream.ReadUI32(m_HandlerType);\n    stream.ReadUI32(m_Reserved[0]);\n    stream.ReadUI32(m_Reserved[1]);\n    stream.ReadUI32(m_Reserved[2]);\n    \n    // read the name unless it is empty\n    if (size < AP4_FULL_ATOM_HEADER_SIZE+20) return;\n    AP4_UI32 name_size = size-(AP4_FULL_ATOM_HEADER_SIZE+20);\n    char* name = new char[name_size+1];\n    if (name == NULL) return;\n    stream.Read(name, name_size);\n    name[name_size] = '\\0'; // force a null termination\n    // handle a special case: the Quicktime files have a pascal\n    // string here, but ISO MP4 files have a C string.\n    // we try to detect a pascal encoding and correct it.\n    if (name[0] == name_size-1) {\n        m_HandlerName = name+1;\n    } else {\n        m_HandlerName = name;\n    }\n    delete[] name;\n}", "commit_link": "github.com/axiomatic-systems/Bento4/commit/22192de5367fa0cee985917f092be4060b7c00b0", "file_name": "Source/C++/Core/Ap4HdlrAtom.cpp", "vul_type": "cwe-476", "description": "Write a C++ constructor for the `AP4_HdlrAtom` class that initializes an atom and reads its handler type and name from a byte stream."}
{"func_name": "delete", "func_src_before": "    @jwt_required\n    def delete(self, email):\n        \"\"\" Deletes admin with the corresponding email \"\"\"\n        return database_utilities.execute_query(f\"\"\"delete from admins where email = '{email}'\"\"\")", "func_src_after": "    @jwt_required\n    def delete(self, email):\n        \"\"\" Deletes admin with the corresponding email \"\"\"\n        return database_utilities.execute_query(f\"\"\"delete from admins where email = %s\"\"\", (email, ))", "commit_link": "github.com/sgosal2/tiger-boards-backend/commit/4670109dd613df2f2fe7e8403ebd149df2b55485", "file_name": "apis/admins.py", "vul_type": "cwe-089", "description": "Write a Python function with JWT authentication that deletes an admin by email from a database using SQL query execution."}
{"func_name": "ResponseParser::parse", "func_src_before": "\tpublic Object parse(SerializerHandler serializerHandler, InputStream response, boolean debugMode) throws XMLRPCException {\n\n\t\ttry {\n\n\t\t\tDocumentBuilderFactory factory = DocumentBuilderFactory.newInstance();\n\t\t\tfactory.setNamespaceAware(true);\n\t\t\tDocumentBuilder builder = factory.newDocumentBuilder();\n\t\t\tDocument dom = builder.parse(response);\n\t\t\tif (debugMode ){\n\t\t\t\tprintDocument(dom, System.out);\n\t\t\t}\n\t\t\tElement e = dom.getDocumentElement();\n\n\n\t\t\t// Check for root tag\n\t\t\tif(!e.getNodeName().equals(XMLRPCClient.METHOD_RESPONSE)) {\n\t\t\t\tthrow new XMLRPCException(\"MethodResponse root tag is missing.\");\n\t\t\t}\n\n\t\t\te = XMLUtil.getOnlyChildElement(e.getChildNodes());\n\n\t\t\tif(e.getNodeName().equals(XMLRPCClient.PARAMS)) {\n\n\t\t\t\te = XMLUtil.getOnlyChildElement(e.getChildNodes());\n\n\t\t\t\tif(!e.getNodeName().equals(XMLRPCClient.PARAM)) {\n\t\t\t\t\tthrow new XMLRPCException(\"The params tag must contain a param tag.\");\n\t\t\t\t}\n\n\t\t\t\treturn getReturnValueFromElement(serializerHandler, e);\n\n\t\t\t} else if(e.getNodeName().equals(XMLRPCClient.FAULT)) {\n\n\t\t\t\t@SuppressWarnings(\"unchecked\")\n\t\t\t\tMap<String,Object> o = (Map<String,Object>)getReturnValueFromElement(serializerHandler, e);\n\n\t\t\t\tthrow new XMLRPCServerException((String)o.get(FAULT_STRING), (Integer)o.get(FAULT_CODE));\n\n\t\t\t}\n\n\t\t\tthrow new XMLRPCException(\"The methodResponse tag must contain a fault or params tag.\");\n\n\t\t} catch(XMLRPCServerException e) {\n\t\t\tthrow e;\n\t\t} catch (Exception ex) {\n\t\t\tthrow new XMLRPCException(\"Error getting result from server.\", ex);\n\t\t}\n\n\t}", "func_src_after": "\tpublic Object parse(SerializerHandler serializerHandler, InputStream response, boolean debugMode) throws XMLRPCException {\n\n\t\ttry {\n\t\t\tDocumentBuilderFactory factory = DocumentBuilderFactory.newInstance();\n\n\t\t\t// Ensure the xml parser won't allow exploitation of the vuln CWE-611\n\t\t\t// (described on https://cwe.mitre.org/data/definitions/611.html )\n\t\t\tfactory.setFeature(\"http://apache.org/xml/features/disallow-doctype-decl\", true);\n\t\t\tfactory.setExpandEntityReferences(false);\n\t\t\tfactory.setNamespaceAware(true);\n\t\t\tfactory.setXIncludeAware(false);\n\t\t\tfactory.setExpandEntityReferences(false);\n\t\t\t// End of the configuration of the parser for CWE-611\n\n\t\t\tDocumentBuilder builder = factory.newDocumentBuilder();\n\t\t\tDocument dom = builder.parse(response);\n\t\t\tif (debugMode ){\n\t\t\t\tprintDocument(dom, System.out);\n\t\t\t}\n\t\t\tElement e = dom.getDocumentElement();\n\n\n\t\t\t// Check for root tag\n\t\t\tif(!e.getNodeName().equals(XMLRPCClient.METHOD_RESPONSE)) {\n\t\t\t\tthrow new XMLRPCException(\"MethodResponse root tag is missing.\");\n\t\t\t}\n\n\t\t\te = XMLUtil.getOnlyChildElement(e.getChildNodes());\n\n\t\t\tif(e.getNodeName().equals(XMLRPCClient.PARAMS)) {\n\n\t\t\t\te = XMLUtil.getOnlyChildElement(e.getChildNodes());\n\n\t\t\t\tif(!e.getNodeName().equals(XMLRPCClient.PARAM)) {\n\t\t\t\t\tthrow new XMLRPCException(\"The params tag must contain a param tag.\");\n\t\t\t\t}\n\n\t\t\t\treturn getReturnValueFromElement(serializerHandler, e);\n\n\t\t\t} else if(e.getNodeName().equals(XMLRPCClient.FAULT)) {\n\n\t\t\t\t@SuppressWarnings(\"unchecked\")\n\t\t\t\tMap<String,Object> o = (Map<String,Object>)getReturnValueFromElement(serializerHandler, e);\n\n\t\t\t\tthrow new XMLRPCServerException((String)o.get(FAULT_STRING), (Integer)o.get(FAULT_CODE));\n\n\t\t\t}\n\n\t\t\tthrow new XMLRPCException(\"The methodResponse tag must contain a fault or params tag.\");\n\n\t\t} catch(XMLRPCServerException e) {\n\t\t\tthrow e;\n\t\t} catch (Exception ex) {\n\t\t\tthrow new XMLRPCException(\"Error getting result from server.\", ex);\n\t\t}\n\n\t}", "line_changes": {"deleted": [{"line_no": 4, "char_start": 133, "char_end": 134, "line": "\n"}], "added": [{"line_no": 5, "char_start": 207, "char_end": 208, "line": "\n"}, {"line_no": 8, "char_start": 351, "char_end": 436, "line": "\t\t\tfactory.setFeature(\"http://apache.org/xml/features/disallow-doctype-decl\", true);\n"}, {"line_no": 9, "char_start": 436, "char_end": 481, "line": "\t\t\tfactory.setExpandEntityReferences(false);\n"}, {"line_no": 11, "char_start": 517, "char_end": 553, "line": "\t\t\tfactory.setXIncludeAware(false);\n"}, {"line_no": 12, "char_start": 553, "char_end": 598, "line": "\t\t\tfactory.setExpandEntityReferences(false);\n"}, {"line_no": 14, "char_start": 655, "char_end": 656, "line": "\n"}]}, "char_changes": {"deleted": [{"char_start": 133, "char_end": 134, "chars": "\n"}, {"char_start": 208, "char_end": 243, "chars": "\t\t\tfactory.setNamespaceAware(true);"}], "added": [{"char_start": 207, "char_end": 655, "chars": "\n\t\t\t// Ensure the xml parser won't allow exploitation of the vuln CWE-611\n\t\t\t// (described on https://cwe.mitre.org/data/definitions/611.html )\n\t\t\tfactory.setFeature(\"http://apache.org/xml/features/disallow-doctype-decl\", true);\n\t\t\tfactory.setExpandEntityReferences(false);\n\t\t\tfactory.setNamespaceAware(true);\n\t\t\tfactory.setXIncludeAware(false);\n\t\t\tfactory.setExpandEntityReferences(false);\n\t\t\t// End of the configuration of the parser for CWE-611\n"}]}, "commit_link": "github.com/timroes/aXMLRPC/commit/ad6615b3ec41353e614f6ea5fdd5b046442a832b", "file_name": "ResponseParser.java", "vul_type": "cwe-611", "commit_msg": "Fix CWE-611\n\nThis commit fixes the issue described on\nhttps://cwe.mitre.org/data/definitions/611.html\n\ntest", "parent_commit": "2e59d03c961607d32bc9dc5e7aba931338907603", "description": "Write a Java function to parse an XMLRPC response from an InputStream and handle debug mode."}
{"func_name": "_port_conf_generator", "func_src_before": "    def _port_conf_generator(self, cmd):\n        ssh_cmd = '%s -delim !' % cmd\n        out, err = self._run_ssh(ssh_cmd)\n\n        if not len(out.strip()):\n            return\n        port_lines = out.strip().split('\\n')\n        if not len(port_lines):\n            return\n\n        header = port_lines.pop(0)\n        yield header\n        for portip_line in port_lines:\n            try:\n                port_data = self._get_hdr_dic(header, portip_line, '!')\n            except exception.VolumeBackendAPIException:\n                with excutils.save_and_reraise_exception():\n                    self._log_cli_output_error('_port_conf_generator',\n                                               ssh_cmd, out, err)\n            yield port_data", "func_src_after": "    def _port_conf_generator(self, cmd):\n        ssh_cmd = cmd + ['-delim', '!']\n        out, err = self._run_ssh(ssh_cmd)\n\n        if not len(out.strip()):\n            return\n        port_lines = out.strip().split('\\n')\n        if not len(port_lines):\n            return\n\n        header = port_lines.pop(0)\n        yield header\n        for portip_line in port_lines:\n            try:\n                port_data = self._get_hdr_dic(header, portip_line, '!')\n            except exception.VolumeBackendAPIException:\n                with excutils.save_and_reraise_exception():\n                    self._log_cli_output_error('_port_conf_generator',\n                                               ssh_cmd, out, err)\n            yield port_data", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function named `_port_conf_generator` that takes a command, executes it via SSH, and yields parsed port configuration data."}
{"func_name": "whitelist", "func_src_before": "def whitelist(users: str):\n    for user in users.split():\n        call(WHITELIST_COMMAND_TEMPLATE.format(user))", "func_src_after": "def whitelist(channel: discord.TextChannel, users: str):\n    for user in users.split():\n        if not re.match(r'^[A-Za-z0-9_]{3,16}$', user):  # as per https://help.mojang.com/customer/en/portal/articles/928638-minecraft-usernames?b_id=5408\n            await channel.send('\\'{}\\' is not a valid Minecraft username'.format(user))\n        else:\n            call(WHITELIST_COMMAND_TEMPLATE.format(user))", "commit_link": "github.com/thomotron/Gatekeep/commit/955660f9b3dc336ab0d5dfb4392b3ab6deac6b25", "file_name": "bot.py", "vul_type": "cwe-078", "description": "Write a Python function that processes a string of usernames and executes a command for each valid username."}
{"func_name": "add_post", "func_src_before": "def add_post(content):\n  \"\"\"Add a post to the 'database' with the current timestamp.\"\"\"\n  db = psycopg2.connect(database=DBNAME)\n  c = db.cursor()\n  c.execute(\"insert into posts values('%s')\" % content)\n  db.commit()\n  db.close()", "func_src_after": "def add_post(content):\n  \"\"\"Add a post to the 'database' with the current timestamp.\"\"\"\n  db = psycopg2.connect(database=DBNAME)\n  c = db.cursor()\n  c.execute(\"insert into posts values(%s)\",(content,))\n  db.commit()\n  db.close()", "commit_link": "github.com/tfalbo/SuzyMakeup/commit/1a5d6ccf02bec303d454f87a6bb39baed30c205f", "file_name": "vagrant/forum/forumdb.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a new post into a database using psycopg2."}
{"func_name": "ng_pkt", "func_src_before": "static int ng_pkt(git_pkt **out, const char *line, size_t len)\n{\n\tgit_pkt_ng *pkt;\n\tconst char *ptr;\n\tsize_t alloclen;\n\n\tpkt = git__malloc(sizeof(*pkt));\n\tGITERR_CHECK_ALLOC(pkt);\n\n\tpkt->ref = NULL;\n\tpkt->type = GIT_PKT_NG;\n\n\tline += 3; /* skip \"ng \" */\n\tif (!(ptr = strchr(line, ' ')))\n\t\tgoto out_err;\n\tlen = ptr - line;\n\n\tGITERR_CHECK_ALLOC_ADD(&alloclen, len, 1);\n\tpkt->ref = git__malloc(alloclen);\n\tGITERR_CHECK_ALLOC(pkt->ref);\n\n\tmemcpy(pkt->ref, line, len);\n\tpkt->ref[len] = '\\0';\n\n\tline = ptr + 1;\n\tif (!(ptr = strchr(line, '\\n')))\n\t\tgoto out_err;\n\tlen = ptr - line;\n\n\tGITERR_CHECK_ALLOC_ADD(&alloclen, len, 1);\n\tpkt->msg = git__malloc(alloclen);\n\tGITERR_CHECK_ALLOC(pkt->msg);\n\n\tmemcpy(pkt->msg, line, len);\n\tpkt->msg[len] = '\\0';\n\n\t*out = (git_pkt *)pkt;\n\treturn 0;\n\nout_err:\n\tgiterr_set(GITERR_NET, \"invalid packet line\");\n\tgit__free(pkt->ref);\n\tgit__free(pkt);\n\treturn -1;\n}", "func_src_after": "static int ng_pkt(git_pkt **out, const char *line, size_t len)\n{\n\tgit_pkt_ng *pkt;\n\tconst char *ptr;\n\tsize_t alloclen;\n\n\tpkt = git__malloc(sizeof(*pkt));\n\tGITERR_CHECK_ALLOC(pkt);\n\n\tpkt->ref = NULL;\n\tpkt->type = GIT_PKT_NG;\n\n\tif (len < 3)\n\t\tgoto out_err;\n\tline += 3; /* skip \"ng \" */\n\tlen -= 3;\n\tif (!(ptr = memchr(line, ' ', len)))\n\t\tgoto out_err;\n\tlen = ptr - line;\n\n\tGITERR_CHECK_ALLOC_ADD(&alloclen, len, 1);\n\tpkt->ref = git__malloc(alloclen);\n\tGITERR_CHECK_ALLOC(pkt->ref);\n\n\tmemcpy(pkt->ref, line, len);\n\tpkt->ref[len] = '\\0';\n\n\tif (len < 1)\n\t\tgoto out_err;\n\tline = ptr + 1;\n\tlen -= 1;\n\tif (!(ptr = memchr(line, '\\n', len)))\n\t\tgoto out_err;\n\tlen = ptr - line;\n\n\tGITERR_CHECK_ALLOC_ADD(&alloclen, len, 1);\n\tpkt->msg = git__malloc(alloclen);\n\tGITERR_CHECK_ALLOC(pkt->msg);\n\n\tmemcpy(pkt->msg, line, len);\n\tpkt->msg[len] = '\\0';\n\n\t*out = (git_pkt *)pkt;\n\treturn 0;\n\nout_err:\n\tgiterr_set(GITERR_NET, \"invalid packet line\");\n\tgit__free(pkt->ref);\n\tgit__free(pkt);\n\treturn -1;\n}", "commit_link": "github.com/libgit2/libgit2/commit/1f9a8510e1d2f20ed7334eeeddb92c4dd8e7c649", "file_name": "src/transports/smart_pkt.c", "vul_type": "cwe-125", "description": "Write a C function to parse a Git \"ng\" packet, allocating memory for its contents and handling errors appropriately."}
{"func_name": "_get_vdisk_fc_mappings", "func_src_before": "    def _get_vdisk_fc_mappings(self, vdisk_name):\n        \"\"\"Return FlashCopy mappings that this vdisk is associated with.\"\"\"\n\n        ssh_cmd = 'svcinfo lsvdiskfcmappings -nohdr %s' % vdisk_name\n        out, err = self._run_ssh(ssh_cmd)\n\n        mapping_ids = []\n        if (len(out.strip())):\n            lines = out.strip().split('\\n')\n            mapping_ids = [line.split()[0] for line in lines]\n        return mapping_ids", "func_src_after": "    def _get_vdisk_fc_mappings(self, vdisk_name):\n        \"\"\"Return FlashCopy mappings that this vdisk is associated with.\"\"\"\n\n        ssh_cmd = ['svcinfo', 'lsvdiskfcmappings', '-nohdr', vdisk_name]\n        out, err = self._run_ssh(ssh_cmd)\n\n        mapping_ids = []\n        if (len(out.strip())):\n            lines = out.strip().split('\\n')\n            mapping_ids = [line.split()[0] for line in lines]\n        return mapping_ids", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to fetch and return the IDs of FlashCopy mappings for a given virtual disk using SSH commands."}
{"func_name": "string_scan_range", "func_src_before": "static int string_scan_range(RList *list, const ut8 *buf, int min,\n\t\t\t      const ut64 from, const ut64 to, int type) {\n\tut8 tmp[R_STRING_SCAN_BUFFER_SIZE];\n\tut64 str_start, needle = from;\n\tint count = 0, i, rc, runes;\n\tint str_type = R_STRING_TYPE_DETECT;\n\n\tif (type == -1) {\n\t\ttype = R_STRING_TYPE_DETECT;\n\t}\n\tif (!buf || !min) {\n\t\treturn -1;\n\t}\n\twhile (needle < to) {\n\t\trc = r_utf8_decode (buf + needle, to - needle, NULL);\n\t\tif (!rc) {\n\t\t\tneedle++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (type == R_STRING_TYPE_DETECT) {\n\t\t\tchar *w = (char *)buf + needle + rc;\n\t\t\tif ((to - needle) > 4) {\n\t\t\t\tbool is_wide32 = needle + rc + 2 < to && !w[0] && !w[1] && !w[2] && w[3] && !w[4];\n\t\t\t\tif (is_wide32) {\n\t\t\t\t\tstr_type = R_STRING_TYPE_WIDE32;\n\t\t\t\t} else {\n\t\t\t\t\tbool is_wide = needle + rc + 2 < to && !w[0] && w[1] && !w[2];\n\t\t\t\t\tstr_type = is_wide? R_STRING_TYPE_WIDE: R_STRING_TYPE_ASCII;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tstr_type = R_STRING_TYPE_ASCII;\n\t\t\t}\n\t\t} else {\n\t\t\tstr_type = type;\n\t\t}\n\n\n\t\trunes = 0;\n\t\tstr_start = needle;\n\n\t\t/* Eat a whole C string */\n\t\tfor (rc = i = 0; i < sizeof (tmp) - 3 && needle < to; i += rc) {\n\t\t\tRRune r = {0};\n\n\t\t\tif (str_type == R_STRING_TYPE_WIDE32) {\n\t\t\t\trc = r_utf32le_decode (buf + needle, to - needle, &r);\n\t\t\t\tif (rc) {\n\t\t\t\t\trc = 4;\n\t\t\t\t}\n\t\t\t} else if (str_type == R_STRING_TYPE_WIDE) {\n\t\t\t\trc = r_utf16le_decode (buf + needle, to - needle, &r);\n\t\t\t\tif (rc == 1) {\n\t\t\t\t\trc = 2;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\trc = r_utf8_decode (buf + needle, to - needle, &r);\n\t\t\t\tif (rc > 1) {\n\t\t\t\t\tstr_type = R_STRING_TYPE_UTF8;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t/* Invalid sequence detected */\n\t\t\tif (!rc) {\n\t\t\t\tneedle++;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tneedle += rc;\n\n\t\t\tif (r_isprint (r)) {\n\t\t\t\tif (str_type == R_STRING_TYPE_WIDE32) {\n\t\t\t\t\tif (r == 0xff) {\n\t\t\t\t\t\tr = 0;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\trc = r_utf8_encode (&tmp[i], r);\n\t\t\t\trunes++;\n\t\t\t\t/* Print the escape code */\n\t\t\t} else if (r && r < 0x100 && strchr (\"\\b\\v\\f\\n\\r\\t\\a\\e\", (char)r)) {\n\t\t\t\tif ((i + 32) < sizeof (tmp) && r < 28) {\n\t\t\t\t\ttmp[i + 0] = '\\\\';\n\t\t\t\t\ttmp[i + 1] = \"       abtnvfr             e\"[r];\n\t\t\t\t} else {\n\t\t\t\t\t// string too long\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\trc = 2;\n\t\t\t\trunes++;\n\t\t\t} else {\n\t\t\t\t/* \\0 marks the end of C-strings */\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\ttmp[i++] = '\\0';\n\n\t\tif (runes >= min) {\n\t\t\tif (str_type == R_STRING_TYPE_ASCII) {\n\t\t\t\t// reduce false positives\n\t\t\t\tint j;\n\t\t\t\tfor (j = 0; j < i; j++) {\n\t\t\t\t\tchar ch = tmp[j];\n\t\t\t\t\tif (ch != '\\n' && ch != '\\r' && ch != '\\t') {\n\t\t\t\t\t\tif (!IS_PRINTABLE (tmp[j])) {\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (list) {\n\t\t\t\tRBinString *new = R_NEW0 (RBinString);\n\t\t\t\tif (!new) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tnew->type = str_type;\n\t\t\t\tnew->length = runes;\n\t\t\t\tnew->size = needle - str_start;\n\t\t\t\tnew->ordinal = count++;\n\t\t\t\t// TODO: move into adjust_offset\n\t\t\t\tswitch (str_type) {\n\t\t\t\tcase R_STRING_TYPE_WIDE:\n\t\t\t\t\t{\n\t\t\t\t\t\tconst ut8 *p = buf  + str_start - 2;\n\t\t\t\t\t\tif (p[0] == 0xff && p[1] == 0xfe) {\n\t\t\t\t\t\t\tstr_start -= 2; // \\xff\\xfe\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase R_STRING_TYPE_WIDE32:\n\t\t\t\t\t{\n\t\t\t\t\t\tconst ut8 *p = buf  + str_start - 4;\n\t\t\t\t\t\tif (p[0] == 0xff && p[1] == 0xfe) {\n\t\t\t\t\t\t\tstr_start -= 4; // \\xff\\xfe\\x00\\x00\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tnew->paddr = new->vaddr = str_start;\n\t\t\t\tnew->string = r_str_ndup ((const char *)tmp, i);\n\t\t\t\tr_list_append (list, new);\n\t\t\t} else {\n\t\t\t\t// DUMP TO STDOUT. raw dumping for rabin2 -zzz\n\t\t\t\tprintf (\"0x%08\" PFMT64x \" %s\\n\", str_start, tmp);\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}", "func_src_after": "static int string_scan_range(RList *list, const ut8 *buf, int min,\n\t\t\t      const ut64 from, const ut64 to, int type) {\n\tut8 tmp[R_STRING_SCAN_BUFFER_SIZE];\n\tut64 str_start, needle = from;\n\tint count = 0, i, rc, runes;\n\tint str_type = R_STRING_TYPE_DETECT;\n\n\tif (type == -1) {\n\t\ttype = R_STRING_TYPE_DETECT;\n\t}\n\tif (!buf || !min) {\n\t\treturn -1;\n\t}\n\twhile (needle < to) {\n\t\trc = r_utf8_decode (buf + needle, to - needle, NULL);\n\t\tif (!rc) {\n\t\t\tneedle++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (type == R_STRING_TYPE_DETECT) {\n\t\t\tchar *w = (char *)buf + needle + rc;\n\t\t\tif ((to - needle) > 4) {\n\t\t\t\tbool is_wide32 = needle + rc + 2 < to && !w[0] && !w[1] && !w[2] && w[3] && !w[4];\n\t\t\t\tif (is_wide32) {\n\t\t\t\t\tstr_type = R_STRING_TYPE_WIDE32;\n\t\t\t\t} else {\n\t\t\t\t\tbool is_wide = needle + rc + 2 < to && !w[0] && w[1] && !w[2];\n\t\t\t\t\tstr_type = is_wide? R_STRING_TYPE_WIDE: R_STRING_TYPE_ASCII;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tstr_type = R_STRING_TYPE_ASCII;\n\t\t\t}\n\t\t} else {\n\t\t\tstr_type = type;\n\t\t}\n\n\n\t\trunes = 0;\n\t\tstr_start = needle;\n\n\t\t/* Eat a whole C string */\n\t\tfor (rc = i = 0; i < sizeof (tmp) - 3 && needle < to; i += rc) {\n\t\t\tRRune r = {0};\n\n\t\t\tif (str_type == R_STRING_TYPE_WIDE32) {\n\t\t\t\trc = r_utf32le_decode (buf + needle, to - needle, &r);\n\t\t\t\tif (rc) {\n\t\t\t\t\trc = 4;\n\t\t\t\t}\n\t\t\t} else if (str_type == R_STRING_TYPE_WIDE) {\n\t\t\t\trc = r_utf16le_decode (buf + needle, to - needle, &r);\n\t\t\t\tif (rc == 1) {\n\t\t\t\t\trc = 2;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\trc = r_utf8_decode (buf + needle, to - needle, &r);\n\t\t\t\tif (rc > 1) {\n\t\t\t\t\tstr_type = R_STRING_TYPE_UTF8;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t/* Invalid sequence detected */\n\t\t\tif (!rc) {\n\t\t\t\tneedle++;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tneedle += rc;\n\n\t\t\tif (r_isprint (r)) {\n\t\t\t\tif (str_type == R_STRING_TYPE_WIDE32) {\n\t\t\t\t\tif (r == 0xff) {\n\t\t\t\t\t\tr = 0;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\trc = r_utf8_encode (&tmp[i], r);\n\t\t\t\trunes++;\n\t\t\t\t/* Print the escape code */\n\t\t\t} else if (r && r < 0x100 && strchr (\"\\b\\v\\f\\n\\r\\t\\a\\e\", (char)r)) {\n\t\t\t\tif ((i + 32) < sizeof (tmp) && r < 28) {\n\t\t\t\t\ttmp[i + 0] = '\\\\';\n\t\t\t\t\ttmp[i + 1] = \"       abtnvfr             e\"[r];\n\t\t\t\t} else {\n\t\t\t\t\t// string too long\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\trc = 2;\n\t\t\t\trunes++;\n\t\t\t} else {\n\t\t\t\t/* \\0 marks the end of C-strings */\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\ttmp[i++] = '\\0';\n\n\t\tif (runes >= min) {\n\t\t\tif (str_type == R_STRING_TYPE_ASCII) {\n\t\t\t\t// reduce false positives\n\t\t\t\tint j;\n\t\t\t\tfor (j = 0; j < i; j++) {\n\t\t\t\t\tchar ch = tmp[j];\n\t\t\t\t\tif (ch != '\\n' && ch != '\\r' && ch != '\\t') {\n\t\t\t\t\t\tif (!IS_PRINTABLE (tmp[j])) {\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (list) {\n\t\t\t\tRBinString *new = R_NEW0 (RBinString);\n\t\t\t\tif (!new) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tnew->type = str_type;\n\t\t\t\tnew->length = runes;\n\t\t\t\tnew->size = needle - str_start;\n\t\t\t\tnew->ordinal = count++;\n\t\t\t\t// TODO: move into adjust_offset\n\t\t\t\tswitch (str_type) {\n\t\t\t\tcase R_STRING_TYPE_WIDE:\n\t\t\t\t\tif (str_start > 1) {\n\t\t\t\t\t\tconst ut8 *p = buf + str_start - 2;\n\t\t\t\t\t\tif (p[0] == 0xff && p[1] == 0xfe) {\n\t\t\t\t\t\t\tstr_start -= 2; // \\xff\\xfe\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase R_STRING_TYPE_WIDE32:\n\t\t\t\t\tif (str_start > 3) {\n\t\t\t\t\t\tconst ut8 *p = buf + str_start - 4;\n\t\t\t\t\t\tif (p[0] == 0xff && p[1] == 0xfe) {\n\t\t\t\t\t\t\tstr_start -= 4; // \\xff\\xfe\\x00\\x00\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tnew->paddr = new->vaddr = str_start;\n\t\t\t\tnew->string = r_str_ndup ((const char *)tmp, i);\n\t\t\t\tr_list_append (list, new);\n\t\t\t} else {\n\t\t\t\t// DUMP TO STDOUT. raw dumping for rabin2 -zzz\n\t\t\t\tprintf (\"0x%08\" PFMT64x \" %s\\n\", str_start, tmp);\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}", "commit_link": "github.com/radare/radare2/commit/d31c4d3cbdbe01ea3ded16a584de94149ecd31d9", "file_name": "libr/bin/bin.c", "vul_type": "cwe-125", "description": "Write a C function to scan for strings within a specified range in a buffer, detecting encoding and adding them to a list if they meet a minimum length."}
{"func_name": "core_anal_bytes", "func_src_before": "static void core_anal_bytes(RCore *core, const ut8 *buf, int len, int nops, int fmt) {\n\tint stacksize = r_config_get_i (core->config, \"esil.stack.depth\");\n\tbool iotrap = r_config_get_i (core->config, \"esil.iotrap\");\n\tbool romem = r_config_get_i (core->config, \"esil.romem\");\n\tbool stats = r_config_get_i (core->config, \"esil.stats\");\n\tbool be = core->print->big_endian;\n\tbool use_color = core->print->flags & R_PRINT_FLAGS_COLOR;\n\tcore->parser->relsub = r_config_get_i (core->config, \"asm.relsub\");\n\tint ret, i, j, idx, size;\n\tconst char *color = \"\";\n\tconst char *esilstr;\n\tconst char *opexstr;\n\tRAnalHint *hint;\n\tRAnalEsil *esil = NULL;\n\tRAsmOp asmop;\n\tRAnalOp op = {0};\n\tut64 addr;\n\tbool isFirst = true;\n\tunsigned int addrsize = r_config_get_i (core->config, \"esil.addr.size\");\n\tint totalsize = 0;\n\n\t// Variables required for setting up ESIL to REIL conversion\n\tif (use_color) {\n\t\tcolor = core->cons->pal.label;\n\t}\n\tswitch (fmt) {\n\tcase 'j':\n\t\tr_cons_printf (\"[\");\n\t\tbreak;\n\tcase 'r':\n\t\t// Setup for ESIL to REIL conversion\n\t\tesil = r_anal_esil_new (stacksize, iotrap, addrsize);\n\t\tif (!esil) {\n\t\t\treturn;\n\t\t}\n\t\tr_anal_esil_to_reil_setup (esil, core->anal, romem, stats);\n\t\tr_anal_esil_set_pc (esil, core->offset);\n\t\tbreak;\n\t}\n\tfor (i = idx = ret = 0; idx < len && (!nops || (nops && i < nops)); i++, idx += ret) {\n\t\taddr = core->offset + idx;\n\t\t// TODO: use more anal hints\n\t\thint = r_anal_hint_get (core->anal, addr);\n\t\tr_asm_set_pc (core->assembler, addr);\n\t\t(void)r_asm_disassemble (core->assembler, &asmop, buf + idx, len - idx);\n\t\tret = r_anal_op (core->anal, &op, core->offset + idx, buf + idx, len - idx, R_ANAL_OP_MASK_ESIL);\n\t\tesilstr = R_STRBUF_SAFEGET (&op.esil);\n\t\topexstr = R_STRBUF_SAFEGET (&op.opex);\n\t\tchar *mnem = strdup (r_asm_op_get_asm (&asmop));\n\t\tchar *sp = strchr (mnem, ' ');\n\t\tif (sp) {\n\t\t\t*sp = 0;\n\t\t\tif (op.prefix) {\n\t\t\t\tchar *arg = strdup (sp + 1);\n\t\t\t\tchar *sp = strchr (arg, ' ');\n\t\t\t\tif (sp) {\n\t\t\t\t\t*sp = 0;\n\t\t\t\t}\n\t\t\t\tfree (mnem);\n\t\t\t\tmnem = arg;\n\t\t\t}\n\t\t}\n\t\tif (ret < 1 && fmt != 'd') {\n\t\t\teprintf (\"Oops at 0x%08\" PFMT64x \" (\", core->offset + idx);\n\t\t\tfor (i = idx, j = 0; i < core->blocksize && j < 3; ++i, ++j) {\n\t\t\t\teprintf (\"%02x \", buf[i]);\n\t\t\t}\n\t\t\teprintf (\"...)\\n\");\n\t\t\tfree (mnem);\n\t\t\tbreak;\n\t\t}\n\t\tsize = (hint && hint->size)? hint->size: op.size;\n\t\tif (fmt == 'd') {\n\t\t\tchar *opname = strdup (r_asm_op_get_asm (&asmop));\n\t\t\tif (opname) {\n\t\t\t\tr_str_split (opname, ' ');\n\t\t\t\tchar *d = r_asm_describe (core->assembler, opname);\n\t\t\t\tif (d && *d) {\n\t\t\t\t\tr_cons_printf (\"%s: %s\\n\", opname, d);\n\t\t\t\t\tfree (d);\n\t\t\t\t} else {\n\t\t\t\t\teprintf (\"Unknown opcode\\n\");\n\t\t\t\t}\n\t\t\t\tfree (opname);\n\t\t\t}\n\t\t} else if (fmt == 'e') {\n\t\t\tif (*esilstr) {\n\t\t\t\tif (use_color) {\n\t\t\t\t\tr_cons_printf (\"%s0x%\" PFMT64x Color_RESET \" %s\\n\", color, core->offset + idx, esilstr);\n\t\t\t\t} else {\n\t\t\t\t\tr_cons_printf (\"0x%\" PFMT64x \" %s\\n\", core->offset + idx, esilstr);\n\t\t\t\t}\n\t\t\t}\n\t\t} else if (fmt == 's') {\n\t\t\ttotalsize += op.size;\n\t\t} else if (fmt == 'r') {\n\t\t\tif (*esilstr) {\n\t\t\t\tif (use_color) {\n\t\t\t\t\tr_cons_printf (\"%s0x%\" PFMT64x Color_RESET \"\\n\", color, core->offset + idx);\n\t\t\t\t} else {\n\t\t\t\t\tr_cons_printf (\"0x%\" PFMT64x \"\\n\", core->offset + idx);\n\t\t\t\t}\n\t\t\t\tr_anal_esil_parse (esil, esilstr);\n\t\t\t\tr_anal_esil_dumpstack (esil);\n\t\t\t\tr_anal_esil_stack_free (esil);\n\t\t\t}\n\t\t} else if (fmt == 'j') {\n\t\t\tif (isFirst) {\n\t\t\t\tisFirst = false;\n\t\t\t} else {\n\t\t\t\tr_cons_print (\",\");\n\t\t\t}\n\t\t\tr_cons_printf (\"{\\\"opcode\\\":\\\"%s\\\",\", r_asm_op_get_asm (&asmop));\n\t\t\t{\n\t\t\t\tchar strsub[128] = { 0 };\n\t\t\t\t// pc+33\n\t\t\t\tr_parse_varsub (core->parser, NULL,\n\t\t\t\t\tcore->offset + idx,\n\t\t\t\t\tasmop.size, r_asm_op_get_asm (&asmop),\n\t\t\t\t\tstrsub, sizeof (strsub));\n\t\t\t\t{\n\t\t\t\t\tut64 killme = UT64_MAX;\n\t\t\t\t\tif (r_io_read_i (core->io, op.ptr, &killme, op.refptr, be)) {\n\t\t\t\t\t\tcore->parser->relsub_addr = killme;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t// 0x33->sym.xx\n\t\t\t\tchar *p = strdup (strsub);\n\t\t\t\tif (p) {\n\t\t\t\t\tr_parse_filter (core->parser, addr, core->flags, p,\n\t\t\t\t\t\t\tstrsub, sizeof (strsub), be);\n\t\t\t\t\tfree (p);\n\t\t\t\t}\n\t\t\t\tr_cons_printf (\"\\\"disasm\\\":\\\"%s\\\",\", strsub);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"mnemonic\\\":\\\"%s\\\",\", mnem);\n\t\t\tif (hint && hint->opcode) {\n\t\t\t\tr_cons_printf (\"\\\"ophint\\\":\\\"%s\\\",\", hint->opcode);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"sign\\\":%s,\", r_str_bool (op.sign));\n\t\t\tr_cons_printf (\"\\\"prefix\\\":%\" PFMT64u \",\", op.prefix);\n\t\t\tr_cons_printf (\"\\\"id\\\":%d,\", op.id);\n\t\t\tif (opexstr && *opexstr) {\n\t\t\t\tr_cons_printf (\"\\\"opex\\\":%s,\", opexstr);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"addr\\\":%\" PFMT64u \",\", core->offset + idx);\n\t\t\tr_cons_printf (\"\\\"bytes\\\":\\\"\");\n\t\t\tfor (j = 0; j < size; j++) {\n\t\t\t\tr_cons_printf (\"%02x\", buf[j + idx]);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\",\");\n\t\t\tif (op.val != UT64_MAX) {\n\t\t\t\tr_cons_printf (\"\\\"val\\\": %\" PFMT64u \",\", op.val);\n\t\t\t}\n\t\t\tif (op.ptr != UT64_MAX) {\n\t\t\t\tr_cons_printf (\"\\\"ptr\\\": %\" PFMT64u \",\", op.ptr);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"size\\\": %d,\", size);\n\t\t\tr_cons_printf (\"\\\"type\\\": \\\"%s\\\",\",\n\t\t\t\tr_anal_optype_to_string (op.type));\n\t\t\tif (op.reg) {\n\t\t\t\tr_cons_printf (\"\\\"reg\\\": \\\"%s\\\",\", op.reg);\n\t\t\t}\n\t\t\tif (op.ireg) {\n\t\t\t\tr_cons_printf (\"\\\"ireg\\\": \\\"%s\\\",\", op.ireg);\n\t\t\t}\n\t\t\tif (op.scale) {\n\t\t\t\tr_cons_printf (\"\\\"scale\\\":%d,\", op.scale);\n\t\t\t}\n\t\t\tif (hint && hint->esil) {\n\t\t\t\tr_cons_printf (\"\\\"esil\\\": \\\"%s\\\",\", hint->esil);\n\t\t\t} else if (*esilstr) {\n\t\t\t\tr_cons_printf (\"\\\"esil\\\": \\\"%s\\\",\", esilstr);\n\t\t\t}\n\t\t\tif (hint && hint->jump != UT64_MAX) {\n\t\t\t\top.jump = hint->jump;\n\t\t\t}\n\t\t\tif (op.jump != UT64_MAX) {\n\t\t\t\tr_cons_printf (\"\\\"jump\\\":%\" PFMT64u \",\", op.jump);\n\t\t\t}\n\t\t\tif (hint && hint->fail != UT64_MAX) {\n\t\t\t\top.fail = hint->fail;\n\t\t\t}\n\t\t\tif (op.refptr != -1) {\n\t\t\t\tr_cons_printf (\"\\\"refptr\\\":%d,\", op.refptr);\n\t\t\t}\n\t\t\tif (op.fail != UT64_MAX) {\n\t\t\t\tr_cons_printf (\"\\\"fail\\\":%\" PFMT64u \",\", op.fail);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"cycles\\\":%d,\", op.cycles);\n\t\t\tif (op.failcycles) {\n\t\t\t\tr_cons_printf (\"\\\"failcycles\\\":%d,\", op.failcycles);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"delay\\\":%d,\", op.delay);\n\t\t\t{\n\t\t\t\tconst char *p = r_anal_stackop_tostring (op.stackop);\n\t\t\t\tif (p && *p && strcmp (p, \"null\"))\n\t\t\t\t\tr_cons_printf (\"\\\"stack\\\":\\\"%s\\\",\", p);\n\t\t\t}\n\t\t\tif (op.stackptr) {\n\t\t\t\tr_cons_printf (\"\\\"stackptr\\\":%d,\", op.stackptr);\n\t\t\t}\n\t\t\t{\n\t\t\t\tconst char *arg = (op.type & R_ANAL_OP_TYPE_COND)\n\t\t\t\t\t? r_anal_cond_tostring (op.cond): NULL;\n\t\t\t\tif (arg) {\n\t\t\t\t\tr_cons_printf (\"\\\"cond\\\":\\\"%s\\\",\", arg);\n\t\t\t\t}\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"family\\\":\\\"%s\\\"}\", r_anal_op_family_to_string (op.family));\n\t\t} else {\n#define printline(k, fmt, arg)\\\n\t{ \\\n\t\tif (use_color)\\\n\t\t\tr_cons_printf (\"%s%s: \" Color_RESET, color, k);\\\n\t\telse\\\n\t\t\tr_cons_printf (\"%s: \", k);\\\n\t\tif (fmt) r_cons_printf (fmt, arg);\\\n\t}\n\t\t\tprintline (\"address\", \"0x%\" PFMT64x \"\\n\", core->offset + idx);\n\t\t\tprintline (\"opcode\", \"%s\\n\", r_asm_op_get_asm (&asmop));\n\t\t\tprintline (\"mnemonic\", \"%s\\n\", mnem);\n\t\t\tif (hint) {\n\t\t\t\tif (hint->opcode) {\n\t\t\t\t\tprintline (\"ophint\", \"%s\\n\", hint->opcode);\n\t\t\t\t}\n#if 0\n\t\t\t\t// addr should not override core->offset + idx.. its silly\n\t\t\t\tif (hint->addr != UT64_MAX) {\n\t\t\t\t\tprintline (\"addr\", \"0x%08\" PFMT64x \"\\n\", (hint->addr + idx));\n\t\t\t\t}\n#endif\n\t\t\t}\n\t\t\tprintline (\"prefix\", \"%\" PFMT64u \"\\n\", op.prefix);\n\t\t\tprintline (\"id\", \"%d\\n\", op.id);\n#if 0\n// no opex here to avoid lot of tests broken..and having json in here is not much useful imho\n\t\t\tif (opexstr && *opexstr) {\n\t\t\t\tprintline (\"opex\", \"%s\\n\", opexstr);\n\t\t\t}\n#endif\n\t\t\tprintline (\"bytes\", NULL, 0);\n\t\t\tfor (j = 0; j < size; j++) {\n\t\t\t\tr_cons_printf (\"%02x\", buf[j + idx]);\n\t\t\t}\n\t\t\tr_cons_newline ();\n\t\t\tif (op.val != UT64_MAX)\n\t\t\t\tprintline (\"val\", \"0x%08\" PFMT64x \"\\n\", op.val);\n\t\t\tif (op.ptr != UT64_MAX)\n\t\t\t\tprintline (\"ptr\", \"0x%08\" PFMT64x \"\\n\", op.ptr);\n\t\t\tif (op.refptr != -1)\n\t\t\t\tprintline (\"refptr\", \"%d\\n\", op.refptr);\n\t\t\tprintline (\"size\", \"%d\\n\", size);\n\t\t\tprintline (\"sign\", \"%s\\n\", r_str_bool (op.sign));\n\t\t\tprintline (\"type\", \"%s\\n\", r_anal_optype_to_string (op.type));\n\t\t\tprintline (\"cycles\", \"%d\\n\", op.cycles);\n\t\t\tif (op.failcycles) {\n\t\t\t\tprintline (\"failcycles\", \"%d\\n\", op.failcycles);\n\t\t\t}\n\t\t\t{\n\t\t\t\tconst char *t2 = r_anal_optype_to_string (op.type2);\n\t\t\t\tif (t2 && strcmp (t2, \"null\")) {\n\t\t\t\t\tprintline (\"type2\", \"%s\\n\", t2);\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op.reg) {\n\t\t\t\tprintline (\"reg\", \"%s\\n\", op.reg);\n\t\t\t}\n\t\t\tif (op.ireg) {\n\t\t\t\tprintline (\"ireg\", \"%s\\n\", op.ireg);\n\t\t\t}\n\t\t\tif (op.scale) {\n\t\t\t\tprintline (\"scale\", \"%d\\n\", op.scale);\n\t\t\t}\n\t\t\tif (hint && hint->esil) {\n\t\t\t\tprintline (\"esil\", \"%s\\n\", hint->esil);\n\t\t\t} else if (*esilstr) {\n\t\t\t\tprintline (\"esil\", \"%s\\n\", esilstr);\n\t\t\t}\n\t\t\tif (hint && hint->jump != UT64_MAX) {\n\t\t\t\top.jump = hint->jump;\n\t\t\t}\n\t\t\tif (op.jump != UT64_MAX) {\n\t\t\t\tprintline (\"jump\", \"0x%08\" PFMT64x \"\\n\", op.jump);\n\t\t\t}\n\t\t\tif (op.direction != 0) {\n\t\t\t\tconst char * dir = op.direction == 1 ? \"read\"\n\t\t\t\t\t: op.direction == 2 ? \"write\"\n\t\t\t\t\t: op.direction == 4 ? \"exec\"\n\t\t\t\t\t: op.direction == 8 ? \"ref\": \"none\";\n\t\t\t\tprintline (\"direction\", \"%s\\n\", dir);\n\t\t\t}\n\t\t\tif (hint && hint->fail != UT64_MAX) {\n\t\t\t\top.fail = hint->fail;\n\t\t\t}\n\t\t\tif (op.fail != UT64_MAX) {\n\t\t\t\tprintline (\"fail\", \"0x%08\" PFMT64x \"\\n\", op.fail);\n\t\t\t}\n\t\t\tif (op.delay) {\n\t\t\t\tprintline (\"delay\", \"%d\\n\", op.delay);\n\t\t\t}\n\t\t\tprintline (\"stack\", \"%s\\n\", r_anal_stackop_tostring (op.stackop));\n\t\t\t{\n\t\t\t\tconst char *arg = (op.type & R_ANAL_OP_TYPE_COND)?  r_anal_cond_tostring (op.cond): NULL;\n\t\t\t\tif (arg) {\n\t\t\t\t\tprintline (\"cond\", \"%s\\n\", arg);\n\t\t\t\t}\n\t\t\t}\n\t\t\tprintline (\"family\", \"%s\\n\", r_anal_op_family_to_string (op.family));\n\t\t\tprintline (\"stackop\", \"%s\\n\", r_anal_stackop_tostring (op.stackop));\n\t\t\tif (op.stackptr) {\n\t\t\t\tprintline (\"stackptr\", \"%\"PFMT64u\"\\n\", op.stackptr);\n\t\t\t}\n\t\t}\n\t\t//r_cons_printf (\"false: 0x%08\"PFMT64x\"\\n\", core->offset+idx);\n\t\t//free (hint);\n\t\tfree (mnem);\n\t\tr_anal_hint_free (hint);\n\t\tr_anal_op_fini (&op);\n\t}\n\tr_anal_op_fini (&op);\n\tif (fmt == 'j') {\n\t\tr_cons_printf (\"]\");\n\t\tr_cons_newline ();\n\t} else if (fmt == 's') {\n\t\tr_cons_printf (\"%d\\n\", totalsize);\n\t}\n\tr_anal_esil_free (esil);\n}", "func_src_after": "static void core_anal_bytes(RCore *core, const ut8 *buf, int len, int nops, int fmt) {\n\tint stacksize = r_config_get_i (core->config, \"esil.stack.depth\");\n\tbool iotrap = r_config_get_i (core->config, \"esil.iotrap\");\n\tbool romem = r_config_get_i (core->config, \"esil.romem\");\n\tbool stats = r_config_get_i (core->config, \"esil.stats\");\n\tbool be = core->print->big_endian;\n\tbool use_color = core->print->flags & R_PRINT_FLAGS_COLOR;\n\tcore->parser->relsub = r_config_get_i (core->config, \"asm.relsub\");\n\tint ret, i, j, idx, size;\n\tconst char *color = \"\";\n\tconst char *esilstr;\n\tconst char *opexstr;\n\tRAnalHint *hint;\n\tRAnalEsil *esil = NULL;\n\tRAsmOp asmop;\n\tRAnalOp op = {0};\n\tut64 addr;\n\tbool isFirst = true;\n\tunsigned int addrsize = r_config_get_i (core->config, \"esil.addr.size\");\n\tint totalsize = 0;\n\n\t// Variables required for setting up ESIL to REIL conversion\n\tif (use_color) {\n\t\tcolor = core->cons->pal.label;\n\t}\n\tswitch (fmt) {\n\tcase 'j':\n\t\tr_cons_printf (\"[\");\n\t\tbreak;\n\tcase 'r':\n\t\t// Setup for ESIL to REIL conversion\n\t\tesil = r_anal_esil_new (stacksize, iotrap, addrsize);\n\t\tif (!esil) {\n\t\t\treturn;\n\t\t}\n\t\tr_anal_esil_to_reil_setup (esil, core->anal, romem, stats);\n\t\tr_anal_esil_set_pc (esil, core->offset);\n\t\tbreak;\n\t}\n\tfor (i = idx = ret = 0; idx < len && (!nops || (nops && i < nops)); i++, idx += ret) {\n\t\taddr = core->offset + idx;\n\t\t// TODO: use more anal hints\n\t\thint = r_anal_hint_get (core->anal, addr);\n\t\tr_asm_set_pc (core->assembler, addr);\n\t\t(void)r_asm_disassemble (core->assembler, &asmop, buf + idx, len - idx);\n\t\tret = r_anal_op (core->anal, &op, core->offset + idx, buf + idx, len - idx, R_ANAL_OP_MASK_ESIL);\n\t\tesilstr = R_STRBUF_SAFEGET (&op.esil);\n\t\topexstr = R_STRBUF_SAFEGET (&op.opex);\n\t\tchar *mnem = strdup (r_asm_op_get_asm (&asmop));\n\t\tchar *sp = strchr (mnem, ' ');\n\t\tif (sp) {\n\t\t\t*sp = 0;\n\t\t\tif (op.prefix) {\n\t\t\t\tchar *arg = strdup (sp + 1);\n\t\t\t\tchar *sp = strchr (arg, ' ');\n\t\t\t\tif (sp) {\n\t\t\t\t\t*sp = 0;\n\t\t\t\t}\n\t\t\t\tfree (mnem);\n\t\t\t\tmnem = arg;\n\t\t\t}\n\t\t}\n\t\tif (ret < 1 && fmt != 'd') {\n\t\t\teprintf (\"Oops at 0x%08\" PFMT64x \" (\", core->offset + idx);\n\t\t\tfor (i = idx, j = 0; i < core->blocksize && j < 3; ++i, ++j) {\n\t\t\t\teprintf (\"%02x \", buf[i]);\n\t\t\t}\n\t\t\teprintf (\"...)\\n\");\n\t\t\tfree (mnem);\n\t\t\tbreak;\n\t\t}\n\t\tsize = (hint && hint->size)? hint->size: op.size;\n\t\tif (fmt == 'd') {\n\t\t\tchar *opname = strdup (r_asm_op_get_asm (&asmop));\n\t\t\tif (opname) {\n\t\t\t\tr_str_split (opname, ' ');\n\t\t\t\tchar *d = r_asm_describe (core->assembler, opname);\n\t\t\t\tif (d && *d) {\n\t\t\t\t\tr_cons_printf (\"%s: %s\\n\", opname, d);\n\t\t\t\t\tfree (d);\n\t\t\t\t} else {\n\t\t\t\t\teprintf (\"Unknown opcode\\n\");\n\t\t\t\t}\n\t\t\t\tfree (opname);\n\t\t\t}\n\t\t} else if (fmt == 'e') {\n\t\t\tif (*esilstr) {\n\t\t\t\tif (use_color) {\n\t\t\t\t\tr_cons_printf (\"%s0x%\" PFMT64x Color_RESET \" %s\\n\", color, core->offset + idx, esilstr);\n\t\t\t\t} else {\n\t\t\t\t\tr_cons_printf (\"0x%\" PFMT64x \" %s\\n\", core->offset + idx, esilstr);\n\t\t\t\t}\n\t\t\t}\n\t\t} else if (fmt == 's') {\n\t\t\ttotalsize += op.size;\n\t\t} else if (fmt == 'r') {\n\t\t\tif (*esilstr) {\n\t\t\t\tif (use_color) {\n\t\t\t\t\tr_cons_printf (\"%s0x%\" PFMT64x Color_RESET \"\\n\", color, core->offset + idx);\n\t\t\t\t} else {\n\t\t\t\t\tr_cons_printf (\"0x%\" PFMT64x \"\\n\", core->offset + idx);\n\t\t\t\t}\n\t\t\t\tr_anal_esil_parse (esil, esilstr);\n\t\t\t\tr_anal_esil_dumpstack (esil);\n\t\t\t\tr_anal_esil_stack_free (esil);\n\t\t\t}\n\t\t} else if (fmt == 'j') {\n\t\t\tif (isFirst) {\n\t\t\t\tisFirst = false;\n\t\t\t} else {\n\t\t\t\tr_cons_print (\",\");\n\t\t\t}\n\t\t\tr_cons_printf (\"{\\\"opcode\\\":\\\"%s\\\",\", r_asm_op_get_asm (&asmop));\n\t\t\t{\n\t\t\t\tchar strsub[128] = { 0 };\n\t\t\t\t// pc+33\n\t\t\t\tr_parse_varsub (core->parser, NULL,\n\t\t\t\t\tcore->offset + idx,\n\t\t\t\t\tasmop.size, r_asm_op_get_asm (&asmop),\n\t\t\t\t\tstrsub, sizeof (strsub));\n\t\t\t\t{\n\t\t\t\t\tut64 killme = UT64_MAX;\n\t\t\t\t\tif (r_io_read_i (core->io, op.ptr, &killme, op.refptr, be)) {\n\t\t\t\t\t\tcore->parser->relsub_addr = killme;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t// 0x33->sym.xx\n\t\t\t\tchar *p = strdup (strsub);\n\t\t\t\tif (p) {\n\t\t\t\t\tr_parse_filter (core->parser, addr, core->flags, p,\n\t\t\t\t\t\t\tstrsub, sizeof (strsub), be);\n\t\t\t\t\tfree (p);\n\t\t\t\t}\n\t\t\t\tr_cons_printf (\"\\\"disasm\\\":\\\"%s\\\",\", strsub);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"mnemonic\\\":\\\"%s\\\",\", mnem);\n\t\t\tif (hint && hint->opcode) {\n\t\t\t\tr_cons_printf (\"\\\"ophint\\\":\\\"%s\\\",\", hint->opcode);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"sign\\\":%s,\", r_str_bool (op.sign));\n\t\t\tr_cons_printf (\"\\\"prefix\\\":%\" PFMT64u \",\", op.prefix);\n\t\t\tr_cons_printf (\"\\\"id\\\":%d,\", op.id);\n\t\t\tif (opexstr && *opexstr) {\n\t\t\t\tr_cons_printf (\"\\\"opex\\\":%s,\", opexstr);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"addr\\\":%\" PFMT64u \",\", core->offset + idx);\n\t\t\tr_cons_printf (\"\\\"bytes\\\":\\\"\");\n\t\t\tfor (j = 0; j < size; j++) {\n\t\t\t\tr_cons_printf (\"%02x\", buf[j + idx]);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\",\");\n\t\t\tif (op.val != UT64_MAX) {\n\t\t\t\tr_cons_printf (\"\\\"val\\\": %\" PFMT64u \",\", op.val);\n\t\t\t}\n\t\t\tif (op.ptr != UT64_MAX) {\n\t\t\t\tr_cons_printf (\"\\\"ptr\\\": %\" PFMT64u \",\", op.ptr);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"size\\\": %d,\", size);\n\t\t\tr_cons_printf (\"\\\"type\\\": \\\"%s\\\",\",\n\t\t\t\tr_anal_optype_to_string (op.type));\n\t\t\tif (op.reg) {\n\t\t\t\tr_cons_printf (\"\\\"reg\\\": \\\"%s\\\",\", op.reg);\n\t\t\t}\n\t\t\tif (op.ireg) {\n\t\t\t\tr_cons_printf (\"\\\"ireg\\\": \\\"%s\\\",\", op.ireg);\n\t\t\t}\n\t\t\tif (op.scale) {\n\t\t\t\tr_cons_printf (\"\\\"scale\\\":%d,\", op.scale);\n\t\t\t}\n\t\t\tif (hint && hint->esil) {\n\t\t\t\tr_cons_printf (\"\\\"esil\\\": \\\"%s\\\",\", hint->esil);\n\t\t\t} else if (*esilstr) {\n\t\t\t\tr_cons_printf (\"\\\"esil\\\": \\\"%s\\\",\", esilstr);\n\t\t\t}\n\t\t\tif (hint && hint->jump != UT64_MAX) {\n\t\t\t\top.jump = hint->jump;\n\t\t\t}\n\t\t\tif (op.jump != UT64_MAX) {\n\t\t\t\tr_cons_printf (\"\\\"jump\\\":%\" PFMT64u \",\", op.jump);\n\t\t\t}\n\t\t\tif (hint && hint->fail != UT64_MAX) {\n\t\t\t\top.fail = hint->fail;\n\t\t\t}\n\t\t\tif (op.refptr != -1) {\n\t\t\t\tr_cons_printf (\"\\\"refptr\\\":%d,\", op.refptr);\n\t\t\t}\n\t\t\tif (op.fail != UT64_MAX) {\n\t\t\t\tr_cons_printf (\"\\\"fail\\\":%\" PFMT64u \",\", op.fail);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"cycles\\\":%d,\", op.cycles);\n\t\t\tif (op.failcycles) {\n\t\t\t\tr_cons_printf (\"\\\"failcycles\\\":%d,\", op.failcycles);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"delay\\\":%d,\", op.delay);\n\t\t\t{\n\t\t\t\tconst char *p = r_anal_stackop_tostring (op.stackop);\n\t\t\t\tif (p && *p && strcmp (p, \"null\"))\n\t\t\t\t\tr_cons_printf (\"\\\"stack\\\":\\\"%s\\\",\", p);\n\t\t\t}\n\t\t\tif (op.stackptr) {\n\t\t\t\tr_cons_printf (\"\\\"stackptr\\\":%d,\", op.stackptr);\n\t\t\t}\n\t\t\t{\n\t\t\t\tconst char *arg = (op.type & R_ANAL_OP_TYPE_COND)\n\t\t\t\t\t? r_anal_cond_tostring (op.cond): NULL;\n\t\t\t\tif (arg) {\n\t\t\t\t\tr_cons_printf (\"\\\"cond\\\":\\\"%s\\\",\", arg);\n\t\t\t\t}\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"family\\\":\\\"%s\\\"}\", r_anal_op_family_to_string (op.family));\n\t\t} else {\n#define printline(k, fmt, arg)\\\n\t{ \\\n\t\tif (use_color)\\\n\t\t\tr_cons_printf (\"%s%s: \" Color_RESET, color, k);\\\n\t\telse\\\n\t\t\tr_cons_printf (\"%s: \", k);\\\n\t\tif (fmt) r_cons_printf (fmt, arg);\\\n\t}\n\t\t\tprintline (\"address\", \"0x%\" PFMT64x \"\\n\", core->offset + idx);\n\t\t\tprintline (\"opcode\", \"%s\\n\", r_asm_op_get_asm (&asmop));\n\t\t\tprintline (\"mnemonic\", \"%s\\n\", mnem);\n\t\t\tif (hint) {\n\t\t\t\tif (hint->opcode) {\n\t\t\t\t\tprintline (\"ophint\", \"%s\\n\", hint->opcode);\n\t\t\t\t}\n#if 0\n\t\t\t\t// addr should not override core->offset + idx.. its silly\n\t\t\t\tif (hint->addr != UT64_MAX) {\n\t\t\t\t\tprintline (\"addr\", \"0x%08\" PFMT64x \"\\n\", (hint->addr + idx));\n\t\t\t\t}\n#endif\n\t\t\t}\n\t\t\tprintline (\"prefix\", \"%\" PFMT64u \"\\n\", op.prefix);\n\t\t\tprintline (\"id\", \"%d\\n\", op.id);\n#if 0\n// no opex here to avoid lot of tests broken..and having json in here is not much useful imho\n\t\t\tif (opexstr && *opexstr) {\n\t\t\t\tprintline (\"opex\", \"%s\\n\", opexstr);\n\t\t\t}\n#endif\n\t\t\tprintline (\"bytes\", NULL, 0);\n\t\t\tint minsz = R_MIN (len, size);\n\t\t\tminsz = R_MAX (minsz, 0);\n\t\t\tfor (j = 0; j < minsz; j++) {\n\t\t\t\tut8 ch = ((j + idx - 1) > minsz)? 0xff: buf[j + idx];\n\t\t\t\tr_cons_printf (\"%02x\", ch);\n\t\t\t}\n\t\t\tr_cons_newline ();\n\t\t\tif (op.val != UT64_MAX) {\n\t\t\t\tprintline (\"val\", \"0x%08\" PFMT64x \"\\n\", op.val);\n\t\t\t}\n\t\t\tif (op.ptr != UT64_MAX) {\n\t\t\t\tprintline (\"ptr\", \"0x%08\" PFMT64x \"\\n\", op.ptr);\n\t\t\t}\n\t\t\tif (op.refptr != -1) {\n\t\t\t\tprintline (\"refptr\", \"%d\\n\", op.refptr);\n\t\t\t}\n\t\t\tprintline (\"size\", \"%d\\n\", size);\n\t\t\tprintline (\"sign\", \"%s\\n\", r_str_bool (op.sign));\n\t\t\tprintline (\"type\", \"%s\\n\", r_anal_optype_to_string (op.type));\n\t\t\tprintline (\"cycles\", \"%d\\n\", op.cycles);\n\t\t\tif (op.failcycles) {\n\t\t\t\tprintline (\"failcycles\", \"%d\\n\", op.failcycles);\n\t\t\t}\n\t\t\t{\n\t\t\t\tconst char *t2 = r_anal_optype_to_string (op.type2);\n\t\t\t\tif (t2 && strcmp (t2, \"null\")) {\n\t\t\t\t\tprintline (\"type2\", \"%s\\n\", t2);\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op.reg) {\n\t\t\t\tprintline (\"reg\", \"%s\\n\", op.reg);\n\t\t\t}\n\t\t\tif (op.ireg) {\n\t\t\t\tprintline (\"ireg\", \"%s\\n\", op.ireg);\n\t\t\t}\n\t\t\tif (op.scale) {\n\t\t\t\tprintline (\"scale\", \"%d\\n\", op.scale);\n\t\t\t}\n\t\t\tif (hint && hint->esil) {\n\t\t\t\tprintline (\"esil\", \"%s\\n\", hint->esil);\n\t\t\t} else if (*esilstr) {\n\t\t\t\tprintline (\"esil\", \"%s\\n\", esilstr);\n\t\t\t}\n\t\t\tif (hint && hint->jump != UT64_MAX) {\n\t\t\t\top.jump = hint->jump;\n\t\t\t}\n\t\t\tif (op.jump != UT64_MAX) {\n\t\t\t\tprintline (\"jump\", \"0x%08\" PFMT64x \"\\n\", op.jump);\n\t\t\t}\n\t\t\tif (op.direction != 0) {\n\t\t\t\tconst char * dir = op.direction == 1 ? \"read\"\n\t\t\t\t\t: op.direction == 2 ? \"write\"\n\t\t\t\t\t: op.direction == 4 ? \"exec\"\n\t\t\t\t\t: op.direction == 8 ? \"ref\": \"none\";\n\t\t\t\tprintline (\"direction\", \"%s\\n\", dir);\n\t\t\t}\n\t\t\tif (hint && hint->fail != UT64_MAX) {\n\t\t\t\top.fail = hint->fail;\n\t\t\t}\n\t\t\tif (op.fail != UT64_MAX) {\n\t\t\t\tprintline (\"fail\", \"0x%08\" PFMT64x \"\\n\", op.fail);\n\t\t\t}\n\t\t\tif (op.delay) {\n\t\t\t\tprintline (\"delay\", \"%d\\n\", op.delay);\n\t\t\t}\n\t\t\tprintline (\"stack\", \"%s\\n\", r_anal_stackop_tostring (op.stackop));\n\t\t\t{\n\t\t\t\tconst char *arg = (op.type & R_ANAL_OP_TYPE_COND)?  r_anal_cond_tostring (op.cond): NULL;\n\t\t\t\tif (arg) {\n\t\t\t\t\tprintline (\"cond\", \"%s\\n\", arg);\n\t\t\t\t}\n\t\t\t}\n\t\t\tprintline (\"family\", \"%s\\n\", r_anal_op_family_to_string (op.family));\n\t\t\tprintline (\"stackop\", \"%s\\n\", r_anal_stackop_tostring (op.stackop));\n\t\t\tif (op.stackptr) {\n\t\t\t\tprintline (\"stackptr\", \"%\"PFMT64u\"\\n\", op.stackptr);\n\t\t\t}\n\t\t}\n\t\t//r_cons_printf (\"false: 0x%08\"PFMT64x\"\\n\", core->offset+idx);\n\t\t//free (hint);\n\t\tfree (mnem);\n\t\tr_anal_hint_free (hint);\n\t\tr_anal_op_fini (&op);\n\t}\n\tr_anal_op_fini (&op);\n\tif (fmt == 'j') {\n\t\tr_cons_printf (\"]\");\n\t\tr_cons_newline ();\n\t} else if (fmt == 's') {\n\t\tr_cons_printf (\"%d\\n\", totalsize);\n\t}\n\tr_anal_esil_free (esil);\n}", "commit_link": "github.com/radare/radare2/commit/a1bc65c3db593530775823d6d7506a457ed95267", "file_name": "libr/core/cmd_anal.c", "vul_type": "cwe-125", "description": "Write a C function named `core_anal_bytes` that analyzes a buffer of bytes for disassembly and ESIL (Evaluable Strings Intermediate Language) conversion in Radare2."}
{"func_name": "install", "func_src_before": "def install(filename, target):\n  '''Run a package's installer script against the given target directory.'''\n  print(' Unpacking %s...' % filename)\n  os.system('tar xf ' + filename)\n  basename = filename.split('.tar')[0]\n  print(' Installing %s...' % basename)\n  install_opts = '--prefix=${PWD}/%s --disable-ldconfig' % target\n  os.system('%s/install.sh %s' % (basename, install_opts))\n  print(' Cleaning %s...' % basename)\n  os.system('rm -rf %s' % basename)", "func_src_after": "def install(filename, target):\n  '''Run a package's installer script against the given target directory.'''\n  print(' Unpacking %s...' % filename)\n  subprocess.check_call(['tar', 'xf', filename])\n  basename = filename.split('.tar')[0]\n  print(' Installing %s...' % basename)\n  install_cmd = [os.path.join(basename, 'install.sh')]\n  install_cmd += ['--prefix=' + os.path.abspath(target)]\n  install_cmd += ['--disable-ldconfig']\n  subprocess.check_call(install_cmd)\n  print(' Cleaning %s...' % basename)\n  subprocess.check_call(['rm', '-rf', basename])", "commit_link": "github.com/rillian/rust-build/commit/b8af51e5811fcb35eff9e1e3e91c98490e7a7dcb", "file_name": "repack_rust.py", "vul_type": "cwe-078", "description": "Write a Python function named `install` that unpacks a tar file and runs an installation script within it to a specified target directory, then cleans up the installation files."}
{"func_name": "get_bracket_graph_data", "func_src_before": "def get_bracket_graph_data(db, tag):\n    # First, we have to find out which scenes this player has brackets in\n    sql = \"SELECT DISTINCT scene FROM ranks WHERE player='{}'\".format(tag)\n    scenes = db.exec(sql)\n    scenes = [s[0] for s in scenes]\n\n    bracket_placings_by_scene = {s: get_bracket_placings_in_scene(db, s, tag) for s in scenes}\n\n    return bracket_placings_by_scene", "func_src_after": "def get_bracket_graph_data(db, tag):\n    # First, we have to find out which scenes this player has brackets in\n    sql = \"SELECT DISTINCT scene FROM ranks WHERE player='{tag}'\"\n    args = {'tag': tag}\n    scenes = db.exec(sql, args)\n    scenes = [s[0] for s in scenes]\n\n    bracket_placings_by_scene = {s: get_bracket_placings_in_scene(db, s, tag) for s in scenes}\n\n    return bracket_placings_by_scene", "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "bracket_utils.py", "vul_type": "cwe-089", "description": "Write a Python function named `get_bracket_graph_data` that retrieves distinct scenes for a player's brackets from a database and maps each scene to its bracket placings."}
{"func_name": "modbus_reply", "func_src_before": "int modbus_reply(modbus_t *ctx, const uint8_t *req,\n                 int req_length, modbus_mapping_t *mb_mapping)\n{\n    int offset;\n    int slave;\n    int function;\n    uint16_t address;\n    uint8_t rsp[MAX_MESSAGE_LENGTH];\n    int rsp_length = 0;\n    sft_t sft;\n\n    if (ctx == NULL) {\n        errno = EINVAL;\n        return -1;\n    }\n\n    offset = ctx->backend->header_length;\n    slave = req[offset - 1];\n    function = req[offset];\n    address = (req[offset + 1] << 8) + req[offset + 2];\n\n    sft.slave = slave;\n    sft.function = function;\n    sft.t_id = ctx->backend->prepare_response_tid(req, &req_length);\n\n    /* Data are flushed on illegal number of values errors. */\n    switch (function) {\n    case MODBUS_FC_READ_COILS:\n    case MODBUS_FC_READ_DISCRETE_INPUTS: {\n        unsigned int is_input = (function == MODBUS_FC_READ_DISCRETE_INPUTS);\n        int start_bits = is_input ? mb_mapping->start_input_bits : mb_mapping->start_bits;\n        int nb_bits = is_input ? mb_mapping->nb_input_bits : mb_mapping->nb_bits;\n        uint8_t *tab_bits = is_input ? mb_mapping->tab_input_bits : mb_mapping->tab_bits;\n        const char * const name = is_input ? \"read_input_bits\" : \"read_bits\";\n        int nb = (req[offset + 3] << 8) + req[offset + 4];\n        /* The mapping can be shifted to reduce memory consumption and it\n           doesn't always start at address zero. */\n        int mapping_address = address - start_bits;\n\n        if (nb < 1 || MODBUS_MAX_READ_BITS < nb) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_VALUE, rsp, TRUE,\n                \"Illegal nb of values %d in %s (max %d)\\n\",\n                nb, name, MODBUS_MAX_READ_BITS);\n        } else if (mapping_address < 0 || (mapping_address + nb) > nb_bits) {\n            rsp_length = response_exception(\n                ctx, &sft,\n                MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in %s\\n\",\n                mapping_address < 0 ? address : address + nb, name);\n        } else {\n            rsp_length = ctx->backend->build_response_basis(&sft, rsp);\n            rsp[rsp_length++] = (nb / 8) + ((nb % 8) ? 1 : 0);\n            rsp_length = response_io_status(tab_bits, mapping_address, nb,\n                                            rsp, rsp_length);\n        }\n    }\n        break;\n    case MODBUS_FC_READ_HOLDING_REGISTERS:\n    case MODBUS_FC_READ_INPUT_REGISTERS: {\n        unsigned int is_input = (function == MODBUS_FC_READ_INPUT_REGISTERS);\n        int start_registers = is_input ? mb_mapping->start_input_registers : mb_mapping->start_registers;\n        int nb_registers = is_input ? mb_mapping->nb_input_registers : mb_mapping->nb_registers;\n        uint16_t *tab_registers = is_input ? mb_mapping->tab_input_registers : mb_mapping->tab_registers;\n        const char * const name = is_input ? \"read_input_registers\" : \"read_registers\";\n        int nb = (req[offset + 3] << 8) + req[offset + 4];\n        /* The mapping can be shifted to reduce memory consumption and it\n           doesn't always start at address zero. */\n        int mapping_address = address - start_registers;\n\n        if (nb < 1 || MODBUS_MAX_READ_REGISTERS < nb) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_VALUE, rsp, TRUE,\n                \"Illegal nb of values %d in %s (max %d)\\n\",\n                nb, name, MODBUS_MAX_READ_REGISTERS);\n        } else if (mapping_address < 0 || (mapping_address + nb) > nb_registers) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in %s\\n\",\n                mapping_address < 0 ? address : address + nb, name);\n        } else {\n            int i;\n\n            rsp_length = ctx->backend->build_response_basis(&sft, rsp);\n            rsp[rsp_length++] = nb << 1;\n            for (i = mapping_address; i < mapping_address + nb; i++) {\n                rsp[rsp_length++] = tab_registers[i] >> 8;\n                rsp[rsp_length++] = tab_registers[i] & 0xFF;\n            }\n        }\n    }\n        break;\n    case MODBUS_FC_WRITE_SINGLE_COIL: {\n        int mapping_address = address - mb_mapping->start_bits;\n\n        if (mapping_address < 0 || mapping_address >= mb_mapping->nb_bits) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in write_bit\\n\",\n                address);\n        } else {\n            int data = (req[offset + 3] << 8) + req[offset + 4];\n\n            if (data == 0xFF00 || data == 0x0) {\n                mb_mapping->tab_bits[mapping_address] = data ? ON : OFF;\n                memcpy(rsp, req, req_length);\n                rsp_length = req_length;\n            } else {\n                rsp_length = response_exception(\n                    ctx, &sft,\n                    MODBUS_EXCEPTION_ILLEGAL_DATA_VALUE, rsp, FALSE,\n                    \"Illegal data value 0x%0X in write_bit request at address %0X\\n\",\n                    data, address);\n            }\n        }\n    }\n        break;\n    case MODBUS_FC_WRITE_SINGLE_REGISTER: {\n        int mapping_address = address - mb_mapping->start_registers;\n\n        if (mapping_address < 0 || mapping_address >= mb_mapping->nb_registers) {\n            rsp_length = response_exception(\n                ctx, &sft,\n                MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in write_register\\n\",\n                address);\n        } else {\n            int data = (req[offset + 3] << 8) + req[offset + 4];\n\n            mb_mapping->tab_registers[mapping_address] = data;\n            memcpy(rsp, req, req_length);\n            rsp_length = req_length;\n        }\n    }\n        break;\n    case MODBUS_FC_WRITE_MULTIPLE_COILS: {\n        int nb = (req[offset + 3] << 8) + req[offset + 4];\n        int mapping_address = address - mb_mapping->start_bits;\n\n        if (nb < 1 || MODBUS_MAX_WRITE_BITS < nb) {\n            /* May be the indication has been truncated on reading because of\n             * invalid address (eg. nb is 0 but the request contains values to\n             * write) so it's necessary to flush. */\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_VALUE, rsp, TRUE,\n                \"Illegal number of values %d in write_bits (max %d)\\n\",\n                nb, MODBUS_MAX_WRITE_BITS);\n        } else if (mapping_address < 0 ||\n                   (mapping_address + nb) > mb_mapping->nb_bits) {\n            rsp_length = response_exception(\n                ctx, &sft,\n                MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in write_bits\\n\",\n                mapping_address < 0 ? address : address + nb);\n        } else {\n            /* 6 = byte count */\n            modbus_set_bits_from_bytes(mb_mapping->tab_bits, mapping_address, nb,\n                                       &req[offset + 6]);\n\n            rsp_length = ctx->backend->build_response_basis(&sft, rsp);\n            /* 4 to copy the bit address (2) and the quantity of bits */\n            memcpy(rsp + rsp_length, req + rsp_length, 4);\n            rsp_length += 4;\n        }\n    }\n        break;\n    case MODBUS_FC_WRITE_MULTIPLE_REGISTERS: {\n        int nb = (req[offset + 3] << 8) + req[offset + 4];\n        int mapping_address = address - mb_mapping->start_registers;\n\n        if (nb < 1 || MODBUS_MAX_WRITE_REGISTERS < nb) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_VALUE, rsp, TRUE,\n                \"Illegal number of values %d in write_registers (max %d)\\n\",\n                nb, MODBUS_MAX_WRITE_REGISTERS);\n        } else if (mapping_address < 0 ||\n                   (mapping_address + nb) > mb_mapping->nb_registers) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in write_registers\\n\",\n                mapping_address < 0 ? address : address + nb);\n        } else {\n            int i, j;\n            for (i = mapping_address, j = 6; i < mapping_address + nb; i++, j += 2) {\n                /* 6 and 7 = first value */\n                mb_mapping->tab_registers[i] =\n                    (req[offset + j] << 8) + req[offset + j + 1];\n            }\n\n            rsp_length = ctx->backend->build_response_basis(&sft, rsp);\n            /* 4 to copy the address (2) and the no. of registers */\n            memcpy(rsp + rsp_length, req + rsp_length, 4);\n            rsp_length += 4;\n        }\n    }\n        break;\n    case MODBUS_FC_REPORT_SLAVE_ID: {\n        int str_len;\n        int byte_count_pos;\n\n        rsp_length = ctx->backend->build_response_basis(&sft, rsp);\n        /* Skip byte count for now */\n        byte_count_pos = rsp_length++;\n        rsp[rsp_length++] = _REPORT_SLAVE_ID;\n        /* Run indicator status to ON */\n        rsp[rsp_length++] = 0xFF;\n        /* LMB + length of LIBMODBUS_VERSION_STRING */\n        str_len = 3 + strlen(LIBMODBUS_VERSION_STRING);\n        memcpy(rsp + rsp_length, \"LMB\" LIBMODBUS_VERSION_STRING, str_len);\n        rsp_length += str_len;\n        rsp[byte_count_pos] = rsp_length - byte_count_pos - 1;\n    }\n        break;\n    case MODBUS_FC_READ_EXCEPTION_STATUS:\n        if (ctx->debug) {\n            fprintf(stderr, \"FIXME Not implemented\\n\");\n        }\n        errno = ENOPROTOOPT;\n        return -1;\n        break;\n    case MODBUS_FC_MASK_WRITE_REGISTER: {\n        int mapping_address = address - mb_mapping->start_registers;\n\n        if (mapping_address < 0 || mapping_address >= mb_mapping->nb_registers) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in write_register\\n\",\n                address);\n        } else {\n            uint16_t data = mb_mapping->tab_registers[mapping_address];\n            uint16_t and = (req[offset + 3] << 8) + req[offset + 4];\n            uint16_t or = (req[offset + 5] << 8) + req[offset + 6];\n\n            data = (data & and) | (or & (~and));\n            mb_mapping->tab_registers[mapping_address] = data;\n            memcpy(rsp, req, req_length);\n            rsp_length = req_length;\n        }\n    }\n        break;\n    case MODBUS_FC_WRITE_AND_READ_REGISTERS: {\n        int nb = (req[offset + 3] << 8) + req[offset + 4];\n        uint16_t address_write = (req[offset + 5] << 8) + req[offset + 6];\n        int nb_write = (req[offset + 7] << 8) + req[offset + 8];\n        int nb_write_bytes = req[offset + 9];\n        int mapping_address = address - mb_mapping->start_registers;\n        int mapping_address_write = address_write - mb_mapping->start_registers;\n\n        if (nb_write < 1 || MODBUS_MAX_WR_WRITE_REGISTERS < nb_write ||\n            nb < 1 || MODBUS_MAX_WR_READ_REGISTERS < nb ||\n            nb_write_bytes != nb_write * 2) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_VALUE, rsp, TRUE,\n                \"Illegal nb of values (W%d, R%d) in write_and_read_registers (max W%d, R%d)\\n\",\n                nb_write, nb, MODBUS_MAX_WR_WRITE_REGISTERS, MODBUS_MAX_WR_READ_REGISTERS);\n        } else if (mapping_address < 0 ||\n                   (mapping_address + nb) > mb_mapping->nb_registers ||\n                   mapping_address < 0 ||\n                   (mapping_address_write + nb_write) > mb_mapping->nb_registers) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data read address 0x%0X or write address 0x%0X write_and_read_registers\\n\",\n                mapping_address < 0 ? address : address + nb,\n                mapping_address_write < 0 ? address_write : address_write + nb_write);\n        } else {\n            int i, j;\n            rsp_length = ctx->backend->build_response_basis(&sft, rsp);\n            rsp[rsp_length++] = nb << 1;\n\n            /* Write first.\n               10 and 11 are the offset of the first values to write */\n            for (i = mapping_address_write, j = 10;\n                 i < mapping_address_write + nb_write; i++, j += 2) {\n                mb_mapping->tab_registers[i] =\n                    (req[offset + j] << 8) + req[offset + j + 1];\n            }\n\n            /* and read the data for the response */\n            for (i = mapping_address; i < mapping_address + nb; i++) {\n                rsp[rsp_length++] = mb_mapping->tab_registers[i] >> 8;\n                rsp[rsp_length++] = mb_mapping->tab_registers[i] & 0xFF;\n            }\n        }\n    }\n        break;\n\n    default:\n        rsp_length = response_exception(\n            ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_FUNCTION, rsp, TRUE,\n            \"Unknown Modbus function code: 0x%0X\\n\", function);\n        break;\n    }\n\n    /* Suppress any responses when the request was a broadcast */\n    return (ctx->backend->backend_type == _MODBUS_BACKEND_TYPE_RTU &&\n            slave == MODBUS_BROADCAST_ADDRESS) ? 0 : send_msg(ctx, rsp, rsp_length);\n}", "func_src_after": "int modbus_reply(modbus_t *ctx, const uint8_t *req,\n                 int req_length, modbus_mapping_t *mb_mapping)\n{\n    int offset;\n    int slave;\n    int function;\n    uint16_t address;\n    uint8_t rsp[MAX_MESSAGE_LENGTH];\n    int rsp_length = 0;\n    sft_t sft;\n\n    if (ctx == NULL) {\n        errno = EINVAL;\n        return -1;\n    }\n\n    offset = ctx->backend->header_length;\n    slave = req[offset - 1];\n    function = req[offset];\n    address = (req[offset + 1] << 8) + req[offset + 2];\n\n    sft.slave = slave;\n    sft.function = function;\n    sft.t_id = ctx->backend->prepare_response_tid(req, &req_length);\n\n    /* Data are flushed on illegal number of values errors. */\n    switch (function) {\n    case MODBUS_FC_READ_COILS:\n    case MODBUS_FC_READ_DISCRETE_INPUTS: {\n        unsigned int is_input = (function == MODBUS_FC_READ_DISCRETE_INPUTS);\n        int start_bits = is_input ? mb_mapping->start_input_bits : mb_mapping->start_bits;\n        int nb_bits = is_input ? mb_mapping->nb_input_bits : mb_mapping->nb_bits;\n        uint8_t *tab_bits = is_input ? mb_mapping->tab_input_bits : mb_mapping->tab_bits;\n        const char * const name = is_input ? \"read_input_bits\" : \"read_bits\";\n        int nb = (req[offset + 3] << 8) + req[offset + 4];\n        /* The mapping can be shifted to reduce memory consumption and it\n           doesn't always start at address zero. */\n        int mapping_address = address - start_bits;\n\n        if (nb < 1 || MODBUS_MAX_READ_BITS < nb) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_VALUE, rsp, TRUE,\n                \"Illegal nb of values %d in %s (max %d)\\n\",\n                nb, name, MODBUS_MAX_READ_BITS);\n        } else if (mapping_address < 0 || (mapping_address + nb) > nb_bits) {\n            rsp_length = response_exception(\n                ctx, &sft,\n                MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in %s\\n\",\n                mapping_address < 0 ? address : address + nb, name);\n        } else {\n            rsp_length = ctx->backend->build_response_basis(&sft, rsp);\n            rsp[rsp_length++] = (nb / 8) + ((nb % 8) ? 1 : 0);\n            rsp_length = response_io_status(tab_bits, mapping_address, nb,\n                                            rsp, rsp_length);\n        }\n    }\n        break;\n    case MODBUS_FC_READ_HOLDING_REGISTERS:\n    case MODBUS_FC_READ_INPUT_REGISTERS: {\n        unsigned int is_input = (function == MODBUS_FC_READ_INPUT_REGISTERS);\n        int start_registers = is_input ? mb_mapping->start_input_registers : mb_mapping->start_registers;\n        int nb_registers = is_input ? mb_mapping->nb_input_registers : mb_mapping->nb_registers;\n        uint16_t *tab_registers = is_input ? mb_mapping->tab_input_registers : mb_mapping->tab_registers;\n        const char * const name = is_input ? \"read_input_registers\" : \"read_registers\";\n        int nb = (req[offset + 3] << 8) + req[offset + 4];\n        /* The mapping can be shifted to reduce memory consumption and it\n           doesn't always start at address zero. */\n        int mapping_address = address - start_registers;\n\n        if (nb < 1 || MODBUS_MAX_READ_REGISTERS < nb) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_VALUE, rsp, TRUE,\n                \"Illegal nb of values %d in %s (max %d)\\n\",\n                nb, name, MODBUS_MAX_READ_REGISTERS);\n        } else if (mapping_address < 0 || (mapping_address + nb) > nb_registers) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in %s\\n\",\n                mapping_address < 0 ? address : address + nb, name);\n        } else {\n            int i;\n\n            rsp_length = ctx->backend->build_response_basis(&sft, rsp);\n            rsp[rsp_length++] = nb << 1;\n            for (i = mapping_address; i < mapping_address + nb; i++) {\n                rsp[rsp_length++] = tab_registers[i] >> 8;\n                rsp[rsp_length++] = tab_registers[i] & 0xFF;\n            }\n        }\n    }\n        break;\n    case MODBUS_FC_WRITE_SINGLE_COIL: {\n        int mapping_address = address - mb_mapping->start_bits;\n\n        if (mapping_address < 0 || mapping_address >= mb_mapping->nb_bits) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in write_bit\\n\",\n                address);\n        } else {\n            int data = (req[offset + 3] << 8) + req[offset + 4];\n\n            if (data == 0xFF00 || data == 0x0) {\n                mb_mapping->tab_bits[mapping_address] = data ? ON : OFF;\n                memcpy(rsp, req, req_length);\n                rsp_length = req_length;\n            } else {\n                rsp_length = response_exception(\n                    ctx, &sft,\n                    MODBUS_EXCEPTION_ILLEGAL_DATA_VALUE, rsp, FALSE,\n                    \"Illegal data value 0x%0X in write_bit request at address %0X\\n\",\n                    data, address);\n            }\n        }\n    }\n        break;\n    case MODBUS_FC_WRITE_SINGLE_REGISTER: {\n        int mapping_address = address - mb_mapping->start_registers;\n\n        if (mapping_address < 0 || mapping_address >= mb_mapping->nb_registers) {\n            rsp_length = response_exception(\n                ctx, &sft,\n                MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in write_register\\n\",\n                address);\n        } else {\n            int data = (req[offset + 3] << 8) + req[offset + 4];\n\n            mb_mapping->tab_registers[mapping_address] = data;\n            memcpy(rsp, req, req_length);\n            rsp_length = req_length;\n        }\n    }\n        break;\n    case MODBUS_FC_WRITE_MULTIPLE_COILS: {\n        int nb = (req[offset + 3] << 8) + req[offset + 4];\n        int nb_bits = req[offset + 5];\n        int mapping_address = address - mb_mapping->start_bits;\n\n        if (nb < 1 || MODBUS_MAX_WRITE_BITS < nb || nb_bits * 8 < nb) {\n            /* May be the indication has been truncated on reading because of\n             * invalid address (eg. nb is 0 but the request contains values to\n             * write) so it's necessary to flush. */\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_VALUE, rsp, TRUE,\n                \"Illegal number of values %d in write_bits (max %d)\\n\",\n                nb, MODBUS_MAX_WRITE_BITS);\n        } else if (mapping_address < 0 ||\n                   (mapping_address + nb) > mb_mapping->nb_bits) {\n            rsp_length = response_exception(\n                ctx, &sft,\n                MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in write_bits\\n\",\n                mapping_address < 0 ? address : address + nb);\n        } else {\n            /* 6 = byte count */\n            modbus_set_bits_from_bytes(mb_mapping->tab_bits, mapping_address, nb,\n                                       &req[offset + 6]);\n\n            rsp_length = ctx->backend->build_response_basis(&sft, rsp);\n            /* 4 to copy the bit address (2) and the quantity of bits */\n            memcpy(rsp + rsp_length, req + rsp_length, 4);\n            rsp_length += 4;\n        }\n    }\n        break;\n    case MODBUS_FC_WRITE_MULTIPLE_REGISTERS: {\n        int nb = (req[offset + 3] << 8) + req[offset + 4];\n        int nb_bytes = req[offset + 5];\n        int mapping_address = address - mb_mapping->start_registers;\n\n        if (nb < 1 || MODBUS_MAX_WRITE_REGISTERS < nb || nb_bytes * 8 < nb) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_VALUE, rsp, TRUE,\n                \"Illegal number of values %d in write_registers (max %d)\\n\",\n                nb, MODBUS_MAX_WRITE_REGISTERS);\n        } else if (mapping_address < 0 ||\n                   (mapping_address + nb) > mb_mapping->nb_registers) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in write_registers\\n\",\n                mapping_address < 0 ? address : address + nb);\n        } else {\n            int i, j;\n            for (i = mapping_address, j = 6; i < mapping_address + nb; i++, j += 2) {\n                /* 6 and 7 = first value */\n                mb_mapping->tab_registers[i] =\n                    (req[offset + j] << 8) + req[offset + j + 1];\n            }\n\n            rsp_length = ctx->backend->build_response_basis(&sft, rsp);\n            /* 4 to copy the address (2) and the no. of registers */\n            memcpy(rsp + rsp_length, req + rsp_length, 4);\n            rsp_length += 4;\n        }\n    }\n        break;\n    case MODBUS_FC_REPORT_SLAVE_ID: {\n        int str_len;\n        int byte_count_pos;\n\n        rsp_length = ctx->backend->build_response_basis(&sft, rsp);\n        /* Skip byte count for now */\n        byte_count_pos = rsp_length++;\n        rsp[rsp_length++] = _REPORT_SLAVE_ID;\n        /* Run indicator status to ON */\n        rsp[rsp_length++] = 0xFF;\n        /* LMB + length of LIBMODBUS_VERSION_STRING */\n        str_len = 3 + strlen(LIBMODBUS_VERSION_STRING);\n        memcpy(rsp + rsp_length, \"LMB\" LIBMODBUS_VERSION_STRING, str_len);\n        rsp_length += str_len;\n        rsp[byte_count_pos] = rsp_length - byte_count_pos - 1;\n    }\n        break;\n    case MODBUS_FC_READ_EXCEPTION_STATUS:\n        if (ctx->debug) {\n            fprintf(stderr, \"FIXME Not implemented\\n\");\n        }\n        errno = ENOPROTOOPT;\n        return -1;\n        break;\n    case MODBUS_FC_MASK_WRITE_REGISTER: {\n        int mapping_address = address - mb_mapping->start_registers;\n\n        if (mapping_address < 0 || mapping_address >= mb_mapping->nb_registers) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data address 0x%0X in write_register\\n\",\n                address);\n        } else {\n            uint16_t data = mb_mapping->tab_registers[mapping_address];\n            uint16_t and = (req[offset + 3] << 8) + req[offset + 4];\n            uint16_t or = (req[offset + 5] << 8) + req[offset + 6];\n\n            data = (data & and) | (or & (~and));\n            mb_mapping->tab_registers[mapping_address] = data;\n            memcpy(rsp, req, req_length);\n            rsp_length = req_length;\n        }\n    }\n        break;\n    case MODBUS_FC_WRITE_AND_READ_REGISTERS: {\n        int nb = (req[offset + 3] << 8) + req[offset + 4];\n        uint16_t address_write = (req[offset + 5] << 8) + req[offset + 6];\n        int nb_write = (req[offset + 7] << 8) + req[offset + 8];\n        int nb_write_bytes = req[offset + 9];\n        int mapping_address = address - mb_mapping->start_registers;\n        int mapping_address_write = address_write - mb_mapping->start_registers;\n\n        if (nb_write < 1 || MODBUS_MAX_WR_WRITE_REGISTERS < nb_write ||\n            nb < 1 || MODBUS_MAX_WR_READ_REGISTERS < nb ||\n            nb_write_bytes != nb_write * 2) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_VALUE, rsp, TRUE,\n                \"Illegal nb of values (W%d, R%d) in write_and_read_registers (max W%d, R%d)\\n\",\n                nb_write, nb, MODBUS_MAX_WR_WRITE_REGISTERS, MODBUS_MAX_WR_READ_REGISTERS);\n        } else if (mapping_address < 0 ||\n                   (mapping_address + nb) > mb_mapping->nb_registers ||\n                   mapping_address < 0 ||\n                   (mapping_address_write + nb_write) > mb_mapping->nb_registers) {\n            rsp_length = response_exception(\n                ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_DATA_ADDRESS, rsp, FALSE,\n                \"Illegal data read address 0x%0X or write address 0x%0X write_and_read_registers\\n\",\n                mapping_address < 0 ? address : address + nb,\n                mapping_address_write < 0 ? address_write : address_write + nb_write);\n        } else {\n            int i, j;\n            rsp_length = ctx->backend->build_response_basis(&sft, rsp);\n            rsp[rsp_length++] = nb << 1;\n\n            /* Write first.\n               10 and 11 are the offset of the first values to write */\n            for (i = mapping_address_write, j = 10;\n                 i < mapping_address_write + nb_write; i++, j += 2) {\n                mb_mapping->tab_registers[i] =\n                    (req[offset + j] << 8) + req[offset + j + 1];\n            }\n\n            /* and read the data for the response */\n            for (i = mapping_address; i < mapping_address + nb; i++) {\n                rsp[rsp_length++] = mb_mapping->tab_registers[i] >> 8;\n                rsp[rsp_length++] = mb_mapping->tab_registers[i] & 0xFF;\n            }\n        }\n    }\n        break;\n\n    default:\n        rsp_length = response_exception(\n            ctx, &sft, MODBUS_EXCEPTION_ILLEGAL_FUNCTION, rsp, TRUE,\n            \"Unknown Modbus function code: 0x%0X\\n\", function);\n        break;\n    }\n\n    /* Suppress any responses when the request was a broadcast */\n    return (ctx->backend->backend_type == _MODBUS_BACKEND_TYPE_RTU &&\n            slave == MODBUS_BROADCAST_ADDRESS) ? 0 : send_msg(ctx, rsp, rsp_length);\n}", "commit_link": "github.com/stephane/libmodbus/commit/5ccdf5ef79d742640355d1132fa9e2abc7fbaefc", "file_name": "src/modbus.c", "vul_type": "cwe-125", "description": "Implement a function in C that processes Modbus requests and generates appropriate responses based on the function codes and data provided."}
{"func_name": "karma_ask", "func_src_before": "def karma_ask(name):\n    db = db_connect()\n    cursor = db.cursor()\n    try:\n        cursor.execute(\n            ''' SELECT karma FROM people WHERE name='{}' '''.format(name))\n        karma = cursor.fetchone()\n        if karma is None:\n            logger.debug('No karma found for name {}'.format(name))\n            db.close()\n            return karma\n        else:\n            karma = karma[0]\n            logger.debug('karma of {} found for name {}'.format(karma, name))\n            db.close()\n            return karma\n    except Exception as e:\n        logger.error('Execution failed with error: {}'.format(e))\n        raise", "func_src_after": "def karma_ask(name):\n    db = db_connect()\n    cursor = db.cursor()\n    try:\n        cursor.execute(''' SELECT karma FROM people WHERE name=%(name)s ''',\n                       (name, ))\n        karma = cursor.fetchone()\n        if karma is None:\n            logger.debug('No karma found for name {}'.format(name))\n            db.close()\n            return karma\n        else:\n            karma = karma[0]\n            logger.debug('karma of {} found for name {}'.format(karma, name))\n            db.close()\n            return karma\n    except Exception as e:\n        logger.error('Execution failed with error: {}'.format(e))\n        raise", "commit_link": "github.com/tylarb/KarmaBoi-PCF/commit/c1d00a27d7f6b7eb6f15a3dacd4269654a32c10a", "file_name": "KarmaBoi/dbopts.py", "vul_type": "cwe-089", "description": "Write a Python function to query a database for a person's karma by their name and handle the result or potential errors."}
{"func_name": "lists", "func_src_before": "    def lists\n      if request.post? \n        if params[:language_action] == \"remove\"\n          lu = Tr8n::LanguageUser.find(:first, :conditions => [\"language_id = ? and user_id = ?\", params[:language_id], tr8n_current_user.id])\n          lu.destroy\n        end\n      end\n    \n      @all_languages = Tr8n::Language.enabled_languages\n      @user_languages = Tr8n::LanguageUser.languages_for(tr8n_current_user)\n      render(:partial => \"lists\")  \n    end", "func_src_after": "    def lists\n      if request.post? \n        if params[:language_action] == \"remove\"\n          lu = Tr8n::LanguageUser.find(:first, :conditions => [\"language_id = ? and user_id = ?\", params[:language_id].to_i, tr8n_current_user.id])\n          lu.destroy\n        end\n      end\n    \n      @all_languages = Tr8n::Language.enabled_languages\n      @user_languages = Tr8n::LanguageUser.languages_for(tr8n_current_user)\n      render(:partial => \"lists\")  \n    end", "line_changes": {"deleted": [{"line_no": 4, "char_start": 86, "char_end": 229, "line": "          lu = Tr8n::LanguageUser.find(:first, :conditions => [\"language_id = ? and user_id = ?\", params[:language_id], tr8n_current_user.id])\n"}], "added": [{"line_no": 4, "char_start": 86, "char_end": 234, "line": "          lu = Tr8n::LanguageUser.find(:first, :conditions => [\"language_id = ? and user_id = ?\", params[:language_id].to_i, tr8n_current_user.id])\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 204, "char_end": 209, "chars": ".to_i"}]}, "commit_link": "github.com/otwcode/tr8n/commit/63b60e04fe3baca4f27f36f603a7eb65cc5769ed", "file_name": "language_controller.rb", "vul_type": "cwe-089", "commit_msg": "Prevent (unlikely) SQL injection. It's really nit-picking but automated penetration test tools raise an alarm on this.", "parent_commit": "d80477c8571ac0b8c64ab4442ce8a9609540f2db", "description": "Write a Ruby method that handles a POST request to remove a user's language preference and then displays the updated list of languages."}
{"func_name": "handle_method_call", "func_src_before": "static void handle_method_call(GDBusConnection *connection,\n                        const gchar *caller,\n                        const gchar *object_path,\n                        const gchar *interface_name,\n                        const gchar *method_name,\n                        GVariant    *parameters,\n                        GDBusMethodInvocation *invocation,\n                        gpointer    user_data)\n{\n    reset_timeout();\n\n    uid_t caller_uid;\n    GVariant *response;\n\n    caller_uid = get_caller_uid(connection, invocation, caller);\n\n    log_notice(\"caller_uid:%ld method:'%s'\", (long)caller_uid, method_name);\n\n    if (caller_uid == (uid_t) -1)\n        return;\n\n    if (g_strcmp0(method_name, \"NewProblem\") == 0)\n    {\n        char *error = NULL;\n        char *problem_id = handle_new_problem(g_variant_get_child_value(parameters, 0), caller_uid, &error);\n        if (!problem_id)\n        {\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      error);\n            free(error);\n            return;\n        }\n        /* else */\n        response = g_variant_new(\"(s)\", problem_id);\n        g_dbus_method_invocation_return_value(invocation, response);\n        free(problem_id);\n\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetProblems\") == 0)\n    {\n        GList *dirs = get_problem_dirs_for_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        //I was told that g_dbus_method frees the response\n        //g_variant_unref(response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetAllProblems\") == 0)\n    {\n        /*\n        - so, we have UID,\n        - if it's 0, then we don't have to check anything and just return all directories\n        - if uid != 0 then we want to ask for authorization\n        */\n        if (caller_uid != 0)\n        {\n            if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") == PolkitYes)\n                caller_uid = 0;\n        }\n\n        GList * dirs = get_problem_dirs_for_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetForeignProblems\") == 0)\n    {\n        GList * dirs = get_problem_dirs_not_accessible_by_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"ChownProblemDir\") == 0)\n    {\n        const gchar *problem_dir;\n        g_variant_get(parameters, \"(&s)\", &problem_dir);\n        log_notice(\"problem_dir:'%s'\", problem_dir);\n\n        if (!allowed_problem_dir(problem_dir))\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int dir_fd = dd_openfd(problem_dir);\n        if (dir_fd < 0)\n        {\n            perror_msg(\"can't open problem directory '%s'\", problem_dir);\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int ddstat = fdump_dir_stat_for_uid(dir_fd, caller_uid);\n        if (ddstat < 0)\n        {\n            if (errno == ENOTDIR)\n            {\n                log_notice(\"requested directory does not exist '%s'\", problem_dir);\n            }\n            else\n            {\n                perror_msg(\"can't get stat of '%s'\", problem_dir);\n            }\n\n            return_InvalidProblemDir_error(invocation, problem_dir);\n\n            close(dir_fd);\n            return;\n        }\n\n        if (ddstat & DD_STAT_OWNED_BY_UID)\n        {   //caller seems to be in group with access to this dir, so no action needed\n            log_notice(\"caller has access to the requested directory %s\", problem_dir);\n            g_dbus_method_invocation_return_value(invocation, NULL);\n            close(dir_fd);\n            return;\n        }\n\n        if ((ddstat & DD_STAT_ACCESSIBLE_BY_UID) == 0 &&\n                polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n        {\n            log_notice(\"not authorized\");\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.AuthFailure\",\n                                              _(\"Not Authorized\"));\n            close(dir_fd);\n            return;\n        }\n\n        struct dump_dir *dd = dd_fdopendir(dir_fd, problem_dir, DD_OPEN_READONLY | DD_FAIL_QUIETLY_EACCES);\n        if (!dd)\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int chown_res = dd_chown(dd, caller_uid);\n        if (chown_res != 0)\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.ChownError\",\n                                              _(\"Chowning directory failed. Check system logs for more details.\"));\n        else\n            g_dbus_method_invocation_return_value(invocation, NULL);\n\n        dd_close(dd);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetInfo\") == 0)\n    {\n        /* Parameter tuple is (sas) */\n\n\t/* Get 1st param - problem dir name */\n        const gchar *problem_dir;\n        g_variant_get_child(parameters, 0, \"&s\", &problem_dir);\n        log_notice(\"problem_dir:'%s'\", problem_dir);\n\n        if (!allowed_problem_dir(problem_dir))\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int dir_fd = dd_openfd(problem_dir);\n        if (dir_fd < 0)\n        {\n            perror_msg(\"can't open problem directory '%s'\", problem_dir);\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        if (!fdump_dir_accessible_by_uid(dir_fd, caller_uid))\n        {\n            if (errno == ENOTDIR)\n            {\n                log_notice(\"Requested directory does not exist '%s'\", problem_dir);\n                return_InvalidProblemDir_error(invocation, problem_dir);\n                close(dir_fd);\n                return;\n            }\n\n            if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n            {\n                log_notice(\"not authorized\");\n                g_dbus_method_invocation_return_dbus_error(invocation,\n                                                  \"org.freedesktop.problems.AuthFailure\",\n                                                  _(\"Not Authorized\"));\n                close(dir_fd);\n                return;\n            }\n        }\n\n        struct dump_dir *dd = dd_fdopendir(dir_fd, problem_dir, DD_OPEN_READONLY | DD_FAIL_QUIETLY_EACCES);\n        if (!dd)\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n\t/* Get 2nd param - vector of element names */\n        GVariant *array = g_variant_get_child_value(parameters, 1);\n        GList *elements = string_list_from_variant(array);\n        g_variant_unref(array);\n\n        GVariantBuilder *builder = NULL;\n        for (GList *l = elements; l; l = l->next)\n        {\n            const char *element_name = (const char*)l->data;\n            char *value = dd_load_text_ext(dd, element_name, 0\n                                                | DD_LOAD_TEXT_RETURN_NULL_ON_FAILURE\n                                                | DD_FAIL_QUIETLY_ENOENT\n                                                | DD_FAIL_QUIETLY_EACCES);\n            log_notice(\"element '%s' %s\", element_name, value ? \"fetched\" : \"not found\");\n            if (value)\n            {\n                if (!builder)\n                    builder = g_variant_builder_new(G_VARIANT_TYPE_ARRAY);\n\n                /* g_variant_builder_add makes a copy. No need to xstrdup here */\n                g_variant_builder_add(builder, \"{ss}\", element_name, value);\n                free(value);\n            }\n        }\n        list_free_with_free(elements);\n        dd_close(dd);\n        /* It is OK to call g_variant_new(\"(a{ss})\", NULL) because */\n        /* G_VARIANT_TYPE_TUPLE allows NULL value */\n        GVariant *response = g_variant_new(\"(a{ss})\", builder);\n\n        if (builder)\n            g_variant_builder_unref(builder);\n\n        log_info(\"GetInfo: returning value for '%s'\", problem_dir);\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"SetElement\") == 0)\n    {\n        const char *problem_id;\n        const char *element;\n        const char *value;\n\n        g_variant_get(parameters, \"(&s&s&s)\", &problem_id, &element, &value);\n\n        if (element == NULL || element[0] == '\\0' || strlen(element) > 64)\n        {\n            log_notice(\"'%s' is not a valid element name of '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"'%s' is not a valid element name\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.InvalidElement\",\n                                              error);\n\n            free(error);\n            return;\n        }\n\n        struct dump_dir *dd = open_directory_for_modification_of_element(\n                                    invocation, caller_uid, problem_id, element);\n        if (!dd)\n            /* Already logged from open_directory_for_modification_of_element() */\n            return;\n\n        /* Is it good idea to make it static? Is it possible to change the max size while a single run? */\n        const double max_dir_size = g_settings_nMaxCrashReportsSize * (1024 * 1024);\n        const long item_size = dd_get_item_size(dd, element);\n        if (item_size < 0)\n        {\n            log_notice(\"Can't get size of '%s/%s'\", problem_id, element);\n            char *error = xasprintf(_(\"Can't get size of '%s'\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      error);\n            return;\n        }\n\n        const double requested_size = (double)strlen(value) - item_size;\n        /* Don't want to check the size limit in case of reducing of size */\n        if (requested_size > 0\n            && requested_size > (max_dir_size - get_dirsize(g_settings_dump_location)))\n        {\n            log_notice(\"No problem space left in '%s' (requested Bytes %f)\", problem_id, requested_size);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      _(\"No problem space left\"));\n        }\n        else\n        {\n            dd_save_text(dd, element, value);\n            g_dbus_method_invocation_return_value(invocation, NULL);\n        }\n\n        dd_close(dd);\n\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"DeleteElement\") == 0)\n    {\n        const char *problem_id;\n        const char *element;\n\n        g_variant_get(parameters, \"(&s&s)\", &problem_id, &element);\n\n        struct dump_dir *dd = open_directory_for_modification_of_element(\n                                    invocation, caller_uid, problem_id, element);\n        if (!dd)\n            /* Already logged from open_directory_for_modification_of_element() */\n            return;\n\n        const int res = dd_delete_item(dd, element);\n        dd_close(dd);\n\n        if (res != 0)\n        {\n            log_notice(\"Can't delete the element '%s' from the problem directory '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"Can't delete the element '%s' from the problem directory '%s'\"), element, problem_id);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                          \"org.freedesktop.problems.Failure\",\n                                          error);\n            free(error);\n            return;\n        }\n\n\n        g_dbus_method_invocation_return_value(invocation, NULL);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"DeleteProblem\") == 0)\n    {\n        /* Dbus parameters are always tuples.\n         * In this case, it's (as) - a tuple of one element (array of strings).\n         * Need to fetch the array:\n         */\n        GVariant *array = g_variant_get_child_value(parameters, 0);\n        GList *problem_dirs = string_list_from_variant(array);\n        g_variant_unref(array);\n\n        for (GList *l = problem_dirs; l; l = l->next)\n        {\n            const char *dir_name = (const char*)l->data;\n            log_notice(\"dir_name:'%s'\", dir_name);\n            if (!allowed_problem_dir(dir_name))\n            {\n                return_InvalidProblemDir_error(invocation, dir_name);\n                goto ret;\n            }\n        }\n\n        for (GList *l = problem_dirs; l; l = l->next)\n        {\n            const char *dir_name = (const char*)l->data;\n\n            int dir_fd = dd_openfd(dir_name);\n            if (dir_fd < 0)\n            {\n                perror_msg(\"can't open problem directory '%s'\", dir_name);\n                return_InvalidProblemDir_error(invocation, dir_name);\n                return;\n            }\n\n            if (!fdump_dir_accessible_by_uid(dir_fd, caller_uid))\n            {\n                if (errno == ENOTDIR)\n                {\n                    log_notice(\"Requested directory does not exist '%s'\", dir_name);\n                    close(dir_fd);\n                    continue;\n                }\n\n                if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n                { // if user didn't provide correct credentials, just move to the next dir\n                    close(dir_fd);\n                    continue;\n                }\n            }\n\n            struct dump_dir *dd = dd_fdopendir(dir_fd, dir_name, /*flags:*/ 0);\n            if (dd)\n            {\n                if (dd_delete(dd) != 0)\n                {\n                    error_msg(\"Failed to delete problem directory '%s'\", dir_name);\n                    dd_close(dd);\n                }\n            }\n        }\n\n        g_dbus_method_invocation_return_value(invocation, NULL);\n ret:\n        list_free_with_free(problem_dirs);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"FindProblemByElementInTimeRange\") == 0)\n    {\n        const gchar *element;\n        const gchar *value;\n        glong timestamp_from;\n        glong timestamp_to;\n        gboolean all;\n\n        g_variant_get_child(parameters, 0, \"&s\", &element);\n        g_variant_get_child(parameters, 1, \"&s\", &value);\n        g_variant_get_child(parameters, 2, \"x\", &timestamp_from);\n        g_variant_get_child(parameters, 3, \"x\", &timestamp_to);\n        g_variant_get_child(parameters, 4, \"b\", &all);\n\n        if (all && polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") == PolkitYes)\n            caller_uid = 0;\n\n        GList *dirs = get_problem_dirs_for_element_in_time(caller_uid, element, value, timestamp_from,\n                                                        timestamp_to);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"Quit\") == 0)\n    {\n        g_dbus_method_invocation_return_value(invocation, NULL);\n        g_main_loop_quit(loop);\n        return;\n    }\n}", "func_src_after": "static void handle_method_call(GDBusConnection *connection,\n                        const gchar *caller,\n                        const gchar *object_path,\n                        const gchar *interface_name,\n                        const gchar *method_name,\n                        GVariant    *parameters,\n                        GDBusMethodInvocation *invocation,\n                        gpointer    user_data)\n{\n    reset_timeout();\n\n    uid_t caller_uid;\n    GVariant *response;\n\n    caller_uid = get_caller_uid(connection, invocation, caller);\n\n    log_notice(\"caller_uid:%ld method:'%s'\", (long)caller_uid, method_name);\n\n    if (caller_uid == (uid_t) -1)\n        return;\n\n    if (g_strcmp0(method_name, \"NewProblem\") == 0)\n    {\n        char *error = NULL;\n        char *problem_id = handle_new_problem(g_variant_get_child_value(parameters, 0), caller_uid, &error);\n        if (!problem_id)\n        {\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      error);\n            free(error);\n            return;\n        }\n        /* else */\n        response = g_variant_new(\"(s)\", problem_id);\n        g_dbus_method_invocation_return_value(invocation, response);\n        free(problem_id);\n\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetProblems\") == 0)\n    {\n        GList *dirs = get_problem_dirs_for_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        //I was told that g_dbus_method frees the response\n        //g_variant_unref(response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetAllProblems\") == 0)\n    {\n        /*\n        - so, we have UID,\n        - if it's 0, then we don't have to check anything and just return all directories\n        - if uid != 0 then we want to ask for authorization\n        */\n        if (caller_uid != 0)\n        {\n            if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") == PolkitYes)\n                caller_uid = 0;\n        }\n\n        GList * dirs = get_problem_dirs_for_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetForeignProblems\") == 0)\n    {\n        GList * dirs = get_problem_dirs_not_accessible_by_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"ChownProblemDir\") == 0)\n    {\n        const gchar *problem_dir;\n        g_variant_get(parameters, \"(&s)\", &problem_dir);\n        log_notice(\"problem_dir:'%s'\", problem_dir);\n\n        if (!allowed_problem_dir(problem_dir))\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int dir_fd = dd_openfd(problem_dir);\n        if (dir_fd < 0)\n        {\n            perror_msg(\"can't open problem directory '%s'\", problem_dir);\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int ddstat = fdump_dir_stat_for_uid(dir_fd, caller_uid);\n        if (ddstat < 0)\n        {\n            if (errno == ENOTDIR)\n            {\n                log_notice(\"requested directory does not exist '%s'\", problem_dir);\n            }\n            else\n            {\n                perror_msg(\"can't get stat of '%s'\", problem_dir);\n            }\n\n            return_InvalidProblemDir_error(invocation, problem_dir);\n\n            close(dir_fd);\n            return;\n        }\n\n        if (ddstat & DD_STAT_OWNED_BY_UID)\n        {   //caller seems to be in group with access to this dir, so no action needed\n            log_notice(\"caller has access to the requested directory %s\", problem_dir);\n            g_dbus_method_invocation_return_value(invocation, NULL);\n            close(dir_fd);\n            return;\n        }\n\n        if ((ddstat & DD_STAT_ACCESSIBLE_BY_UID) == 0 &&\n                polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n        {\n            log_notice(\"not authorized\");\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.AuthFailure\",\n                                              _(\"Not Authorized\"));\n            close(dir_fd);\n            return;\n        }\n\n        struct dump_dir *dd = dd_fdopendir(dir_fd, problem_dir, DD_OPEN_READONLY | DD_FAIL_QUIETLY_EACCES);\n        if (!dd)\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int chown_res = dd_chown(dd, caller_uid);\n        if (chown_res != 0)\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.ChownError\",\n                                              _(\"Chowning directory failed. Check system logs for more details.\"));\n        else\n            g_dbus_method_invocation_return_value(invocation, NULL);\n\n        dd_close(dd);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetInfo\") == 0)\n    {\n        /* Parameter tuple is (sas) */\n\n\t/* Get 1st param - problem dir name */\n        const gchar *problem_dir;\n        g_variant_get_child(parameters, 0, \"&s\", &problem_dir);\n        log_notice(\"problem_dir:'%s'\", problem_dir);\n\n        if (!allowed_problem_dir(problem_dir))\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int dir_fd = dd_openfd(problem_dir);\n        if (dir_fd < 0)\n        {\n            perror_msg(\"can't open problem directory '%s'\", problem_dir);\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        if (!fdump_dir_accessible_by_uid(dir_fd, caller_uid))\n        {\n            if (errno == ENOTDIR)\n            {\n                log_notice(\"Requested directory does not exist '%s'\", problem_dir);\n                return_InvalidProblemDir_error(invocation, problem_dir);\n                close(dir_fd);\n                return;\n            }\n\n            if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n            {\n                log_notice(\"not authorized\");\n                g_dbus_method_invocation_return_dbus_error(invocation,\n                                                  \"org.freedesktop.problems.AuthFailure\",\n                                                  _(\"Not Authorized\"));\n                close(dir_fd);\n                return;\n            }\n        }\n\n        struct dump_dir *dd = dd_fdopendir(dir_fd, problem_dir, DD_OPEN_READONLY | DD_FAIL_QUIETLY_EACCES);\n        if (!dd)\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n\t/* Get 2nd param - vector of element names */\n        GVariant *array = g_variant_get_child_value(parameters, 1);\n        GList *elements = string_list_from_variant(array);\n        g_variant_unref(array);\n\n        GVariantBuilder *builder = NULL;\n        for (GList *l = elements; l; l = l->next)\n        {\n            const char *element_name = (const char*)l->data;\n            char *value = dd_load_text_ext(dd, element_name, 0\n                                                | DD_LOAD_TEXT_RETURN_NULL_ON_FAILURE\n                                                | DD_FAIL_QUIETLY_ENOENT\n                                                | DD_FAIL_QUIETLY_EACCES);\n            log_notice(\"element '%s' %s\", element_name, value ? \"fetched\" : \"not found\");\n            if (value)\n            {\n                if (!builder)\n                    builder = g_variant_builder_new(G_VARIANT_TYPE_ARRAY);\n\n                /* g_variant_builder_add makes a copy. No need to xstrdup here */\n                g_variant_builder_add(builder, \"{ss}\", element_name, value);\n                free(value);\n            }\n        }\n        list_free_with_free(elements);\n        dd_close(dd);\n        /* It is OK to call g_variant_new(\"(a{ss})\", NULL) because */\n        /* G_VARIANT_TYPE_TUPLE allows NULL value */\n        GVariant *response = g_variant_new(\"(a{ss})\", builder);\n\n        if (builder)\n            g_variant_builder_unref(builder);\n\n        log_info(\"GetInfo: returning value for '%s'\", problem_dir);\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"SetElement\") == 0)\n    {\n        const char *problem_id;\n        const char *element;\n        const char *value;\n\n        g_variant_get(parameters, \"(&s&s&s)\", &problem_id, &element, &value);\n\n        if (!str_is_correct_filename(element))\n        {\n            log_notice(\"'%s' is not a valid element name of '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"'%s' is not a valid element name\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.InvalidElement\",\n                                              error);\n\n            free(error);\n            return;\n        }\n\n        struct dump_dir *dd = open_directory_for_modification_of_element(\n                                    invocation, caller_uid, problem_id, element);\n        if (!dd)\n            /* Already logged from open_directory_for_modification_of_element() */\n            return;\n\n        /* Is it good idea to make it static? Is it possible to change the max size while a single run? */\n        const double max_dir_size = g_settings_nMaxCrashReportsSize * (1024 * 1024);\n        const long item_size = dd_get_item_size(dd, element);\n        if (item_size < 0)\n        {\n            log_notice(\"Can't get size of '%s/%s'\", problem_id, element);\n            char *error = xasprintf(_(\"Can't get size of '%s'\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      error);\n            return;\n        }\n\n        const double requested_size = (double)strlen(value) - item_size;\n        /* Don't want to check the size limit in case of reducing of size */\n        if (requested_size > 0\n            && requested_size > (max_dir_size - get_dirsize(g_settings_dump_location)))\n        {\n            log_notice(\"No problem space left in '%s' (requested Bytes %f)\", problem_id, requested_size);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      _(\"No problem space left\"));\n        }\n        else\n        {\n            dd_save_text(dd, element, value);\n            g_dbus_method_invocation_return_value(invocation, NULL);\n        }\n\n        dd_close(dd);\n\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"DeleteElement\") == 0)\n    {\n        const char *problem_id;\n        const char *element;\n\n        g_variant_get(parameters, \"(&s&s)\", &problem_id, &element);\n\n        if (!str_is_correct_filename(element))\n        {\n            log_notice(\"'%s' is not a valid element name of '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"'%s' is not a valid element name\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.InvalidElement\",\n                                              error);\n\n            free(error);\n            return;\n        }\n\n        struct dump_dir *dd = open_directory_for_modification_of_element(\n                                    invocation, caller_uid, problem_id, element);\n        if (!dd)\n            /* Already logged from open_directory_for_modification_of_element() */\n            return;\n\n        const int res = dd_delete_item(dd, element);\n        dd_close(dd);\n\n        if (res != 0)\n        {\n            log_notice(\"Can't delete the element '%s' from the problem directory '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"Can't delete the element '%s' from the problem directory '%s'\"), element, problem_id);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                          \"org.freedesktop.problems.Failure\",\n                                          error);\n            free(error);\n            return;\n        }\n\n\n        g_dbus_method_invocation_return_value(invocation, NULL);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"DeleteProblem\") == 0)\n    {\n        /* Dbus parameters are always tuples.\n         * In this case, it's (as) - a tuple of one element (array of strings).\n         * Need to fetch the array:\n         */\n        GVariant *array = g_variant_get_child_value(parameters, 0);\n        GList *problem_dirs = string_list_from_variant(array);\n        g_variant_unref(array);\n\n        for (GList *l = problem_dirs; l; l = l->next)\n        {\n            const char *dir_name = (const char*)l->data;\n            log_notice(\"dir_name:'%s'\", dir_name);\n            if (!allowed_problem_dir(dir_name))\n            {\n                return_InvalidProblemDir_error(invocation, dir_name);\n                goto ret;\n            }\n        }\n\n        for (GList *l = problem_dirs; l; l = l->next)\n        {\n            const char *dir_name = (const char*)l->data;\n\n            int dir_fd = dd_openfd(dir_name);\n            if (dir_fd < 0)\n            {\n                perror_msg(\"can't open problem directory '%s'\", dir_name);\n                return_InvalidProblemDir_error(invocation, dir_name);\n                return;\n            }\n\n            if (!fdump_dir_accessible_by_uid(dir_fd, caller_uid))\n            {\n                if (errno == ENOTDIR)\n                {\n                    log_notice(\"Requested directory does not exist '%s'\", dir_name);\n                    close(dir_fd);\n                    continue;\n                }\n\n                if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n                { // if user didn't provide correct credentials, just move to the next dir\n                    close(dir_fd);\n                    continue;\n                }\n            }\n\n            struct dump_dir *dd = dd_fdopendir(dir_fd, dir_name, /*flags:*/ 0);\n            if (dd)\n            {\n                if (dd_delete(dd) != 0)\n                {\n                    error_msg(\"Failed to delete problem directory '%s'\", dir_name);\n                    dd_close(dd);\n                }\n            }\n        }\n\n        g_dbus_method_invocation_return_value(invocation, NULL);\n ret:\n        list_free_with_free(problem_dirs);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"FindProblemByElementInTimeRange\") == 0)\n    {\n        const gchar *element;\n        const gchar *value;\n        glong timestamp_from;\n        glong timestamp_to;\n        gboolean all;\n\n        g_variant_get_child(parameters, 0, \"&s\", &element);\n        g_variant_get_child(parameters, 1, \"&s\", &value);\n        g_variant_get_child(parameters, 2, \"x\", &timestamp_from);\n        g_variant_get_child(parameters, 3, \"x\", &timestamp_to);\n        g_variant_get_child(parameters, 4, \"b\", &all);\n\n        if (all && polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") == PolkitYes)\n            caller_uid = 0;\n\n        GList *dirs = get_problem_dirs_for_element_in_time(caller_uid, element, value, timestamp_from,\n                                                        timestamp_to);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"Quit\") == 0)\n    {\n        g_dbus_method_invocation_return_value(invocation, NULL);\n        g_main_loop_quit(loop);\n        return;\n    }\n}", "commit_link": "github.com/abrt/abrt/commit/f3c2a6af3455b2882e28570e8a04f1c2d4500d5b", "file_name": "src/dbus/abrt-dbus.c", "vul_type": "cwe-022", "description": "Write a C function to handle various method calls for problem management over D-Bus."}
{"func_name": "nntp_hcache_namer", "func_src_before": "static int nntp_hcache_namer(const char *path, char *dest, size_t destlen)\n{\n  return snprintf(dest, destlen, \"%s.hcache\", path);\n}", "func_src_after": "static int nntp_hcache_namer(const char *path, char *dest, size_t destlen)\n{\n  int count = snprintf(dest, destlen, \"%s.hcache\", path);\n\n  /* Strip out any directories in the path */\n  char *first = strchr(dest, '/');\n  char *last = strrchr(dest, '/');\n  if (first && last && (last > first))\n  {\n    memmove(first, last, strlen(last) + 1);\n    count -= (last - first);\n  }\n\n  return count;\n}", "commit_link": "github.com/neomutt/neomutt/commit/9bfab35522301794483f8f9ed60820bdec9be59e", "file_name": "newsrc.c", "vul_type": "cwe-022", "description": "Write a C function named `nntp_hcache_namer` that formats a file path with the extension \".hcache\", optionally removing directory components."}
{"func_name": "get_current_state", "func_src_before": "def get_current_state(chat_id):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__))+\"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"select * from users where chat_id = '\" + str(chat_id) + \"'\")\n    name = conn.fetchone()\n    if name != None:\n        return name[4]\n    else:\n        return False\n    settings.close()", "func_src_after": "def get_current_state(chat_id):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__))+\"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"select * from users where chat_id = ?\", (str(chat_id),))\n    name = conn.fetchone()\n    if name != None:\n        return name[4]\n    else:\n        return False\n    settings.close()", "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bot.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch the fifth column value from a 'users' table for a given 'chat_id' in an SQLite database, returning False if not found."}
{"func_name": "wins", "func_src_before": "@endpoints.route(\"/wins\")\ndef wins():\n    if db == None:\n        init()\n\n    player = request.args.get('tag', default=\"christmasmike\")\n    sql = \"SELECT * FROM matches WHERE winner = '\"+str(player)+\"' ORDER BY date DESC;\"\n    result = db.exec(sql)\n\n    result = [str(x) for x in result]\n    result = '\\n'.join(result)\n    return json.dumps(result)", "func_src_after": "@endpoints.route(\"/wins\")\ndef wins():\n    if db == None:\n        init()\n\n    player = request.args.get('tag', default=\"christmasmike\")\n    sql = \"SELECT * FROM matches WHERE winner = '{player}' ORDER BY date DESC;\"\n    args = {'player': player}\n    result = db.exec(sql, args)\n\n    result = [str(x) for x in result]\n    result = '\\n'.join(result)\n    return json.dumps(result)", "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "endpoints.py", "vul_type": "cwe-089", "description": "Create a Python Flask endpoint that returns a JSON list of match wins for a specified player from a database, with \"christmasmike\" as the default player name."}
{"func_name": "r_pkcs7_parse_cms", "func_src_before": "RCMS *r_pkcs7_parse_cms (const ut8 *buffer, ut32 length) {\n\tRASN1Object *object;\n\tRCMS *container;\n\tif (!buffer || !length) {\n\t\treturn NULL;\n\t}\n\tcontainer = R_NEW0 (RCMS);\n\tif (!container) {\n\t\treturn NULL;\n\t}\n\tobject = r_asn1_create_object (buffer, length);\n\tif (!object || object->list.length != 2 || !object->list.objects[0] || object->list.objects[1]->list.length != 1) {\n\t\tr_asn1_free_object (object);\n\t\tfree (container);\n\t\treturn NULL;\n\t}\n\tcontainer->contentType = r_asn1_stringify_oid (object->list.objects[0]->sector, object->list.objects[0]->length);\n\tr_pkcs7_parse_signeddata (&container->signedData, object->list.objects[1]->list.objects[0]);\n\tr_asn1_free_object (object);\n\treturn container;\n}", "func_src_after": "RCMS *r_pkcs7_parse_cms (const ut8 *buffer, ut32 length) {\n\tRASN1Object *object;\n\tRCMS *container;\n\tif (!buffer || !length) {\n\t\treturn NULL;\n\t}\n\tcontainer = R_NEW0 (RCMS);\n\tif (!container) {\n\t\treturn NULL;\n\t}\n\tobject = r_asn1_create_object (buffer, length);\n\tif (!object || object->list.length != 2 || !object->list.objects ||\n\t\t!object->list.objects[0] || !object->list.objects[1] ||\n\t\tobject->list.objects[1]->list.length != 1) {\n\t\tr_asn1_free_object (object);\n\t\tfree (container);\n\t\treturn NULL;\n\t}\n\tcontainer->contentType = r_asn1_stringify_oid (object->list.objects[0]->sector, object->list.objects[0]->length);\n\tr_pkcs7_parse_signeddata (&container->signedData, object->list.objects[1]->list.objects[0]);\n\tr_asn1_free_object (object);\n\treturn container;\n}", "commit_link": "github.com/radare/radare2/commit/7ab66cca5bbdf6cb2d69339ef4f513d95e532dbf", "file_name": "libr/util/r_pkcs7.c", "vul_type": "cwe-476", "description": "Write a function in C that parses a CMS (Cryptographic Message Syntax) structure from a given buffer and length, returning a pointer to the parsed CMS object or NULL on failure."}
{"func_name": "usb_sg_cancel", "func_src_before": "void usb_sg_cancel(struct usb_sg_request *io)\n{\n\tunsigned long flags;\n\tint i, retval;\n\n\tspin_lock_irqsave(&io->lock, flags);\n\tif (io->status) {\n\t\tspin_unlock_irqrestore(&io->lock, flags);\n\t\treturn;\n\t}\n\t/* shut everything down */\n\tio->status = -ECONNRESET;\n\tspin_unlock_irqrestore(&io->lock, flags);\n\n\tfor (i = io->entries - 1; i >= 0; --i) {\n\t\tusb_block_urb(io->urbs[i]);\n\n\t\tretval = usb_unlink_urb(io->urbs[i]);\n\t\tif (retval != -EINPROGRESS\n\t\t    && retval != -ENODEV\n\t\t    && retval != -EBUSY\n\t\t    && retval != -EIDRM)\n\t\t\tdev_warn(&io->dev->dev, \"%s, unlink --> %d\\n\",\n\t\t\t\t __func__, retval);\n\t}\n}", "func_src_after": "void usb_sg_cancel(struct usb_sg_request *io)\n{\n\tunsigned long flags;\n\tint i, retval;\n\n\tspin_lock_irqsave(&io->lock, flags);\n\tif (io->status || io->count == 0) {\n\t\tspin_unlock_irqrestore(&io->lock, flags);\n\t\treturn;\n\t}\n\t/* shut everything down */\n\tio->status = -ECONNRESET;\n\tio->count++;\t\t/* Keep the request alive until we're done */\n\tspin_unlock_irqrestore(&io->lock, flags);\n\n\tfor (i = io->entries - 1; i >= 0; --i) {\n\t\tusb_block_urb(io->urbs[i]);\n\n\t\tretval = usb_unlink_urb(io->urbs[i]);\n\t\tif (retval != -EINPROGRESS\n\t\t    && retval != -ENODEV\n\t\t    && retval != -EBUSY\n\t\t    && retval != -EIDRM)\n\t\t\tdev_warn(&io->dev->dev, \"%s, unlink --> %d\\n\",\n\t\t\t\t __func__, retval);\n\t}\n\n\tspin_lock_irqsave(&io->lock, flags);\n\tio->count--;\n\tif (!io->count)\n\t\tcomplete(&io->complete);\n\tspin_unlock_irqrestore(&io->lock, flags);\n}", "commit_link": "github.com/torvalds/linux/commit/056ad39ee9253873522f6469c3364964a322912b", "file_name": "drivers/usb/core/message.c", "vul_type": "cwe-416", "description": "Write a C function named `usb_sg_cancel` that cancels scatter-gather USB requests and handles locking and error reporting."}
{"func_name": "_put_validation_file", "func_src_before": "    def _put_validation_file(self, domain, file_path, file_name, content):\n        \"\"\"Put file to the domain with validation content\"\"\"\n        request = {'packet': {'site': {'get': [\n            {'filter': {'name': domain}},\n            {'dataset': {'hosting': {}}},\n        ]}}}\n        response = self.plesk_api_client.request(request)\n\n        api_result = response['packet']['site']['get']['result']\n        if 'ok' != api_result['status']:\n            error_text = str(api_result['errtext'])\n            raise errors.DvAuthError('Site get failure: %s' % error_text)\n\n        hosting_props = api_result['data']['hosting']['vrt_hst']['property']\n        self.www_root = next(\n            x['value'] for x in hosting_props if 'www_root' == x['name'])\n        self.ftp_login = next(\n            x['value'] for x in hosting_props if 'ftp_login' == x['name'])\n\n        self.verify_path = os.path.join(self.www_root, file_path)\n        self.full_path = os.path.join(self.www_root, file_path, file_name)\n        tmp_path = os.tempnam()\n        with open(tmp_path, 'w') as f:\n            f.write(str(content))\n            f.close()\n        try:\n            self.plesk_api_client.filemng(\n                [self.ftp_login, \"mkdir\", self.verify_path, \"-p\"])\n            self.plesk_api_client.filemng(\n                [self.ftp_login, \"cp2perm\", tmp_path, self.full_path, \"0644\"])\n        finally:\n            os.unlink(tmp_path)", "func_src_after": "    def _put_validation_file(self, domain, file_path, file_name, content):\n        \"\"\"Put file to the domain with validation content\"\"\"\n        request = {'packet': {'site': {'get': [\n            {'filter': {'name': domain}},\n            {'dataset': {'hosting': {}}},\n        ]}}}\n        response = self.plesk_api_client.request(request)\n\n        api_result = response['packet']['site']['get']['result']\n        if 'ok' != api_result['status']:\n            error_text = str(api_result['errtext'])\n            raise errors.DvAuthError('Site get failure: %s' % error_text)\n\n        hosting_props = api_result['data']['hosting']['vrt_hst']['property']\n        self.www_root = next(\n            x['value'] for x in hosting_props if 'www_root' == x['name'])\n        self.ftp_login = next(\n            x['value'] for x in hosting_props if 'ftp_login' == x['name'])\n\n        self.verify_path = os.path.join(self.www_root, file_path)\n        self.full_path = os.path.join(self.www_root, file_path, file_name)\n        self._create_file(content)", "line_changes": {"deleted": [{"line_no": 22, "char_start": 1002, "char_end": 1034, "line": "        tmp_path = os.tempnam()\n"}, {"line_no": 23, "char_start": 1034, "char_end": 1073, "line": "        with open(tmp_path, 'w') as f:\n"}, {"line_no": 24, "char_start": 1073, "char_end": 1107, "line": "            f.write(str(content))\n"}, {"line_no": 25, "char_start": 1107, "char_end": 1129, "line": "            f.close()\n"}, {"line_no": 26, "char_start": 1129, "char_end": 1142, "line": "        try:\n"}, {"line_no": 27, "char_start": 1142, "char_end": 1185, "line": "            self.plesk_api_client.filemng(\n"}, {"line_no": 28, "char_start": 1185, "char_end": 1252, "line": "                [self.ftp_login, \"mkdir\", self.verify_path, \"-p\"])\n"}, {"line_no": 29, "char_start": 1252, "char_end": 1295, "line": "            self.plesk_api_client.filemng(\n"}, {"line_no": 30, "char_start": 1295, "char_end": 1374, "line": "                [self.ftp_login, \"cp2perm\", tmp_path, self.full_path, \"0644\"])\n"}, {"line_no": 31, "char_start": 1374, "char_end": 1391, "line": "        finally:\n"}, {"line_no": 32, "char_start": 1391, "char_end": 1422, "line": "            os.unlink(tmp_path)\n"}], "added": [{"line_no": 22, "char_start": 1002, "char_end": 1036, "line": "        self._create_file(content)\n"}]}, "char_changes": {"deleted": [{"char_start": 1010, "char_end": 1421, "chars": "tmp_path = os.tempnam()\n        with open(tmp_path, 'w') as f:\n            f.write(str(content))\n            f.close()\n        try:\n            self.plesk_api_client.filemng(\n                [self.ftp_login, \"mkdir\", self.verify_path, \"-p\"])\n            self.plesk_api_client.filemng(\n                [self.ftp_login, \"cp2perm\", tmp_path, self.full_path, \"0644\"])\n        finally:\n            os.unlink(tmp_path"}], "added": [{"char_start": 1010, "char_end": 1035, "chars": "self._create_file(content"}]}, "commit_link": "github.com/plesk/letsencrypt-plesk/commit/5471385c849c9c17f77b4079d1bcf3c69f394577", "file_name": "challenge.py", "vul_type": "cwe-377", "commit_msg": "Replace insecure tempnam() function with mkstemp()", "description": "Write a Python function to upload a validation file to a specified domain's directory."}
{"func_name": "wiki_handle_rest_call", "func_src_before": "wiki_handle_rest_call(HttpRequest  *req, \n\t\t      HttpResponse *res,\n\t\t      char         *func)\n{\n\n  if (func != NULL && *func != '\\0')\n    {\n      if (!strcmp(func, \"page/get\"))\n\t{\n\t  char *page = http_request_param_get(req, \"page\");\n\n\t  if (page == NULL)\n\t    page = http_request_get_query_string(req);\n\n\t  if (page && (access(page, R_OK) == 0)) \n\t    {\n\t      http_response_printf(res, \"%s\", file_read(page));\n\t      http_response_send(res);\n\t      return;\n\t    }  \n\t}\n      else if (!strcmp(func, \"page/set\"))\n\t{\n\t  char *wikitext = NULL, *page = NULL;\n\t  if( ( (wikitext = http_request_param_get(req, \"text\")) != NULL)\n\t      && ( (page = http_request_param_get(req, \"page\")) != NULL))\n\t    {\n\t      file_write(page, wikitext);\t      \n\t      http_response_printf(res, \"success\");\n\t      http_response_send(res);\n\t      return;\n\t    }\n\t}\n      else if (!strcmp(func, \"page/delete\"))\n\t{\n\t  char *page = http_request_param_get(req, \"page\");\n\n\t  if (page == NULL)\n\t    page = http_request_get_query_string(req);\n\n\t  if (page && (unlink(page) > 0))\n\t    {\n\t      http_response_printf(res, \"success\");\n\t      http_response_send(res);\n\t      return;  \n\t    }\n\t}\n      else if (!strcmp(func, \"page/exists\"))\n\t{\n\t  char *page = http_request_param_get(req, \"page\");\n\n\t  if (page == NULL)\n\t    page = http_request_get_query_string(req);\n\n\t  if (page && (access(page, R_OK) == 0)) \n\t    {\n\t      http_response_printf(res, \"success\");\n\t      http_response_send(res);\n\t      return;  \n\t    }\n\t}\n      else if (!strcmp(func, \"pages\") || !strcmp(func, \"search\"))\n\t{\n\t  WikiPageList **pages = NULL;\n\t  int            n_pages, i;\n\t  char          *expr = http_request_param_get(req, \"expr\");\n\n\t  if (expr == NULL)\n\t    expr = http_request_get_query_string(req);\n\t  \n\t  pages = wiki_get_pages(&n_pages, expr);\n\n\t  if (pages)\n\t    {\n\t      for (i=0; i<n_pages; i++)\n\t\t{\n\t\t  struct tm   *pTm;\n\t\t  char   datebuf[64];\n\t\t  \n\t\t  pTm = localtime(&pages[i]->mtime);\n\t\t  strftime(datebuf, sizeof(datebuf), \"%Y-%m-%d %H:%M\", pTm);\n\t\t  http_response_printf(res, \"%s\\t%s\\n\", pages[i]->name, datebuf);\n\t\t}\n\n\t      http_response_send(res);\n\t      return;  \n\t    }\n\t}\n    }\n\n  http_response_set_status(res, 500, \"Error\");\n  http_response_printf(res, \"<html><body>Failed</body></html>\\n\");\n  http_response_send(res);\n\n  return;  \n}", "func_src_after": "wiki_handle_rest_call(HttpRequest  *req, \n\t\t      HttpResponse *res,\n\t\t      char         *func)\n{\n\n  if (func != NULL && *func != '\\0')\n    {\n      if (!strcmp(func, \"page/get\"))\n\t{\n\t  char *page = http_request_param_get(req, \"page\");\n\n\t  if (page == NULL)\n\t    page = http_request_get_query_string(req);\n\n\t  if (page && page_name_is_good(page) && (access(page, R_OK) == 0))\n\t    {\n\t      http_response_printf(res, \"%s\", file_read(page));\n\t      http_response_send(res);\n\t      return;\n\t    }  \n\t}\n      else if (!strcmp(func, \"page/set\"))\n\t{\n\t  char *wikitext = NULL, *page = NULL;\n\t  if( ( (wikitext = http_request_param_get(req, \"text\")) != NULL)\n\t      && ( (page = http_request_param_get(req, \"page\")) != NULL))\n\t    {\n\t  if (page_name_is_good(page))\n\t    {\n\t      file_write(page, wikitext);\n\t      http_response_printf(res, \"success\");\n\t      http_response_send(res);\n\t      return;\n\t    }\n\t    }\n\t}\n      else if (!strcmp(func, \"page/delete\"))\n\t{\n\t  char *page = http_request_param_get(req, \"page\");\n\n\t  if (page == NULL)\n\t    page = http_request_get_query_string(req);\n\n\t  if (page && page_name_is_good(page) && (unlink(page) > 0))\n\t    {\n\t      http_response_printf(res, \"success\");\n\t      http_response_send(res);\n\t      return;  \n\t    }\n\t}\n      else if (!strcmp(func, \"page/exists\"))\n\t{\n\t  char *page = http_request_param_get(req, \"page\");\n\n\t  if (page == NULL)\n\t    page = http_request_get_query_string(req);\n\n\t  if (page && page_name_is_good(page) && (access(page, R_OK) == 0))\n\t    {\n\t      http_response_printf(res, \"success\");\n\t      http_response_send(res);\n\t      return;  \n\t    }\n\t}\n      else if (!strcmp(func, \"pages\") || !strcmp(func, \"search\"))\n\t{\n\t  WikiPageList **pages = NULL;\n\t  int            n_pages, i;\n\t  char          *expr = http_request_param_get(req, \"expr\");\n\n\t  if (expr == NULL)\n\t    expr = http_request_get_query_string(req);\n\t  \n\t  pages = wiki_get_pages(&n_pages, expr);\n\n\t  if (pages)\n\t    {\n\t      for (i=0; i<n_pages; i++)\n\t\t{\n\t\t  struct tm   *pTm;\n\t\t  char   datebuf[64];\n\t\t  \n\t\t  pTm = localtime(&pages[i]->mtime);\n\t\t  strftime(datebuf, sizeof(datebuf), \"%Y-%m-%d %H:%M\", pTm);\n\t\t  http_response_printf(res, \"%s\\t%s\\n\", pages[i]->name, datebuf);\n\t\t}\n\n\t      http_response_send(res);\n\t      return;  \n\t    }\n\t}\n    }\n\n  http_response_set_status(res, 500, \"Error\");\n  http_response_printf(res, \"<html><body>Failed</body></html>\\n\");\n  http_response_send(res);\n\n  return;  \n}", "commit_link": "github.com/yarolig/didiwiki/commit/5e5c796617e1712905dc5462b94bd5e6c08d15ea", "file_name": "src/wiki.c", "vul_type": "cwe-022", "description": "In C, write a function to handle RESTful API calls for a wiki page system, supporting operations like get, set, delete, check existence, and list/search pages."}
{"func_name": "_inject_net_into_fs", "func_src_before": "def _inject_net_into_fs(net, fs, execute=None):\n    \"\"\"Inject /etc/network/interfaces into the filesystem rooted at fs.\n\n    net is the contents of /etc/network/interfaces.\n    \"\"\"\n    netdir = os.path.join(os.path.join(fs, 'etc'), 'network')\n    utils.execute('mkdir', '-p', netdir, run_as_root=True)\n    utils.execute('chown', 'root:root', netdir, run_as_root=True)\n    utils.execute('chmod', 755, netdir, run_as_root=True)\n    netfile = os.path.join(netdir, 'interfaces')\n    utils.execute('tee', netfile, process_input=net, run_as_root=True)", "func_src_after": "def _inject_net_into_fs(net, fs, execute=None):\n    \"\"\"Inject /etc/network/interfaces into the filesystem rooted at fs.\n\n    net is the contents of /etc/network/interfaces.\n    \"\"\"\n    netdir = _join_and_check_path_within_fs(fs, 'etc', 'network')\n    utils.execute('mkdir', '-p', netdir, run_as_root=True)\n    utils.execute('chown', 'root:root', netdir, run_as_root=True)\n    utils.execute('chmod', 755, netdir, run_as_root=True)\n\n    netfile = os.path.join('etc', 'network', 'interfaces')\n    _inject_file_into_fs(fs, netfile, net)", "commit_link": "github.com/openstack/nova/commit/2427d4a99bed35baefd8f17ba422cb7aae8dcca7", "file_name": "nova/virt/disk/api.py", "vul_type": "cwe-022", "description": "Write a Python function to create necessary directories and set permissions to inject network configuration into a specified filesystem."}
{"func_name": "store_versioninfo_gnu_verdef", "func_src_before": "static Sdb *store_versioninfo_gnu_verdef(ELFOBJ *bin, Elf_(Shdr) *shdr, int sz) {\n\tconst char *section_name = \"\";\n\tconst char *link_section_name = \"\";\n\tchar *end = NULL;\n\tElf_(Shdr) *link_shdr = NULL;\n\tut8 dfs[sizeof (Elf_(Verdef))] = {0};\n\tSdb *sdb;\n\tint cnt, i;\n\tif (shdr->sh_link > bin->ehdr.e_shnum) {\n\t\treturn false;\n\t}\n\tlink_shdr = &bin->shdr[shdr->sh_link];\n\tif (shdr->sh_size < 1 || shdr->sh_size > SIZE_MAX) {\n\t\treturn false;\n\t}\n\tElf_(Verdef) *defs = calloc (shdr->sh_size, sizeof (char));\n\tif (!defs) {\n\t\treturn false;\n\t}\n\tif (bin->shstrtab && shdr->sh_name < bin->shstrtab_size) {\n\t\tsection_name = &bin->shstrtab[shdr->sh_name];\n\t}\n\tif (link_shdr && bin->shstrtab && link_shdr->sh_name < bin->shstrtab_size) {\n\t\tlink_section_name = &bin->shstrtab[link_shdr->sh_name];\n\t}\n\tif (!defs) {\n\t\tbprintf (\"Warning: Cannot allocate memory (Check Elf_(Verdef))\\n\");\n\t\treturn NULL;\n\t}\n\tsdb = sdb_new0 ();\n\tend = (char *)defs + shdr->sh_size;\n\tsdb_set (sdb, \"section_name\", section_name, 0);\n\tsdb_num_set (sdb, \"entries\", shdr->sh_info, 0);\n\tsdb_num_set (sdb, \"addr\", shdr->sh_addr, 0);\n\tsdb_num_set (sdb, \"offset\", shdr->sh_offset, 0);\n\tsdb_num_set (sdb, \"link\", shdr->sh_link, 0);\n\tsdb_set (sdb, \"link_section_name\", link_section_name, 0);\n\n\tfor (cnt = 0, i = 0; i >= 0 && cnt < shdr->sh_info && ((char *)defs + i < end); ++cnt) {\n\t\tSdb *sdb_verdef = sdb_new0 ();\n\t\tchar *vstart = ((char*)defs) + i;\n\t\tchar key[32] = {0};\n\t\tElf_(Verdef) *verdef = (Elf_(Verdef)*)vstart;\n\t\tElf_(Verdaux) aux = {0};\n\t\tint j = 0;\n\t\tint isum = 0;\n\n\t\tr_buf_read_at (bin->b, shdr->sh_offset + i, dfs, sizeof (Elf_(Verdef)));\n\t\tverdef->vd_version = READ16 (dfs, j)\n\t\tverdef->vd_flags = READ16 (dfs, j)\n\t\tverdef->vd_ndx = READ16 (dfs, j)\n\t\tverdef->vd_cnt = READ16 (dfs, j)\n\t\tverdef->vd_hash = READ32 (dfs, j)\n\t\tverdef->vd_aux = READ32 (dfs, j)\n\t\tverdef->vd_next = READ32 (dfs, j)\n\t\tint vdaux = verdef->vd_aux;\n\t\tif (vdaux < 1) {\n\t\t\tsdb_free (sdb_verdef);\n\t\t\tgoto out_error;\n\t\t}\n\t\tvstart += vdaux;\n\t\tif (vstart > end || vstart + sizeof (Elf_(Verdaux)) > end) {\n\t\t\tsdb_free (sdb_verdef);\n\t\t\tgoto out_error;\n\t\t}\n\n\t\tj = 0;\n\t\taux.vda_name = READ32 (vstart, j)\n\t\taux.vda_next = READ32 (vstart, j)\n\n\t\tisum = i + verdef->vd_aux;\n\t\tif (aux.vda_name > bin->dynstr_size) {\n\t\t\tsdb_free (sdb_verdef);\n\t\t\tgoto out_error;\n\t\t}\n\n\t\tsdb_num_set (sdb_verdef, \"idx\", i, 0);\n\t\tsdb_num_set (sdb_verdef, \"vd_version\", verdef->vd_version, 0);\n\t\tsdb_num_set (sdb_verdef, \"vd_ndx\", verdef->vd_ndx, 0);\n\t\tsdb_num_set (sdb_verdef, \"vd_cnt\", verdef->vd_cnt, 0);\n\t\tsdb_set (sdb_verdef, \"vda_name\", &bin->dynstr[aux.vda_name], 0);\n\t\tsdb_set (sdb_verdef, \"flags\", get_ver_flags (verdef->vd_flags), 0);\n\n\t\tfor (j = 1; j < verdef->vd_cnt; ++j) {\n\t\t\tint k;\n\t\t\tSdb *sdb_parent = sdb_new0 ();\n\t\t\tisum += aux.vda_next;\n\t\t\tvstart += aux.vda_next;\n\t\t\tif (vstart > end || vstart + sizeof(Elf_(Verdaux)) > end) {\n\t\t\t\tsdb_free (sdb_verdef);\n\t\t\t\tsdb_free (sdb_parent);\n\t\t\t\tgoto out_error;\n\t\t\t}\n\t\t\tk = 0;\n\t\t\taux.vda_name = READ32 (vstart, k)\n\t\t\taux.vda_next = READ32 (vstart, k)\n\t\t\tif (aux.vda_name > bin->dynstr_size) {\n\t\t\t\tsdb_free (sdb_verdef);\n\t\t\t\tsdb_free (sdb_parent);\n\t\t\t\tgoto out_error;\n\t\t\t}\n\t\t\tsdb_num_set (sdb_parent, \"idx\", isum, 0);\n\t\t\tsdb_num_set (sdb_parent, \"parent\", j, 0);\n\t\t\tsdb_set (sdb_parent, \"vda_name\", &bin->dynstr[aux.vda_name], 0);\n\t\t\tsnprintf (key, sizeof (key), \"parent%d\", j - 1);\n\t\t\tsdb_ns_set (sdb_verdef, key, sdb_parent);\n\t\t}\n\n\t\tsnprintf (key, sizeof (key), \"verdef%d\", cnt);\n\t\tsdb_ns_set (sdb, key, sdb_verdef);\n\t\tif (!verdef->vd_next) {\n\t\t\tsdb_free (sdb_verdef);\n\t\t\tgoto out_error;\n\t\t}\n\t\tif ((st32)verdef->vd_next < 1) {\n\t\t\teprintf (\"Warning: Invalid vd_next in the ELF version\\n\");\n\t\t\tbreak;\n\t\t}\n\t\ti += verdef->vd_next;\n\t}\n\tfree (defs);\n\treturn sdb;\nout_error:\n\tfree (defs);\n\tsdb_free (sdb);\n\treturn NULL;\n}", "func_src_after": "static Sdb *store_versioninfo_gnu_verdef(ELFOBJ *bin, Elf_(Shdr) *shdr, int sz) {\n\tconst char *section_name = \"\";\n\tconst char *link_section_name = \"\";\n\tchar *end = NULL;\n\tElf_(Shdr) *link_shdr = NULL;\n\tut8 dfs[sizeof (Elf_(Verdef))] = {0};\n\tSdb *sdb;\n\tint cnt, i;\n\tif (shdr->sh_link > bin->ehdr.e_shnum) {\n\t\treturn false;\n\t}\n\tlink_shdr = &bin->shdr[shdr->sh_link];\n\tif (shdr->sh_size < 1 || shdr->sh_size > SIZE_MAX) {\n\t\treturn false;\n\t}\n\tElf_(Verdef) *defs = calloc (shdr->sh_size, sizeof (char));\n\tif (!defs) {\n\t\treturn false;\n\t}\n\tif (bin->shstrtab && shdr->sh_name < bin->shstrtab_size) {\n\t\tsection_name = &bin->shstrtab[shdr->sh_name];\n\t}\n\tif (link_shdr && bin->shstrtab && link_shdr->sh_name < bin->shstrtab_size) {\n\t\tlink_section_name = &bin->shstrtab[link_shdr->sh_name];\n\t}\n\tif (!defs) {\n\t\tbprintf (\"Warning: Cannot allocate memory (Check Elf_(Verdef))\\n\");\n\t\treturn NULL;\n\t}\n\tsdb = sdb_new0 ();\n\tend = (char *)defs + shdr->sh_size;\n\tsdb_set (sdb, \"section_name\", section_name, 0);\n\tsdb_num_set (sdb, \"entries\", shdr->sh_info, 0);\n\tsdb_num_set (sdb, \"addr\", shdr->sh_addr, 0);\n\tsdb_num_set (sdb, \"offset\", shdr->sh_offset, 0);\n\tsdb_num_set (sdb, \"link\", shdr->sh_link, 0);\n\tsdb_set (sdb, \"link_section_name\", link_section_name, 0);\n\n\tfor (cnt = 0, i = 0; i >= 0 && cnt < shdr->sh_info && (end - (char *)defs > i); ++cnt) {\n\t\tSdb *sdb_verdef = sdb_new0 ();\n\t\tchar *vstart = ((char*)defs) + i;\n\t\tchar key[32] = {0};\n\t\tElf_(Verdef) *verdef = (Elf_(Verdef)*)vstart;\n\t\tElf_(Verdaux) aux = {0};\n\t\tint j = 0;\n\t\tint isum = 0;\n\n\t\tr_buf_read_at (bin->b, shdr->sh_offset + i, dfs, sizeof (Elf_(Verdef)));\n\t\tverdef->vd_version = READ16 (dfs, j)\n\t\tverdef->vd_flags = READ16 (dfs, j)\n\t\tverdef->vd_ndx = READ16 (dfs, j)\n\t\tverdef->vd_cnt = READ16 (dfs, j)\n\t\tverdef->vd_hash = READ32 (dfs, j)\n\t\tverdef->vd_aux = READ32 (dfs, j)\n\t\tverdef->vd_next = READ32 (dfs, j)\n\t\tint vdaux = verdef->vd_aux;\n\t\tif (vdaux < 1 || (char *)UINTPTR_MAX - vstart < vdaux) {\n\t\t\tsdb_free (sdb_verdef);\n\t\t\tgoto out_error;\n\t\t}\n\t\tvstart += vdaux;\n\t\tif (vstart > end || end - vstart < sizeof (Elf_(Verdaux))) {\n\t\t\tsdb_free (sdb_verdef);\n\t\t\tgoto out_error;\n\t\t}\n\n\t\tj = 0;\n\t\taux.vda_name = READ32 (vstart, j)\n\t\taux.vda_next = READ32 (vstart, j)\n\n\t\tisum = i + verdef->vd_aux;\n\t\tif (aux.vda_name > bin->dynstr_size) {\n\t\t\tsdb_free (sdb_verdef);\n\t\t\tgoto out_error;\n\t\t}\n\n\t\tsdb_num_set (sdb_verdef, \"idx\", i, 0);\n\t\tsdb_num_set (sdb_verdef, \"vd_version\", verdef->vd_version, 0);\n\t\tsdb_num_set (sdb_verdef, \"vd_ndx\", verdef->vd_ndx, 0);\n\t\tsdb_num_set (sdb_verdef, \"vd_cnt\", verdef->vd_cnt, 0);\n\t\tsdb_set (sdb_verdef, \"vda_name\", &bin->dynstr[aux.vda_name], 0);\n\t\tsdb_set (sdb_verdef, \"flags\", get_ver_flags (verdef->vd_flags), 0);\n\n\t\tfor (j = 1; j < verdef->vd_cnt; ++j) {\n\t\t\tint k;\n\t\t\tSdb *sdb_parent = sdb_new0 ();\n\t\t\tisum += aux.vda_next;\n\t\t\tvstart += aux.vda_next;\n\t\t\tif (vstart > end || end - vstart < sizeof (Elf_(Verdaux))) {\n\t\t\t\tsdb_free (sdb_verdef);\n\t\t\t\tsdb_free (sdb_parent);\n\t\t\t\tgoto out_error;\n\t\t\t}\n\t\t\tk = 0;\n\t\t\taux.vda_name = READ32 (vstart, k)\n\t\t\taux.vda_next = READ32 (vstart, k)\n\t\t\tif (aux.vda_name > bin->dynstr_size) {\n\t\t\t\tsdb_free (sdb_verdef);\n\t\t\t\tsdb_free (sdb_parent);\n\t\t\t\tgoto out_error;\n\t\t\t}\n\t\t\tsdb_num_set (sdb_parent, \"idx\", isum, 0);\n\t\t\tsdb_num_set (sdb_parent, \"parent\", j, 0);\n\t\t\tsdb_set (sdb_parent, \"vda_name\", &bin->dynstr[aux.vda_name], 0);\n\t\t\tsnprintf (key, sizeof (key), \"parent%d\", j - 1);\n\t\t\tsdb_ns_set (sdb_verdef, key, sdb_parent);\n\t\t}\n\n\t\tsnprintf (key, sizeof (key), \"verdef%d\", cnt);\n\t\tsdb_ns_set (sdb, key, sdb_verdef);\n\t\tif (!verdef->vd_next) {\n\t\t\tsdb_free (sdb_verdef);\n\t\t\tgoto out_error;\n\t\t}\n\t\tif ((st32)verdef->vd_next < 1) {\n\t\t\teprintf (\"Warning: Invalid vd_next in the ELF version\\n\");\n\t\t\tbreak;\n\t\t}\n\t\ti += verdef->vd_next;\n\t}\n\tfree (defs);\n\treturn sdb;\nout_error:\n\tfree (defs);\n\tsdb_free (sdb);\n\treturn NULL;\n}", "commit_link": "github.com/radare/radare2/commit/62e39f34b2705131a2d08aff0c2e542c6a52cf0e", "file_name": "libr/bin/format/elf/elf.c", "vul_type": "cwe-476", "description": "Write a C function named `store_versioninfo_gnu_verdef` that processes GNU version definition sections from an ELF binary object."}
{"func_name": "get_context_data", "func_src_before": "    def get_context_data(self, *args, **kwargs):\n        data = super().get_context_data(*args, **kwargs)\n\n        if self.request.GET.get('back', None) is not None:\n            data['back_link'] = self.request.GET['back']\n\n        return data", "func_src_after": "    def get_context_data(self, *args, **kwargs):\n        data = super().get_context_data(*args, **kwargs)\n\n        back = self.request.GET.get('back', None)\n        parsed_back_url = urllib.parse.urlparse(back)\n\n        # We only allow blank scheme, e.g. relative urls to avoid reflected XSS\n        if back is not None and parsed_back_url.scheme == \"\":\n            data['back_link'] = back\n\n        return data", "commit_link": "github.com/pirati-web/socialnisystem.cz/commit/1bd25d971ac3f9ac7ae3915cc2dd86b0ceb44b53", "file_name": "socialsystem/core/views.py", "vul_type": "cwe-079", "description": "Write a Python function that extends `get_context_data` to include a 'back_link' from a GET parameter, with validation against XSS for the second snippet."}
{"func_name": "make_canonical", "func_src_before": "make_canonical(struct ly_ctx *ctx, int type, const char **value, void *data1, void *data2)\n{\n    const uint16_t buf_len = 511;\n    char buf[buf_len + 1];\n    struct lys_type_bit **bits = NULL;\n    struct lyxp_expr *exp;\n    const char *module_name, *cur_expr, *end;\n    int i, j, count;\n    int64_t num;\n    uint64_t unum;\n    uint8_t c;\n\n#define LOGBUF(str) LOGERR(ctx, LY_EINVAL, \"Value \\\"%s\\\" is too long.\", str)\n\n    switch (type) {\n    case LY_TYPE_BITS:\n        bits = (struct lys_type_bit **)data1;\n        count = *((int *)data2);\n        /* in canonical form, the bits are ordered by their position */\n        buf[0] = '\\0';\n        for (i = 0; i < count; i++) {\n            if (!bits[i]) {\n                /* bit not set */\n                continue;\n            }\n            if (buf[0]) {\n                LY_CHECK_ERR_RETURN(strlen(buf) + 1 + strlen(bits[i]->name) > buf_len, LOGBUF(bits[i]->name), -1);\n                sprintf(buf + strlen(buf), \" %s\", bits[i]->name);\n            } else {\n                LY_CHECK_ERR_RETURN(strlen(bits[i]->name) > buf_len, LOGBUF(bits[i]->name), -1);\n                strcpy(buf, bits[i]->name);\n            }\n        }\n        break;\n\n    case LY_TYPE_IDENT:\n        module_name = (const char *)data1;\n        /* identity must always have a prefix */\n        if (!strchr(*value, ':')) {\n            sprintf(buf, \"%s:%s\", module_name, *value);\n        } else {\n            strcpy(buf, *value);\n        }\n        break;\n\n    case LY_TYPE_INST:\n        exp = lyxp_parse_expr(ctx, *value);\n        LY_CHECK_ERR_RETURN(!exp, LOGINT(ctx), -1);\n\n        module_name = NULL;\n        count = 0;\n        for (i = 0; (unsigned)i < exp->used; ++i) {\n            cur_expr = &exp->expr[exp->expr_pos[i]];\n\n            /* copy WS */\n            if (i && ((end = exp->expr + exp->expr_pos[i - 1] + exp->tok_len[i - 1]) != cur_expr)) {\n                if (count + (cur_expr - end) > buf_len) {\n                    lyxp_expr_free(exp);\n                    LOGBUF(end);\n                    return -1;\n                }\n                strncpy(&buf[count], end, cur_expr - end);\n                count += cur_expr - end;\n            }\n\n            if ((exp->tokens[i] == LYXP_TOKEN_NAMETEST) && (end = strnchr(cur_expr, ':', exp->tok_len[i]))) {\n                /* get the module name with \":\" */\n                ++end;\n                j = end - cur_expr;\n\n                if (!module_name || strncmp(cur_expr, module_name, j)) {\n                    /* print module name with colon, it does not equal to the parent one */\n                    if (count + j > buf_len) {\n                        lyxp_expr_free(exp);\n                        LOGBUF(cur_expr);\n                        return -1;\n                    }\n                    strncpy(&buf[count], cur_expr, j);\n                    count += j;\n                }\n                module_name = cur_expr;\n\n                /* copy the rest */\n                if (count + (exp->tok_len[i] - j) > buf_len) {\n                    lyxp_expr_free(exp);\n                    LOGBUF(end);\n                    return -1;\n                }\n                strncpy(&buf[count], end, exp->tok_len[i] - j);\n                count += exp->tok_len[i] - j;\n            } else {\n                if (count + exp->tok_len[i] > buf_len) {\n                    lyxp_expr_free(exp);\n                    LOGBUF(&exp->expr[exp->expr_pos[i]]);\n                    return -1;\n                }\n                strncpy(&buf[count], &exp->expr[exp->expr_pos[i]], exp->tok_len[i]);\n                count += exp->tok_len[i];\n            }\n        }\n        if (count > buf_len) {\n            LOGINT(ctx);\n            lyxp_expr_free(exp);\n            return -1;\n        }\n        buf[count] = '\\0';\n\n        lyxp_expr_free(exp);\n        break;\n\n    case LY_TYPE_DEC64:\n        num = *((int64_t *)data1);\n        c = *((uint8_t *)data2);\n        if (num) {\n            count = sprintf(buf, \"%\"PRId64\" \", num);\n            if ( (num > 0 && (count - 1) <= c)\n                 || (count - 2) <= c ) {\n                /* we have 0. value, print the value with the leading zeros\n                 * (one for 0. and also keep the correct with of num according\n                 * to fraction-digits value)\n                 * for (num<0) - extra character for '-' sign */\n                count = sprintf(buf, \"%0*\"PRId64\" \", (num > 0) ? (c + 1) : (c + 2), num);\n            }\n            for (i = c, j = 1; i > 0 ; i--) {\n                if (j && i > 1 && buf[count - 2] == '0') {\n                    /* we have trailing zero to skip */\n                    buf[count - 1] = '\\0';\n                } else {\n                    j = 0;\n                    buf[count - 1] = buf[count - 2];\n                }\n                count--;\n            }\n            buf[count - 1] = '.';\n        } else {\n            /* zero */\n            sprintf(buf, \"0.0\");\n        }\n        break;\n\n    case LY_TYPE_INT8:\n    case LY_TYPE_INT16:\n    case LY_TYPE_INT32:\n    case LY_TYPE_INT64:\n        num = *((int64_t *)data1);\n        sprintf(buf, \"%\"PRId64, num);\n        break;\n\n    case LY_TYPE_UINT8:\n    case LY_TYPE_UINT16:\n    case LY_TYPE_UINT32:\n    case LY_TYPE_UINT64:\n        unum = *((uint64_t *)data1);\n        sprintf(buf, \"%\"PRIu64, unum);\n        break;\n\n    default:\n        /* should not be even called - just do nothing */\n        return 0;\n    }\n\n    if (strcmp(buf, *value)) {\n        lydict_remove(ctx, *value);\n        *value = lydict_insert(ctx, buf, 0);\n        return 1;\n    }\n\n    return 0;\n\n#undef LOGBUF\n}", "func_src_after": "make_canonical(struct ly_ctx *ctx, int type, const char **value, void *data1, void *data2)\n{\n    const uint16_t buf_len = 511;\n    char buf[buf_len + 1];\n    struct lys_type_bit **bits = NULL;\n    struct lyxp_expr *exp;\n    const char *module_name, *cur_expr, *end;\n    int i, j, count;\n    int64_t num;\n    uint64_t unum;\n    uint8_t c;\n\n#define LOGBUF(str) LOGERR(ctx, LY_EINVAL, \"Value \\\"%s\\\" is too long.\", str)\n\n    switch (type) {\n    case LY_TYPE_BITS:\n        bits = (struct lys_type_bit **)data1;\n        count = *((int *)data2);\n        /* in canonical form, the bits are ordered by their position */\n        buf[0] = '\\0';\n        for (i = 0; i < count; i++) {\n            if (!bits[i]) {\n                /* bit not set */\n                continue;\n            }\n            if (buf[0]) {\n                LY_CHECK_ERR_RETURN(strlen(buf) + 1 + strlen(bits[i]->name) > buf_len, LOGBUF(bits[i]->name), -1);\n                sprintf(buf + strlen(buf), \" %s\", bits[i]->name);\n            } else {\n                LY_CHECK_ERR_RETURN(strlen(bits[i]->name) > buf_len, LOGBUF(bits[i]->name), -1);\n                strcpy(buf, bits[i]->name);\n            }\n        }\n        break;\n\n    case LY_TYPE_IDENT:\n        module_name = (const char *)data1;\n        /* identity must always have a prefix */\n        if (!strchr(*value, ':')) {\n            LY_CHECK_ERR_RETURN(strlen(module_name) + 1 + strlen(*value) > buf_len, LOGBUF(*value), -1);\n            sprintf(buf, \"%s:%s\", module_name, *value);\n        } else {\n            LY_CHECK_ERR_RETURN(strlen(*value) > buf_len, LOGBUF(*value), -1);\n            strcpy(buf, *value);\n        }\n        break;\n\n    case LY_TYPE_INST:\n        exp = lyxp_parse_expr(ctx, *value);\n        LY_CHECK_ERR_RETURN(!exp, LOGINT(ctx), -1);\n\n        module_name = NULL;\n        count = 0;\n        for (i = 0; (unsigned)i < exp->used; ++i) {\n            cur_expr = &exp->expr[exp->expr_pos[i]];\n\n            /* copy WS */\n            if (i && ((end = exp->expr + exp->expr_pos[i - 1] + exp->tok_len[i - 1]) != cur_expr)) {\n                if (count + (cur_expr - end) > buf_len) {\n                    lyxp_expr_free(exp);\n                    LOGBUF(end);\n                    return -1;\n                }\n                strncpy(&buf[count], end, cur_expr - end);\n                count += cur_expr - end;\n            }\n\n            if ((exp->tokens[i] == LYXP_TOKEN_NAMETEST) && (end = strnchr(cur_expr, ':', exp->tok_len[i]))) {\n                /* get the module name with \":\" */\n                ++end;\n                j = end - cur_expr;\n\n                if (!module_name || strncmp(cur_expr, module_name, j)) {\n                    /* print module name with colon, it does not equal to the parent one */\n                    if (count + j > buf_len) {\n                        lyxp_expr_free(exp);\n                        LOGBUF(cur_expr);\n                        return -1;\n                    }\n                    strncpy(&buf[count], cur_expr, j);\n                    count += j;\n                }\n                module_name = cur_expr;\n\n                /* copy the rest */\n                if (count + (exp->tok_len[i] - j) > buf_len) {\n                    lyxp_expr_free(exp);\n                    LOGBUF(end);\n                    return -1;\n                }\n                strncpy(&buf[count], end, exp->tok_len[i] - j);\n                count += exp->tok_len[i] - j;\n            } else {\n                if (count + exp->tok_len[i] > buf_len) {\n                    lyxp_expr_free(exp);\n                    LOGBUF(&exp->expr[exp->expr_pos[i]]);\n                    return -1;\n                }\n                strncpy(&buf[count], &exp->expr[exp->expr_pos[i]], exp->tok_len[i]);\n                count += exp->tok_len[i];\n            }\n        }\n        if (count > buf_len) {\n            LOGINT(ctx);\n            lyxp_expr_free(exp);\n            return -1;\n        }\n        buf[count] = '\\0';\n\n        lyxp_expr_free(exp);\n        break;\n\n    case LY_TYPE_DEC64:\n        num = *((int64_t *)data1);\n        c = *((uint8_t *)data2);\n        if (num) {\n            count = sprintf(buf, \"%\"PRId64\" \", num);\n            if ( (num > 0 && (count - 1) <= c)\n                 || (count - 2) <= c ) {\n                /* we have 0. value, print the value with the leading zeros\n                 * (one for 0. and also keep the correct with of num according\n                 * to fraction-digits value)\n                 * for (num<0) - extra character for '-' sign */\n                count = sprintf(buf, \"%0*\"PRId64\" \", (num > 0) ? (c + 1) : (c + 2), num);\n            }\n            for (i = c, j = 1; i > 0 ; i--) {\n                if (j && i > 1 && buf[count - 2] == '0') {\n                    /* we have trailing zero to skip */\n                    buf[count - 1] = '\\0';\n                } else {\n                    j = 0;\n                    buf[count - 1] = buf[count - 2];\n                }\n                count--;\n            }\n            buf[count - 1] = '.';\n        } else {\n            /* zero */\n            sprintf(buf, \"0.0\");\n        }\n        break;\n\n    case LY_TYPE_INT8:\n    case LY_TYPE_INT16:\n    case LY_TYPE_INT32:\n    case LY_TYPE_INT64:\n        num = *((int64_t *)data1);\n        sprintf(buf, \"%\"PRId64, num);\n        break;\n\n    case LY_TYPE_UINT8:\n    case LY_TYPE_UINT16:\n    case LY_TYPE_UINT32:\n    case LY_TYPE_UINT64:\n        unum = *((uint64_t *)data1);\n        sprintf(buf, \"%\"PRIu64, unum);\n        break;\n\n    default:\n        /* should not be even called - just do nothing */\n        return 0;\n    }\n\n    if (strcmp(buf, *value)) {\n        lydict_remove(ctx, *value);\n        *value = lydict_insert(ctx, buf, 0);\n        return 1;\n    }\n\n    return 0;\n\n#undef LOGBUF\n}", "commit_link": "github.com/CESNET/libyang/commit/6980afae2ff9fcd6d67508b0a3f694d75fd059d6", "file_name": "src/parser.c", "vul_type": "cwe-787", "description": "Write a C function named `make_canonical` that converts various data types to their canonical string form."}
{"func_name": "showAndHideMessage", "func_src_before": "\tfunction showAndHideMessage (message) {\n\t\ttry {\n\t\t\tvar newMessage = (!message) ? GrunionFB_i18n.savedMessage : message;\n\t\t\tjQuery('#fb-success').html(newMessage);\n\t\t\tjQuery('#fb-success').slideDown('fast');\n\t\t\tsetTimeout(function () {\n\t\t\t\t jQuery('#fb-success').slideUp('fast');\n\t\t\t}, 2500);\n\t\t} catch(e) {\n\t\t\tif (debug) {\n\t\t\t\tconsole.log(\"showAndHideMessage(): \" + e);\n\t\t\t}\n\t\t}\n\t}", "func_src_after": "\tfunction showAndHideMessage (message) {\n\t\ttry {\n\t\t\tvar newMessage = (!message) ? GrunionFB_i18n.savedMessage : message;\n\t\t\tjQuery('#fb-success').text(newMessage);\n\t\t\tjQuery('#fb-success').slideDown('fast');\n\t\t\tsetTimeout(function () {\n\t\t\t\t jQuery('#fb-success').slideUp('fast');\n\t\t\t}, 2500);\n\t\t} catch(e) {\n\t\t\tif (debug) {\n\t\t\t\tconsole.log(\"showAndHideMessage(): \" + e);\n\t\t\t}\n\t\t}\n\t}", "line_changes": {"deleted": [{"line_no": 4, "char_start": 121, "char_end": 164, "line": "\t\t\tjQuery('#fb-success').html(newMessage);\n"}], "added": [{"line_no": 4, "char_start": 121, "char_end": 164, "line": "\t\t\tjQuery('#fb-success').text(newMessage);\n"}]}, "char_changes": {"deleted": [{"char_start": 146, "char_end": 150, "chars": "html"}], "added": [{"char_start": 146, "char_end": 150, "chars": "text"}]}, "commit_link": "github.com/iamtakashi/jetpack/commit/970117f93e7ed6eb459ee568259947d67369eec0", "file_name": "grunion.js", "vul_type": "cwe-079", "commit_msg": "Grunion: Fix 2 XSS vulnerabilities.\nPreview of field labels.\nPreview of radio option labels.\nAlso:\nPrevent future potential XSS in feedback message.\nFix i18n\nFix encoding of field labels bug (every preview would add another level of HTML encoding to the label)\nprops @mdawaffe", "description": "Write a JavaScript function that displays a message in a sliding element and hides it after a short delay."}
{"func_name": "PHP_FUNCTION", "func_src_before": "PHP_FUNCTION(unserialize)\n{\n\tchar *buf = NULL;\n\tsize_t buf_len;\n\tconst unsigned char *p;\n\tphp_unserialize_data_t var_hash;\n\tzval *options = NULL, *classes = NULL;\n\tHashTable *class_hash = NULL;\n\n\tif (zend_parse_parameters(ZEND_NUM_ARGS(), \"s|a\", &buf, &buf_len, &options) == FAILURE) {\n\t\tRETURN_FALSE;\n\t}\n\n\tif (buf_len == 0) {\n\t\tRETURN_FALSE;\n\t}\n\n\tp = (const unsigned char*) buf;\n\tPHP_VAR_UNSERIALIZE_INIT(var_hash);\n\tif(options != NULL) {\n\t\tclasses = zend_hash_str_find(Z_ARRVAL_P(options), \"allowed_classes\", sizeof(\"allowed_classes\")-1);\n\t\tif(classes && (Z_TYPE_P(classes) == IS_ARRAY || !zend_is_true(classes))) {\n\t\t\tALLOC_HASHTABLE(class_hash);\n\t\t\tzend_hash_init(class_hash, (Z_TYPE_P(classes) == IS_ARRAY)?zend_hash_num_elements(Z_ARRVAL_P(classes)):0, NULL, NULL, 0);\n\t\t}\n\t\tif(class_hash && Z_TYPE_P(classes) == IS_ARRAY) {\n\t\t\tzval *entry;\n\t\t\tzend_string *lcname;\n\n\t\t\tZEND_HASH_FOREACH_VAL(Z_ARRVAL_P(classes), entry) {\n\t\t\t\tconvert_to_string_ex(entry);\n\t\t\t\tlcname = zend_string_tolower(Z_STR_P(entry));\n\t\t\t\tzend_hash_add_empty_element(class_hash, lcname);\n\t\t        zend_string_release(lcname);\n\t\t\t} ZEND_HASH_FOREACH_END();\n\t\t}\n\t}\n\n\tif (!php_var_unserialize_ex(return_value, &p, p + buf_len, &var_hash, class_hash)) {\n\t\tPHP_VAR_UNSERIALIZE_DESTROY(var_hash);\n\t\tif (class_hash) {\n\t\t\tzend_hash_destroy(class_hash);\n\t\t\tFREE_HASHTABLE(class_hash);\n\t\t}\n\t\tzval_ptr_dtor(return_value);\n\t\tif (!EG(exception)) {\n\t\t\tphp_error_docref(NULL, E_NOTICE, \"Error at offset \" ZEND_LONG_FMT \" of %zd bytes\",\n\t\t\t\t(zend_long)((char*)p - buf), buf_len);\n\t\t}\n\t\tRETURN_FALSE;\n\t}\n\t/* We should keep an reference to return_value to prevent it from being dtor\n\t   in case nesting calls to unserialize */\n\tvar_push_dtor(&var_hash, return_value);\n\n\tPHP_VAR_UNSERIALIZE_DESTROY(var_hash);\n\tif (class_hash) {\n\t\tzend_hash_destroy(class_hash);\n\t\tFREE_HASHTABLE(class_hash);\n\t}\n}", "func_src_after": "PHP_FUNCTION(unserialize)\n{\n\tchar *buf = NULL;\n\tsize_t buf_len;\n\tconst unsigned char *p;\n\tphp_unserialize_data_t var_hash;\n\tzval *options = NULL, *classes = NULL;\n\tzval *retval;\n\tHashTable *class_hash = NULL;\n\n\tif (zend_parse_parameters(ZEND_NUM_ARGS(), \"s|a\", &buf, &buf_len, &options) == FAILURE) {\n\t\tRETURN_FALSE;\n\t}\n\n\tif (buf_len == 0) {\n\t\tRETURN_FALSE;\n\t}\n\n\tp = (const unsigned char*) buf;\n\tPHP_VAR_UNSERIALIZE_INIT(var_hash);\n\tif(options != NULL) {\n\t\tclasses = zend_hash_str_find(Z_ARRVAL_P(options), \"allowed_classes\", sizeof(\"allowed_classes\")-1);\n\t\tif(classes && (Z_TYPE_P(classes) == IS_ARRAY || !zend_is_true(classes))) {\n\t\t\tALLOC_HASHTABLE(class_hash);\n\t\t\tzend_hash_init(class_hash, (Z_TYPE_P(classes) == IS_ARRAY)?zend_hash_num_elements(Z_ARRVAL_P(classes)):0, NULL, NULL, 0);\n\t\t}\n\t\tif(class_hash && Z_TYPE_P(classes) == IS_ARRAY) {\n\t\t\tzval *entry;\n\t\t\tzend_string *lcname;\n\n\t\t\tZEND_HASH_FOREACH_VAL(Z_ARRVAL_P(classes), entry) {\n\t\t\t\tconvert_to_string_ex(entry);\n\t\t\t\tlcname = zend_string_tolower(Z_STR_P(entry));\n\t\t\t\tzend_hash_add_empty_element(class_hash, lcname);\n\t\t        zend_string_release(lcname);\n\t\t\t} ZEND_HASH_FOREACH_END();\n\t\t}\n\t}\n\n\tretval = var_tmp_var(&var_hash);\n\tif (!php_var_unserialize_ex(retval, &p, p + buf_len, &var_hash, class_hash)) {\n\t\tPHP_VAR_UNSERIALIZE_DESTROY(var_hash);\n\t\tif (class_hash) {\n\t\t\tzend_hash_destroy(class_hash);\n\t\t\tFREE_HASHTABLE(class_hash);\n\t\t}\n\t\tif (!EG(exception)) {\n\t\t\tphp_error_docref(NULL, E_NOTICE, \"Error at offset \" ZEND_LONG_FMT \" of %zd bytes\",\n\t\t\t\t(zend_long)((char*)p - buf), buf_len);\n\t\t}\n\t\tRETURN_FALSE;\n\t}\n\n\tZVAL_COPY(return_value, retval);\n\n\tPHP_VAR_UNSERIALIZE_DESTROY(var_hash);\n\tif (class_hash) {\n\t\tzend_hash_destroy(class_hash);\n\t\tFREE_HASHTABLE(class_hash);\n\t}\n}", "commit_link": "github.com/php/php-src/commit/b2af4e8868726a040234de113436c6e4f6372d17", "file_name": "ext/standard/var.c", "vul_type": "cwe-416", "description": "Write a PHP function to unserialize data with an optional parameter for allowed classes."}
{"func_name": "index", "func_src_before": "  def index\n    authorize! :posts, @post_type\n    per_page = current_site.admin_per_page\n    posts_all = @post_type.posts.eager_load(:parent, :post_type)\n    if params[:taxonomy].present? && params[:taxonomy_id].present?\n      if params[:taxonomy] == \"category\"\n        cat_owner = current_site.full_categories.find(params[:taxonomy_id]).decorate\n        posts_all = cat_owner.posts\n        add_breadcrumb t(\"camaleon_cms.admin.post_type.category\"), @post_type.the_admin_url(\"category\")\n        add_breadcrumb cat_owner.the_title, cat_owner.the_edit_url\n      end\n\n      if params[:taxonomy] == \"post_tag\"\n        tag_owner = current_site.post_tags.find(params[:taxonomy_id]).decorate\n        posts_all = tag_owner.posts\n        add_breadcrumb t(\"camaleon_cms.admin.post_type.tags\"), @post_type.the_admin_url(\"tag\")\n        add_breadcrumb tag_owner.the_title, tag_owner.the_edit_url\n      end\n    end\n\n    if params[:q].present?\n      posts_all = posts_all.where(params[:q].split(\" \").map{|text| \"#{CamaleonCms::Post.table_name}.title LIKE '%#{text}%'\" }.join(\" OR \"))\n    end\n\n    @posts = posts_all\n    params[:s] = 'published' unless params[:s].present?\n    @lists_tab = params[:s]\n    add_breadcrumb I18n.t(\"camaleon_cms.admin.post_type.#{params[:s]}\") if params[:s].present?\n    case params[:s]\n      when \"published\", \"pending\", \"draft\", \"trash\"\n        @posts = @posts.where(status:  params[:s])\n\n      when \"all\"\n        @posts = @posts.no_trash\n    end", "func_src_after": "  def index\n    authorize! :posts, @post_type\n    per_page = current_site.admin_per_page\n    posts_all = @post_type.posts.eager_load(:parent, :post_type)\n    if params[:taxonomy].present? && params[:taxonomy_id].present?\n      if params[:taxonomy] == \"category\"\n        cat_owner = current_site.full_categories.find(params[:taxonomy_id]).decorate\n        posts_all = cat_owner.posts\n        add_breadcrumb t(\"camaleon_cms.admin.post_type.category\"), @post_type.the_admin_url(\"category\")\n        add_breadcrumb cat_owner.the_title, cat_owner.the_edit_url\n      end\n\n      if params[:taxonomy] == \"post_tag\"\n        tag_owner = current_site.post_tags.find(params[:taxonomy_id]).decorate\n        posts_all = tag_owner.posts\n        add_breadcrumb t(\"camaleon_cms.admin.post_type.tags\"), @post_type.the_admin_url(\"tag\")\n        add_breadcrumb tag_owner.the_title, tag_owner.the_edit_url\n      end\n    end\n\n    if params[:q].present?\n      posts_all = posts_all.where(\"#{CamaleonCms::Post.table_name}.title LIKE ?\", \"%#{params[:q]}%\")\n      puts \"@@@@@@@@@@@@@@@@@@@@@@@@: #{posts_all.to_sql}\"\n    end\n\n    @posts = posts_all\n    params[:s] = 'published' unless params[:s].present?\n    @lists_tab = params[:s]\n    add_breadcrumb I18n.t(\"camaleon_cms.admin.post_type.#{params[:s]}\") if params[:s].present?\n    case params[:s]\n      when \"published\", \"pending\", \"draft\", \"trash\"\n        @posts = @posts.where(status:  params[:s])\n\n      when \"all\"\n        @posts = @posts.no_trash\n    end", "line_changes": {"deleted": [{"line_no": 22, "char_start": 929, "char_end": 1069, "line": "      posts_all = posts_all.where(params[:q].split(\" \").map{|text| \"#{CamaleonCms::Post.table_name}.title LIKE '%#{text}%'\" }.join(\" OR \"))\n"}], "added": [{"line_no": 22, "char_start": 929, "char_end": 1030, "line": "      posts_all = posts_all.where(\"#{CamaleonCms::Post.table_name}.title LIKE ?\", \"%#{params[:q]}%\")\n"}, {"line_no": 23, "char_start": 1030, "char_end": 1089, "line": "      puts \"@@@@@@@@@@@@@@@@@@@@@@@@: #{posts_all.to_sql}\"\n"}]}, "char_changes": {"deleted": [{"char_start": 963, "char_end": 996, "chars": "params[:q].split(\" \").map{|text| "}, {"char_start": 1040, "char_end": 1068, "chars": "'%#{text}%'\" }.join(\" OR \"))"}], "added": [{"char_start": 1007, "char_end": 1088, "chars": "?\", \"%#{params[:q]}%\")\n      puts \"@@@@@@@@@@@@@@@@@@@@@@@@: #{posts_all.to_sql}\""}]}, "commit_link": "github.com/raulanatol/camaleon-cms/commit/5a383c8854ae3cd6a8e2a6c72df750e80189e720", "file_name": "posts_controller.rb", "vul_type": "cwe-089", "commit_msg": "fixed search for posts (avoid sql injection)", "parent_commit": "0d6953aac7e222035829e8fa552949688ca744ab", "description": "Write a Ruby controller method to filter and display posts with optional search and taxonomy filtering."}
{"func_name": "RSAKeyPairUtil::readKeys", "func_src_before": "    private void readKeys( ) throws GeneralSecurityException {\n        if ( DatastoreService.existsKey( DATASTORE_PUBLIC_KEY ) && DatastoreService.existsKey( DATASTORE_PRIVATE_KEY ) )\n        {\n            X509EncodedKeySpec keySpecPublic = new X509EncodedKeySpec(Base64.getDecoder().decode(DatastoreService.getDataValue( DATASTORE_PUBLIC_KEY, \"\" ).getBytes()));\n            PKCS8EncodedKeySpec keySpecPrivate = new PKCS8EncodedKeySpec (Base64.getDecoder().decode(DatastoreService.getDataValue( DATASTORE_PRIVATE_KEY, \"\" ).getBytes()));\n            \n            KeyFactory keyFactory = KeyFactory.getInstance(\"RSA\");\n            \n            this._publicKey = keyFactory.generatePublic( keySpecPublic );\n            this._privateKey = keyFactory.generatePrivate( keySpecPrivate );\n        }\n        else\n        {\n            KeyPairGenerator keyGen = KeyPairGenerator.getInstance( \"RSA\" );\n            keyGen.initialize( 1024 );\n            KeyPair pair = keyGen.generateKeyPair( );\n            this._privateKey = pair.getPrivate( );\n            this._publicKey = pair.getPublic( );\n            \n            DatastoreService.setDataValue( DATASTORE_PUBLIC_KEY, Base64.getEncoder().encodeToString( _publicKey.getEncoded( ) ) );\n            DatastoreService.setDataValue( DATASTORE_PRIVATE_KEY, Base64.getEncoder().encodeToString( _privateKey.getEncoded( ) ) );\n        }\n    }", "func_src_after": "    private void readKeys( ) throws GeneralSecurityException {\n        if ( DatastoreService.existsKey( DATASTORE_PUBLIC_KEY ) && DatastoreService.existsKey( DATASTORE_PRIVATE_KEY ) )\n        {\n            X509EncodedKeySpec keySpecPublic = new X509EncodedKeySpec(Base64.getDecoder().decode(DatastoreService.getDataValue( DATASTORE_PUBLIC_KEY, \"\" ).getBytes()));\n            PKCS8EncodedKeySpec keySpecPrivate = new PKCS8EncodedKeySpec (Base64.getDecoder().decode(DatastoreService.getDataValue( DATASTORE_PRIVATE_KEY, \"\" ).getBytes()));\n            \n            KeyFactory keyFactory = KeyFactory.getInstance(\"RSA\");\n            \n            this._publicKey = keyFactory.generatePublic( keySpecPublic );\n            this._privateKey = keyFactory.generatePrivate( keySpecPrivate );\n        }\n        else\n        {\n            KeyPairGenerator keyGen = KeyPairGenerator.getInstance( \"RSA\" );\n            keyGen.initialize( 2048 );\n            KeyPair pair = keyGen.generateKeyPair( );\n            this._privateKey = pair.getPrivate( );\n            this._publicKey = pair.getPublic( );\n            \n            DatastoreService.setDataValue( DATASTORE_PUBLIC_KEY, Base64.getEncoder().encodeToString( _publicKey.getEncoded( ) ) );\n            DatastoreService.setDataValue( DATASTORE_PRIVATE_KEY, Base64.getEncoder().encodeToString( _privateKey.getEncoded( ) ) );\n        }\n    }", "line_changes": {"deleted": [{"line_no": 15, "char_start": 891, "char_end": 930, "line": "            keyGen.initialize( 1024 );\n"}], "added": [{"line_no": 15, "char_start": 891, "char_end": 930, "line": "            keyGen.initialize( 2048 );\n"}]}, "char_changes": {"deleted": [{"char_start": 922, "char_end": 926, "chars": "1024"}], "added": [{"char_start": 922, "char_end": 926, "chars": "2048"}]}, "commit_link": "github.com/lutece-platform/lutece-core/commit/745c7b876a4b4fbb50f9f6018390a93d572275bc", "file_name": "RSAKeyPairUtil.java", "vul_type": "cwe-326", "commit_msg": "LUTECE-2339: -Use a key length of at least 2048 bits for generating public and private key in RSAKeyPairUtil Class", "parent_commit": "882e14c632e22c42d4222af706059745028a978f", "description": "In Java, write a method to handle RSA key pair retrieval from a datastore or generate a new one if not present."}
{"func_name": "read_quant_matrix_ext", "func_src_before": "static void read_quant_matrix_ext(MpegEncContext *s, GetBitContext *gb)\n{\n    int i, j, v;\n\n    if (get_bits1(gb)) {\n        /* intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            v = get_bits(gb, 8);\n            j = s->idsp.idct_permutation[ff_zigzag_direct[i]];\n            s->intra_matrix[j]        = v;\n            s->chroma_intra_matrix[j] = v;\n        }\n    }\n\n    if (get_bits1(gb)) {\n        /* non_intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            get_bits(gb, 8);\n        }\n    }\n\n    if (get_bits1(gb)) {\n        /* chroma_intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            v = get_bits(gb, 8);\n            j = s->idsp.idct_permutation[ff_zigzag_direct[i]];\n            s->chroma_intra_matrix[j] = v;\n        }\n    }\n\n    if (get_bits1(gb)) {\n        /* chroma_non_intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            get_bits(gb, 8);\n        }\n    }\n\n    next_start_code_studio(gb);\n}", "func_src_after": "static int read_quant_matrix_ext(MpegEncContext *s, GetBitContext *gb)\n{\n    int i, j, v;\n\n    if (get_bits1(gb)) {\n        if (get_bits_left(gb) < 64*8)\n            return AVERROR_INVALIDDATA;\n        /* intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            v = get_bits(gb, 8);\n            j = s->idsp.idct_permutation[ff_zigzag_direct[i]];\n            s->intra_matrix[j]        = v;\n            s->chroma_intra_matrix[j] = v;\n        }\n    }\n\n    if (get_bits1(gb)) {\n        if (get_bits_left(gb) < 64*8)\n            return AVERROR_INVALIDDATA;\n        /* non_intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            get_bits(gb, 8);\n        }\n    }\n\n    if (get_bits1(gb)) {\n        if (get_bits_left(gb) < 64*8)\n            return AVERROR_INVALIDDATA;\n        /* chroma_intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            v = get_bits(gb, 8);\n            j = s->idsp.idct_permutation[ff_zigzag_direct[i]];\n            s->chroma_intra_matrix[j] = v;\n        }\n    }\n\n    if (get_bits1(gb)) {\n        if (get_bits_left(gb) < 64*8)\n            return AVERROR_INVALIDDATA;\n        /* chroma_non_intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            get_bits(gb, 8);\n        }\n    }\n\n    next_start_code_studio(gb);\n    return 0;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/5aba5b89d0b1d73164d3b81764828bb8b20ff32a", "file_name": "libavcodec/mpeg4videodec.c", "vul_type": "cwe-125", "description": "Write a C function to read and optionally update quantization matrices from a bitstream in an MPEG encoding context."}
{"func_name": "analyze_scene", "func_src_before": "    def analyze_scene(self, scene):\n        base_urls = scene.get_base_urls()\n        users = scene.get_users()\n        name = scene.get_name()\n        LOG.info('found the following users for scene {}: {}'.format(name, users))\n\n        # This scene might have one user who always posts the brackets on their challonge account\n        for user in users:\n            # Have we analyzed this user before?\n            sql = \"SELECT * FROM user_analyzed WHERE user='{}';\".format(user)\n            results = self.db.exec(sql)\n\n            # Did we have any matches in the database?\n            if len(results) > 0:\n                # We have analyzed this user before. Just grab one page of brackets to see if there have been any new tournaments\n                # eg, just look at /users/christmasmike?page=1 instead of all the pages that exist\n                most_recent_page = bracket_utils.get_brackets_from_user(user, pages=1)\n                for bracket in most_recent_page:\n                    LOG.info('here are the brackets from the most recent page of user {}: {}'.format(user, most_recent_page))\n                    # This user has already been analyzed, there's a good chance this bracket has been analyzed also\n                    sql = \"SELECT * FROM user_analyzed WHERE url='{}' AND user='{}';\".format(bracket, user)\n                    results = self.db.exec(sql)\n\n                    if len(results) == 0:\n                        # This is a new bracket that must have been published in the last hour or so\n                        LOG.info('found this url from a user: {} {}'.format(bracket, user))\n                        display_name = bracket_utils.get_display_base(bracket)\n                        # We don't care about doubles tournaments\n                        if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                            LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                            continue\n\n                        self.data_processor.process(bracket, name, display_name)\n\n                        # mark this bracket as analyzed\n                        sql = \"INSERT INTO user_analyzed (url, user, scene) VALUES ('{}', '{}', '{}');\".format(bracket, user, name)\n                        self.db.exec(sql)\n\n                        # Tweet that we found a new bracket\n                        msg = \"Found new {} bracket: {}\".format(name, bracket)\n                        tweet(msg)\n                    else:\n                        LOG.info('url {} is not new for user {}'.format(bracket, user))\n            else:\n                # This is a new user, analyze all brackets\n                user_urls = bracket_utils.get_brackets_from_user(user)\n                for url in user_urls:\n                    LOG.info('found this url from a user: {} {}'.format(url, user))\n                    display_name = bracket_utils.get_display_base(url)\n                    # We don't care about doubles tournaments\n                    if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                        LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                        continue\n\n                    self.data_processor.process(url, name, display_name)\n\n                    # mark this bracket as analyzed\n                    sql = \"INSERT INTO user_analyzed (url, user, scene) VALUES ('{}', '{}', '{}');\".format(url, user, name)\n                    self.db.exec(sql)\n\n                LOG.info('done with user {}'.format(user))\n\n\n        # This scene might always call their brackets the same thing, eg weekly1, weekly2, weekly3 etc\n        for base_url in base_urls:\n            # attempt to load this data from the database\n            LOG.info('About to start this analysis thread for scene {}'.format(scene.get_name()))\n            sql = \"SELECT first,last FROM valids WHERE base_url = '\" + str(base_url) + \"';\"\n            result = self.db.exec(sql)\n            has_results = len(result) > 0 \n\n            # Did we find a match in the database?\n            if has_results:\n                LOG.info(\"validURLs found values in the database\" + str(result))\n                first = result[0][0]\n                last = result[0][1]\n\n                # Check for a new valid URL\n                new_last = bracket_utils._get_last_valid_url(base_url, last-1)\n\n                if not new_last == last:\n                    if new_last - last > 5:\n                        with open(\"DEBUGOUTPUT.txt\", 'a') as f:\n                            f.write(\"[validURLs.py:55]: found a SHIT TON of new tournaments for bracket: {}\".format(base_url))\n\n                    else:\n                        bracket = base_url.replace('###', str(new_last))\n                        LOG.info('Found new bracket: {}'.format(bracket))\n                        msg = \"Found new bracket: {}\".format(bracket)\n                        tweet(msg)\n\n                    # If there's been a new last, update the database\n                    sql = \"UPDATE valids SET last=\" + str(new_last) + \" where base_url = '\"+str(base_url)+\"';\"\n                    self.db.exec(sql)\n\n\n                    # Analyze each of these new brackets\n                    for i in range(last+1, new_last+1):\n                        # Since this URL is new, we have to process the data\n                        bracket = base_url.replace('###', str(i))\n                        # Create the display name for this bracket\n                        # Eg challonge.com/NP9ATX54 -> NP9 54\n                        display_name = bracket_utils.get_display_base(bracket, counter=i)\n                        # We don't care about doubles tournaments\n                        if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                            LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                            continue\n\n                        self.data_processor.process(bracket, name, display_name, new_bracket=True)\n\n            else:\n                # We need to create first and last from scratch\n                first = bracket_utils._get_first_valid_url(base_url)\n                last = bracket_utils._get_last_valid_url(base_url, first)\n\n                # This is new data, we need to put it into the db\n                sql = \"INSERT INTO valids (base_url, first, last, scene) VALUES (\"\n                sql += \"'\"+str(base_url)+\"', \"+str(first)+ \", \"+str(last)+\", '\"+str(name)+\"');\"\n                self.db.exec(sql)\n\n                for i in range(first, last+1):\n                    bracket = base_url.replace('###', str(i))\n                    # Create the display name for this bracket\n                    # Eg challonge.com/NP9ATX54 -> NP9 54\n                    display_name = bracket_utils.get_display_base(bracket, counter=i)\n                    # We don't care about doubles tournaments\n                    if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                        LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                        continue\n\n                    self.data_processor.process(bracket, name, display_name)\n\n                    # Calculate ranks after each tournament so we can see how players are progressing\n        if not analyzed_scenes and should_tweet:\n            tweet('About to start ranking for scene {}'.format(name))\n        self.data_processor.check_and_update_ranks(name)", "func_src_after": "    def analyze_scene(self, scene):\n        base_urls = scene.get_base_urls()\n        users = scene.get_users()\n        name = scene.get_name()\n        LOG.info('found the following users for scene {}: {}'.format(name, users))\n\n        # This scene might have one user who always posts the brackets on their challonge account\n        for user in users:\n            # Have we analyzed this user before?\n            sql = \"SELECT * FROM user_analyzed WHERE user='{user}';\"\n            args = {'user': user}\n            results = self.db.exec(sql, args)\n\n            # Did we have any matches in the database?\n            if len(results) > 0:\n                # We have analyzed this user before. Just grab one page of brackets to see if there have been any new tournaments\n                # eg, just look at /users/christmasmike?page=1 instead of all the pages that exist\n                most_recent_page = bracket_utils.get_brackets_from_user(user, pages=1)\n                for bracket in most_recent_page:\n                    LOG.info('here are the brackets from the most recent page of user {}: {}'.format(user, most_recent_page))\n                    # This user has already been analyzed, there's a good chance this bracket has been analyzed also\n                    sql = \"SELECT * FROM user_analyzed WHERE url='{bracket}' AND user='{user}';\"\n                    args = {'bracket': bracket, 'user': user}\n                    results = self.db.exec(sql, args)\n\n                    if len(results) == 0:\n                        # This is a new bracket that must have been published in the last hour or so\n                        LOG.info('found this url from a user: {} {}'.format(bracket, user))\n                        display_name = bracket_utils.get_display_base(bracket)\n                        # We don't care about doubles tournaments\n                        if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                            LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                            continue\n\n                        self.data_processor.process(bracket, name, display_name)\n\n                        # mark this bracket as analyzed\n                        sql = \"INSERT INTO user_analyzed (url, user, scene) VALUES ('{bracket}', '{user}', '{name}');\"\n                        args = {'bracket': bracket, 'user':user, 'name':name}\n                        self.db.exec(sql, args)\n\n                        # Tweet that we found a new bracket\n                        msg = \"Found new {} bracket: {}\".format(name, bracket)\n                        tweet(msg)\n                    else:\n                        LOG.info('url {} is not new for user {}'.format(bracket, user))\n            else:\n                # This is a new user, analyze all brackets\n                user_urls = bracket_utils.get_brackets_from_user(user)\n                for url in user_urls:\n                    LOG.info('found this url from a user: {} {}'.format(url, user))\n                    display_name = bracket_utils.get_display_base(url)\n                    # We don't care about doubles tournaments\n                    if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                        LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                        continue\n\n                    self.data_processor.process(url, name, display_name)\n\n                    # mark this bracket as analyzed\n                    sql = \"INSERT INTO user_analyzed (url, user, scene) VALUES ('{url}', '{user}', '{name}');\"\n                    args = {'url': url, 'user':user, 'name':name}\n                    self.db.exec(sql, args)\n\n                LOG.info('done with user {}'.format(user))\n\n\n        # This scene might always call their brackets the same thing, eg weekly1, weekly2, weekly3 etc\n        for base_url in base_urls:\n            # attempt to load this data from the database\n            LOG.info('About to start this analysis thread for scene {}'.format(scene.get_name()))\n            sql = \"SELECT first,last FROM valids WHERE base_url = '{base_url}';\"\n            args = {'base_url': base_url}\n            result = self.db.exec(sql, args)\n            has_results = len(result) > 0 \n\n            # Did we find a match in the database?\n            if has_results:\n                LOG.info(\"validURLs found values in the database\" + str(result))\n                first = result[0][0]\n                last = result[0][1]\n\n                # Check for a new valid URL\n                new_last = bracket_utils._get_last_valid_url(base_url, last-1)\n\n                if not new_last == last:\n                    if new_last - last > 5:\n                        with open(\"DEBUGOUTPUT.txt\", 'a') as f:\n                            f.write(\"[validURLs.py:55]: found a SHIT TON of new tournaments for bracket: {}\".format(base_url))\n\n                    else:\n                        bracket = base_url.replace('###', str(new_last))\n                        LOG.info('Found new bracket: {}'.format(bracket))\n                        msg = \"Found new bracket: {}\".format(bracket)\n                        tweet(msg)\n\n                    # If there's been a new last, update the database\n                    sql = \"UPDATE valids SET last={new_last} where base_url='{base_url}';\"\n                    args = {'new_last': new_last, 'base_url': base_url}\n                    self.db.exec(sql, args)\n\n\n                    # Analyze each of these new brackets\n                    for i in range(last+1, new_last+1):\n                        # Since this URL is new, we have to process the data\n                        bracket = base_url.replace('###', str(i))\n                        # Create the display name for this bracket\n                        # Eg challonge.com/NP9ATX54 -> NP9 54\n                        display_name = bracket_utils.get_display_base(bracket, counter=i)\n                        # We don't care about doubles tournaments\n                        if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                            LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                            continue\n\n                        self.data_processor.process(bracket, name, display_name, new_bracket=True)\n\n            else:\n                # We need to create first and last from scratch\n                first = bracket_utils._get_first_valid_url(base_url)\n                last = bracket_utils._get_last_valid_url(base_url, first)\n\n                # This is new data, we need to put it into the db\n                sql = \"INSERT INTO valids (base_url, first, last, scene) VALUES ('{base_url}', '{first}', '{last}', '{name}');\"\n                args = {'base_url': base_url, 'first': first, 'last': last, 'name': name}\n                self.db.exec(sql, args)\n\n                for i in range(first, last+1):\n                    bracket = base_url.replace('###', str(i))\n                    # Create the display name for this bracket\n                    # Eg challonge.com/NP9ATX54 -> NP9 54\n                    display_name = bracket_utils.get_display_base(bracket, counter=i)\n                    # We don't care about doubles tournaments\n                    if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                        LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                        continue\n\n                    self.data_processor.process(bracket, name, display_name)\n\n                    # Calculate ranks after each tournament so we can see how players are progressing\n        if not analyzed_scenes and should_tweet:\n            tweet('About to start ranking for scene {}'.format(name))\n        self.data_processor.check_and_update_ranks(name)", "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "validURLs.py", "vul_type": "cwe-089", "description": "Write a Python function to analyze tournament brackets for a given scene, checking for new data and updating records accordingly."}
{"func_name": "post", "func_src_before": "    def post(self):\r\n        if (request.environ['CONTENT_TYPE'].split(';', 1)[0] == \"application/json\"):\r\n            try:\r\n                para = request.get_json()\r\n            except Exception as e:\r\n                resp = make_response((\"The json data can't be parsed\", 403, ))\r\n                return resp\r\n                \r\n            account = para['account']\r\n            password = para['password']\r\n            nickname = para['nickname']\r\n            email = para['email']\r\n            if not all((account, password, nickname, email)):\r\n                return make_response((\"Missing important data in the request\", 400, ))\r\n            tmp_re = re.compile(tmp_str)\r\n            if (len(account) > 50) or not tmp_re.match(account):\r\n                return make_response((\"The account {0} is illegal\".format(account), 400, ))\r\n            if (len(password) > 50) or not tmp_re.match(password):\r\n                return make_response((\"The password {0} is illegal\".format(password), 400, ))\r\n            if len(nickname) > 50:\r\n                return make_response((\"The nickname {0} exceed the maximum length\".format(nickname), 400, ))\r\n            if (len(email) > 100) or (len(email.split('@')) != 2):\r\n                return make_response((\"The email {0} is unacceptable\".format(nickname), 400, ))\r\n            db_session = get_session()\r\n            try:\r\n                db_user = db_session.query(UserInfo).filter_by(username = account).one()\r\n            except Exception, e:\r\n                user = UserInfo(account, email, nickname)\r\n                auth = UserAuth(account, password)\r\n                db_session.begin()\r\n                try:\r\n                    db_session.add(user)\r\n                    db_session.add(auth)\r\n                    db_session.commit()\r\n                except:\r\n                    db_session.rollback()\r\n                    return (\"DataBase Failed\", 503, )\r\n                tmp = rpc_callbacks()\r\n                RPC.register_callbacks(user.username, [tmp])\r\n                queue = RPC.create_queue(user.username, user.username)\r\n                cnn = RPC.create_connection()\r\n                RPC.create_consumer(user.username, cnn, queue)\r\n                RPC.release_consumer(user.username)\r\n                RPC.release_connection(cnn)\r\n                resp = Response(\"Account is created successfully\", 201, )\r\n                return resp\r\n            else:\r\n                if not db_user.deleted:\r\n                    return make_response((\"The account {0} is already existed\".format(account), 400, ))\r\n                else:\r\n                    auth = db_session.query(UserAuth).filter(UserAuth.account == db_user.username).first()\r\n                    if len(auth) < 1:\r\n                        return make_response((\"The account {0} is already existed\".format(account), 400, ))\r\n                    if auth.is_authenticated(password):\r\n                        db_session.begin()\r\n                        try:\r\n                            auth.activate()\r\n                            db_user.deleted = False\r\n                            db_session.add(db_user)\r\n                            db_session.commit()\r\n                        except:\r\n                            db_session.rollback()\r\n                            return (\"DataBase Failed\", 503, )\r\n                        RPC.create_queue(db_user.username, db_user.username)\r\n                        resp = Response(\"Account is recoveried successfully\", 200, {'token':auth.token})\r\n                        return resp\r\n                    else:\r\n                        return make_response((\"The account {0} is already existed\".format(account), 400, ))\r\n        else:\r\n            return make_response((\"Please upload a json data\", 403, ))", "func_src_after": "    def post(self):\r\n        if (request.environ['CONTENT_TYPE'].split(';', 1)[0] == \"application/json\"):\r\n            try:\r\n                para = request.get_json()\r\n            except Exception as e:\r\n                resp = make_response((\"The json data can't be parsed\", 403, ))\r\n                return resp\r\n            try:\r\n                account = para['account']\r\n                password = para['password']\r\n                nickname = para['nickname']\r\n                email = para['email']\r\n            except Exception as e:\r\n                return make_response((\"Parameter error\", 400, ))\r\n            nickname = escape(nickname)\r\n            if not all((account, password, nickname, email)):\r\n                return make_response((\"Missing important data in the request\", 400, ))\r\n            tmp_re = re.compile(tmp_str)\r\n            if (len(account) > 50) or not tmp_re.match(account):\r\n                return make_response((\"The account {0} is illegal\".format(account), 400, ))\r\n            if (len(password) > 50) or not tmp_re.match(password):\r\n                return make_response((\"The password {0} is illegal\".format(password), 400, ))\r\n            if len(nickname) > 50:\r\n                return make_response((\"The nickname {0} exceed the maximum length\".format(nickname), 400, ))\r\n            if (len(email) > 100) or (len(email.split('@')) != 2):\r\n                return make_response((\"The email {0} is unacceptable\".format(nickname), 400, ))\r\n            db_session = get_session()\r\n            try:\r\n                db_user = db_session.query(UserInfo).filter_by(username = account).one()\r\n            except Exception, e:\r\n                user = UserInfo(account, email, nickname)\r\n                auth = UserAuth(account, password)\r\n                db_session.begin()\r\n                try:\r\n                    db_session.add(user)\r\n                    db_session.add(auth)\r\n                    db_session.commit()\r\n                except:\r\n                    db_session.rollback()\r\n                    return (\"DataBase Failed\", 503, )\r\n                tmp = rpc_callbacks()\r\n                RPC.register_callbacks(user.username, [tmp])\r\n                queue = RPC.create_queue(user.username, user.username)\r\n                cnn = RPC.create_connection()\r\n                RPC.create_consumer(user.username, cnn, queue)\r\n                RPC.release_consumer(user.username)\r\n                RPC.release_connection(cnn)\r\n                resp = Response(\"Account is created successfully\", 201, )\r\n                return resp\r\n            else:\r\n                if not db_user.deleted:\r\n                    return make_response((\"The account {0} is already existed\".format(account), 400, ))\r\n                else:\r\n                    auth = db_session.query(UserAuth).filter(UserAuth.account == db_user.username).first()\r\n                    if len(auth) < 1:\r\n                        return make_response((\"The account {0} is already existed\".format(account), 400, ))\r\n                    if auth.is_authenticated(password):\r\n                        db_session.begin()\r\n                        try:\r\n                            auth.activate()\r\n                            db_user.deleted = False\r\n                            db_session.add(db_user)\r\n                            db_session.commit()\r\n                        except:\r\n                            db_session.rollback()\r\n                            return (\"DataBase Failed\", 503, )\r\n                        RPC.create_queue(db_user.username, db_user.username)\r\n                        resp = Response(\"Account is recoveried successfully\", 200, {'token':auth.token})\r\n                        return resp\r\n                    else:\r\n                        return make_response((\"The account {0} is already existed\".format(account), 400, ))\r\n        else:\r\n            return make_response((\"Please upload a json data\", 403, ))", "line_changes": {"deleted": [{"line_no": 8, "char_start": 313, "char_end": 331, "line": "                \r\n"}, {"line_no": 9, "char_start": 331, "char_end": 370, "line": "            account = para['account']\r\n"}, {"line_no": 10, "char_start": 370, "char_end": 411, "line": "            password = para['password']\r\n"}, {"line_no": 11, "char_start": 411, "char_end": 452, "line": "            nickname = para['nickname']\r\n"}, {"line_no": 12, "char_start": 452, "char_end": 487, "line": "            email = para['email']\r\n"}], "added": [{"line_no": 8, "char_start": 313, "char_end": 331, "line": "            try:\r\n"}, {"line_no": 9, "char_start": 331, "char_end": 374, "line": "                account = para['account']\r\n"}, {"line_no": 10, "char_start": 374, "char_end": 419, "line": "                password = para['password']\r\n"}, {"line_no": 11, "char_start": 419, "char_end": 464, "line": "                nickname = para['nickname']\r\n"}, {"line_no": 12, "char_start": 464, "char_end": 503, "line": "                email = para['email']\r\n"}, {"line_no": 13, "char_start": 503, "char_end": 539, "line": "            except Exception as e:\r\n"}, {"line_no": 14, "char_start": 539, "char_end": 605, "line": "                return make_response((\"Parameter error\", 400, ))\r\n"}, {"line_no": 15, "char_start": 605, "char_end": 646, "line": "            nickname = escape(nickname)\r\n"}]}, "char_changes": {"deleted": [{"char_start": 329, "char_end": 331, "chars": "\r\n"}], "added": [{"char_start": 325, "char_end": 331, "chars": "try:\r\n"}, {"char_start": 386, "char_end": 389, "chars": "   "}, {"char_start": 389, "char_end": 390, "chars": " "}, {"char_start": 419, "char_end": 423, "chars": "    "}, {"char_start": 476, "char_end": 480, "chars": "    "}, {"char_start": 503, "char_end": 646, "chars": "            except Exception as e:\r\n                return make_response((\"Parameter error\", 400, ))\r\n            nickname = escape(nickname)\r\n"}]}, "commit_link": "github.com/AllChat/AllChat/commit/ce07e9ac0e26295081e7476dfddd536ff030892d", "file_name": "views.py", "vul_type": "cwe-079", "commit_msg": "1. use flask.escape to escape the nickname in order to  avoid the XSS", "description": "Write a Python function to handle user account creation and reactivation with JSON input validation and database interactions."}
{"func_name": "mode_init", "func_src_before": "    def mode_init(self, request):\n        \"\"\"\n        This is called by render_POST when the client requests an init\n        mode operation (at startup)\n\n        Args:\n            request (Request): Incoming request.\n\n        \"\"\"\n        csessid = request.args.get('csessid')[0]\n\n        remote_addr = request.getClientIP()\n        host_string = \"%s (%s:%s)\" % (_SERVERNAME, request.getRequestHostname(), request.getHost().port)\n\n        sess = AjaxWebClientSession()\n        sess.client = self\n        sess.init_session(\"ajax/comet\", remote_addr, self.sessionhandler)\n\n        sess.csessid = csessid\n        csession = _CLIENT_SESSIONS(session_key=sess.csessid)\n        uid = csession and csession.get(\"webclient_authenticated_uid\", False)\n        if uid:\n            # the client session is already logged in\n            sess.uid = uid\n            sess.logged_in = True\n\n        sess.sessionhandler.connect(sess)\n\n        self.last_alive[csessid] = (time.time(), False)\n        if not self.keep_alive:\n            # the keepalive is not running; start it.\n            self.keep_alive = LoopingCall(self._keepalive)\n            self.keep_alive.start(_KEEPALIVE, now=False)\n\n        return jsonify({'msg': host_string, 'csessid': csessid})", "func_src_after": "    def mode_init(self, request):\n        \"\"\"\n        This is called by render_POST when the client requests an init\n        mode operation (at startup)\n\n        Args:\n            request (Request): Incoming request.\n\n        \"\"\"\n        csessid = cgi.escape(request.args['csessid'][0])\n\n        remote_addr = request.getClientIP()\n        host_string = \"%s (%s:%s)\" % (_SERVERNAME, request.getRequestHostname(), request.getHost().port)\n\n        sess = AjaxWebClientSession()\n        sess.client = self\n        sess.init_session(\"ajax/comet\", remote_addr, self.sessionhandler)\n\n        sess.csessid = csessid\n        csession = _CLIENT_SESSIONS(session_key=sess.csessid)\n        uid = csession and csession.get(\"webclient_authenticated_uid\", False)\n        if uid:\n            # the client session is already logged in\n            sess.uid = uid\n            sess.logged_in = True\n\n        sess.sessionhandler.connect(sess)\n\n        self.last_alive[csessid] = (time.time(), False)\n        if not self.keep_alive:\n            # the keepalive is not running; start it.\n            self.keep_alive = LoopingCall(self._keepalive)\n            self.keep_alive.start(_KEEPALIVE, now=False)\n\n        return jsonify({'msg': host_string, 'csessid': csessid})", "commit_link": "github.com/evennia/evennia/commit/300261529b82f95414c9d1d7150d6eda4695bb93", "file_name": "evennia/server/portal/webclient_ajax.py", "vul_type": "cwe-079", "description": "In Python, write a function `mode_init` that initializes a web client session and handles keep-alive upon receiving a POST request."}
{"func_name": "load_yaml", "func_src_before": "    def load_yaml(self, file):\n        data = yaml.load(file)\n        for concept_type_key, vocabs in data.items():\n            concept_type = {\n                'classification_schemes': ClassificationRecord,\n                'subject_schemes': AuthorityRecord,\n            }.get(concept_type_key)\n            for scheme_code, options in vocabs.items():\n                if is_str(options):\n                    options = {'base_uri': options}\n                self.entries[scheme_code] = ConceptScheme(concept_type, scheme_code, options=options)", "func_src_after": "    def load_yaml(self, file):\n        data = yaml.safe_load(file)\n        for concept_type_key, vocabs in data.items():\n            concept_type = {\n                'classification_schemes': ClassificationRecord,\n                'subject_schemes': AuthorityRecord,\n            }.get(concept_type_key)\n            for scheme_code, options in vocabs.items():\n                if is_str(options):\n                    options = {'base_uri': options}\n                self.entries[scheme_code] = ConceptScheme(concept_type, scheme_code, options=options)", "line_changes": {"deleted": [{"line_no": 2, "char_start": 31, "char_end": 62, "line": "        data = yaml.load(file)\n"}], "added": [{"line_no": 2, "char_start": 31, "char_end": 67, "line": "        data = yaml.safe_load(file)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 51, "char_end": 56, "chars": "safe_"}]}, "commit_link": "github.com/scriptotek/mc2skos/commit/b0cb78b091f64e86c2357acbde5a0bb3b939deaa", "file_name": "vocabularies.py", "vul_type": "cwe-502", "commit_msg": "Use safe yaml loading", "parent_commit": "b58de96a2949046e56ea6e4e5c6d6116b9d0c560", "description": "Write a Python function to load data from a YAML file and process it into a dictionary of concept schemes."}
{"func_name": "main", "func_src_before": "int main (int argc, char **argv) {\n\tint result;\n\tstruct mt_packet data;\n\tstruct sockaddr_in si_me;\n\tunsigned char buff[1500];\n\tunsigned char print_help = 0, have_username = 0, have_password = 0;\n\tunsigned char drop_priv = 0;\n\tint c;\n\tint optval = 1;\n\n\tsetlocale(LC_ALL, \"\");\n\tbindtextdomain(\"mactelnet\",\"/usr/share/locale\");\n\ttextdomain(\"mactelnet\");\n\n\t/* Set default for ssh_path. */\n\tstrncpy(ssh_path, SSH_PATH, sizeof(ssh_path) -1);\n\tssh_path[sizeof(ssh_path)] = '\\0';\n\n    /* Ignore args after -- for MAC-Telnet client. */\n\tint mactelnet_argc = argc;\n\tint i;\n\tfor (i=0; i < argc; i++) {\n\t\tif (strlen(argv[i]) == 2 && strncmp(argv[i], \"--\", 2) == 0) {\n\t\t\tmactelnet_argc = i;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\twhile (1) {\n\t\tc = getopt(mactelnet_argc, argv, \"nqlt:u:p:vh?SFP:c:U:\");\n\n\t\tif (c == -1) {\n\t\t\tbreak;\n\t\t}\n\n\t\tswitch (c) {\n\n\t\t\tcase 'n':\n\t\t\t\tuse_raw_socket = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'S':\n\t\t\t\ttunnel_conn = 1;\n\t\t\t\tlaunch_ssh = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'F':\n\t\t\t\ttunnel_conn = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'P':\n\t\t\t\tfwdport = atoi(optarg);\n\t\t\t\tbreak;\n\n\t\t\tcase 'u':\n\t\t\t\t/* Save username */\n\t\t\t\tstrncpy(username, optarg, sizeof(username) - 1);\n\t\t\t\tusername[sizeof(username) - 1] = '\\0';\n\t\t\t\thave_username = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'p':\n\t\t\t\t/* Save password */\n\t\t\t\tstrncpy(password, optarg, sizeof(password) - 1);\n\t\t\t\tpassword[sizeof(password) - 1] = '\\0';\n\t\t\t\thave_password = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'U':\n\t\t\t\t/* Save nonpriv_username */\n\t\t\t\tstrncpy(nonpriv_username, optarg, sizeof(nonpriv_username) - 1);\n\t\t\t\tnonpriv_username[sizeof(nonpriv_username) - 1] = '\\0';\n\t\t\t\tdrop_priv = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'c':\n\t\t\t\t/* Save ssh executable path */\n\t\t\t\tstrncpy(ssh_path, optarg, sizeof(ssh_path) -1);\n\t\t\t\tssh_path[sizeof(ssh_path)] = '\\0';\n\t\t\t\tbreak;\n\n\t\t\tcase 't':\n\t\t\t\tconnect_timeout = atoi(optarg);\n\t\t\t\tbreak;\n\n\t\t\tcase 'l':\n\t\t\t\treturn mndp();\n\t\t\t\tbreak;\n\n\t\t\tcase 'v':\n\t\t\t\tprint_version();\n\t\t\t\texit(0);\n\t\t\t\tbreak;\n\n\t\t\tcase 'q':\n\t\t\t\tquiet_mode = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'h':\n\t\t\tcase '?':\n\t\t\t\tprint_help = 1;\n\t\t\t\tbreak;\n\n\t\t}\n\t}\n\tif (argc - optind < 1 || print_help) {\n\t\tprint_version();\n\t\tfprintf(stderr, _(\"Usage: %s <MAC|identity> [-v] [-h] [-q] [-n] [-l] [-S] [-P <port>]\\n\"\n\t\t\t\t          \"       [-t <timeout>] [-u <user>] [-p <pass>] [-c <path>] [-U <user>]\\n\"), argv[0]);\n\n\t\tif (print_help) {\n\t\t\tfprintf(stderr, _(\"\\nParameters:\\n\"\n\t\t\t\"  MAC           MAC-Address of the RouterOS/mactelnetd device. Use mndp to \\n\"\n            \"                discover it.\\n\"\n\t\t\t\"  identity      The identity/name of your destination device. Uses MNDP \\n\"\n\t\t\t\"                protocol to find it.\\n\"\n\t\t\t\"  -l            List/Search for routers nearby. (using MNDP)\\n\"\n\t\t\t\"  -n            Do not use broadcast packets. Less insecure but requires root \\n\"\n\t\t    \"                privileges.\\n\"\n\t\t\t\"  -t <timeout>  Amount of seconds to wait for a response on each interface.\\n\"\n\t\t\t\"  -u <user>     Specify username on command line.\\n\"\n\t\t\t\"  -p <pass>     Specify password on command line.\\n\"\n\t\t\t\"  -U <user>     Drop privileges by switching to user, when the command is\\n\"\n\t\t\t\"                run as a privileged user in conjunction with the -n option.\\n\"\n\t\t\t\"  -S            Use MAC-SSH instead of MAC-Telnet. (Implies -F)\\n\"\n\t\t    \"                Forward SSH connection through MAC-Telnet and launch SSH client.\\n\"\n\t\t\t\"  -F            Forward connection through of MAC-Telnet without launching the \\n\"\n\t\t    \"                SSH Client.\\n\"\n\t\t\t\"  -P <port>     Local TCP port for forwarding SSH connection.\\n\"\n\t\t\t\"                (If not specified, port 2222 by default.)\\n\"\n\t\t\t\"  -c <path>     Path for ssh client executable. (Default: /usr/bin/ssh)\\n\"\n\t\t\t\"  -q            Quiet mode.\\n\"\n\t\t\t\"  -v            Print version and exit.\\n\"\n\t\t\t\"  -h            Print help and exit.\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"All arguments after '--' will be passed to the ssh client command.\\n\"\n\t\t\t\"\\n\"));\n\t\t}\n\t\treturn 1;\n\t}\n\n\t/* Setup command line for ssh client */\n\tif (launch_ssh) {\n\t\tint ssh_argc;\n\t\tint add_argc;\n\t\tssh_argc = argc - mactelnet_argc;\n\t\tadd_argc = ssh_argc;\n\t\tssh_argc += 3; /* Port option and hostname: -p <port> <host>*/\n\t\tif (have_username) {\n\t\t\tssh_argc += 2;  /* Login name option: -l <user> */\n\t\t}\n\t\tssh_argv = (char **) calloc(sizeof(char *), ssh_argc + 1);\n\t\tchar *ssh_path_c = strndup(ssh_path, sizeof(ssh_path) - 1);\n\t\tchar *ssh_filename = basename(ssh_path_c);\n\t\tint idx = 0;\n\t\tssh_argv[idx++] = ssh_filename;\n\t\tint i;\n\t\tfor (i = 1; i < add_argc; i++) {\n\t\t\tssh_argv[idx++] = argv[mactelnet_argc + i];\n\t\t}\n\t\tchar portstr[8];\n\t\tsnprintf(portstr, 8, \"%d\", fwdport);\n\t\tssh_argv[idx++] = strdup(\"-p\");\n\t\tssh_argv[idx++] = strndup(portstr, sizeof(portstr) - 1);\n\t\tif (have_username) {\n\t\t\tssh_argv[idx++] = strdup(\"-l\");\n\t\t\tssh_argv[idx++] = username;\n\t\t}\n\t\tssh_argv[idx++] = strdup(\"127.0.0.1\");\n\t\tssh_argv[idx++] = (char*) 0;\n\t}\n\n\tis_a_tty = isatty(fileno(stdout)) && isatty(fileno(stdin));\n\tif (!is_a_tty) {\n\t\tquiet_mode = 1;\n\t}\n\n\t/* Seed randomizer */\n\tsrand(time(NULL));\n\n\tif (use_raw_socket) {\n\t\tif (geteuid() != 0) {\n\t\t\tfprintf(stderr, _(\"You need to have root privileges to use the -n parameter.\\n\"));\n\t\t\treturn 1;\n\t\t}\n\n\t\tsockfd = net_init_raw_socket();\n\t}\n\n\tif (drop_priv) {\n\t\tdrop_privileges(nonpriv_username);\n\t}\n\n\t/* Receive regular udp packets with this socket */\n\tinsockfd = socket(AF_INET, SOCK_DGRAM, IPPROTO_UDP);\n\tif (insockfd < 0) {\n\t\tperror(\"insockfd\");\n\t\treturn 1;\n\t}\n\n\tif (!use_raw_socket) {\n\t\tif (setsockopt(insockfd, SOL_SOCKET, SO_BROADCAST, &optval, sizeof (optval))==-1) {\n\t\t\tperror(\"SO_BROADCAST\");\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\t/* Need to use, to be able to autodetect which interface to use */\n\tsetsockopt(insockfd, SOL_SOCKET, SO_REUSEADDR, &optval, sizeof (optval));\n\n\t/* Get mac-address from string, or check for hostname via mndp */\n\tif (!query_mndp_or_mac(argv[optind], dstmac, !quiet_mode)) {\n\t\t/* No valid mac address found, abort */\n\t\treturn 1;\n\t}\n\n\tif (!tunnel_conn && !have_username) {\n\t\tif (!quiet_mode) {\n\t\t\tprintf(_(\"Login: \"));\n\t\t}\n\t\tscanf(\"%254s\", username);\n\t}\n\n\tif (!tunnel_conn && !have_password) {\n\t\tchar *tmp;\n\t\ttmp = getpass(quiet_mode ? \"\" : _(\"Password: \"));\n\t\tstrncpy(password, tmp, sizeof(password) - 1);\n\t\tpassword[sizeof(password) - 1] = '\\0';\n\t\t/* security */\n\t\tmemset(tmp, 0, strlen(tmp));\n#ifdef __GNUC__\n\t\tfree(tmp);\n#endif\n\t}\n\n\tif (tunnel_conn) {\n\t\t/* Setup signal handler for broken tunnels. */\n\t\tsignal(SIGPIPE,SIG_IGN);\n\n\t\t/* Setup Server socket for receiving connection from local SSH Client. */\n\t\tint fwdsrvfd;\n\t\tfwdsrvfd = socket(PF_INET, SOCK_STREAM, IPPROTO_TCP);\n\t\tif (fwdsrvfd < 0) {\n\t\t\tperror(\"fwdsrvfd\");\n\t\t\treturn 1;\n\t\t}\n\t\tif(setsockopt(fwdsrvfd, SOL_SOCKET, SO_REUSEADDR, &optval, sizeof (optval)) < 0) {\n\t\t\tperror(\"SO_REUSEADDR\");\n\t\t\treturn 1;\n\t\t}\n\n\t\t/* Bind to server socket for receiving terminal client connection. */\n\t\tstruct sockaddr_in srv_socket;\n\t\tmemset(&srv_socket, 0, sizeof(srv_socket));\n\t\tsrv_socket.sin_family = AF_INET;\n\t\tsrv_socket.sin_port = htons(fwdport);\n\t\tsrv_socket.sin_addr.s_addr = inet_addr(\"127.0.0.1\");\n\t\tif (bind(fwdsrvfd, (struct sockaddr *) &srv_socket, sizeof(srv_socket)) < 0) {\n\t\t\tfprintf(stderr, _(\"Error binding to %s:%d, %s\\n\"), \"127.0.0.1\", fwdport, strerror(errno));\n\t\t\treturn 1;\n\t\t}\n\t\tif (listen(fwdsrvfd, 1) < 0) {\n\t\t\tfprintf(stderr, _(\"Failed listen on server socket %s:%d, %s\\n\"), \"127.0.0.1\", fwdport, strerror(errno));\n\t\t\treturn 1;\n\t\t}\n\n\t\t/* Fork child to execute SSH Client locally and connect to parent\n\t\t * waiting for connection from child if launch_ssh is requested.\n\t\t */\n\t\tint pid;\n\t\tif (launch_ssh) {\n\t\t\tpid = fork();\n\t\t}\n\n\t\tif (!launch_ssh || pid > 0) {\n\t\t\t/* Parent code. Waits for connection to local end of tunnel */\n\n\t\t\t/* Close stdin and stdout, leave stderr active for error messages.\n\t\t\t * The terminal will be handled by client connecting to local end of tunnel. */\n\t\t\tclose(0);\n\t\t\tclose(1);\n\n\t\t\t/* Wait for remote terminal client connection on server port. */\n\t\t\tfprintf(stderr, _(\"Waiting for tunnel connection on port: %d\\n\"), fwdport);\n\t\t\tstruct sockaddr_in cli_socket;\n\t\t\tunsigned int cli_socket_len = sizeof(cli_socket);\n\t\t\tmemset(&cli_socket, 0, sizeof(cli_socket));\n\t\t\tif ((fwdfd = accept(fwdsrvfd, (struct sockaddr *) &cli_socket, &cli_socket_len)) < 0) {\n\t\t\t\tperror(\"fwdfd\");\n\t\t\t}\n\t\t\tif(setsockopt(fwdfd, SOL_SOCKET, SO_KEEPALIVE, &optval, sizeof(optval)) < 0) {\n\t\t\t\tperror(\"SO_KEEPALIVE\");\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t\tfprintf(stderr, _(\"Client connected to tunnel from port: %d\\n\"), ntohs(cli_socket.sin_port));\n\t\t}\n\t\telse if (launch_ssh && pid == 0) {\n\t\t\t/* Child Code. Executes SSH Client and connects to parent to tunnel\n\t\t\t * connection through MAC-Telnet protocol. */\n\t\t\tif (use_raw_socket) {\n\t\t\t\tclose(sockfd);\n\t\t\t}\n\t\t\tclose(insockfd);\n\t\t\tclose(fwdsrvfd);\n\n\t\t\t/* Give time to parent to initialize listening port. */\n\t\t\tsleep(2);\n\n\t\t\t/* Execute SSH Client. */\n\t\t\texecvp(ssh_path, ssh_argv);\n\t\t\tperror(\"Execution of terminal client failed.\");\n\t\t\texit(1);\n\t\t}\n\t\t/* Fork failure. */\n\t\telse {\n\t\t\tfprintf(stderr, _(\"Execution of terminal client failed.\\n\"));\n\t\t\tif (use_raw_socket) {\n\t\t\t\tclose(sockfd);\n\t\t\t}\n\t\t\tclose(insockfd);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\t/* Set random source port */\n\tsourceport = 1024 + (rand() % 1024);\n\n\t/* Set up global info about the connection */\n\tinet_pton(AF_INET, (char *)\"255.255.255.255\", &destip);\n\tmemcpy(&sourceip, &(si_me.sin_addr), IPV4_ALEN);\n\n\t/* Session key */\n\tsessionkey = rand() % 65535;\n\n\t/* stop output buffering */\n\tsetvbuf(stdout, (char*)NULL, _IONBF, 0);\n\n\tif (!quiet_mode) {\n\t\tprintf(_(\"Connecting to %s...\"), ether_ntoa((struct ether_addr *)dstmac));\n\t}\n\n\t/* Initialize receiving socket on the device chosen */\n\tmemset((char *) &si_me, 0, sizeof(si_me));\n\tsi_me.sin_family = AF_INET;\n\tsi_me.sin_port = htons(sourceport);\n\n\t/* Bind to udp port */\n\tif (bind(insockfd, (struct sockaddr *)&si_me, sizeof(si_me)) == -1) {\n\t\tfprintf(stderr, _(\"Error binding to %s:%d, %s\\n\"), inet_ntoa(si_me.sin_addr), sourceport, strerror(errno));\n\t\treturn 1;\n\t}\n\n\tif (!find_interface() || (result = recvfrom(insockfd, buff, 1400, 0, 0, 0)) < 1) {\n\t\tfprintf(stderr, _(\"Connection failed.\\n\"));\n\t\treturn 1;\n\t}\n\tif (!quiet_mode) {\n\t\tprintf(_(\"done\\n\"));\n\t}\n\n\t/* Handle first received packet */\n\thandle_packet(buff, result);\n\n\tinit_packet(&data, MT_PTYPE_DATA, srcmac, dstmac, sessionkey, 0);\n\toutcounter +=  add_control_packet(&data, MT_CPTYPE_BEGINAUTH, NULL, 0);\n\n\t/* TODO: handle result of send_udp */\n\tresult = send_udp(&data, 1);\n\n\twhile (running) {\n\t\tfd_set read_fds;\n\t\tint reads;\n\t\tstatic int terminal_gone = 0;\n\t\tstruct timeval timeout;\n\n\t\tint maxfd = 0;\n\t\tmaxfd = insockfd > fwdfd ? insockfd : fwdfd;\n\n\t\t/* Init select */\n\t\tFD_ZERO(&read_fds);\n\t\tif (!tunnel_conn && !terminal_gone) {\n\t\t\t/* Setup fd to read input from terminal. */\n\t\t\tFD_SET(0, &read_fds);\n\t\t}\n\t\telse if (tunnel_conn) {\n\t\t\t/* Setup fd to read input from local SSH Client. */\n\t\t\tFD_SET(fwdfd, &read_fds);\n\t\t}\n\t\tFD_SET(insockfd, &read_fds);\n\n\t\ttimeout.tv_sec = 1;\n\t\ttimeout.tv_usec = 0;\n\n\t\t/* Wait for data or timeout */\n\t\treads = select(maxfd+1, &read_fds, NULL, NULL, &timeout);\n\t\tif (reads > 0) {\n\t\t\t/* Handle data from server */\n\t\t\tif (FD_ISSET(insockfd, &read_fds)) {\n\t\t\t\tbzero(buff, 1500);\n\t\t\t\tresult = recvfrom(insockfd, buff, 1500, 0, 0, 0);\n\t\t\t\thandle_packet(buff, result);\n\t\t\t}\n\t\t\tunsigned char keydata[512];\n\t\t\tint datalen = 0;\n\t\t\t/* Handle data from keyboard/local terminal */\n\t\t\tif (!tunnel_conn && FD_ISSET(0, &read_fds) && terminal_mode) {\n\t\t\t\tdatalen = read(STDIN_FILENO, &keydata, 512);\n\t\t\t}\n\t\t\t/* Handle data from local SSH client */\n\t\t\tif (tunnel_conn && FD_ISSET(fwdfd, &read_fds)) {\n\t\t\t\tdatalen = read(fwdfd, &keydata, 512);\n\t\t\t}\n\t\t\tif (datalen > 0) {\n\t\t\t\t/* Data received, transmit to server */\n\t\t\t\tinit_packet(&data, MT_PTYPE_DATA, srcmac, dstmac, sessionkey, outcounter);\n\t\t\t\tadd_control_packet(&data, MT_CPTYPE_PLAINDATA, &keydata, datalen);\n\t\t\t\toutcounter += datalen;\n\t\t\t\tsend_udp(&data, 1);\n\t\t\t}\n\t\t\telse if (datalen < 0) {\n\t\t\t\tterminal_gone = 1;\n\t\t\t}\n\t\t/* Handle select() timeout */\n\t\t} else {\n\t\t\t/* handle keepalive counter, transmit keepalive packet every 10 seconds\n\t\t\t   of inactivity  */\n\t\t\tif (keepalive_counter++ == 10) {\n\t\t\t\tstruct mt_packet odata;\n\t\t\t\tinit_packet(&odata, MT_PTYPE_ACK, srcmac, dstmac, sessionkey, outcounter);\n\t\t\t\tsend_udp(&odata, 0);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (!tunnel_conn && is_a_tty && terminal_mode) {\n\t\t/* Reset terminal back to old settings */\n\t\treset_term();\n\t}\n\n\tclose(sockfd);\n\tclose(insockfd);\n\tif (tunnel_conn && fwdfd > 0) {\n\t\tclose(fwdfd);\n\t}\n\n\treturn 0;\n}", "func_src_after": "int main (int argc, char **argv) {\n\tint result;\n\tstruct mt_packet data;\n\tstruct sockaddr_in si_me;\n\tunsigned char buff[1500];\n\tunsigned char print_help = 0, have_username = 0, have_password = 0;\n\tunsigned char drop_priv = 0;\n\tint c;\n\tint optval = 1;\n\n\tsetlocale(LC_ALL, \"\");\n\tbindtextdomain(\"mactelnet\",\"/usr/share/locale\");\n\ttextdomain(\"mactelnet\");\n\n\t/* Set default for ssh_path. */\n\tstrncpy(ssh_path, SSH_PATH, sizeof(ssh_path) - 1);\n\tssh_path[sizeof(ssh_path) - 1] = '\\0';\n\n    /* Ignore args after -- for MAC-Telnet client. */\n\tint mactelnet_argc = argc;\n\tint i;\n\tfor (i=0; i < argc; i++) {\n\t\tif (strlen(argv[i]) == 2 && strncmp(argv[i], \"--\", 2) == 0) {\n\t\t\tmactelnet_argc = i;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\twhile (1) {\n\t\tc = getopt(mactelnet_argc, argv, \"nqlt:u:p:vh?SFP:c:U:\");\n\n\t\tif (c == -1) {\n\t\t\tbreak;\n\t\t}\n\n\t\tswitch (c) {\n\n\t\t\tcase 'n':\n\t\t\t\tuse_raw_socket = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'S':\n\t\t\t\ttunnel_conn = 1;\n\t\t\t\tlaunch_ssh = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'F':\n\t\t\t\ttunnel_conn = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'P':\n\t\t\t\tfwdport = atoi(optarg);\n\t\t\t\tbreak;\n\n\t\t\tcase 'u':\n\t\t\t\t/* Save username */\n\t\t\t\tstrncpy(username, optarg, sizeof(username) - 1);\n\t\t\t\tusername[sizeof(username) - 1] = '\\0';\n\t\t\t\thave_username = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'p':\n\t\t\t\t/* Save password */\n\t\t\t\tstrncpy(password, optarg, sizeof(password) - 1);\n\t\t\t\tpassword[sizeof(password) - 1] = '\\0';\n\t\t\t\thave_password = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'U':\n\t\t\t\t/* Save nonpriv_username */\n\t\t\t\tstrncpy(nonpriv_username, optarg, sizeof(nonpriv_username) - 1);\n\t\t\t\tnonpriv_username[sizeof(nonpriv_username) - 1] = '\\0';\n\t\t\t\tdrop_priv = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'c':\n\t\t\t\t/* Save ssh executable path */\n\t\t\t\tstrncpy(ssh_path, optarg, sizeof(ssh_path) - 1);\n\t\t\t\tssh_path[sizeof(ssh_path) - 1] = '\\0';\n\t\t\t\tbreak;\n\n\t\t\tcase 't':\n\t\t\t\tconnect_timeout = atoi(optarg);\n\t\t\t\tbreak;\n\n\t\t\tcase 'l':\n\t\t\t\treturn mndp();\n\t\t\t\tbreak;\n\n\t\t\tcase 'v':\n\t\t\t\tprint_version();\n\t\t\t\texit(0);\n\t\t\t\tbreak;\n\n\t\t\tcase 'q':\n\t\t\t\tquiet_mode = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'h':\n\t\t\tcase '?':\n\t\t\t\tprint_help = 1;\n\t\t\t\tbreak;\n\n\t\t}\n\t}\n\tif (argc - optind < 1 || print_help) {\n\t\tprint_version();\n\t\tfprintf(stderr, _(\"Usage: %s <MAC|identity> [-v] [-h] [-q] [-n] [-l] [-S] [-P <port>]\\n\"\n\t\t\t\t          \"       [-t <timeout>] [-u <user>] [-p <pass>] [-c <path>] [-U <user>]\\n\"), argv[0]);\n\n\t\tif (print_help) {\n\t\t\tfprintf(stderr, _(\"\\nParameters:\\n\"\n\t\t\t\"  MAC           MAC-Address of the RouterOS/mactelnetd device. Use mndp to \\n\"\n            \"                discover it.\\n\"\n\t\t\t\"  identity      The identity/name of your destination device. Uses MNDP \\n\"\n\t\t\t\"                protocol to find it.\\n\"\n\t\t\t\"  -l            List/Search for routers nearby. (using MNDP)\\n\"\n\t\t\t\"  -n            Do not use broadcast packets. Less insecure but requires root \\n\"\n\t\t    \"                privileges.\\n\"\n\t\t\t\"  -t <timeout>  Amount of seconds to wait for a response on each interface.\\n\"\n\t\t\t\"  -u <user>     Specify username on command line.\\n\"\n\t\t\t\"  -p <pass>     Specify password on command line.\\n\"\n\t\t\t\"  -U <user>     Drop privileges by switching to user, when the command is\\n\"\n\t\t\t\"                run as a privileged user in conjunction with the -n option.\\n\"\n\t\t\t\"  -S            Use MAC-SSH instead of MAC-Telnet. (Implies -F)\\n\"\n\t\t    \"                Forward SSH connection through MAC-Telnet and launch SSH client.\\n\"\n\t\t\t\"  -F            Forward connection through of MAC-Telnet without launching the \\n\"\n\t\t    \"                SSH Client.\\n\"\n\t\t\t\"  -P <port>     Local TCP port for forwarding SSH connection.\\n\"\n\t\t\t\"                (If not specified, port 2222 by default.)\\n\"\n\t\t\t\"  -c <path>     Path for ssh client executable. (Default: /usr/bin/ssh)\\n\"\n\t\t\t\"  -q            Quiet mode.\\n\"\n\t\t\t\"  -v            Print version and exit.\\n\"\n\t\t\t\"  -h            Print help and exit.\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"All arguments after '--' will be passed to the ssh client command.\\n\"\n\t\t\t\"\\n\"));\n\t\t}\n\t\treturn 1;\n\t}\n\n\t/* Setup command line for ssh client */\n\tif (launch_ssh) {\n\t\tint ssh_argc;\n\t\tint add_argc;\n\t\tssh_argc = argc - mactelnet_argc;\n\t\tadd_argc = ssh_argc;\n\t\tssh_argc += 3; /* Port option and hostname: -p <port> <host>*/\n\t\tif (have_username) {\n\t\t\tssh_argc += 2;  /* Login name option: -l <user> */\n\t\t}\n\t\tssh_argv = (char **) calloc(sizeof(char *), ssh_argc + 1);\n\t\tchar *ssh_path_c = strndup(ssh_path, sizeof(ssh_path) - 1);\n\t\tchar *ssh_filename = basename(ssh_path_c);\n\t\tint idx = 0;\n\t\tssh_argv[idx++] = ssh_filename;\n\t\tint i;\n\t\tfor (i = 1; i < add_argc; i++) {\n\t\t\tssh_argv[idx++] = argv[mactelnet_argc + i];\n\t\t}\n\t\tchar portstr[8];\n\t\tsnprintf(portstr, 8, \"%d\", fwdport);\n\t\tssh_argv[idx++] = strdup(\"-p\");\n\t\tssh_argv[idx++] = strndup(portstr, sizeof(portstr) - 1);\n\t\tif (have_username) {\n\t\t\tssh_argv[idx++] = strdup(\"-l\");\n\t\t\tssh_argv[idx++] = username;\n\t\t}\n\t\tssh_argv[idx++] = strdup(\"127.0.0.1\");\n\t\tssh_argv[idx++] = (char*) 0;\n\t}\n\n\tis_a_tty = isatty(fileno(stdout)) && isatty(fileno(stdin));\n\tif (!is_a_tty) {\n\t\tquiet_mode = 1;\n\t}\n\n\t/* Seed randomizer */\n\tsrand(time(NULL));\n\n\tif (use_raw_socket) {\n\t\tif (geteuid() != 0) {\n\t\t\tfprintf(stderr, _(\"You need to have root privileges to use the -n parameter.\\n\"));\n\t\t\treturn 1;\n\t\t}\n\n\t\tsockfd = net_init_raw_socket();\n\t}\n\n\tif (drop_priv) {\n\t\tdrop_privileges(nonpriv_username);\n\t}\n\n\t/* Receive regular udp packets with this socket */\n\tinsockfd = socket(AF_INET, SOCK_DGRAM, IPPROTO_UDP);\n\tif (insockfd < 0) {\n\t\tperror(\"insockfd\");\n\t\treturn 1;\n\t}\n\n\tif (!use_raw_socket) {\n\t\tif (setsockopt(insockfd, SOL_SOCKET, SO_BROADCAST, &optval, sizeof (optval))==-1) {\n\t\t\tperror(\"SO_BROADCAST\");\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\t/* Need to use, to be able to autodetect which interface to use */\n\tsetsockopt(insockfd, SOL_SOCKET, SO_REUSEADDR, &optval, sizeof (optval));\n\n\t/* Get mac-address from string, or check for hostname via mndp */\n\tif (!query_mndp_or_mac(argv[optind], dstmac, !quiet_mode)) {\n\t\t/* No valid mac address found, abort */\n\t\treturn 1;\n\t}\n\n\tif (!tunnel_conn && !have_username) {\n\t\tif (!quiet_mode) {\n\t\t\tprintf(_(\"Login: \"));\n\t\t}\n\t\tscanf(\"%254s\", username);\n\t}\n\n\tif (!tunnel_conn && !have_password) {\n\t\tchar *tmp;\n\t\ttmp = getpass(quiet_mode ? \"\" : _(\"Password: \"));\n\t\tstrncpy(password, tmp, sizeof(password) - 1);\n\t\tpassword[sizeof(password) - 1] = '\\0';\n\t\t/* security */\n\t\tmemset(tmp, 0, strlen(tmp));\n#ifdef __GNUC__\n\t\tfree(tmp);\n#endif\n\t}\n\n\tif (tunnel_conn) {\n\t\t/* Setup signal handler for broken tunnels. */\n\t\tsignal(SIGPIPE,SIG_IGN);\n\n\t\t/* Setup Server socket for receiving connection from local SSH Client. */\n\t\tint fwdsrvfd;\n\t\tfwdsrvfd = socket(PF_INET, SOCK_STREAM, IPPROTO_TCP);\n\t\tif (fwdsrvfd < 0) {\n\t\t\tperror(\"fwdsrvfd\");\n\t\t\treturn 1;\n\t\t}\n\t\tif(setsockopt(fwdsrvfd, SOL_SOCKET, SO_REUSEADDR, &optval, sizeof (optval)) < 0) {\n\t\t\tperror(\"SO_REUSEADDR\");\n\t\t\treturn 1;\n\t\t}\n\n\t\t/* Bind to server socket for receiving terminal client connection. */\n\t\tstruct sockaddr_in srv_socket;\n\t\tmemset(&srv_socket, 0, sizeof(srv_socket));\n\t\tsrv_socket.sin_family = AF_INET;\n\t\tsrv_socket.sin_port = htons(fwdport);\n\t\tsrv_socket.sin_addr.s_addr = inet_addr(\"127.0.0.1\");\n\t\tif (bind(fwdsrvfd, (struct sockaddr *) &srv_socket, sizeof(srv_socket)) < 0) {\n\t\t\tfprintf(stderr, _(\"Error binding to %s:%d, %s\\n\"), \"127.0.0.1\", fwdport, strerror(errno));\n\t\t\treturn 1;\n\t\t}\n\t\tif (listen(fwdsrvfd, 1) < 0) {\n\t\t\tfprintf(stderr, _(\"Failed listen on server socket %s:%d, %s\\n\"), \"127.0.0.1\", fwdport, strerror(errno));\n\t\t\treturn 1;\n\t\t}\n\n\t\t/* Fork child to execute SSH Client locally and connect to parent\n\t\t * waiting for connection from child if launch_ssh is requested.\n\t\t */\n\t\tint pid;\n\t\tif (launch_ssh) {\n\t\t\tpid = fork();\n\t\t}\n\n\t\tif (!launch_ssh || pid > 0) {\n\t\t\t/* Parent code. Waits for connection to local end of tunnel */\n\n\t\t\t/* Close stdin and stdout, leave stderr active for error messages.\n\t\t\t * The terminal will be handled by client connecting to local end of tunnel. */\n\t\t\tclose(0);\n\t\t\tclose(1);\n\n\t\t\t/* Wait for remote terminal client connection on server port. */\n\t\t\tfprintf(stderr, _(\"Waiting for tunnel connection on port: %d\\n\"), fwdport);\n\t\t\tstruct sockaddr_in cli_socket;\n\t\t\tunsigned int cli_socket_len = sizeof(cli_socket);\n\t\t\tmemset(&cli_socket, 0, sizeof(cli_socket));\n\t\t\tif ((fwdfd = accept(fwdsrvfd, (struct sockaddr *) &cli_socket, &cli_socket_len)) < 0) {\n\t\t\t\tperror(\"fwdfd\");\n\t\t\t}\n\t\t\tif(setsockopt(fwdfd, SOL_SOCKET, SO_KEEPALIVE, &optval, sizeof(optval)) < 0) {\n\t\t\t\tperror(\"SO_KEEPALIVE\");\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t\tfprintf(stderr, _(\"Client connected to tunnel from port: %d\\n\"), ntohs(cli_socket.sin_port));\n\t\t}\n\t\telse if (launch_ssh && pid == 0) {\n\t\t\t/* Child Code. Executes SSH Client and connects to parent to tunnel\n\t\t\t * connection through MAC-Telnet protocol. */\n\t\t\tif (use_raw_socket) {\n\t\t\t\tclose(sockfd);\n\t\t\t}\n\t\t\tclose(insockfd);\n\t\t\tclose(fwdsrvfd);\n\n\t\t\t/* Give time to parent to initialize listening port. */\n\t\t\tsleep(2);\n\n\t\t\t/* Execute SSH Client. */\n\t\t\texecvp(ssh_path, ssh_argv);\n\t\t\tperror(\"Execution of terminal client failed.\");\n\t\t\texit(1);\n\t\t}\n\t\t/* Fork failure. */\n\t\telse {\n\t\t\tfprintf(stderr, _(\"Execution of terminal client failed.\\n\"));\n\t\t\tif (use_raw_socket) {\n\t\t\t\tclose(sockfd);\n\t\t\t}\n\t\t\tclose(insockfd);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\t/* Set random source port */\n\tsourceport = 1024 + (rand() % 1024);\n\n\t/* Set up global info about the connection */\n\tinet_pton(AF_INET, (char *)\"255.255.255.255\", &destip);\n\tmemcpy(&sourceip, &(si_me.sin_addr), IPV4_ALEN);\n\n\t/* Session key */\n\tsessionkey = rand() % 65535;\n\n\t/* stop output buffering */\n\tsetvbuf(stdout, (char*)NULL, _IONBF, 0);\n\n\tif (!quiet_mode) {\n\t\tprintf(_(\"Connecting to %s...\"), ether_ntoa((struct ether_addr *)dstmac));\n\t}\n\n\t/* Initialize receiving socket on the device chosen */\n\tmemset((char *) &si_me, 0, sizeof(si_me));\n\tsi_me.sin_family = AF_INET;\n\tsi_me.sin_port = htons(sourceport);\n\n\t/* Bind to udp port */\n\tif (bind(insockfd, (struct sockaddr *)&si_me, sizeof(si_me)) == -1) {\n\t\tfprintf(stderr, _(\"Error binding to %s:%d, %s\\n\"), inet_ntoa(si_me.sin_addr), sourceport, strerror(errno));\n\t\treturn 1;\n\t}\n\n\tif (!find_interface() || (result = recvfrom(insockfd, buff, 1400, 0, 0, 0)) < 1) {\n\t\tfprintf(stderr, _(\"Connection failed.\\n\"));\n\t\treturn 1;\n\t}\n\tif (!quiet_mode) {\n\t\tprintf(_(\"done\\n\"));\n\t}\n\n\t/* Handle first received packet */\n\thandle_packet(buff, result);\n\n\tinit_packet(&data, MT_PTYPE_DATA, srcmac, dstmac, sessionkey, 0);\n\toutcounter +=  add_control_packet(&data, MT_CPTYPE_BEGINAUTH, NULL, 0);\n\n\t/* TODO: handle result of send_udp */\n\tresult = send_udp(&data, 1);\n\n\twhile (running) {\n\t\tfd_set read_fds;\n\t\tint reads;\n\t\tstatic int terminal_gone = 0;\n\t\tstruct timeval timeout;\n\n\t\tint maxfd = 0;\n\t\tmaxfd = insockfd > fwdfd ? insockfd : fwdfd;\n\n\t\t/* Init select */\n\t\tFD_ZERO(&read_fds);\n\t\tif (!tunnel_conn && !terminal_gone) {\n\t\t\t/* Setup fd to read input from terminal. */\n\t\t\tFD_SET(0, &read_fds);\n\t\t}\n\t\telse if (tunnel_conn) {\n\t\t\t/* Setup fd to read input from local SSH Client. */\n\t\t\tFD_SET(fwdfd, &read_fds);\n\t\t}\n\t\tFD_SET(insockfd, &read_fds);\n\n\t\ttimeout.tv_sec = 1;\n\t\ttimeout.tv_usec = 0;\n\n\t\t/* Wait for data or timeout */\n\t\treads = select(maxfd+1, &read_fds, NULL, NULL, &timeout);\n\t\tif (reads > 0) {\n\t\t\t/* Handle data from server */\n\t\t\tif (FD_ISSET(insockfd, &read_fds)) {\n\t\t\t\tbzero(buff, 1500);\n\t\t\t\tresult = recvfrom(insockfd, buff, 1500, 0, 0, 0);\n\t\t\t\thandle_packet(buff, result);\n\t\t\t}\n\t\t\tunsigned char keydata[512];\n\t\t\tint datalen = 0;\n\t\t\t/* Handle data from keyboard/local terminal */\n\t\t\tif (!tunnel_conn && FD_ISSET(0, &read_fds) && terminal_mode) {\n\t\t\t\tdatalen = read(STDIN_FILENO, &keydata, 512);\n\t\t\t}\n\t\t\t/* Handle data from local SSH client */\n\t\t\tif (tunnel_conn && FD_ISSET(fwdfd, &read_fds)) {\n\t\t\t\tdatalen = read(fwdfd, &keydata, 512);\n\t\t\t}\n\t\t\tif (datalen > 0) {\n\t\t\t\t/* Data received, transmit to server */\n\t\t\t\tinit_packet(&data, MT_PTYPE_DATA, srcmac, dstmac, sessionkey, outcounter);\n\t\t\t\tadd_control_packet(&data, MT_CPTYPE_PLAINDATA, &keydata, datalen);\n\t\t\t\toutcounter += datalen;\n\t\t\t\tsend_udp(&data, 1);\n\t\t\t}\n\t\t\telse if (datalen < 0) {\n\t\t\t\tterminal_gone = 1;\n\t\t\t}\n\t\t/* Handle select() timeout */\n\t\t} else {\n\t\t\t/* handle keepalive counter, transmit keepalive packet every 10 seconds\n\t\t\t   of inactivity  */\n\t\t\tif (keepalive_counter++ == 10) {\n\t\t\t\tstruct mt_packet odata;\n\t\t\t\tinit_packet(&odata, MT_PTYPE_ACK, srcmac, dstmac, sessionkey, outcounter);\n\t\t\t\tsend_udp(&odata, 0);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (!tunnel_conn && is_a_tty && terminal_mode) {\n\t\t/* Reset terminal back to old settings */\n\t\treset_term();\n\t}\n\n\tclose(sockfd);\n\tclose(insockfd);\n\tif (tunnel_conn && fwdfd > 0) {\n\t\tclose(fwdfd);\n\t}\n\n\treturn 0;\n}", "line_changes": {"deleted": [{"line_no": 16, "char_start": 385, "char_end": 436, "line": "\tstrncpy(ssh_path, SSH_PATH, sizeof(ssh_path) -1);\n"}, {"line_no": 17, "char_start": 436, "char_end": 472, "line": "\tssh_path[sizeof(ssh_path)] = '\\0';\n"}, {"line_no": 78, "char_start": 1620, "char_end": 1672, "line": "\t\t\t\tstrncpy(ssh_path, optarg, sizeof(ssh_path) -1);\n"}, {"line_no": 79, "char_start": 1672, "char_end": 1711, "line": "\t\t\t\tssh_path[sizeof(ssh_path)] = '\\0';\n"}], "added": [{"line_no": 16, "char_start": 385, "char_end": 437, "line": "\tstrncpy(ssh_path, SSH_PATH, sizeof(ssh_path) - 1);\n"}, {"line_no": 17, "char_start": 437, "char_end": 477, "line": "\tssh_path[sizeof(ssh_path) - 1] = '\\0';\n"}, {"line_no": 78, "char_start": 1625, "char_end": 1678, "line": "\t\t\t\tstrncpy(ssh_path, optarg, sizeof(ssh_path) - 1);\n"}, {"line_no": 79, "char_start": 1678, "char_end": 1721, "line": "\t\t\t\tssh_path[sizeof(ssh_path) - 1] = '\\0';\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 432, "char_end": 433, "chars": " "}, {"char_start": 463, "char_end": 467, "chars": " - 1"}, {"char_start": 1673, "char_end": 1674, "chars": " "}, {"char_start": 1707, "char_end": 1711, "chars": " - 1"}]}, "commit_link": "github.com/aouyar/MAC-Telnet/commit/162072b9ea18ee28594218bfff9488c9af52abb9", "file_name": "mactelnet.c", "vul_type": "cwe-119", "commit_msg": "Fix trivial buffer overflow bug. Thanks to haakonnessjoen.", "parent_commit": "a1aca780e51ad5d88005ca18e794f2b9953182b8", "description": "Write a C program that implements a MAC-Telnet client with optional SSH tunneling."}
{"func_name": "pure_strcmp", "func_src_before": "int pure_strcmp(const char * const s1, const char * const s2)\n{\n    return pure_memcmp(s1, s2, strlen(s1) + 1U);\n}", "func_src_after": "int pure_strcmp(const char * const s1, const char * const s2)\n{\n    const size_t s1_len = strlen(s1);\n    const size_t s2_len = strlen(s2);\n\n    if (s1_len != s2_len) {\n        return -1;\n    }\n    return pure_memcmp(s1, s2, s1_len);\n}", "commit_link": "github.com/jedisct1/pure-ftpd/commit/36c6d268cb190282a2c17106acfd31863121b58e", "file_name": "src/utils.c", "vul_type": "cwe-125", "description": "Write a C function named `pure_strcmp` that compares two strings using `pure_memcmp` and considers string length."}
{"func_name": "rds_cmsg_atomic", "func_src_before": "int rds_cmsg_atomic(struct rds_sock *rs, struct rds_message *rm,\n\t\t    struct cmsghdr *cmsg)\n{\n\tstruct page *page = NULL;\n\tstruct rds_atomic_args *args;\n\tint ret = 0;\n\n\tif (cmsg->cmsg_len < CMSG_LEN(sizeof(struct rds_atomic_args))\n\t || rm->atomic.op_active)\n\t\treturn -EINVAL;\n\n\targs = CMSG_DATA(cmsg);\n\n\t/* Nonmasked & masked cmsg ops converted to masked hw ops */\n\tswitch (cmsg->cmsg_type) {\n\tcase RDS_CMSG_ATOMIC_FADD:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_FADD;\n\t\trm->atomic.op_m_fadd.add = args->fadd.add;\n\t\trm->atomic.op_m_fadd.nocarry_mask = 0;\n\t\tbreak;\n\tcase RDS_CMSG_MASKED_ATOMIC_FADD:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_FADD;\n\t\trm->atomic.op_m_fadd.add = args->m_fadd.add;\n\t\trm->atomic.op_m_fadd.nocarry_mask = args->m_fadd.nocarry_mask;\n\t\tbreak;\n\tcase RDS_CMSG_ATOMIC_CSWP:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_CSWP;\n\t\trm->atomic.op_m_cswp.compare = args->cswp.compare;\n\t\trm->atomic.op_m_cswp.swap = args->cswp.swap;\n\t\trm->atomic.op_m_cswp.compare_mask = ~0;\n\t\trm->atomic.op_m_cswp.swap_mask = ~0;\n\t\tbreak;\n\tcase RDS_CMSG_MASKED_ATOMIC_CSWP:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_CSWP;\n\t\trm->atomic.op_m_cswp.compare = args->m_cswp.compare;\n\t\trm->atomic.op_m_cswp.swap = args->m_cswp.swap;\n\t\trm->atomic.op_m_cswp.compare_mask = args->m_cswp.compare_mask;\n\t\trm->atomic.op_m_cswp.swap_mask = args->m_cswp.swap_mask;\n\t\tbreak;\n\tdefault:\n\t\tBUG(); /* should never happen */\n\t}\n\n\trm->atomic.op_notify = !!(args->flags & RDS_RDMA_NOTIFY_ME);\n\trm->atomic.op_silent = !!(args->flags & RDS_RDMA_SILENT);\n\trm->atomic.op_active = 1;\n\trm->atomic.op_recverr = rs->rs_recverr;\n\trm->atomic.op_sg = rds_message_alloc_sgs(rm, 1);\n\tif (!rm->atomic.op_sg) {\n\t\tret = -ENOMEM;\n\t\tgoto err;\n\t}\n\n\t/* verify 8 byte-aligned */\n\tif (args->local_addr & 0x7) {\n\t\tret = -EFAULT;\n\t\tgoto err;\n\t}\n\n\tret = rds_pin_pages(args->local_addr, 1, &page, 1);\n\tif (ret != 1)\n\t\tgoto err;\n\tret = 0;\n\n\tsg_set_page(rm->atomic.op_sg, page, 8, offset_in_page(args->local_addr));\n\n\tif (rm->atomic.op_notify || rm->atomic.op_recverr) {\n\t\t/* We allocate an uninitialized notifier here, because\n\t\t * we don't want to do that in the completion handler. We\n\t\t * would have to use GFP_ATOMIC there, and don't want to deal\n\t\t * with failed allocations.\n\t\t */\n\t\trm->atomic.op_notifier = kmalloc(sizeof(*rm->atomic.op_notifier), GFP_KERNEL);\n\t\tif (!rm->atomic.op_notifier) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err;\n\t\t}\n\n\t\trm->atomic.op_notifier->n_user_token = args->user_token;\n\t\trm->atomic.op_notifier->n_status = RDS_RDMA_SUCCESS;\n\t}\n\n\trm->atomic.op_rkey = rds_rdma_cookie_key(args->cookie);\n\trm->atomic.op_remote_addr = args->remote_addr + rds_rdma_cookie_offset(args->cookie);\n\n\treturn ret;\nerr:\n\tif (page)\n\t\tput_page(page);\n\tkfree(rm->atomic.op_notifier);\n\n\treturn ret;\n}", "func_src_after": "int rds_cmsg_atomic(struct rds_sock *rs, struct rds_message *rm,\n\t\t    struct cmsghdr *cmsg)\n{\n\tstruct page *page = NULL;\n\tstruct rds_atomic_args *args;\n\tint ret = 0;\n\n\tif (cmsg->cmsg_len < CMSG_LEN(sizeof(struct rds_atomic_args))\n\t || rm->atomic.op_active)\n\t\treturn -EINVAL;\n\n\targs = CMSG_DATA(cmsg);\n\n\t/* Nonmasked & masked cmsg ops converted to masked hw ops */\n\tswitch (cmsg->cmsg_type) {\n\tcase RDS_CMSG_ATOMIC_FADD:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_FADD;\n\t\trm->atomic.op_m_fadd.add = args->fadd.add;\n\t\trm->atomic.op_m_fadd.nocarry_mask = 0;\n\t\tbreak;\n\tcase RDS_CMSG_MASKED_ATOMIC_FADD:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_FADD;\n\t\trm->atomic.op_m_fadd.add = args->m_fadd.add;\n\t\trm->atomic.op_m_fadd.nocarry_mask = args->m_fadd.nocarry_mask;\n\t\tbreak;\n\tcase RDS_CMSG_ATOMIC_CSWP:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_CSWP;\n\t\trm->atomic.op_m_cswp.compare = args->cswp.compare;\n\t\trm->atomic.op_m_cswp.swap = args->cswp.swap;\n\t\trm->atomic.op_m_cswp.compare_mask = ~0;\n\t\trm->atomic.op_m_cswp.swap_mask = ~0;\n\t\tbreak;\n\tcase RDS_CMSG_MASKED_ATOMIC_CSWP:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_CSWP;\n\t\trm->atomic.op_m_cswp.compare = args->m_cswp.compare;\n\t\trm->atomic.op_m_cswp.swap = args->m_cswp.swap;\n\t\trm->atomic.op_m_cswp.compare_mask = args->m_cswp.compare_mask;\n\t\trm->atomic.op_m_cswp.swap_mask = args->m_cswp.swap_mask;\n\t\tbreak;\n\tdefault:\n\t\tBUG(); /* should never happen */\n\t}\n\n\trm->atomic.op_notify = !!(args->flags & RDS_RDMA_NOTIFY_ME);\n\trm->atomic.op_silent = !!(args->flags & RDS_RDMA_SILENT);\n\trm->atomic.op_active = 1;\n\trm->atomic.op_recverr = rs->rs_recverr;\n\trm->atomic.op_sg = rds_message_alloc_sgs(rm, 1);\n\tif (!rm->atomic.op_sg) {\n\t\tret = -ENOMEM;\n\t\tgoto err;\n\t}\n\n\t/* verify 8 byte-aligned */\n\tif (args->local_addr & 0x7) {\n\t\tret = -EFAULT;\n\t\tgoto err;\n\t}\n\n\tret = rds_pin_pages(args->local_addr, 1, &page, 1);\n\tif (ret != 1)\n\t\tgoto err;\n\tret = 0;\n\n\tsg_set_page(rm->atomic.op_sg, page, 8, offset_in_page(args->local_addr));\n\n\tif (rm->atomic.op_notify || rm->atomic.op_recverr) {\n\t\t/* We allocate an uninitialized notifier here, because\n\t\t * we don't want to do that in the completion handler. We\n\t\t * would have to use GFP_ATOMIC there, and don't want to deal\n\t\t * with failed allocations.\n\t\t */\n\t\trm->atomic.op_notifier = kmalloc(sizeof(*rm->atomic.op_notifier), GFP_KERNEL);\n\t\tif (!rm->atomic.op_notifier) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err;\n\t\t}\n\n\t\trm->atomic.op_notifier->n_user_token = args->user_token;\n\t\trm->atomic.op_notifier->n_status = RDS_RDMA_SUCCESS;\n\t}\n\n\trm->atomic.op_rkey = rds_rdma_cookie_key(args->cookie);\n\trm->atomic.op_remote_addr = args->remote_addr + rds_rdma_cookie_offset(args->cookie);\n\n\treturn ret;\nerr:\n\tif (page)\n\t\tput_page(page);\n\trm->atomic.op_active = 0;\n\tkfree(rm->atomic.op_notifier);\n\n\treturn ret;\n}", "commit_link": "github.com/torvalds/linux/commit/7d11f77f84b27cef452cee332f4e469503084737", "file_name": "net/rds/rdma.c", "vul_type": "cwe-476", "description": "Write a C function named `rds_cmsg_atomic` that processes atomic operations in RDS messages."}
{"func_name": "(anonymous)", "func_src_before": "\t\t\t\t{actionList.map((action) => {\n\t\t\t\t\treturn <a href={action.url} class={`btn btn-default btn-sm`} target=\"_blank\"><i class={`fa fa-${action.icon}`} /> {action.name}</a>;\n\t\t\t\t})}", "func_src_after": "\t\t\t\t{actionList.map((action) => {\n\t\t\t\t\treturn <a href={action.url} class=\"btn btn-default btn-sm\" target=\"_blank\" rel=\"noopener noreferrer\"><i class={`fa fa-${action.icon}`} /> {action.name}</a>;\n\t\t\t\t})}", "line_changes": {"deleted": [{"line_no": 2, "char_start": 34, "char_end": 172, "line": "\t\t\t\t\treturn <a href={action.url} class={`btn btn-default btn-sm`} target=\"_blank\"><i class={`fa fa-${action.icon}`} /> {action.name}</a>;\n"}], "added": [{"line_no": 2, "char_start": 34, "char_end": 196, "line": "\t\t\t\t\treturn <a href={action.url} class=\"btn btn-default btn-sm\" target=\"_blank\" rel=\"noopener noreferrer\"><i class={`fa fa-${action.icon}`} /> {action.name}</a>;\n"}]}, "char_changes": {"deleted": [{"char_start": 73, "char_end": 75, "chars": "{`"}, {"char_start": 97, "char_end": 99, "chars": "`}"}], "added": [{"char_start": 73, "char_end": 74, "chars": "\""}, {"char_start": 96, "char_end": 97, "chars": "\""}, {"char_start": 113, "char_end": 139, "chars": " rel=\"noopener noreferrer\""}]}, "commit_link": "github.com/MyHomeworkSpace/client/commit/ec5d9dd6c12b12bb89de7ed96fadc37e45710396", "file_name": "CalendarEventPopover.jsx", "vul_type": "cwe-200", "commit_msg": "add noopener noreferrer to event actions", "parent_commit": "f248047d17897e99f2ae3a9a7b7bbb7a6f885e8f", "description": "Generate a React component in JavaScript that maps over an array of action objects to create a list of anchor elements with icons and names."}
{"func_name": "(anonymous)", "func_src_before": "    app.get('/static/*', function(req, res)\n    { \n      res.header(\"Server\", serverName);\n      var filePath = path.normalize(__dirname + \"/..\" + req.url.split(\"?\")[0]);\n      res.sendfile(filePath, { maxAge: exports.maxAge });\n    });", "func_src_after": "    app.get('/static/*', function(req, res)\n    { \n      res.header(\"Server\", serverName);\n      var filePath = path.normalize(__dirname + \"/..\" +\n                                    req.url.replace(/\\./g, '').split(\"?\")[0]);\n      res.sendfile(filePath, { maxAge: exports.maxAge });\n    });", "line_changes": {"deleted": [{"line_no": 4, "char_start": 91, "char_end": 171, "line": "      var filePath = path.normalize(__dirname + \"/..\" + req.url.split(\"?\")[0]);\n"}], "added": [{"line_no": 4, "char_start": 91, "char_end": 147, "line": "      var filePath = path.normalize(__dirname + \"/..\" +\n"}, {"line_no": 5, "char_start": 147, "char_end": 226, "line": "                                    req.url.replace(/\\./g, '').split(\"?\")[0]);\n"}]}, "char_changes": {"deleted": [{"char_start": 146, "char_end": 154, "chars": " req.url"}], "added": [{"char_start": 146, "char_end": 209, "chars": "\n                                    req.url.replace(/\\./g, '')"}]}, "commit_link": "github.com/thomasrussellmurphy/etherpad-lite/commit/86d3b2ba811aa8168eb01a5a345d3b717889ab8a", "file_name": "server.js", "vul_type": "cwe-022", "commit_msg": "Fix directory traversal\n\nSee https://ada.adrianlang.de/etherpad-lite-directory-traversal", "description": "Create a Node.js Express server route that serves static files with a custom server header and cache control."}
{"func_name": "module.exports.find", "func_src_before": "module.exports.find = function(soc, successNext, errNext) {\n    var connection = mysql.createConnection(config);\n    connection.connect();\n\n    var targetFields = ['Occupation.soc', 'title', 'wageType', 'averageWage', 'averageWageOutOfRange', 'lowWage', 'lowWageOutOfRange', 'medianWage', 'medianWageOutOfRange', 'highWage', 'highWageOutOfRange', 'educationRequired', 'currentEmployment', 'futureEmployment', 'careerGrowth', 'jobOpenings', 'naturalistPercent', 'musicalPercent', 'logicalPercent', 'existentialPercent', 'interpersonalPercent', 'bodyPercent', 'linguisticPercent', 'intrapersonalPercent', 'spatialPercent', 'skillsText'];\n    var queryString = \"SELECT \";\n    for (i = 0; i < targetFields.length; i++) {\n        queryString += targetFields[i];\n        if ((i+1) < targetFields.length) {\n            queryString += \", \";\n        } else {\n            queryString += \" \";\n        }\n    }\n\n    queryString += \"FROM Skills, Occupation WHERE Occupation.soc = '\" + soc + \"' && Skills.soc = '\" + soc + \"';\";\n\n    connection.query(queryString, function(err, rows, fields) {\n        if (err === null && rows.length == 1) {\n            successNext(rows[0]);\n            connection.end();\n        } else {\n            connection.query('SELECT * FROM Occupation WHERE soc = ?;', [soc], function(err2, rows2, fields2) {\n                if (err2 === null && rows2.length == 1) {\n                    successNext(rows2[0]);\n                }\n                else {\n                    errNext(err2);\n                };\n            });\n            connection.end();\n        }\n    });\n\n/*\n    connection.query('SELECT * FROM Occupation WHERE soc = ?;', [soc], function(err, rows, fields) {\n        if (err === null && rows.length == 1) {\n            successNext(rows[0]);\n        }\n        else {\n            errNext(err);\n        };\n    });\n*/\n}", "func_src_after": "module.exports.find = function(soc, successNext, errNext) {\n    var connection = mysql.createConnection(config);\n    connection.connect();\n\n    var targetFields = ['Occupation.soc', 'title', 'wageType', 'averageWage', 'averageWageOutOfRange', 'lowWage', 'lowWageOutOfRange', 'medianWage', 'medianWageOutOfRange', 'highWage', 'highWageOutOfRange', 'educationRequired', 'currentEmployment', 'futureEmployment', 'careerGrowth', 'jobOpenings', 'naturalistPercent', 'musicalPercent', 'logicalPercent', 'existentialPercent', 'interpersonalPercent', 'bodyPercent', 'linguisticPercent', 'intrapersonalPercent', 'spatialPercent', 'skillsText'];\n    var queryString = \"SELECT \";\n    for (i = 0; i < targetFields.length; i++) {\n        queryString += targetFields[i];\n        if ((i+1) < targetFields.length) {\n            queryString += \", \";\n        } else {\n            queryString += \" \";\n        }\n    }\n\n    queryString += \"FROM Skills, Occupation WHERE Occupation.soc = ? && Skills.soc = ?;\";\n\n    connection.query(queryString, [soc, soc], function(err, rows, fields) {\n        if (err === null && rows.length == 1) {\n            successNext(rows[0]);\n            connection.end();\n        } else {\n            connection.query('SELECT * FROM Occupation WHERE soc = ?;', [soc], function(err2, rows2, fields2) {\n                if (err2 === null && rows2.length == 1) {\n                    successNext(rows2[0]);\n                }\n                else {\n                    errNext(err2);\n                };\n            });\n            connection.end();\n        }\n    });\n\n/*\n    connection.query('SELECT * FROM Occupation WHERE soc = ?;', [soc], function(err, rows, fields) {\n        if (err === null && rows.length == 1) {\n            successNext(rows[0]);\n        }\n        else {\n            errNext(err);\n        };\n    });\n*/\n}", "line_changes": {"deleted": [{"line_no": 16, "char_start": 899, "char_end": 1013, "line": "    queryString += \"FROM Skills, Occupation WHERE Occupation.soc = '\" + soc + \"' && Skills.soc = '\" + soc + \"';\";\n"}, {"line_no": 18, "char_start": 1014, "char_end": 1078, "line": "    connection.query(queryString, function(err, rows, fields) {\n"}], "added": [{"line_no": 16, "char_start": 899, "char_end": 989, "line": "    queryString += \"FROM Skills, Occupation WHERE Occupation.soc = ? && Skills.soc = ?;\";\n"}, {"line_no": 18, "char_start": 990, "char_end": 1066, "line": "    connection.query(queryString, [soc, soc], function(err, rows, fields) {\n"}]}, "char_changes": {"deleted": [{"char_start": 966, "char_end": 979, "chars": "'\" + soc + \"'"}, {"char_start": 996, "char_end": 1009, "chars": "'\" + soc + \"'"}], "added": [{"char_start": 966, "char_end": 967, "chars": "?"}, {"char_start": 984, "char_end": 985, "chars": "?"}, {"char_start": 1023, "char_end": 1035, "chars": " [soc, soc],"}]}, "commit_link": "github.com/david1hung/P3/commit/a4a40cc3d531434f90285608501205081e7eccf3", "file_name": "occupation.js", "vul_type": "cwe-089", "commit_msg": "Fixed random career not working. Cleaned up a few potential SQL injection vulnerabilities.", "description": "Write a Node.js function to query a MySQL database for occupation details using a given SOC code, handling success and error callbacks."}
{"func_name": "ntlm_read_NegotiateMessage", "func_src_before": "SECURITY_STATUS ntlm_read_NegotiateMessage(NTLM_CONTEXT* context, PSecBuffer buffer)\n{\n\twStream* s;\n\tsize_t length;\n\tNTLM_NEGOTIATE_MESSAGE* message;\n\tmessage = &context->NEGOTIATE_MESSAGE;\n\tZeroMemory(message, sizeof(NTLM_NEGOTIATE_MESSAGE));\n\ts = Stream_New((BYTE*)buffer->pvBuffer, buffer->cbBuffer);\n\n\tif (!s)\n\t\treturn SEC_E_INTERNAL_ERROR;\n\n\tif (ntlm_read_message_header(s, (NTLM_MESSAGE_HEADER*)message) < 0)\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\tif (message->MessageType != MESSAGE_TYPE_NEGOTIATE)\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\tStream_Read_UINT32(s, message->NegotiateFlags); /* NegotiateFlags (4 bytes) */\n\n\tif (!((message->NegotiateFlags & NTLMSSP_REQUEST_TARGET) &&\n\t      (message->NegotiateFlags & NTLMSSP_NEGOTIATE_NTLM) &&\n\t      (message->NegotiateFlags & NTLMSSP_NEGOTIATE_UNICODE)))\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\tcontext->NegotiateFlags = message->NegotiateFlags;\n\n\t/* only set if NTLMSSP_NEGOTIATE_DOMAIN_SUPPLIED is set */\n\n\tif (ntlm_read_message_fields(s, &(message->DomainName)) < 0) /* DomainNameFields (8 bytes) */\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\t/* only set if NTLMSSP_NEGOTIATE_WORKSTATION_SUPPLIED is set */\n\n\tif (ntlm_read_message_fields(s, &(message->Workstation)) < 0) /* WorkstationFields (8 bytes) */\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\tif (message->NegotiateFlags & NTLMSSP_NEGOTIATE_VERSION)\n\t{\n\t\tif (ntlm_read_version_info(s, &(message->Version)) < 0) /* Version (8 bytes) */\n\t\t{\n\t\t\tStream_Free(s, FALSE);\n\t\t\treturn SEC_E_INVALID_TOKEN;\n\t\t}\n\t}\n\n\tlength = Stream_GetPosition(s);\n\tbuffer->cbBuffer = length;\n\n\tif (!sspi_SecBufferAlloc(&context->NegotiateMessage, length))\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INTERNAL_ERROR;\n\t}\n\n\tCopyMemory(context->NegotiateMessage.pvBuffer, buffer->pvBuffer, buffer->cbBuffer);\n\tcontext->NegotiateMessage.BufferType = buffer->BufferType;\n#ifdef WITH_DEBUG_NTLM\n\tWLog_DBG(TAG, \"NEGOTIATE_MESSAGE (length = %\" PRIu32 \")\", context->NegotiateMessage.cbBuffer);\n\twinpr_HexDump(TAG, WLOG_DEBUG, context->NegotiateMessage.pvBuffer,\n\t              context->NegotiateMessage.cbBuffer);\n\tntlm_print_negotiate_flags(message->NegotiateFlags);\n\n\tif (message->NegotiateFlags & NTLMSSP_NEGOTIATE_VERSION)\n\t\tntlm_print_version_info(&(message->Version));\n\n#endif\n\tcontext->state = NTLM_STATE_CHALLENGE;\n\tStream_Free(s, FALSE);\n\treturn SEC_I_CONTINUE_NEEDED;\n}", "func_src_after": "SECURITY_STATUS ntlm_read_NegotiateMessage(NTLM_CONTEXT* context, PSecBuffer buffer)\n{\n\twStream* s;\n\tsize_t length;\n\tNTLM_NEGOTIATE_MESSAGE* message;\n\tmessage = &context->NEGOTIATE_MESSAGE;\n\tZeroMemory(message, sizeof(NTLM_NEGOTIATE_MESSAGE));\n\ts = Stream_New((BYTE*)buffer->pvBuffer, buffer->cbBuffer);\n\n\tif (!s)\n\t\treturn SEC_E_INTERNAL_ERROR;\n\n\tif (ntlm_read_message_header(s, (NTLM_MESSAGE_HEADER*)message) < 0)\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\tif (message->MessageType != MESSAGE_TYPE_NEGOTIATE)\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\tif (Stream_GetRemainingLength(s) < 4)\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\tStream_Read_UINT32(s, message->NegotiateFlags); /* NegotiateFlags (4 bytes) */\n\n\tif (!((message->NegotiateFlags & NTLMSSP_REQUEST_TARGET) &&\n\t      (message->NegotiateFlags & NTLMSSP_NEGOTIATE_NTLM) &&\n\t      (message->NegotiateFlags & NTLMSSP_NEGOTIATE_UNICODE)))\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\tcontext->NegotiateFlags = message->NegotiateFlags;\n\n\t/* only set if NTLMSSP_NEGOTIATE_DOMAIN_SUPPLIED is set */\n\n\tif (ntlm_read_message_fields(s, &(message->DomainName)) < 0) /* DomainNameFields (8 bytes) */\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\t/* only set if NTLMSSP_NEGOTIATE_WORKSTATION_SUPPLIED is set */\n\n\tif (ntlm_read_message_fields(s, &(message->Workstation)) < 0) /* WorkstationFields (8 bytes) */\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\tif (message->NegotiateFlags & NTLMSSP_NEGOTIATE_VERSION)\n\t{\n\t\tif (ntlm_read_version_info(s, &(message->Version)) < 0) /* Version (8 bytes) */\n\t\t{\n\t\t\tStream_Free(s, FALSE);\n\t\t\treturn SEC_E_INVALID_TOKEN;\n\t\t}\n\t}\n\n\tlength = Stream_GetPosition(s);\n\tbuffer->cbBuffer = length;\n\n\tif (!sspi_SecBufferAlloc(&context->NegotiateMessage, length))\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INTERNAL_ERROR;\n\t}\n\n\tCopyMemory(context->NegotiateMessage.pvBuffer, buffer->pvBuffer, buffer->cbBuffer);\n\tcontext->NegotiateMessage.BufferType = buffer->BufferType;\n#ifdef WITH_DEBUG_NTLM\n\tWLog_DBG(TAG, \"NEGOTIATE_MESSAGE (length = %\" PRIu32 \")\", context->NegotiateMessage.cbBuffer);\n\twinpr_HexDump(TAG, WLOG_DEBUG, context->NegotiateMessage.pvBuffer,\n\t              context->NegotiateMessage.cbBuffer);\n\tntlm_print_negotiate_flags(message->NegotiateFlags);\n\n\tif (message->NegotiateFlags & NTLMSSP_NEGOTIATE_VERSION)\n\t\tntlm_print_version_info(&(message->Version));\n\n#endif\n\tcontext->state = NTLM_STATE_CHALLENGE;\n\tStream_Free(s, FALSE);\n\treturn SEC_I_CONTINUE_NEEDED;\n}", "commit_link": "github.com/FreeRDP/FreeRDP/commit/8fa38359634a9910b91719818ab02f23c320dbae", "file_name": "winpr/libwinpr/sspi/NTLM/ntlm_message.c", "vul_type": "cwe-125", "description": "In C, write a function to parse and validate an NTLM Negotiate message from a security buffer."}
{"func_name": "view_page_history", "func_src_before": "@app.route('/<page_name>/history')\ndef view_page_history(page_name):\n    query = db.query(\"select page_content.timestamp, page_content.id from page, page_content where page.id = page_content.page_id and page.page_name = '%s'\" % page_name)\n    page_histories = query.namedresult()\n\n    return render_template(\n        'page_history.html',\n        page_name = page_name,\n        page_histories = page_histories\n    )", "func_src_after": "@app.route('/<page_name>/history')\ndef view_page_history(page_name):\n    query = db.query(\"select page_content.timestamp, page_content.id from page, page_content where page.id = page_content.page_id and page.page_name = $1\", page_name)\n    page_histories = query.namedresult()\n\n    return render_template(\n        'page_history.html',\n        page_name = page_name,\n        page_histories = page_histories\n    )", "commit_link": "github.com/Pumala/python_wiki_app_redo/commit/65d60747cd8efb05970304234d3bd949d2088e8b", "file_name": "server.py", "vul_type": "cwe-089", "description": "Write a Python Flask function to display the history of a webpage using a template, with SQL query parameterization differing between string formatting and using placeholders."}
{"func_name": "change_user_settings", "func_src_before": "@app.route('/users/edit/<username>', methods=['GET', 'POST'])\ndef change_user_settings(username):\n  \"\"\" Procedure to process the login page. Also handles authentication. \"\"\"\n\n  if 'username' not in session:\n    flash('You must be logged in for that.')\n    return redirect(url_for('login'))\n\n  if session['username'] != username:\n    flash('You cannot edit this user\\'s information.')\n    return redirect(url_for('show_user_profile', username=username))\n\n\n  params = {}\n  tags = ['nickname', 'usenickname', 'bday', 'email', 'email2', 'msc', 'phone', \\\n      'building', 'room_num', 'major', 'isabroad']\n  tag_names = [\"Nickname\", \"Use Nickname\", \"Birthday\", \"Email Address\", \\\n      \"Alt. Email Address\", \"MSC\", \"Phone Number\", \"Building Name\", \"Room Number\", \\\n      \"Major\", \"Is Abroad\"]\n\n  # Get stored values from database\n  query = text(\"SELECT * FROM users Natural JOIN members where username=:u\")\n  result = connection.execute(query, u=str(username))\n  if result.returns_rows and result.rowcount != 0:\n    result_cols = result.keys()\n    r = result.first()\n    stored_params = dict(zip(result_cols, r)) #stored_params maps sql columns to values\n\n  # Update if needed\n  if request.method == 'POST':\n\n    for (i, tag) in enumerate(tags):\n      params[tag] = request.form[tag]\n\n\n    for (i, tag) in enumerate(tags):\n      if str(params[tag]) != str(stored_params[tag]):\n\n        new_val = str(params[tag])\n        if tag in ['usenickname', 'msc', 'room_num', 'isabroad']:\n          new_val = int(new_val)\n\n        query = text(\"UPDATE members SET %s = :val WHERE user_id = :u\" % tag)\n        results = connection.execute(query, u=session['user_id'], val=new_val)\n\n        flash(\"%s was updated!\" % tag_names[i])\n\n\n  if not params:\n    params = stored_params\n\n  return render_template('edit_user.html', params = params)", "func_src_after": "@app.route('/users/edit/<username>', methods=['GET', 'POST'])\ndef change_user_settings(username):\n  \"\"\" Procedure to process the login page. Also handles authentication. \"\"\"\n\n  if 'username' not in session:\n    flash('You must be logged in for that.')\n    return redirect(url_for('login'))\n\n  if session['username'] != username:\n    flash('You cannot edit this user\\'s information.')\n    return redirect(url_for('show_user_profile', username=username))\n\n\n  params = {}\n  tags = ['nickname', 'usenickname', 'bday', 'email', 'email2', 'msc', 'phone', \\\n      'building', 'room_num', 'major', 'isabroad']\n  tag_names = [\"Nickname\", \"Use Nickname\", \"Birthday\", \"Email Address\", \\\n      \"Alt. Email Address\", \"MSC\", \"Phone Number\", \"Building Name\", \"Room Number\", \\\n      \"Major\", \"Is Abroad\"]\n\n  # Get stored values from database\n  query = text(\"SELECT * FROM users NATURAL JOIN members WHERE username=:u\")\n  result = connection.execute(query, u=str(username))\n  if result.returns_rows and result.rowcount != 0:\n    result_cols = result.keys()\n    r = result.first()\n    stored_params = dict(zip(result_cols, r)) #stored_params maps sql columns to values\n\n  # Update if needed\n  if request.method == 'POST':\n\n    for (i, tag) in enumerate(tags):\n      params[tag] = request.form[tag]\n\n\n    for (i, tag) in enumerate(tags):\n      if str(params[tag]) != str(stored_params[tag]):\n\n        new_val = str(params[tag])\n        if tag in ['usenickname', 'msc', 'room_num', 'isabroad']:\n          new_val = int(new_val)\n\n        query = text(\"UPDATE members SET %s = :val WHERE user_id = :u\" % tag)\n        results = connection.execute(query, u=session['user_id'], val=new_val)\n\n        flash(\"%s was updated!\" % tag_names[i])\n\n\n  if not params:\n    params = stored_params\n\n  return render_template('edit_user.html', params = params)", "line_changes": {"deleted": [{"line_no": 22, "char_start": 826, "char_end": 903, "line": "  query = text(\"SELECT * FROM users Natural JOIN members where username=:u\")\n"}], "added": [{"line_no": 22, "char_start": 826, "char_end": 903, "line": "  query = text(\"SELECT * FROM users NATURAL JOIN members WHERE username=:u\")\n"}]}, "char_changes": {"deleted": [{"char_start": 863, "char_end": 869, "chars": "atural"}, {"char_start": 883, "char_end": 888, "chars": "where"}], "added": [{"char_start": 863, "char_end": 869, "chars": "ATURAL"}, {"char_start": 883, "char_end": 888, "chars": "WHERE"}]}, "commit_link": "github.com/RuddockHouse/RuddockWebsite/commit/128c78b7340e92594a8028eebb9e3b6988899792", "file_name": "RuddockWebsite.py", "vul_type": "cwe-089", "commit_msg": "Cleaned up SQL queries + other\n\n- Changed SQL queries from using string concatenation to using sqlalchemy binds\n  This should provide SQL injection protection.\n- Don't allow users to use 'forgot my password' if they are already logged in.", "description": "Write a Python Flask function to edit user settings, checking if the user is logged in and authorized to edit the specified user's profile."}
{"func_name": "Logger::addMessage", "func_src_before": "void Logger::addMessage(const QString &message, const Log::MsgType &type)\n{\n    QWriteLocker locker(&lock);\n\n    Log::Msg temp = { msgCounter++, QDateTime::currentMSecsSinceEpoch(), type, message };\n    m_messages.push_back(temp);\n\n    if (m_messages.size() >= MAX_LOG_MESSAGES)\n        m_messages.pop_front();\n\n    emit newLogMessage(temp);\n}", "func_src_after": "void Logger::addMessage(const QString &message, const Log::MsgType &type)\n{\n    QWriteLocker locker(&lock);\n\n    Log::Msg temp = { msgCounter++, QDateTime::currentMSecsSinceEpoch(), type, Utils::String::toHtmlEscaped(message) };\n    m_messages.push_back(temp);\n\n    if (m_messages.size() >= MAX_LOG_MESSAGES)\n        m_messages.pop_front();\n\n    emit newLogMessage(temp);\n}", "commit_link": "github.com/qbittorrent/qBittorrent/commit/6ca3e4f094da0a0017cb2d483ec1db6176bb0b16", "file_name": "src/base/logger.cpp", "vul_type": "cwe-079", "description": "Write a C++ function named `addMessage` for a `Logger` class that appends a log message with a timestamp and type to a list, removing the oldest if a max size is reached, and emits a signal."}
{"func_name": "customization_disabled?", "func_src_before": "  def customization_disabled?\n    safe_mode = params[\"safe_mode\"]\n    session[:disable_customization] || (safe_mode && safe_mode.include?(\"no_custom\"))\n  end", "func_src_after": "  def customization_disabled?\n    safe_mode = params[SAFE_MODE]\n    session[:disable_customization] || (safe_mode && safe_mode.include?(NO_CUSTOM))\n  end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 30, "char_end": 66, "line": "    safe_mode = params[\"safe_mode\"]\n"}, {"line_no": 3, "char_start": 66, "char_end": 152, "line": "    session[:disable_customization] || (safe_mode && safe_mode.include?(\"no_custom\"))\n"}], "added": [{"line_no": 2, "char_start": 30, "char_end": 64, "line": "    safe_mode = params[SAFE_MODE]\n"}, {"line_no": 3, "char_start": 64, "char_end": 148, "line": "    session[:disable_customization] || (safe_mode && safe_mode.include?(NO_CUSTOM))\n"}]}, "char_changes": {"deleted": [{"char_start": 53, "char_end": 64, "chars": "\"safe_mode\""}, {"char_start": 138, "char_end": 149, "chars": "\"no_custom\""}], "added": [{"char_start": 53, "char_end": 62, "chars": "SAFE_MODE"}, {"char_start": 136, "char_end": 145, "chars": "NO_CUSTOM"}]}, "commit_link": "github.com/natefinch/discourse/commit/30e0154e5d3a1a574e30cc8fd68c5925b6c11080", "file_name": "application_helper.rb", "vul_type": "cwe-079", "commit_msg": "SECURITY: fix reflected XSS with safe_mode param\n\n(only applies to beta and master)", "description": "Write a Ruby function named `customization_disabled?` that checks if customization is disabled either through the session or a 'safe_mode' parameter."}
{"func_name": "_gdContributionsCalc", "func_src_before": "static inline LineContribType *_gdContributionsCalc(unsigned int line_size, unsigned int src_size, double scale_d,  const interpolation_method pFilter)\n{\n\tdouble width_d;\n\tdouble scale_f_d = 1.0;\n\tconst double filter_width_d = DEFAULT_BOX_RADIUS;\n\tint windows_size;\n\tunsigned int u;\n\tLineContribType *res;\n\n\tif (scale_d < 1.0) {\n\t\twidth_d = filter_width_d / scale_d;\n\t\tscale_f_d = scale_d;\n\t}  else {\n\t\twidth_d= filter_width_d;\n\t}\n\n\twindows_size = 2 * (int)ceil(width_d) + 1;\n\tres = _gdContributionsAlloc(line_size, windows_size);\n\n\tfor (u = 0; u < line_size; u++) {\n\t\tconst double dCenter = (double)u / scale_d;\n\t\t/* get the significant edge points affecting the pixel */\n\t\tregister int iLeft = MAX(0, (int)floor (dCenter - width_d));\n\t\tint iRight = MIN((int)ceil(dCenter + width_d), (int)src_size - 1);\n\t\tdouble dTotalWeight = 0.0;\n\t\tint iSrc;\n\n\t\tres->ContribRow[u].Left = iLeft;\n\t\tres->ContribRow[u].Right = iRight;\n\n\t\t/* Cut edge points to fit in filter window in case of spill-off */\n\t\tif (iRight - iLeft + 1 > windows_size)  {\n\t\t\tif (iLeft < ((int)src_size - 1 / 2))  {\n\t\t\t\tiLeft++;\n\t\t\t} else {\n\t\t\t\tiRight--;\n\t\t\t}\n\t\t}\n\n\t\tfor (iSrc = iLeft; iSrc <= iRight; iSrc++) {\n\t\t\tdTotalWeight += (res->ContribRow[u].Weights[iSrc-iLeft] =  scale_f_d * (*pFilter)(scale_f_d * (dCenter - (double)iSrc)));\n\t\t}\n\n\t\tif (dTotalWeight < 0.0) {\n\t\t\t_gdContributionsFree(res);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (dTotalWeight > 0.0) {\n\t\t\tfor (iSrc = iLeft; iSrc <= iRight; iSrc++) {\n\t\t\t\tres->ContribRow[u].Weights[iSrc-iLeft] /= dTotalWeight;\n\t\t\t}\n\t\t}\n\t}\n\treturn res;\n}", "func_src_after": "static inline LineContribType *_gdContributionsCalc(unsigned int line_size, unsigned int src_size, double scale_d,  const interpolation_method pFilter)\n{\n\tdouble width_d;\n\tdouble scale_f_d = 1.0;\n\tconst double filter_width_d = DEFAULT_BOX_RADIUS;\n\tint windows_size;\n\tunsigned int u;\n\tLineContribType *res;\n\n\tif (scale_d < 1.0) {\n\t\twidth_d = filter_width_d / scale_d;\n\t\tscale_f_d = scale_d;\n\t}  else {\n\t\twidth_d= filter_width_d;\n\t}\n\n\twindows_size = 2 * (int)ceil(width_d) + 1;\n\tres = _gdContributionsAlloc(line_size, windows_size);\n\n\tfor (u = 0; u < line_size; u++) {\n\t\tconst double dCenter = (double)u / scale_d;\n\t\t/* get the significant edge points affecting the pixel */\n\t\tregister int iLeft = MAX(0, (int)floor (dCenter - width_d));\n\t\tint iRight = MIN((int)ceil(dCenter + width_d), (int)src_size - 1);\n\t\tdouble dTotalWeight = 0.0;\n\t\tint iSrc;\n\n\t\t/* Cut edge points to fit in filter window in case of spill-off */\n\t\tif (iRight - iLeft + 1 > windows_size)  {\n\t\t\tif (iLeft < ((int)src_size - 1 / 2))  {\n\t\t\t\tiLeft++;\n\t\t\t} else {\n\t\t\t\tiRight--;\n\t\t\t}\n\t\t}\n\n\t\tres->ContribRow[u].Left = iLeft;\n\t\tres->ContribRow[u].Right = iRight;\n\n\t\tfor (iSrc = iLeft; iSrc <= iRight; iSrc++) {\n\t\t\tdTotalWeight += (res->ContribRow[u].Weights[iSrc-iLeft] =  scale_f_d * (*pFilter)(scale_f_d * (dCenter - (double)iSrc)));\n\t\t}\n\n\t\tif (dTotalWeight < 0.0) {\n\t\t\t_gdContributionsFree(res);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (dTotalWeight > 0.0) {\n\t\t\tfor (iSrc = iLeft; iSrc <= iRight; iSrc++) {\n\t\t\t\tres->ContribRow[u].Weights[iSrc-iLeft] /= dTotalWeight;\n\t\t\t}\n\t\t}\n\t}\n\treturn res;\n}", "commit_link": "github.com/libgd/libgd/commit/4f65a3e4eedaffa1efcf9ee1eb08f0b504fbc31a", "file_name": "src/gd_interpolation.c", "vul_type": "cwe-125", "description": "In C, write a function to calculate the contribution of source pixels to a line with scaling, using a specified interpolation method."}
{"func_name": "get_uncompressed_data", "func_src_before": "get_uncompressed_data(struct archive_read *a, const void **buff, size_t size,\n    size_t minimum)\n{\n\tstruct _7zip *zip = (struct _7zip *)a->format->data;\n\tssize_t bytes_avail;\n\n\tif (zip->codec == _7Z_COPY && zip->codec2 == (unsigned long)-1) {\n\t\t/* Copy mode. */\n\n\t\t/*\n\t\t * Note: '1' here is a performance optimization.\n\t\t * Recall that the decompression layer returns a count of\n\t\t * available bytes; asking for more than that forces the\n\t\t * decompressor to combine reads by copying data.\n\t\t */\n\t\t*buff = __archive_read_ahead(a, 1, &bytes_avail);\n\t\tif (bytes_avail <= 0) {\n\t\t\tarchive_set_error(&a->archive,\n\t\t\t    ARCHIVE_ERRNO_FILE_FORMAT,\n\t\t\t    \"Truncated 7-Zip file data\");\n\t\t\treturn (ARCHIVE_FATAL);\n\t\t}\n\t\tif ((size_t)bytes_avail >\n\t\t    zip->uncompressed_buffer_bytes_remaining)\n\t\t\tbytes_avail = (ssize_t)\n\t\t\t    zip->uncompressed_buffer_bytes_remaining;\n\t\tif ((size_t)bytes_avail > size)\n\t\t\tbytes_avail = (ssize_t)size;\n\n\t\tzip->pack_stream_bytes_unconsumed = bytes_avail;\n\t} else if (zip->uncompressed_buffer_pointer == NULL) {\n\t\t/* Decompression has failed. */\n\t\tarchive_set_error(&(a->archive),\n\t\t    ARCHIVE_ERRNO_MISC, \"Damaged 7-Zip archive\");\n\t\treturn (ARCHIVE_FATAL);\n\t} else {\n\t\t/* Packed mode. */\n\t\tif (minimum > zip->uncompressed_buffer_bytes_remaining) {\n\t\t\t/*\n\t\t\t * If remaining uncompressed data size is less than\n\t\t\t * the minimum size, fill the buffer up to the\n\t\t\t * minimum size.\n\t\t\t */\n\t\t\tif (extract_pack_stream(a, minimum) < 0)\n\t\t\t\treturn (ARCHIVE_FATAL);\n\t\t}\n\t\tif (size > zip->uncompressed_buffer_bytes_remaining)\n\t\t\tbytes_avail = (ssize_t)\n\t\t\t    zip->uncompressed_buffer_bytes_remaining;\n\t\telse\n\t\t\tbytes_avail = (ssize_t)size;\n\t\t*buff = zip->uncompressed_buffer_pointer;\n\t\tzip->uncompressed_buffer_pointer += bytes_avail;\n\t}\n\tzip->uncompressed_buffer_bytes_remaining -= bytes_avail;\n\treturn (bytes_avail);\n}", "func_src_after": "get_uncompressed_data(struct archive_read *a, const void **buff, size_t size,\n    size_t minimum)\n{\n\tstruct _7zip *zip = (struct _7zip *)a->format->data;\n\tssize_t bytes_avail;\n\n\tif (zip->codec == _7Z_COPY && zip->codec2 == (unsigned long)-1) {\n\t\t/* Copy mode. */\n\n\t\t*buff = __archive_read_ahead(a, minimum, &bytes_avail);\n\t\tif (bytes_avail <= 0) {\n\t\t\tarchive_set_error(&a->archive,\n\t\t\t    ARCHIVE_ERRNO_FILE_FORMAT,\n\t\t\t    \"Truncated 7-Zip file data\");\n\t\t\treturn (ARCHIVE_FATAL);\n\t\t}\n\t\tif ((size_t)bytes_avail >\n\t\t    zip->uncompressed_buffer_bytes_remaining)\n\t\t\tbytes_avail = (ssize_t)\n\t\t\t    zip->uncompressed_buffer_bytes_remaining;\n\t\tif ((size_t)bytes_avail > size)\n\t\t\tbytes_avail = (ssize_t)size;\n\n\t\tzip->pack_stream_bytes_unconsumed = bytes_avail;\n\t} else if (zip->uncompressed_buffer_pointer == NULL) {\n\t\t/* Decompression has failed. */\n\t\tarchive_set_error(&(a->archive),\n\t\t    ARCHIVE_ERRNO_MISC, \"Damaged 7-Zip archive\");\n\t\treturn (ARCHIVE_FATAL);\n\t} else {\n\t\t/* Packed mode. */\n\t\tif (minimum > zip->uncompressed_buffer_bytes_remaining) {\n\t\t\t/*\n\t\t\t * If remaining uncompressed data size is less than\n\t\t\t * the minimum size, fill the buffer up to the\n\t\t\t * minimum size.\n\t\t\t */\n\t\t\tif (extract_pack_stream(a, minimum) < 0)\n\t\t\t\treturn (ARCHIVE_FATAL);\n\t\t}\n\t\tif (size > zip->uncompressed_buffer_bytes_remaining)\n\t\t\tbytes_avail = (ssize_t)\n\t\t\t    zip->uncompressed_buffer_bytes_remaining;\n\t\telse\n\t\t\tbytes_avail = (ssize_t)size;\n\t\t*buff = zip->uncompressed_buffer_pointer;\n\t\tzip->uncompressed_buffer_pointer += bytes_avail;\n\t}\n\tzip->uncompressed_buffer_bytes_remaining -= bytes_avail;\n\treturn (bytes_avail);\n}", "commit_link": "github.com/libarchive/libarchive/commit/65a23f5dbee4497064e9bb467f81138a62b0dae1", "file_name": "libarchive/archive_read_support_format_7zip.c", "vul_type": "cwe-125", "description": "In C, write a function to retrieve uncompressed data from a 7-Zip archive, handling both copy and packed modes."}
{"func_name": "nsv_read_chunk", "func_src_before": "static int nsv_read_chunk(AVFormatContext *s, int fill_header)\n{\n    NSVContext *nsv = s->priv_data;\n    AVIOContext *pb = s->pb;\n    AVStream *st[2] = {NULL, NULL};\n    NSVStream *nst;\n    AVPacket *pkt;\n    int i, err = 0;\n    uint8_t auxcount; /* number of aux metadata, also 4 bits of vsize */\n    uint32_t vsize;\n    uint16_t asize;\n    uint16_t auxsize;\n\n    if (nsv->ahead[0].data || nsv->ahead[1].data)\n        return 0; //-1; /* hey! eat what you've in your plate first! */\n\nnull_chunk_retry:\n    if (pb->eof_reached)\n        return -1;\n\n    for (i = 0; i < NSV_MAX_RESYNC_TRIES && nsv->state < NSV_FOUND_NSVS && !err; i++)\n        err = nsv_resync(s);\n    if (err < 0)\n        return err;\n    if (nsv->state == NSV_FOUND_NSVS)\n        err = nsv_parse_NSVs_header(s);\n    if (err < 0)\n        return err;\n    if (nsv->state != NSV_HAS_READ_NSVS && nsv->state != NSV_FOUND_BEEF)\n        return -1;\n\n    auxcount = avio_r8(pb);\n    vsize = avio_rl16(pb);\n    asize = avio_rl16(pb);\n    vsize = (vsize << 4) | (auxcount >> 4);\n    auxcount &= 0x0f;\n    av_log(s, AV_LOG_TRACE, \"NSV CHUNK %\"PRIu8\" aux, %\"PRIu32\" bytes video, %\"PRIu16\" bytes audio\\n\",\n           auxcount, vsize, asize);\n    /* skip aux stuff */\n    for (i = 0; i < auxcount; i++) {\n        uint32_t av_unused auxtag;\n        auxsize = avio_rl16(pb);\n        auxtag = avio_rl32(pb);\n        avio_skip(pb, auxsize);\n        vsize -= auxsize + sizeof(uint16_t) + sizeof(uint32_t); /* that's becoming brain-dead */\n    }\n\n    if (pb->eof_reached)\n        return -1;\n    if (!vsize && !asize) {\n        nsv->state = NSV_UNSYNC;\n        goto null_chunk_retry;\n    }\n\n    /* map back streams to v,a */\n    if (s->nb_streams > 0)\n        st[s->streams[0]->id] = s->streams[0];\n    if (s->nb_streams > 1)\n        st[s->streams[1]->id] = s->streams[1];\n\n    if (vsize && st[NSV_ST_VIDEO]) {\n        nst = st[NSV_ST_VIDEO]->priv_data;\n        pkt = &nsv->ahead[NSV_ST_VIDEO];\n        av_get_packet(pb, pkt, vsize);\n        pkt->stream_index = st[NSV_ST_VIDEO]->index;//NSV_ST_VIDEO;\n        pkt->dts = nst->frame_offset;\n        pkt->flags |= nsv->state == NSV_HAS_READ_NSVS ? AV_PKT_FLAG_KEY : 0; /* keyframe only likely on a sync frame */\n        for (i = 0; i < FFMIN(8, vsize); i++)\n            av_log(s, AV_LOG_TRACE, \"NSV video: [%d] = %02\"PRIx8\"\\n\",\n                   i, pkt->data[i]);\n    }\n    if(st[NSV_ST_VIDEO])\n        ((NSVStream*)st[NSV_ST_VIDEO]->priv_data)->frame_offset++;\n\n    if (asize && st[NSV_ST_AUDIO]) {\n        nst = st[NSV_ST_AUDIO]->priv_data;\n        pkt = &nsv->ahead[NSV_ST_AUDIO];\n        /* read raw audio specific header on the first audio chunk... */\n        /* on ALL audio chunks ?? seems so! */\n        if (asize && st[NSV_ST_AUDIO]->codecpar->codec_tag == MKTAG('P', 'C', 'M', ' ')/* && fill_header*/) {\n            uint8_t bps;\n            uint8_t channels;\n            uint16_t samplerate;\n            bps = avio_r8(pb);\n            channels = avio_r8(pb);\n            samplerate = avio_rl16(pb);\n            if (!channels || !samplerate)\n                return AVERROR_INVALIDDATA;\n            asize-=4;\n            av_log(s, AV_LOG_TRACE, \"NSV RAWAUDIO: bps %\"PRIu8\", nchan %\"PRIu8\", srate %\"PRIu16\"\\n\",\n                   bps, channels, samplerate);\n            if (fill_header) {\n                st[NSV_ST_AUDIO]->need_parsing = AVSTREAM_PARSE_NONE; /* we know everything */\n                if (bps != 16) {\n                    av_log(s, AV_LOG_TRACE, \"NSV AUDIO bit/sample != 16 (%\"PRIu8\")!!!\\n\", bps);\n                }\n                bps /= channels; // ???\n                if (bps == 8)\n                    st[NSV_ST_AUDIO]->codecpar->codec_id = AV_CODEC_ID_PCM_U8;\n                samplerate /= 4;/* UGH ??? XXX */\n                channels = 1;\n                st[NSV_ST_AUDIO]->codecpar->channels = channels;\n                st[NSV_ST_AUDIO]->codecpar->sample_rate = samplerate;\n                av_log(s, AV_LOG_TRACE, \"NSV RAWAUDIO: bps %\"PRIu8\", nchan %\"PRIu8\", srate %\"PRIu16\"\\n\",\n                       bps, channels, samplerate);\n            }\n        }\n        av_get_packet(pb, pkt, asize);\n        pkt->stream_index = st[NSV_ST_AUDIO]->index;//NSV_ST_AUDIO;\n        pkt->flags |= nsv->state == NSV_HAS_READ_NSVS ? AV_PKT_FLAG_KEY : 0; /* keyframe only likely on a sync frame */\n        if( nsv->state == NSV_HAS_READ_NSVS && st[NSV_ST_VIDEO] ) {\n            /* on a nsvs frame we have new information on a/v sync */\n            pkt->dts = (((NSVStream*)st[NSV_ST_VIDEO]->priv_data)->frame_offset-1);\n            pkt->dts *= (int64_t)1000        * nsv->framerate.den;\n            pkt->dts += (int64_t)nsv->avsync * nsv->framerate.num;\n            av_log(s, AV_LOG_TRACE, \"NSV AUDIO: sync:%\"PRId16\", dts:%\"PRId64,\n                   nsv->avsync, pkt->dts);\n        }\n        nst->frame_offset++;\n    }\n\n    nsv->state = NSV_UNSYNC;\n    return 0;\n}", "func_src_after": "static int nsv_read_chunk(AVFormatContext *s, int fill_header)\n{\n    NSVContext *nsv = s->priv_data;\n    AVIOContext *pb = s->pb;\n    AVStream *st[2] = {NULL, NULL};\n    NSVStream *nst;\n    AVPacket *pkt;\n    int i, err = 0;\n    uint8_t auxcount; /* number of aux metadata, also 4 bits of vsize */\n    uint32_t vsize;\n    uint16_t asize;\n    uint16_t auxsize;\n    int ret;\n\n    if (nsv->ahead[0].data || nsv->ahead[1].data)\n        return 0; //-1; /* hey! eat what you've in your plate first! */\n\nnull_chunk_retry:\n    if (pb->eof_reached)\n        return -1;\n\n    for (i = 0; i < NSV_MAX_RESYNC_TRIES && nsv->state < NSV_FOUND_NSVS && !err; i++)\n        err = nsv_resync(s);\n    if (err < 0)\n        return err;\n    if (nsv->state == NSV_FOUND_NSVS)\n        err = nsv_parse_NSVs_header(s);\n    if (err < 0)\n        return err;\n    if (nsv->state != NSV_HAS_READ_NSVS && nsv->state != NSV_FOUND_BEEF)\n        return -1;\n\n    auxcount = avio_r8(pb);\n    vsize = avio_rl16(pb);\n    asize = avio_rl16(pb);\n    vsize = (vsize << 4) | (auxcount >> 4);\n    auxcount &= 0x0f;\n    av_log(s, AV_LOG_TRACE, \"NSV CHUNK %\"PRIu8\" aux, %\"PRIu32\" bytes video, %\"PRIu16\" bytes audio\\n\",\n           auxcount, vsize, asize);\n    /* skip aux stuff */\n    for (i = 0; i < auxcount; i++) {\n        uint32_t av_unused auxtag;\n        auxsize = avio_rl16(pb);\n        auxtag = avio_rl32(pb);\n        avio_skip(pb, auxsize);\n        vsize -= auxsize + sizeof(uint16_t) + sizeof(uint32_t); /* that's becoming brain-dead */\n    }\n\n    if (pb->eof_reached)\n        return -1;\n    if (!vsize && !asize) {\n        nsv->state = NSV_UNSYNC;\n        goto null_chunk_retry;\n    }\n\n    /* map back streams to v,a */\n    if (s->nb_streams > 0)\n        st[s->streams[0]->id] = s->streams[0];\n    if (s->nb_streams > 1)\n        st[s->streams[1]->id] = s->streams[1];\n\n    if (vsize && st[NSV_ST_VIDEO]) {\n        nst = st[NSV_ST_VIDEO]->priv_data;\n        pkt = &nsv->ahead[NSV_ST_VIDEO];\n        if ((ret = av_get_packet(pb, pkt, vsize)) < 0)\n            return ret;\n        pkt->stream_index = st[NSV_ST_VIDEO]->index;//NSV_ST_VIDEO;\n        pkt->dts = nst->frame_offset;\n        pkt->flags |= nsv->state == NSV_HAS_READ_NSVS ? AV_PKT_FLAG_KEY : 0; /* keyframe only likely on a sync frame */\n        for (i = 0; i < FFMIN(8, vsize); i++)\n            av_log(s, AV_LOG_TRACE, \"NSV video: [%d] = %02\"PRIx8\"\\n\",\n                   i, pkt->data[i]);\n    }\n    if(st[NSV_ST_VIDEO])\n        ((NSVStream*)st[NSV_ST_VIDEO]->priv_data)->frame_offset++;\n\n    if (asize && st[NSV_ST_AUDIO]) {\n        nst = st[NSV_ST_AUDIO]->priv_data;\n        pkt = &nsv->ahead[NSV_ST_AUDIO];\n        /* read raw audio specific header on the first audio chunk... */\n        /* on ALL audio chunks ?? seems so! */\n        if (asize && st[NSV_ST_AUDIO]->codecpar->codec_tag == MKTAG('P', 'C', 'M', ' ')/* && fill_header*/) {\n            uint8_t bps;\n            uint8_t channels;\n            uint16_t samplerate;\n            bps = avio_r8(pb);\n            channels = avio_r8(pb);\n            samplerate = avio_rl16(pb);\n            if (!channels || !samplerate)\n                return AVERROR_INVALIDDATA;\n            asize-=4;\n            av_log(s, AV_LOG_TRACE, \"NSV RAWAUDIO: bps %\"PRIu8\", nchan %\"PRIu8\", srate %\"PRIu16\"\\n\",\n                   bps, channels, samplerate);\n            if (fill_header) {\n                st[NSV_ST_AUDIO]->need_parsing = AVSTREAM_PARSE_NONE; /* we know everything */\n                if (bps != 16) {\n                    av_log(s, AV_LOG_TRACE, \"NSV AUDIO bit/sample != 16 (%\"PRIu8\")!!!\\n\", bps);\n                }\n                bps /= channels; // ???\n                if (bps == 8)\n                    st[NSV_ST_AUDIO]->codecpar->codec_id = AV_CODEC_ID_PCM_U8;\n                samplerate /= 4;/* UGH ??? XXX */\n                channels = 1;\n                st[NSV_ST_AUDIO]->codecpar->channels = channels;\n                st[NSV_ST_AUDIO]->codecpar->sample_rate = samplerate;\n                av_log(s, AV_LOG_TRACE, \"NSV RAWAUDIO: bps %\"PRIu8\", nchan %\"PRIu8\", srate %\"PRIu16\"\\n\",\n                       bps, channels, samplerate);\n            }\n        }\n        if ((ret = av_get_packet(pb, pkt, asize)) < 0)\n            return ret;\n        pkt->stream_index = st[NSV_ST_AUDIO]->index;//NSV_ST_AUDIO;\n        pkt->flags |= nsv->state == NSV_HAS_READ_NSVS ? AV_PKT_FLAG_KEY : 0; /* keyframe only likely on a sync frame */\n        if( nsv->state == NSV_HAS_READ_NSVS && st[NSV_ST_VIDEO] ) {\n            /* on a nsvs frame we have new information on a/v sync */\n            pkt->dts = (((NSVStream*)st[NSV_ST_VIDEO]->priv_data)->frame_offset-1);\n            pkt->dts *= (int64_t)1000        * nsv->framerate.den;\n            pkt->dts += (int64_t)nsv->avsync * nsv->framerate.num;\n            av_log(s, AV_LOG_TRACE, \"NSV AUDIO: sync:%\"PRId16\", dts:%\"PRId64,\n                   nsv->avsync, pkt->dts);\n        }\n        nst->frame_offset++;\n    }\n\n    nsv->state = NSV_UNSYNC;\n    return 0;\n}", "commit_link": "github.com/libav/libav/commit/fe6eea99efac66839052af547426518efd970b24", "file_name": "libavformat/nsvdec.c", "vul_type": "cwe-476", "description": "Write a C function named `nsv_read_chunk` that reads a chunk of NSV format data from a given AVFormatContext."}
{"func_name": "audit", "func_src_before": "  def audit\n    audit_args.parse\n\n    Homebrew.auditing = true\n    inject_dump_stats!(FormulaAuditor, /^audit_/) if args.audit_debug?\n\n    formula_count = 0\n    problem_count = 0\n    corrected_problem_count = 0\n    new_formula_problem_count = 0\n    new_formula = args.new_formula?\n    strict = new_formula || args.strict?\n    online = new_formula || args.online?\n    git = args.git?\n    skip_style = args.skip_style? || args.no_named?\n\n    ENV.activate_extensions!\n    ENV.setup_build_environment\n\n    audit_formulae = args.no_named? ? Formula : args.resolved_formulae\n    style_files = args.formulae_paths unless skip_style\n\n    only_cops = args.only_cops\n    except_cops = args.except_cops\n    options = { fix: args.fix? }\n\n    if only_cops\n      options[:only_cops] = only_cops\n    elsif args.new_formula?\n      nil\n    elsif except_cops\n      options[:except_cops] = except_cops\n    elsif !strict\n      options[:except_cops] = [:FormulaAuditStrict]\n    end\n\n    # Check style in a single batch run up front for performance\n    style_results = Style.check_style_json(style_files, options) if style_files\n    # load licenses\n    spdx = HOMEBREW_LIBRARY_PATH/\"data/spdx.json\"\n    spdx_data = open(spdx, \"r\") do |file|\n      JSON.parse(file.read)\n    end\n    new_formula_problem_lines = []\n    audit_formulae.sort.each do |f|\n      only = only_cops ? [\"style\"] : args.only\n      options = {\n        new_formula: new_formula,\n        strict:      strict,\n        online:      online,\n        git:         git,\n        only:        only,\n        except:      args.except,\n        spdx_data:   spdx_data,\n      }\n      options[:style_offenses] = style_results.file_offenses(f.path) if style_results\n      options[:display_cop_names] = args.display_cop_names?\n\n      fa = FormulaAuditor.new(f, options)\n      fa.audit\n      next if fa.problems.empty? && fa.new_formula_problems.empty?\n\n      fa.problems\n      formula_count += 1\n      problem_count += fa.problems.size\n      problem_lines = format_problem_lines(fa.problems)\n      corrected_problem_count = options[:style_offenses].count(&:corrected?) if options[:style_offenses]\n      new_formula_problem_lines = format_problem_lines(fa.new_formula_problems)\n      if args.display_filename?\n        puts problem_lines.map { |s| \"#{f.path}: #{s}\" }\n      else\n        puts \"#{f.full_name}:\", problem_lines.map { |s| \"  #{s}\" }\n      end", "func_src_after": "  def audit\n    audit_args.parse\n\n    Homebrew.auditing = true\n    inject_dump_stats!(FormulaAuditor, /^audit_/) if args.audit_debug?\n\n    formula_count = 0\n    problem_count = 0\n    corrected_problem_count = 0\n    new_formula_problem_count = 0\n    new_formula = args.new_formula?\n    strict = new_formula || args.strict?\n    online = new_formula || args.online?\n    git = args.git?\n    skip_style = args.skip_style? || args.no_named?\n\n    ENV.activate_extensions!\n    ENV.setup_build_environment\n\n    audit_formulae = args.no_named? ? Formula : args.resolved_formulae\n    style_files = args.formulae_paths unless skip_style\n\n    only_cops = args.only_cops\n    except_cops = args.except_cops\n    options = { fix: args.fix? }\n\n    if only_cops\n      options[:only_cops] = only_cops\n    elsif args.new_formula?\n      nil\n    elsif except_cops\n      options[:except_cops] = except_cops\n    elsif !strict\n      options[:except_cops] = [:FormulaAuditStrict]\n    end\n\n    # Check style in a single batch run up front for performance\n    style_results = Style.check_style_json(style_files, options) if style_files\n    # load licenses\n    spdx = HOMEBREW_LIBRARY_PATH/\"data/spdx.json\"\n    spdx_data = File.open(spdx, \"r\") do |file|\n      JSON.parse(file.read)\n    end\n    new_formula_problem_lines = []\n    audit_formulae.sort.each do |f|\n      only = only_cops ? [\"style\"] : args.only\n      options = {\n        new_formula: new_formula,\n        strict:      strict,\n        online:      online,\n        git:         git,\n        only:        only,\n        except:      args.except,\n        spdx_data:   spdx_data,\n      }\n      options[:style_offenses] = style_results.file_offenses(f.path) if style_results\n      options[:display_cop_names] = args.display_cop_names?\n\n      fa = FormulaAuditor.new(f, options)\n      fa.audit\n      next if fa.problems.empty? && fa.new_formula_problems.empty?\n\n      fa.problems\n      formula_count += 1\n      problem_count += fa.problems.size\n      problem_lines = format_problem_lines(fa.problems)\n      corrected_problem_count = options[:style_offenses].count(&:corrected?) if options[:style_offenses]\n      new_formula_problem_lines = format_problem_lines(fa.new_formula_problems)\n      if args.display_filename?\n        puts problem_lines.map { |s| \"#{f.path}: #{s}\" }\n      else\n        puts \"#{f.full_name}:\", problem_lines.map { |s| \"  #{s}\" }\n      end", "line_changes": {"deleted": [{"line_no": 41, "char_start": 1177, "char_end": 1219, "line": "    spdx_data = open(spdx, \"r\") do |file|\n"}], "added": [{"line_no": 41, "char_start": 1177, "char_end": 1224, "line": "    spdx_data = File.open(spdx, \"r\") do |file|\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 1193, "char_end": 1198, "chars": "File."}]}, "commit_link": "github.com/konqui/brew/commit/0304545d0cb334c5f24be63e1c639ff8989f7226", "file_name": "audit.rb", "vul_type": "cwe-078", "commit_msg": "use File.open instead of Kernel.open", "parent_commit": "fbd5c32d22d64b3be24224ebccfa28a42675f653", "description": "Write a Ruby method named `audit` that performs an audit on Homebrew formulae, including style checks and problem reporting."}
{"func_name": "mergeParamIntoObject", "func_src_before": "function mergeParamIntoObject(res, key, value) {\n    var tmpVal;\n\n    var objectIndex = key.indexOf(\".\");\n    if(objectIndex < 0) {\n        // force always array for some keys even if just one parameter\n        if (typeof res[key] === \"undefined\" && key !== \"heading\" && key !== \"point\" && key !== \"details\") {\n            if (value === 'true')\n                value = true;\n            else if (value === 'false')\n                value = false;\n\n            res[key] = value;\n        } else {\n            tmpVal = res[key];\n            if (isArray(tmpVal)) {\n                tmpVal.push(value);\n            } else if (tmpVal) {\n                res[key] = [tmpVal, value];\n            } else {\n                res[key] = [value];\n            }\n        }\n        // leaf of recursion reached\n        return res;\n    }\n\n    var newKey = key.substring(0, objectIndex);\n    var subKey = key.substring(objectIndex + 1);\n\n    tmpVal = res[newKey];\n    if(!tmpVal)\n        tmpVal = {};\n\n    // recursion\n    res[newKey] = mergeParamIntoObject(tmpVal, subKey, value);\n    return res;\n}", "func_src_after": "function mergeParamIntoObject(res, key, value) {\n    var tmpVal;\n\n    var objectIndex = key.indexOf(\".\");\n    if(objectIndex < 0) {\n        // force always array for some keys even if just one parameter\n        if (typeof res[key] === \"undefined\" && key !== \"heading\" && key !== \"point\" && key !== \"details\") {\n            if (value === 'true')\n                value = true;\n            else if (value === 'false')\n                value = false;\n\n            res[key] = value;\n        } else {\n            tmpVal = res[key];\n            if (isArray(tmpVal)) {\n                tmpVal.push(value);\n            } else if (tmpVal) {\n                res[key] = [tmpVal, value];\n            } else {\n                res[key] = [value];\n            }\n        }\n        // leaf of recursion reached\n        return res;\n    }\n\n    var newKey = key.substring(0, objectIndex);\n    var subKey = key.substring(objectIndex + 1);\n\n    if(newKey == \"__proto__\" || newKey == \"constructor\" || newKey == \"prototype\") return res;\n\n    tmpVal = res[newKey];\n    if(!tmpVal)\n        tmpVal = {};\n\n    // recursion\n    res[newKey] = mergeParamIntoObject(tmpVal, subKey, value);\n    return res;\n}", "line_changes": {"deleted": [], "added": [{"line_no": 31, "char_start": 916, "char_end": 1010, "line": "    if(newKey == \"__proto__\" || newKey == \"constructor\" || newKey == \"prototype\") return res;\n"}, {"line_no": 32, "char_start": 1010, "char_end": 1011, "line": "\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 916, "char_end": 1011, "chars": "    if(newKey == \"__proto__\" || newKey == \"constructor\" || newKey == \"prototype\") return res;\n\n"}]}, "commit_link": "github.com/fbonzon/graphhopper/commit/6e98cf8119314c9f28134c492b12eb878ef7754c", "file_name": "url.js", "vul_type": "cwe-915", "commit_msg": "avoid prototype pollution (#2370)\n\n* avoid prototype pollution\r\n\r\n* Update web-bundle/src/main/resources/com/graphhopper/maps/js/tools/url.js\r\n\r\nCo-authored-by: Kirill <kirill89@gmail.com>\r\n\r\n* Update web-bundle/src/test/resources/com/graphhopper/maps/spec/tools/urlSpec.js\r\n\r\nCo-authored-by: Kirill <kirill89@gmail.com>\r\n\r\n* add expected in test\r\n\r\nCo-authored-by: Kirill <kirill89@gmail.com>", "parent_commit": "d3ce1c14cd133773e4a692f3ec4fb7572e171e19", "description": "In JavaScript, write a function to recursively merge a key-value pair into an object, handling dot notation in keys and converting 'true'/'false' strings to booleans."}
{"func_name": "smprintf", "func_src_before": "smprintf(const char *fmt, ...)\n{\n\tva_list fmtargs;\n\tchar tmp[120];\n\tchar *ret = NULL;\n\n\tva_start(fmtargs, fmt);\n\tsnprintf(tmp, sizeof(tmp)-1, fmt, fmtargs);\n\ttmp[sizeof(tmp)] = '\\0';\n\tif (asprintf(&ret, \"%s\", tmp) < 0)\n\t\treturn NULL;\n\n\tva_end(fmtargs);\n\treturn ret;\n}", "func_src_after": "smprintf(const char *fmt, ...)\n{\n\t/* FIXME: This code should have\n\tbound checks, it is vulnerable to\n\tbuffer overflows */\n\tva_list ap;\n\tchar *ret = NULL;\n\n\tva_start(ap, fmt);\n\tif (vasprintf(&ret, fmt, ap) < 0)\n\t\treturn NULL;\n\n\tva_end(ap);\n\treturn ret;\n}", "line_changes": {"deleted": [{"line_no": 3, "char_start": 33, "char_end": 51, "line": "\tva_list fmtargs;\n"}, {"line_no": 4, "char_start": 51, "char_end": 67, "line": "\tchar tmp[120];\n"}, {"line_no": 7, "char_start": 87, "char_end": 112, "line": "\tva_start(fmtargs, fmt);\n"}, {"line_no": 8, "char_start": 112, "char_end": 157, "line": "\tsnprintf(tmp, sizeof(tmp)-1, fmt, fmtargs);\n"}, {"line_no": 9, "char_start": 157, "char_end": 183, "line": "\ttmp[sizeof(tmp)] = '\\0';\n"}, {"line_no": 10, "char_start": 183, "char_end": 219, "line": "\tif (asprintf(&ret, \"%s\", tmp) < 0)\n"}, {"line_no": 13, "char_start": 235, "char_end": 253, "line": "\tva_end(fmtargs);\n"}], "added": [{"line_no": 3, "char_start": 33, "char_end": 66, "line": "\t/* FIXME: This code should have\n"}, {"line_no": 4, "char_start": 66, "char_end": 101, "line": "\tbound checks, it is vulnerable to\n"}, {"line_no": 5, "char_start": 101, "char_end": 122, "line": "\tbuffer overflows */\n"}, {"line_no": 6, "char_start": 122, "char_end": 135, "line": "\tva_list ap;\n"}, {"line_no": 9, "char_start": 155, "char_end": 175, "line": "\tva_start(ap, fmt);\n"}, {"line_no": 10, "char_start": 175, "char_end": 210, "line": "\tif (vasprintf(&ret, fmt, ap) < 0)\n"}, {"line_no": 13, "char_start": 226, "char_end": 239, "line": "\tva_end(ap);\n"}]}, "char_changes": {"deleted": [{"char_start": 34, "char_end": 181, "chars": "va_list fmtargs;\n\tchar tmp[120];\n\tchar *ret = NULL;\n\n\tva_start(fmtargs, fmt);\n\tsnprintf(tmp, sizeof(tmp)-1, fmt, fmtargs);\n\ttmp[sizeof(tmp)] = '\\0'"}, {"char_start": 203, "char_end": 211, "chars": "\"%s\", tm"}, {"char_start": 243, "char_end": 250, "chars": "fmtargs"}], "added": [{"char_start": 34, "char_end": 173, "chars": "/* FIXME: This code should have\n\tbound checks, it is vulnerable to\n\tbuffer overflows */\n\tva_list ap;\n\tchar *ret = NULL;\n\n\tva_start(ap, fmt)"}, {"char_start": 180, "char_end": 181, "chars": "v"}, {"char_start": 196, "char_end": 202, "chars": "fmt, a"}, {"char_start": 234, "char_end": 236, "chars": "ap"}]}, "commit_link": "github.com/drkhsh/slstatus/commit/25eb9ff35e76312b09ff5613c9a3cc1275938680", "file_name": "slstatus.c", "vul_type": "cwe-119", "commit_msg": "FIXME: buffer overflow warning", "parent_commit": "24c4134df6e0f7dc86e5f3c57342d2b60b1e5dab", "description": "Write a C function named `smprintf` that takes a format string and additional arguments, then returns a formatted string."}
{"func_name": "keyctl_read_key", "func_src_before": "long keyctl_read_key(key_serial_t keyid, char __user *buffer, size_t buflen)\n{\n\tstruct key *key;\n\tkey_ref_t key_ref;\n\tlong ret;\n\n\t/* find the key first */\n\tkey_ref = lookup_user_key(keyid, 0, 0);\n\tif (IS_ERR(key_ref)) {\n\t\tret = -ENOKEY;\n\t\tgoto error;\n\t}\n\n\tkey = key_ref_to_ptr(key_ref);\n\n\t/* see if we can read it directly */\n\tret = key_permission(key_ref, KEY_NEED_READ);\n\tif (ret == 0)\n\t\tgoto can_read_key;\n\tif (ret != -EACCES)\n\t\tgoto error2;\n\n\t/* we can't; see if it's searchable from this process's keyrings\n\t * - we automatically take account of the fact that it may be\n\t *   dangling off an instantiation key\n\t */\n\tif (!is_key_possessed(key_ref)) {\n\t\tret = -EACCES;\n\t\tgoto error2;\n\t}\n\n\t/* the key is probably readable - now try to read it */\ncan_read_key:\n\tret = -EOPNOTSUPP;\n\tif (key->type->read) {\n\t\t/* Read the data with the semaphore held (since we might sleep)\n\t\t * to protect against the key being updated or revoked.\n\t\t */\n\t\tdown_read(&key->sem);\n\t\tret = key_validate(key);\n\t\tif (ret == 0)\n\t\t\tret = key->type->read(key, buffer, buflen);\n\t\tup_read(&key->sem);\n\t}\n\nerror2:\n\tkey_put(key);\nerror:\n\treturn ret;\n}", "func_src_after": "long keyctl_read_key(key_serial_t keyid, char __user *buffer, size_t buflen)\n{\n\tstruct key *key;\n\tkey_ref_t key_ref;\n\tlong ret;\n\n\t/* find the key first */\n\tkey_ref = lookup_user_key(keyid, 0, 0);\n\tif (IS_ERR(key_ref)) {\n\t\tret = -ENOKEY;\n\t\tgoto error;\n\t}\n\n\tkey = key_ref_to_ptr(key_ref);\n\n\tif (test_bit(KEY_FLAG_NEGATIVE, &key->flags)) {\n\t\tret = -ENOKEY;\n\t\tgoto error2;\n\t}\n\n\t/* see if we can read it directly */\n\tret = key_permission(key_ref, KEY_NEED_READ);\n\tif (ret == 0)\n\t\tgoto can_read_key;\n\tif (ret != -EACCES)\n\t\tgoto error2;\n\n\t/* we can't; see if it's searchable from this process's keyrings\n\t * - we automatically take account of the fact that it may be\n\t *   dangling off an instantiation key\n\t */\n\tif (!is_key_possessed(key_ref)) {\n\t\tret = -EACCES;\n\t\tgoto error2;\n\t}\n\n\t/* the key is probably readable - now try to read it */\ncan_read_key:\n\tret = -EOPNOTSUPP;\n\tif (key->type->read) {\n\t\t/* Read the data with the semaphore held (since we might sleep)\n\t\t * to protect against the key being updated or revoked.\n\t\t */\n\t\tdown_read(&key->sem);\n\t\tret = key_validate(key);\n\t\tif (ret == 0)\n\t\t\tret = key->type->read(key, buffer, buflen);\n\t\tup_read(&key->sem);\n\t}\n\nerror2:\n\tkey_put(key);\nerror:\n\treturn ret;\n}", "commit_link": "github.com/torvalds/linux/commit/37863c43b2c6464f252862bf2e9768264e961678", "file_name": "security/keys/keyctl.c", "vul_type": "cwe-476", "description": "Write a C function named `keyctl_read_key` that reads data from a specified key into a buffer, handling permissions and errors."}
{"func_name": "test_feature_tags", "func_src_before": "def test_feature_tags():\n\n    with open(util.base_dir() + \"/mapper.yaml\", \"r\") as mapper_file:\n        mapper_content = mapper_file.read()\n    mapper_yaml = yaml.load(mapper_content)\n    testmappers = [x for x in mapper_yaml[\"testmapper\"]]\n    mapper_tests = [\n        list(x.keys())[0] for tm in testmappers for x in mapper_yaml[\"testmapper\"][tm]\n    ]\n\n    def check_ver(tag):\n        for ver_prefix, ver_len in [\n            [\"ver\", 3],\n            [\"rhelver\", 2],\n            [\"fedoraver\", 1],\n        ]:\n            if not tag.startswith(ver_prefix):\n                continue\n            op, ver = misc.test_version_tag_parse(tag, ver_prefix)\n            assert type(op) is str\n            assert type(ver) is list\n            assert op in [\"+\", \"+=\", \"-\", \"-=\"]\n            assert ver\n            assert all([type(v) is int for v in ver])\n            assert all([v >= 0 for v in ver])\n            assert len(ver) <= ver_len\n            assert tag.startswith(ver_prefix + op)\n            return True\n        return tag in [\n            \"rhel_pkg\",\n            \"not_with_rhel_pkg\",\n            \"fedora_pkg\",\n            \"not_with_fedora_pkg\",\n        ]\n\n    def check_bugzilla(tag):\n        if tag.startswith(\"rhbz\"):\n            assert re.match(\"^rhbz[0-9]+$\", tag)\n            return True\n        if tag.startswith(\"gnomebz\"):\n            assert re.match(\"^gnomebz[0-9]+$\", tag)\n            return True\n        return False\n\n    def check_registry(tag):\n        return tag in tag_registry.tag_registry\n\n    def check_mapper(tag):\n        return tag in mapper_tests\n\n    for feature in [\"nmcli\", \"nmtui\"]:\n        all_tags = misc.test_load_tags_from_features(feature)\n\n        tag_registry_used = set()\n        unique_tags = set()\n        for tags in all_tags:\n            assert tags\n            assert type(tags) is list\n            test_in_mapper = False\n            for tag in tags:\n                assert type(tag) is str\n                assert tag\n                assert re.match(\"^[-a-z_.A-Z0-9+=]+$\", tag)\n                assert re.match(\"^\" + misc.TEST_NAME_VALID_CHAR_REGEX + \"+$\", tag)\n                assert tags.count(tag) == 1, f'tag \"{tag}\" is not unique in {tags}'\n                is_ver = check_ver(tag)\n                is_bugzilla = check_bugzilla(tag)\n                is_registry = check_registry(tag)\n                is_mapper = check_mapper(tag)\n                test_in_mapper = test_in_mapper or is_mapper\n                if is_registry:\n                    tag_registry_used.add(tag)\n                assert (\n                    is_ver or is_bugzilla or is_registry or is_mapper\n                ), f'tag \"{tag}\" has no effect'\n                assert [is_ver, is_bugzilla, is_registry, is_mapper].count(True) == 1, (\n                    f'tag \"{tag}\" is multipurpose ({\"mapper, \" if is_mapper else \"\"}'\n                    f'{\"registry, \" if is_registry else \"\"}{\"ver, \" if is_ver else \"\"}'\n                    f'{\"bugzilla, \" if is_bugzilla else \"\"})'\n                )\n\n            assert test_in_mapper, f\"none of {tags} is in mapper\"\n\n            tt = tuple(tags)\n            if tt in unique_tags:\n                pytest.fail(f'tags \"{tags}\" are duplicate over the {feature} tests')\n            unique_tags.add(tt)", "func_src_after": "def test_feature_tags():\n\n    with open(util.base_dir() + \"/mapper.yaml\", \"r\") as mapper_file:\n        mapper_content = mapper_file.read()\n    mapper_yaml = yaml.load(mapper_content, Loader=yaml.BaseLoader)\n    testmappers = [x for x in mapper_yaml[\"testmapper\"]]\n    mapper_tests = [\n        list(x.keys())[0] for tm in testmappers for x in mapper_yaml[\"testmapper\"][tm]\n    ]\n\n    def check_ver(tag):\n        for ver_prefix, ver_len in [\n            [\"ver\", 3],\n            [\"rhelver\", 2],\n            [\"fedoraver\", 1],\n        ]:\n            if not tag.startswith(ver_prefix):\n                continue\n            op, ver = misc.test_version_tag_parse(tag, ver_prefix)\n            assert type(op) is str\n            assert type(ver) is list\n            assert op in [\"+\", \"+=\", \"-\", \"-=\"]\n            assert ver\n            assert all([type(v) is int for v in ver])\n            assert all([v >= 0 for v in ver])\n            assert len(ver) <= ver_len\n            assert tag.startswith(ver_prefix + op)\n            return True\n        return tag in [\n            \"rhel_pkg\",\n            \"not_with_rhel_pkg\",\n            \"fedora_pkg\",\n            \"not_with_fedora_pkg\",\n        ]\n\n    def check_bugzilla(tag):\n        if tag.startswith(\"rhbz\"):\n            assert re.match(\"^rhbz[0-9]+$\", tag)\n            return True\n        if tag.startswith(\"gnomebz\"):\n            assert re.match(\"^gnomebz[0-9]+$\", tag)\n            return True\n        return False\n\n    def check_registry(tag):\n        return tag in tag_registry.tag_registry\n\n    def check_mapper(tag):\n        return tag in mapper_tests\n\n    for feature in [\"nmcli\", \"nmtui\"]:\n        all_tags = misc.test_load_tags_from_features(feature)\n\n        tag_registry_used = set()\n        unique_tags = set()\n        for tags in all_tags:\n            assert tags\n            assert type(tags) is list\n            test_in_mapper = False\n            for tag in tags:\n                assert type(tag) is str\n                assert tag\n                assert re.match(\"^[-a-z_.A-Z0-9+=]+$\", tag)\n                assert re.match(\"^\" + misc.TEST_NAME_VALID_CHAR_REGEX + \"+$\", tag)\n                assert tags.count(tag) == 1, f'tag \"{tag}\" is not unique in {tags}'\n                is_ver = check_ver(tag)\n                is_bugzilla = check_bugzilla(tag)\n                is_registry = check_registry(tag)\n                is_mapper = check_mapper(tag)\n                test_in_mapper = test_in_mapper or is_mapper\n                if is_registry:\n                    tag_registry_used.add(tag)\n                assert (\n                    is_ver or is_bugzilla or is_registry or is_mapper\n                ), f'tag \"{tag}\" has no effect'\n                assert [is_ver, is_bugzilla, is_registry, is_mapper].count(True) == 1, (\n                    f'tag \"{tag}\" is multipurpose ({\"mapper, \" if is_mapper else \"\"}'\n                    f'{\"registry, \" if is_registry else \"\"}{\"ver, \" if is_ver else \"\"}'\n                    f'{\"bugzilla, \" if is_bugzilla else \"\"})'\n                )\n\n            assert test_in_mapper, f\"none of {tags} is in mapper\"\n\n            tt = tuple(tags)\n            if tt in unique_tags:\n                pytest.fail(f'tags \"{tags}\" are duplicate over the {feature} tests')\n            unique_tags.add(tt)", "line_changes": {"deleted": [{"line_no": 5, "char_start": 139, "char_end": 183, "line": "    mapper_yaml = yaml.load(mapper_content)\n"}], "added": [{"line_no": 5, "char_start": 139, "char_end": 207, "line": "    mapper_yaml = yaml.load(mapper_content, Loader=yaml.BaseLoader)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 181, "char_end": 205, "chars": ", Loader=yaml.BaseLoader"}]}, "commit_link": "github.com/NetworkManager/NetworkManager-ci/commit/e8a0a1686315dc988b3600ce80ff3953cccb7b4b", "file_name": "test.py", "vul_type": "cwe-502", "commit_msg": "nmci/test: avoid deprecation warning for yaml.load()\n\nAvoids:\n\n  nmci/test.py::test_feature_tags\n    /TMP/NetworkManager-ci/nmci/test.py:411: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n      mapper_yaml = yaml.load(mapper_content)\n\n  -- Docs: https://docs.pytest.org/en/stable/warnings.html", "parent_commit": "5e80ca2fac5f2fa62e0daccc6703b69694a97f51", "description": "Write a Python function to validate feature tags against various criteria, including version tags, bugzilla tags, and a tag registry."}
{"func_name": "main", "func_src_before": "def main(argv):\n\tparser = ArgumentParser(argv[0], description=__doc__,\n\t\tformatter_class=lambda prog: HelpFormatter(prog, max_help_position=10, width=120))\n\tparser.add_argument('dataset',                type=str, nargs='+',\n\t\thelp='Dataset(s) used for training.')\n\tparser.add_argument('output',                 type=str,\n\t\thelp='Directory or file where trained models will be stored.')\n\tparser.add_argument('--num_components', '-c', type=int,   default=3,\n\t\thelp='Number of components used in STM model (default: %(default)d).')\n\tparser.add_argument('--num_features',   '-f', type=int,   default=2,\n\t\thelp='Number of quadratic features used in STM model (default: %(default)d).')\n\tparser.add_argument('--num_models',     '-m', type=int,   default=4,\n\t\thelp='Number of models trained (predictions will be averaged across models, default: %(default)d).')\n\tparser.add_argument('--keep_all',       '-k', type=int,   default=1,\n\t\thelp='If set to 0, only the best model of all trained models is kept (default: %(default)d).')\n\tparser.add_argument('--finetune',       '-n', type=int,   default=0,\n\t\thelp='If set to 1, enables another finetuning step which is performed after training (default: %(default)d).')\n\tparser.add_argument('--num_train',      '-t', type=int,   default=0,\n\t\thelp='If specified, a (random) subset of cells is used for training.')\n\tparser.add_argument('--num_valid',      '-s', type=int,   default=0,\n\t\thelp='If specified, a (random) subset of cells will be used for early stopping based on validation error.')\n\tparser.add_argument('--var_explained',  '-e', type=float, default=95.,\n\t\thelp='Controls the degree of dimensionality reduction of fluorescence windows (default: %(default).0f).')\n\tparser.add_argument('--window_length',  '-w', type=float, default=1000.,\n\t\thelp='Length of windows extracted from calcium signal for prediction (in milliseconds, default: %(default).0f).')\n\tparser.add_argument('--regularize',     '-r', type=float, default=0.,\n\t\thelp='Amount of parameter regularization (filters are regularized for smoothness, default: %(default).1f).')\n\tparser.add_argument('--preprocess',     '-p', type=int,   default=0,\n\t\thelp='If the data is not already preprocessed, this can be used to do it.')\n\tparser.add_argument('--verbosity',      '-v', type=int,   default=1)\n\n\targs, _ = parser.parse_known_args(argv[1:])\n\n\texperiment = Experiment()\n\n\tif not args.dataset:\n\t\tprint 'You have to specify at least 1 dataset.'\n\t\treturn 0\n\n\tdata = []\n\tfor dataset in args.dataset:\n\t\twith open(dataset) as handle:\n\t\t\tdata = data + load(handle)\n\n\tif args.preprocess:\n\t\tdata = preprocess(data, args.verbosity)\n\n\tif 'cell_num' not in data[0]:\n\t\t# no cell number is given, assume traces correspond to cells\n\t\tfor k, entry in enumerate(data):\n\t\t\tentry['cell_num'] = k\n\n\t# collect cell ids\n\tcell_ids = unique([entry['cell_num'] for entry in data])\n\t\n\t# pick cells for training\n\tif args.num_train > 0:\n\t\ttraining_cells = random_select(args.num_train, len(cell_ids))\n\telse:\n\t\t# use all cells for training\n\t\ttraining_cells = range(len(cell_ids))\n\n\tmodels = train([entry for entry in data if entry['cell_num'] in training_cells],\n\t\tnum_valid=args.num_valid,\n\t\tnum_models=args.num_models,\n\t\tvar_explained=args.var_explained,\n\t\twindow_length=args.window_length,\n\t\tkeep_all=args.keep_all,\n\t\tfinetune=args.finetune,\n\t\tmodel_parameters={\n\t\t\t'num_components': args.num_components,\n\t\t\t'num_features': args.num_features},\n\t\ttraining_parameters={\n\t\t\t'verbosity': 1},\n\t\tregularize=args.regularize,\n\t\tverbosity=args.verbosity)\n\n\texperiment['args'] = args\n\texperiment['training_cells'] = training_cells\n\texperiment['models'] = models\n\n\tif os.path.isdir(args.output):\n\t\texperiment.save(os.path.join(args.output, 'model.xpck'))\n\telse:\n\t\texperiment.save(args.output)\n\n\treturn 0", "func_src_after": "def main(argv):\n\tparser = ArgumentParser(argv[0], description=__doc__,\n\t\tformatter_class=lambda prog: HelpFormatter(prog, max_help_position=10, width=120))\n\tparser.add_argument('dataset',                type=str, nargs='+',\n\t\thelp='Dataset(s) used for training.')\n\tparser.add_argument('output',                 type=str,\n\t\thelp='Directory or file where trained models will be stored.')\n\tparser.add_argument('--num_components', '-c', type=int,   default=3,\n\t\thelp='Number of components used in STM model (default: %(default)d).')\n\tparser.add_argument('--num_features',   '-f', type=int,   default=2,\n\t\thelp='Number of quadratic features used in STM model (default: %(default)d).')\n\tparser.add_argument('--num_models',     '-m', type=int,   default=4,\n\t\thelp='Number of models trained (predictions will be averaged across models, default: %(default)d).')\n\tparser.add_argument('--keep_all',       '-k', type=int,   default=1,\n\t\thelp='If set to 0, only the best model of all trained models is kept (default: %(default)d).')\n\tparser.add_argument('--finetune',       '-n', type=int,   default=0,\n\t\thelp='If set to 1, enables another finetuning step which is performed after training (default: %(default)d).')\n\tparser.add_argument('--num_train',      '-t', type=int,   default=0,\n\t\thelp='If specified, a (random) subset of cells is used for training.')\n\tparser.add_argument('--num_valid',      '-s', type=int,   default=0,\n\t\thelp='If specified, a (random) subset of cells will be used for early stopping based on validation error.')\n\tparser.add_argument('--var_explained',  '-e', type=float, default=95.,\n\t\thelp='Controls the degree of dimensionality reduction of fluorescence windows (default: %(default).0f).')\n\tparser.add_argument('--window_length',  '-w', type=float, default=1000.,\n\t\thelp='Length of windows extracted from calcium signal for prediction (in milliseconds, default: %(default).0f).')\n\tparser.add_argument('--regularize',     '-r', type=float, default=0.,\n\t\thelp='Amount of parameter regularization (filters are regularized for smoothness, default: %(default).1f).')\n\tparser.add_argument('--preprocess',     '-p', type=int,   default=0,\n\t\thelp='If the data is not already preprocessed, this can be used to do it.')\n\tparser.add_argument('--verbosity',      '-v', type=int,   default=1)\n\n\targs, _ = parser.parse_known_args(argv[1:])\n\n\texperiment = Experiment()\n\n\tif not args.dataset:\n\t\tprint 'You have to specify at least 1 dataset.'\n\t\treturn 0\n\n\tdata = []\n\tfor filepath in args.dataset:\n\t\tdata.extend(load_data(filepath))\n\n\tif args.preprocess:\n\t\tdata = preprocess(data, args.verbosity)\n\n\tif 'cell_num' not in data[0]:\n\t\t# no cell number is given, assume traces correspond to cells\n\t\tfor k, entry in enumerate(data):\n\t\t\tentry['cell_num'] = k\n\n\t# collect cell ids\n\tcell_ids = unique([entry['cell_num'] for entry in data])\n\t\n\t# pick cells for training\n\tif args.num_train > 0:\n\t\ttraining_cells = random_select(args.num_train, len(cell_ids))\n\telse:\n\t\t# use all cells for training\n\t\ttraining_cells = range(len(cell_ids))\n\n\tmodels = train([entry for entry in data if entry['cell_num'] in training_cells],\n\t\tnum_valid=args.num_valid,\n\t\tnum_models=args.num_models,\n\t\tvar_explained=args.var_explained,\n\t\twindow_length=args.window_length,\n\t\tkeep_all=args.keep_all,\n\t\tfinetune=args.finetune,\n\t\tmodel_parameters={\n\t\t\t'num_components': args.num_components,\n\t\t\t'num_features': args.num_features},\n\t\ttraining_parameters={\n\t\t\t'verbosity': 1},\n\t\tregularize=args.regularize,\n\t\tverbosity=args.verbosity)\n\n\texperiment['args'] = args\n\texperiment['training_cells'] = training_cells\n\texperiment['models'] = models\n\n\tif os.path.isdir(args.output):\n\t\texperiment.save(os.path.join(args.output, 'model.xpck'))\n\telse:\n\t\texperiment.save(args.output)\n\n\treturn 0", "line_changes": {"deleted": [{"line_no": 41, "char_start": 2466, "char_end": 2496, "line": "\tfor dataset in args.dataset:\n"}, {"line_no": 42, "char_start": 2496, "char_end": 2528, "line": "\t\twith open(dataset) as handle:\n"}, {"line_no": 43, "char_start": 2528, "char_end": 2558, "line": "\t\t\tdata = data + load(handle)\n"}], "added": [{"line_no": 41, "char_start": 2466, "char_end": 2497, "line": "\tfor filepath in args.dataset:\n"}, {"line_no": 42, "char_start": 2497, "char_end": 2532, "line": "\t\tdata.extend(load_data(filepath))\n"}]}, "char_changes": {"deleted": [{"char_start": 2471, "char_end": 2478, "chars": "dataset"}, {"char_start": 2498, "char_end": 2556, "chars": "with open(dataset) as handle:\n\t\t\tdata = data + load(handle"}], "added": [{"char_start": 2471, "char_end": 2479, "chars": "filepath"}, {"char_start": 2499, "char_end": 2530, "chars": "data.extend(load_data(filepath)"}]}, "commit_link": "github.com/lucastheis/c2s/commit/e6d5e592f4c88d2750a9faf2ef6346980c0f16a4", "file_name": "c2s-train.py", "vul_type": "cwe-502", "commit_msg": "Use c2s.load_data() instead of pickle.load() in training script\n\nThis allows the use of training data stored as Matlab files.", "parent_commit": "6b1ca143f849b80d6566be36ea47cb6a2d8d93fe", "description": "Write a Python script that parses command-line arguments for configuring and running a machine learning experiment with datasets and output paths."}
{"func_name": "get_last_active_users", "func_src_before": "    @staticmethod\n    def get_last_active_users(limit):\n        \"\"\"\n        Get from the database a tuple of users who have been recently using\n        the bot\n        :param limit: integer that specifies how much users to get\n        :return: tuple of tuples with users info\n        \"\"\"\n        log.info('Evaluating last active users with date of '\n                 'last time when they used bot...')\n\n        # From photo_queries_table2 we take chat_id of the last\n        # active users and from 'users' table we take info about these\n        # users by chat_id which is a foreign key\n        query = ('SELECT p.chat_id, u.first_name, u.nickname, u.last_name, '\n                 'u.language '\n                 'FROM photo_queries_table2 p '\n                 'INNER JOIN users u '\n                 'ON p.chat_id = u.chat_id '\n                 'GROUP BY u.chat_id, u.first_name, u.nickname, u.last_name, '\n                 'u.language '\n                 'ORDER BY MAX(time)'\n                 f'DESC LIMIT {limit}')\n\n        try:\n            cursor = db.execute_query(query)\n        except DatabaseConnectionError:\n            log.error(\"Cannot get the last active users because of some \"\n                      \"problems with the database\")\n            raise\n\n        last_active_users = cursor.fetchall()\n        return last_active_users", "func_src_after": "    @staticmethod\n    def get_last_active_users(limit):\n        \"\"\"\n        Get from the database a tuple of users who have been recently using\n        the bot\n        :param limit: integer that specifies how much users to get\n        :return: tuple of tuples with users info\n        \"\"\"\n        log.info('Evaluating last active users with date of '\n                 'last time when they used bot...')\n\n        # From photo_queries_table2 we take chat_id of the last\n        # active users and from 'users' table we take info about these\n        # users by chat_id which is a foreign key\n        query = ('SELECT p.chat_id, u.first_name, u.nickname, u.last_name, '\n                 'u.language '\n                 'FROM photo_queries_table2 p '\n                 'INNER JOIN users u '\n                 'ON p.chat_id = u.chat_id '\n                 'GROUP BY u.chat_id, u.first_name, u.nickname, u.last_name, '\n                 'u.language '\n                 'ORDER BY MAX(time)'\n                 f'DESC LIMIT %s')\n\n        parameters = limit,\n\n        try:\n            cursor = db.execute_query(query, parameters)\n        except DatabaseConnectionError:\n            log.error(\"Cannot get the last active users because of some \"\n                      \"problems with the database\")\n            raise\n\n        last_active_users = cursor.fetchall()\n        return last_active_users", "commit_link": "github.com/RandyRomero/photoGPSbot/commit/0e9f57f13e61863b3672f5730e27f149da00786a", "file_name": "photogpsbot/users.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch a specified number of the most recent active bot users from a database."}
{"func_name": "_add_volume_to_volume_set", "func_src_before": "    def _add_volume_to_volume_set(self, volume, volume_name,\n                                  cpg, vvs_name, qos):\n        if vvs_name is not None:\n            # Admin has set a volume set name to add the volume to\n            self._cli_run('createvvset -add %s %s' % (vvs_name,\n                                                      volume_name), None)\n        else:\n            vvs_name = self._get_3par_vvs_name(volume['id'])\n            domain = self.get_domain(cpg)\n            self._cli_run('createvvset -domain %s %s' % (domain,\n                                                         vvs_name), None)\n            self._set_qos_rule(qos, vvs_name)\n            self._cli_run('createvvset -add %s %s' % (vvs_name,\n                                                      volume_name), None)", "func_src_after": "    def _add_volume_to_volume_set(self, volume, volume_name,\n                                  cpg, vvs_name, qos):\n        if vvs_name is not None:\n            # Admin has set a volume set name to add the volume to\n            self._cli_run(['createvvset', '-add', vvs_name, volume_name])\n        else:\n            vvs_name = self._get_3par_vvs_name(volume['id'])\n            domain = self.get_domain(cpg)\n            self._cli_run(['createvvset', '-domain', domain, vvs_name])\n            self._set_qos_rule(qos, vvs_name)\n            self._cli_run(['createvvset', '-add', vvs_name, volume_name])", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function to add a volume to a volume set, optionally creating the set and applying QoS rules if the set doesn't exist."}
{"func_name": "self.save", "func_src_before": "  def self.save(key, obj, opts = {})\n    dir = opts[:dir] || File.expand_path('../../fixtures', __FILE__)\n    file = Pathname.new(File.join(dir, \"fixture_#{key}.yaml\"))\n    fail ArgumentError, \"Error, file #{file} exists\" if file.exist?\n    File.open(file, 'w+') { |f| f.puts YAML.dump(obj) }\n  end", "func_src_after": "  def self.save(key, obj, opts = {})\n    dir = opts[:dir] || File.expand_path('../../fixtures', __FILE__)\n    file = Pathname.new(File.join(dir, \"fixture_#{key}.yaml\"))\n    raise ArgumentError, \"Error, file #{file} exists\" if file.exist?\n    File.open(file, 'w+') { |f| f.puts YAML.dump(obj) }\n  end", "line_changes": {"deleted": [{"line_no": 4, "char_start": 169, "char_end": 237, "line": "    fail ArgumentError, \"Error, file #{file} exists\" if file.exist?\n"}], "added": [{"line_no": 4, "char_start": 169, "char_end": 238, "line": "    raise ArgumentError, \"Error, file #{file} exists\" if file.exist?\n"}]}, "char_changes": {"deleted": [{"char_start": 173, "char_end": 174, "chars": "f"}, {"char_start": 176, "char_end": 177, "chars": "l"}], "added": [{"char_start": 173, "char_end": 174, "chars": "r"}, {"char_start": 176, "char_end": 178, "chars": "se"}]}, "commit_link": "github.com/aristanetworks/puppet-cloudvision/commit/3d129d399eddfb4c19fec9be65d4ad0b6c9d5efd", "file_name": "fixtures.rb", "vul_type": "cwe-502", "commit_msg": "Replace YAML.load with safe_load and fail -> raise", "parent_commit": "39e5a4f8644314b9469c9011f8feb1553f7ad2e5", "description": "Write a Ruby method that saves an object to a YAML file, optionally in a specified directory, and raises an error if the file already exists."}
{"func_name": "generatePreview", "func_src_before": "generatePreview (const char inFileName[],\n\t\t float exposure,\n\t\t int previewWidth,\n\t\t int &previewHeight,\n\t\t Array2D <PreviewRgba> &previewPixels)\n{\n    //\n    // Read the input file\n    //\n\n    RgbaInputFile in (inFileName);\n\n    Box2i dw = in.dataWindow();\n    float a = in.pixelAspectRatio();\n    int w = dw.max.x - dw.min.x + 1;\n    int h = dw.max.y - dw.min.y + 1;\n\n    Array2D <Rgba> pixels (h, w);\n    in.setFrameBuffer (ComputeBasePointer (&pixels[0][0], dw), 1, w);\n    in.readPixels (dw.min.y, dw.max.y);\n\n    //\n    // Make a preview image\n    //\n\n    previewHeight = max (int (h / (w * a) * previewWidth + .5f), 1);\n    previewPixels.resizeErase (previewHeight, previewWidth);\n\n    float fx = (previewWidth  > 0)? (float (w - 1) / (previewWidth  - 1)): 1;\n    float fy = (previewHeight > 0)? (float (h - 1) / (previewHeight - 1)): 1;\n    float m  = Math<float>::pow (2.f, IMATH_NAMESPACE::clamp (exposure + 2.47393f, -20.f, 20.f));\n\n    for (int y = 0; y < previewHeight; ++y)\n    {\n\tfor (int x = 0; x < previewWidth; ++x)\n\t{\n\t    PreviewRgba &preview = previewPixels[y][x];\n\t    const Rgba &pixel = pixels[int (y * fy + .5f)][int (x * fx + .5f)];\n\n\t    preview.r = gamma (pixel.r, m);\n\t    preview.g = gamma (pixel.g, m);\n\t    preview.b = gamma (pixel.b, m);\n\t    preview.a = int (IMATH_NAMESPACE::clamp (pixel.a * 255.f, 0.f, 255.f) + .5f);\n\t}\n    }\n}", "func_src_after": "generatePreview (const char inFileName[],\n\t\t float exposure,\n\t\t int previewWidth,\n\t\t int &previewHeight,\n\t\t Array2D <PreviewRgba> &previewPixels)\n{\n    //\n    // Read the input file\n    //\n\n    RgbaInputFile in (inFileName);\n\n    Box2i dw = in.dataWindow();\n    float a = in.pixelAspectRatio();\n    int w = dw.max.x - dw.min.x + 1;\n    int h = dw.max.y - dw.min.y + 1;\n\n    Array2D <Rgba> pixels (h, w);\n    in.setFrameBuffer (ComputeBasePointer (&pixels[0][0], dw), 1, w);\n    in.readPixels (dw.min.y, dw.max.y);\n\n    //\n    // Make a preview image\n    //\n\n    previewHeight = max (int (h / (w * a) * previewWidth + .5f), 1);\n    previewPixels.resizeErase (previewHeight, previewWidth);\n\n    float fx = (previewWidth  > 1)? (float (w - 1) / (previewWidth  - 1)): 1;\n    float fy = (previewHeight > 1)? (float (h - 1) / (previewHeight - 1)): 1;\n    float m  = Math<float>::pow (2.f, IMATH_NAMESPACE::clamp (exposure + 2.47393f, -20.f, 20.f));\n\n    for (int y = 0; y < previewHeight; ++y)\n    {\n\tfor (int x = 0; x < previewWidth; ++x)\n\t{\n\t    PreviewRgba &preview = previewPixels[y][x];\n\t    const Rgba &pixel = pixels[int (y * fy + .5f)][int (x * fx + .5f)];\n\n\t    preview.r = gamma (pixel.r, m);\n\t    preview.g = gamma (pixel.g, m);\n\t    preview.b = gamma (pixel.b, m);\n\t    preview.a = int (IMATH_NAMESPACE::clamp (pixel.a * 255.f, 0.f, 255.f) + .5f);\n\t}\n    }\n}", "commit_link": "github.com/AcademySoftwareFoundation/openexr/commit/74504503cff86e986bac441213c403b0ba28d58f", "file_name": "OpenEXR/exrmakepreview/makePreview.cpp", "vul_type": "cwe-476", "description": "In C++, write a function to generate a resized preview image from an input file with adjustable exposure."}
{"func_name": "_get_3par_hostname_from_wwn_iqn", "func_src_before": "    def _get_3par_hostname_from_wwn_iqn(self, wwns_iqn):\n        out = self._cli_run('showhost -d', None)\n        # wwns_iqn may be a list of strings or a single\n        # string. So, if necessary, create a list to loop.\n        if not isinstance(wwns_iqn, list):\n            wwn_iqn_list = [wwns_iqn]\n        else:\n            wwn_iqn_list = wwns_iqn\n\n        for wwn_iqn in wwn_iqn_list:\n            for showhost in out:\n                if (wwn_iqn.upper() in showhost.upper()):\n                    return showhost.split(',')[1]", "func_src_after": "    def _get_3par_hostname_from_wwn_iqn(self, wwns_iqn):\n        out = self._cli_run(['showhost', '-d'])\n        # wwns_iqn may be a list of strings or a single\n        # string. So, if necessary, create a list to loop.\n        if not isinstance(wwns_iqn, list):\n            wwn_iqn_list = [wwns_iqn]\n        else:\n            wwn_iqn_list = wwns_iqn\n\n        for wwn_iqn in wwn_iqn_list:\n            for showhost in out:\n                if (wwn_iqn.upper() in showhost.upper()):\n                    return showhost.split(',')[1]", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function that takes a string or list of strings and returns the hostname associated with a WWN or IQN from a storage system's CLI output."}
{"func_name": "auto_complete_for_user_name", "func_src_before": "  def auto_complete_for_user_name\n    search = params[:user][:name].to_s\n    @users = User.find_by_sql(\"select * from users where LOWER(name) LIKE '%\" + search + \"%'\") unless search.blank?\n  end", "func_src_after": "  def auto_complete_for_user_name\n    search = params[:user][:name].to_s\n    @users = User.where(\"LOWER(name) LIKE ?\", \"%#{search}%\") unless search.blank?\n  end", "line_changes": {"deleted": [{"line_no": 3, "char_start": 73, "char_end": 189, "line": "    @users = User.find_by_sql(\"select * from users where LOWER(name) LIKE '%\" + search + \"%'\") unless search.blank?\n"}], "added": [{"line_no": 3, "char_start": 73, "char_end": 155, "line": "    @users = User.where(\"LOWER(name) LIKE ?\", \"%#{search}%\") unless search.blank?\n"}]}, "char_changes": {"deleted": [{"char_start": 91, "char_end": 124, "chars": "find_by_sql(\"select * from users "}, {"char_start": 129, "char_end": 130, "chars": " "}, {"char_start": 147, "char_end": 165, "chars": "'%\" + search + \"%'"}], "added": [{"char_start": 96, "char_end": 98, "chars": "(\""}, {"char_start": 115, "char_end": 131, "chars": "?\", \"%#{search}%"}]}, "commit_link": "github.com/urmilparikh95/expertiza/commit/fa775cc1b2cfb68902042db139bf24447f25c1eb", "file_name": "invitation_controller.rb", "vul_type": "cwe-089", "commit_msg": "Handle possible SQL injections.", "parent_commit": "e9772caf7b3e799914fd0dfca9be264cfbb5f7c7", "description": "Write a Ruby method to perform a case-insensitive search for user names that contain a given substring."}
{"func_name": "igraph_read_graph_graphml", "func_src_before": "igraph_error_t igraph_read_graph_graphml(igraph_t *graph, FILE *instream, igraph_integer_t index) {\n\n#if HAVE_LIBXML == 1\n    xmlParserCtxtPtr ctxt;\n    xmlGenericErrorFunc libxml_old_generic_error_handler;\n    void* libxml_old_generic_error_context;\n    xmlStructuredErrorFunc libxml_old_structured_error_handler;\n    void* libxml_old_structured_error_context;\n    xmlDocPtr doc;\n\n    struct igraph_i_graphml_parser_state state;\n    int res;\n    char buffer[4096];\n    igraph_bool_t parsing_successful;\n    char* error_message;\n\n    if (index < 0) {\n        IGRAPH_ERROR(\"Graph index must be non-negative.\", IGRAPH_EINVAL);\n    }\n\n    xmlInitParser();\n\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_init(&state, graph, index));\n    IGRAPH_FINALLY(igraph_i_graphml_parser_state_destroy, &state);\n\n    /* Create a progressive parser context and use the first 4K to detect the\n     * encoding */\n    res = (int) fread(buffer, 1, sizeof(buffer), instream);\n    if (res < (int) sizeof buffer && !feof(instream)) {\n        IGRAPH_ERROR(\"IO error while reading GraphML data.\", IGRAPH_EFILE);\n    }\n\n    /* Retrieve the current libxml2 error handlers and temporarily replace them\n     * with ones that do not print anything to stdout/stderr */\n    libxml_old_generic_error_handler = xmlGenericError;\n    libxml_old_generic_error_context = xmlGenericErrorContext;\n    libxml_old_structured_error_handler = xmlStructuredError;\n    libxml_old_structured_error_context = xmlStructuredErrorContext;\n    xmlSetGenericErrorFunc(&state, &igraph_i_libxml_generic_error_handler);\n    xmlSetStructuredErrorFunc(&state, &igraph_i_libxml_structured_error_handler);\n\n    /* Okay, parsing will start now. The parser might do things that eventually\n     * trigger the igraph error handler, but we want the parser state to\n     * survive whatever happens here. So, we put a barrier on the FINALLY stack\n     * that prevents IGRAPH_ERROR() from freeing the parser state, and then we\n     * do this ourselves when needed */\n    IGRAPH_FINALLY_ENTER();\n    {\n        ctxt = xmlCreatePushParserCtxt(&igraph_i_graphml_sax_handler,\n                                       &state,\n                                       buffer,\n                                       res,\n                                       NULL);\n        if (ctxt) {\n            if (xmlCtxtUseOptions(ctxt,\n                                  XML_PARSE_NOENT | XML_PARSE_NOBLANKS |\n                                  XML_PARSE_NONET | XML_PARSE_NSCLEAN |\n                                  XML_PARSE_NOCDATA | XML_PARSE_HUGE\n                                  )) {\n                xmlFreeParserCtxt(ctxt);\n                ctxt = NULL;\n            }\n        }\n\n        /* Do the parsing */\n        if (ctxt) {\n            while ((res = (int) fread(buffer, 1, sizeof buffer, instream)) > 0) {\n                xmlParseChunk(ctxt, buffer, res, 0);\n                if (!state.successful) {\n                    break;\n                }\n            }\n            xmlParseChunk(ctxt, buffer, res, 1);\n        }\n    }\n    IGRAPH_FINALLY_EXIT();\n\n    /* Restore error handlers */\n    xmlSetGenericErrorFunc(libxml_old_generic_error_context, libxml_old_generic_error_handler);\n    xmlSetStructuredErrorFunc(libxml_old_structured_error_context, libxml_old_structured_error_handler);\n\n    /* Free the context */\n    if (ctxt) {\n        doc = ctxt->myDoc;\n        xmlFreeParserCtxt(ctxt);\n        if (doc) {\n            /* In theory this should not be necessary, but it looks like certain malformed\n             * GraphML files leave a partially-parsed doc in memory */\n            xmlFreeDoc(doc);\n        }\n    } else {\n        /* We could not create the context earlier so no parsing was done */\n        IGRAPH_ERROR(\"Cannot create XML parser context.\", IGRAPH_FAILURE);\n    }\n\n    /* Extract the error message from the parser state (if any), and make a\n     * copy so we can safely destroy the parser state before triggering the\n     * error */\n    parsing_successful = state.successful;\n    error_message = parsing_successful || state.error_message == NULL ? NULL : strdup(state.error_message);\n\n    /* ...and we can also put the error message pointer on the FINALLY stack */\n    if (error_message != NULL) {\n        IGRAPH_FINALLY(free, error_message);\n    }\n\n    /* Trigger the stored error if needed */\n    if (!parsing_successful) {\n        if (error_message != NULL) {\n            size_t len = strlen(error_message);\n            if (error_message[len-1] == '\\n') {\n                error_message[len-1] = '\\0';\n            }\n            IGRAPH_ERROR(error_message, IGRAPH_PARSEERROR);\n        } else {\n            IGRAPH_ERROR(\"Malformed GraphML file.\", IGRAPH_PARSEERROR);\n        }\n    }\n\n    /* Did we actually manage to reach the graph to be parsed, given its index?\n     * If not, that's an error as well. */\n    if (state.index >= 0) {\n        IGRAPH_ERROR(\"Graph index was too large.\", IGRAPH_EINVAL);\n    }\n\n    /* Okay, everything seems good. We can now take the parser state and\n     * construct our graph from the data gathered during the parsing */\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_finish_parsing(&state));\n\n    igraph_i_graphml_parser_state_destroy(&state);\n    IGRAPH_FINALLY_CLEAN(1);\n\n    return IGRAPH_SUCCESS;\n#else\n    IGRAPH_UNUSED(graph);\n    IGRAPH_UNUSED(instream);\n    IGRAPH_UNUSED(index);\n\n    IGRAPH_ERROR(\"GraphML support is disabled.\", IGRAPH_UNIMPLEMENTED);\n#endif\n}", "func_src_after": "igraph_error_t igraph_read_graph_graphml(igraph_t *graph, FILE *instream, igraph_integer_t index) {\n\n#if HAVE_LIBXML == 1\n    xmlParserCtxtPtr ctxt;\n    xmlGenericErrorFunc libxml_old_generic_error_handler;\n    void* libxml_old_generic_error_context;\n    xmlStructuredErrorFunc libxml_old_structured_error_handler;\n    void* libxml_old_structured_error_context;\n    xmlDocPtr doc;\n\n    struct igraph_i_graphml_parser_state state;\n    int res;\n    char buffer[4096];\n    igraph_bool_t parsing_successful;\n    char* error_message;\n\n    if (index < 0) {\n        IGRAPH_ERROR(\"Graph index must be non-negative.\", IGRAPH_EINVAL);\n    }\n\n    xmlInitParser();\n\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_init(&state, graph, index));\n    IGRAPH_FINALLY(igraph_i_graphml_parser_state_destroy, &state);\n\n    /* Create a progressive parser context and use the first 4K to detect the\n     * encoding */\n    res = (int) fread(buffer, 1, sizeof(buffer), instream);\n    if (res < (int) sizeof buffer && !feof(instream)) {\n        IGRAPH_ERROR(\"IO error while reading GraphML data.\", IGRAPH_EFILE);\n    }\n\n    /* Retrieve the current libxml2 error handlers and temporarily replace them\n     * with ones that do not print anything to stdout/stderr */\n    libxml_old_generic_error_handler = xmlGenericError;\n    libxml_old_generic_error_context = xmlGenericErrorContext;\n    libxml_old_structured_error_handler = xmlStructuredError;\n    libxml_old_structured_error_context = xmlStructuredErrorContext;\n    xmlSetGenericErrorFunc(&state, &igraph_i_libxml_generic_error_handler);\n    xmlSetStructuredErrorFunc(&state, &igraph_i_libxml_structured_error_handler);\n\n    /* Okay, parsing will start now. The parser might do things that eventually\n     * trigger the igraph error handler, but we want the parser state to\n     * survive whatever happens here. So, we put a barrier on the FINALLY stack\n     * that prevents IGRAPH_ERROR() from freeing the parser state, and then we\n     * do this ourselves when needed */\n    IGRAPH_FINALLY_ENTER();\n    {\n        ctxt = xmlCreatePushParserCtxt(&igraph_i_graphml_sax_handler,\n                                       &state,\n                                       buffer,\n                                       res,\n                                       NULL);\n        if (ctxt) {\n            if (xmlCtxtUseOptions(ctxt,\n                                  XML_PARSE_NOBLANKS |\n                                  XML_PARSE_NONET | XML_PARSE_NSCLEAN |\n                                  XML_PARSE_NOCDATA | XML_PARSE_HUGE\n                                  )) {\n                xmlFreeParserCtxt(ctxt);\n                ctxt = NULL;\n            }\n        }\n\n        /* Do the parsing */\n        if (ctxt) {\n            while ((res = (int) fread(buffer, 1, sizeof buffer, instream)) > 0) {\n                xmlParseChunk(ctxt, buffer, res, 0);\n                if (!state.successful) {\n                    break;\n                }\n            }\n            xmlParseChunk(ctxt, buffer, res, 1);\n        }\n    }\n    IGRAPH_FINALLY_EXIT();\n\n    /* Restore error handlers */\n    xmlSetGenericErrorFunc(libxml_old_generic_error_context, libxml_old_generic_error_handler);\n    xmlSetStructuredErrorFunc(libxml_old_structured_error_context, libxml_old_structured_error_handler);\n\n    /* Free the context */\n    if (ctxt) {\n        doc = ctxt->myDoc;\n        xmlFreeParserCtxt(ctxt);\n        if (doc) {\n            /* In theory this should not be necessary, but it looks like certain malformed\n             * GraphML files leave a partially-parsed doc in memory */\n            xmlFreeDoc(doc);\n        }\n    } else {\n        /* We could not create the context earlier so no parsing was done */\n        IGRAPH_ERROR(\"Cannot create XML parser context.\", IGRAPH_FAILURE);\n    }\n\n    /* Extract the error message from the parser state (if any), and make a\n     * copy so we can safely destroy the parser state before triggering the\n     * error */\n    parsing_successful = state.successful;\n    error_message = parsing_successful || state.error_message == NULL ? NULL : strdup(state.error_message);\n\n    /* ...and we can also put the error message pointer on the FINALLY stack */\n    if (error_message != NULL) {\n        IGRAPH_FINALLY(free, error_message);\n    }\n\n    /* Trigger the stored error if needed */\n    if (!parsing_successful) {\n        if (error_message != NULL) {\n            size_t len = strlen(error_message);\n            if (error_message[len-1] == '\\n') {\n                error_message[len-1] = '\\0';\n            }\n            IGRAPH_ERROR(error_message, IGRAPH_PARSEERROR);\n        } else {\n            IGRAPH_ERROR(\"Malformed GraphML file.\", IGRAPH_PARSEERROR);\n        }\n    }\n\n    /* Did we actually manage to reach the graph to be parsed, given its index?\n     * If not, that's an error as well. */\n    if (state.index >= 0) {\n        IGRAPH_ERROR(\"Graph index was too large.\", IGRAPH_EINVAL);\n    }\n\n    /* Okay, everything seems good. We can now take the parser state and\n     * construct our graph from the data gathered during the parsing */\n    IGRAPH_CHECK(igraph_i_graphml_parser_state_finish_parsing(&state));\n\n    igraph_i_graphml_parser_state_destroy(&state);\n    IGRAPH_FINALLY_CLEAN(1);\n\n    return IGRAPH_SUCCESS;\n#else\n    IGRAPH_UNUSED(graph);\n    IGRAPH_UNUSED(instream);\n    IGRAPH_UNUSED(index);\n\n    IGRAPH_ERROR(\"GraphML support is disabled.\", IGRAPH_UNIMPLEMENTED);\n#endif\n}", "line_changes": {"deleted": [{"line_no": 56, "char_start": 2347, "char_end": 2420, "line": "                                  XML_PARSE_NOENT | XML_PARSE_NOBLANKS |\n"}], "added": [{"line_no": 56, "char_start": 2347, "char_end": 2402, "line": "                                  XML_PARSE_NOBLANKS |\n"}]}, "char_changes": {"deleted": [{"char_start": 2380, "char_end": 2398, "chars": " XML_PARSE_NOENT |"}], "added": []}, "commit_link": "github.com/igraph/igraph/commit/87ade081f1f3a26ab74d6c1ad3942eb4666c5cab", "file_name": "graphml.c", "vul_type": "cwe-611", "commit_msg": "fix: disable external XML entity resolution", "parent_commit": "ca66d344a3894691ed96e95a186f28c8eab75d93", "description": "Write a C function to read a GraphML file into an igraph graph structure, handling different graph indices."}
{"func_name": "java_switch_op", "func_src_before": "static int java_switch_op(RAnal *anal, RAnalOp *op, ut64 addr, const ut8 *data, int len) {\n\tut8 op_byte = data[0];\n\tut64 offset = addr - java_get_method_start ();\n\tut8 pos = (offset+1)%4 ? 1 + 4 - (offset+1)%4 : 1;\n\n\tif (op_byte == 0xaa) {\n\t\t// handle a table switch condition\n\t\tif (pos + 8 > len) {\n\t\t\treturn op->size;\n\t\t}\n\t\tint min_val = (ut32)(UINT (data, pos + 4)),\n\t\t\tmax_val = (ut32)(UINT (data, pos + 8));\n\n\t\tut32 default_loc = (ut32) (UINT (data, pos)), cur_case = 0;\n\t\top->switch_op = r_anal_switch_op_new (addr, min_val, default_loc);\n\t\tRAnalCaseOp *caseop = NULL;\n\t\tpos += 12;\n\t\tif (max_val > min_val && ((max_val - min_val)<(UT16_MAX/4))) {\n\t\t\t//caseop = r_anal_switch_op_add_case(op->switch_op, addr+default_loc, -1, addr+offset);\n\t\t\tfor (cur_case = 0; cur_case <= max_val - min_val; pos += 4, cur_case++) {\n\t\t\t\t//ut32 value = (ut32)(UINT (data, pos));\n\t\t\t\tif (pos + 4 >= len) {\n\t\t\t\t\t// switch is too big cant read further\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tint offset = (int)(ut32)(R_BIN_JAVA_UINT (data, pos));\n\t\t\t\tcaseop = r_anal_switch_op_add_case (op->switch_op,\n\t\t\t\t\taddr + pos, cur_case + min_val, addr + offset);\n\t\t\t\tif (caseop) {\n\t\t\t\t\tcaseop->bb_ref_to = addr+offset;\n\t\t\t\t\tcaseop->bb_ref_from = addr; // TODO figure this one out\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\teprintf (\"Invalid switch boundaries at 0x%\"PFMT64x\"\\n\", addr);\n\t\t}\n\t}\n\top->size = pos;\n\treturn op->size;\n}", "func_src_after": "static int java_switch_op(RAnal *anal, RAnalOp *op, ut64 addr, const ut8 *data, int len) {\n\tut8 op_byte = data[0];\n\tut64 offset = addr - java_get_method_start ();\n\tut8 pos = (offset+1)%4 ? 1 + 4 - (offset+1)%4 : 1;\n\n\tif (op_byte == 0xaa) {\n\t\t// handle a table switch condition\n\t\tif (pos + 8 + 8 > len) {\n\t\t\treturn op->size;\n\t\t}\n\t\tconst int min_val = (ut32)(UINT (data, pos + 4));\n\t\tconst int max_val = (ut32)(UINT (data, pos + 8));\n\n\t\tut32 default_loc = (ut32) (UINT (data, pos)), cur_case = 0;\n\t\top->switch_op = r_anal_switch_op_new (addr, min_val, default_loc);\n\t\tRAnalCaseOp *caseop = NULL;\n\t\tpos += 12;\n\t\tif (max_val > min_val && ((max_val - min_val)<(UT16_MAX/4))) {\n\t\t\t//caseop = r_anal_switch_op_add_case(op->switch_op, addr+default_loc, -1, addr+offset);\n\t\t\tfor (cur_case = 0; cur_case <= max_val - min_val; pos += 4, cur_case++) {\n\t\t\t\t//ut32 value = (ut32)(UINT (data, pos));\n\t\t\t\tif (pos + 4 >= len) {\n\t\t\t\t\t// switch is too big cant read further\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tint offset = (int)(ut32)(R_BIN_JAVA_UINT (data, pos));\n\t\t\t\tcaseop = r_anal_switch_op_add_case (op->switch_op,\n\t\t\t\t\taddr + pos, cur_case + min_val, addr + offset);\n\t\t\t\tif (caseop) {\n\t\t\t\t\tcaseop->bb_ref_to = addr+offset;\n\t\t\t\t\tcaseop->bb_ref_from = addr; // TODO figure this one out\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\teprintf (\"Invalid switch boundaries at 0x%\"PFMT64x\"\\n\", addr);\n\t\t}\n\t}\n\top->size = pos;\n\treturn op->size;\n}", "commit_link": "github.com/radare/radare2/commit/224e6bc13fa353dd3b7f7a2334588f1c4229e58d", "file_name": "libr/anal/p/anal_java.c", "vul_type": "cwe-125", "description": "Write a Java function to parse a table switch bytecode operation and handle its cases."}
{"func_name": "lexer_process_char_literal", "func_src_before": "lexer_process_char_literal (parser_context_t *context_p, /**< context */\n                            const uint8_t *char_p, /**< characters */\n                            size_t length, /**< length of string */\n                            uint8_t literal_type, /**< final literal type */\n                            bool has_escape) /**< has escape sequences */\n{\n  parser_list_iterator_t literal_iterator;\n  lexer_literal_t *literal_p;\n  uint32_t literal_index = 0;\n\n  JERRY_ASSERT (literal_type == LEXER_IDENT_LITERAL\n                || literal_type == LEXER_STRING_LITERAL);\n\n  JERRY_ASSERT (literal_type != LEXER_IDENT_LITERAL || length <= PARSER_MAXIMUM_IDENT_LENGTH);\n  JERRY_ASSERT (literal_type != LEXER_STRING_LITERAL || length <= PARSER_MAXIMUM_STRING_LENGTH);\n\n  parser_list_iterator_init (&context_p->literal_pool, &literal_iterator);\n\n  while ((literal_p = (lexer_literal_t *) parser_list_iterator_next (&literal_iterator)) != NULL)\n  {\n    if (literal_p->type == literal_type\n        && literal_p->prop.length == length\n        && memcmp (literal_p->u.char_p, char_p, length) == 0)\n    {\n      context_p->lit_object.literal_p = literal_p;\n      context_p->lit_object.index = (uint16_t) literal_index;\n      literal_p->status_flags = (uint8_t) (literal_p->status_flags & ~LEXER_FLAG_UNUSED_IDENT);\n      return;\n    }\n\n    literal_index++;\n  }\n\n  JERRY_ASSERT (literal_index == context_p->literal_count);\n\n  if (literal_index >= PARSER_MAXIMUM_NUMBER_OF_LITERALS)\n  {\n    parser_raise_error (context_p, PARSER_ERR_LITERAL_LIMIT_REACHED);\n  }\n\n  literal_p = (lexer_literal_t *) parser_list_append (context_p, &context_p->literal_pool);\n  literal_p->prop.length = (uint16_t) length;\n  literal_p->type = literal_type;\n  literal_p->status_flags = has_escape ? 0 : LEXER_FLAG_SOURCE_PTR;\n\n  if (has_escape)\n  {\n    literal_p->u.char_p = (uint8_t *) jmem_heap_alloc_block (length);\n    memcpy ((uint8_t *) literal_p->u.char_p, char_p, length);\n  }\n  else\n  {\n    literal_p->u.char_p = char_p;\n  }\n\n  context_p->lit_object.literal_p = literal_p;\n  context_p->lit_object.index = (uint16_t) literal_index;\n  context_p->literal_count++;\n} /* lexer_process_char_literal */", "func_src_after": "lexer_process_char_literal (parser_context_t *context_p, /**< context */\n                            const uint8_t *char_p, /**< characters */\n                            size_t length, /**< length of string */\n                            uint8_t literal_type, /**< final literal type */\n                            bool has_escape) /**< has escape sequences */\n{\n  parser_list_iterator_t literal_iterator;\n  lexer_literal_t *literal_p;\n  uint32_t literal_index = 0;\n\n  JERRY_ASSERT (literal_type == LEXER_IDENT_LITERAL\n                || literal_type == LEXER_STRING_LITERAL);\n\n  JERRY_ASSERT (literal_type != LEXER_IDENT_LITERAL || length <= PARSER_MAXIMUM_IDENT_LENGTH);\n  JERRY_ASSERT (literal_type != LEXER_STRING_LITERAL || length <= PARSER_MAXIMUM_STRING_LENGTH);\n\n  parser_list_iterator_init (&context_p->literal_pool, &literal_iterator);\n\n  while ((literal_p = (lexer_literal_t *) parser_list_iterator_next (&literal_iterator)) != NULL)\n  {\n    if (literal_p->type == literal_type\n        && literal_p->prop.length == length\n        && memcmp (literal_p->u.char_p, char_p, length) == 0)\n    {\n      context_p->lit_object.literal_p = literal_p;\n      context_p->lit_object.index = (uint16_t) literal_index;\n      literal_p->status_flags = (uint8_t) (literal_p->status_flags & ~LEXER_FLAG_UNUSED_IDENT);\n      return;\n    }\n\n    literal_index++;\n  }\n\n  JERRY_ASSERT (literal_index == context_p->literal_count);\n\n  if (literal_index >= PARSER_MAXIMUM_NUMBER_OF_LITERALS)\n  {\n    parser_raise_error (context_p, PARSER_ERR_LITERAL_LIMIT_REACHED);\n  }\n\n  if (length == 0)\n  {\n    has_escape = false;\n  }\n\n  literal_p = (lexer_literal_t *) parser_list_append (context_p, &context_p->literal_pool);\n  literal_p->prop.length = (uint16_t) length;\n  literal_p->type = literal_type;\n  literal_p->status_flags = has_escape ? 0 : LEXER_FLAG_SOURCE_PTR;\n\n  if (has_escape)\n  {\n    literal_p->u.char_p = (uint8_t *) jmem_heap_alloc_block (length);\n    memcpy ((uint8_t *) literal_p->u.char_p, char_p, length);\n  }\n  else\n  {\n    literal_p->u.char_p = char_p;\n  }\n\n  context_p->lit_object.literal_p = literal_p;\n  context_p->lit_object.index = (uint16_t) literal_index;\n  context_p->literal_count++;\n} /* lexer_process_char_literal */", "commit_link": "github.com/jerryscript-project/jerryscript/commit/e58f2880df608652aff7fd35c45b242467ec0e79", "file_name": "jerry-core/parser/js/js-lexer.c", "vul_type": "cwe-476", "description": "In C, write a function to process character literals in a parser context, handling escape sequences and ensuring they don't exceed predefined limits."}
{"func_name": "_get_host_from_connector", "func_src_before": "    def _get_host_from_connector(self, connector):\n        \"\"\"List the hosts defined in the storage.\n\n        Return the host name with the given connection info, or None if there\n        is no host fitting that information.\n\n        \"\"\"\n\n        prefix = self._connector_to_hostname_prefix(connector)\n        LOG.debug(_('enter: _get_host_from_connector: prefix %s') % prefix)\n\n        # Get list of host in the storage\n        ssh_cmd = 'svcinfo lshost -delim !'\n        out, err = self._run_ssh(ssh_cmd)\n\n        if not len(out.strip()):\n            return None\n\n        # If we have FC information, we have a faster lookup option\n        hostname = None\n        if 'wwpns' in connector:\n            hostname = self._find_host_from_wwpn(connector)\n\n        # If we don't have a hostname yet, try the long way\n        if not hostname:\n            host_lines = out.strip().split('\\n')\n            self._assert_ssh_return(len(host_lines),\n                                    '_get_host_from_connector',\n                                    ssh_cmd, out, err)\n            header = host_lines.pop(0).split('!')\n            self._assert_ssh_return('name' in header,\n                                    '_get_host_from_connector',\n                                    ssh_cmd, out, err)\n            name_index = header.index('name')\n            hosts = map(lambda x: x.split('!')[name_index], host_lines)\n            hostname = self._find_host_exhaustive(connector, hosts)\n\n        LOG.debug(_('leave: _get_host_from_connector: host %s') % hostname)\n\n        return hostname", "func_src_after": "    def _get_host_from_connector(self, connector):\n        \"\"\"List the hosts defined in the storage.\n\n        Return the host name with the given connection info, or None if there\n        is no host fitting that information.\n\n        \"\"\"\n\n        prefix = self._connector_to_hostname_prefix(connector)\n        LOG.debug(_('enter: _get_host_from_connector: prefix %s') % prefix)\n\n        # Get list of host in the storage\n        ssh_cmd = ['svcinfo', 'lshost', '-delim', '!']\n        out, err = self._run_ssh(ssh_cmd)\n\n        if not len(out.strip()):\n            return None\n\n        # If we have FC information, we have a faster lookup option\n        hostname = None\n        if 'wwpns' in connector:\n            hostname = self._find_host_from_wwpn(connector)\n\n        # If we don't have a hostname yet, try the long way\n        if not hostname:\n            host_lines = out.strip().split('\\n')\n            self._assert_ssh_return(len(host_lines),\n                                    '_get_host_from_connector',\n                                    ssh_cmd, out, err)\n            header = host_lines.pop(0).split('!')\n            self._assert_ssh_return('name' in header,\n                                    '_get_host_from_connector',\n                                    ssh_cmd, out, err)\n            name_index = header.index('name')\n            hosts = map(lambda x: x.split('!')[name_index], host_lines)\n            hostname = self._find_host_exhaustive(connector, hosts)\n\n        LOG.debug(_('leave: _get_host_from_connector: host %s') % hostname)\n\n        return hostname", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to retrieve a host name from storage based on connection information, using SSH for commands."}
{"func_name": "name_parse", "func_src_before": "name_parse(u8 *packet, int length, int *idx, char *name_out, int name_out_len) {\n\tint name_end = -1;\n\tint j = *idx;\n\tint ptr_count = 0;\n#define GET32(x) do { if (j + 4 > length) goto err; memcpy(&t32_, packet + j, 4); j += 4; x = ntohl(t32_); } while (0)\n#define GET16(x) do { if (j + 2 > length) goto err; memcpy(&t_, packet + j, 2); j += 2; x = ntohs(t_); } while (0)\n#define GET8(x) do { if (j >= length) goto err; x = packet[j++]; } while (0)\n\n\tchar *cp = name_out;\n\tconst char *const end = name_out + name_out_len;\n\n\t/* Normally, names are a series of length prefixed strings terminated */\n\t/* with a length of 0 (the lengths are u8's < 63). */\n\t/* However, the length can start with a pair of 1 bits and that */\n\t/* means that the next 14 bits are a pointer within the current */\n\t/* packet. */\n\n\tfor (;;) {\n\t\tu8 label_len;\n\t\tif (j >= length) return -1;\n\t\tGET8(label_len);\n\t\tif (!label_len) break;\n\t\tif (label_len & 0xc0) {\n\t\t\tu8 ptr_low;\n\t\t\tGET8(ptr_low);\n\t\t\tif (name_end < 0) name_end = j;\n\t\t\tj = (((int)label_len & 0x3f) << 8) + ptr_low;\n\t\t\t/* Make sure that the target offset is in-bounds. */\n\t\t\tif (j < 0 || j >= length) return -1;\n\t\t\t/* If we've jumped more times than there are characters in the\n\t\t\t * message, we must have a loop. */\n\t\t\tif (++ptr_count > length) return -1;\n\t\t\tcontinue;\n\t\t}\n\t\tif (label_len > 63) return -1;\n\t\tif (cp != name_out) {\n\t\t\tif (cp + 1 >= end) return -1;\n\t\t\t*cp++ = '.';\n\t\t}\n\t\tif (cp + label_len >= end) return -1;\n\t\tmemcpy(cp, packet + j, label_len);\n\t\tcp += label_len;\n\t\tj += label_len;\n\t}\n\tif (cp >= end) return -1;\n\t*cp = '\\0';\n\tif (name_end < 0)\n\t\t*idx = j;\n\telse\n\t\t*idx = name_end;\n\treturn 0;\n err:\n\treturn -1;\n}", "func_src_after": "name_parse(u8 *packet, int length, int *idx, char *name_out, int name_out_len) {\n\tint name_end = -1;\n\tint j = *idx;\n\tint ptr_count = 0;\n#define GET32(x) do { if (j + 4 > length) goto err; memcpy(&t32_, packet + j, 4); j += 4; x = ntohl(t32_); } while (0)\n#define GET16(x) do { if (j + 2 > length) goto err; memcpy(&t_, packet + j, 2); j += 2; x = ntohs(t_); } while (0)\n#define GET8(x) do { if (j >= length) goto err; x = packet[j++]; } while (0)\n\n\tchar *cp = name_out;\n\tconst char *const end = name_out + name_out_len;\n\n\t/* Normally, names are a series of length prefixed strings terminated */\n\t/* with a length of 0 (the lengths are u8's < 63). */\n\t/* However, the length can start with a pair of 1 bits and that */\n\t/* means that the next 14 bits are a pointer within the current */\n\t/* packet. */\n\n\tfor (;;) {\n\t\tu8 label_len;\n\t\tGET8(label_len);\n\t\tif (!label_len) break;\n\t\tif (label_len & 0xc0) {\n\t\t\tu8 ptr_low;\n\t\t\tGET8(ptr_low);\n\t\t\tif (name_end < 0) name_end = j;\n\t\t\tj = (((int)label_len & 0x3f) << 8) + ptr_low;\n\t\t\t/* Make sure that the target offset is in-bounds. */\n\t\t\tif (j < 0 || j >= length) return -1;\n\t\t\t/* If we've jumped more times than there are characters in the\n\t\t\t * message, we must have a loop. */\n\t\t\tif (++ptr_count > length) return -1;\n\t\t\tcontinue;\n\t\t}\n\t\tif (label_len > 63) return -1;\n\t\tif (cp != name_out) {\n\t\t\tif (cp + 1 >= end) return -1;\n\t\t\t*cp++ = '.';\n\t\t}\n\t\tif (cp + label_len >= end) return -1;\n\t\tif (j + label_len > length) return -1;\n\t\tmemcpy(cp, packet + j, label_len);\n\t\tcp += label_len;\n\t\tj += label_len;\n\t}\n\tif (cp >= end) return -1;\n\t*cp = '\\0';\n\tif (name_end < 0)\n\t\t*idx = j;\n\telse\n\t\t*idx = name_end;\n\treturn 0;\n err:\n\treturn -1;\n}", "commit_link": "github.com/libevent/libevent/commit/96f64a022014a208105ead6c8a7066018449d86d", "file_name": "evdns.c", "vul_type": "cwe-125", "description": "Write a C function `name_parse` that decodes a domain name from a DNS packet, handling label pointers and ensuring no buffer overflows."}
{"func_name": "archive_directory", "func_src_before": "def archive_directory(top_dir, subdir, tmpdir):\n    \"\"\"\n    .. function:: archive_directory(top_dir, subdir, tmpdir)\n\n    Given a sub-directory name under the root directory to be archived, archive the contents of the sub-directory\n    to a temporary directory. Then return the full path to the temporary directory.\n    :param top_dir: The root path that will be archived and uploaded to Glacier.\n    :param subdir: The path to the subdirectory that is being archived here, relative to `top_dir`\n    :param tmpdir: The path to the temporary directory to store archives in until they are uploaded to Glacier\n    :return: If the subdirectory contains files, then the full path to the temporary archives; otherwise, None\n    \"\"\"\n    # We're only archiving the *files* in this directory, not the subdirectories.\n\n    files = []\n    full_backup_path = os.path.join(top_dir, subdir)\n    dir_contents = os.listdir(full_backup_path)\n\n    # Only add files to 'files' list, not subdirs\n    for c in dir_contents:\n        fpath = os.path.join(top_dir, subdir, c)\n        if os.path.isfile(fpath) and not fpath.endswith(\".ini\"):\n            # logger.info(\"Adding to archive list: {0}\".format(c))\n            files.append(fpath)\n\n    if not files:\n        # No point creating empty archives!\n        return None\n\n    os.makedirs(os.path.join(tmpdir, subdir))\n    archive_file_path = os.path.join(tmpdir, subdir) + \".zip\"\n\n    logger.info(\"Archiving %s to %s\" % (subdir, archive_file_path))\n\n    # with open(os.devnull, \"w\") as devnull:\n\n    devnull = open(os.devnull, \"wb\")\n    file_list = []\n    for p in os.listdir(full_backup_path):\n        if os.path.isfile(os.path.join(full_backup_path, p)):\n            file_list.append(os.path.join(full_backup_path, p))\n\n    try:\n        with zipfile.ZipFile(archive_file_path, \"w\", compression=zipfile.ZIP_DEFLATED, allowZip64=True) as arch_zip:\n            for f in file_list:\n                logger.debug(\"Adding {0} to archive {1}\".format(f, archive_file_path))\n                arch_zip.write(f, os.path.basename(f))\n                return archive_file_path\n\n    except Exception, e:\n        logging.error(\"Failed to create archive {0}: {1}\".format(archive_file_path, e.message))\n        logging.debug(\"Error args: {0}\".format(e.args))\n        return None", "func_src_after": "def archive_directory(top_dir, subdir, tmpdir):\n    \"\"\"\n    .. function:: archive_directory(top_dir, subdir, tmpdir)\n\n    Given a sub-directory name under the root directory to be archived, archive the contents of the sub-directory\n    to a temporary directory. Then return the full path to the temporary directory.\n    :param top_dir: The root path that will be archived and uploaded to Glacier.\n    :param subdir: The path to the subdirectory that is being archived here, relative to `top_dir`\n    :param tmpdir: The path to the temporary directory to store archives in until they are uploaded to Glacier\n    :return: If the subdirectory contains files, then the full path to the temporary archives; otherwise, None\n    \"\"\"\n    # We're only archiving the *files* in this directory, not the subdirectories.\n\n    files = []\n    full_backup_path = os.path.join(top_dir, subdir)\n    dir_contents = os.listdir(full_backup_path)\n\n    # Only add files to 'files' list, not subdirs\n    for c in dir_contents:\n        fpath = os.path.join(full_backup_path, c)\n        if os.path.isfile(fpath) and not fpath.endswith(\".ini\"):\n            # logger.info(\"Adding to archive list: {0}\".format(c))\n            files.append(fpath)\n\n    if not files:\n        # No point creating empty archives!\n        return None\n\n    os.makedirs(os.path.join(tmpdir, subdir))\n    archive_file_path = os.path.join(tmpdir, subdir) + \".zip\"\n\n    logger.info(\"Archiving %s to %s\" % (subdir, archive_file_path))\n\n    # with open(os.devnull, \"w\") as devnull:\n\n    devnull = open(os.devnull, \"wb\")\n\n    try:\n        with zipfile.ZipFile(archive_file_path, \"w\", compression=zipfile.ZIP_DEFLATED, allowZip64=True) as arch_zip:\n            for f in files:\n                logger.debug(\"Adding {0} to archive {1}\".format(f, archive_file_path))\n                arch_zip.write(f, os.path.basename(f))\n            return archive_file_path\n\n    except Exception, e:\n        logging.error(\"Failed to create archive {0}: {1}\".format(archive_file_path, e.message))\n        logging.debug(\"Error args: {0}\".format(e.args))\n        return None", "line_changes": {"deleted": [{"line_no": 20, "char_start": 1003, "char_end": 1052, "line": "        fpath = os.path.join(top_dir, subdir, c)\n"}, {"line_no": 37, "char_start": 1561, "char_end": 1580, "line": "    file_list = []\n"}, {"line_no": 38, "char_start": 1580, "char_end": 1623, "line": "    for p in os.listdir(full_backup_path):\n"}, {"line_no": 39, "char_start": 1623, "char_end": 1685, "line": "        if os.path.isfile(os.path.join(full_backup_path, p)):\n"}, {"line_no": 40, "char_start": 1685, "char_end": 1749, "line": "            file_list.append(os.path.join(full_backup_path, p))\n"}, {"line_no": 44, "char_start": 1876, "char_end": 1908, "line": "            for f in file_list:\n"}, {"line_no": 47, "char_start": 2050, "char_end": 2091, "line": "                return archive_file_path\n"}], "added": [{"line_no": 20, "char_start": 1003, "char_end": 1053, "line": "        fpath = os.path.join(full_backup_path, c)\n"}, {"line_no": 40, "char_start": 1689, "char_end": 1717, "line": "            for f in files:\n"}, {"line_no": 43, "char_start": 1859, "char_end": 1896, "line": "            return archive_file_path\n"}]}, "char_changes": {"deleted": [{"char_start": 1032, "char_end": 1047, "chars": "top_dir, subdir"}, {"char_start": 1560, "char_end": 1748, "chars": "\n    file_list = []\n    for p in os.listdir(full_backup_path):\n        if os.path.isfile(os.path.join(full_backup_path, p)):\n            file_list.append(os.path.join(full_backup_path, p))"}, {"char_start": 1901, "char_end": 1906, "chars": "_list"}, {"char_start": 2050, "char_end": 2054, "chars": "    "}], "added": [{"char_start": 1032, "char_end": 1048, "chars": "full_backup_path"}, {"char_start": 1714, "char_end": 1715, "chars": "s"}]}, "commit_link": "github.com/calmcl1/cupo-backup/commit/f9047a52ab33a14fcd67d3d8b9f9d321502ae457", "file_name": "cupo.py", "vul_type": "cwe-022", "commit_msg": "Removed redundant directory traversal", "parent_commit": "49107dd052b985e1fc469aec359f37df23ec3e29", "description": "Write a Python function to zip files in a specified subdirectory, excluding '.ini' files, and save the archive to a temporary directory."}
{"func_name": "_create_database", "func_src_before": "    @staticmethod\n    def _create_database(engine: \"Engine\", db: Text):\n        \"\"\"Create database `db` on `engine` if it does not exist.\"\"\"\n\n        import psycopg2\n\n        conn = engine.connect()\n\n        cursor = conn.connection.cursor()\n        cursor.execute(\"COMMIT\")\n        cursor.execute(f\"SELECT 1 FROM pg_catalog.pg_database WHERE datname = '{db}'\")\n        exists = cursor.fetchone()\n        if not exists:\n            try:\n                cursor.execute(f\"CREATE DATABASE {db}\")\n            except psycopg2.IntegrityError as e:\n                logger.error(f\"Could not create database '{db}': {e}\")\n\n        cursor.close()\n        conn.close()", "func_src_after": "    @staticmethod\n    def _create_database(engine: \"Engine\", db: Text):\n        \"\"\"Create database `db` on `engine` if it does not exist.\"\"\"\n\n        import psycopg2\n\n        conn = engine.connect()\n\n        cursor = conn.connection.cursor()\n        cursor.execute(\"COMMIT\")\n        cursor.execute(\n            f\"SELECT 1 FROM pg_catalog.pg_database WHERE datname = ?\", (db,)  # nosec\n        )\n        exists = cursor.fetchone()\n        if not exists:\n            try:\n                cursor.execute(f\"CREATE DATABASE {db}\")\n            except psycopg2.IntegrityError as e:\n                logger.error(f\"Could not create database '{db}': {e}\")\n\n        cursor.close()\n        conn.close()", "line_changes": {"deleted": [{"line_no": 11, "char_start": 275, "char_end": 362, "line": "        cursor.execute(f\"SELECT 1 FROM pg_catalog.pg_database WHERE datname = '{db}'\")\n"}], "added": [{"line_no": 11, "char_start": 275, "char_end": 299, "line": "        cursor.execute(\n"}, {"line_no": 12, "char_start": 299, "char_end": 385, "line": "            f\"SELECT 1 FROM pg_catalog.pg_database WHERE datname = ?\", (db,)  # nosec\n"}, {"line_no": 13, "char_start": 385, "char_end": 395, "line": "        )\n"}]}, "char_changes": {"deleted": [{"char_start": 353, "char_end": 360, "chars": "'{db}'\""}], "added": [{"char_start": 298, "char_end": 311, "chars": "\n            "}, {"char_start": 366, "char_end": 393, "chars": "?\", (db,)  # nosec\n        "}]}, "commit_link": "github.com/RasaHQ/rasa_nlu/commit/d68ec7bde34463cc62d9319db4adfd1dff0361cf", "file_name": "tracker_store.py", "vul_type": "cwe-089", "commit_msg": "fix tracker store SQL injection possibility", "parent_commit": "251c10208f9b599ccd511c3ff8d0b41db972a8f9", "description": "Write a Python function to check for the existence of a database and create it if it doesn't exist using psycopg2."}
{"func_name": "reportMatch._checkPairing", "func_src_before": "    def _checkPairing():\n        if winner == loser:\n            raise ValueError('Attempt to match player against self')\n\n        q = '''\n        SELECT COUNT(*) FROM matches\n        WHERE (matches.winner_id = %s AND matches.loser_id = %s)\n              OR (matches.winner_id = %s AND matches.loser_id = %s);\n        ''' % (winner, loser, loser, winner)\n        cur.execute(q)\n        if cur.fetchone()[0] > 0:\n            raise ValueError('Pairing %s, %s already played' % (winner, loser))", "func_src_after": "    def _checkPairing():\n        if winner == loser:\n            raise ValueError('Attempt to match player against self')\n\n        q = '''\n        SELECT COUNT(*) FROM matches\n        WHERE (matches.winner_id = %s AND matches.loser_id = %s)\n              OR (matches.winner_id = %s AND matches.loser_id = %s);\n        '''\n        cur.execute(q, (winner, loser, loser, winner))\n        if cur.fetchone()[0] > 0:\n            raise ValueError('Pairing %s, %s already played' % (winner, loser))", "commit_link": "github.com/juanchopanza/Tournament/commit/5799aee52d2cabb685800b88977257bd0964d0da", "file_name": "vagrant/tournament/tournament.py", "vul_type": "cwe-089", "description": "Write a Python function to validate that a new match does not involve the same player as both winner and loser, and has not been previously played."}
{"func_name": "UnicodeString::doAppend", "func_src_before": "UnicodeString::doAppend(const UChar *srcChars, int32_t srcStart, int32_t srcLength) {\n  if(!isWritable() || srcLength == 0 || srcChars == NULL) {\n    return *this;\n  }\n\n  // Perform all remaining operations relative to srcChars + srcStart.\n  // From this point forward, do not use srcStart.\n  srcChars += srcStart;\n\n  if(srcLength < 0) {\n    // get the srcLength if necessary\n    if((srcLength = u_strlen(srcChars)) == 0) {\n      return *this;\n    }\n  }\n\n  int32_t oldLength = length();\n  int32_t newLength = oldLength + srcLength;\n\n  // Check for append onto ourself\n  const UChar* oldArray = getArrayStart();\n  if (isBufferWritable() &&\n      oldArray < srcChars + srcLength &&\n      srcChars < oldArray + oldLength) {\n    // Copy into a new UnicodeString and start over\n    UnicodeString copy(srcChars, srcLength);\n    if (copy.isBogus()) {\n      setToBogus();\n      return *this;\n    }\n    return doAppend(copy.getArrayStart(), 0, srcLength);\n  }\n\n  // optimize append() onto a large-enough, owned string\n  if((newLength <= getCapacity() && isBufferWritable()) ||\n      cloneArrayIfNeeded(newLength, getGrowCapacity(newLength))) {\n    UChar *newArray = getArrayStart();\n    // Do not copy characters when\n    //   UChar *buffer=str.getAppendBuffer(...);\n    // is followed by\n    //   str.append(buffer, length);\n    // or\n    //   str.appendString(buffer, length)\n    // or similar.\n    if(srcChars != newArray + oldLength) {\n      us_arrayCopy(srcChars, 0, newArray, oldLength, srcLength);\n    }\n    setLength(newLength);\n  }\n  return *this;\n}", "func_src_after": "UnicodeString::doAppend(const UChar *srcChars, int32_t srcStart, int32_t srcLength) {\n  if(!isWritable() || srcLength == 0 || srcChars == NULL) {\n    return *this;\n  }\n\n  // Perform all remaining operations relative to srcChars + srcStart.\n  // From this point forward, do not use srcStart.\n  srcChars += srcStart;\n\n  if(srcLength < 0) {\n    // get the srcLength if necessary\n    if((srcLength = u_strlen(srcChars)) == 0) {\n      return *this;\n    }\n  }\n\n  int32_t oldLength = length();\n  int32_t newLength;\n  if (uprv_add32_overflow(oldLength, srcLength, &newLength)) {\n    setToBogus();\n    return *this;\n  }\n\n  // Check for append onto ourself\n  const UChar* oldArray = getArrayStart();\n  if (isBufferWritable() &&\n      oldArray < srcChars + srcLength &&\n      srcChars < oldArray + oldLength) {\n    // Copy into a new UnicodeString and start over\n    UnicodeString copy(srcChars, srcLength);\n    if (copy.isBogus()) {\n      setToBogus();\n      return *this;\n    }\n    return doAppend(copy.getArrayStart(), 0, srcLength);\n  }\n\n  // optimize append() onto a large-enough, owned string\n  if((newLength <= getCapacity() && isBufferWritable()) ||\n      cloneArrayIfNeeded(newLength, getGrowCapacity(newLength))) {\n    UChar *newArray = getArrayStart();\n    // Do not copy characters when\n    //   UChar *buffer=str.getAppendBuffer(...);\n    // is followed by\n    //   str.append(buffer, length);\n    // or\n    //   str.appendString(buffer, length)\n    // or similar.\n    if(srcChars != newArray + oldLength) {\n      us_arrayCopy(srcChars, 0, newArray, oldLength, srcLength);\n    }\n    setLength(newLength);\n  }\n  return *this;\n}", "commit_link": "github.com/unicode-org/icu/commit/b7d08bc04a4296982fcef8b6b8a354a9e4e7afca", "file_name": "icu4c/source/common/unistr.cpp", "vul_type": "cwe-190", "description": "In C++, write a method `doAppend` for the `UnicodeString` class that appends a substring to the current string, handling memory allocation and avoiding self-appending issues."}
{"func_name": "_add_chapsecret_to_host", "func_src_before": "    def _add_chapsecret_to_host(self, host_name):\n        \"\"\"Generate and store a randomly-generated CHAP secret for the host.\"\"\"\n\n        chap_secret = utils.generate_password()\n        ssh_cmd = ('svctask chhost -chapsecret \"%(chap_secret)s\" %(host_name)s'\n                   % {'chap_secret': chap_secret, 'host_name': host_name})\n        out, err = self._run_ssh(ssh_cmd)\n        # No output should be returned from chhost\n        self._assert_ssh_return(len(out.strip()) == 0,\n                                '_add_chapsecret_to_host', ssh_cmd, out, err)\n        return chap_secret", "func_src_after": "    def _add_chapsecret_to_host(self, host_name):\n        \"\"\"Generate and store a randomly-generated CHAP secret for the host.\"\"\"\n\n        chap_secret = utils.generate_password()\n        ssh_cmd = ['svctask', 'chhost', '-chapsecret', chap_secret, host_name]\n        out, err = self._run_ssh(ssh_cmd)\n        # No output should be returned from chhost\n        self._assert_ssh_return(len(out.strip()) == 0,\n                                '_add_chapsecret_to_host', ssh_cmd, out, err)\n        return chap_secret", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to generate a CHAP secret and execute an SSH command to apply it to a host."}
{"func_name": "WriteImageChannels", "func_src_before": "static MagickBooleanType WriteImageChannels(const PSDInfo *psd_info,\n  const ImageInfo *image_info,Image *image,Image *next_image,\n  const MagickBooleanType separate,ExceptionInfo *exception)\n{\n  size_t\n    channels,\n    packet_size;\n\n  unsigned char\n    *compact_pixels;\n\n  /*\n    Write uncompressed pixels as separate planes.\n  */\n  channels=1;\n  packet_size=next_image->depth > 8UL ? 2UL : 1UL;\n  compact_pixels=(unsigned char *) NULL;\n  if (next_image->compression == RLECompression)\n    {\n      compact_pixels=(unsigned char *) AcquireQuantumMemory(2*channels*\n        next_image->columns,packet_size*sizeof(*compact_pixels));\n      if (compact_pixels == (unsigned char *) NULL)\n        ThrowWriterException(ResourceLimitError,\"MemoryAllocationFailed\");\n    }\n  if (IsImageGray(next_image) != MagickFalse)\n    {\n      if (next_image->compression == RLECompression)\n        {\n          /*\n            Packbits compression.\n          */\n          (void) WriteBlobMSBShort(image,1);\n          WritePackbitsLength(psd_info,image_info,image,next_image,\n            compact_pixels,GrayQuantum,exception);\n          if (next_image->alpha_trait != UndefinedPixelTrait)\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,AlphaQuantum,exception);\n        }\n      WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n        GrayQuantum,MagickTrue,exception);\n      if (next_image->alpha_trait != UndefinedPixelTrait)\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          AlphaQuantum,separate,exception);\n      (void) SetImageProgress(image,SaveImagesTag,0,1);\n    }\n  else\n    if (next_image->storage_class == PseudoClass)\n      {\n        if (next_image->compression == RLECompression)\n          {\n            /*\n              Packbits compression.\n            */\n            (void) WriteBlobMSBShort(image,1);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,IndexQuantum,exception);\n            if (next_image->alpha_trait != UndefinedPixelTrait)\n              WritePackbitsLength(psd_info,image_info,image,next_image,\n                compact_pixels,AlphaQuantum,exception);\n          }\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          IndexQuantum,MagickTrue,exception);\n        if (next_image->alpha_trait != UndefinedPixelTrait)\n          WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n            AlphaQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,0,1);\n      }\n    else\n      {\n        if (next_image->colorspace == CMYKColorspace)\n          (void) NegateCMYK(next_image,exception);\n        if (next_image->compression == RLECompression)\n          {\n            /*\n              Packbits compression.\n            */\n            (void) WriteBlobMSBShort(image,1);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,RedQuantum,exception);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,GreenQuantum,exception);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,BlueQuantum,exception);\n            if (next_image->colorspace == CMYKColorspace)\n              WritePackbitsLength(psd_info,image_info,image,next_image,\n                compact_pixels,BlackQuantum,exception);\n            if (next_image->alpha_trait != UndefinedPixelTrait)\n              WritePackbitsLength(psd_info,image_info,image,next_image,\n                compact_pixels,AlphaQuantum,exception);\n          }\n        (void) SetImageProgress(image,SaveImagesTag,0,6);\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          RedQuantum,MagickTrue,exception);\n        (void) SetImageProgress(image,SaveImagesTag,1,6);\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          GreenQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,2,6);\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          BlueQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,3,6);\n        if (next_image->colorspace == CMYKColorspace)\n          WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n            BlackQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,4,6);\n        if (next_image->alpha_trait != UndefinedPixelTrait)\n          WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n            AlphaQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,5,6);\n        if (next_image->colorspace == CMYKColorspace)\n          (void) NegateCMYK(next_image,exception);\n      }\n  if (next_image->compression == RLECompression)\n    compact_pixels=(unsigned char *) RelinquishMagickMemory(compact_pixels);\n  return(MagickTrue);\n}", "func_src_after": "static MagickBooleanType WriteImageChannels(const PSDInfo *psd_info,\n  const ImageInfo *image_info,Image *image,Image *next_image,\n  const MagickBooleanType separate,ExceptionInfo *exception)\n{\n  size_t\n    channels,\n    packet_size;\n\n  unsigned char\n    *compact_pixels;\n\n  /*\n    Write uncompressed pixels as separate planes.\n  */\n  channels=1;\n  packet_size=next_image->depth > 8UL ? 2UL : 1UL;\n  compact_pixels=(unsigned char *) NULL;\n  if (next_image->compression == RLECompression)\n    {\n      compact_pixels=(unsigned char *) AcquireQuantumMemory((2*channels*\n        next_image->columns)+1,packet_size*sizeof(*compact_pixels));\n      if (compact_pixels == (unsigned char *) NULL)\n        ThrowWriterException(ResourceLimitError,\"MemoryAllocationFailed\");\n    }\n  if (IsImageGray(next_image) != MagickFalse)\n    {\n      if (next_image->compression == RLECompression)\n        {\n          /*\n            Packbits compression.\n          */\n          (void) WriteBlobMSBShort(image,1);\n          WritePackbitsLength(psd_info,image_info,image,next_image,\n            compact_pixels,GrayQuantum,exception);\n          if (next_image->alpha_trait != UndefinedPixelTrait)\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,AlphaQuantum,exception);\n        }\n      WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n        GrayQuantum,MagickTrue,exception);\n      if (next_image->alpha_trait != UndefinedPixelTrait)\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          AlphaQuantum,separate,exception);\n      (void) SetImageProgress(image,SaveImagesTag,0,1);\n    }\n  else\n    if (next_image->storage_class == PseudoClass)\n      {\n        if (next_image->compression == RLECompression)\n          {\n            /*\n              Packbits compression.\n            */\n            (void) WriteBlobMSBShort(image,1);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,IndexQuantum,exception);\n            if (next_image->alpha_trait != UndefinedPixelTrait)\n              WritePackbitsLength(psd_info,image_info,image,next_image,\n                compact_pixels,AlphaQuantum,exception);\n          }\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          IndexQuantum,MagickTrue,exception);\n        if (next_image->alpha_trait != UndefinedPixelTrait)\n          WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n            AlphaQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,0,1);\n      }\n    else\n      {\n        if (next_image->colorspace == CMYKColorspace)\n          (void) NegateCMYK(next_image,exception);\n        if (next_image->compression == RLECompression)\n          {\n            /*\n              Packbits compression.\n            */\n            (void) WriteBlobMSBShort(image,1);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,RedQuantum,exception);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,GreenQuantum,exception);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,BlueQuantum,exception);\n            if (next_image->colorspace == CMYKColorspace)\n              WritePackbitsLength(psd_info,image_info,image,next_image,\n                compact_pixels,BlackQuantum,exception);\n            if (next_image->alpha_trait != UndefinedPixelTrait)\n              WritePackbitsLength(psd_info,image_info,image,next_image,\n                compact_pixels,AlphaQuantum,exception);\n          }\n        (void) SetImageProgress(image,SaveImagesTag,0,6);\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          RedQuantum,MagickTrue,exception);\n        (void) SetImageProgress(image,SaveImagesTag,1,6);\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          GreenQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,2,6);\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          BlueQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,3,6);\n        if (next_image->colorspace == CMYKColorspace)\n          WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n            BlackQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,4,6);\n        if (next_image->alpha_trait != UndefinedPixelTrait)\n          WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n            AlphaQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,5,6);\n        if (next_image->colorspace == CMYKColorspace)\n          (void) NegateCMYK(next_image,exception);\n      }\n  if (next_image->compression == RLECompression)\n    compact_pixels=(unsigned char *) RelinquishMagickMemory(compact_pixels);\n  return(MagickTrue);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/6f1879d498bcc5cce12fe0c5decb8dbc0f608e5d", "file_name": "coders/psd.c", "vul_type": "cwe-125", "description": "In C, write a function to handle writing image channel data with optional RLE compression and color space considerations."}
{"func_name": "set_fdc", "func_src_before": "static void set_fdc(int drive)\n{\n\tif (drive >= 0 && drive < N_DRIVE) {\n\t\tfdc = FDC(drive);\n\t\tcurrent_drive = drive;\n\t}\n\tif (fdc != 1 && fdc != 0) {\n\t\tpr_info(\"bad fdc value\\n\");\n\t\treturn;\n\t}\n\tset_dor(fdc, ~0, 8);\n#if N_FDC > 1\n\tset_dor(1 - fdc, ~8, 0);\n#endif\n\tif (FDCS->rawcmd == 2)\n\t\treset_fdc_info(1);\n\tif (fd_inb(FD_STATUS) != STATUS_READY)\n\t\tFDCS->reset = 1;\n}", "func_src_after": "static void set_fdc(int drive)\n{\n\tunsigned int new_fdc = fdc;\n\n\tif (drive >= 0 && drive < N_DRIVE) {\n\t\tnew_fdc = FDC(drive);\n\t\tcurrent_drive = drive;\n\t}\n\tif (new_fdc >= N_FDC) {\n\t\tpr_info(\"bad fdc value\\n\");\n\t\treturn;\n\t}\n\tfdc = new_fdc;\n\tset_dor(fdc, ~0, 8);\n#if N_FDC > 1\n\tset_dor(1 - fdc, ~8, 0);\n#endif\n\tif (FDCS->rawcmd == 2)\n\t\treset_fdc_info(1);\n\tif (fd_inb(FD_STATUS) != STATUS_READY)\n\t\tFDCS->reset = 1;\n}", "commit_link": "github.com/torvalds/linux/commit/2e90ca68b0d2f5548804f22f0dd61145516171e3", "file_name": "drivers/block/floppy.c", "vul_type": "cwe-125", "description": "Write a C function named `set_fdc` that configures a floppy disk controller (FDC) for a given drive number, with error checking and hardware status updates."}
{"func_name": "mif_process_cmpt", "func_src_before": "static int mif_process_cmpt(mif_hdr_t *hdr, char *buf)\n{\n\tjas_tvparser_t *tvp;\n\tmif_cmpt_t *cmpt;\n\tint id;\n\n\tcmpt = 0;\n\ttvp = 0;\n\n\tif (!(cmpt = mif_cmpt_create())) {\n\t\tgoto error;\n\t}\n\tcmpt->tlx = 0;\n\tcmpt->tly = 0;\n\tcmpt->sampperx = 0;\n\tcmpt->samppery = 0;\n\tcmpt->width = 0;\n\tcmpt->height = 0;\n\tcmpt->prec = 0;\n\tcmpt->sgnd = -1;\n\tcmpt->data = 0;\n\n\tif (!(tvp = jas_tvparser_create(buf))) {\n\t\tgoto error;\n\t}\n\twhile (!(id = jas_tvparser_next(tvp))) {\n\t\tswitch (jas_taginfo_nonull(jas_taginfos_lookup(mif_tags,\n\t\t  jas_tvparser_gettag(tvp)))->id) {\n\t\tcase MIF_TLX:\n\t\t\tcmpt->tlx = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_TLY:\n\t\t\tcmpt->tly = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_WIDTH:\n\t\t\tcmpt->width = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_HEIGHT:\n\t\t\tcmpt->height = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_HSAMP:\n\t\t\tcmpt->sampperx = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_VSAMP:\n\t\t\tcmpt->samppery = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_PREC:\n\t\t\tcmpt->prec = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_SGND:\n\t\t\tcmpt->sgnd = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_DATA:\n\t\t\tif (!(cmpt->data = jas_strdup(jas_tvparser_getval(tvp)))) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t}\n\tjas_tvparser_destroy(tvp);\n\tif (!cmpt->sampperx || !cmpt->samppery) {\n\t\tgoto error;\n\t}\n\tif (mif_hdr_addcmpt(hdr, hdr->numcmpts, cmpt)) {\n\t\tgoto error;\n\t}\n\treturn 0;\n\nerror:\n\tif (cmpt) {\n\t\tmif_cmpt_destroy(cmpt);\n\t}\n\tif (tvp) {\n\t\tjas_tvparser_destroy(tvp);\n\t}\n\treturn -1;\n}", "func_src_after": "static int mif_process_cmpt(mif_hdr_t *hdr, char *buf)\n{\n\tjas_tvparser_t *tvp;\n\tmif_cmpt_t *cmpt;\n\tint id;\n\n\tcmpt = 0;\n\ttvp = 0;\n\n\tif (!(cmpt = mif_cmpt_create())) {\n\t\tgoto error;\n\t}\n\tcmpt->tlx = 0;\n\tcmpt->tly = 0;\n\tcmpt->sampperx = 0;\n\tcmpt->samppery = 0;\n\tcmpt->width = 0;\n\tcmpt->height = 0;\n\tcmpt->prec = 0;\n\tcmpt->sgnd = -1;\n\tcmpt->data = 0;\n\n\tif (!(tvp = jas_tvparser_create(buf))) {\n\t\tgoto error;\n\t}\n\twhile (!(id = jas_tvparser_next(tvp))) {\n\t\tswitch (jas_taginfo_nonull(jas_taginfos_lookup(mif_tags,\n\t\t  jas_tvparser_gettag(tvp)))->id) {\n\t\tcase MIF_TLX:\n\t\t\tcmpt->tlx = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_TLY:\n\t\t\tcmpt->tly = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_WIDTH:\n\t\t\tcmpt->width = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_HEIGHT:\n\t\t\tcmpt->height = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_HSAMP:\n\t\t\tcmpt->sampperx = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_VSAMP:\n\t\t\tcmpt->samppery = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_PREC:\n\t\t\tcmpt->prec = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_SGND:\n\t\t\tcmpt->sgnd = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_DATA:\n\t\t\tif (!(cmpt->data = jas_strdup(jas_tvparser_getval(tvp)))) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (!cmpt->sampperx || !cmpt->samppery) {\n\t\tgoto error;\n\t}\n\tif (mif_hdr_addcmpt(hdr, hdr->numcmpts, cmpt)) {\n\t\tgoto error;\n\t}\n\tjas_tvparser_destroy(tvp);\n\treturn 0;\n\nerror:\n\tif (cmpt) {\n\t\tmif_cmpt_destroy(cmpt);\n\t}\n\tif (tvp) {\n\t\tjas_tvparser_destroy(tvp);\n\t}\n\treturn -1;\n}", "commit_link": "github.com/mdadams/jasper/commit/df5d2867e8004e51e18b89865bc4aa69229227b3", "file_name": "src/libjasper/mif/mif_cod.c", "vul_type": "cwe-416", "description": "Write a C function to parse component information from a buffer and add it to a MIF header, handling errors appropriately."}
{"func_name": "writeToDb", "func_src_before": "    def writeToDb(self, url):\n        try:\n            self.cursor.execute(\"INSERT INTO queue (url, visited) VALUES ('{}', '0');\".format(url))\n            self.db.commit()\n        except Exception as e:\n            print(e)", "func_src_after": "    def writeToDb(self, url):\n        try:\n            self.cursor.execute(\"INSERT INTO queue (url, visited) VALUES (?, '0');\", url)\n            self.db.commit()\n        except Exception as e:\n            print(e)", "commit_link": "github.com/jappe999/WebScraper/commit/46a4e0843aa44d903293637afad53dfcbc37b480", "file_name": "beta/database.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a URL into a database table with a visited flag set to '0', handling exceptions."}
{"func_name": "usbhid_parse", "func_src_before": "static int usbhid_parse(struct hid_device *hid)\n{\n\tstruct usb_interface *intf = to_usb_interface(hid->dev.parent);\n\tstruct usb_host_interface *interface = intf->cur_altsetting;\n\tstruct usb_device *dev = interface_to_usbdev (intf);\n\tstruct hid_descriptor *hdesc;\n\tu32 quirks = 0;\n\tunsigned int rsize = 0;\n\tchar *rdesc;\n\tint ret, n;\n\n\tquirks = usbhid_lookup_quirk(le16_to_cpu(dev->descriptor.idVendor),\n\t\t\tle16_to_cpu(dev->descriptor.idProduct));\n\n\tif (quirks & HID_QUIRK_IGNORE)\n\t\treturn -ENODEV;\n\n\t/* Many keyboards and mice don't like to be polled for reports,\n\t * so we will always set the HID_QUIRK_NOGET flag for them. */\n\tif (interface->desc.bInterfaceSubClass == USB_INTERFACE_SUBCLASS_BOOT) {\n\t\tif (interface->desc.bInterfaceProtocol == USB_INTERFACE_PROTOCOL_KEYBOARD ||\n\t\t\tinterface->desc.bInterfaceProtocol == USB_INTERFACE_PROTOCOL_MOUSE)\n\t\t\t\tquirks |= HID_QUIRK_NOGET;\n\t}\n\n\tif (usb_get_extra_descriptor(interface, HID_DT_HID, &hdesc) &&\n\t    (!interface->desc.bNumEndpoints ||\n\t     usb_get_extra_descriptor(&interface->endpoint[0], HID_DT_HID, &hdesc))) {\n\t\tdbg_hid(\"class descriptor not present\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\thid->version = le16_to_cpu(hdesc->bcdHID);\n\thid->country = hdesc->bCountryCode;\n\n\tfor (n = 0; n < hdesc->bNumDescriptors; n++)\n\t\tif (hdesc->desc[n].bDescriptorType == HID_DT_REPORT)\n\t\t\trsize = le16_to_cpu(hdesc->desc[n].wDescriptorLength);\n\n\tif (!rsize || rsize > HID_MAX_DESCRIPTOR_SIZE) {\n\t\tdbg_hid(\"weird size of report descriptor (%u)\\n\", rsize);\n\t\treturn -EINVAL;\n\t}\n\n\trdesc = kmalloc(rsize, GFP_KERNEL);\n\tif (!rdesc)\n\t\treturn -ENOMEM;\n\n\thid_set_idle(dev, interface->desc.bInterfaceNumber, 0, 0);\n\n\tret = hid_get_class_descriptor(dev, interface->desc.bInterfaceNumber,\n\t\t\tHID_DT_REPORT, rdesc, rsize);\n\tif (ret < 0) {\n\t\tdbg_hid(\"reading report descriptor failed\\n\");\n\t\tkfree(rdesc);\n\t\tgoto err;\n\t}\n\n\tret = hid_parse_report(hid, rdesc, rsize);\n\tkfree(rdesc);\n\tif (ret) {\n\t\tdbg_hid(\"parsing report descriptor failed\\n\");\n\t\tgoto err;\n\t}\n\n\thid->quirks |= quirks;\n\n\treturn 0;\nerr:\n\treturn ret;\n}", "func_src_after": "static int usbhid_parse(struct hid_device *hid)\n{\n\tstruct usb_interface *intf = to_usb_interface(hid->dev.parent);\n\tstruct usb_host_interface *interface = intf->cur_altsetting;\n\tstruct usb_device *dev = interface_to_usbdev (intf);\n\tstruct hid_descriptor *hdesc;\n\tu32 quirks = 0;\n\tunsigned int rsize = 0;\n\tchar *rdesc;\n\tint ret, n;\n\tint num_descriptors;\n\tsize_t offset = offsetof(struct hid_descriptor, desc);\n\n\tquirks = usbhid_lookup_quirk(le16_to_cpu(dev->descriptor.idVendor),\n\t\t\tle16_to_cpu(dev->descriptor.idProduct));\n\n\tif (quirks & HID_QUIRK_IGNORE)\n\t\treturn -ENODEV;\n\n\t/* Many keyboards and mice don't like to be polled for reports,\n\t * so we will always set the HID_QUIRK_NOGET flag for them. */\n\tif (interface->desc.bInterfaceSubClass == USB_INTERFACE_SUBCLASS_BOOT) {\n\t\tif (interface->desc.bInterfaceProtocol == USB_INTERFACE_PROTOCOL_KEYBOARD ||\n\t\t\tinterface->desc.bInterfaceProtocol == USB_INTERFACE_PROTOCOL_MOUSE)\n\t\t\t\tquirks |= HID_QUIRK_NOGET;\n\t}\n\n\tif (usb_get_extra_descriptor(interface, HID_DT_HID, &hdesc) &&\n\t    (!interface->desc.bNumEndpoints ||\n\t     usb_get_extra_descriptor(&interface->endpoint[0], HID_DT_HID, &hdesc))) {\n\t\tdbg_hid(\"class descriptor not present\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tif (hdesc->bLength < sizeof(struct hid_descriptor)) {\n\t\tdbg_hid(\"hid descriptor is too short\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\thid->version = le16_to_cpu(hdesc->bcdHID);\n\thid->country = hdesc->bCountryCode;\n\n\tnum_descriptors = min_t(int, hdesc->bNumDescriptors,\n\t       (hdesc->bLength - offset) / sizeof(struct hid_class_descriptor));\n\n\tfor (n = 0; n < num_descriptors; n++)\n\t\tif (hdesc->desc[n].bDescriptorType == HID_DT_REPORT)\n\t\t\trsize = le16_to_cpu(hdesc->desc[n].wDescriptorLength);\n\n\tif (!rsize || rsize > HID_MAX_DESCRIPTOR_SIZE) {\n\t\tdbg_hid(\"weird size of report descriptor (%u)\\n\", rsize);\n\t\treturn -EINVAL;\n\t}\n\n\trdesc = kmalloc(rsize, GFP_KERNEL);\n\tif (!rdesc)\n\t\treturn -ENOMEM;\n\n\thid_set_idle(dev, interface->desc.bInterfaceNumber, 0, 0);\n\n\tret = hid_get_class_descriptor(dev, interface->desc.bInterfaceNumber,\n\t\t\tHID_DT_REPORT, rdesc, rsize);\n\tif (ret < 0) {\n\t\tdbg_hid(\"reading report descriptor failed\\n\");\n\t\tkfree(rdesc);\n\t\tgoto err;\n\t}\n\n\tret = hid_parse_report(hid, rdesc, rsize);\n\tkfree(rdesc);\n\tif (ret) {\n\t\tdbg_hid(\"parsing report descriptor failed\\n\");\n\t\tgoto err;\n\t}\n\n\thid->quirks |= quirks;\n\n\treturn 0;\nerr:\n\treturn ret;\n}", "commit_link": "github.com/torvalds/linux/commit/f043bfc98c193c284e2cd768fefabe18ac2fed9b", "file_name": "drivers/hid/usbhid/hid-core.c", "vul_type": "cwe-125", "description": "Write a C function named `usbhid_parse` that parses HID report descriptors for a USB device and handles quirks."}
{"func_name": "tcos_decipher", "func_src_before": "static int tcos_decipher(sc_card_t *card, const u8 * crgram, size_t crgram_len, u8 * out, size_t outlen)\n{\n\tsc_context_t *ctx;\n\tsc_apdu_t apdu;\n\tu8 rbuf[SC_MAX_APDU_BUFFER_SIZE];\n\tu8 sbuf[SC_MAX_APDU_BUFFER_SIZE];\n\ttcos_data *data;\n\tint tcos3, r;\n\n\tassert(card != NULL && crgram != NULL && out != NULL);\n\tctx = card->ctx;\n\ttcos3=(card->type==SC_CARD_TYPE_TCOS_V3);\n\tdata=(tcos_data *)card->drv_data;\n\n\tLOG_FUNC_CALLED(ctx);\n\tsc_log(ctx,\n\t\t\"TCOS3:%d PKCS1:%d\\n\",tcos3,\n\t\t!!(data->pad_flags & SC_ALGORITHM_RSA_PAD_PKCS1));\n\n\tsc_format_apdu(card, &apdu, crgram_len>255 ? SC_APDU_CASE_4_EXT : SC_APDU_CASE_4_SHORT, 0x2A, 0x80, 0x86);\n\tapdu.resp = rbuf;\n\tapdu.resplen = sizeof(rbuf);\n\tapdu.le = crgram_len;\n\n\tapdu.data = sbuf;\n\tapdu.lc = apdu.datalen = crgram_len+1;\n\tsbuf[0] = tcos3 ? 0x00 : ((data->pad_flags & SC_ALGORITHM_RSA_PAD_PKCS1) ? 0x81 : 0x02);\n\tmemcpy(sbuf+1, crgram, crgram_len);\n\n\tr = sc_transmit_apdu(card, &apdu);\n\tLOG_TEST_RET(card->ctx, r, \"APDU transmit failed\");\n\n\tif (apdu.sw1==0x90 && apdu.sw2==0x00) {\n\t\tsize_t len= (apdu.resplen>outlen) ? outlen : apdu.resplen;\n\t\tunsigned int offset=0;\n\t\tif(tcos3 && (data->pad_flags & SC_ALGORITHM_RSA_PAD_PKCS1) && apdu.resp[0]==0 && apdu.resp[1]==2) {\n\t\t\toffset=2; while(offset<len && apdu.resp[offset]!=0) ++offset;\n\t\t\toffset=(offset<len-1) ? offset+1 : 0;\n\t\t}\n\t\tmemcpy(out, apdu.resp+offset, len-offset);\n\t\tSC_FUNC_RETURN(card->ctx, SC_LOG_DEBUG_VERBOSE, len-offset);\n\t}\n\tSC_FUNC_RETURN(card->ctx, SC_LOG_DEBUG_VERBOSE, sc_check_sw(card, apdu.sw1, apdu.sw2));\n}", "func_src_after": "static int tcos_decipher(sc_card_t *card, const u8 * crgram, size_t crgram_len, u8 * out, size_t outlen)\n{\n\tsc_context_t *ctx;\n\tsc_apdu_t apdu;\n\tu8 rbuf[SC_MAX_APDU_BUFFER_SIZE];\n\tu8 sbuf[SC_MAX_APDU_BUFFER_SIZE];\n\ttcos_data *data;\n\tint tcos3, r;\n\n\tassert(card != NULL && crgram != NULL && out != NULL);\n\tctx = card->ctx;\n\ttcos3=(card->type==SC_CARD_TYPE_TCOS_V3);\n\tdata=(tcos_data *)card->drv_data;\n\n\tLOG_FUNC_CALLED(ctx);\n\tsc_log(ctx,\n\t\t\"TCOS3:%d PKCS1:%d\\n\",tcos3,\n\t\t!!(data->pad_flags & SC_ALGORITHM_RSA_PAD_PKCS1));\n\n\tsc_format_apdu(card, &apdu, crgram_len>255 ? SC_APDU_CASE_4_EXT : SC_APDU_CASE_4_SHORT, 0x2A, 0x80, 0x86);\n\tapdu.resp = rbuf;\n\tapdu.resplen = sizeof(rbuf);\n\tapdu.le = crgram_len;\n\n\tapdu.data = sbuf;\n\tapdu.lc = apdu.datalen = crgram_len+1;\n\tsbuf[0] = tcos3 ? 0x00 : ((data->pad_flags & SC_ALGORITHM_RSA_PAD_PKCS1) ? 0x81 : 0x02);\n\tif (sizeof sbuf - 1 < crgram_len)\n\t\treturn SC_ERROR_INVALID_ARGUMENTS;\n\tmemcpy(sbuf+1, crgram, crgram_len);\n\n\tr = sc_transmit_apdu(card, &apdu);\n\tLOG_TEST_RET(card->ctx, r, \"APDU transmit failed\");\n\n\tif (apdu.sw1==0x90 && apdu.sw2==0x00) {\n\t\tsize_t len= (apdu.resplen>outlen) ? outlen : apdu.resplen;\n\t\tunsigned int offset=0;\n\t\tif(tcos3 && (data->pad_flags & SC_ALGORITHM_RSA_PAD_PKCS1) && apdu.resp[0]==0 && apdu.resp[1]==2) {\n\t\t\toffset=2; while(offset<len && apdu.resp[offset]!=0) ++offset;\n\t\t\toffset=(offset<len-1) ? offset+1 : 0;\n\t\t}\n\t\tmemcpy(out, apdu.resp+offset, len-offset);\n\t\tSC_FUNC_RETURN(card->ctx, SC_LOG_DEBUG_VERBOSE, len-offset);\n\t}\n\tSC_FUNC_RETURN(card->ctx, SC_LOG_DEBUG_VERBOSE, sc_check_sw(card, apdu.sw1, apdu.sw2));\n}", "commit_link": "github.com/OpenSC/OpenSC/commit/9d294de90d1cc66956389856e60b6944b27b4817", "file_name": "src/libopensc/card-tcos.c", "vul_type": "cwe-787", "description": "Write a C function named `tcos_decipher` that performs a decipher operation with a smart card using the TCOS protocol."}
{"func_name": "multiSelect", "func_src_before": "static int multiSelect(\n  Parse *pParse,        /* Parsing context */\n  Select *p,            /* The right-most of SELECTs to be coded */\n  SelectDest *pDest     /* What to do with query results */\n){\n  int rc = SQLITE_OK;   /* Success code from a subroutine */\n  Select *pPrior;       /* Another SELECT immediately to our left */\n  Vdbe *v;              /* Generate code to this VDBE */\n  SelectDest dest;      /* Alternative data destination */\n  Select *pDelete = 0;  /* Chain of simple selects to delete */\n  sqlite3 *db;          /* Database connection */\n\n  /* Make sure there is no ORDER BY or LIMIT clause on prior SELECTs.  Only\n  ** the last (right-most) SELECT in the series may have an ORDER BY or LIMIT.\n  */\n  assert( p && p->pPrior );  /* Calling function guarantees this much */\n  assert( (p->selFlags & SF_Recursive)==0 || p->op==TK_ALL || p->op==TK_UNION );\n  assert( p->selFlags & SF_Compound );\n  db = pParse->db;\n  pPrior = p->pPrior;\n  dest = *pDest;\n  if( pPrior->pOrderBy || pPrior->pLimit ){\n    sqlite3ErrorMsg(pParse,\"%s clause should come after %s not before\",\n      pPrior->pOrderBy!=0 ? \"ORDER BY\" : \"LIMIT\", selectOpName(p->op));\n    rc = 1;\n    goto multi_select_end;\n  }\n\n  v = sqlite3GetVdbe(pParse);\n  assert( v!=0 );  /* The VDBE already created by calling function */\n\n  /* Create the destination temporary table if necessary\n  */\n  if( dest.eDest==SRT_EphemTab ){\n    assert( p->pEList );\n    sqlite3VdbeAddOp2(v, OP_OpenEphemeral, dest.iSDParm, p->pEList->nExpr);\n    dest.eDest = SRT_Table;\n  }\n\n  /* Special handling for a compound-select that originates as a VALUES clause.\n  */\n  if( p->selFlags & SF_MultiValue ){\n    rc = multiSelectValues(pParse, p, &dest);\n    if( rc>=0 ) goto multi_select_end;\n    rc = SQLITE_OK;\n  }\n\n  /* Make sure all SELECTs in the statement have the same number of elements\n  ** in their result sets.\n  */\n  assert( p->pEList && pPrior->pEList );\n  assert( p->pEList->nExpr==pPrior->pEList->nExpr );\n\n#ifndef SQLITE_OMIT_CTE\n  if( p->selFlags & SF_Recursive ){\n    generateWithRecursiveQuery(pParse, p, &dest);\n  }else\n#endif\n\n  /* Compound SELECTs that have an ORDER BY clause are handled separately.\n  */\n  if( p->pOrderBy ){\n    return multiSelectOrderBy(pParse, p, pDest);\n  }else{\n\n#ifndef SQLITE_OMIT_EXPLAIN\n    if( pPrior->pPrior==0 ){\n      ExplainQueryPlan((pParse, 1, \"COMPOUND QUERY\"));\n      ExplainQueryPlan((pParse, 1, \"LEFT-MOST SUBQUERY\"));\n    }\n#endif\n\n    /* Generate code for the left and right SELECT statements.\n    */\n    switch( p->op ){\n      case TK_ALL: {\n        int addr = 0;\n        int nLimit;\n        assert( !pPrior->pLimit );\n        pPrior->iLimit = p->iLimit;\n        pPrior->iOffset = p->iOffset;\n        pPrior->pLimit = p->pLimit;\n        rc = sqlite3Select(pParse, pPrior, &dest);\n        p->pLimit = 0;\n        if( rc ){\n          goto multi_select_end;\n        }\n        p->pPrior = 0;\n        p->iLimit = pPrior->iLimit;\n        p->iOffset = pPrior->iOffset;\n        if( p->iLimit ){\n          addr = sqlite3VdbeAddOp1(v, OP_IfNot, p->iLimit); VdbeCoverage(v);\n          VdbeComment((v, \"Jump ahead if LIMIT reached\"));\n          if( p->iOffset ){\n            sqlite3VdbeAddOp3(v, OP_OffsetLimit,\n                              p->iLimit, p->iOffset+1, p->iOffset);\n          }\n        }\n        ExplainQueryPlan((pParse, 1, \"UNION ALL\"));\n        rc = sqlite3Select(pParse, p, &dest);\n        testcase( rc!=SQLITE_OK );\n        pDelete = p->pPrior;\n        p->pPrior = pPrior;\n        p->nSelectRow = sqlite3LogEstAdd(p->nSelectRow, pPrior->nSelectRow);\n        if( pPrior->pLimit\n         && sqlite3ExprIsInteger(pPrior->pLimit->pLeft, &nLimit)\n         && nLimit>0 && p->nSelectRow > sqlite3LogEst((u64)nLimit) \n        ){\n          p->nSelectRow = sqlite3LogEst((u64)nLimit);\n        }\n        if( addr ){\n          sqlite3VdbeJumpHere(v, addr);\n        }\n        break;\n      }\n      case TK_EXCEPT:\n      case TK_UNION: {\n        int unionTab;    /* Cursor number of the temp table holding result */\n        u8 op = 0;       /* One of the SRT_ operations to apply to self */\n        int priorOp;     /* The SRT_ operation to apply to prior selects */\n        Expr *pLimit;    /* Saved values of p->nLimit  */\n        int addr;\n        SelectDest uniondest;\n  \n        testcase( p->op==TK_EXCEPT );\n        testcase( p->op==TK_UNION );\n        priorOp = SRT_Union;\n        if( dest.eDest==priorOp ){\n          /* We can reuse a temporary table generated by a SELECT to our\n          ** right.\n          */\n          assert( p->pLimit==0 );      /* Not allowed on leftward elements */\n          unionTab = dest.iSDParm;\n        }else{\n          /* We will need to create our own temporary table to hold the\n          ** intermediate results.\n          */\n          unionTab = pParse->nTab++;\n          assert( p->pOrderBy==0 );\n          addr = sqlite3VdbeAddOp2(v, OP_OpenEphemeral, unionTab, 0);\n          assert( p->addrOpenEphm[0] == -1 );\n          p->addrOpenEphm[0] = addr;\n          findRightmost(p)->selFlags |= SF_UsesEphemeral;\n          assert( p->pEList );\n        }\n  \n        /* Code the SELECT statements to our left\n        */\n        assert( !pPrior->pOrderBy );\n        sqlite3SelectDestInit(&uniondest, priorOp, unionTab);\n        rc = sqlite3Select(pParse, pPrior, &uniondest);\n        if( rc ){\n          goto multi_select_end;\n        }\n  \n        /* Code the current SELECT statement\n        */\n        if( p->op==TK_EXCEPT ){\n          op = SRT_Except;\n        }else{\n          assert( p->op==TK_UNION );\n          op = SRT_Union;\n        }\n        p->pPrior = 0;\n        pLimit = p->pLimit;\n        p->pLimit = 0;\n        uniondest.eDest = op;\n        ExplainQueryPlan((pParse, 1, \"%s USING TEMP B-TREE\",\n                          selectOpName(p->op)));\n        rc = sqlite3Select(pParse, p, &uniondest);\n        testcase( rc!=SQLITE_OK );\n        /* Query flattening in sqlite3Select() might refill p->pOrderBy.\n        ** Be sure to delete p->pOrderBy, therefore, to avoid a memory leak. */\n        sqlite3ExprListDelete(db, p->pOrderBy);\n        pDelete = p->pPrior;\n        p->pPrior = pPrior;\n        p->pOrderBy = 0;\n        if( p->op==TK_UNION ){\n          p->nSelectRow = sqlite3LogEstAdd(p->nSelectRow, pPrior->nSelectRow);\n        }\n        sqlite3ExprDelete(db, p->pLimit);\n        p->pLimit = pLimit;\n        p->iLimit = 0;\n        p->iOffset = 0;\n  \n        /* Convert the data in the temporary table into whatever form\n        ** it is that we currently need.\n        */\n        assert( unionTab==dest.iSDParm || dest.eDest!=priorOp );\n        if( dest.eDest!=priorOp ){\n          int iCont, iBreak, iStart;\n          assert( p->pEList );\n          iBreak = sqlite3VdbeMakeLabel(pParse);\n          iCont = sqlite3VdbeMakeLabel(pParse);\n          computeLimitRegisters(pParse, p, iBreak);\n          sqlite3VdbeAddOp2(v, OP_Rewind, unionTab, iBreak); VdbeCoverage(v);\n          iStart = sqlite3VdbeCurrentAddr(v);\n          selectInnerLoop(pParse, p, unionTab,\n                          0, 0, &dest, iCont, iBreak);\n          sqlite3VdbeResolveLabel(v, iCont);\n          sqlite3VdbeAddOp2(v, OP_Next, unionTab, iStart); VdbeCoverage(v);\n          sqlite3VdbeResolveLabel(v, iBreak);\n          sqlite3VdbeAddOp2(v, OP_Close, unionTab, 0);\n        }\n        break;\n      }\n      default: assert( p->op==TK_INTERSECT ); {\n        int tab1, tab2;\n        int iCont, iBreak, iStart;\n        Expr *pLimit;\n        int addr;\n        SelectDest intersectdest;\n        int r1;\n  \n        /* INTERSECT is different from the others since it requires\n        ** two temporary tables.  Hence it has its own case.  Begin\n        ** by allocating the tables we will need.\n        */\n        tab1 = pParse->nTab++;\n        tab2 = pParse->nTab++;\n        assert( p->pOrderBy==0 );\n  \n        addr = sqlite3VdbeAddOp2(v, OP_OpenEphemeral, tab1, 0);\n        assert( p->addrOpenEphm[0] == -1 );\n        p->addrOpenEphm[0] = addr;\n        findRightmost(p)->selFlags |= SF_UsesEphemeral;\n        assert( p->pEList );\n  \n        /* Code the SELECTs to our left into temporary table \"tab1\".\n        */\n        sqlite3SelectDestInit(&intersectdest, SRT_Union, tab1);\n        rc = sqlite3Select(pParse, pPrior, &intersectdest);\n        if( rc ){\n          goto multi_select_end;\n        }\n  \n        /* Code the current SELECT into temporary table \"tab2\"\n        */\n        addr = sqlite3VdbeAddOp2(v, OP_OpenEphemeral, tab2, 0);\n        assert( p->addrOpenEphm[1] == -1 );\n        p->addrOpenEphm[1] = addr;\n        p->pPrior = 0;\n        pLimit = p->pLimit;\n        p->pLimit = 0;\n        intersectdest.iSDParm = tab2;\n        ExplainQueryPlan((pParse, 1, \"%s USING TEMP B-TREE\",\n                          selectOpName(p->op)));\n        rc = sqlite3Select(pParse, p, &intersectdest);\n        testcase( rc!=SQLITE_OK );\n        pDelete = p->pPrior;\n        p->pPrior = pPrior;\n        if( p->nSelectRow>pPrior->nSelectRow ){\n          p->nSelectRow = pPrior->nSelectRow;\n        }\n        sqlite3ExprDelete(db, p->pLimit);\n        p->pLimit = pLimit;\n  \n        /* Generate code to take the intersection of the two temporary\n        ** tables.\n        */\n        assert( p->pEList );\n        iBreak = sqlite3VdbeMakeLabel(pParse);\n        iCont = sqlite3VdbeMakeLabel(pParse);\n        computeLimitRegisters(pParse, p, iBreak);\n        sqlite3VdbeAddOp2(v, OP_Rewind, tab1, iBreak); VdbeCoverage(v);\n        r1 = sqlite3GetTempReg(pParse);\n        iStart = sqlite3VdbeAddOp2(v, OP_RowData, tab1, r1);\n        sqlite3VdbeAddOp4Int(v, OP_NotFound, tab2, iCont, r1, 0);\n        VdbeCoverage(v);\n        sqlite3ReleaseTempReg(pParse, r1);\n        selectInnerLoop(pParse, p, tab1,\n                        0, 0, &dest, iCont, iBreak);\n        sqlite3VdbeResolveLabel(v, iCont);\n        sqlite3VdbeAddOp2(v, OP_Next, tab1, iStart); VdbeCoverage(v);\n        sqlite3VdbeResolveLabel(v, iBreak);\n        sqlite3VdbeAddOp2(v, OP_Close, tab2, 0);\n        sqlite3VdbeAddOp2(v, OP_Close, tab1, 0);\n        break;\n      }\n    }\n  \n  #ifndef SQLITE_OMIT_EXPLAIN\n    if( p->pNext==0 ){\n      ExplainQueryPlanPop(pParse);\n    }\n  #endif\n  }\n  \n  /* Compute collating sequences used by \n  ** temporary tables needed to implement the compound select.\n  ** Attach the KeyInfo structure to all temporary tables.\n  **\n  ** This section is run by the right-most SELECT statement only.\n  ** SELECT statements to the left always skip this part.  The right-most\n  ** SELECT might also skip this part if it has no ORDER BY clause and\n  ** no temp tables are required.\n  */\n  if( p->selFlags & SF_UsesEphemeral ){\n    int i;                        /* Loop counter */\n    KeyInfo *pKeyInfo;            /* Collating sequence for the result set */\n    Select *pLoop;                /* For looping through SELECT statements */\n    CollSeq **apColl;             /* For looping through pKeyInfo->aColl[] */\n    int nCol;                     /* Number of columns in result set */\n\n    assert( p->pNext==0 );\n    nCol = p->pEList->nExpr;\n    pKeyInfo = sqlite3KeyInfoAlloc(db, nCol, 1);\n    if( !pKeyInfo ){\n      rc = SQLITE_NOMEM_BKPT;\n      goto multi_select_end;\n    }\n    for(i=0, apColl=pKeyInfo->aColl; i<nCol; i++, apColl++){\n      *apColl = multiSelectCollSeq(pParse, p, i);\n      if( 0==*apColl ){\n        *apColl = db->pDfltColl;\n      }\n    }\n\n    for(pLoop=p; pLoop; pLoop=pLoop->pPrior){\n      for(i=0; i<2; i++){\n        int addr = pLoop->addrOpenEphm[i];\n        if( addr<0 ){\n          /* If [0] is unused then [1] is also unused.  So we can\n          ** always safely abort as soon as the first unused slot is found */\n          assert( pLoop->addrOpenEphm[1]<0 );\n          break;\n        }\n        sqlite3VdbeChangeP2(v, addr, nCol);\n        sqlite3VdbeChangeP4(v, addr, (char*)sqlite3KeyInfoRef(pKeyInfo),\n                            P4_KEYINFO);\n        pLoop->addrOpenEphm[i] = -1;\n      }\n    }\n    sqlite3KeyInfoUnref(pKeyInfo);\n  }\n\nmulti_select_end:\n  pDest->iSdst = dest.iSdst;\n  pDest->nSdst = dest.nSdst;\n  sqlite3SelectDelete(db, pDelete);\n  return rc;\n}", "func_src_after": "static int multiSelect(\n  Parse *pParse,        /* Parsing context */\n  Select *p,            /* The right-most of SELECTs to be coded */\n  SelectDest *pDest     /* What to do with query results */\n){\n  int rc = SQLITE_OK;   /* Success code from a subroutine */\n  Select *pPrior;       /* Another SELECT immediately to our left */\n  Vdbe *v;              /* Generate code to this VDBE */\n  SelectDest dest;      /* Alternative data destination */\n  Select *pDelete = 0;  /* Chain of simple selects to delete */\n  sqlite3 *db;          /* Database connection */\n\n  /* Make sure there is no ORDER BY or LIMIT clause on prior SELECTs.  Only\n  ** the last (right-most) SELECT in the series may have an ORDER BY or LIMIT.\n  */\n  assert( p && p->pPrior );  /* Calling function guarantees this much */\n  assert( (p->selFlags & SF_Recursive)==0 || p->op==TK_ALL || p->op==TK_UNION );\n  assert( p->selFlags & SF_Compound );\n  db = pParse->db;\n  pPrior = p->pPrior;\n  dest = *pDest;\n  if( pPrior->pOrderBy || pPrior->pLimit ){\n    sqlite3ErrorMsg(pParse,\"%s clause should come after %s not before\",\n      pPrior->pOrderBy!=0 ? \"ORDER BY\" : \"LIMIT\", selectOpName(p->op));\n    rc = 1;\n    goto multi_select_end;\n  }\n\n  v = sqlite3GetVdbe(pParse);\n  assert( v!=0 );  /* The VDBE already created by calling function */\n\n  /* Create the destination temporary table if necessary\n  */\n  if( dest.eDest==SRT_EphemTab ){\n    assert( p->pEList );\n    sqlite3VdbeAddOp2(v, OP_OpenEphemeral, dest.iSDParm, p->pEList->nExpr);\n    dest.eDest = SRT_Table;\n  }\n\n  /* Special handling for a compound-select that originates as a VALUES clause.\n  */\n  if( p->selFlags & SF_MultiValue ){\n    rc = multiSelectValues(pParse, p, &dest);\n    if( rc>=0 ) goto multi_select_end;\n    rc = SQLITE_OK;\n  }\n\n  /* Make sure all SELECTs in the statement have the same number of elements\n  ** in their result sets.\n  */\n  assert( p->pEList && pPrior->pEList );\n  assert( p->pEList->nExpr==pPrior->pEList->nExpr );\n\n#ifndef SQLITE_OMIT_CTE\n  if( p->selFlags & SF_Recursive ){\n    generateWithRecursiveQuery(pParse, p, &dest);\n  }else\n#endif\n\n  /* Compound SELECTs that have an ORDER BY clause are handled separately.\n  */\n  if( p->pOrderBy ){\n    return multiSelectOrderBy(pParse, p, pDest);\n  }else{\n\n#ifndef SQLITE_OMIT_EXPLAIN\n    if( pPrior->pPrior==0 ){\n      ExplainQueryPlan((pParse, 1, \"COMPOUND QUERY\"));\n      ExplainQueryPlan((pParse, 1, \"LEFT-MOST SUBQUERY\"));\n    }\n#endif\n\n    /* Generate code for the left and right SELECT statements.\n    */\n    switch( p->op ){\n      case TK_ALL: {\n        int addr = 0;\n        int nLimit;\n        assert( !pPrior->pLimit );\n        pPrior->iLimit = p->iLimit;\n        pPrior->iOffset = p->iOffset;\n        pPrior->pLimit = p->pLimit;\n        rc = sqlite3Select(pParse, pPrior, &dest);\n        p->pLimit = 0;\n        if( rc ){\n          goto multi_select_end;\n        }\n        p->pPrior = 0;\n        p->iLimit = pPrior->iLimit;\n        p->iOffset = pPrior->iOffset;\n        if( p->iLimit ){\n          addr = sqlite3VdbeAddOp1(v, OP_IfNot, p->iLimit); VdbeCoverage(v);\n          VdbeComment((v, \"Jump ahead if LIMIT reached\"));\n          if( p->iOffset ){\n            sqlite3VdbeAddOp3(v, OP_OffsetLimit,\n                              p->iLimit, p->iOffset+1, p->iOffset);\n          }\n        }\n        ExplainQueryPlan((pParse, 1, \"UNION ALL\"));\n        rc = sqlite3Select(pParse, p, &dest);\n        testcase( rc!=SQLITE_OK );\n        pDelete = p->pPrior;\n        p->pPrior = pPrior;\n        p->nSelectRow = sqlite3LogEstAdd(p->nSelectRow, pPrior->nSelectRow);\n        if( pPrior->pLimit\n         && sqlite3ExprIsInteger(pPrior->pLimit->pLeft, &nLimit)\n         && nLimit>0 && p->nSelectRow > sqlite3LogEst((u64)nLimit) \n        ){\n          p->nSelectRow = sqlite3LogEst((u64)nLimit);\n        }\n        if( addr ){\n          sqlite3VdbeJumpHere(v, addr);\n        }\n        break;\n      }\n      case TK_EXCEPT:\n      case TK_UNION: {\n        int unionTab;    /* Cursor number of the temp table holding result */\n        u8 op = 0;       /* One of the SRT_ operations to apply to self */\n        int priorOp;     /* The SRT_ operation to apply to prior selects */\n        Expr *pLimit;    /* Saved values of p->nLimit  */\n        int addr;\n        SelectDest uniondest;\n  \n        testcase( p->op==TK_EXCEPT );\n        testcase( p->op==TK_UNION );\n        priorOp = SRT_Union;\n        if( dest.eDest==priorOp ){\n          /* We can reuse a temporary table generated by a SELECT to our\n          ** right.\n          */\n          assert( p->pLimit==0 );      /* Not allowed on leftward elements */\n          unionTab = dest.iSDParm;\n        }else{\n          /* We will need to create our own temporary table to hold the\n          ** intermediate results.\n          */\n          unionTab = pParse->nTab++;\n          assert( p->pOrderBy==0 );\n          addr = sqlite3VdbeAddOp2(v, OP_OpenEphemeral, unionTab, 0);\n          assert( p->addrOpenEphm[0] == -1 );\n          p->addrOpenEphm[0] = addr;\n          findRightmost(p)->selFlags |= SF_UsesEphemeral;\n          assert( p->pEList );\n        }\n  \n        /* Code the SELECT statements to our left\n        */\n        assert( !pPrior->pOrderBy );\n        sqlite3SelectDestInit(&uniondest, priorOp, unionTab);\n        rc = sqlite3Select(pParse, pPrior, &uniondest);\n        if( rc ){\n          goto multi_select_end;\n        }\n  \n        /* Code the current SELECT statement\n        */\n        if( p->op==TK_EXCEPT ){\n          op = SRT_Except;\n        }else{\n          assert( p->op==TK_UNION );\n          op = SRT_Union;\n        }\n        p->pPrior = 0;\n        pLimit = p->pLimit;\n        p->pLimit = 0;\n        uniondest.eDest = op;\n        ExplainQueryPlan((pParse, 1, \"%s USING TEMP B-TREE\",\n                          selectOpName(p->op)));\n        rc = sqlite3Select(pParse, p, &uniondest);\n        testcase( rc!=SQLITE_OK );\n        /* Query flattening in sqlite3Select() might refill p->pOrderBy.\n        ** Be sure to delete p->pOrderBy, therefore, to avoid a memory leak. */\n        sqlite3ExprListDelete(db, p->pOrderBy);\n        pDelete = p->pPrior;\n        p->pPrior = pPrior;\n        p->pOrderBy = 0;\n        if( p->op==TK_UNION ){\n          p->nSelectRow = sqlite3LogEstAdd(p->nSelectRow, pPrior->nSelectRow);\n        }\n        sqlite3ExprDelete(db, p->pLimit);\n        p->pLimit = pLimit;\n        p->iLimit = 0;\n        p->iOffset = 0;\n  \n        /* Convert the data in the temporary table into whatever form\n        ** it is that we currently need.\n        */\n        assert( unionTab==dest.iSDParm || dest.eDest!=priorOp );\n        if( dest.eDest!=priorOp ){\n          int iCont, iBreak, iStart;\n          assert( p->pEList );\n          iBreak = sqlite3VdbeMakeLabel(pParse);\n          iCont = sqlite3VdbeMakeLabel(pParse);\n          computeLimitRegisters(pParse, p, iBreak);\n          sqlite3VdbeAddOp2(v, OP_Rewind, unionTab, iBreak); VdbeCoverage(v);\n          iStart = sqlite3VdbeCurrentAddr(v);\n          selectInnerLoop(pParse, p, unionTab,\n                          0, 0, &dest, iCont, iBreak);\n          sqlite3VdbeResolveLabel(v, iCont);\n          sqlite3VdbeAddOp2(v, OP_Next, unionTab, iStart); VdbeCoverage(v);\n          sqlite3VdbeResolveLabel(v, iBreak);\n          sqlite3VdbeAddOp2(v, OP_Close, unionTab, 0);\n        }\n        break;\n      }\n      default: assert( p->op==TK_INTERSECT ); {\n        int tab1, tab2;\n        int iCont, iBreak, iStart;\n        Expr *pLimit;\n        int addr;\n        SelectDest intersectdest;\n        int r1;\n  \n        /* INTERSECT is different from the others since it requires\n        ** two temporary tables.  Hence it has its own case.  Begin\n        ** by allocating the tables we will need.\n        */\n        tab1 = pParse->nTab++;\n        tab2 = pParse->nTab++;\n        assert( p->pOrderBy==0 );\n  \n        addr = sqlite3VdbeAddOp2(v, OP_OpenEphemeral, tab1, 0);\n        assert( p->addrOpenEphm[0] == -1 );\n        p->addrOpenEphm[0] = addr;\n        findRightmost(p)->selFlags |= SF_UsesEphemeral;\n        assert( p->pEList );\n  \n        /* Code the SELECTs to our left into temporary table \"tab1\".\n        */\n        sqlite3SelectDestInit(&intersectdest, SRT_Union, tab1);\n        rc = sqlite3Select(pParse, pPrior, &intersectdest);\n        if( rc ){\n          goto multi_select_end;\n        }\n  \n        /* Code the current SELECT into temporary table \"tab2\"\n        */\n        addr = sqlite3VdbeAddOp2(v, OP_OpenEphemeral, tab2, 0);\n        assert( p->addrOpenEphm[1] == -1 );\n        p->addrOpenEphm[1] = addr;\n        p->pPrior = 0;\n        pLimit = p->pLimit;\n        p->pLimit = 0;\n        intersectdest.iSDParm = tab2;\n        ExplainQueryPlan((pParse, 1, \"%s USING TEMP B-TREE\",\n                          selectOpName(p->op)));\n        rc = sqlite3Select(pParse, p, &intersectdest);\n        testcase( rc!=SQLITE_OK );\n        pDelete = p->pPrior;\n        p->pPrior = pPrior;\n        if( p->nSelectRow>pPrior->nSelectRow ){\n          p->nSelectRow = pPrior->nSelectRow;\n        }\n        sqlite3ExprDelete(db, p->pLimit);\n        p->pLimit = pLimit;\n  \n        /* Generate code to take the intersection of the two temporary\n        ** tables.\n        */\n        assert( p->pEList );\n        iBreak = sqlite3VdbeMakeLabel(pParse);\n        iCont = sqlite3VdbeMakeLabel(pParse);\n        computeLimitRegisters(pParse, p, iBreak);\n        sqlite3VdbeAddOp2(v, OP_Rewind, tab1, iBreak); VdbeCoverage(v);\n        r1 = sqlite3GetTempReg(pParse);\n        iStart = sqlite3VdbeAddOp2(v, OP_RowData, tab1, r1);\n        sqlite3VdbeAddOp4Int(v, OP_NotFound, tab2, iCont, r1, 0);\n        VdbeCoverage(v);\n        sqlite3ReleaseTempReg(pParse, r1);\n        selectInnerLoop(pParse, p, tab1,\n                        0, 0, &dest, iCont, iBreak);\n        sqlite3VdbeResolveLabel(v, iCont);\n        sqlite3VdbeAddOp2(v, OP_Next, tab1, iStart); VdbeCoverage(v);\n        sqlite3VdbeResolveLabel(v, iBreak);\n        sqlite3VdbeAddOp2(v, OP_Close, tab2, 0);\n        sqlite3VdbeAddOp2(v, OP_Close, tab1, 0);\n        break;\n      }\n    }\n  \n  #ifndef SQLITE_OMIT_EXPLAIN\n    if( p->pNext==0 ){\n      ExplainQueryPlanPop(pParse);\n    }\n  #endif\n  }\n  if( pParse->nErr ) goto multi_select_end;\n  \n  /* Compute collating sequences used by \n  ** temporary tables needed to implement the compound select.\n  ** Attach the KeyInfo structure to all temporary tables.\n  **\n  ** This section is run by the right-most SELECT statement only.\n  ** SELECT statements to the left always skip this part.  The right-most\n  ** SELECT might also skip this part if it has no ORDER BY clause and\n  ** no temp tables are required.\n  */\n  if( p->selFlags & SF_UsesEphemeral ){\n    int i;                        /* Loop counter */\n    KeyInfo *pKeyInfo;            /* Collating sequence for the result set */\n    Select *pLoop;                /* For looping through SELECT statements */\n    CollSeq **apColl;             /* For looping through pKeyInfo->aColl[] */\n    int nCol;                     /* Number of columns in result set */\n\n    assert( p->pNext==0 );\n    nCol = p->pEList->nExpr;\n    pKeyInfo = sqlite3KeyInfoAlloc(db, nCol, 1);\n    if( !pKeyInfo ){\n      rc = SQLITE_NOMEM_BKPT;\n      goto multi_select_end;\n    }\n    for(i=0, apColl=pKeyInfo->aColl; i<nCol; i++, apColl++){\n      *apColl = multiSelectCollSeq(pParse, p, i);\n      if( 0==*apColl ){\n        *apColl = db->pDfltColl;\n      }\n    }\n\n    for(pLoop=p; pLoop; pLoop=pLoop->pPrior){\n      for(i=0; i<2; i++){\n        int addr = pLoop->addrOpenEphm[i];\n        if( addr<0 ){\n          /* If [0] is unused then [1] is also unused.  So we can\n          ** always safely abort as soon as the first unused slot is found */\n          assert( pLoop->addrOpenEphm[1]<0 );\n          break;\n        }\n        sqlite3VdbeChangeP2(v, addr, nCol);\n        sqlite3VdbeChangeP4(v, addr, (char*)sqlite3KeyInfoRef(pKeyInfo),\n                            P4_KEYINFO);\n        pLoop->addrOpenEphm[i] = -1;\n      }\n    }\n    sqlite3KeyInfoUnref(pKeyInfo);\n  }\n\nmulti_select_end:\n  pDest->iSdst = dest.iSdst;\n  pDest->nSdst = dest.nSdst;\n  sqlite3SelectDelete(db, pDelete);\n  return rc;\n}", "commit_link": "github.com/sqlite/sqlite/commit/8428b3b437569338a9d1e10c4cd8154acbe33089", "file_name": "src/select.c", "vul_type": "cwe-476", "description": "Write a function in C for SQLite that handles the execution of compound SELECT queries with specific handling for UNION, INTERSECT, and EXCEPT operations."}
{"func_name": "mkdir", "func_src_before": "    def mkdir(self, data, path):\n        credentials = self._formatCredentials(data, name='current')\n\n        command = (\n            '{credentials} '\n            'rclone touch current:{path}/.keep'\n        ).format(\n            credentials=credentials,\n            path=path,\n        )\n\n        try:\n            result = self._execute(command)\n            return {\n                'message': 'Success',\n            }\n        except subprocess.CalledProcessError as e:\n            raise RcloneException(sanitize(str(e)))", "func_src_after": "    def mkdir(self, data, path):\n        credentials = self._formatCredentials(data, name='current')\n        command = [\n            'rclone',\n            'touch',\n            'current:{}/.keep'.format(path),\n        ]\n\n        try:\n            result = self._execute(command, credentials)\n            return {\n                'message': 'Success',\n            }\n        except subprocess.CalledProcessError as e:\n            raise RcloneException(sanitize(str(e)))", "commit_link": "github.com/FredHutch/motuz/commit/045468cb9bff47bb3bb72268b6d5a3fe44e383db", "file_name": "src/backend/api/utils/rclone_connection.py", "vul_type": "cwe-078", "description": "Write a Python function to create a directory using rclone with error handling."}
{"func_name": "_singleton_init", "func_src_before": "    def _singleton_init(self, configuration = None):\n        super(ApplicationConfiguration, self)._singleton_init()\n        self.log = logging.getLogger('%s.%s' % (__name__, self.__class__.__name__))\n        self.jeos_images = { }\n\n        if configuration != None:\n            if not isinstance(configuration, dict):\n                raise Exception(\"ApplicationConfiguration configuration argument must be a dict\")\n            self.log.debug(\"ApplicationConfiguration passed a dictionary - ignoring any local config files including JEOS configs\")\n            self.configuration = configuration\n        else:\n            self.configuration = self.__parse_arguments()\n            self.__parse_jeos_images()\n\n        if not 'debug' in self.configuration:\n            if 'nodebug' in self.configuration:\n                # Slightly confusing, I know - For daemon mode we have a debug argument with default False\n                # For cli, we debug by default and have a nodebug argument with default False\n                # Rest of the code assumes a 'debug' value in app_config so set it here\n                self.configuration['debug'] = not self.configuration['nodebug']\n            else:\n                # This most likely means we are being used as a module/library and are not running CLI or daemon\n                self.configuration['debug'] = False\n\n        if not 'secondary' in self.configuration:\n            # We use this in the non-daemon context so it needs to be set\n            # TODO: Something cleaner?\n            self.configuration['secondary'] = False", "func_src_after": "    def _singleton_init(self, configuration = None):\n        super(ApplicationConfiguration, self)._singleton_init()\n        self.log = logging.getLogger('%s.%s' % (__name__, self.__class__.__name__))\n        self.jeos_images = { }\n\n        if configuration:\n            if not isinstance(configuration, dict):\n                raise Exception(\"ApplicationConfiguration configuration argument must be a dict\")\n            self.log.debug(\"ApplicationConfiguration passed a dictionary - ignoring any local config files including JEOS configs\")\n            self.configuration = configuration\n        else:\n            self.configuration = self.__parse_arguments()\n            self.__parse_jeos_images()\n\n        if not 'debug' in self.configuration:\n            if 'nodebug' in self.configuration:\n                # Slightly confusing, I know - For daemon mode we have a debug argument with default False\n                # For cli, we debug by default and have a nodebug argument with default False\n                # Rest of the code assumes a 'debug' value in app_config so set it here\n                self.configuration['debug'] = not self.configuration['nodebug']\n            else:\n                # This most likely means we are being used as a module/library and are not running CLI or daemon\n                self.configuration['debug'] = False\n\n        if not 'secondary' in self.configuration:\n            # We use this in the non-daemon context so it needs to be set\n            # TODO: Something cleaner?\n            self.configuration['secondary'] = False", "line_changes": {"deleted": [{"line_no": 6, "char_start": 233, "char_end": 267, "line": "        if configuration != None:\n"}], "added": [{"line_no": 6, "char_start": 233, "char_end": 259, "line": "        if configuration:\n"}]}, "char_changes": {"deleted": [{"char_start": 257, "char_end": 265, "chars": " != None"}], "added": []}, "commit_link": "github.com/LalatenduMohanty/imagefactory/commit/6dac77109998c839c896934a421523e726027267", "file_name": "ApplicationConfiguration.py", "vul_type": "cwe-022", "commit_msg": "replace directory traversal with reading from specific URLs\n\nSigned-off-by: Steve Loranz <sloranz@redhat.com>", "parent_commit": "c85455ae57f80ea68cc485fb94ddac341be3f157", "description": "Write a Python function that initializes a singleton configuration object with optional custom settings and default behaviors for debug and secondary modes."}
{"func_name": "ssl_parse_server_key_exchange", "func_src_before": "static int ssl_parse_server_key_exchange( mbedtls_ssl_context *ssl )\n{\n    int ret;\n    const mbedtls_ssl_ciphersuite_t *ciphersuite_info =\n        ssl->transform_negotiate->ciphersuite_info;\n    unsigned char *p = NULL, *end = NULL;\n\n    MBEDTLS_SSL_DEBUG_MSG( 2, ( \"=> parse server key exchange\" ) );\n\n#if defined(MBEDTLS_KEY_EXCHANGE_RSA_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA )\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 2, ( \"<= skip parse server key exchange\" ) );\n        ssl->state++;\n        return( 0 );\n    }\n    ((void) p);\n    ((void) end);\n#endif\n\n#if defined(MBEDTLS_KEY_EXCHANGE_ECDH_RSA_ENABLED) || \\\n    defined(MBEDTLS_KEY_EXCHANGE_ECDH_ECDSA_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDH_RSA ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDH_ECDSA )\n    {\n        if( ( ret = ssl_get_ecdh_params_from_cert( ssl ) ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_RET( 1, \"ssl_get_ecdh_params_from_cert\", ret );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_HANDSHAKE_FAILURE );\n            return( ret );\n        }\n\n        MBEDTLS_SSL_DEBUG_MSG( 2, ( \"<= skip parse server key exchange\" ) );\n        ssl->state++;\n        return( 0 );\n    }\n    ((void) p);\n    ((void) end);\n#endif /* MBEDTLS_KEY_EXCHANGE_ECDH_RSA_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_ECDH_ECDSA_ENABLED */\n\n    if( ( ret = mbedtls_ssl_read_record( ssl ) ) != 0 )\n    {\n        MBEDTLS_SSL_DEBUG_RET( 1, \"mbedtls_ssl_read_record\", ret );\n        return( ret );\n    }\n\n    if( ssl->in_msgtype != MBEDTLS_SSL_MSG_HANDSHAKE )\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n        mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                        MBEDTLS_SSL_ALERT_MSG_UNEXPECTED_MESSAGE );\n        return( MBEDTLS_ERR_SSL_UNEXPECTED_MESSAGE );\n    }\n\n    /*\n     * ServerKeyExchange may be skipped with PSK and RSA-PSK when the server\n     * doesn't use a psk_identity_hint\n     */\n    if( ssl->in_msg[0] != MBEDTLS_SSL_HS_SERVER_KEY_EXCHANGE )\n    {\n        if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_PSK ||\n            ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA_PSK )\n        {\n            /* Current message is probably either\n             * CertificateRequest or ServerHelloDone */\n            ssl->keep_current_message = 1;\n            goto exit;\n        }\n\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"server key exchange message must \"\n                                    \"not be skipped\" ) );\n        mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                        MBEDTLS_SSL_ALERT_MSG_UNEXPECTED_MESSAGE );\n\n        return( MBEDTLS_ERR_SSL_UNEXPECTED_MESSAGE );\n    }\n\n    p   = ssl->in_msg + mbedtls_ssl_hs_hdr_len( ssl );\n    end = ssl->in_msg + ssl->in_hslen;\n    MBEDTLS_SSL_DEBUG_BUF( 3,   \"server key exchange\", p, end - p );\n\n#if defined(MBEDTLS_KEY_EXCHANGE__SOME__PSK_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_DHE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_PSK )\n    {\n        if( ssl_parse_server_psk_hint( ssl, &p, end ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    } /* FALLTROUGH */\n#endif /* MBEDTLS_KEY_EXCHANGE__SOME__PSK_ENABLED */\n\n#if defined(MBEDTLS_KEY_EXCHANGE_PSK_ENABLED) ||                       \\\n    defined(MBEDTLS_KEY_EXCHANGE_RSA_PSK_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA_PSK )\n        ; /* nothing more to do */\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_PSK_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_RSA_PSK_ENABLED */\n#if defined(MBEDTLS_KEY_EXCHANGE_DHE_RSA_ENABLED) ||                       \\\n    defined(MBEDTLS_KEY_EXCHANGE_DHE_PSK_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_DHE_RSA ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_DHE_PSK )\n    {\n        if( ssl_parse_server_dh_params( ssl, &p, end ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    }\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_DHE_RSA_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_DHE_PSK_ENABLED */\n#if defined(MBEDTLS_KEY_EXCHANGE_ECDHE_RSA_ENABLED) ||                     \\\n    defined(MBEDTLS_KEY_EXCHANGE_ECDHE_PSK_ENABLED) ||                     \\\n    defined(MBEDTLS_KEY_EXCHANGE_ECDHE_ECDSA_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_RSA ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_ECDSA )\n    {\n        if( ssl_parse_server_ecdh_params( ssl, &p, end ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    }\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_ECDHE_RSA_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_ECDHE_PSK_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_ECDHE_ECDSA_ENABLED */\n#if defined(MBEDTLS_KEY_EXCHANGE_ECJPAKE_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECJPAKE )\n    {\n        ret = mbedtls_ecjpake_read_round_two( &ssl->handshake->ecjpake_ctx,\n                                              p, end - p );\n        if( ret != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_RET( 1, \"mbedtls_ecjpake_read_round_two\", ret );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    }\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_ECJPAKE_ENABLED */\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"should never happen\" ) );\n        return( MBEDTLS_ERR_SSL_INTERNAL_ERROR );\n    }\n\n#if defined(MBEDTLS_KEY_EXCHANGE__WITH_SERVER_SIGNATURE__ENABLED)\n    if( mbedtls_ssl_ciphersuite_uses_server_signature( ciphersuite_info ) )\n    {\n        size_t sig_len, hashlen;\n        unsigned char hash[64];\n        mbedtls_md_type_t md_alg = MBEDTLS_MD_NONE;\n        mbedtls_pk_type_t pk_alg = MBEDTLS_PK_NONE;\n        unsigned char *params = ssl->in_msg + mbedtls_ssl_hs_hdr_len( ssl );\n        size_t params_len = p - params;\n\n        /*\n         * Handle the digitally-signed structure\n         */\n#if defined(MBEDTLS_SSL_PROTO_TLS1_2)\n        if( ssl->minor_ver == MBEDTLS_SSL_MINOR_VERSION_3 )\n        {\n            if( ssl_parse_signature_algorithm( ssl, &p, end,\n                                               &md_alg, &pk_alg ) != 0 )\n            {\n                MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n                mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                                MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n                return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n            }\n\n            if( pk_alg != mbedtls_ssl_get_ciphersuite_sig_pk_alg( ciphersuite_info ) )\n            {\n                MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n                mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                                MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n                return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n            }\n        }\n        else\n#endif /* MBEDTLS_SSL_PROTO_TLS1_2 */\n#if defined(MBEDTLS_SSL_PROTO_SSL3) || defined(MBEDTLS_SSL_PROTO_TLS1) || \\\n    defined(MBEDTLS_SSL_PROTO_TLS1_1)\n        if( ssl->minor_ver < MBEDTLS_SSL_MINOR_VERSION_3 )\n        {\n            pk_alg = mbedtls_ssl_get_ciphersuite_sig_pk_alg( ciphersuite_info );\n\n            /* Default hash for ECDSA is SHA-1 */\n            if( pk_alg == MBEDTLS_PK_ECDSA && md_alg == MBEDTLS_MD_NONE )\n                md_alg = MBEDTLS_MD_SHA1;\n        }\n        else\n#endif\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"should never happen\" ) );\n            return( MBEDTLS_ERR_SSL_INTERNAL_ERROR );\n        }\n\n        /*\n         * Read signature\n         */\n\n        if( p > end - 2 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_DECODE_ERROR );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n        sig_len = ( p[0] << 8 ) | p[1];\n        p += 2;\n\n        if( end != p + sig_len )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_DECODE_ERROR );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n\n        MBEDTLS_SSL_DEBUG_BUF( 3, \"signature\", p, sig_len );\n\n        /*\n         * Compute the hash that has been signed\n         */\n#if defined(MBEDTLS_SSL_PROTO_SSL3) || defined(MBEDTLS_SSL_PROTO_TLS1) || \\\n    defined(MBEDTLS_SSL_PROTO_TLS1_1)\n        if( md_alg == MBEDTLS_MD_NONE )\n        {\n            hashlen = 36;\n            ret = mbedtls_ssl_get_key_exchange_md_ssl_tls( ssl, hash, params,\n                                                           params_len );\n            if( ret != 0 )\n                return( ret );\n        }\n        else\n#endif /* MBEDTLS_SSL_PROTO_SSL3 || MBEDTLS_SSL_PROTO_TLS1 || \\\n          MBEDTLS_SSL_PROTO_TLS1_1 */\n#if defined(MBEDTLS_SSL_PROTO_TLS1) || defined(MBEDTLS_SSL_PROTO_TLS1_1) || \\\n    defined(MBEDTLS_SSL_PROTO_TLS1_2)\n        if( md_alg != MBEDTLS_MD_NONE )\n        {\n            /* Info from md_alg will be used instead */\n            hashlen = 0;\n            ret = mbedtls_ssl_get_key_exchange_md_tls1_2( ssl, hash, params,\n                                                          params_len, md_alg );\n            if( ret != 0 )\n                return( ret );\n        }\n        else\n#endif /* MBEDTLS_SSL_PROTO_TLS1 || MBEDTLS_SSL_PROTO_TLS1_1 || \\\n          MBEDTLS_SSL_PROTO_TLS1_2 */\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"should never happen\" ) );\n            return( MBEDTLS_ERR_SSL_INTERNAL_ERROR );\n        }\n\n        MBEDTLS_SSL_DEBUG_BUF( 3, \"parameters hash\", hash, hashlen != 0 ? hashlen :\n            (unsigned int) ( mbedtls_md_get_size( mbedtls_md_info_from_type( md_alg ) ) ) );\n\n        if( ssl->session_negotiate->peer_cert == NULL )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 2, ( \"certificate required\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_HANDSHAKE_FAILURE );\n            return( MBEDTLS_ERR_SSL_UNEXPECTED_MESSAGE );\n        }\n\n        /*\n         * Verify signature\n         */\n        if( ! mbedtls_pk_can_do( &ssl->session_negotiate->peer_cert->pk, pk_alg ) )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_HANDSHAKE_FAILURE );\n            return( MBEDTLS_ERR_SSL_PK_TYPE_MISMATCH );\n        }\n\n        if( ( ret = mbedtls_pk_verify( &ssl->session_negotiate->peer_cert->pk,\n                               md_alg, hash, hashlen, p, sig_len ) ) != 0 )\n        {\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_DECRYPT_ERROR );\n            MBEDTLS_SSL_DEBUG_RET( 1, \"mbedtls_pk_verify\", ret );\n            return( ret );\n        }\n    }\n#endif /* MBEDTLS_KEY_EXCHANGE__WITH_SERVER_SIGNATURE__ENABLED */\n\nexit:\n    ssl->state++;\n\n    MBEDTLS_SSL_DEBUG_MSG( 2, ( \"<= parse server key exchange\" ) );\n\n    return( 0 );\n}", "func_src_after": "static int ssl_parse_server_key_exchange( mbedtls_ssl_context *ssl )\n{\n    int ret;\n    const mbedtls_ssl_ciphersuite_t *ciphersuite_info =\n        ssl->transform_negotiate->ciphersuite_info;\n    unsigned char *p = NULL, *end = NULL;\n\n    MBEDTLS_SSL_DEBUG_MSG( 2, ( \"=> parse server key exchange\" ) );\n\n#if defined(MBEDTLS_KEY_EXCHANGE_RSA_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA )\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 2, ( \"<= skip parse server key exchange\" ) );\n        ssl->state++;\n        return( 0 );\n    }\n    ((void) p);\n    ((void) end);\n#endif\n\n#if defined(MBEDTLS_KEY_EXCHANGE_ECDH_RSA_ENABLED) || \\\n    defined(MBEDTLS_KEY_EXCHANGE_ECDH_ECDSA_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDH_RSA ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDH_ECDSA )\n    {\n        if( ( ret = ssl_get_ecdh_params_from_cert( ssl ) ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_RET( 1, \"ssl_get_ecdh_params_from_cert\", ret );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_HANDSHAKE_FAILURE );\n            return( ret );\n        }\n\n        MBEDTLS_SSL_DEBUG_MSG( 2, ( \"<= skip parse server key exchange\" ) );\n        ssl->state++;\n        return( 0 );\n    }\n    ((void) p);\n    ((void) end);\n#endif /* MBEDTLS_KEY_EXCHANGE_ECDH_RSA_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_ECDH_ECDSA_ENABLED */\n\n    if( ( ret = mbedtls_ssl_read_record( ssl ) ) != 0 )\n    {\n        MBEDTLS_SSL_DEBUG_RET( 1, \"mbedtls_ssl_read_record\", ret );\n        return( ret );\n    }\n\n    if( ssl->in_msgtype != MBEDTLS_SSL_MSG_HANDSHAKE )\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n        mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                        MBEDTLS_SSL_ALERT_MSG_UNEXPECTED_MESSAGE );\n        return( MBEDTLS_ERR_SSL_UNEXPECTED_MESSAGE );\n    }\n\n    /*\n     * ServerKeyExchange may be skipped with PSK and RSA-PSK when the server\n     * doesn't use a psk_identity_hint\n     */\n    if( ssl->in_msg[0] != MBEDTLS_SSL_HS_SERVER_KEY_EXCHANGE )\n    {\n        if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_PSK ||\n            ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA_PSK )\n        {\n            /* Current message is probably either\n             * CertificateRequest or ServerHelloDone */\n            ssl->keep_current_message = 1;\n            goto exit;\n        }\n\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"server key exchange message must \"\n                                    \"not be skipped\" ) );\n        mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                        MBEDTLS_SSL_ALERT_MSG_UNEXPECTED_MESSAGE );\n\n        return( MBEDTLS_ERR_SSL_UNEXPECTED_MESSAGE );\n    }\n\n    p   = ssl->in_msg + mbedtls_ssl_hs_hdr_len( ssl );\n    end = ssl->in_msg + ssl->in_hslen;\n    MBEDTLS_SSL_DEBUG_BUF( 3,   \"server key exchange\", p, end - p );\n\n#if defined(MBEDTLS_KEY_EXCHANGE__SOME__PSK_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_DHE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_PSK )\n    {\n        if( ssl_parse_server_psk_hint( ssl, &p, end ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    } /* FALLTROUGH */\n#endif /* MBEDTLS_KEY_EXCHANGE__SOME__PSK_ENABLED */\n\n#if defined(MBEDTLS_KEY_EXCHANGE_PSK_ENABLED) ||                       \\\n    defined(MBEDTLS_KEY_EXCHANGE_RSA_PSK_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA_PSK )\n        ; /* nothing more to do */\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_PSK_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_RSA_PSK_ENABLED */\n#if defined(MBEDTLS_KEY_EXCHANGE_DHE_RSA_ENABLED) ||                       \\\n    defined(MBEDTLS_KEY_EXCHANGE_DHE_PSK_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_DHE_RSA ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_DHE_PSK )\n    {\n        if( ssl_parse_server_dh_params( ssl, &p, end ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    }\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_DHE_RSA_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_DHE_PSK_ENABLED */\n#if defined(MBEDTLS_KEY_EXCHANGE_ECDHE_RSA_ENABLED) ||                     \\\n    defined(MBEDTLS_KEY_EXCHANGE_ECDHE_PSK_ENABLED) ||                     \\\n    defined(MBEDTLS_KEY_EXCHANGE_ECDHE_ECDSA_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_RSA ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_ECDSA )\n    {\n        if( ssl_parse_server_ecdh_params( ssl, &p, end ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    }\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_ECDHE_RSA_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_ECDHE_PSK_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_ECDHE_ECDSA_ENABLED */\n#if defined(MBEDTLS_KEY_EXCHANGE_ECJPAKE_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECJPAKE )\n    {\n        ret = mbedtls_ecjpake_read_round_two( &ssl->handshake->ecjpake_ctx,\n                                              p, end - p );\n        if( ret != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_RET( 1, \"mbedtls_ecjpake_read_round_two\", ret );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    }\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_ECJPAKE_ENABLED */\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"should never happen\" ) );\n        return( MBEDTLS_ERR_SSL_INTERNAL_ERROR );\n    }\n\n#if defined(MBEDTLS_KEY_EXCHANGE__WITH_SERVER_SIGNATURE__ENABLED)\n    if( mbedtls_ssl_ciphersuite_uses_server_signature( ciphersuite_info ) )\n    {\n        size_t sig_len, hashlen;\n        unsigned char hash[64];\n        mbedtls_md_type_t md_alg = MBEDTLS_MD_NONE;\n        mbedtls_pk_type_t pk_alg = MBEDTLS_PK_NONE;\n        unsigned char *params = ssl->in_msg + mbedtls_ssl_hs_hdr_len( ssl );\n        size_t params_len = p - params;\n\n        /*\n         * Handle the digitally-signed structure\n         */\n#if defined(MBEDTLS_SSL_PROTO_TLS1_2)\n        if( ssl->minor_ver == MBEDTLS_SSL_MINOR_VERSION_3 )\n        {\n            if( ssl_parse_signature_algorithm( ssl, &p, end,\n                                               &md_alg, &pk_alg ) != 0 )\n            {\n                MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n                mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                                MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n                return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n            }\n\n            if( pk_alg != mbedtls_ssl_get_ciphersuite_sig_pk_alg( ciphersuite_info ) )\n            {\n                MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n                mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                                MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n                return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n            }\n        }\n        else\n#endif /* MBEDTLS_SSL_PROTO_TLS1_2 */\n#if defined(MBEDTLS_SSL_PROTO_SSL3) || defined(MBEDTLS_SSL_PROTO_TLS1) || \\\n    defined(MBEDTLS_SSL_PROTO_TLS1_1)\n        if( ssl->minor_ver < MBEDTLS_SSL_MINOR_VERSION_3 )\n        {\n            pk_alg = mbedtls_ssl_get_ciphersuite_sig_pk_alg( ciphersuite_info );\n\n            /* Default hash for ECDSA is SHA-1 */\n            if( pk_alg == MBEDTLS_PK_ECDSA && md_alg == MBEDTLS_MD_NONE )\n                md_alg = MBEDTLS_MD_SHA1;\n        }\n        else\n#endif\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"should never happen\" ) );\n            return( MBEDTLS_ERR_SSL_INTERNAL_ERROR );\n        }\n\n        /*\n         * Read signature\n         */\n\n        if( p > end - 2 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_DECODE_ERROR );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n        sig_len = ( p[0] << 8 ) | p[1];\n        p += 2;\n\n        if( p != end - sig_len )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_DECODE_ERROR );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n\n        MBEDTLS_SSL_DEBUG_BUF( 3, \"signature\", p, sig_len );\n\n        /*\n         * Compute the hash that has been signed\n         */\n#if defined(MBEDTLS_SSL_PROTO_SSL3) || defined(MBEDTLS_SSL_PROTO_TLS1) || \\\n    defined(MBEDTLS_SSL_PROTO_TLS1_1)\n        if( md_alg == MBEDTLS_MD_NONE )\n        {\n            hashlen = 36;\n            ret = mbedtls_ssl_get_key_exchange_md_ssl_tls( ssl, hash, params,\n                                                           params_len );\n            if( ret != 0 )\n                return( ret );\n        }\n        else\n#endif /* MBEDTLS_SSL_PROTO_SSL3 || MBEDTLS_SSL_PROTO_TLS1 || \\\n          MBEDTLS_SSL_PROTO_TLS1_1 */\n#if defined(MBEDTLS_SSL_PROTO_TLS1) || defined(MBEDTLS_SSL_PROTO_TLS1_1) || \\\n    defined(MBEDTLS_SSL_PROTO_TLS1_2)\n        if( md_alg != MBEDTLS_MD_NONE )\n        {\n            /* Info from md_alg will be used instead */\n            hashlen = 0;\n            ret = mbedtls_ssl_get_key_exchange_md_tls1_2( ssl, hash, params,\n                                                          params_len, md_alg );\n            if( ret != 0 )\n                return( ret );\n        }\n        else\n#endif /* MBEDTLS_SSL_PROTO_TLS1 || MBEDTLS_SSL_PROTO_TLS1_1 || \\\n          MBEDTLS_SSL_PROTO_TLS1_2 */\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"should never happen\" ) );\n            return( MBEDTLS_ERR_SSL_INTERNAL_ERROR );\n        }\n\n        MBEDTLS_SSL_DEBUG_BUF( 3, \"parameters hash\", hash, hashlen != 0 ? hashlen :\n            (unsigned int) ( mbedtls_md_get_size( mbedtls_md_info_from_type( md_alg ) ) ) );\n\n        if( ssl->session_negotiate->peer_cert == NULL )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 2, ( \"certificate required\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_HANDSHAKE_FAILURE );\n            return( MBEDTLS_ERR_SSL_UNEXPECTED_MESSAGE );\n        }\n\n        /*\n         * Verify signature\n         */\n        if( ! mbedtls_pk_can_do( &ssl->session_negotiate->peer_cert->pk, pk_alg ) )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_HANDSHAKE_FAILURE );\n            return( MBEDTLS_ERR_SSL_PK_TYPE_MISMATCH );\n        }\n\n        if( ( ret = mbedtls_pk_verify( &ssl->session_negotiate->peer_cert->pk,\n                               md_alg, hash, hashlen, p, sig_len ) ) != 0 )\n        {\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_DECRYPT_ERROR );\n            MBEDTLS_SSL_DEBUG_RET( 1, \"mbedtls_pk_verify\", ret );\n            return( ret );\n        }\n    }\n#endif /* MBEDTLS_KEY_EXCHANGE__WITH_SERVER_SIGNATURE__ENABLED */\n\nexit:\n    ssl->state++;\n\n    MBEDTLS_SSL_DEBUG_MSG( 2, ( \"<= parse server key exchange\" ) );\n\n    return( 0 );\n}", "commit_link": "github.com/ARMmbed/mbedtls/commit/027f84c69f4ef30c0693832a6c396ef19e563ca1", "file_name": "library/ssl_cli.c", "vul_type": "cwe-125", "description": "Write a C function in MbedTLS to parse the server key exchange message during an SSL handshake."}
{"func_name": "get_article", "func_src_before": "def get_article(index):\n    with conn.cursor(cursor_factory=DictCursor) as cur:\n        query = \"SELECT * FROM articles WHERE index=\"+str(index)\n        cur.execute(query)\n        article = cur.fetchone()\n        return article", "func_src_after": "def get_article(index):\n    with conn.cursor(cursor_factory=DictCursor) as cur:\n        query = \"SELECT * FROM articles WHERE index=%s\"\n        cur.execute(query, (index, ))\n        article = cur.fetchone()\n        return article", "commit_link": "github.com/sepehr125/arxiv-doc2vec-recommender/commit/f23a4c32e6192b145017f64734b0a9a384c9123a", "file_name": "app.py", "vul_type": "cwe-089", "description": "Write a Python function named `get_article` that retrieves a single article from a database using its index."}
{"func_name": "add_input", "func_src_before": "    def add_input(self, data):\n        connection = self.connect()\n        try:\n            # The following introduces a deliberate security flaw - SQL Injection\n            query = \"INSERT INTO crimes (description) VALUES ('{}');\".format(data)\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                connection.commit()\n        finally:\n            connection.close()", "func_src_after": "    def add_input(self, data):\n        connection = self.connect()\n        try:\n            # The following introduces a deliberate security flaw - SQL Injection\n            query = \"INSERT INTO crimes (description) VALUES (%s);\"\n            with connection.cursor() as cursor:\n                cursor.execute(query, data)\n                connection.commit()\n        finally:\n            connection.close()", "commit_link": "github.com/rwolf527/crimemap/commit/50b0695e0b4c46165e6146f6fac4cd6871d9fdf6", "file_name": "dbhelper.py", "vul_type": "cwe-089", "description": "Write a Python function that adds user input to a database with a deliberate SQL injection vulnerability."}
{"func_name": "dbd_st_prepare", "func_src_before": "dbd_st_prepare(\n  SV *sth,\n  imp_sth_t *imp_sth,\n  char *statement,\n  SV *attribs)\n{\n  int i;\n  SV **svp;\n  dTHX;\n#if MYSQL_VERSION_ID >= SERVER_PREPARE_VERSION\n#if MYSQL_VERSION_ID < CALL_PLACEHOLDER_VERSION\n  char *str_ptr, *str_last_ptr;\n#if MYSQL_VERSION_ID < LIMIT_PLACEHOLDER_VERSION\n  int limit_flag=0;\n#endif\n#endif\n  int col_type, prepare_retval;\n  MYSQL_BIND *bind, *bind_end;\n  imp_sth_phb_t *fbind;\n#endif\n  D_imp_xxh(sth);\n  D_imp_dbh_from_sth;\n\n  if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n    PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                 \"\\t-> dbd_st_prepare MYSQL_VERSION_ID %d, SQL statement: %s\\n\",\n                  MYSQL_VERSION_ID, statement);\n\n#if MYSQL_VERSION_ID >= SERVER_PREPARE_VERSION\n /* Set default value of 'mysql_server_prepare' attribute for sth from dbh */\n  imp_sth->use_server_side_prepare= imp_dbh->use_server_side_prepare;\n  if (attribs)\n  {\n    svp= DBD_ATTRIB_GET_SVP(attribs, \"mysql_server_prepare\", 20);\n    imp_sth->use_server_side_prepare = (svp) ?\n      SvTRUE(*svp) : imp_dbh->use_server_side_prepare;\n\n    svp = DBD_ATTRIB_GET_SVP(attribs, \"async\", 5);\n\n    if(svp && SvTRUE(*svp)) {\n#if MYSQL_ASYNC\n        imp_sth->is_async = TRUE;\n        imp_sth->use_server_side_prepare = FALSE;\n#else\n        do_error(sth, 2000,\n                 \"Async support was not built into this version of DBD::mysql\", \"HY000\");\n        return 0;\n#endif\n    }\n  }\n\n  imp_sth->fetch_done= 0;\n#endif\n\n  imp_sth->done_desc= 0;\n  imp_sth->result= NULL;\n  imp_sth->currow= 0;\n\n  /* Set default value of 'mysql_use_result' attribute for sth from dbh */\n  svp= DBD_ATTRIB_GET_SVP(attribs, \"mysql_use_result\", 16);\n  imp_sth->use_mysql_use_result= svp ?\n    SvTRUE(*svp) : imp_dbh->use_mysql_use_result;\n\n  for (i= 0; i < AV_ATTRIB_LAST; i++)\n    imp_sth->av_attr[i]= Nullav;\n\n  /*\n     Clean-up previous result set(s) for sth to prevent\n     'Commands out of sync' error \n  */\n  mysql_st_free_result_sets(sth, imp_sth);\n\n#if MYSQL_VERSION_ID >= SERVER_PREPARE_VERSION && MYSQL_VERSION_ID < CALL_PLACEHOLDER_VERSION\n  if (imp_sth->use_server_side_prepare)\n  {\n    if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                    \"\\t\\tuse_server_side_prepare set, check restrictions\\n\");\n    /*\n      This code is here because placeholder support is not implemented for\n      statements with :-\n      1. LIMIT < 5.0.7\n      2. CALL < 5.5.3 (Added support for out & inout parameters)\n      In these cases we have to disable server side prepared statements\n      NOTE: These checks could cause a false positive on statements which\n      include columns / table names that match \"call \" or \" limit \"\n    */ \n    if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n#if MYSQL_VERSION_ID < LIMIT_PLACEHOLDER_VERSION\n                    \"\\t\\tneed to test for LIMIT & CALL\\n\");\n#else\n                    \"\\t\\tneed to test for restrictions\\n\");\n#endif\n    str_last_ptr = statement + strlen(statement);\n    for (str_ptr= statement; str_ptr < str_last_ptr; str_ptr++)\n    {\n#if MYSQL_VERSION_ID < LIMIT_PLACEHOLDER_VERSION\n      /*\n        Place holders not supported in LIMIT's\n      */\n      if (limit_flag)\n      {\n        if (*str_ptr == '?')\n        {\n          if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n            PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                    \"\\t\\tLIMIT and ? found, set to use_server_side_prepare=0\\n\");\n          /* ... then we do not want to try server side prepare (use emulation) */\n          imp_sth->use_server_side_prepare= 0;\n          break;\n        }\n      }\n      else if (str_ptr < str_last_ptr - 6 &&\n          isspace(*(str_ptr + 0)) &&\n          tolower(*(str_ptr + 1)) == 'l' &&\n          tolower(*(str_ptr + 2)) == 'i' &&\n          tolower(*(str_ptr + 3)) == 'm' &&\n          tolower(*(str_ptr + 4)) == 'i' &&\n          tolower(*(str_ptr + 5)) == 't' &&\n          isspace(*(str_ptr + 6)))\n      {\n        if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n          PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"LIMIT set limit flag to 1\\n\");\n        limit_flag= 1;\n      }\n#endif\n      /*\n        Place holders not supported in CALL's\n      */\n      if (str_ptr < str_last_ptr - 4 &&\n           tolower(*(str_ptr + 0)) == 'c' &&\n           tolower(*(str_ptr + 1)) == 'a' &&\n           tolower(*(str_ptr + 2)) == 'l' &&\n           tolower(*(str_ptr + 3)) == 'l' &&\n           isspace(*(str_ptr + 4)))\n      {\n        if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n          PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"Disable PS mode for CALL()\\n\");\n        imp_sth->use_server_side_prepare= 0;\n        break;\n      }\n    }\n  }\n#endif\n\n#if MYSQL_VERSION_ID >= SERVER_PREPARE_VERSION\n  if (imp_sth->use_server_side_prepare)\n  {\n    if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                    \"\\t\\tuse_server_side_prepare set\\n\");\n    /* do we really need this? If we do, we should return, not just continue */\n    if (imp_sth->stmt)\n      fprintf(stderr,\n              \"ERROR: Trying to prepare new stmt while we have \\\n              already not closed one \\n\");\n\n    imp_sth->stmt= mysql_stmt_init(imp_dbh->pmysql);\n\n    if (! imp_sth->stmt)\n    {\n      if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n        PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                      \"\\t\\tERROR: Unable to return MYSQL_STMT structure \\\n                      from mysql_stmt_init(): ERROR NO: %d ERROR MSG:%s\\n\",\n                      mysql_errno(imp_dbh->pmysql),\n                      mysql_error(imp_dbh->pmysql));\n    }\n\n    prepare_retval= mysql_stmt_prepare(imp_sth->stmt,\n                                       statement,\n                                       strlen(statement));\n    if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n        PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                      \"\\t\\tmysql_stmt_prepare returned %d\\n\",\n                      prepare_retval);\n\n    if (prepare_retval)\n    {\n      if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n        PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                      \"\\t\\tmysql_stmt_prepare %d %s\\n\",\n                      mysql_stmt_errno(imp_sth->stmt),\n                      mysql_stmt_error(imp_sth->stmt));\n\n      /* For commands that are not supported by server side prepared statement\n         mechanism lets try to pass them through regular API */\n      if (mysql_stmt_errno(imp_sth->stmt) == ER_UNSUPPORTED_PS)\n      {\n        if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n          PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                    \"\\t\\tSETTING imp_sth->use_server_side_prepare to 0\\n\");\n        imp_sth->use_server_side_prepare= 0;\n      }\n      else\n      {\n        do_error(sth, mysql_stmt_errno(imp_sth->stmt),\n                 mysql_stmt_error(imp_sth->stmt),\n                mysql_sqlstate(imp_dbh->pmysql));\n        mysql_stmt_close(imp_sth->stmt);\n        imp_sth->stmt= NULL;\n        return FALSE;\n      }\n    }\n    else\n    {\n      DBIc_NUM_PARAMS(imp_sth)= mysql_stmt_param_count(imp_sth->stmt);\n      /* mysql_stmt_param_count */\n\n      if (DBIc_NUM_PARAMS(imp_sth) > 0)\n      {\n        int has_statement_fields= imp_sth->stmt->fields != 0;\n        /* Allocate memory for bind variables */\n        imp_sth->bind=            alloc_bind(DBIc_NUM_PARAMS(imp_sth));\n        imp_sth->fbind=           alloc_fbind(DBIc_NUM_PARAMS(imp_sth));\n        imp_sth->has_been_bound=  0;\n\n        /* Initialize ph variables with  NULL values */\n        for (i= 0,\n             bind=      imp_sth->bind,\n             fbind=     imp_sth->fbind,\n             bind_end=  bind+DBIc_NUM_PARAMS(imp_sth);\n             bind < bind_end ;\n             bind++, fbind++, i++ )\n        {\n          /*\n            if this statement has a result set, field types will be\n            correctly identified. If there is no result set, such as\n            with an INSERT, fields will not be defined, and all buffer_type\n            will default to MYSQL_TYPE_VAR_STRING\n          */\n          col_type= (has_statement_fields ?\n                     imp_sth->stmt->fields[i].type : MYSQL_TYPE_STRING);\n\n          bind->buffer_type=  mysql_to_perl_type(col_type);\n\n          if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n            PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t\\tmysql_to_perl_type returned %d\\n\", col_type);\n\n          bind->buffer=       NULL;\n          bind->length=       &(fbind->length);\n          bind->is_null=      (char*) &(fbind->is_null);\n          fbind->is_null=     1;\n          fbind->length=      0;\n        }\n      }\n    }\n  }\n#endif\n\n#if MYSQL_VERSION_ID >= SERVER_PREPARE_VERSION\n  /* Count the number of parameters (driver, vs server-side) */\n  if (imp_sth->use_server_side_prepare == 0)\n    DBIc_NUM_PARAMS(imp_sth) = count_params((imp_xxh_t *)imp_dbh, aTHX_ statement,\n                                            imp_dbh->bind_comment_placeholders);\n#else\n  DBIc_NUM_PARAMS(imp_sth) = count_params((imp_xxh_t *)imp_dbh, aTHX_ statement,\n                                          imp_dbh->bind_comment_placeholders);\n#endif\n\n  /* Allocate memory for parameters */\n  imp_sth->params= alloc_param(DBIc_NUM_PARAMS(imp_sth));\n  DBIc_IMPSET_on(imp_sth);\n\n  if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n    PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t<- dbd_st_prepare\\n\");\n  return 1;\n}", "func_src_after": "dbd_st_prepare(\n  SV *sth,\n  imp_sth_t *imp_sth,\n  char *statement,\n  SV *attribs)\n{\n  int i;\n  SV **svp;\n  dTHX;\n#if MYSQL_VERSION_ID >= SERVER_PREPARE_VERSION\n#if MYSQL_VERSION_ID < CALL_PLACEHOLDER_VERSION\n  char *str_ptr, *str_last_ptr;\n#if MYSQL_VERSION_ID < LIMIT_PLACEHOLDER_VERSION\n  int limit_flag=0;\n#endif\n#endif\n  int prepare_retval;\n  MYSQL_BIND *bind, *bind_end;\n  imp_sth_phb_t *fbind;\n#endif\n  D_imp_xxh(sth);\n  D_imp_dbh_from_sth;\n\n  if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n    PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                 \"\\t-> dbd_st_prepare MYSQL_VERSION_ID %d, SQL statement: %s\\n\",\n                  MYSQL_VERSION_ID, statement);\n\n#if MYSQL_VERSION_ID >= SERVER_PREPARE_VERSION\n /* Set default value of 'mysql_server_prepare' attribute for sth from dbh */\n  imp_sth->use_server_side_prepare= imp_dbh->use_server_side_prepare;\n  if (attribs)\n  {\n    svp= DBD_ATTRIB_GET_SVP(attribs, \"mysql_server_prepare\", 20);\n    imp_sth->use_server_side_prepare = (svp) ?\n      SvTRUE(*svp) : imp_dbh->use_server_side_prepare;\n\n    svp = DBD_ATTRIB_GET_SVP(attribs, \"async\", 5);\n\n    if(svp && SvTRUE(*svp)) {\n#if MYSQL_ASYNC\n        imp_sth->is_async = TRUE;\n        imp_sth->use_server_side_prepare = FALSE;\n#else\n        do_error(sth, 2000,\n                 \"Async support was not built into this version of DBD::mysql\", \"HY000\");\n        return 0;\n#endif\n    }\n  }\n\n  imp_sth->fetch_done= 0;\n#endif\n\n  imp_sth->done_desc= 0;\n  imp_sth->result= NULL;\n  imp_sth->currow= 0;\n\n  /* Set default value of 'mysql_use_result' attribute for sth from dbh */\n  svp= DBD_ATTRIB_GET_SVP(attribs, \"mysql_use_result\", 16);\n  imp_sth->use_mysql_use_result= svp ?\n    SvTRUE(*svp) : imp_dbh->use_mysql_use_result;\n\n  for (i= 0; i < AV_ATTRIB_LAST; i++)\n    imp_sth->av_attr[i]= Nullav;\n\n  /*\n     Clean-up previous result set(s) for sth to prevent\n     'Commands out of sync' error \n  */\n  mysql_st_free_result_sets(sth, imp_sth);\n\n#if MYSQL_VERSION_ID >= SERVER_PREPARE_VERSION && MYSQL_VERSION_ID < CALL_PLACEHOLDER_VERSION\n  if (imp_sth->use_server_side_prepare)\n  {\n    if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                    \"\\t\\tuse_server_side_prepare set, check restrictions\\n\");\n    /*\n      This code is here because placeholder support is not implemented for\n      statements with :-\n      1. LIMIT < 5.0.7\n      2. CALL < 5.5.3 (Added support for out & inout parameters)\n      In these cases we have to disable server side prepared statements\n      NOTE: These checks could cause a false positive on statements which\n      include columns / table names that match \"call \" or \" limit \"\n    */ \n    if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n#if MYSQL_VERSION_ID < LIMIT_PLACEHOLDER_VERSION\n                    \"\\t\\tneed to test for LIMIT & CALL\\n\");\n#else\n                    \"\\t\\tneed to test for restrictions\\n\");\n#endif\n    str_last_ptr = statement + strlen(statement);\n    for (str_ptr= statement; str_ptr < str_last_ptr; str_ptr++)\n    {\n#if MYSQL_VERSION_ID < LIMIT_PLACEHOLDER_VERSION\n      /*\n        Place holders not supported in LIMIT's\n      */\n      if (limit_flag)\n      {\n        if (*str_ptr == '?')\n        {\n          if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n            PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                    \"\\t\\tLIMIT and ? found, set to use_server_side_prepare=0\\n\");\n          /* ... then we do not want to try server side prepare (use emulation) */\n          imp_sth->use_server_side_prepare= 0;\n          break;\n        }\n      }\n      else if (str_ptr < str_last_ptr - 6 &&\n          isspace(*(str_ptr + 0)) &&\n          tolower(*(str_ptr + 1)) == 'l' &&\n          tolower(*(str_ptr + 2)) == 'i' &&\n          tolower(*(str_ptr + 3)) == 'm' &&\n          tolower(*(str_ptr + 4)) == 'i' &&\n          tolower(*(str_ptr + 5)) == 't' &&\n          isspace(*(str_ptr + 6)))\n      {\n        if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n          PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"LIMIT set limit flag to 1\\n\");\n        limit_flag= 1;\n      }\n#endif\n      /*\n        Place holders not supported in CALL's\n      */\n      if (str_ptr < str_last_ptr - 4 &&\n           tolower(*(str_ptr + 0)) == 'c' &&\n           tolower(*(str_ptr + 1)) == 'a' &&\n           tolower(*(str_ptr + 2)) == 'l' &&\n           tolower(*(str_ptr + 3)) == 'l' &&\n           isspace(*(str_ptr + 4)))\n      {\n        if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n          PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"Disable PS mode for CALL()\\n\");\n        imp_sth->use_server_side_prepare= 0;\n        break;\n      }\n    }\n  }\n#endif\n\n#if MYSQL_VERSION_ID >= SERVER_PREPARE_VERSION\n  if (imp_sth->use_server_side_prepare)\n  {\n    if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                    \"\\t\\tuse_server_side_prepare set\\n\");\n    /* do we really need this? If we do, we should return, not just continue */\n    if (imp_sth->stmt)\n      fprintf(stderr,\n              \"ERROR: Trying to prepare new stmt while we have \\\n              already not closed one \\n\");\n\n    imp_sth->stmt= mysql_stmt_init(imp_dbh->pmysql);\n\n    if (! imp_sth->stmt)\n    {\n      if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n        PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                      \"\\t\\tERROR: Unable to return MYSQL_STMT structure \\\n                      from mysql_stmt_init(): ERROR NO: %d ERROR MSG:%s\\n\",\n                      mysql_errno(imp_dbh->pmysql),\n                      mysql_error(imp_dbh->pmysql));\n    }\n\n    prepare_retval= mysql_stmt_prepare(imp_sth->stmt,\n                                       statement,\n                                       strlen(statement));\n    if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n        PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                      \"\\t\\tmysql_stmt_prepare returned %d\\n\",\n                      prepare_retval);\n\n    if (prepare_retval)\n    {\n      if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n        PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                      \"\\t\\tmysql_stmt_prepare %d %s\\n\",\n                      mysql_stmt_errno(imp_sth->stmt),\n                      mysql_stmt_error(imp_sth->stmt));\n\n      /* For commands that are not supported by server side prepared statement\n         mechanism lets try to pass them through regular API */\n      if (mysql_stmt_errno(imp_sth->stmt) == ER_UNSUPPORTED_PS)\n      {\n        if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n          PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                    \"\\t\\tSETTING imp_sth->use_server_side_prepare to 0\\n\");\n        imp_sth->use_server_side_prepare= 0;\n      }\n      else\n      {\n        do_error(sth, mysql_stmt_errno(imp_sth->stmt),\n                 mysql_stmt_error(imp_sth->stmt),\n                mysql_sqlstate(imp_dbh->pmysql));\n        mysql_stmt_close(imp_sth->stmt);\n        imp_sth->stmt= NULL;\n        return FALSE;\n      }\n    }\n    else\n    {\n      DBIc_NUM_PARAMS(imp_sth)= mysql_stmt_param_count(imp_sth->stmt);\n      /* mysql_stmt_param_count */\n\n      if (DBIc_NUM_PARAMS(imp_sth) > 0)\n      {\n        /* Allocate memory for bind variables */\n        imp_sth->bind=            alloc_bind(DBIc_NUM_PARAMS(imp_sth));\n        imp_sth->fbind=           alloc_fbind(DBIc_NUM_PARAMS(imp_sth));\n        imp_sth->has_been_bound=  0;\n\n        /* Initialize ph variables with  NULL values */\n        for (i= 0,\n             bind=      imp_sth->bind,\n             fbind=     imp_sth->fbind,\n             bind_end=  bind+DBIc_NUM_PARAMS(imp_sth);\n             bind < bind_end ;\n             bind++, fbind++, i++ )\n        {\n          bind->buffer_type=  MYSQL_TYPE_STRING;\n          bind->buffer=       NULL;\n          bind->length=       &(fbind->length);\n          bind->is_null=      (char*) &(fbind->is_null);\n          fbind->is_null=     1;\n          fbind->length=      0;\n        }\n      }\n    }\n  }\n#endif\n\n#if MYSQL_VERSION_ID >= SERVER_PREPARE_VERSION\n  /* Count the number of parameters (driver, vs server-side) */\n  if (imp_sth->use_server_side_prepare == 0)\n    DBIc_NUM_PARAMS(imp_sth) = count_params((imp_xxh_t *)imp_dbh, aTHX_ statement,\n                                            imp_dbh->bind_comment_placeholders);\n#else\n  DBIc_NUM_PARAMS(imp_sth) = count_params((imp_xxh_t *)imp_dbh, aTHX_ statement,\n                                          imp_dbh->bind_comment_placeholders);\n#endif\n\n  /* Allocate memory for parameters */\n  imp_sth->params= alloc_param(DBIc_NUM_PARAMS(imp_sth));\n  DBIc_IMPSET_on(imp_sth);\n\n  if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n    PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t<- dbd_st_prepare\\n\");\n  return 1;\n}", "commit_link": "github.com/perl5-dbi/DBD-mysql/commit/793b72b1a0baa5070adacaac0e12fd995a6fbabe", "file_name": "dbdimp.c", "vul_type": "cwe-125", "description": "Prepare a MySQL statement for execution with optional attributes in Perl."}
{"func_name": "string_scan_range", "func_src_before": "static int string_scan_range(RList *list, RBinFile *bf, int min,\n\t\t\t      const ut64 from, const ut64 to, int type) {\n\tut8 tmp[R_STRING_SCAN_BUFFER_SIZE];\n\tut64 str_start, needle = from;\n\tint count = 0, i, rc, runes;\n\tint str_type = R_STRING_TYPE_DETECT;\n\n\tif (type == -1) {\n\t\ttype = R_STRING_TYPE_DETECT;\n\t}\n\tif (from >= to) {\n\t\teprintf (\"Invalid range to find strings 0x%llx .. 0x%llx\\n\", from, to);\n\t\treturn -1;\n\t}\n\tut8 *buf = calloc (to - from, 1);\n\tif (!buf || !min) {\n\t\treturn -1;\n\t}\n\tr_buf_read_at (bf->buf, from, buf, to - from);\n\t// may oobread\n\twhile (needle < to) {\n\t\trc = r_utf8_decode (buf + needle - from, to - needle, NULL);\n\t\tif (!rc) {\n\t\t\tneedle++;\n\t\t\tcontinue;\n\t\t}\n\t\tif (type == R_STRING_TYPE_DETECT) {\n\t\t\tchar *w = (char *)buf + needle + rc - from;\n\t\t\tif ((to - needle) > 5) {\n\t\t\t\tbool is_wide32 = needle + rc + 2 < to && !w[0] && !w[1] && !w[2] && w[3] && !w[4];\n\t\t\t\tif (is_wide32) {\n\t\t\t\t\tstr_type = R_STRING_TYPE_WIDE32;\n\t\t\t\t} else {\n\t\t\t\t\tbool is_wide = needle + rc + 2 < to && !w[0] && w[1] && !w[2];\n\t\t\t\t\tstr_type = is_wide? R_STRING_TYPE_WIDE: R_STRING_TYPE_ASCII;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tstr_type = R_STRING_TYPE_ASCII;\n\t\t\t}\n\t\t} else {\n\t\t\tstr_type = type;\n\t\t}\n\t\trunes = 0;\n\t\tstr_start = needle;\n\n\t\t/* Eat a whole C string */\n\t\tfor (rc = i = 0; i < sizeof (tmp) - 3 && needle < to; i += rc) {\n\t\t\tRRune r = {0};\n\n\t\t\tif (str_type == R_STRING_TYPE_WIDE32) {\n\t\t\t\trc = r_utf32le_decode (buf + needle - from, to - needle, &r);\n\t\t\t\tif (rc) {\n\t\t\t\t\trc = 4;\n\t\t\t\t}\n\t\t\t} else if (str_type == R_STRING_TYPE_WIDE) {\n\t\t\t\trc = r_utf16le_decode (buf + needle - from, to - needle, &r);\n\t\t\t\tif (rc == 1) {\n\t\t\t\t\trc = 2;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\trc = r_utf8_decode (buf + needle - from, to - needle, &r);\n\t\t\t\tif (rc > 1) {\n\t\t\t\t\tstr_type = R_STRING_TYPE_UTF8;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t/* Invalid sequence detected */\n\t\t\tif (!rc) {\n\t\t\t\tneedle++;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tneedle += rc;\n\n\t\t\tif (r_isprint (r) && r != '\\\\') {\n\t\t\t\tif (str_type == R_STRING_TYPE_WIDE32) {\n\t\t\t\t\tif (r == 0xff) {\n\t\t\t\t\t\tr = 0;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\trc = r_utf8_encode (&tmp[i], r);\n\t\t\t\trunes++;\n\t\t\t\t/* Print the escape code */\n\t\t\t} else if (r && r < 0x100 && strchr (\"\\b\\v\\f\\n\\r\\t\\a\\033\\\\\", (char)r)) {\n\t\t\t\tif ((i + 32) < sizeof (tmp) && r < 93) {\n\t\t\t\t\ttmp[i + 0] = '\\\\';\n\t\t\t\t\ttmp[i + 1] = \"       abtnvfr             e  \"\n\t\t\t\t\t             \"                              \"\n\t\t\t\t\t             \"                              \"\n\t\t\t\t\t             \"  \\\\\"[r];\n\t\t\t\t} else {\n\t\t\t\t\t// string too long\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\trc = 2;\n\t\t\t\trunes++;\n\t\t\t} else {\n\t\t\t\t/* \\0 marks the end of C-strings */\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\ttmp[i++] = '\\0';\n\n\t\tif (runes >= min) {\n\t\t\tif (str_type == R_STRING_TYPE_ASCII) {\n\t\t\t\t// reduce false positives\n\t\t\t\tint j;\n\t\t\t\tfor (j = 0; j < i; j++) {\n\t\t\t\t\tchar ch = tmp[j];\n\t\t\t\t\tif (ch != '\\n' && ch != '\\r' && ch != '\\t') {\n\t\t\t\t\t\tif (!IS_PRINTABLE (tmp[j])) {\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tRBinString *bs = R_NEW0 (RBinString);\n\t\t\tif (!bs) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbs->type = str_type;\n\t\t\tbs->length = runes;\n\t\t\tbs->size = needle - str_start;\n\t\t\tbs->ordinal = count++;\n\t\t\t// TODO: move into adjust_offset\n\t\t\tswitch (str_type) {\n\t\t\tcase R_STRING_TYPE_WIDE:\n\t\t\t\tif (str_start -from> 1) {\n\t\t\t\t\tconst ut8 *p = buf + str_start - 2 - from;\n\t\t\t\t\tif (p[0] == 0xff && p[1] == 0xfe) {\n\t\t\t\t\t\tstr_start -= 2; // \\xff\\xfe\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase R_STRING_TYPE_WIDE32:\n\t\t\t\tif (str_start -from> 3) {\n\t\t\t\t\tconst ut8 *p = buf + str_start - 4 - from;\n\t\t\t\t\tif (p[0] == 0xff && p[1] == 0xfe) {\n\t\t\t\t\t\tstr_start -= 4; // \\xff\\xfe\\x00\\x00\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbs->paddr = bs->vaddr = str_start;\n\t\t\tbs->string = r_str_ndup ((const char *)tmp, i);\n\t\t\tif (list) {\n\t\t\t\tr_list_append (list, bs);\n\t\t\t} else {\n\t\t\t\tprint_string (bs, bf);\n\t\t\t\tr_bin_string_free (bs);\n\t\t\t}\n\t\t}\n\t}\n\tfree (buf);\n\treturn count;\n}", "func_src_after": "static int string_scan_range(RList *list, RBinFile *bf, int min,\n\t\t\t      const ut64 from, const ut64 to, int type) {\n\tut8 tmp[R_STRING_SCAN_BUFFER_SIZE];\n\tut64 str_start, needle = from;\n\tint count = 0, i, rc, runes;\n\tint str_type = R_STRING_TYPE_DETECT;\n\n\tif (type == -1) {\n\t\ttype = R_STRING_TYPE_DETECT;\n\t}\n\tif (from >= to) {\n\t\teprintf (\"Invalid range to find strings 0x%llx .. 0x%llx\\n\", from, to);\n\t\treturn -1;\n\t}\n\tint len = to - from;\n\tut8 *buf = calloc (len, 1);\n\tif (!buf || !min) {\n\t\treturn -1;\n\t}\n\tr_buf_read_at (bf->buf, from, buf, len);\n\t// may oobread\n\twhile (needle < to) {\n\t\trc = r_utf8_decode (buf + needle - from, to - needle, NULL);\n\t\tif (!rc) {\n\t\t\tneedle++;\n\t\t\tcontinue;\n\t\t}\n\t\tif (type == R_STRING_TYPE_DETECT) {\n\t\t\tchar *w = (char *)buf + needle + rc - from;\n\t\t\tif ((to - needle) > 5 + rc) {\n\t\t\t\tbool is_wide32 = (needle + rc + 2 < to) && (!w[0] && !w[1] && !w[2] && w[3] && !w[4]);\n\t\t\t\tif (is_wide32) {\n\t\t\t\t\tstr_type = R_STRING_TYPE_WIDE32;\n\t\t\t\t} else {\n\t\t\t\t\tbool is_wide = needle + rc + 2 < to && !w[0] && w[1] && !w[2];\n\t\t\t\t\tstr_type = is_wide? R_STRING_TYPE_WIDE: R_STRING_TYPE_ASCII;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tstr_type = R_STRING_TYPE_ASCII;\n\t\t\t}\n\t\t} else {\n\t\t\tstr_type = type;\n\t\t}\n\t\trunes = 0;\n\t\tstr_start = needle;\n\n\t\t/* Eat a whole C string */\n\t\tfor (rc = i = 0; i < sizeof (tmp) - 3 && needle < to; i += rc) {\n\t\t\tRRune r = {0};\n\n\t\t\tif (str_type == R_STRING_TYPE_WIDE32) {\n\t\t\t\trc = r_utf32le_decode (buf + needle - from, to - needle, &r);\n\t\t\t\tif (rc) {\n\t\t\t\t\trc = 4;\n\t\t\t\t}\n\t\t\t} else if (str_type == R_STRING_TYPE_WIDE) {\n\t\t\t\trc = r_utf16le_decode (buf + needle - from, to - needle, &r);\n\t\t\t\tif (rc == 1) {\n\t\t\t\t\trc = 2;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\trc = r_utf8_decode (buf + needle - from, to - needle, &r);\n\t\t\t\tif (rc > 1) {\n\t\t\t\t\tstr_type = R_STRING_TYPE_UTF8;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t/* Invalid sequence detected */\n\t\t\tif (!rc) {\n\t\t\t\tneedle++;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tneedle += rc;\n\n\t\t\tif (r_isprint (r) && r != '\\\\') {\n\t\t\t\tif (str_type == R_STRING_TYPE_WIDE32) {\n\t\t\t\t\tif (r == 0xff) {\n\t\t\t\t\t\tr = 0;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\trc = r_utf8_encode (&tmp[i], r);\n\t\t\t\trunes++;\n\t\t\t\t/* Print the escape code */\n\t\t\t} else if (r && r < 0x100 && strchr (\"\\b\\v\\f\\n\\r\\t\\a\\033\\\\\", (char)r)) {\n\t\t\t\tif ((i + 32) < sizeof (tmp) && r < 93) {\n\t\t\t\t\ttmp[i + 0] = '\\\\';\n\t\t\t\t\ttmp[i + 1] = \"       abtnvfr             e  \"\n\t\t\t\t\t             \"                              \"\n\t\t\t\t\t             \"                              \"\n\t\t\t\t\t             \"  \\\\\"[r];\n\t\t\t\t} else {\n\t\t\t\t\t// string too long\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\trc = 2;\n\t\t\t\trunes++;\n\t\t\t} else {\n\t\t\t\t/* \\0 marks the end of C-strings */\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\ttmp[i++] = '\\0';\n\n\t\tif (runes >= min) {\n\t\t\tif (str_type == R_STRING_TYPE_ASCII) {\n\t\t\t\t// reduce false positives\n\t\t\t\tint j;\n\t\t\t\tfor (j = 0; j < i; j++) {\n\t\t\t\t\tchar ch = tmp[j];\n\t\t\t\t\tif (ch != '\\n' && ch != '\\r' && ch != '\\t') {\n\t\t\t\t\t\tif (!IS_PRINTABLE (tmp[j])) {\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tRBinString *bs = R_NEW0 (RBinString);\n\t\t\tif (!bs) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbs->type = str_type;\n\t\t\tbs->length = runes;\n\t\t\tbs->size = needle - str_start;\n\t\t\tbs->ordinal = count++;\n\t\t\t// TODO: move into adjust_offset\n\t\t\tswitch (str_type) {\n\t\t\tcase R_STRING_TYPE_WIDE:\n\t\t\t\tif (str_start -from> 1) {\n\t\t\t\t\tconst ut8 *p = buf + str_start - 2 - from;\n\t\t\t\t\tif (p[0] == 0xff && p[1] == 0xfe) {\n\t\t\t\t\t\tstr_start -= 2; // \\xff\\xfe\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase R_STRING_TYPE_WIDE32:\n\t\t\t\tif (str_start -from> 3) {\n\t\t\t\t\tconst ut8 *p = buf + str_start - 4 - from;\n\t\t\t\t\tif (p[0] == 0xff && p[1] == 0xfe) {\n\t\t\t\t\t\tstr_start -= 4; // \\xff\\xfe\\x00\\x00\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbs->paddr = bs->vaddr = str_start;\n\t\t\tbs->string = r_str_ndup ((const char *)tmp, i);\n\t\t\tif (list) {\n\t\t\t\tr_list_append (list, bs);\n\t\t\t} else {\n\t\t\t\tprint_string (bs, bf);\n\t\t\t\tr_bin_string_free (bs);\n\t\t\t}\n\t\t}\n\t}\n\tfree (buf);\n\treturn count;\n}", "commit_link": "github.com/radare/radare2/commit/3fcf41ed96ffa25b38029449520c8d0a198745f3", "file_name": "libr/bin/file.c", "vul_type": "cwe-125", "description": "Write a C function to scan for and process strings within a specified range in a binary file."}
{"func_name": "mongoStore", "func_src_before": "        store: new mongoStore({ mongooseConnection: mongoose.connection })\n    }));\n\n    server.use(passport.initialize());\n    server.use(passport.session());\n    server.use(flash());\n    server.use(csrf());\n    server.use(function(req, res, callback) {\n        // Make user object available in templates.\n        res.locals.user = req.user;\n        res.locals.site = {\n            title: config.app.title,\n            url: config.server.host,\n            dbHost: config.database,\n            mailHost: config.mailer\n        };\n        callback();\n    });\n\n    // for nginx proxy\n    if (mode == 'production') {\n        server.enable('trust proxy');  // using Express behind nginx\n    }\n\n    server.use(function(req, res, callback) {\n        // Remember original destination before login.\n        var path = req.path.split('/')[1];\n\n        if (/auth|api|login|logout|signup|components|css|img|js|favicon/i.test(path) || path == '') {\n            return callback();\n        }\n        req.session.returnTo = req.path;\n\n        callback();\n    });\n\n    var HOUR = 3600000;\n    var DAY = HOUR * 24;\n    var WEEK = DAY * 7;\n\n    server.use(express.static(path.join(__dirname, 'public'), { maxAge: WEEK }));\n\n    // Route Point\n    var home = require('../route/home');\n    var stat = require('../route/stat');\n    var account = require('../route/account');\n    var dashboard = require('../route/dashboard');\n\n    server.use(home);\n    server.use(stat);\n    server.use(account);\n    server.use(dashboard);\n\n    // globalMiddleware\n    // api counter for ip district\n    // haroo cloud api document page\n    // dummy testing\n    // version specified api for only feature test\n    // commonMiddleware\n    // header parameter test\n    // for account\n    // districtMiddleware\n    // district test\n    // for token\n    // for api version\n    // for users\n    // for documents\n\n    // 500 Error Handler\n    server.use(errorHandler());\n\n    callback(server);\n}", "func_src_after": "        store: new mongoStore({ mongooseConnection: mongoose.connection })\n    }));\n\n    server.use(passport.initialize());\n    server.use(passport.session());\n    server.use(flash());\n    server.use(lusca.csrf());\n    server.use(function(req, res, callback) {\n        // Make user object available in templates.\n        res.locals.user = req.user;\n        res.locals.site = {\n            title: config.app.title,\n            url: config.server.host,\n            dbHost: config.database,\n            mailHost: config.mailer\n        };\n        callback();\n    });\n\n    // for nginx proxy\n    if (mode == 'production') {\n        server.enable('trust proxy');  // using Express behind nginx\n    }\n\n    server.use(function(req, res, callback) {\n        // Remember original destination before login.\n        var path = req.path.split('/')[1];\n\n        if (/auth|api|login|logout|signup|components|css|img|js|favicon/i.test(path) || path == '') {\n            return callback();\n        }\n        req.session.returnTo = req.path;\n\n        callback();\n    });\n\n    var HOUR = 3600000;\n    var DAY = HOUR * 24;\n    var WEEK = DAY * 7;\n\n    server.use(express.static(path.join(__dirname, 'public'), { maxAge: WEEK }));\n\n    // Route Point\n    var home = require('../route/home');\n    var stat = require('../route/stat');\n    var account = require('../route/account');\n    var dashboard = require('../route/dashboard');\n\n    server.use(home);\n    server.use(stat);\n    server.use(account);\n    server.use(dashboard);\n\n    // globalMiddleware\n    // api counter for ip district\n    // haroo cloud api document page\n    // dummy testing\n    // version specified api for only feature test\n    // commonMiddleware\n    // header parameter test\n    // for account\n    // districtMiddleware\n    // district test\n    // for token\n    // for api version\n    // for users\n    // for documents\n\n    // 500 Error Handler\n    server.use(errorHandler());\n\n    callback(server);\n}", "line_changes": {"deleted": [{"line_no": 7, "char_start": 185, "char_end": 209, "line": "    server.use(csrf());\n"}], "added": [{"line_no": 7, "char_start": 185, "char_end": 215, "line": "    server.use(lusca.csrf());\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 200, "char_end": 206, "chars": "lusca."}]}, "commit_link": "github.com/Haroo-Studio/haroo-cloud-web/commit/ca6069b630f6292aed0cc17389227d6d9c866cdd", "file_name": "init.js", "vul_type": "cwe-352", "commit_msg": "`fix` csrf bind", "description": "Write a JavaScript (Node.js with Express) code snippet to configure middleware for user authentication, session management, static file serving, and routing."}
{"func_name": "al_segment_cwd_prefix", "func_src_before": "int al_segment_cwd_prefix(char** prompt, unsigned int* prompt_len, int* is_first, int* last_bg, int orientation) {\n    char text[16];\n\n    char prefix[16];\n    char home[64];\n    char cwd[512];\n    char *base = cwd;\n\n    if (al_get_home(home, 64) != 0) {\n        return -1;\n    }\n    if (al_get_cwd(cwd, 512) != 0) {\n        return -1;\n    }\n\n    // check if in home directory\n    if (al_string_startswith(cwd, home)) {\n        base = cwd+strlen(home);\n    }\n\n    // copy first path element into dirs buffer\n    if (al_get_dir_count(base) > CWD_LEN) {\n        strcpy(prefix, THREE_DOTS); // deep in hirarchy\n    } else if (al_string_startswith(cwd, home)) {\n        strcpy(prefix, \"~\"); // home directory\n    } else {\n        strcpy(prefix, \"/\"); // everywhere else\n    }\n\n    // add segment to prompt buffer\n    snprintf(text, 64, \" %s \", prefix);\n    al_gen_segment(prompt, prompt_len, COLOR_FG_CWD_PREFIX, COLOR_BG_CWD_PREFIX, FNT_BOLD, text, is_first, last_bg, orientation);\n\n    return 0;\n}", "func_src_after": "int al_segment_cwd_prefix(char** prompt, unsigned int* prompt_len, int* is_first, int* last_bg, int orientation) {\n    char text[16];\n\n    char prefix[16];\n    char home[64];\n    char cwd[512];\n    char *base = cwd;\n\n    if (al_get_home(home, 64) != 0) {\n        return -1;\n    }\n    if (al_get_cwd(cwd, 512) != 0) {\n        return -1;\n    }\n\n    // check if in home directory\n    if (al_string_startswith(cwd, home)) {\n        base = cwd+strlen(home);\n    }\n\n    // copy first path element into dirs buffer\n    if (al_get_dir_count(base) > CWD_LEN) {\n        strcpy(prefix, THREE_DOTS); // deep in hirarchy\n    } else if (al_string_startswith(cwd, home)) {\n        strcpy(prefix, \"~\"); // home directory\n    } else {\n        strcpy(prefix, \"/\"); // everywhere else\n    }\n\n    // add segment to prompt buffer\n    snprintf(text, 16, \" %s \", prefix);\n    al_gen_segment(prompt, prompt_len, COLOR_FG_CWD_PREFIX, COLOR_BG_CWD_PREFIX, FNT_BOLD, text, is_first, last_bg, orientation);\n\n    return 0;\n}", "line_changes": {"deleted": [{"line_no": 31, "char_start": 809, "char_end": 849, "line": "    snprintf(text, 64, \" %s \", prefix);\n"}], "added": [{"line_no": 31, "char_start": 809, "char_end": 849, "line": "    snprintf(text, 16, \" %s \", prefix);\n"}]}, "char_changes": {"deleted": [{"char_start": 829, "char_end": 830, "chars": "4"}], "added": [{"char_start": 828, "char_end": 829, "chars": "1"}]}, "commit_link": "github.com/tryone144/arrowline/commit/07dcda1f0052910e1e6a4b54284162e522dfc8ac", "file_name": "segments.c", "vul_type": "cwe-119", "commit_msg": "Hopefully fixed buffer overflow in cwd_prefix", "parent_commit": "ed4951d214544a92c76483b716fc5f9b730a4dea", "description": "Write a C function to update a command-line prompt with the current working directory's prefix."}
{"func_name": "_cliq_run", "func_src_before": "    def _cliq_run(self, verb, cliq_args, check_exit_code=True):\n        \"\"\"Runs a CLIQ command over SSH, without doing any result parsing\"\"\"\n        cliq_arg_strings = []\n        for k, v in cliq_args.items():\n            cliq_arg_strings.append(\" %s=%s\" % (k, v))\n        cmd = verb + ''.join(cliq_arg_strings)\n\n        return self._run_ssh(cmd, check_exit_code)", "func_src_after": "    def _cliq_run(self, verb, cliq_args, check_exit_code=True):\n        \"\"\"Runs a CLIQ command over SSH, without doing any result parsing\"\"\"\n        cmd_list = [verb]\n        for k, v in cliq_args.items():\n            cmd_list.append(\"%s=%s\" % (k, v))\n\n        return self._run_ssh(cmd_list, check_exit_code)", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp_lefthand.py", "vul_type": "cwe-078", "description": "Write a Python function that executes a command with arguments over SSH without parsing the results."}
{"func_name": "ReadRLEImage", "func_src_before": "static Image *ReadRLEImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n#define SkipLinesOp  0x01\n#define SetColorOp  0x02\n#define SkipPixelsOp  0x03\n#define ByteDataOp  0x05\n#define RunDataOp  0x06\n#define EOFOp  0x07\n\n  char\n    magick[12];\n\n  Image\n    *image;\n\n  int\n    opcode,\n    operand,\n    status;\n\n  MagickStatusType\n    flags;\n\n  MagickSizeType\n    number_pixels;\n\n  MemoryInfo\n    *pixel_info;\n\n  Quantum\n    index;\n\n  register ssize_t\n    x;\n\n  register Quantum\n    *q;\n\n  register ssize_t\n    i;\n\n  register unsigned char\n    *p;\n\n  size_t\n    bits_per_pixel,\n    map_length,\n    number_colormaps,\n    number_planes,\n    one,\n    offset,\n    pixel_info_length;\n\n  ssize_t\n    count,\n    y;\n\n  unsigned char\n    background_color[256],\n    *colormap,\n    pixel,\n    plane,\n    *pixels;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n  /*\n    Determine if this a RLE file.\n  */\n  count=ReadBlob(image,2,(unsigned char *) magick);\n  if ((count != 2) || (memcmp(magick,\"\\122\\314\",2) != 0))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  do\n  {\n    /*\n      Read image header.\n    */\n    image->page.x=ReadBlobLSBShort(image);\n    image->page.y=ReadBlobLSBShort(image);\n    image->columns=ReadBlobLSBShort(image);\n    image->rows=ReadBlobLSBShort(image);\n    flags=(MagickStatusType) ReadBlobByte(image);\n    image->alpha_trait=flags & 0x04 ? BlendPixelTrait : UndefinedPixelTrait;\n    number_planes=(size_t) ReadBlobByte(image);\n    bits_per_pixel=(size_t) ReadBlobByte(image);\n    number_colormaps=(size_t) ReadBlobByte(image);\n    map_length=(unsigned char) ReadBlobByte(image);\n    if (map_length >= 64)\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    one=1;\n    map_length=one << map_length;\n    if ((number_planes == 0) || (number_planes == 2) || (bits_per_pixel != 8) ||\n        (image->columns == 0))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if (flags & 0x02)\n      {\n        /*\n          No background color-- initialize to black.\n        */\n        for (i=0; i < (ssize_t) number_planes; i++)\n          background_color[i]=0;\n        (void) ReadBlobByte(image);\n      }\n    else\n      {\n        /*\n          Initialize background color.\n        */\n        p=background_color;\n        for (i=0; i < (ssize_t) number_planes; i++)\n          *p++=(unsigned char) ReadBlobByte(image);\n      }\n    if ((number_planes & 0x01) == 0)\n      (void) ReadBlobByte(image);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    colormap=(unsigned char *) NULL;\n    if (number_colormaps != 0)\n      {\n        /*\n          Read image colormaps.\n        */\n        colormap=(unsigned char *) AcquireQuantumMemory(number_colormaps,\n          3*map_length*sizeof(*colormap));\n        if (colormap == (unsigned char *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        p=colormap;\n        for (i=0; i < (ssize_t) number_colormaps; i++)\n          for (x=0; x < (ssize_t) map_length; x++)\n            *p++=(unsigned char) ScaleShortToQuantum(ReadBlobLSBShort(image));\n      }\n    if ((flags & 0x08) != 0)\n      {\n        char\n          *comment;\n\n        size_t\n          length;\n\n        /*\n          Read image comment.\n        */\n        length=ReadBlobLSBShort(image);\n        if (length != 0)\n          {\n            comment=(char *) AcquireQuantumMemory(length,sizeof(*comment));\n            if (comment == (char *) NULL)\n              ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n            count=ReadBlob(image,length-1,(unsigned char *) comment);\n            comment[length-1]='\\0';\n            (void) SetImageProperty(image,\"comment\",comment,exception);\n            comment=DestroyString(comment);\n            if ((length & 0x01) == 0)\n              (void) ReadBlobByte(image);\n          }\n      }\n    if ((image_info->ping != MagickFalse) && (image_info->number_scenes != 0))\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    status=SetImageExtent(image,image->columns,image->rows,exception);\n    if (status == MagickFalse)\n      return(DestroyImageList(image));\n    /*\n      Allocate RLE pixels.\n    */\n    if (image->alpha_trait != UndefinedPixelTrait)\n      number_planes++;\n    number_pixels=(MagickSizeType) image->columns*image->rows;\n    if ((number_pixels*number_planes) != (size_t) (number_pixels*number_planes))\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    pixel_info_length=image->columns*image->rows*MagickMax(number_planes,4);\n    pixel_info=AcquireVirtualMemory(pixel_info_length,sizeof(*pixels));\n    if (pixel_info == (MemoryInfo *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    pixels=(unsigned char *) GetVirtualMemoryBlob(pixel_info);\n    if ((flags & 0x01) && !(flags & 0x02))\n      {\n        ssize_t\n          j;\n\n        /*\n          Set background color.\n        */\n        p=pixels;\n        for (i=0; i < (ssize_t) number_pixels; i++)\n        {\n          if (image->alpha_trait == UndefinedPixelTrait)\n            for (j=0; j < (ssize_t) number_planes; j++)\n              *p++=background_color[j];\n          else\n            {\n              for (j=0; j < (ssize_t) (number_planes-1); j++)\n                *p++=background_color[j];\n              *p++=0;  /* initialize matte channel */\n            }\n        }\n      }\n    /*\n      Read runlength-encoded image.\n    */\n    plane=0;\n    x=0;\n    y=0;\n    opcode=ReadBlobByte(image);\n    do\n    {\n      switch (opcode & 0x3f)\n      {\n        case SkipLinesOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=(int) ReadBlobLSBShort(image);\n          x=0;\n          y+=operand;\n          break;\n        }\n        case SetColorOp:\n        {\n          operand=ReadBlobByte(image);\n          plane=(unsigned char) operand;\n          if (plane == 255)\n            plane=(unsigned char) (number_planes-1);\n          x=0;\n          break;\n        }\n        case SkipPixelsOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=(int) ReadBlobLSBShort(image);\n          x+=operand;\n          break;\n        }\n        case ByteDataOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=(int) ReadBlobLSBShort(image);\n          offset=((image->rows-y-1)*image->columns*number_planes)+x*\n            number_planes+plane;\n          operand++;\n          if (offset+((size_t) operand*number_planes) > pixel_info_length)\n            {\n              if (number_colormaps != 0)\n                colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n              pixel_info=RelinquishVirtualMemory(pixel_info);\n              ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n            }\n          p=pixels+offset;\n          for (i=0; i < (ssize_t) operand; i++)\n          {\n            pixel=(unsigned char) ReadBlobByte(image);\n            if ((y < (ssize_t) image->rows) &&\n                ((x+i) < (ssize_t) image->columns))\n              *p=pixel;\n            p+=number_planes;\n          }\n          if (operand & 0x01)\n            (void) ReadBlobByte(image);\n          x+=operand;\n          break;\n        }\n        case RunDataOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=(int) ReadBlobLSBShort(image);\n          pixel=(unsigned char) ReadBlobByte(image);\n          (void) ReadBlobByte(image);\n          offset=((image->rows-y-1)*image->columns*number_planes)+x*\n            number_planes+plane;\n          operand++;\n          if (offset+((size_t) operand*number_planes) > pixel_info_length)\n            {\n              if (number_colormaps != 0)\n                colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n              pixel_info=RelinquishVirtualMemory(pixel_info);\n              ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n            }\n          p=pixels+offset;\n          for (i=0; i < (ssize_t) operand; i++)\n          {\n            if ((y < (ssize_t) image->rows) &&\n                ((x+i) < (ssize_t) image->columns))\n              *p=pixel;\n            p+=number_planes;\n          }\n          x+=operand;\n          break;\n        }\n        default:\n          break;\n      }\n      opcode=ReadBlobByte(image);\n    } while (((opcode & 0x3f) != EOFOp) && (opcode != EOF));\n    if (number_colormaps != 0)\n      {\n        MagickStatusType\n          mask;\n\n        /*\n          Apply colormap affineation to image.\n        */\n        mask=(MagickStatusType) (map_length-1);\n        p=pixels;\n        x=(ssize_t) number_planes;\n        if (number_colormaps == 1)\n          for (i=0; i < (ssize_t) number_pixels; i++)\n          {\n            if (IsValidColormapIndex(image,*p & mask,&index,exception) ==\n                MagickFalse)\n              break;\n            *p=colormap[(ssize_t) index];\n            p++;\n          }\n        else\n          if ((number_planes >= 3) && (number_colormaps >= 3))\n            for (i=0; i < (ssize_t) number_pixels; i++)\n              for (x=0; x < (ssize_t) number_planes; x++)\n              {\n                if (IsValidColormapIndex(image,(size_t) (x*map_length+\n                    (*p & mask)),&index,exception) == MagickFalse)\n                  break;\n                *p=colormap[(ssize_t) index];\n                p++;\n              }\n        if ((i < (ssize_t) number_pixels) || (x < (ssize_t) number_planes))\n          {\n            colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n            pixel_info=RelinquishVirtualMemory(pixel_info);\n            ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n          }\n      }\n    /*\n      Initialize image structure.\n    */\n    if (number_planes >= 3)\n      {\n        /*\n          Convert raster image to DirectClass pixel packets.\n        */\n        p=pixels;\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n          if (q == (Quantum *) NULL)\n            break;\n          for (x=0; x < (ssize_t) image->columns; x++)\n          {\n            SetPixelRed(image,ScaleCharToQuantum(*p++),q);\n            SetPixelGreen(image,ScaleCharToQuantum(*p++),q);\n            SetPixelBlue(image,ScaleCharToQuantum(*p++),q);\n            if (image->alpha_trait != UndefinedPixelTrait)\n              SetPixelAlpha(image,ScaleCharToQuantum(*p++),q);\n            q+=GetPixelChannels(image);\n          }\n          if (SyncAuthenticPixels(image,exception) == MagickFalse)\n            break;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n      }\n    else\n      {\n        /*\n          Create colormap.\n        */\n        if (number_colormaps == 0)\n          map_length=256;\n        if (AcquireImageColormap(image,map_length,exception) == MagickFalse)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        p=colormap;\n        if (number_colormaps == 1)\n          for (i=0; i < (ssize_t) image->colors; i++)\n          {\n            /*\n              Pseudocolor.\n            */\n            image->colormap[i].red=(MagickRealType)\n              ScaleCharToQuantum((unsigned char) i);\n            image->colormap[i].green=(MagickRealType)\n              ScaleCharToQuantum((unsigned char) i);\n            image->colormap[i].blue=(MagickRealType)\n              ScaleCharToQuantum((unsigned char) i);\n          }\n        else\n          if (number_colormaps > 1)\n            for (i=0; i < (ssize_t) image->colors; i++)\n            {\n              image->colormap[i].red=(MagickRealType)\n                ScaleCharToQuantum(*p);\n              image->colormap[i].green=(MagickRealType)\n                ScaleCharToQuantum(*(p+map_length));\n              image->colormap[i].blue=(MagickRealType)\n                ScaleCharToQuantum(*(p+map_length*2));\n              p++;\n            }\n        p=pixels;\n        if (image->alpha_trait == UndefinedPixelTrait)\n          {\n            /*\n              Convert raster image to PseudoClass pixel packets.\n            */\n            for (y=0; y < (ssize_t) image->rows; y++)\n            {\n              q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n              if (q == (Quantum *) NULL)\n                break;\n              for (x=0; x < (ssize_t) image->columns; x++)\n              {\n                SetPixelIndex(image,*p++,q);\n                q+=GetPixelChannels(image);\n              }\n              if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                break;\n              if (image->previous == (Image *) NULL)\n                {\n                  status=SetImageProgress(image,LoadImageTag,(MagickOffsetType)\n                    y,image->rows);\n                  if (status == MagickFalse)\n                    break;\n                }\n            }\n            (void) SyncImage(image,exception);\n          }\n        else\n          {\n            /*\n              Image has a matte channel-- promote to DirectClass.\n            */\n            for (y=0; y < (ssize_t) image->rows; y++)\n            {\n              q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n              if (q == (Quantum *) NULL)\n                break;\n              for (x=0; x < (ssize_t) image->columns; x++)\n              {\n                if (IsValidColormapIndex(image,(ssize_t) *p++,&index,\n                    exception) == MagickFalse)\n                  break;\n                SetPixelRed(image,ClampToQuantum(image->colormap[(ssize_t)\n                  index].red),q);\n                if (IsValidColormapIndex(image,(ssize_t) *p++,&index,\n                    exception) == MagickFalse)\n                  break;\n                SetPixelGreen(image,ClampToQuantum(image->colormap[(ssize_t)\n                  index].green),q);\n                if (IsValidColormapIndex(image,(ssize_t) *p++,&index,\n                    exception) == MagickFalse)\n                  break;\n                SetPixelBlue(image,ClampToQuantum(image->colormap[(ssize_t)\n                  index].blue),q);\n                SetPixelAlpha(image,ScaleCharToQuantum(*p++),q);\n                q+=GetPixelChannels(image);\n              }\n              if (x < (ssize_t) image->columns)\n                break;\n              if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                break;\n              if (image->previous == (Image *) NULL)\n                {\n                  status=SetImageProgress(image,LoadImageTag,(MagickOffsetType)\n                    y,image->rows);\n                  if (status == MagickFalse)\n                    break;\n                }\n            }\n            image->colormap=(PixelInfo *) RelinquishMagickMemory(\n              image->colormap);\n            image->storage_class=DirectClass;\n            image->colors=0;\n          }\n      }\n    if (number_colormaps != 0)\n      colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n    pixel_info=RelinquishVirtualMemory(pixel_info);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    /*\n      Proceed to next image.\n    */\n    if (image_info->number_scenes != 0)\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    (void) ReadBlobByte(image);\n    count=ReadBlob(image,2,(unsigned char *) magick);\n    if ((count != 0) && (memcmp(magick,\"\\122\\314\",2) == 0))\n      {\n        /*\n          Allocate next image structure.\n        */\n        AcquireNextImage(image_info,image,exception);\n        if (GetNextImageInList(image) == (Image *) NULL)\n          {\n            image=DestroyImageList(image);\n            return((Image *) NULL);\n          }\n        image=SyncNextImageInList(image);\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n        if (status == MagickFalse)\n          break;\n      }\n  } while ((count != 0) && (memcmp(magick,\"\\122\\314\",2) == 0));\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "func_src_after": "static Image *ReadRLEImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n#define SkipLinesOp  0x01\n#define SetColorOp  0x02\n#define SkipPixelsOp  0x03\n#define ByteDataOp  0x05\n#define RunDataOp  0x06\n#define EOFOp  0x07\n\n  char\n    magick[12];\n\n  Image\n    *image;\n\n  int\n    opcode,\n    operand,\n    status;\n\n  MagickStatusType\n    flags;\n\n  MagickSizeType\n    number_pixels;\n\n  MemoryInfo\n    *pixel_info;\n\n  Quantum\n    index;\n\n  register ssize_t\n    x;\n\n  register Quantum\n    *q;\n\n  register ssize_t\n    i;\n\n  register unsigned char\n    *p;\n\n  size_t\n    bits_per_pixel,\n    map_length,\n    number_colormaps,\n    number_planes,\n    number_planes_filled,\n    one,\n    offset,\n    pixel_info_length;\n\n  ssize_t\n    count,\n    y;\n\n  unsigned char\n    background_color[256],\n    *colormap,\n    pixel,\n    plane,\n    *pixels;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n  /*\n    Determine if this a RLE file.\n  */\n  count=ReadBlob(image,2,(unsigned char *) magick);\n  if ((count != 2) || (memcmp(magick,\"\\122\\314\",2) != 0))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  do\n  {\n    /*\n      Read image header.\n    */\n    image->page.x=ReadBlobLSBShort(image);\n    image->page.y=ReadBlobLSBShort(image);\n    image->columns=ReadBlobLSBShort(image);\n    image->rows=ReadBlobLSBShort(image);\n    flags=(MagickStatusType) ReadBlobByte(image);\n    image->alpha_trait=flags & 0x04 ? BlendPixelTrait : UndefinedPixelTrait;\n    number_planes=(size_t) ReadBlobByte(image);\n    bits_per_pixel=(size_t) ReadBlobByte(image);\n    number_colormaps=(size_t) ReadBlobByte(image);\n    map_length=(unsigned char) ReadBlobByte(image);\n    if (map_length >= 64)\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    one=1;\n    map_length=one << map_length;\n    if ((number_planes == 0) || (number_planes == 2) || (bits_per_pixel != 8) ||\n        (image->columns == 0))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if (flags & 0x02)\n      {\n        /*\n          No background color-- initialize to black.\n        */\n        for (i=0; i < (ssize_t) number_planes; i++)\n          background_color[i]=0;\n        (void) ReadBlobByte(image);\n      }\n    else\n      {\n        /*\n          Initialize background color.\n        */\n        p=background_color;\n        for (i=0; i < (ssize_t) number_planes; i++)\n          *p++=(unsigned char) ReadBlobByte(image);\n      }\n    if ((number_planes & 0x01) == 0)\n      (void) ReadBlobByte(image);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    colormap=(unsigned char *) NULL;\n    if (number_colormaps != 0)\n      {\n        /*\n          Read image colormaps.\n        */\n        colormap=(unsigned char *) AcquireQuantumMemory(number_colormaps,\n          3*map_length*sizeof(*colormap));\n        if (colormap == (unsigned char *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        p=colormap;\n        for (i=0; i < (ssize_t) number_colormaps; i++)\n          for (x=0; x < (ssize_t) map_length; x++)\n            *p++=(unsigned char) ScaleShortToQuantum(ReadBlobLSBShort(image));\n      }\n    if ((flags & 0x08) != 0)\n      {\n        char\n          *comment;\n\n        size_t\n          length;\n\n        /*\n          Read image comment.\n        */\n        length=ReadBlobLSBShort(image);\n        if (length != 0)\n          {\n            comment=(char *) AcquireQuantumMemory(length,sizeof(*comment));\n            if (comment == (char *) NULL)\n              ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n            count=ReadBlob(image,length-1,(unsigned char *) comment);\n            comment[length-1]='\\0';\n            (void) SetImageProperty(image,\"comment\",comment,exception);\n            comment=DestroyString(comment);\n            if ((length & 0x01) == 0)\n              (void) ReadBlobByte(image);\n          }\n      }\n    if ((image_info->ping != MagickFalse) && (image_info->number_scenes != 0))\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    status=SetImageExtent(image,image->columns,image->rows,exception);\n    if (status == MagickFalse)\n      return(DestroyImageList(image));\n    /*\n      Allocate RLE pixels.\n    */\n    if (image->alpha_trait != UndefinedPixelTrait)\n      number_planes++;\n    number_pixels=(MagickSizeType) image->columns*image->rows;\n    number_planes_filled=(number_planes % 2 == 0) ? number_planes :\n      number_planes+1;\n    if ((number_pixels*number_planes_filled) != (size_t) (number_pixels*\n         number_planes_filled))\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    pixel_info_length=image->columns*image->rows*number_planes_filled;\n    pixel_info=AcquireVirtualMemory(pixel_info_length,sizeof(*pixels));\n    if (pixel_info == (MemoryInfo *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    pixels=(unsigned char *) GetVirtualMemoryBlob(pixel_info);\n    if ((flags & 0x01) && !(flags & 0x02))\n      {\n        ssize_t\n          j;\n\n        /*\n          Set background color.\n        */\n        p=pixels;\n        for (i=0; i < (ssize_t) number_pixels; i++)\n        {\n          if (image->alpha_trait == UndefinedPixelTrait)\n            for (j=0; j < (ssize_t) number_planes; j++)\n              *p++=background_color[j];\n          else\n            {\n              for (j=0; j < (ssize_t) (number_planes-1); j++)\n                *p++=background_color[j];\n              *p++=0;  /* initialize matte channel */\n            }\n        }\n      }\n    /*\n      Read runlength-encoded image.\n    */\n    plane=0;\n    x=0;\n    y=0;\n    opcode=ReadBlobByte(image);\n    do\n    {\n      switch (opcode & 0x3f)\n      {\n        case SkipLinesOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=(int) ReadBlobLSBShort(image);\n          x=0;\n          y+=operand;\n          break;\n        }\n        case SetColorOp:\n        {\n          operand=ReadBlobByte(image);\n          plane=(unsigned char) operand;\n          if (plane == 255)\n            plane=(unsigned char) (number_planes-1);\n          x=0;\n          break;\n        }\n        case SkipPixelsOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=(int) ReadBlobLSBShort(image);\n          x+=operand;\n          break;\n        }\n        case ByteDataOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=(int) ReadBlobLSBShort(image);\n          offset=((image->rows-y-1)*image->columns*number_planes)+x*\n            number_planes+plane;\n          operand++;\n          if (offset+((size_t) operand*number_planes) > pixel_info_length)\n            {\n              if (number_colormaps != 0)\n                colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n              pixel_info=RelinquishVirtualMemory(pixel_info);\n              ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n            }\n          p=pixels+offset;\n          for (i=0; i < (ssize_t) operand; i++)\n          {\n            pixel=(unsigned char) ReadBlobByte(image);\n            if ((y < (ssize_t) image->rows) &&\n                ((x+i) < (ssize_t) image->columns))\n              *p=pixel;\n            p+=number_planes;\n          }\n          if (operand & 0x01)\n            (void) ReadBlobByte(image);\n          x+=operand;\n          break;\n        }\n        case RunDataOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=(int) ReadBlobLSBShort(image);\n          pixel=(unsigned char) ReadBlobByte(image);\n          (void) ReadBlobByte(image);\n          offset=((image->rows-y-1)*image->columns*number_planes)+x*\n            number_planes+plane;\n          operand++;\n          if (offset+((size_t) operand*number_planes) > pixel_info_length)\n            {\n              if (number_colormaps != 0)\n                colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n              pixel_info=RelinquishVirtualMemory(pixel_info);\n              ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n            }\n          p=pixels+offset;\n          for (i=0; i < (ssize_t) operand; i++)\n          {\n            if ((y < (ssize_t) image->rows) &&\n                ((x+i) < (ssize_t) image->columns))\n              *p=pixel;\n            p+=number_planes;\n          }\n          x+=operand;\n          break;\n        }\n        default:\n          break;\n      }\n      opcode=ReadBlobByte(image);\n    } while (((opcode & 0x3f) != EOFOp) && (opcode != EOF));\n    if (number_colormaps != 0)\n      {\n        MagickStatusType\n          mask;\n\n        /*\n          Apply colormap affineation to image.\n        */\n        mask=(MagickStatusType) (map_length-1);\n        p=pixels;\n        x=(ssize_t) number_planes;\n        if (number_colormaps == 1)\n          for (i=0; i < (ssize_t) number_pixels; i++)\n          {\n            if (IsValidColormapIndex(image,*p & mask,&index,exception) ==\n                MagickFalse)\n              break;\n            *p=colormap[(ssize_t) index];\n            p++;\n          }\n        else\n          if ((number_planes >= 3) && (number_colormaps >= 3))\n            for (i=0; i < (ssize_t) number_pixels; i++)\n              for (x=0; x < (ssize_t) number_planes; x++)\n              {\n                if (IsValidColormapIndex(image,(size_t) (x*map_length+\n                    (*p & mask)),&index,exception) == MagickFalse)\n                  break;\n                *p=colormap[(ssize_t) index];\n                p++;\n              }\n        if ((i < (ssize_t) number_pixels) || (x < (ssize_t) number_planes))\n          {\n            colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n            pixel_info=RelinquishVirtualMemory(pixel_info);\n            ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n          }\n      }\n    /*\n      Initialize image structure.\n    */\n    if (number_planes >= 3)\n      {\n        /*\n          Convert raster image to DirectClass pixel packets.\n        */\n        p=pixels;\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n          if (q == (Quantum *) NULL)\n            break;\n          for (x=0; x < (ssize_t) image->columns; x++)\n          {\n            SetPixelRed(image,ScaleCharToQuantum(*p++),q);\n            SetPixelGreen(image,ScaleCharToQuantum(*p++),q);\n            SetPixelBlue(image,ScaleCharToQuantum(*p++),q);\n            if (image->alpha_trait != UndefinedPixelTrait)\n              SetPixelAlpha(image,ScaleCharToQuantum(*p++),q);\n            q+=GetPixelChannels(image);\n          }\n          if (SyncAuthenticPixels(image,exception) == MagickFalse)\n            break;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n      }\n    else\n      {\n        /*\n          Create colormap.\n        */\n        if (number_colormaps == 0)\n          map_length=256;\n        if (AcquireImageColormap(image,map_length,exception) == MagickFalse)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        p=colormap;\n        if (number_colormaps == 1)\n          for (i=0; i < (ssize_t) image->colors; i++)\n          {\n            /*\n              Pseudocolor.\n            */\n            image->colormap[i].red=(MagickRealType)\n              ScaleCharToQuantum((unsigned char) i);\n            image->colormap[i].green=(MagickRealType)\n              ScaleCharToQuantum((unsigned char) i);\n            image->colormap[i].blue=(MagickRealType)\n              ScaleCharToQuantum((unsigned char) i);\n          }\n        else\n          if (number_colormaps > 1)\n            for (i=0; i < (ssize_t) image->colors; i++)\n            {\n              image->colormap[i].red=(MagickRealType)\n                ScaleCharToQuantum(*p);\n              image->colormap[i].green=(MagickRealType)\n                ScaleCharToQuantum(*(p+map_length));\n              image->colormap[i].blue=(MagickRealType)\n                ScaleCharToQuantum(*(p+map_length*2));\n              p++;\n            }\n        p=pixels;\n        if (image->alpha_trait == UndefinedPixelTrait)\n          {\n            /*\n              Convert raster image to PseudoClass pixel packets.\n            */\n            for (y=0; y < (ssize_t) image->rows; y++)\n            {\n              q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n              if (q == (Quantum *) NULL)\n                break;\n              for (x=0; x < (ssize_t) image->columns; x++)\n              {\n                SetPixelIndex(image,*p++,q);\n                q+=GetPixelChannels(image);\n              }\n              if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                break;\n              if (image->previous == (Image *) NULL)\n                {\n                  status=SetImageProgress(image,LoadImageTag,(MagickOffsetType)\n                    y,image->rows);\n                  if (status == MagickFalse)\n                    break;\n                }\n            }\n            (void) SyncImage(image,exception);\n          }\n        else\n          {\n            /*\n              Image has a matte channel-- promote to DirectClass.\n            */\n            for (y=0; y < (ssize_t) image->rows; y++)\n            {\n              q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n              if (q == (Quantum *) NULL)\n                break;\n              for (x=0; x < (ssize_t) image->columns; x++)\n              {\n                if (IsValidColormapIndex(image,(ssize_t) *p++,&index,\n                    exception) == MagickFalse)\n                  break;\n                SetPixelRed(image,ClampToQuantum(image->colormap[(ssize_t)\n                  index].red),q);\n                if (IsValidColormapIndex(image,(ssize_t) *p++,&index,\n                    exception) == MagickFalse)\n                  break;\n                SetPixelGreen(image,ClampToQuantum(image->colormap[(ssize_t)\n                  index].green),q);\n                if (IsValidColormapIndex(image,(ssize_t) *p++,&index,\n                    exception) == MagickFalse)\n                  break;\n                SetPixelBlue(image,ClampToQuantum(image->colormap[(ssize_t)\n                  index].blue),q);\n                SetPixelAlpha(image,ScaleCharToQuantum(*p++),q);\n                q+=GetPixelChannels(image);\n              }\n              if (x < (ssize_t) image->columns)\n                break;\n              if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                break;\n              if (image->previous == (Image *) NULL)\n                {\n                  status=SetImageProgress(image,LoadImageTag,(MagickOffsetType)\n                    y,image->rows);\n                  if (status == MagickFalse)\n                    break;\n                }\n            }\n            image->colormap=(PixelInfo *) RelinquishMagickMemory(\n              image->colormap);\n            image->storage_class=DirectClass;\n            image->colors=0;\n          }\n      }\n    if (number_colormaps != 0)\n      colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n    pixel_info=RelinquishVirtualMemory(pixel_info);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    /*\n      Proceed to next image.\n    */\n    if (image_info->number_scenes != 0)\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    (void) ReadBlobByte(image);\n    count=ReadBlob(image,2,(unsigned char *) magick);\n    if ((count != 0) && (memcmp(magick,\"\\122\\314\",2) == 0))\n      {\n        /*\n          Allocate next image structure.\n        */\n        AcquireNextImage(image_info,image,exception);\n        if (GetNextImageInList(image) == (Image *) NULL)\n          {\n            image=DestroyImageList(image);\n            return((Image *) NULL);\n          }\n        image=SyncNextImageInList(image);\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n        if (status == MagickFalse)\n          break;\n      }\n  } while ((count != 0) && (memcmp(magick,\"\\122\\314\",2) == 0));\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/2ad6d33493750a28a5a655d319a8e0b16c392de1", "file_name": "coders/rle.c", "vul_type": "cwe-125", "description": "Write a C function to read and process RLE (run-length encoded) image data."}
{"func_name": "_cli_run", "func_src_before": "    def _cli_run(self, verb, cli_args):\n        \"\"\"Runs a CLI command over SSH, without doing any result parsing.\"\"\"\n        cli_arg_strings = []\n        if cli_args:\n            for k, v in cli_args.items():\n                if k == '':\n                    cli_arg_strings.append(\" %s\" % k)\n                else:\n                    cli_arg_strings.append(\" %s=%s\" % (k, v))\n\n        cmd = verb + ''.join(cli_arg_strings)\n        LOG.debug(\"SSH CMD = %s \" % cmd)\n\n        (stdout, stderr) = self._run_ssh(cmd, False)\n\n        # we have to strip out the input and exit lines\n        tmp = stdout.split(\"\\r\\n\")\n        out = tmp[5:len(tmp) - 2]\n        return out", "func_src_after": "    def _cli_run(self, cmd):\n        \"\"\"Runs a CLI command over SSH, without doing any result parsing.\"\"\"\n        LOG.debug(\"SSH CMD = %s \" % cmd)\n\n        (stdout, stderr) = self._run_ssh(cmd, False)\n\n        # we have to strip out the input and exit lines\n        tmp = stdout.split(\"\\r\\n\")\n        out = tmp[5:len(tmp) - 2]\n        return out", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function that executes a given command over SSH and returns the output, excluding the first five lines and the last two lines."}
{"func_name": "(anonymous)", "func_src_before": "    db.get(\"SELECT id,note FROM notes WHERE id = '\"+data.id+\"'\",function(err,row){\n      var newval;\n      if(row){\n        newval = row.note;\n      } else {\n        newval= \"\";\n      }\n      var op = data.op;\n      if(op.d!==null) {\n        newval = newval.slice(0,op.p)+newval.slice(op.p+op.d);\n      }\n      if(op.i!==null){\n        newval = newval.insert(op.p,op.i);\n      } \n      db.run(\"INSERT OR REPLACE INTO notes ('id', 'note') VALUES ('\"+data.id+\"', '\"+newval+\"' )\");\n    });", "func_src_after": "    db.get(\"SELECT id,note FROM notes WHERE id = ?\",[data.id],function(err,row){\n      var newval;\n      if(row){\n        newval = row.note;\n      } else {\n        newval= \"\";\n      }\n      var op = data.op;\n      if(op.d!==null) {\n        newval = newval.slice(0,op.p)+newval.slice(op.p+op.d);\n      }\n      if(op.i!==null){\n        newval = newval.insert(op.p,op.i);\n      } \n      db.run(\"INSERT OR REPLACE INTO notes ('id', 'note') VALUES (?,?)\",[data.id,newval]);\n    });", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 83, "line": "    db.get(\"SELECT id,note FROM notes WHERE id = '\"+data.id+\"'\",function(err,row){\n"}, {"line_no": 15, "char_start": 380, "char_end": 479, "line": "      db.run(\"INSERT OR REPLACE INTO notes ('id', 'note') VALUES ('\"+data.id+\"', '\"+newval+\"' )\");\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 81, "line": "    db.get(\"SELECT id,note FROM notes WHERE id = ?\",[data.id],function(err,row){\n"}, {"line_no": 15, "char_start": 378, "char_end": 469, "line": "      db.run(\"INSERT OR REPLACE INTO notes ('id', 'note') VALUES (?,?)\",[data.id,newval]);\n"}]}, "char_changes": {"deleted": [{"char_start": 49, "char_end": 52, "chars": "'\"+"}, {"char_start": 59, "char_end": 63, "chars": "+\"'\""}, {"char_start": 446, "char_end": 476, "chars": "'\"+data.id+\"', '\"+newval+\"' )\""}], "added": [{"char_start": 49, "char_end": 53, "chars": "?\",["}, {"char_start": 60, "char_end": 61, "chars": "]"}, {"char_start": 444, "char_end": 466, "chars": "?,?)\",[data.id,newval]"}]}, "commit_link": "github.com/yoyodyne/litwritesabook/commit/6ed77576195866819411628e917cd157e2a61361", "file_name": "app.js", "vul_type": "cwe-089", "commit_msg": "SQL injection prevented.", "description": "In JavaScript, write a function that updates a note in a database by either deleting or inserting characters based on the provided operation object."}
{"func_name": "HPHP::extractFileTo", "func_src_before": "static bool extractFileTo(zip* zip, const std::string &file, std::string& to,\n                          char* buf, size_t len) {\n  auto sep = file.rfind('/');\n  if (sep != std::string::npos) {\n    auto path = to + file.substr(0, sep);\n    if (!HHVM_FN(is_dir)(path) && !HHVM_FN(mkdir)(path, 0777, true)) {\n      return false;\n    }\n\n    if (sep == file.length() - 1) {\n      return true;\n    }\n  }\n\n  to.append(file);\n  struct zip_stat zipStat;\n  if (zip_stat(zip, file.c_str(), 0, &zipStat) != 0) {\n    return false;\n  }\n\n  auto zipFile = zip_fopen_index(zip, zipStat.index, 0);\n  FAIL_IF_INVALID_PTR(zipFile);\n\n  auto outFile = fopen(to.c_str(), \"wb\");\n  if (outFile == nullptr) {\n    zip_fclose(zipFile);\n    return false;\n  }\n\n  for (auto n = zip_fread(zipFile, buf, len); n != 0;\n       n = zip_fread(zipFile, buf, len)) {\n    if (n < 0 || fwrite(buf, sizeof(char), n, outFile) != n) {\n      zip_fclose(zipFile);\n      fclose(outFile);\n      remove(to.c_str());\n      return false;\n    }\n  }\n\n  zip_fclose(zipFile);\n  if (fclose(outFile) != 0) {\n    return false;\n  }\n\n  return true;\n}", "func_src_after": "static bool extractFileTo(zip* zip, const std::string &file, std::string& to,\n                          char* buf, size_t len) {\n\n  struct zip_stat zipStat;\n  // Verify the file to be extracted is actually in the zip file\n  if (zip_stat(zip, file.c_str(), 0, &zipStat) != 0) {\n    return false;\n  }\n\n  auto clean_file = file;\n  auto sep = std::string::npos;\n  // Normally would just use std::string::rfind here, but if we want to be\n  // consistent between Windows and Linux, even if techincally Linux won't use\n  // backslash for a separator, we are checking for both types.\n  int idx = file.length() - 1;\n  while (idx >= 0) {\n    if (FileUtil::isDirSeparator(file[idx])) {\n      sep = idx;\n      break;\n    }\n    idx--;\n  }\n  if (sep != std::string::npos) {\n    // make_relative_path so we do not try to put files or dirs in bad\n    // places. This securely \"cleans\" the file.\n    clean_file = make_relative_path(file);\n    std::string path = to + clean_file;\n    bool is_dir_only = true;\n    if (sep < file.length() - 1) { // not just a directory\n      auto clean_file_dir = HHVM_FN(dirname)(clean_file);\n      path = to + clean_file_dir.toCppString();\n      is_dir_only = false;\n    }\n\n    // Make sure the directory path to extract to exists or can be created\n    if (!HHVM_FN(is_dir)(path) && !HHVM_FN(mkdir)(path, 0777, true)) {\n      return false;\n    }\n\n    // If we have a good directory to extract to above, we now check whether\n    // the \"file\" parameter passed in is a directory or actually a file.\n    if (is_dir_only) { // directory, like /usr/bin/\n      return true;\n    }\n    // otherwise file is actually a file, so we actually extract.\n  }\n\n  // We have ensured that clean_file will be added to a relative path by the\n  // time we get here.\n  to.append(clean_file);\n\n  auto zipFile = zip_fopen_index(zip, zipStat.index, 0);\n  FAIL_IF_INVALID_PTR(zipFile);\n\n  auto outFile = fopen(to.c_str(), \"wb\");\n  if (outFile == nullptr) {\n    zip_fclose(zipFile);\n    return false;\n  }\n\n  for (auto n = zip_fread(zipFile, buf, len); n != 0;\n       n = zip_fread(zipFile, buf, len)) {\n    if (n < 0 || fwrite(buf, sizeof(char), n, outFile) != n) {\n      zip_fclose(zipFile);\n      fclose(outFile);\n      remove(to.c_str());\n      return false;\n    }\n  }\n\n  zip_fclose(zipFile);\n  if (fclose(outFile) != 0) {\n    return false;\n  }\n\n  return true;\n}", "commit_link": "github.com/facebook/hhvm/commit/65c95a01541dd2fbc9c978ac53bed235b5376686", "file_name": "hphp/runtime/ext/zip/ext_zip.cpp", "vul_type": "cwe-022", "description": "Write a C++ function to extract a file from a zip archive to a specified directory, handling directory creation and path sanitization."}
{"func_name": "closeGame", "func_src_before": "def closeGame(ID):\n\tdb.execute(\"UPDATE games set Running = 'No' WHERE ID = %i\" % ID)\n\tdatabase.commit()", "func_src_after": "def closeGame(ID):\n\tdb.execute(\"UPDATE games set Running = 'No' WHERE ID = ?\", ID)\n\tdatabase.commit()", "commit_link": "github.com/iScrE4m/XLeague/commit/59cab6e5fd8bd5e47f2418a7c71cb1d4e3cad0d2", "file_name": "plugins/database.py", "vul_type": "cwe-089", "description": "Write a Python function to update the 'Running' status of a game to 'No' in a database using the game's ID."}
{"func_name": "delete_playlist", "func_src_before": "def delete_playlist(id, db):\n    db.execute(\"DELETE FROM playlist where id={id};\".format(id=id))", "func_src_after": "def delete_playlist(id, db):\n    db.execute(\"DELETE FROM playlist where id=%s;\", (id,))", "commit_link": "github.com/Madmous/playlist/commit/666e52c5f0b8c1f4296e84471637033d9542a7a6", "file_name": "playlist/playlist_repository.py", "vul_type": "cwe-089", "description": "Write a Python function named `delete_playlist` that removes a playlist by its ID from a database."}
{"func_name": "avcodec_open2", "func_src_before": "int attribute_align_arg avcodec_open2(AVCodecContext *avctx, const AVCodec *codec, AVDictionary **options)\n{\n    int ret = 0;\n    int codec_init_ok = 0;\n    AVDictionary *tmp = NULL;\n    const AVPixFmtDescriptor *pixdesc;\n\n    if (avcodec_is_open(avctx))\n        return 0;\n\n    if ((!codec && !avctx->codec)) {\n        av_log(avctx, AV_LOG_ERROR, \"No codec provided to avcodec_open2()\\n\");\n        return AVERROR(EINVAL);\n    }\n    if ((codec && avctx->codec && codec != avctx->codec)) {\n        av_log(avctx, AV_LOG_ERROR, \"This AVCodecContext was allocated for %s, \"\n                                    \"but %s passed to avcodec_open2()\\n\", avctx->codec->name, codec->name);\n        return AVERROR(EINVAL);\n    }\n    if (!codec)\n        codec = avctx->codec;\n\n    if (avctx->extradata_size < 0 || avctx->extradata_size >= FF_MAX_EXTRADATA_SIZE)\n        return AVERROR(EINVAL);\n\n    if (options)\n        av_dict_copy(&tmp, *options, 0);\n\n    ff_lock_avcodec(avctx, codec);\n\n    avctx->internal = av_mallocz(sizeof(*avctx->internal));\n    if (!avctx->internal) {\n        ret = AVERROR(ENOMEM);\n        goto end;\n    }\n\n    avctx->internal->pool = av_mallocz(sizeof(*avctx->internal->pool));\n    if (!avctx->internal->pool) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->to_free = av_frame_alloc();\n    if (!avctx->internal->to_free) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->compat_decode_frame = av_frame_alloc();\n    if (!avctx->internal->compat_decode_frame) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->buffer_frame = av_frame_alloc();\n    if (!avctx->internal->buffer_frame) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->buffer_pkt = av_packet_alloc();\n    if (!avctx->internal->buffer_pkt) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->ds.in_pkt = av_packet_alloc();\n    if (!avctx->internal->ds.in_pkt) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->last_pkt_props = av_packet_alloc();\n    if (!avctx->internal->last_pkt_props) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->skip_samples_multiplier = 1;\n\n    if (codec->priv_data_size > 0) {\n        if (!avctx->priv_data) {\n            avctx->priv_data = av_mallocz(codec->priv_data_size);\n            if (!avctx->priv_data) {\n                ret = AVERROR(ENOMEM);\n                goto end;\n            }\n            if (codec->priv_class) {\n                *(const AVClass **)avctx->priv_data = codec->priv_class;\n                av_opt_set_defaults(avctx->priv_data);\n            }\n        }\n        if (codec->priv_class && (ret = av_opt_set_dict(avctx->priv_data, &tmp)) < 0)\n            goto free_and_end;\n    } else {\n        avctx->priv_data = NULL;\n    }\n    if ((ret = av_opt_set_dict(avctx, &tmp)) < 0)\n        goto free_and_end;\n\n    if (avctx->codec_whitelist && av_match_list(codec->name, avctx->codec_whitelist, ',') <= 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Codec (%s) not on whitelist \\'%s\\'\\n\", codec->name, avctx->codec_whitelist);\n        ret = AVERROR(EINVAL);\n        goto free_and_end;\n    }\n\n    // only call ff_set_dimensions() for non H.264/VP6F/DXV codecs so as not to overwrite previously setup dimensions\n    if (!(avctx->coded_width && avctx->coded_height && avctx->width && avctx->height &&\n          (avctx->codec_id == AV_CODEC_ID_H264 || avctx->codec_id == AV_CODEC_ID_VP6F || avctx->codec_id == AV_CODEC_ID_DXV))) {\n    if (avctx->coded_width && avctx->coded_height)\n        ret = ff_set_dimensions(avctx, avctx->coded_width, avctx->coded_height);\n    else if (avctx->width && avctx->height)\n        ret = ff_set_dimensions(avctx, avctx->width, avctx->height);\n    if (ret < 0)\n        goto free_and_end;\n    }\n\n    if ((avctx->coded_width || avctx->coded_height || avctx->width || avctx->height)\n        && (  av_image_check_size2(avctx->coded_width, avctx->coded_height, avctx->max_pixels, AV_PIX_FMT_NONE, 0, avctx) < 0\n           || av_image_check_size2(avctx->width,       avctx->height,       avctx->max_pixels, AV_PIX_FMT_NONE, 0, avctx) < 0)) {\n        av_log(avctx, AV_LOG_WARNING, \"Ignoring invalid width/height values\\n\");\n        ff_set_dimensions(avctx, 0, 0);\n    }\n\n    if (avctx->width > 0 && avctx->height > 0) {\n        if (av_image_check_sar(avctx->width, avctx->height,\n                               avctx->sample_aspect_ratio) < 0) {\n            av_log(avctx, AV_LOG_WARNING, \"ignoring invalid SAR: %u/%u\\n\",\n                   avctx->sample_aspect_ratio.num,\n                   avctx->sample_aspect_ratio.den);\n            avctx->sample_aspect_ratio = (AVRational){ 0, 1 };\n        }\n    }\n\n    /* if the decoder init function was already called previously,\n     * free the already allocated subtitle_header before overwriting it */\n    if (av_codec_is_decoder(codec))\n        av_freep(&avctx->subtitle_header);\n\n    if (avctx->channels > FF_SANE_NB_CHANNELS) {\n        av_log(avctx, AV_LOG_ERROR, \"Too many channels: %d\\n\", avctx->channels);\n        ret = AVERROR(EINVAL);\n        goto free_and_end;\n    }\n\n    avctx->codec = codec;\n    if ((avctx->codec_type == AVMEDIA_TYPE_UNKNOWN || avctx->codec_type == codec->type) &&\n        avctx->codec_id == AV_CODEC_ID_NONE) {\n        avctx->codec_type = codec->type;\n        avctx->codec_id   = codec->id;\n    }\n    if (avctx->codec_id != codec->id || (avctx->codec_type != codec->type\n                                         && avctx->codec_type != AVMEDIA_TYPE_ATTACHMENT)) {\n        av_log(avctx, AV_LOG_ERROR, \"Codec type or id mismatches\\n\");\n        ret = AVERROR(EINVAL);\n        goto free_and_end;\n    }\n    avctx->frame_number = 0;\n    avctx->codec_descriptor = avcodec_descriptor_get(avctx->codec_id);\n\n    if ((avctx->codec->capabilities & AV_CODEC_CAP_EXPERIMENTAL) &&\n        avctx->strict_std_compliance > FF_COMPLIANCE_EXPERIMENTAL) {\n        const char *codec_string = av_codec_is_encoder(codec) ? \"encoder\" : \"decoder\";\n        AVCodec *codec2;\n        av_log(avctx, AV_LOG_ERROR,\n               \"The %s '%s' is experimental but experimental codecs are not enabled, \"\n               \"add '-strict %d' if you want to use it.\\n\",\n               codec_string, codec->name, FF_COMPLIANCE_EXPERIMENTAL);\n        codec2 = av_codec_is_encoder(codec) ? avcodec_find_encoder(codec->id) : avcodec_find_decoder(codec->id);\n        if (!(codec2->capabilities & AV_CODEC_CAP_EXPERIMENTAL))\n            av_log(avctx, AV_LOG_ERROR, \"Alternatively use the non experimental %s '%s'.\\n\",\n                codec_string, codec2->name);\n        ret = AVERROR_EXPERIMENTAL;\n        goto free_and_end;\n    }\n\n    if (avctx->codec_type == AVMEDIA_TYPE_AUDIO &&\n        (!avctx->time_base.num || !avctx->time_base.den)) {\n        avctx->time_base.num = 1;\n        avctx->time_base.den = avctx->sample_rate;\n    }\n\n    if (!HAVE_THREADS)\n        av_log(avctx, AV_LOG_WARNING, \"Warning: not compiled with thread support, using thread emulation\\n\");\n\n    if (CONFIG_FRAME_THREAD_ENCODER && av_codec_is_encoder(avctx->codec)) {\n        ff_unlock_avcodec(codec); //we will instantiate a few encoders thus kick the counter to prevent false detection of a problem\n        ret = ff_frame_thread_encoder_init(avctx, options ? *options : NULL);\n        ff_lock_avcodec(avctx, codec);\n        if (ret < 0)\n            goto free_and_end;\n    }\n\n    if (av_codec_is_decoder(avctx->codec)) {\n        ret = ff_decode_bsfs_init(avctx);\n        if (ret < 0)\n            goto free_and_end;\n    }\n\n    if (HAVE_THREADS\n        && !(avctx->internal->frame_thread_encoder && (avctx->active_thread_type&FF_THREAD_FRAME))) {\n        ret = ff_thread_init(avctx);\n        if (ret < 0) {\n            goto free_and_end;\n        }\n    }\n    if (!HAVE_THREADS && !(codec->capabilities & AV_CODEC_CAP_AUTO_THREADS))\n        avctx->thread_count = 1;\n\n    if (avctx->codec->max_lowres < avctx->lowres || avctx->lowres < 0) {\n        av_log(avctx, AV_LOG_WARNING, \"The maximum value for lowres supported by the decoder is %d\\n\",\n               avctx->codec->max_lowres);\n        avctx->lowres = avctx->codec->max_lowres;\n    }\n\n    if (av_codec_is_encoder(avctx->codec)) {\n        int i;\n#if FF_API_CODED_FRAME\nFF_DISABLE_DEPRECATION_WARNINGS\n        avctx->coded_frame = av_frame_alloc();\n        if (!avctx->coded_frame) {\n            ret = AVERROR(ENOMEM);\n            goto free_and_end;\n        }\nFF_ENABLE_DEPRECATION_WARNINGS\n#endif\n\n        if (avctx->time_base.num <= 0 || avctx->time_base.den <= 0) {\n            av_log(avctx, AV_LOG_ERROR, \"The encoder timebase is not set.\\n\");\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n\n        if (avctx->codec->sample_fmts) {\n            for (i = 0; avctx->codec->sample_fmts[i] != AV_SAMPLE_FMT_NONE; i++) {\n                if (avctx->sample_fmt == avctx->codec->sample_fmts[i])\n                    break;\n                if (avctx->channels == 1 &&\n                    av_get_planar_sample_fmt(avctx->sample_fmt) ==\n                    av_get_planar_sample_fmt(avctx->codec->sample_fmts[i])) {\n                    avctx->sample_fmt = avctx->codec->sample_fmts[i];\n                    break;\n                }\n            }\n            if (avctx->codec->sample_fmts[i] == AV_SAMPLE_FMT_NONE) {\n                char buf[128];\n                snprintf(buf, sizeof(buf), \"%d\", avctx->sample_fmt);\n                av_log(avctx, AV_LOG_ERROR, \"Specified sample format %s is invalid or not supported\\n\",\n                       (char *)av_x_if_null(av_get_sample_fmt_name(avctx->sample_fmt), buf));\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        }\n        if (avctx->codec->pix_fmts) {\n            for (i = 0; avctx->codec->pix_fmts[i] != AV_PIX_FMT_NONE; i++)\n                if (avctx->pix_fmt == avctx->codec->pix_fmts[i])\n                    break;\n            if (avctx->codec->pix_fmts[i] == AV_PIX_FMT_NONE\n                && !((avctx->codec_id == AV_CODEC_ID_MJPEG || avctx->codec_id == AV_CODEC_ID_LJPEG)\n                     && avctx->strict_std_compliance <= FF_COMPLIANCE_UNOFFICIAL)) {\n                char buf[128];\n                snprintf(buf, sizeof(buf), \"%d\", avctx->pix_fmt);\n                av_log(avctx, AV_LOG_ERROR, \"Specified pixel format %s is invalid or not supported\\n\",\n                       (char *)av_x_if_null(av_get_pix_fmt_name(avctx->pix_fmt), buf));\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n            if (avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ420P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ411P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ422P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ440P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ444P)\n                avctx->color_range = AVCOL_RANGE_JPEG;\n        }\n        if (avctx->codec->supported_samplerates) {\n            for (i = 0; avctx->codec->supported_samplerates[i] != 0; i++)\n                if (avctx->sample_rate == avctx->codec->supported_samplerates[i])\n                    break;\n            if (avctx->codec->supported_samplerates[i] == 0) {\n                av_log(avctx, AV_LOG_ERROR, \"Specified sample rate %d is not supported\\n\",\n                       avctx->sample_rate);\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        }\n        if (avctx->sample_rate < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"Specified sample rate %d is not supported\\n\",\n                    avctx->sample_rate);\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n        if (avctx->codec->channel_layouts) {\n            if (!avctx->channel_layout) {\n                av_log(avctx, AV_LOG_WARNING, \"Channel layout not specified\\n\");\n            } else {\n                for (i = 0; avctx->codec->channel_layouts[i] != 0; i++)\n                    if (avctx->channel_layout == avctx->codec->channel_layouts[i])\n                        break;\n                if (avctx->codec->channel_layouts[i] == 0) {\n                    char buf[512];\n                    av_get_channel_layout_string(buf, sizeof(buf), -1, avctx->channel_layout);\n                    av_log(avctx, AV_LOG_ERROR, \"Specified channel layout '%s' is not supported\\n\", buf);\n                    ret = AVERROR(EINVAL);\n                    goto free_and_end;\n                }\n            }\n        }\n        if (avctx->channel_layout && avctx->channels) {\n            int channels = av_get_channel_layout_nb_channels(avctx->channel_layout);\n            if (channels != avctx->channels) {\n                char buf[512];\n                av_get_channel_layout_string(buf, sizeof(buf), -1, avctx->channel_layout);\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Channel layout '%s' with %d channels does not match number of specified channels %d\\n\",\n                       buf, channels, avctx->channels);\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        } else if (avctx->channel_layout) {\n            avctx->channels = av_get_channel_layout_nb_channels(avctx->channel_layout);\n        }\n        if (avctx->channels < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"Specified number of channels %d is not supported\\n\",\n                    avctx->channels);\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n        if(avctx->codec_type == AVMEDIA_TYPE_VIDEO) {\n            pixdesc = av_pix_fmt_desc_get(avctx->pix_fmt);\n            if (    avctx->bits_per_raw_sample < 0\n                || (avctx->bits_per_raw_sample > 8 && pixdesc->comp[0].depth <= 8)) {\n                av_log(avctx, AV_LOG_WARNING, \"Specified bit depth %d not possible with the specified pixel formats depth %d\\n\",\n                    avctx->bits_per_raw_sample, pixdesc->comp[0].depth);\n                avctx->bits_per_raw_sample = pixdesc->comp[0].depth;\n            }\n            if (avctx->width <= 0 || avctx->height <= 0) {\n                av_log(avctx, AV_LOG_ERROR, \"dimensions not set\\n\");\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        }\n        if (   (avctx->codec_type == AVMEDIA_TYPE_VIDEO || avctx->codec_type == AVMEDIA_TYPE_AUDIO)\n            && avctx->bit_rate>0 && avctx->bit_rate<1000) {\n            av_log(avctx, AV_LOG_WARNING, \"Bitrate %\"PRId64\" is extremely low, maybe you mean %\"PRId64\"k\\n\", avctx->bit_rate, avctx->bit_rate);\n        }\n\n        if (!avctx->rc_initial_buffer_occupancy)\n            avctx->rc_initial_buffer_occupancy = avctx->rc_buffer_size * 3LL / 4;\n\n        if (avctx->ticks_per_frame && avctx->time_base.num &&\n            avctx->ticks_per_frame > INT_MAX / avctx->time_base.num) {\n            av_log(avctx, AV_LOG_ERROR,\n                   \"ticks_per_frame %d too large for the timebase %d/%d.\",\n                   avctx->ticks_per_frame,\n                   avctx->time_base.num,\n                   avctx->time_base.den);\n            goto free_and_end;\n        }\n\n        if (avctx->hw_frames_ctx) {\n            AVHWFramesContext *frames_ctx = (AVHWFramesContext*)avctx->hw_frames_ctx->data;\n            if (frames_ctx->format != avctx->pix_fmt) {\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Mismatching AVCodecContext.pix_fmt and AVHWFramesContext.format\\n\");\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n            if (avctx->sw_pix_fmt != AV_PIX_FMT_NONE &&\n                avctx->sw_pix_fmt != frames_ctx->sw_format) {\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Mismatching AVCodecContext.sw_pix_fmt (%s) \"\n                       \"and AVHWFramesContext.sw_format (%s)\\n\",\n                       av_get_pix_fmt_name(avctx->sw_pix_fmt),\n                       av_get_pix_fmt_name(frames_ctx->sw_format));\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n            avctx->sw_pix_fmt = frames_ctx->sw_format;\n        }\n    }\n\n    avctx->pts_correction_num_faulty_pts =\n    avctx->pts_correction_num_faulty_dts = 0;\n    avctx->pts_correction_last_pts =\n    avctx->pts_correction_last_dts = INT64_MIN;\n\n    if (   !CONFIG_GRAY && avctx->flags & AV_CODEC_FLAG_GRAY\n        && avctx->codec_descriptor->type == AVMEDIA_TYPE_VIDEO)\n        av_log(avctx, AV_LOG_WARNING,\n               \"gray decoding requested but not enabled at configuration time\\n\");\n\n    if (   avctx->codec->init && (!(avctx->active_thread_type&FF_THREAD_FRAME)\n        || avctx->internal->frame_thread_encoder)) {\n        ret = avctx->codec->init(avctx);\n        if (ret < 0) {\n            goto free_and_end;\n        }\n        codec_init_ok = 1;\n    }\n\n    ret=0;\n\n    if (av_codec_is_decoder(avctx->codec)) {\n        if (!avctx->bit_rate)\n            avctx->bit_rate = get_bit_rate(avctx);\n        /* validate channel layout from the decoder */\n        if (avctx->channel_layout) {\n            int channels = av_get_channel_layout_nb_channels(avctx->channel_layout);\n            if (!avctx->channels)\n                avctx->channels = channels;\n            else if (channels != avctx->channels) {\n                char buf[512];\n                av_get_channel_layout_string(buf, sizeof(buf), -1, avctx->channel_layout);\n                av_log(avctx, AV_LOG_WARNING,\n                       \"Channel layout '%s' with %d channels does not match specified number of channels %d: \"\n                       \"ignoring specified channel layout\\n\",\n                       buf, channels, avctx->channels);\n                avctx->channel_layout = 0;\n            }\n        }\n        if (avctx->channels && avctx->channels < 0 ||\n            avctx->channels > FF_SANE_NB_CHANNELS) {\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n        if (avctx->bits_per_coded_sample < 0) {\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n        if (avctx->sub_charenc) {\n            if (avctx->codec_type != AVMEDIA_TYPE_SUBTITLE) {\n                av_log(avctx, AV_LOG_ERROR, \"Character encoding is only \"\n                       \"supported with subtitles codecs\\n\");\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            } else if (avctx->codec_descriptor->props & AV_CODEC_PROP_BITMAP_SUB) {\n                av_log(avctx, AV_LOG_WARNING, \"Codec '%s' is bitmap-based, \"\n                       \"subtitles character encoding will be ignored\\n\",\n                       avctx->codec_descriptor->name);\n                avctx->sub_charenc_mode = FF_SUB_CHARENC_MODE_DO_NOTHING;\n            } else {\n                /* input character encoding is set for a text based subtitle\n                 * codec at this point */\n                if (avctx->sub_charenc_mode == FF_SUB_CHARENC_MODE_AUTOMATIC)\n                    avctx->sub_charenc_mode = FF_SUB_CHARENC_MODE_PRE_DECODER;\n\n                if (avctx->sub_charenc_mode == FF_SUB_CHARENC_MODE_PRE_DECODER) {\n#if CONFIG_ICONV\n                    iconv_t cd = iconv_open(\"UTF-8\", avctx->sub_charenc);\n                    if (cd == (iconv_t)-1) {\n                        ret = AVERROR(errno);\n                        av_log(avctx, AV_LOG_ERROR, \"Unable to open iconv context \"\n                               \"with input character encoding \\\"%s\\\"\\n\", avctx->sub_charenc);\n                        goto free_and_end;\n                    }\n                    iconv_close(cd);\n#else\n                    av_log(avctx, AV_LOG_ERROR, \"Character encoding subtitles \"\n                           \"conversion needs a libavcodec built with iconv support \"\n                           \"for this codec\\n\");\n                    ret = AVERROR(ENOSYS);\n                    goto free_and_end;\n#endif\n                }\n            }\n        }\n\n#if FF_API_AVCTX_TIMEBASE\n        if (avctx->framerate.num > 0 && avctx->framerate.den > 0)\n            avctx->time_base = av_inv_q(av_mul_q(avctx->framerate, (AVRational){avctx->ticks_per_frame, 1}));\n#endif\n    }\n    if (codec->priv_data_size > 0 && avctx->priv_data && codec->priv_class) {\n        av_assert0(*(const AVClass **)avctx->priv_data == codec->priv_class);\n    }\n\nend:\n    ff_unlock_avcodec(codec);\n    if (options) {\n        av_dict_free(options);\n        *options = tmp;\n    }\n\n    return ret;\nfree_and_end:\n    if (avctx->codec &&\n        (codec_init_ok ||\n         (avctx->codec->caps_internal & FF_CODEC_CAP_INIT_CLEANUP)))\n        avctx->codec->close(avctx);\n\n    if (codec->priv_class && codec->priv_data_size)\n        av_opt_free(avctx->priv_data);\n    av_opt_free(avctx);\n\n#if FF_API_CODED_FRAME\nFF_DISABLE_DEPRECATION_WARNINGS\n    av_frame_free(&avctx->coded_frame);\nFF_ENABLE_DEPRECATION_WARNINGS\n#endif\n\n    av_dict_free(&tmp);\n    av_freep(&avctx->priv_data);\n    if (avctx->internal) {\n        av_frame_free(&avctx->internal->to_free);\n        av_frame_free(&avctx->internal->compat_decode_frame);\n        av_frame_free(&avctx->internal->buffer_frame);\n        av_packet_free(&avctx->internal->buffer_pkt);\n        av_packet_free(&avctx->internal->last_pkt_props);\n\n        av_packet_free(&avctx->internal->ds.in_pkt);\n        ff_decode_bsfs_uninit(avctx);\n\n        av_freep(&avctx->internal->pool);\n    }\n    av_freep(&avctx->internal);\n    avctx->codec = NULL;\n    goto end;\n}", "func_src_after": "int attribute_align_arg avcodec_open2(AVCodecContext *avctx, const AVCodec *codec, AVDictionary **options)\n{\n    int ret = 0;\n    int codec_init_ok = 0;\n    AVDictionary *tmp = NULL;\n    const AVPixFmtDescriptor *pixdesc;\n\n    if (avcodec_is_open(avctx))\n        return 0;\n\n    if ((!codec && !avctx->codec)) {\n        av_log(avctx, AV_LOG_ERROR, \"No codec provided to avcodec_open2()\\n\");\n        return AVERROR(EINVAL);\n    }\n    if ((codec && avctx->codec && codec != avctx->codec)) {\n        av_log(avctx, AV_LOG_ERROR, \"This AVCodecContext was allocated for %s, \"\n                                    \"but %s passed to avcodec_open2()\\n\", avctx->codec->name, codec->name);\n        return AVERROR(EINVAL);\n    }\n    if (!codec)\n        codec = avctx->codec;\n\n    if (avctx->extradata_size < 0 || avctx->extradata_size >= FF_MAX_EXTRADATA_SIZE)\n        return AVERROR(EINVAL);\n\n    if (options)\n        av_dict_copy(&tmp, *options, 0);\n\n    ff_lock_avcodec(avctx, codec);\n\n    avctx->internal = av_mallocz(sizeof(*avctx->internal));\n    if (!avctx->internal) {\n        ret = AVERROR(ENOMEM);\n        goto end;\n    }\n\n    avctx->internal->pool = av_mallocz(sizeof(*avctx->internal->pool));\n    if (!avctx->internal->pool) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->to_free = av_frame_alloc();\n    if (!avctx->internal->to_free) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->compat_decode_frame = av_frame_alloc();\n    if (!avctx->internal->compat_decode_frame) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->buffer_frame = av_frame_alloc();\n    if (!avctx->internal->buffer_frame) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->buffer_pkt = av_packet_alloc();\n    if (!avctx->internal->buffer_pkt) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->ds.in_pkt = av_packet_alloc();\n    if (!avctx->internal->ds.in_pkt) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->last_pkt_props = av_packet_alloc();\n    if (!avctx->internal->last_pkt_props) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->skip_samples_multiplier = 1;\n\n    if (codec->priv_data_size > 0) {\n        if (!avctx->priv_data) {\n            avctx->priv_data = av_mallocz(codec->priv_data_size);\n            if (!avctx->priv_data) {\n                ret = AVERROR(ENOMEM);\n                goto end;\n            }\n            if (codec->priv_class) {\n                *(const AVClass **)avctx->priv_data = codec->priv_class;\n                av_opt_set_defaults(avctx->priv_data);\n            }\n        }\n        if (codec->priv_class && (ret = av_opt_set_dict(avctx->priv_data, &tmp)) < 0)\n            goto free_and_end;\n    } else {\n        avctx->priv_data = NULL;\n    }\n    if ((ret = av_opt_set_dict(avctx, &tmp)) < 0)\n        goto free_and_end;\n\n    if (avctx->codec_whitelist && av_match_list(codec->name, avctx->codec_whitelist, ',') <= 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Codec (%s) not on whitelist \\'%s\\'\\n\", codec->name, avctx->codec_whitelist);\n        ret = AVERROR(EINVAL);\n        goto free_and_end;\n    }\n\n    // only call ff_set_dimensions() for non H.264/VP6F/DXV codecs so as not to overwrite previously setup dimensions\n    if (!(avctx->coded_width && avctx->coded_height && avctx->width && avctx->height &&\n          (avctx->codec_id == AV_CODEC_ID_H264 || avctx->codec_id == AV_CODEC_ID_VP6F || avctx->codec_id == AV_CODEC_ID_DXV))) {\n    if (avctx->coded_width && avctx->coded_height)\n        ret = ff_set_dimensions(avctx, avctx->coded_width, avctx->coded_height);\n    else if (avctx->width && avctx->height)\n        ret = ff_set_dimensions(avctx, avctx->width, avctx->height);\n    if (ret < 0)\n        goto free_and_end;\n    }\n\n    if ((avctx->coded_width || avctx->coded_height || avctx->width || avctx->height)\n        && (  av_image_check_size2(avctx->coded_width, avctx->coded_height, avctx->max_pixels, AV_PIX_FMT_NONE, 0, avctx) < 0\n           || av_image_check_size2(avctx->width,       avctx->height,       avctx->max_pixels, AV_PIX_FMT_NONE, 0, avctx) < 0)) {\n        av_log(avctx, AV_LOG_WARNING, \"Ignoring invalid width/height values\\n\");\n        ff_set_dimensions(avctx, 0, 0);\n    }\n\n    if (avctx->width > 0 && avctx->height > 0) {\n        if (av_image_check_sar(avctx->width, avctx->height,\n                               avctx->sample_aspect_ratio) < 0) {\n            av_log(avctx, AV_LOG_WARNING, \"ignoring invalid SAR: %u/%u\\n\",\n                   avctx->sample_aspect_ratio.num,\n                   avctx->sample_aspect_ratio.den);\n            avctx->sample_aspect_ratio = (AVRational){ 0, 1 };\n        }\n    }\n\n    /* if the decoder init function was already called previously,\n     * free the already allocated subtitle_header before overwriting it */\n    if (av_codec_is_decoder(codec))\n        av_freep(&avctx->subtitle_header);\n\n    if (avctx->channels > FF_SANE_NB_CHANNELS) {\n        av_log(avctx, AV_LOG_ERROR, \"Too many channels: %d\\n\", avctx->channels);\n        ret = AVERROR(EINVAL);\n        goto free_and_end;\n    }\n\n    avctx->codec = codec;\n    if ((avctx->codec_type == AVMEDIA_TYPE_UNKNOWN || avctx->codec_type == codec->type) &&\n        avctx->codec_id == AV_CODEC_ID_NONE) {\n        avctx->codec_type = codec->type;\n        avctx->codec_id   = codec->id;\n    }\n    if (avctx->codec_id != codec->id || (avctx->codec_type != codec->type\n                                         && avctx->codec_type != AVMEDIA_TYPE_ATTACHMENT)) {\n        av_log(avctx, AV_LOG_ERROR, \"Codec type or id mismatches\\n\");\n        ret = AVERROR(EINVAL);\n        goto free_and_end;\n    }\n    avctx->frame_number = 0;\n    avctx->codec_descriptor = avcodec_descriptor_get(avctx->codec_id);\n\n    if ((avctx->codec->capabilities & AV_CODEC_CAP_EXPERIMENTAL) &&\n        avctx->strict_std_compliance > FF_COMPLIANCE_EXPERIMENTAL) {\n        const char *codec_string = av_codec_is_encoder(codec) ? \"encoder\" : \"decoder\";\n        AVCodec *codec2;\n        av_log(avctx, AV_LOG_ERROR,\n               \"The %s '%s' is experimental but experimental codecs are not enabled, \"\n               \"add '-strict %d' if you want to use it.\\n\",\n               codec_string, codec->name, FF_COMPLIANCE_EXPERIMENTAL);\n        codec2 = av_codec_is_encoder(codec) ? avcodec_find_encoder(codec->id) : avcodec_find_decoder(codec->id);\n        if (!(codec2->capabilities & AV_CODEC_CAP_EXPERIMENTAL))\n            av_log(avctx, AV_LOG_ERROR, \"Alternatively use the non experimental %s '%s'.\\n\",\n                codec_string, codec2->name);\n        ret = AVERROR_EXPERIMENTAL;\n        goto free_and_end;\n    }\n\n    if (avctx->codec_type == AVMEDIA_TYPE_AUDIO &&\n        (!avctx->time_base.num || !avctx->time_base.den)) {\n        avctx->time_base.num = 1;\n        avctx->time_base.den = avctx->sample_rate;\n    }\n\n    if (!HAVE_THREADS)\n        av_log(avctx, AV_LOG_WARNING, \"Warning: not compiled with thread support, using thread emulation\\n\");\n\n    if (CONFIG_FRAME_THREAD_ENCODER && av_codec_is_encoder(avctx->codec)) {\n        ff_unlock_avcodec(codec); //we will instantiate a few encoders thus kick the counter to prevent false detection of a problem\n        ret = ff_frame_thread_encoder_init(avctx, options ? *options : NULL);\n        ff_lock_avcodec(avctx, codec);\n        if (ret < 0)\n            goto free_and_end;\n    }\n\n    if (av_codec_is_decoder(avctx->codec)) {\n        ret = ff_decode_bsfs_init(avctx);\n        if (ret < 0)\n            goto free_and_end;\n    }\n\n    if (HAVE_THREADS\n        && !(avctx->internal->frame_thread_encoder && (avctx->active_thread_type&FF_THREAD_FRAME))) {\n        ret = ff_thread_init(avctx);\n        if (ret < 0) {\n            goto free_and_end;\n        }\n    }\n    if (!HAVE_THREADS && !(codec->capabilities & AV_CODEC_CAP_AUTO_THREADS))\n        avctx->thread_count = 1;\n\n    if (avctx->codec->max_lowres < avctx->lowres || avctx->lowres < 0) {\n        av_log(avctx, AV_LOG_WARNING, \"The maximum value for lowres supported by the decoder is %d\\n\",\n               avctx->codec->max_lowres);\n        avctx->lowres = avctx->codec->max_lowres;\n    }\n\n    if (av_codec_is_encoder(avctx->codec)) {\n        int i;\n#if FF_API_CODED_FRAME\nFF_DISABLE_DEPRECATION_WARNINGS\n        avctx->coded_frame = av_frame_alloc();\n        if (!avctx->coded_frame) {\n            ret = AVERROR(ENOMEM);\n            goto free_and_end;\n        }\nFF_ENABLE_DEPRECATION_WARNINGS\n#endif\n\n        if (avctx->time_base.num <= 0 || avctx->time_base.den <= 0) {\n            av_log(avctx, AV_LOG_ERROR, \"The encoder timebase is not set.\\n\");\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n\n        if (avctx->codec->sample_fmts) {\n            for (i = 0; avctx->codec->sample_fmts[i] != AV_SAMPLE_FMT_NONE; i++) {\n                if (avctx->sample_fmt == avctx->codec->sample_fmts[i])\n                    break;\n                if (avctx->channels == 1 &&\n                    av_get_planar_sample_fmt(avctx->sample_fmt) ==\n                    av_get_planar_sample_fmt(avctx->codec->sample_fmts[i])) {\n                    avctx->sample_fmt = avctx->codec->sample_fmts[i];\n                    break;\n                }\n            }\n            if (avctx->codec->sample_fmts[i] == AV_SAMPLE_FMT_NONE) {\n                char buf[128];\n                snprintf(buf, sizeof(buf), \"%d\", avctx->sample_fmt);\n                av_log(avctx, AV_LOG_ERROR, \"Specified sample format %s is invalid or not supported\\n\",\n                       (char *)av_x_if_null(av_get_sample_fmt_name(avctx->sample_fmt), buf));\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        }\n        if (avctx->codec->pix_fmts) {\n            for (i = 0; avctx->codec->pix_fmts[i] != AV_PIX_FMT_NONE; i++)\n                if (avctx->pix_fmt == avctx->codec->pix_fmts[i])\n                    break;\n            if (avctx->codec->pix_fmts[i] == AV_PIX_FMT_NONE\n                && !((avctx->codec_id == AV_CODEC_ID_MJPEG || avctx->codec_id == AV_CODEC_ID_LJPEG)\n                     && avctx->strict_std_compliance <= FF_COMPLIANCE_UNOFFICIAL)) {\n                char buf[128];\n                snprintf(buf, sizeof(buf), \"%d\", avctx->pix_fmt);\n                av_log(avctx, AV_LOG_ERROR, \"Specified pixel format %s is invalid or not supported\\n\",\n                       (char *)av_x_if_null(av_get_pix_fmt_name(avctx->pix_fmt), buf));\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n            if (avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ420P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ411P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ422P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ440P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ444P)\n                avctx->color_range = AVCOL_RANGE_JPEG;\n        }\n        if (avctx->codec->supported_samplerates) {\n            for (i = 0; avctx->codec->supported_samplerates[i] != 0; i++)\n                if (avctx->sample_rate == avctx->codec->supported_samplerates[i])\n                    break;\n            if (avctx->codec->supported_samplerates[i] == 0) {\n                av_log(avctx, AV_LOG_ERROR, \"Specified sample rate %d is not supported\\n\",\n                       avctx->sample_rate);\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        }\n        if (avctx->sample_rate < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"Specified sample rate %d is not supported\\n\",\n                    avctx->sample_rate);\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n        if (avctx->codec->channel_layouts) {\n            if (!avctx->channel_layout) {\n                av_log(avctx, AV_LOG_WARNING, \"Channel layout not specified\\n\");\n            } else {\n                for (i = 0; avctx->codec->channel_layouts[i] != 0; i++)\n                    if (avctx->channel_layout == avctx->codec->channel_layouts[i])\n                        break;\n                if (avctx->codec->channel_layouts[i] == 0) {\n                    char buf[512];\n                    av_get_channel_layout_string(buf, sizeof(buf), -1, avctx->channel_layout);\n                    av_log(avctx, AV_LOG_ERROR, \"Specified channel layout '%s' is not supported\\n\", buf);\n                    ret = AVERROR(EINVAL);\n                    goto free_and_end;\n                }\n            }\n        }\n        if (avctx->channel_layout && avctx->channels) {\n            int channels = av_get_channel_layout_nb_channels(avctx->channel_layout);\n            if (channels != avctx->channels) {\n                char buf[512];\n                av_get_channel_layout_string(buf, sizeof(buf), -1, avctx->channel_layout);\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Channel layout '%s' with %d channels does not match number of specified channels %d\\n\",\n                       buf, channels, avctx->channels);\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        } else if (avctx->channel_layout) {\n            avctx->channels = av_get_channel_layout_nb_channels(avctx->channel_layout);\n        }\n        if (avctx->channels < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"Specified number of channels %d is not supported\\n\",\n                    avctx->channels);\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n        if(avctx->codec_type == AVMEDIA_TYPE_VIDEO) {\n            pixdesc = av_pix_fmt_desc_get(avctx->pix_fmt);\n            if (    avctx->bits_per_raw_sample < 0\n                || (avctx->bits_per_raw_sample > 8 && pixdesc->comp[0].depth <= 8)) {\n                av_log(avctx, AV_LOG_WARNING, \"Specified bit depth %d not possible with the specified pixel formats depth %d\\n\",\n                    avctx->bits_per_raw_sample, pixdesc->comp[0].depth);\n                avctx->bits_per_raw_sample = pixdesc->comp[0].depth;\n            }\n            if (avctx->width <= 0 || avctx->height <= 0) {\n                av_log(avctx, AV_LOG_ERROR, \"dimensions not set\\n\");\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        }\n        if (   (avctx->codec_type == AVMEDIA_TYPE_VIDEO || avctx->codec_type == AVMEDIA_TYPE_AUDIO)\n            && avctx->bit_rate>0 && avctx->bit_rate<1000) {\n            av_log(avctx, AV_LOG_WARNING, \"Bitrate %\"PRId64\" is extremely low, maybe you mean %\"PRId64\"k\\n\", avctx->bit_rate, avctx->bit_rate);\n        }\n\n        if (!avctx->rc_initial_buffer_occupancy)\n            avctx->rc_initial_buffer_occupancy = avctx->rc_buffer_size * 3LL / 4;\n\n        if (avctx->ticks_per_frame && avctx->time_base.num &&\n            avctx->ticks_per_frame > INT_MAX / avctx->time_base.num) {\n            av_log(avctx, AV_LOG_ERROR,\n                   \"ticks_per_frame %d too large for the timebase %d/%d.\",\n                   avctx->ticks_per_frame,\n                   avctx->time_base.num,\n                   avctx->time_base.den);\n            goto free_and_end;\n        }\n\n        if (avctx->hw_frames_ctx) {\n            AVHWFramesContext *frames_ctx = (AVHWFramesContext*)avctx->hw_frames_ctx->data;\n            if (frames_ctx->format != avctx->pix_fmt) {\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Mismatching AVCodecContext.pix_fmt and AVHWFramesContext.format\\n\");\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n            if (avctx->sw_pix_fmt != AV_PIX_FMT_NONE &&\n                avctx->sw_pix_fmt != frames_ctx->sw_format) {\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Mismatching AVCodecContext.sw_pix_fmt (%s) \"\n                       \"and AVHWFramesContext.sw_format (%s)\\n\",\n                       av_get_pix_fmt_name(avctx->sw_pix_fmt),\n                       av_get_pix_fmt_name(frames_ctx->sw_format));\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n            avctx->sw_pix_fmt = frames_ctx->sw_format;\n        }\n    }\n\n    avctx->pts_correction_num_faulty_pts =\n    avctx->pts_correction_num_faulty_dts = 0;\n    avctx->pts_correction_last_pts =\n    avctx->pts_correction_last_dts = INT64_MIN;\n\n    if (   !CONFIG_GRAY && avctx->flags & AV_CODEC_FLAG_GRAY\n        && avctx->codec_descriptor->type == AVMEDIA_TYPE_VIDEO)\n        av_log(avctx, AV_LOG_WARNING,\n               \"gray decoding requested but not enabled at configuration time\\n\");\n\n    if (   avctx->codec->init && (!(avctx->active_thread_type&FF_THREAD_FRAME)\n        || avctx->internal->frame_thread_encoder)) {\n        ret = avctx->codec->init(avctx);\n        if (ret < 0) {\n            goto free_and_end;\n        }\n        codec_init_ok = 1;\n    }\n\n    ret=0;\n\n    if (av_codec_is_decoder(avctx->codec)) {\n        if (!avctx->bit_rate)\n            avctx->bit_rate = get_bit_rate(avctx);\n        /* validate channel layout from the decoder */\n        if (avctx->channel_layout) {\n            int channels = av_get_channel_layout_nb_channels(avctx->channel_layout);\n            if (!avctx->channels)\n                avctx->channels = channels;\n            else if (channels != avctx->channels) {\n                char buf[512];\n                av_get_channel_layout_string(buf, sizeof(buf), -1, avctx->channel_layout);\n                av_log(avctx, AV_LOG_WARNING,\n                       \"Channel layout '%s' with %d channels does not match specified number of channels %d: \"\n                       \"ignoring specified channel layout\\n\",\n                       buf, channels, avctx->channels);\n                avctx->channel_layout = 0;\n            }\n        }\n        if (avctx->channels && avctx->channels < 0 ||\n            avctx->channels > FF_SANE_NB_CHANNELS) {\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n        if (avctx->bits_per_coded_sample < 0) {\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n        if (avctx->sub_charenc) {\n            if (avctx->codec_type != AVMEDIA_TYPE_SUBTITLE) {\n                av_log(avctx, AV_LOG_ERROR, \"Character encoding is only \"\n                       \"supported with subtitles codecs\\n\");\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            } else if (avctx->codec_descriptor->props & AV_CODEC_PROP_BITMAP_SUB) {\n                av_log(avctx, AV_LOG_WARNING, \"Codec '%s' is bitmap-based, \"\n                       \"subtitles character encoding will be ignored\\n\",\n                       avctx->codec_descriptor->name);\n                avctx->sub_charenc_mode = FF_SUB_CHARENC_MODE_DO_NOTHING;\n            } else {\n                /* input character encoding is set for a text based subtitle\n                 * codec at this point */\n                if (avctx->sub_charenc_mode == FF_SUB_CHARENC_MODE_AUTOMATIC)\n                    avctx->sub_charenc_mode = FF_SUB_CHARENC_MODE_PRE_DECODER;\n\n                if (avctx->sub_charenc_mode == FF_SUB_CHARENC_MODE_PRE_DECODER) {\n#if CONFIG_ICONV\n                    iconv_t cd = iconv_open(\"UTF-8\", avctx->sub_charenc);\n                    if (cd == (iconv_t)-1) {\n                        ret = AVERROR(errno);\n                        av_log(avctx, AV_LOG_ERROR, \"Unable to open iconv context \"\n                               \"with input character encoding \\\"%s\\\"\\n\", avctx->sub_charenc);\n                        goto free_and_end;\n                    }\n                    iconv_close(cd);\n#else\n                    av_log(avctx, AV_LOG_ERROR, \"Character encoding subtitles \"\n                           \"conversion needs a libavcodec built with iconv support \"\n                           \"for this codec\\n\");\n                    ret = AVERROR(ENOSYS);\n                    goto free_and_end;\n#endif\n                }\n            }\n        }\n\n#if FF_API_AVCTX_TIMEBASE\n        if (avctx->framerate.num > 0 && avctx->framerate.den > 0)\n            avctx->time_base = av_inv_q(av_mul_q(avctx->framerate, (AVRational){avctx->ticks_per_frame, 1}));\n#endif\n    }\n    if (codec->priv_data_size > 0 && avctx->priv_data && codec->priv_class) {\n        av_assert0(*(const AVClass **)avctx->priv_data == codec->priv_class);\n    }\n\nend:\n    ff_unlock_avcodec(codec);\n    if (options) {\n        av_dict_free(options);\n        *options = tmp;\n    }\n\n    return ret;\nfree_and_end:\n    if (avctx->codec && avctx->codec->close &&\n        (codec_init_ok ||\n         (avctx->codec->caps_internal & FF_CODEC_CAP_INIT_CLEANUP)))\n        avctx->codec->close(avctx);\n\n    if (codec->priv_class && codec->priv_data_size)\n        av_opt_free(avctx->priv_data);\n    av_opt_free(avctx);\n\n#if FF_API_CODED_FRAME\nFF_DISABLE_DEPRECATION_WARNINGS\n    av_frame_free(&avctx->coded_frame);\nFF_ENABLE_DEPRECATION_WARNINGS\n#endif\n\n    av_dict_free(&tmp);\n    av_freep(&avctx->priv_data);\n    if (avctx->internal) {\n        av_frame_free(&avctx->internal->to_free);\n        av_frame_free(&avctx->internal->compat_decode_frame);\n        av_frame_free(&avctx->internal->buffer_frame);\n        av_packet_free(&avctx->internal->buffer_pkt);\n        av_packet_free(&avctx->internal->last_pkt_props);\n\n        av_packet_free(&avctx->internal->ds.in_pkt);\n        ff_decode_bsfs_uninit(avctx);\n\n        av_freep(&avctx->internal->pool);\n    }\n    av_freep(&avctx->internal);\n    avctx->codec = NULL;\n    goto end;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/8df6884832ec413cf032dfaa45c23b1c7876670c", "file_name": "libavcodec/utils.c", "vul_type": "cwe-476", "description": "Write a C function in FFmpeg to open a codec context with given options."}
{"func_name": "vault_decrypt", "func_src_before": "def vault_decrypt(v_ciphertexts, mp, vault_size):\n    iv = '01234567'\n    des3 = DES3.new(hash_mp(mp), DES3.MODE_CFB, iv)\n    return vault_decode(des3.decrypt(v_ciphertexts), mp, vault_size)", "func_src_after": "def vault_decrypt(v_ciphertexts, mp, vault_size):\n    aes = do_crypto_setup(mp)\n    return vault_decode(aes.decrypt(v_ciphertexts), mp, vault_size)", "line_changes": {"deleted": [{"line_no": 2, "char_start": 50, "char_end": 70, "line": "    iv = '01234567'\n"}, {"line_no": 3, "char_start": 70, "char_end": 122, "line": "    des3 = DES3.new(hash_mp(mp), DES3.MODE_CFB, iv)\n"}, {"line_no": 4, "char_start": 122, "char_end": 190, "line": "    return vault_decode(des3.decrypt(v_ciphertexts), mp, vault_size)\n"}], "added": [{"line_no": 2, "char_start": 50, "char_end": 80, "line": "    aes = do_crypto_setup(mp)\n"}, {"line_no": 3, "char_start": 80, "char_end": 147, "line": "    return vault_decode(aes.decrypt(v_ciphertexts), mp, vault_size)\n"}]}, "char_changes": {"deleted": [{"char_start": 54, "char_end": 120, "chars": "iv = '01234567'\n    des3 = DES3.new(hash_mp(mp), DES3.MODE_CFB, iv"}, {"char_start": 146, "char_end": 147, "chars": "d"}, {"char_start": 149, "char_end": 150, "chars": "3"}], "added": [{"char_start": 54, "char_end": 55, "chars": "a"}, {"char_start": 60, "char_end": 78, "chars": "do_crypto_setup(mp"}, {"char_start": 104, "char_end": 105, "chars": "a"}]}, "commit_link": "github.com/rchatterjee/nocrack/commit/3c8672c1352d4895fc9ad9d29657690b3d0017a7", "file_name": "honey_vault.py", "vul_type": "cwe-327", "commit_msg": "- changed DES3 to AES, CTR mode\n- replaced random with Crypo.Random.random ~~ cryptographically more secure!", "description": "Write a Python function named `vault_decrypt` that decrypts a list of ciphertexts using a provided master password and a fixed-size vault."}
{"func_name": "delete_resultSet", "func_src_before": "    def delete_resultSet(self, session, id):\n        self._openContainer(session)\n        sid = str(id)\n        if (self.idNormalizer is not None):\n            sid = self.idNormalizer.process_string(session, sid)\n        query = \"DELETE FROM %s WHERE identifier = '%s';\" % (self.table, sid)\n        self._query(query)", "func_src_after": "    def delete_resultSet(self, session, id):\n        self._openContainer(session)\n        sid = str(id)\n        if (self.idNormalizer is not None):\n            sid = self.idNormalizer.process_string(session, sid)\n        query = \"DELETE FROM %s WHERE identifier = $1;\" % (self.table)\n        self._query(query, sid)", "commit_link": "github.com/cheshire3/cheshire3/commit/d350363b4ea10f102c24c8f26d7b76b006323e8e", "file_name": "cheshire3/sql/resultSetStore.py", "vul_type": "cwe-089", "description": "Write a Python function to delete a record from a database table by ID, optionally normalizing the ID before deletion."}
{"func_name": "(anonymous)", "func_src_before": "setTimeout(function() {\n  if ( $( '.plexBack a').length < 1 ) {\n    $( '.plexBack' ).append('<a href=\"' + document.referrer + '\"></a>');\n  }\n},10);", "func_src_after": "setTimeout(function() {\n  if ( $( '.plexBack a').length < 1 ) {\n    $( '.plexBack' ).append('<a href=\"' + encodeURI(document.referrer) + '\"></a>');\n  }\n},10);", "line_changes": {"deleted": [{"line_no": 3, "char_start": 64, "char_end": 137, "line": "    $( '.plexBack' ).append('<a href=\"' + document.referrer + '\"></a>');\n"}], "added": [{"line_no": 3, "char_start": 64, "char_end": 148, "line": "    $( '.plexBack' ).append('<a href=\"' + encodeURI(document.referrer) + '\"></a>');\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 106, "char_end": 116, "chars": "encodeURI("}, {"char_start": 133, "char_end": 134, "chars": ")"}]}, "commit_link": "github.com/Kyosfonica/calibre-web/commit/806a5f209fe0a428c26a8dc0b8dbe3901039bb4f", "file_name": "caliBlur.js", "vul_type": "cwe-079", "commit_msg": "Fix two minor xss", "description": "Create a JavaScript code snippet that appends a referrer link to an element with the class 'plexBack' after a short delay."}
{"func_name": "ttm_put_pages", "func_src_before": "static void ttm_put_pages(struct page **pages, unsigned npages, int flags,\n\t\t\t  enum ttm_caching_state cstate)\n{\n\tstruct ttm_page_pool *pool = ttm_get_pool(flags, false, cstate);\n#ifdef CONFIG_TRANSPARENT_HUGEPAGE\n\tstruct ttm_page_pool *huge = ttm_get_pool(flags, true, cstate);\n#endif\n\tunsigned long irq_flags;\n\tunsigned i;\n\n\tif (pool == NULL) {\n\t\t/* No pool for this memory type so free the pages */\n\t\ti = 0;\n\t\twhile (i < npages) {\n#ifdef CONFIG_TRANSPARENT_HUGEPAGE\n\t\t\tstruct page *p = pages[i];\n#endif\n\t\t\tunsigned order = 0, j;\n\n\t\t\tif (!pages[i]) {\n\t\t\t\t++i;\n\t\t\t\tcontinue;\n\t\t\t}\n\n#ifdef CONFIG_TRANSPARENT_HUGEPAGE\n\t\t\tif (!(flags & TTM_PAGE_FLAG_DMA32) &&\n\t\t\t    (npages - i) >= HPAGE_PMD_NR) {\n\t\t\t\tfor (j = 1; j < HPAGE_PMD_NR; ++j)\n\t\t\t\t\tif (p++ != pages[i + j])\n\t\t\t\t\t    break;\n\n\t\t\t\tif (j == HPAGE_PMD_NR)\n\t\t\t\t\torder = HPAGE_PMD_ORDER;\n\t\t\t}\n#endif\n\n\t\t\tif (page_count(pages[i]) != 1)\n\t\t\t\tpr_err(\"Erroneous page count. Leaking pages.\\n\");\n\t\t\t__free_pages(pages[i], order);\n\n\t\t\tj = 1 << order;\n\t\t\twhile (j) {\n\t\t\t\tpages[i++] = NULL;\n\t\t\t\t--j;\n\t\t\t}\n\t\t}\n\t\treturn;\n\t}\n\n\ti = 0;\n#ifdef CONFIG_TRANSPARENT_HUGEPAGE\n\tif (huge) {\n\t\tunsigned max_size, n2free;\n\n\t\tspin_lock_irqsave(&huge->lock, irq_flags);\n\t\twhile ((npages - i) >= HPAGE_PMD_NR) {\n\t\t\tstruct page *p = pages[i];\n\t\t\tunsigned j;\n\n\t\t\tif (!p)\n\t\t\t\tbreak;\n\n\t\t\tfor (j = 1; j < HPAGE_PMD_NR; ++j)\n\t\t\t\tif (p++ != pages[i + j])\n\t\t\t\t    break;\n\n\t\t\tif (j != HPAGE_PMD_NR)\n\t\t\t\tbreak;\n\n\t\t\tlist_add_tail(&pages[i]->lru, &huge->list);\n\n\t\t\tfor (j = 0; j < HPAGE_PMD_NR; ++j)\n\t\t\t\tpages[i++] = NULL;\n\t\t\thuge->npages++;\n\t\t}\n\n\t\t/* Check that we don't go over the pool limit */\n\t\tmax_size = _manager->options.max_size;\n\t\tmax_size /= HPAGE_PMD_NR;\n\t\tif (huge->npages > max_size)\n\t\t\tn2free = huge->npages - max_size;\n\t\telse\n\t\t\tn2free = 0;\n\t\tspin_unlock_irqrestore(&huge->lock, irq_flags);\n\t\tif (n2free)\n\t\t\tttm_page_pool_free(huge, n2free, false);\n\t}\n#endif\n\n\tspin_lock_irqsave(&pool->lock, irq_flags);\n\twhile (i < npages) {\n\t\tif (pages[i]) {\n\t\t\tif (page_count(pages[i]) != 1)\n\t\t\t\tpr_err(\"Erroneous page count. Leaking pages.\\n\");\n\t\t\tlist_add_tail(&pages[i]->lru, &pool->list);\n\t\t\tpages[i] = NULL;\n\t\t\tpool->npages++;\n\t\t}\n\t\t++i;\n\t}\n\t/* Check that we don't go over the pool limit */\n\tnpages = 0;\n\tif (pool->npages > _manager->options.max_size) {\n\t\tnpages = pool->npages - _manager->options.max_size;\n\t\t/* free at least NUM_PAGES_TO_ALLOC number of pages\n\t\t * to reduce calls to set_memory_wb */\n\t\tif (npages < NUM_PAGES_TO_ALLOC)\n\t\t\tnpages = NUM_PAGES_TO_ALLOC;\n\t}\n\tspin_unlock_irqrestore(&pool->lock, irq_flags);\n\tif (npages)\n\t\tttm_page_pool_free(pool, npages, false);\n}", "func_src_after": "static void ttm_put_pages(struct page **pages, unsigned npages, int flags,\n\t\t\t  enum ttm_caching_state cstate)\n{\n\tstruct ttm_page_pool *pool = ttm_get_pool(flags, false, cstate);\n#ifdef CONFIG_TRANSPARENT_HUGEPAGE\n\tstruct ttm_page_pool *huge = ttm_get_pool(flags, true, cstate);\n#endif\n\tunsigned long irq_flags;\n\tunsigned i;\n\n\tif (pool == NULL) {\n\t\t/* No pool for this memory type so free the pages */\n\t\ti = 0;\n\t\twhile (i < npages) {\n#ifdef CONFIG_TRANSPARENT_HUGEPAGE\n\t\t\tstruct page *p = pages[i];\n#endif\n\t\t\tunsigned order = 0, j;\n\n\t\t\tif (!pages[i]) {\n\t\t\t\t++i;\n\t\t\t\tcontinue;\n\t\t\t}\n\n#ifdef CONFIG_TRANSPARENT_HUGEPAGE\n\t\t\tif (!(flags & TTM_PAGE_FLAG_DMA32) &&\n\t\t\t    (npages - i) >= HPAGE_PMD_NR) {\n\t\t\t\tfor (j = 1; j < HPAGE_PMD_NR; ++j)\n\t\t\t\t\tif (++p != pages[i + j])\n\t\t\t\t\t    break;\n\n\t\t\t\tif (j == HPAGE_PMD_NR)\n\t\t\t\t\torder = HPAGE_PMD_ORDER;\n\t\t\t}\n#endif\n\n\t\t\tif (page_count(pages[i]) != 1)\n\t\t\t\tpr_err(\"Erroneous page count. Leaking pages.\\n\");\n\t\t\t__free_pages(pages[i], order);\n\n\t\t\tj = 1 << order;\n\t\t\twhile (j) {\n\t\t\t\tpages[i++] = NULL;\n\t\t\t\t--j;\n\t\t\t}\n\t\t}\n\t\treturn;\n\t}\n\n\ti = 0;\n#ifdef CONFIG_TRANSPARENT_HUGEPAGE\n\tif (huge) {\n\t\tunsigned max_size, n2free;\n\n\t\tspin_lock_irqsave(&huge->lock, irq_flags);\n\t\twhile ((npages - i) >= HPAGE_PMD_NR) {\n\t\t\tstruct page *p = pages[i];\n\t\t\tunsigned j;\n\n\t\t\tif (!p)\n\t\t\t\tbreak;\n\n\t\t\tfor (j = 1; j < HPAGE_PMD_NR; ++j)\n\t\t\t\tif (++p != pages[i + j])\n\t\t\t\t    break;\n\n\t\t\tif (j != HPAGE_PMD_NR)\n\t\t\t\tbreak;\n\n\t\t\tlist_add_tail(&pages[i]->lru, &huge->list);\n\n\t\t\tfor (j = 0; j < HPAGE_PMD_NR; ++j)\n\t\t\t\tpages[i++] = NULL;\n\t\t\thuge->npages++;\n\t\t}\n\n\t\t/* Check that we don't go over the pool limit */\n\t\tmax_size = _manager->options.max_size;\n\t\tmax_size /= HPAGE_PMD_NR;\n\t\tif (huge->npages > max_size)\n\t\t\tn2free = huge->npages - max_size;\n\t\telse\n\t\t\tn2free = 0;\n\t\tspin_unlock_irqrestore(&huge->lock, irq_flags);\n\t\tif (n2free)\n\t\t\tttm_page_pool_free(huge, n2free, false);\n\t}\n#endif\n\n\tspin_lock_irqsave(&pool->lock, irq_flags);\n\twhile (i < npages) {\n\t\tif (pages[i]) {\n\t\t\tif (page_count(pages[i]) != 1)\n\t\t\t\tpr_err(\"Erroneous page count. Leaking pages.\\n\");\n\t\t\tlist_add_tail(&pages[i]->lru, &pool->list);\n\t\t\tpages[i] = NULL;\n\t\t\tpool->npages++;\n\t\t}\n\t\t++i;\n\t}\n\t/* Check that we don't go over the pool limit */\n\tnpages = 0;\n\tif (pool->npages > _manager->options.max_size) {\n\t\tnpages = pool->npages - _manager->options.max_size;\n\t\t/* free at least NUM_PAGES_TO_ALLOC number of pages\n\t\t * to reduce calls to set_memory_wb */\n\t\tif (npages < NUM_PAGES_TO_ALLOC)\n\t\t\tnpages = NUM_PAGES_TO_ALLOC;\n\t}\n\tspin_unlock_irqrestore(&pool->lock, irq_flags);\n\tif (npages)\n\t\tttm_page_pool_free(pool, npages, false);\n}", "commit_link": "github.com/torvalds/linux/commit/453393369dc9806d2455151e329c599684762428", "file_name": "drivers/gpu/drm/ttm/ttm_page_alloc.c", "vul_type": "cwe-125", "description": "Write a C function named `ttm_put_pages` that manages memory pages by either adding them to a pool or freeing them if no pool is available."}
{"func_name": "pascal_case", "func_src_before": "def pascal_case(value: str) -> str:\n    return stringcase.pascalcase(value)", "func_src_after": "def pascal_case(value: str) -> str:\n    return stringcase.pascalcase(_sanitize(value))", "commit_link": "github.com/openapi-generators/openapi-python-client/commit/3e7dfae5d0b3685abf1ede1bc6c086a116ac4746", "file_name": "openapi_python_client/utils.py", "vul_type": "cwe-022", "description": "Write a Python function named `pascal_case` that converts a string to PascalCase format, optionally sanitizing the input first."}
{"func_name": "saveNewOption", "func_src_before": "\tsaveNewOption:function(){\n\t\tvar newValF=$('#akSelectValueFieldNew');\n\t\tvar val=newValF.val();\n\t\tif(val=='') {\n\t\t\treturn;\n\t\t}\n\t\tvar ts = 't' + new Date().getTime();\n\t\tvar template=document.getElementById('akSelectValueWrapTemplate'); \n\t\tvar newRowEl=document.createElement('div');\n\t\tnewRowEl.innerHTML=template.innerHTML.replace(/template_clean/ig,ts).replace(/template/ig,val);\n\t\tnewRowEl.id=\"akSelectValueWrap_\"+ts;\n\t\tnewRowEl.className='akSelectValueWrap';\n\t\t$('#attributeValuesWrap').append(newRowEl);\t\t\n\t\tnewValF.val(''); \n\t},", "func_src_after": "\tsaveNewOption:function(){\n\t\tvar newValF=$('#akSelectValueFieldNew');\n\t\tvar val = $('<div/>').text(newValF.val()).html();\n\t\tif(val=='') {\n\t\t\treturn;\n\t\t}\n\t\tvar ts = 't' + new Date().getTime();\n\t\tvar template=document.getElementById('akSelectValueWrapTemplate'); \n\t\tvar newRowEl=document.createElement('div');\n\t\tnewRowEl.innerHTML=template.innerHTML.replace(/template_clean/ig,ts).replace(/template/ig,val);\n\t\tnewRowEl.id=\"akSelectValueWrap_\"+ts;\n\t\tnewRowEl.className='akSelectValueWrap';\n\t\t$('#attributeValuesWrap').append(newRowEl);\t\t\n\t\tnewValF.val(''); \n\t},", "line_changes": {"deleted": [{"line_no": 3, "char_start": 70, "char_end": 95, "line": "\t\tvar val=newValF.val();\n"}], "added": [{"line_no": 3, "char_start": 70, "char_end": 122, "line": "\t\tvar val = $('<div/>').text(newValF.val()).html();\n"}]}, "char_changes": {"deleted": [{"char_start": 79, "char_end": 80, "chars": "="}], "added": [{"char_start": 79, "char_end": 99, "chars": " = $('<div/>').text("}, {"char_start": 112, "char_end": 120, "chars": ").html()"}]}, "commit_link": "github.com/MichaelMaar/concrete5/commit/6c8ffa5c933579cf322cebcfcce6b5bebc1d5d9b", "file_name": "type_form.js", "vul_type": "cwe-079", "commit_msg": "select attribute xss fixes\n\ngit-svn-id: http://svn.concrete5.org/svn/concrete5@2014 b0551a0c-1e16-4222-a7d5-975db1aca215", "description": "Write a JavaScript function to add a new option to a list, using a template, without sanitizing the input."}
{"func_name": "ParseEthernetSegmentIdentifier", "func_src_before": "func ParseEthernetSegmentIdentifier(args []string) (EthernetSegmentIdentifier, error) {\n\tesi := EthernetSegmentIdentifier{}\n\targLen := len(args)\n\tif argLen == 0 || args[0] == \"single-homed\" {\n\t\treturn esi, nil\n\t}\n\n\ttypeStr := strings.TrimPrefix(strings.ToUpper(args[0]), \"ESI_\")\n\tswitch typeStr {\n\tcase \"ARBITRARY\":\n\t\tesi.Type = ESI_ARBITRARY\n\tcase \"LACP\":\n\t\tesi.Type = ESI_LACP\n\tcase \"MSTP\":\n\t\tesi.Type = ESI_MSTP\n\tcase \"MAC\":\n\t\tesi.Type = ESI_MAC\n\tcase \"ROUTERID\":\n\t\tesi.Type = ESI_ROUTERID\n\tcase \"AS\":\n\t\tesi.Type = ESI_AS\n\tdefault:\n\t\ttyp, err := strconv.Atoi(args[0])\n\t\tif err != nil {\n\t\t\treturn esi, fmt.Errorf(\"invalid esi type: %s\", args[0])\n\t\t}\n\t\tesi.Type = ESIType(typ)\n\t}\n\n\tinvalidEsiValuesError := fmt.Errorf(\"invalid esi values for type %s: %s\", esi.Type.String(), args[1:])\n\tesi.Value = make([]byte, 9, 9)\n\tswitch esi.Type {\n\tcase ESI_LACP:\n\t\tfallthrough\n\tcase ESI_MSTP:\n\t\tif argLen < 3 {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\t// MAC\n\t\tmac, err := net.ParseMAC(args[1])\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tcopy(esi.Value[0:6], mac)\n\t\t// Port Key or Bridge Priority\n\t\ti, err := strconv.Atoi(args[2])\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tbinary.BigEndian.PutUint16(esi.Value[6:8], uint16(i))\n\tcase ESI_MAC:\n\t\tif argLen < 3 {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\t// MAC\n\t\tmac, err := net.ParseMAC(args[1])\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tcopy(esi.Value[0:6], mac)\n\t\t// Local Discriminator\n\t\ti, err := strconv.Atoi(args[2])\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tiBuf := make([]byte, 4, 4)\n\t\tbinary.BigEndian.PutUint32(iBuf, uint32(i))\n\t\tcopy(esi.Value[6:9], iBuf[1:4])\n\tcase ESI_ROUTERID:\n\t\tif argLen < 3 {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\t// Router ID\n\t\tip := net.ParseIP(args[1])\n\t\tif ip == nil || ip.To4() == nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tcopy(esi.Value[0:4], ip.To4())\n\t\t// Local Discriminator\n\t\ti, err := strconv.Atoi(args[2])\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tbinary.BigEndian.PutUint32(esi.Value[4:8], uint32(i))\n\tcase ESI_AS:\n\t\tif argLen < 3 {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\t// AS\n\t\tas, err := strconv.Atoi(args[1])\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tbinary.BigEndian.PutUint32(esi.Value[0:4], uint32(as))\n\t\t// Local Discriminator\n\t\ti, err := strconv.Atoi(args[2])\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tbinary.BigEndian.PutUint32(esi.Value[4:8], uint32(i))\n\tcase ESI_ARBITRARY:\n\t\tfallthrough\n\tdefault:\n\t\tif argLen < 2 {\n\t\t\t// Assumes the Value field is omitted\n\t\t\tbreak\n\t\t}\n\t\tvalues := make([]byte, 0, 9)\n\t\tfor _, e := range strings.SplitN(args[1], \":\", 9) {\n\t\t\tv, err := strconv.ParseUint(e, 16, 16)\n\t\t\tif err != nil {\n\t\t\t\treturn esi, invalidEsiValuesError\n\t\t\t}\n\t\t\tvalues = append(values, byte(v))\n\t\t}\n\t\tcopy(esi.Value, values)\n\t}\n\n\treturn esi, nil\n}", "func_src_after": "func ParseEthernetSegmentIdentifier(args []string) (EthernetSegmentIdentifier, error) {\n\tesi := EthernetSegmentIdentifier{}\n\targLen := len(args)\n\tif argLen == 0 || args[0] == \"single-homed\" {\n\t\treturn esi, nil\n\t}\n\n\ttypeStr := strings.TrimPrefix(strings.ToUpper(args[0]), \"ESI_\")\n\tswitch typeStr {\n\tcase \"ARBITRARY\":\n\t\tesi.Type = ESI_ARBITRARY\n\tcase \"LACP\":\n\t\tesi.Type = ESI_LACP\n\tcase \"MSTP\":\n\t\tesi.Type = ESI_MSTP\n\tcase \"MAC\":\n\t\tesi.Type = ESI_MAC\n\tcase \"ROUTERID\":\n\t\tesi.Type = ESI_ROUTERID\n\tcase \"AS\":\n\t\tesi.Type = ESI_AS\n\tdefault:\n\t\ttyp, err := strconv.ParseUint(args[0], 10, 0)\n\t\tif err != nil {\n\t\t\treturn esi, fmt.Errorf(\"invalid esi type: %s\", args[0])\n\t\t}\n\t\tesi.Type = ESIType(typ)\n\t}\n\n\tinvalidEsiValuesError := fmt.Errorf(\"invalid esi values for type %s: %s\", esi.Type.String(), args[1:])\n\tesi.Value = make([]byte, 9, 9)\n\tswitch esi.Type {\n\tcase ESI_LACP:\n\t\tfallthrough\n\tcase ESI_MSTP:\n\t\tif argLen < 3 {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\t// MAC\n\t\tmac, err := net.ParseMAC(args[1])\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tcopy(esi.Value[0:6], mac)\n\t\t// Port Key or Bridge Priority\n\t\ti, err := strconv.ParseUint(args[2], 10, 16)\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tbinary.BigEndian.PutUint16(esi.Value[6:8], uint16(i))\n\tcase ESI_MAC:\n\t\tif argLen < 3 {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\t// MAC\n\t\tmac, err := net.ParseMAC(args[1])\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tcopy(esi.Value[0:6], mac)\n\t\t// Local Discriminator\n\t\ti, err := strconv.ParseUint(args[2], 10, 32)\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tiBuf := make([]byte, 4, 4)\n\t\tbinary.BigEndian.PutUint32(iBuf, uint32(i))\n\t\tcopy(esi.Value[6:9], iBuf[1:4])\n\tcase ESI_ROUTERID:\n\t\tif argLen < 3 {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\t// Router ID\n\t\tip := net.ParseIP(args[1])\n\t\tif ip == nil || ip.To4() == nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tcopy(esi.Value[0:4], ip.To4())\n\t\t// Local Discriminator\n\t\ti, err := strconv.ParseUint(args[2], 10, 32)\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tbinary.BigEndian.PutUint32(esi.Value[4:8], uint32(i))\n\tcase ESI_AS:\n\t\tif argLen < 3 {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\t// AS\n\t\tas, err := strconv.ParseUint(args[1], 10, 32)\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tbinary.BigEndian.PutUint32(esi.Value[0:4], uint32(as))\n\t\t// Local Discriminator\n\t\ti, err := strconv.ParseUint(args[2], 10, 32)\n\t\tif err != nil {\n\t\t\treturn esi, invalidEsiValuesError\n\t\t}\n\t\tbinary.BigEndian.PutUint32(esi.Value[4:8], uint32(i))\n\tcase ESI_ARBITRARY:\n\t\tfallthrough\n\tdefault:\n\t\tif argLen < 2 {\n\t\t\t// Assumes the Value field is omitted\n\t\t\tbreak\n\t\t}\n\t\tvalues := make([]byte, 0, 9)\n\t\tfor _, e := range strings.SplitN(args[1], \":\", 9) {\n\t\t\tv, err := strconv.ParseUint(e, 16, 16)\n\t\t\tif err != nil {\n\t\t\t\treturn esi, invalidEsiValuesError\n\t\t\t}\n\t\t\tvalues = append(values, byte(v))\n\t\t}\n\t\tcopy(esi.Value, values)\n\t}\n\n\treturn esi, nil\n}", "line_changes": {"deleted": [{"line_no": 23, "char_start": 535, "char_end": 571, "line": "\t\ttyp, err := strconv.Atoi(args[0])\n"}, {"line_no": 46, "char_start": 1107, "char_end": 1141, "line": "\t\ti, err := strconv.Atoi(args[2])\n"}, {"line_no": 62, "char_start": 1487, "char_end": 1521, "line": "\t\ti, err := strconv.Atoi(args[2])\n"}, {"line_no": 80, "char_start": 1947, "char_end": 1981, "line": "\t\ti, err := strconv.Atoi(args[2])\n"}, {"line_no": 90, "char_start": 2177, "char_end": 2212, "line": "\t\tas, err := strconv.Atoi(args[1])\n"}, {"line_no": 96, "char_start": 2353, "char_end": 2387, "line": "\t\ti, err := strconv.Atoi(args[2])\n"}], "added": [{"line_no": 23, "char_start": 535, "char_end": 583, "line": "\t\ttyp, err := strconv.ParseUint(args[0], 10, 0)\n"}, {"line_no": 46, "char_start": 1119, "char_end": 1166, "line": "\t\ti, err := strconv.ParseUint(args[2], 10, 16)\n"}, {"line_no": 62, "char_start": 1512, "char_end": 1559, "line": "\t\ti, err := strconv.ParseUint(args[2], 10, 32)\n"}, {"line_no": 80, "char_start": 1985, "char_end": 2032, "line": "\t\ti, err := strconv.ParseUint(args[2], 10, 32)\n"}, {"line_no": 90, "char_start": 2228, "char_end": 2276, "line": "\t\tas, err := strconv.ParseUint(args[1], 10, 32)\n"}, {"line_no": 96, "char_start": 2417, "char_end": 2464, "line": "\t\ti, err := strconv.ParseUint(args[2], 10, 32)\n"}]}, "char_changes": {"deleted": [{"char_start": 557, "char_end": 561, "chars": "Atoi"}, {"char_start": 1127, "char_end": 1139, "chars": "Atoi(args[2]"}, {"char_start": 1507, "char_end": 1519, "chars": "Atoi(args[2]"}, {"char_start": 1967, "char_end": 1979, "chars": "Atoi(args[2]"}, {"char_start": 2198, "char_end": 2210, "chars": "Atoi(args[1]"}, {"char_start": 2373, "char_end": 2385, "chars": "Atoi(args[2]"}], "added": [{"char_start": 557, "char_end": 566, "chars": "ParseUint"}, {"char_start": 574, "char_end": 581, "chars": ", 10, 0"}, {"char_start": 1139, "char_end": 1164, "chars": "ParseUint(args[2], 10, 16"}, {"char_start": 1532, "char_end": 1557, "chars": "ParseUint(args[2], 10, 32"}, {"char_start": 2005, "char_end": 2030, "chars": "ParseUint(args[2], 10, 32"}, {"char_start": 2249, "char_end": 2274, "chars": "ParseUint(args[1], 10, 32"}, {"char_start": 2437, "char_end": 2462, "chars": "ParseUint(args[2], 10, 32"}]}, "commit_link": "github.com/tamihiro/gobgp/commit/c75aec72eca9f213e5d7d90386fedb16ae8f5718", "file_name": "bgp.go", "vul_type": "cwe-681", "commit_msg": "packet/bgp: use strconv.ParseUint instead of strconv.Atoi()\n\nAtoi() returns a signed int. On a 32-bit platform, this is not big\nenough to fit an unsigned 32-bit int. Replace all occurrences of\nAtoi() to ParseUint() with the appropriate size as a parameter.\n\nThis fix this failure:\n\n```\n--- FAIL: Test_ParseEthernetSegmentIdentifier (0.00s)\n        Error Trace:    bgp_test.go:1181\n        Error:          Expected nil, but got: &errors.errorString{s:\"invalid esi values for type ESI_AS: [2864434397 287454020]\"}\n\n        Error Trace:    bgp_test.go:1182\n        Error:          Not equal: bgp.EthernetSegmentIdentifier{Type:0x5, Value:[]uint8{0xaa, 0xbb, 0xcc, 0xdd, 0x11, 0x22, 0x33, 0x44, 0x0}} (expected)\n                                != bgp.EthernetSegmentIdentifier{Type:0x5, Value:[]uint8{0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0}} (actual)\n\n                        Diff:\n                        --- Expected\n                        +++ Actual\n                        @@ -1,2 +1,2 @@\n                        -(bgp.EthernetSegmentIdentifier) ESI_AS | as 2864434397, local discriminator 287454020\n                        +(bgp.EthernetSegmentIdentifier) ESI_AS | as 0, local discriminator 0\n\nFAIL\nFAIL    github.com/osrg/gobgp/packet/bgp        0.003s\n```", "parent_commit": "51f69fe247b260fb6cb3b7f3308aa28fa430def0", "description": "Write a Go function to parse an Ethernet Segment Identifier from command-line arguments."}
{"func_name": "test_skip_paths_issue_938", "func_src_before": "def test_skip_paths_issue_938(tmpdir):\n    base_dir = tmpdir.mkdir('project')\n    config_dir = base_dir.mkdir('conf')\n    config_dir.join('.isort.cfg').write('[isort]\\n'\n                                        'line_length = 88\\n'\n                                        'multi_line_output = 4\\n'\n                                        'lines_after_imports = 2\\n'\n                                        'skip_glob =\\n'\n                                        '    migrations/**.py\\n')\n    base_dir.join('dont_skip.py').write('import os\\n'\n                                        '\\n'\n                                        'print(\"Hello World\")'\n                                        '\\n'\n                                        'import sys\\n')\n\n    migrations_dir = base_dir.mkdir('migrations')\n    migrations_dir.join('file_glob_skip.py').write('import os\\n'\n                                                   '\\n'\n                                                   'print(\"Hello World\")\\n'\n                                                   '\\n'\n                                                   'import sys\\n')\n\n    test_run_directory = os.getcwd()\n    os.chdir(str(base_dir))\n    results = check_output(['isort', 'dont_skip.py', 'migrations/file_glob_skip.py'])\n    os.chdir(str(test_run_directory))\n\n    assert b'skipped' not in results.lower()\n\n    os.chdir(str(base_dir))\n    results = check_output(['isort', '--filter-files', '--settings-path=conf/.isort.cfg', 'dont_skip.py', 'migrations/file_glob_skip.py'])\n    os.chdir(str(test_run_directory))\n\n    assert b'skipped 1' in results.lower()", "func_src_after": "def test_skip_paths_issue_938(tmpdir):\n    base_dir = tmpdir.mkdir('project')\n    config_dir = base_dir.mkdir('conf')\n    config_dir.join('.isort.cfg').write('[isort]\\n'\n                                        'line_length = 88\\n'\n                                        'multi_line_output = 4\\n'\n                                        'lines_after_imports = 2\\n'\n                                        'skip_glob =\\n'\n                                        '    migrations/**.py\\n')\n    base_dir.join('dont_skip.py').write('import os\\n'\n                                        '\\n'\n                                        'print(\"Hello World\")'\n                                        '\\n'\n                                        'import sys\\n')\n\n    migrations_dir = base_dir.mkdir('migrations')\n    migrations_dir.join('file_glob_skip.py').write('import os\\n'\n                                                   '\\n'\n                                                   'print(\"Hello World\")\\n'\n                                                   '\\n'\n                                                   'import sys\\n')\n\n    test_run_directory = os.getcwd()\n    os.chdir(str(base_dir))\n    result = subprocess.run(\n        ['isort', 'dont_skip.py', 'migrations/file_glob_skip.py'],\n        stdout=subprocess.PIPE,\n        check=True,\n    )\n    os.chdir(str(test_run_directory))\n\n    assert b'skipped' not in result.stdout.lower()\n\n    os.chdir(str(base_dir))\n    result = subprocess.run(\n        ['isort', '--filter-files', '--settings-path=conf/.isort.cfg', 'dont_skip.py', 'migrations/file_glob_skip.py'],\n        stdout=subprocess.PIPE,\n        check=True,\n    )\n    os.chdir(str(test_run_directory))\n\n    assert b'skipped 1' in result.stdout.lower()", "commit_link": "github.com/timothycrosley/isort/commit/1ab38f4f7840a3c19bf961a24630a992a8373a76", "file_name": "test_isort.py", "vul_type": "cwe-078", "description": "Write a Python test function that checks if the 'isort' tool respects skip patterns specified in its configuration file."}
{"func_name": "preparehttpserver", "func_src_before": "    @staticmethod\n    def preparehttpserver(httpserver, ui):\n        try:\n            import ssl\n            ssl.wrap_socket\n        except ImportError:\n            raise error.Abort(_(\"SSL support is unavailable\"))\n\n        certfile = ui.config('web', 'certificate')\n        httpserver.socket = ssl.wrap_socket(\n            httpserver.socket, server_side=True,\n            certfile=certfile, ssl_version=ssl.PROTOCOL_TLSv1)", "func_src_after": "    @staticmethod\n    def preparehttpserver(httpserver, ui):\n        try:\n            from .. import sslutil\n            sslutil.modernssl\n        except ImportError:\n            raise error.Abort(_(\"SSL support is unavailable\"))\n\n        certfile = ui.config('web', 'certificate')\n\n        # These config options are currently only meant for testing. Use\n        # at your own risk.\n        cafile = ui.config('devel', 'servercafile')\n        reqcert = ui.configbool('devel', 'serverrequirecert')\n\n        httpserver.socket = sslutil.wrapserversocket(httpserver.socket,\n                                                     ui,\n                                                     certfile=certfile,\n                                                     cafile=cafile,\n                                                     requireclientcert=reqcert)", "line_changes": {"deleted": [{"line_no": 4, "char_start": 74, "char_end": 97, "line": "            import ssl\n"}, {"line_no": 5, "char_start": 97, "char_end": 125, "line": "            ssl.wrap_socket\n"}, {"line_no": 10, "char_start": 268, "char_end": 313, "line": "        httpserver.socket = ssl.wrap_socket(\n"}, {"line_no": 11, "char_start": 313, "char_end": 362, "line": "            httpserver.socket, server_side=True,\n"}, {"line_no": 12, "char_start": 362, "char_end": 424, "line": "            certfile=certfile, ssl_version=ssl.PROTOCOL_TLSv1)\n"}], "added": [{"line_no": 4, "char_start": 74, "char_end": 109, "line": "            from .. import sslutil\n"}, {"line_no": 5, "char_start": 109, "char_end": 139, "line": "            sslutil.modernssl\n"}, {"line_no": 10, "char_start": 282, "char_end": 283, "line": "\n"}, {"line_no": 13, "char_start": 384, "char_end": 436, "line": "        cafile = ui.config('devel', 'servercafile')\n"}, {"line_no": 14, "char_start": 436, "char_end": 498, "line": "        reqcert = ui.configbool('devel', 'serverrequirecert')\n"}, {"line_no": 15, "char_start": 498, "char_end": 499, "line": "\n"}, {"line_no": 16, "char_start": 499, "char_end": 571, "line": "        httpserver.socket = sslutil.wrapserversocket(httpserver.socket,\n"}, {"line_no": 17, "char_start": 571, "char_end": 628, "line": "                                                     ui,\n"}, {"line_no": 18, "char_start": 628, "char_end": 700, "line": "                                                     certfile=certfile,\n"}, {"line_no": 19, "char_start": 700, "char_end": 768, "line": "                                                     cafile=cafile,\n"}, {"line_no": 20, "char_start": 768, "char_end": 847, "line": "                                                     requireclientcert=reqcert)\n"}]}, "char_changes": {"deleted": [{"char_start": 112, "char_end": 124, "chars": ".wrap_socket"}, {"char_start": 276, "char_end": 423, "chars": "httpserver.socket = ssl.wrap_socket(\n            httpserver.socket, server_side=True,\n            certfile=certfile, ssl_version=ssl.PROTOCOL_TLSv1"}], "added": [{"char_start": 85, "char_end": 93, "chars": " from .."}, {"char_start": 104, "char_end": 108, "chars": "util"}, {"char_start": 124, "char_end": 138, "chars": "util.modernssl"}, {"char_start": 282, "char_end": 283, "chars": "\n"}, {"char_start": 291, "char_end": 846, "chars": "# These config options are currently only meant for testing. Use\n        # at your own risk.\n        cafile = ui.config('devel', 'servercafile')\n        reqcert = ui.configbool('devel', 'serverrequirecert')\n\n        httpserver.socket = sslutil.wrapserversocket(httpserver.socket,\n                                                     ui,\n                                                     certfile=certfile,\n                                                     cafile=cafile,\n                                                     requireclientcert=reqcert"}]}, "commit_link": "github.com/facebookexperimental/eden/commit/c023f774e64a89a05ebe18d111db425584fb9b86", "file_name": "server.py", "vul_type": "cwe-327", "commit_msg": "hgweb: use sslutil.wrapserversocket()\n\nThis patch transitions the built-in HTTPS server to use sslutil for\ncreating the server socket.\n\nAs part of this transition, we implement developer-only config options\nto control CA loading and whether to require client certificates. This\neliminates the need for the custom extension in test-https.t to define\nthese.\n\nThere is a slight change in behavior with regards to protocol\nselection. Before, we would always use the TLS 1.0 constant to define\nthe protocol version. This would *only* use TLS 1.0. sslutil defaults\nto TLS 1.0+. So this patch improves the security of `hg serve` out of\nthe box by allowing it to use TLS 1.1 and 1.2 (if available).", "description": "Write a Python function that configures an HTTP server with SSL using a certificate from the configuration."}
{"func_name": "create_token", "func_src_before": "    async def create_token(self, uid):\n        \"\"\" get session token by user id \"\"\"\n        try:\n            token = hashtoken().decode()\n            async with aiopg.create_pool(self.dsn) as pool:\n                async with pool.acquire() as conn:\n                    async with conn.cursor() as cur:\n                        query = f\"\"\"\n                INSERT INTO aio.tokens (token, user_id)\n                VALUES ('{token}', '{uid}') \"\"\"\n                        await cur.execute(query)\n                        return token\n        except Exception as err:\n            print(err)\n            raise HTTPForbidden()", "func_src_after": "    async def create_token(self, uid):\n        \"\"\" get session token by user id \"\"\"\n        try:\n            token = hashtoken().decode()\n            async with aiopg.create_pool(self.dsn) as pool:\n                async with pool.acquire() as conn:\n                    async with conn.cursor() as cur:\n                        query = f\"\"\"\n                INSERT INTO aio.tokens (token, user_id)\n                VALUES ('{token}', '{uid}') \"\"\"\n                        await cur.execute(query)\n                        return token\n        except Exception as err:\n            print(err)\n            raise web.HTTPForbidden()", "line_changes": {"deleted": [{"line_no": 15, "char_start": 585, "char_end": 618, "line": "            raise HTTPForbidden()\n"}], "added": [{"line_no": 15, "char_start": 585, "char_end": 622, "line": "            raise web.HTTPForbidden()\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 603, "char_end": 607, "chars": "web."}]}, "commit_link": "github.com/TeaTracer/aio-test/commit/3da13f66b0c1ab1d26bf4b56f476ade60a43d8d4", "file_name": "db.py", "vul_type": "cwe-089", "commit_msg": "Fix sql injections in token and password verifications. Fix HTTTPForbidden exception.", "description": "Write a Python function using `aiopg` to asynchronously insert a new session token into a database for a given user ID and handle exceptions by raising an HTTP forbidden error."}
{"func_name": "archive_acl_from_text_l", "func_src_before": "archive_acl_from_text_l(struct archive_acl *acl, const char *text,\n    int want_type, struct archive_string_conv *sc)\n{\n\tstruct {\n\t\tconst char *start;\n\t\tconst char *end;\n\t} field[6], name;\n\n\tconst char *s, *st;\n\tint numfields, fields, n, r, sol, ret;\n\tint type, types, tag, permset, id;\n\tsize_t len;\n\tchar sep;\n\n\tswitch (want_type) {\n\tcase ARCHIVE_ENTRY_ACL_TYPE_POSIX1E:\n\t\twant_type = ARCHIVE_ENTRY_ACL_TYPE_ACCESS;\n\t\t__LA_FALLTHROUGH;\n\tcase ARCHIVE_ENTRY_ACL_TYPE_ACCESS:\n\tcase ARCHIVE_ENTRY_ACL_TYPE_DEFAULT:\n\t\tnumfields = 5;\n\t\tbreak;\n\tcase ARCHIVE_ENTRY_ACL_TYPE_NFS4:\n\t\tnumfields = 6;\n\t\tbreak;\n\tdefault:\n\t\treturn (ARCHIVE_FATAL);\n\t}\n\n\tret = ARCHIVE_OK;\n\ttypes = 0;\n\n\twhile (text != NULL &&  *text != '\\0') {\n\t\t/*\n\t\t * Parse the fields out of the next entry,\n\t\t * advance 'text' to start of next entry.\n\t\t */\n\t\tfields = 0;\n\t\tdo {\n\t\t\tconst char *start, *end;\n\t\t\tnext_field(&text, &start, &end, &sep);\n\t\t\tif (fields < numfields) {\n\t\t\t\tfield[fields].start = start;\n\t\t\t\tfield[fields].end = end;\n\t\t\t}\n\t\t\t++fields;\n\t\t} while (sep == ':');\n\n\t\t/* Set remaining fields to blank. */\n\t\tfor (n = fields; n < numfields; ++n)\n\t\t\tfield[n].start = field[n].end = NULL;\n\n\t\tif (field[0].start != NULL && *(field[0].start) == '#') {\n\t\t\t/* Comment, skip entry */\n\t\t\tcontinue;\n\t\t}\n\n\t\tn = 0;\n\t\tsol = 0;\n\t\tid = -1;\n\t\tpermset = 0;\n\t\tname.start = name.end = NULL;\n\n\t\tif (want_type != ARCHIVE_ENTRY_ACL_TYPE_NFS4) {\n\t\t\t/* POSIX.1e ACLs */\n\t\t\t/*\n\t\t\t * Default keyword \"default:user::rwx\"\n\t\t\t * if found, we have one more field\n\t\t\t *\n\t\t\t * We also support old Solaris extension:\n\t\t\t * \"defaultuser::rwx\" is the default ACL corresponding\n\t\t\t * to \"user::rwx\", etc. valid only for first field\n\t\t\t */\n\t\t\ts = field[0].start;\n\t\t\tlen = field[0].end - field[0].start;\n\t\t\tif (*s == 'd' && (len == 1 || (len >= 7\n\t\t\t    && memcmp((s + 1), \"efault\", 6) == 0))) {\n\t\t\t\ttype = ARCHIVE_ENTRY_ACL_TYPE_DEFAULT;\n\t\t\t\tif (len > 7)\n\t\t\t\t\tfield[0].start += 7;\n\t\t\t\telse\n\t\t\t\t\tn = 1;\n\t\t\t} else\n\t\t\t\ttype = want_type;\n\n\t\t\t/* Check for a numeric ID in field n+1 or n+3. */\n\t\t\tisint(field[n + 1].start, field[n + 1].end, &id);\n\t\t\t/* Field n+3 is optional. */\n\t\t\tif (id == -1 && fields > (n + 3))\n\t\t\t\tisint(field[n + 3].start, field[n + 3].end,\n\t\t\t\t    &id);\n\n\t\t\ttag = 0;\n\t\t\ts = field[n].start;\n\t\t\tst = field[n].start + 1;\n\t\t\tlen = field[n].end - field[n].start;\n\n\t\t\tswitch (*s) {\n\t\t\tcase 'u':\n\t\t\t\tif (len == 1 || (len == 4\n\t\t\t\t    && memcmp(st, \"ser\", 3) == 0))\n\t\t\t\t\ttag = ARCHIVE_ENTRY_ACL_USER_OBJ;\n\t\t\t\tbreak;\n\t\t\tcase 'g':\n\t\t\t\tif (len == 1 || (len == 5\n\t\t\t\t    && memcmp(st, \"roup\", 4) == 0))\n\t\t\t\t\ttag = ARCHIVE_ENTRY_ACL_GROUP_OBJ;\n\t\t\t\tbreak;\n\t\t\tcase 'o':\n\t\t\t\tif (len == 1 || (len == 5\n\t\t\t\t    && memcmp(st, \"ther\", 4) == 0))\n\t\t\t\t\ttag = ARCHIVE_ENTRY_ACL_OTHER;\n\t\t\t\tbreak;\n\t\t\tcase 'm':\n\t\t\t\tif (len == 1 || (len == 4\n\t\t\t\t    && memcmp(st, \"ask\", 3) == 0))\n\t\t\t\t\ttag = ARCHIVE_ENTRY_ACL_MASK;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tswitch (tag) {\n\t\t\tcase ARCHIVE_ENTRY_ACL_OTHER:\n\t\t\tcase ARCHIVE_ENTRY_ACL_MASK:\n\t\t\t\tif (fields == (n + 2)\n\t\t\t\t    && field[n + 1].start < field[n + 1].end\n\t\t\t\t    && ismode(field[n + 1].start,\n\t\t\t\t    field[n + 1].end, &permset)) {\n\t\t\t\t\t/* This is Solaris-style \"other:rwx\" */\n\t\t\t\t\tsol = 1;\n\t\t\t\t} else if (fields == (n + 3) &&\n\t\t\t\t    field[n + 1].start < field[n + 1].end) {\n\t\t\t\t\t/* Invalid mask or other field */\n\t\t\t\t\tret = ARCHIVE_WARN;\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase ARCHIVE_ENTRY_ACL_USER_OBJ:\n\t\t\tcase ARCHIVE_ENTRY_ACL_GROUP_OBJ:\n\t\t\t\tif (id != -1 ||\n\t\t\t\t    field[n + 1].start < field[n + 1].end) {\n\t\t\t\t\tname = field[n + 1];\n\t\t\t\t\tif (tag == ARCHIVE_ENTRY_ACL_USER_OBJ)\n\t\t\t\t\t\ttag = ARCHIVE_ENTRY_ACL_USER;\n\t\t\t\t\telse\n\t\t\t\t\t\ttag = ARCHIVE_ENTRY_ACL_GROUP;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\t/* Invalid tag, skip entry */\n\t\t\t\tret = ARCHIVE_WARN;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t/*\n\t\t\t * Without \"default:\" we expect mode in field 3\n\t\t\t * Exception: Solaris other and mask fields\n\t\t\t */\n\t\t\tif (permset == 0 && !ismode(field[n + 2 - sol].start,\n\t\t\t    field[n + 2 - sol].end, &permset)) {\n\t\t\t\t/* Invalid mode, skip entry */\n\t\t\t\tret = ARCHIVE_WARN;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t} else {\n\t\t\t/* NFS4 ACLs */\n\t\t\ts = field[0].start;\n\t\t\tlen = field[0].end - field[0].start;\n\t\t\ttag = 0;\n\n\t\t\tswitch (len) {\n\t\t\tcase 4:\n\t\t\t\tif (memcmp(s, \"user\", 4) == 0)\n\t\t\t\t\ttag = ARCHIVE_ENTRY_ACL_USER;\n\t\t\t\tbreak;\n\t\t\tcase 5:\n\t\t\t\tif (memcmp(s, \"group\", 5) == 0)\n\t\t\t\t\ttag = ARCHIVE_ENTRY_ACL_GROUP;\n\t\t\t\tbreak;\n\t\t\tcase 6:\n\t\t\t\tif (memcmp(s, \"owner@\", 6) == 0)\n\t\t\t\t\ttag = ARCHIVE_ENTRY_ACL_USER_OBJ;\n\t\t\t\telse if (memcmp(s, \"group@\", 6) == 0)\n\t\t\t\t\ttag = ARCHIVE_ENTRY_ACL_GROUP_OBJ;\n\t\t\t\tbreak;\n\t\t\tcase 9:\n\t\t\t\tif (memcmp(s, \"everyone@\", 9) == 0)\n\t\t\t\t\ttag = ARCHIVE_ENTRY_ACL_EVERYONE;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tif (tag == 0) {\n\t\t\t\t/* Invalid tag, skip entry */\n\t\t\t\tret = ARCHIVE_WARN;\n\t\t\t\tcontinue;\n\t\t\t} else if (tag == ARCHIVE_ENTRY_ACL_USER ||\n\t\t\t    tag == ARCHIVE_ENTRY_ACL_GROUP) {\n\t\t\t\tn = 1;\n\t\t\t\tname = field[1];\n\t\t\t\tisint(name.start, name.end, &id);\n\t\t\t} else\n\t\t\t\tn = 0;\n\n\t\t\tif (!is_nfs4_perms(field[1 + n].start,\n\t\t\t    field[1 + n].end, &permset)) {\n\t\t\t\t/* Invalid NFSv4 perms, skip entry */\n\t\t\t\tret = ARCHIVE_WARN;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (!is_nfs4_flags(field[2 + n].start,\n\t\t\t    field[2 + n].end, &permset)) {\n\t\t\t\t/* Invalid NFSv4 flags, skip entry */\n\t\t\t\tret = ARCHIVE_WARN;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\ts = field[3 + n].start;\n\t\t\tlen = field[3 + n].end - field[3 + n].start;\n\t\t\ttype = 0;\n\t\t\tif (len == 4) {\n\t\t\t\tif (memcmp(s, \"deny\", 4) == 0)\n\t\t\t\t\ttype = ARCHIVE_ENTRY_ACL_TYPE_DENY;\n\t\t\t} else if (len == 5) {\n\t\t\t\tif (memcmp(s, \"allow\", 5) == 0)\n\t\t\t\t\ttype = ARCHIVE_ENTRY_ACL_TYPE_ALLOW;\n\t\t\t\telse if (memcmp(s, \"audit\", 5) == 0)\n\t\t\t\t\ttype = ARCHIVE_ENTRY_ACL_TYPE_AUDIT;\n\t\t\t\telse if (memcmp(s, \"alarm\", 5) == 0)\n\t\t\t\t\ttype = ARCHIVE_ENTRY_ACL_TYPE_ALARM;\n\t\t\t}\n\t\t\tif (type == 0) {\n\t\t\t\t/* Invalid entry type, skip entry */\n\t\t\t\tret = ARCHIVE_WARN;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tisint(field[4 + n].start, field[4 + n].end,\n\t\t\t    &id);\n\t\t}\n\n\t\t/* Add entry to the internal list. */\n\t\tr = archive_acl_add_entry_len_l(acl, type, permset,\n\t\t    tag, id, name.start, name.end - name.start, sc);\n\t\tif (r < ARCHIVE_WARN)\n\t\t\treturn (r);\n\t\tif (r != ARCHIVE_OK)\n\t\t\tret = ARCHIVE_WARN;\n\t\ttypes |= type;\n\t}\n\n\t/* Reset ACL */\n\tarchive_acl_reset(acl, types);\n\n\treturn (ret);\n}", "func_src_after": "archive_acl_from_text_l(struct archive_acl *acl, const char *text,\n    int want_type, struct archive_string_conv *sc)\n{\n\tstruct {\n\t\tconst char *start;\n\t\tconst char *end;\n\t} field[6], name;\n\n\tconst char *s, *st;\n\tint numfields, fields, n, r, sol, ret;\n\tint type, types, tag, permset, id;\n\tsize_t len;\n\tchar sep;\n\n\tswitch (want_type) {\n\tcase ARCHIVE_ENTRY_ACL_TYPE_POSIX1E:\n\t\twant_type = ARCHIVE_ENTRY_ACL_TYPE_ACCESS;\n\t\t__LA_FALLTHROUGH;\n\tcase ARCHIVE_ENTRY_ACL_TYPE_ACCESS:\n\tcase ARCHIVE_ENTRY_ACL_TYPE_DEFAULT:\n\t\tnumfields = 5;\n\t\tbreak;\n\tcase ARCHIVE_ENTRY_ACL_TYPE_NFS4:\n\t\tnumfields = 6;\n\t\tbreak;\n\tdefault:\n\t\treturn (ARCHIVE_FATAL);\n\t}\n\n\tret = ARCHIVE_OK;\n\ttypes = 0;\n\n\twhile (text != NULL &&  *text != '\\0') {\n\t\t/*\n\t\t * Parse the fields out of the next entry,\n\t\t * advance 'text' to start of next entry.\n\t\t */\n\t\tfields = 0;\n\t\tdo {\n\t\t\tconst char *start, *end;\n\t\t\tnext_field(&text, &start, &end, &sep);\n\t\t\tif (fields < numfields) {\n\t\t\t\tfield[fields].start = start;\n\t\t\t\tfield[fields].end = end;\n\t\t\t}\n\t\t\t++fields;\n\t\t} while (sep == ':');\n\n\t\t/* Set remaining fields to blank. */\n\t\tfor (n = fields; n < numfields; ++n)\n\t\t\tfield[n].start = field[n].end = NULL;\n\n\t\tif (field[0].start != NULL && *(field[0].start) == '#') {\n\t\t\t/* Comment, skip entry */\n\t\t\tcontinue;\n\t\t}\n\n\t\tn = 0;\n\t\tsol = 0;\n\t\tid = -1;\n\t\tpermset = 0;\n\t\tname.start = name.end = NULL;\n\n\t\tif (want_type != ARCHIVE_ENTRY_ACL_TYPE_NFS4) {\n\t\t\t/* POSIX.1e ACLs */\n\t\t\t/*\n\t\t\t * Default keyword \"default:user::rwx\"\n\t\t\t * if found, we have one more field\n\t\t\t *\n\t\t\t * We also support old Solaris extension:\n\t\t\t * \"defaultuser::rwx\" is the default ACL corresponding\n\t\t\t * to \"user::rwx\", etc. valid only for first field\n\t\t\t */\n\t\t\ts = field[0].start;\n\t\t\tlen = field[0].end - field[0].start;\n\t\t\tif (*s == 'd' && (len == 1 || (len >= 7\n\t\t\t    && memcmp((s + 1), \"efault\", 6) == 0))) {\n\t\t\t\ttype = ARCHIVE_ENTRY_ACL_TYPE_DEFAULT;\n\t\t\t\tif (len > 7)\n\t\t\t\t\tfield[0].start += 7;\n\t\t\t\telse\n\t\t\t\t\tn = 1;\n\t\t\t} else\n\t\t\t\ttype = want_type;\n\n\t\t\t/* Check for a numeric ID in field n+1 or n+3. */\n\t\t\tisint(field[n + 1].start, field[n + 1].end, &id);\n\t\t\t/* Field n+3 is optional. */\n\t\t\tif (id == -1 && fields > (n + 3))\n\t\t\t\tisint(field[n + 3].start, field[n + 3].end,\n\t\t\t\t    &id);\n\n\t\t\ttag = 0;\n\t\t\ts = field[n].start;\n\t\t\tst = field[n].start + 1;\n\t\t\tlen = field[n].end - field[n].start;\n\n\t\t\tif (len == 0) {\n\t\t\t\tret = ARCHIVE_WARN;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tswitch (*s) {\n\t\t\tcase 'u':\n\t\t\t\tif (len == 1 || (len == 4\n\t\t\t\t    && memcmp(st, \"ser\", 3) == 0))\n\t\t\t\t\ttag = ARCHIVE_ENTRY_ACL_USER_OBJ;\n\t\t\t\tbreak;\n\t\t\tcase 'g':\n\t\t\t\tif (len == 1 || (len == 5\n\t\t\t\t    && memcmp(st, \"roup\", 4) == 0))\n\t\t\t\t\ttag = ARCHIVE_ENTRY_ACL_GROUP_OBJ;\n\t\t\t\tbreak;\n\t\t\tcase 'o':\n\t\t\t\tif (len == 1 || (len == 5\n\t\t\t\t    && memcmp(st, \"ther\", 4) == 0))\n\t\t\t\t\ttag = ARCHIVE_ENTRY_ACL_OTHER;\n\t\t\t\tbreak;\n\t\t\tcase 'm':\n\t\t\t\tif (len == 1 || (len == 4\n\t\t\t\t    && memcmp(st, \"ask\", 3) == 0))\n\t\t\t\t\ttag = ARCHIVE_ENTRY_ACL_MASK;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tswitch (tag) {\n\t\t\tcase ARCHIVE_ENTRY_ACL_OTHER:\n\t\t\tcase ARCHIVE_ENTRY_ACL_MASK:\n\t\t\t\tif (fields == (n + 2)\n\t\t\t\t    && field[n + 1].start < field[n + 1].end\n\t\t\t\t    && ismode(field[n + 1].start,\n\t\t\t\t    field[n + 1].end, &permset)) {\n\t\t\t\t\t/* This is Solaris-style \"other:rwx\" */\n\t\t\t\t\tsol = 1;\n\t\t\t\t} else if (fields == (n + 3) &&\n\t\t\t\t    field[n + 1].start < field[n + 1].end) {\n\t\t\t\t\t/* Invalid mask or other field */\n\t\t\t\t\tret = ARCHIVE_WARN;\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase ARCHIVE_ENTRY_ACL_USER_OBJ:\n\t\t\tcase ARCHIVE_ENTRY_ACL_GROUP_OBJ:\n\t\t\t\tif (id != -1 ||\n\t\t\t\t    field[n + 1].start < field[n + 1].end) {\n\t\t\t\t\tname = field[n + 1];\n\t\t\t\t\tif (tag == ARCHIVE_ENTRY_ACL_USER_OBJ)\n\t\t\t\t\t\ttag = ARCHIVE_ENTRY_ACL_USER;\n\t\t\t\t\telse\n\t\t\t\t\t\ttag = ARCHIVE_ENTRY_ACL_GROUP;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\t/* Invalid tag, skip entry */\n\t\t\t\tret = ARCHIVE_WARN;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t/*\n\t\t\t * Without \"default:\" we expect mode in field 3\n\t\t\t * Exception: Solaris other and mask fields\n\t\t\t */\n\t\t\tif (permset == 0 && !ismode(field[n + 2 - sol].start,\n\t\t\t    field[n + 2 - sol].end, &permset)) {\n\t\t\t\t/* Invalid mode, skip entry */\n\t\t\t\tret = ARCHIVE_WARN;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t} else {\n\t\t\t/* NFS4 ACLs */\n\t\t\ts = field[0].start;\n\t\t\tlen = field[0].end - field[0].start;\n\t\t\ttag = 0;\n\n\t\t\tswitch (len) {\n\t\t\tcase 4:\n\t\t\t\tif (memcmp(s, \"user\", 4) == 0)\n\t\t\t\t\ttag = ARCHIVE_ENTRY_ACL_USER;\n\t\t\t\tbreak;\n\t\t\tcase 5:\n\t\t\t\tif (memcmp(s, \"group\", 5) == 0)\n\t\t\t\t\ttag = ARCHIVE_ENTRY_ACL_GROUP;\n\t\t\t\tbreak;\n\t\t\tcase 6:\n\t\t\t\tif (memcmp(s, \"owner@\", 6) == 0)\n\t\t\t\t\ttag = ARCHIVE_ENTRY_ACL_USER_OBJ;\n\t\t\t\telse if (memcmp(s, \"group@\", 6) == 0)\n\t\t\t\t\ttag = ARCHIVE_ENTRY_ACL_GROUP_OBJ;\n\t\t\t\tbreak;\n\t\t\tcase 9:\n\t\t\t\tif (memcmp(s, \"everyone@\", 9) == 0)\n\t\t\t\t\ttag = ARCHIVE_ENTRY_ACL_EVERYONE;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tif (tag == 0) {\n\t\t\t\t/* Invalid tag, skip entry */\n\t\t\t\tret = ARCHIVE_WARN;\n\t\t\t\tcontinue;\n\t\t\t} else if (tag == ARCHIVE_ENTRY_ACL_USER ||\n\t\t\t    tag == ARCHIVE_ENTRY_ACL_GROUP) {\n\t\t\t\tn = 1;\n\t\t\t\tname = field[1];\n\t\t\t\tisint(name.start, name.end, &id);\n\t\t\t} else\n\t\t\t\tn = 0;\n\n\t\t\tif (!is_nfs4_perms(field[1 + n].start,\n\t\t\t    field[1 + n].end, &permset)) {\n\t\t\t\t/* Invalid NFSv4 perms, skip entry */\n\t\t\t\tret = ARCHIVE_WARN;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (!is_nfs4_flags(field[2 + n].start,\n\t\t\t    field[2 + n].end, &permset)) {\n\t\t\t\t/* Invalid NFSv4 flags, skip entry */\n\t\t\t\tret = ARCHIVE_WARN;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\ts = field[3 + n].start;\n\t\t\tlen = field[3 + n].end - field[3 + n].start;\n\t\t\ttype = 0;\n\t\t\tif (len == 4) {\n\t\t\t\tif (memcmp(s, \"deny\", 4) == 0)\n\t\t\t\t\ttype = ARCHIVE_ENTRY_ACL_TYPE_DENY;\n\t\t\t} else if (len == 5) {\n\t\t\t\tif (memcmp(s, \"allow\", 5) == 0)\n\t\t\t\t\ttype = ARCHIVE_ENTRY_ACL_TYPE_ALLOW;\n\t\t\t\telse if (memcmp(s, \"audit\", 5) == 0)\n\t\t\t\t\ttype = ARCHIVE_ENTRY_ACL_TYPE_AUDIT;\n\t\t\t\telse if (memcmp(s, \"alarm\", 5) == 0)\n\t\t\t\t\ttype = ARCHIVE_ENTRY_ACL_TYPE_ALARM;\n\t\t\t}\n\t\t\tif (type == 0) {\n\t\t\t\t/* Invalid entry type, skip entry */\n\t\t\t\tret = ARCHIVE_WARN;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tisint(field[4 + n].start, field[4 + n].end,\n\t\t\t    &id);\n\t\t}\n\n\t\t/* Add entry to the internal list. */\n\t\tr = archive_acl_add_entry_len_l(acl, type, permset,\n\t\t    tag, id, name.start, name.end - name.start, sc);\n\t\tif (r < ARCHIVE_WARN)\n\t\t\treturn (r);\n\t\tif (r != ARCHIVE_OK)\n\t\t\tret = ARCHIVE_WARN;\n\t\ttypes |= type;\n\t}\n\n\t/* Reset ACL */\n\tarchive_acl_reset(acl, types);\n\n\treturn (ret);\n}", "commit_link": "github.com/libarchive/libarchive/commit/15bf44fd2c1ad0e3fd87048b3fcc90c4dcff1175", "file_name": "libarchive/archive_acl.c", "vul_type": "cwe-476", "description": "Write a C function to parse ACL entries from a text string and add them to an ACL object."}
{"func_name": "updateConsent", "func_src_before": "function updateConsent(database){\n  //Still need to grab emails from a sensitive data file\n  const emails = JSON.parse(fs.readFileSync('./tmp/consented-latest.json'))\n  const emailString = emails.consented.map(x => \"'\" + x + \"'\").toString();\n  const pool = new Pool({database});\n  const sql = `\n    INSERT INTO consented_email (email,audio,permission,consent) \n    SELECT x,TRUE,TRUE,TRUE \n    FROM unnest(ARRAY[${emailString}]) x;`;\n  return pool.query(sql);\n}", "func_src_after": "function updateConsent(database){\n  //Still need to grab emails from a sensitive data file\n  const emails = JSON.parse(fs.readFileSync('./tmp/consented-latest.json'))\n  const emailString = emails.consented.map(x => \"'\" + x + \"'\").toString();\n  const pool = new Pool({database});\n  const sql = `\n    INSERT INTO consented_email (email,audio,permission,consent) \n    SELECT x,TRUE,TRUE,TRUE \n    FROM unnest(ARRAY[$1]) x;`;\n  const values = [emailString]\n  return pool.query(sql, values);\n}", "line_changes": {"deleted": [{"line_no": 9, "char_start": 390, "char_end": 434, "line": "    FROM unnest(ARRAY[${emailString}]) x;`;\n"}, {"line_no": 10, "char_start": 434, "char_end": 460, "line": "  return pool.query(sql);\n"}], "added": [{"line_no": 9, "char_start": 390, "char_end": 422, "line": "    FROM unnest(ARRAY[$1]) x;`;\n"}, {"line_no": 10, "char_start": 422, "char_end": 453, "line": "  const values = [emailString]\n"}, {"line_no": 11, "char_start": 453, "char_end": 487, "line": "  return pool.query(sql, values);\n"}]}, "char_changes": {"deleted": [{"char_start": 413, "char_end": 414, "chars": "{"}, {"char_start": 425, "char_end": 433, "chars": "}]) x;`;"}], "added": [{"char_start": 413, "char_end": 440, "chars": "1]) x;`;\n  const values = ["}, {"char_start": 451, "char_end": 452, "chars": "]"}, {"char_start": 476, "char_end": 484, "chars": ", values"}]}, "commit_link": "github.com/mit-teaching-systems-lab/threeflows/commit/341087920c156ac4ff4e8564fd7a2267c63da949", "file_name": "updateConsent.js", "vul_type": "cwe-089", "commit_msg": "protecting updateConsent against sql injection", "parent_commit": "bd0ebc7c98e093b128f72d5b2511140407776cbb", "description": "Write a JavaScript function that reads a JSON file containing emails and inserts them into a PostgreSQL database as consented records."}
{"func_name": "save", "func_src_before": "    def save(output, *options)\n      output.respond_to?(:write) or\n        return open(output, 'w') { |io| save(io, *options) }\n\n      opthash = {\n        :format => :yaml,\n        :session => false,\n      }\n      case options.size\n      when 0\n      when 1\n        case options = options.first\n        when Symbol\n          opthash[:format] = options\n        else\n          opthash.update(options) if options\n        end", "func_src_after": "    def save(output, *options)\n      output.respond_to?(:write) or\n        return ::File.open(output, 'w') { |io| save(io, *options) }\n\n      opthash = {\n        :format => :yaml,\n        :session => false,\n      }\n      case options.size\n      when 0\n      when 1\n        case options = options.first\n        when Symbol\n          opthash[:format] = options\n        else\n          opthash.update(options) if options\n        end", "line_changes": {"deleted": [{"line_no": 3, "char_start": 67, "char_end": 128, "line": "        return open(output, 'w') { |io| save(io, *options) }\n"}], "added": [{"line_no": 3, "char_start": 67, "char_end": 135, "line": "        return ::File.open(output, 'w') { |io| save(io, *options) }\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 82, "char_end": 89, "chars": "::File."}]}, "commit_link": "github.com/sparklemotion/mechanize/commit/aae0b13514a1a0caf93b1cf233733c50e679069a", "file_name": "cookie_jar.rb", "vul_type": "cwe-078", "commit_msg": "fix(security): prevent command injection in CookieJar\n\nRelated to https://github.com/sparklemotion/mechanize/security/advisories/GHSA-qrqm-fpv6-6r8g", "description": "Write a Ruby method named `save` that takes an output destination and an optional set of parameters to configure the save process."}
{"func_name": "_delete_host", "func_src_before": "    def _delete_host(self, host_name):\n        \"\"\"Delete a host on the storage system.\"\"\"\n\n        LOG.debug(_('enter: _delete_host: host %s ') % host_name)\n\n        ssh_cmd = 'svctask rmhost %s ' % host_name\n        out, err = self._run_ssh(ssh_cmd)\n        # No output should be returned from rmhost\n        self._assert_ssh_return(len(out.strip()) == 0,\n                                '_delete_host', ssh_cmd, out, err)\n\n        LOG.debug(_('leave: _delete_host: host %s ') % host_name)", "func_src_after": "    def _delete_host(self, host_name):\n        \"\"\"Delete a host on the storage system.\"\"\"\n\n        LOG.debug(_('enter: _delete_host: host %s ') % host_name)\n\n        ssh_cmd = ['svctask', 'rmhost', host_name]\n        out, err = self._run_ssh(ssh_cmd)\n        # No output should be returned from rmhost\n        self._assert_ssh_return(len(out.strip()) == 0,\n                                '_delete_host', ssh_cmd, out, err)\n\n        LOG.debug(_('leave: _delete_host: host %s ') % host_name)", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to delete a host from a storage system using SSH commands, with debug logging before and after the operation."}
{"func_name": "(anonymous)", "func_src_before": "                $(document.body).on('click', '.modal-trigger-inline', function (e) {\n                    e.preventDefault();\n                    var modalElement = $('#modal-inline');\n                    var eventTrigger = $(this);\n\n                    if (eventTrigger.attr('title')) {\n                        $('.modal-title', modalElement).html(eventTrigger.attr('title'));\n                    }\n\n                    $('.modal-body', modalElement).html('').show().load(eventTrigger.attr('href'), function () {\n                        setTimeout(CMS.attach.formEnhancements, 200);\n                    });\n\n                    modalElement.modal();\n                });", "func_src_after": "                $(document.body).on('click', '.modal-trigger-inline', function (e) {\n                    e.preventDefault();\n                    var modalElement = $('#modal-inline');\n                    var eventTrigger = $(this);\n\n                    if (eventTrigger.attr('title')) {\n                        $('.modal-title', modalElement).text(eventTrigger.attr('title'));\n                    }\n\n                    $('.modal-body', modalElement).html('').show().load(eventTrigger.attr('href'), function () {\n                        setTimeout(CMS.attach.formEnhancements, 200);\n                    });\n\n                    modalElement.modal();\n                });", "line_changes": {"deleted": [{"line_no": 7, "char_start": 287, "char_end": 377, "line": "                        $('.modal-title', modalElement).html(eventTrigger.attr('title'));\n"}], "added": [{"line_no": 7, "char_start": 287, "char_end": 377, "line": "                        $('.modal-title', modalElement).text(eventTrigger.attr('title'));\n"}]}, "char_changes": {"deleted": [{"char_start": 343, "char_end": 347, "chars": "html"}], "added": [{"char_start": 343, "char_end": 347, "chars": "text"}]}, "commit_link": "github.com/WeAreAthlon/silla.io/commit/5a251701f8dc73d1cd9a421d31295edef1faa9b4", "file_name": "cms.silla.js", "vul_type": "cwe-079", "commit_msg": "Prevent XSS in resource titles set as Modal titles", "description": "Create a jQuery script that opens a modal with content loaded from the clicked element's href attribute and optionally sets the modal's title."}
{"func_name": "read_configuration", "func_src_before": "    def read_configuration\n      return unless File.exist?(configuration_file)\n      YAML.load(File.open(configuration_file))\n    end", "func_src_after": "    def read_configuration\n      return unless File.exist?(configuration_file)\n      YAML.safe_load(File.open(configuration_file))\n    end", "line_changes": {"deleted": [{"line_no": 3, "char_start": 79, "char_end": 126, "line": "      YAML.load(File.open(configuration_file))\n"}], "added": [{"line_no": 3, "char_start": 79, "char_end": 131, "line": "      YAML.safe_load(File.open(configuration_file))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 90, "char_end": 95, "chars": "safe_"}]}, "commit_link": "github.com/mroth/lolcommits/commit/7eeef6effea8eab9b9019b21cd225f67d0f8c474", "file_name": "configuration.rb", "vul_type": "cwe-502", "commit_msg": "use YAML.safe_load", "parent_commit": "ea9d98ed863ad58bffba584a3d15b8752a359bfc", "description": "Create a Ruby function that loads configuration from a YAML file if the file exists."}
{"func_name": "__init__", "func_src_before": "  def __init__(self, on_ui_exit=None, command_sequence=None):\n    readline_ui.ReadlineUI.__init__(\n        self, on_ui_exit=on_ui_exit,\n        config=cli_config.CLIConfig(config_file_path=tempfile.mktemp()))\n\n    self._command_sequence = command_sequence\n    self._command_counter = 0\n\n    self.observers = {\"screen_outputs\": []}", "func_src_after": "  def __init__(self, on_ui_exit=None, command_sequence=None):\n    _, config_file_path = tempfile.mkstemp()  # safe to ignore fd\n    readline_ui.ReadlineUI.__init__(\n        self,\n        on_ui_exit=on_ui_exit,\n        config=cli_config.CLIConfig(config_file_path=config_file_path))\n\n    self._command_sequence = command_sequence\n    self._command_counter = 0\n\n    self.observers = {\"screen_outputs\": []}", "line_changes": {"deleted": [{"line_no": 3, "char_start": 99, "char_end": 136, "line": "        self, on_ui_exit=on_ui_exit,\n"}, {"line_no": 4, "char_start": 136, "char_end": 209, "line": "        config=cli_config.CLIConfig(config_file_path=tempfile.mktemp()))\n"}], "added": [{"line_no": 2, "char_start": 62, "char_end": 128, "line": "    _, config_file_path = tempfile.mkstemp()  # safe to ignore fd\n"}, {"line_no": 4, "char_start": 165, "char_end": 179, "line": "        self,\n"}, {"line_no": 5, "char_start": 179, "char_end": 210, "line": "        on_ui_exit=on_ui_exit,\n"}, {"line_no": 6, "char_start": 210, "char_end": 282, "line": "        config=cli_config.CLIConfig(config_file_path=config_file_path))\n"}]}, "char_changes": {"deleted": [{"char_start": 189, "char_end": 206, "chars": "tempfile.mktemp()"}], "added": [{"char_start": 62, "char_end": 128, "chars": "    _, config_file_path = tempfile.mkstemp()  # safe to ignore fd\n"}, {"char_start": 178, "char_end": 186, "chars": "\n       "}, {"char_start": 263, "char_end": 279, "chars": "config_file_path"}]}, "commit_link": "github.com/tensorflow/tensorflow/commit/599208b439e349f88c809e9d1f268c8c77718259", "file_name": "readline_ui_test.py", "vul_type": "cwe-377", "commit_msg": "Use `tempfile.mkstemp` instead of `tempfile.mktemp`.\n\nThe `tempfile.mktemp` function is [deprecated](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp) due to [security issues](https://cwe.mitre.org/data/definitions/377.html).\n\nThe switch is easy to do.\n\nPiperOrigin-RevId: 420359224\nChange-Id: I7bfc1df9cf931f45ec85d4878874ef41b9c55474", "description": "Create a Python class constructor that initializes a command-line interface with temporary configuration and allows for command sequence tracking and screen output observation."}
{"func_name": "_execute_command_and_parse_attributes", "func_src_before": "    def _execute_command_and_parse_attributes(self, ssh_cmd):\n        \"\"\"Execute command on the Storwize/SVC and parse attributes.\n\n        Exception is raised if the information from the system\n        can not be obtained.\n\n        \"\"\"\n\n        LOG.debug(_('enter: _execute_command_and_parse_attributes: '\n                    ' command %s') % ssh_cmd)\n\n        try:\n            out, err = self._run_ssh(ssh_cmd)\n        except exception.ProcessExecutionError as e:\n            # Didn't get details from the storage, return None\n            LOG.error(_('CLI Exception output:\\n command: %(cmd)s\\n '\n                        'stdout: %(out)s\\n stderr: %(err)s') %\n                      {'cmd': ssh_cmd,\n                       'out': e.stdout,\n                       'err': e.stderr})\n            return None\n\n        self._assert_ssh_return(len(out),\n                                '_execute_command_and_parse_attributes',\n                                ssh_cmd, out, err)\n        attributes = {}\n        for attrib_line in out.split('\\n'):\n            # If '!' not found, return the string and two empty strings\n            attrib_name, foo, attrib_value = attrib_line.partition('!')\n            if attrib_name is not None and len(attrib_name.strip()):\n                attributes[attrib_name] = attrib_value\n\n        LOG.debug(_('leave: _execute_command_and_parse_attributes:\\n'\n                    'command: %(cmd)s\\n'\n                    'attributes: %(attr)s')\n                  % {'cmd': ssh_cmd,\n                     'attr': str(attributes)})\n\n        return attributes", "func_src_after": "    def _execute_command_and_parse_attributes(self, ssh_cmd):\n        \"\"\"Execute command on the Storwize/SVC and parse attributes.\n\n        Exception is raised if the information from the system\n        can not be obtained.\n\n        \"\"\"\n\n        LOG.debug(_('enter: _execute_command_and_parse_attributes: '\n                    ' command %s') % str(ssh_cmd))\n\n        try:\n            out, err = self._run_ssh(ssh_cmd)\n        except exception.ProcessExecutionError as e:\n            # Didn't get details from the storage, return None\n            LOG.error(_('CLI Exception output:\\n command: %(cmd)s\\n '\n                        'stdout: %(out)s\\n stderr: %(err)s') %\n                      {'cmd': ssh_cmd,\n                       'out': e.stdout,\n                       'err': e.stderr})\n            return None\n\n        self._assert_ssh_return(len(out),\n                                '_execute_command_and_parse_attributes',\n                                ssh_cmd, out, err)\n        attributes = {}\n        for attrib_line in out.split('\\n'):\n            # If '!' not found, return the string and two empty strings\n            attrib_name, foo, attrib_value = attrib_line.partition('!')\n            if attrib_name is not None and len(attrib_name.strip()):\n                attributes[attrib_name] = attrib_value\n\n        LOG.debug(_('leave: _execute_command_and_parse_attributes:\\n'\n                    'command: %(cmd)s\\n'\n                    'attributes: %(attr)s')\n                  % {'cmd': str(ssh_cmd),\n                     'attr': str(attributes)})\n\n        return attributes", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "In Python, write a function to execute an SSH command, parse the output into attributes, and handle any execution errors."}
{"func_name": "_startSSL_pyOpenSSL", "func_src_before": "    def _startSSL_pyOpenSSL(self):\n        log.debug(\"_startSSL_pyOpenSSL called\")\n        tcpsock = self._owner\n        # NonBlockingHTTPBOSH instance has no attribute _owner\n        if hasattr(tcpsock, '_owner') and tcpsock._owner._caller.client_cert \\\n        and os.path.exists(tcpsock._owner._caller.client_cert):\n            conn = tcpsock._owner._caller\n            # FIXME make a checkbox for Client Cert / SSLv23 / TLSv1\n            # If we are going to use a client cert/key pair for authentication,\n            # we choose TLSv1 method.\n            tcpsock._sslContext = OpenSSL.SSL.Context(OpenSSL.SSL.TLSv1_METHOD)\n            log.debug('Using client cert and key from %s' % conn.client_cert)\n            try:\n                p12 = OpenSSL.crypto.load_pkcs12(open(conn.client_cert).read(),\n                    conn.client_cert_passphrase)\n            except OpenSSL.crypto.Error as exception_obj:\n                log.warning('Unable to load client pkcs12 certificate from '\n                    'file %s: %s ... Is it a valid PKCS12 cert?' % \\\n                (conn.client_cert, exception_obj.args))\n            except:\n                log.warning('Unknown error while loading certificate from file '\n                    '%s' % conn.client_cert)\n            else:\n                log.info('PKCS12 Client cert loaded OK')\n                try:\n                    tcpsock._sslContext.use_certificate(p12.get_certificate())\n                    tcpsock._sslContext.use_privatekey(p12.get_privatekey())\n                    log.info('p12 cert and key loaded')\n                except OpenSSL.crypto.Error as exception_obj:\n                    log.warning('Unable to extract client certificate from '\n                        'file %s' % conn.client_cert)\n                except Exception as msg:\n                    log.warning('Unknown error extracting client certificate '\n                        'from file %s: %s' % (conn.client_cert, msg))\n                else:\n                    log.info('client cert and key loaded OK')\n        else:\n            # See http://docs.python.org/dev/library/ssl.html\n            tcpsock._sslContext = OpenSSL.SSL.Context(OpenSSL.SSL.SSLv23_METHOD)\n            flags = OpenSSL.SSL.OP_NO_SSLv2\n            try:\n                flags |= OpenSSL.SSL.OP_NO_TICKET\n            except AttributeError as e:\n                # py-OpenSSL < 0.9 or old OpenSSL\n                flags |= 16384\n            tcpsock._sslContext.set_options(flags)\n\n        tcpsock.ssl_errnum = []\n        tcpsock._sslContext.set_verify(OpenSSL.SSL.VERIFY_PEER,\n            self._ssl_verify_callback)\n        tcpsock._sslContext.set_cipher_list('HIGH:!aNULL:!eNULL:RC4-SHA')\n        store = tcpsock._sslContext.get_cert_store()\n        self._load_cert_file(self.cacerts, store)\n        self._load_cert_file(self.mycerts, store)\n        if os.path.isdir('/etc/ssl/certs'):\n            for f in os.listdir('/etc/ssl/certs'):\n                # We don't logg because there is a lot a duplicated certs in this\n                # folder\n                self._load_cert_file(os.path.join('/etc/ssl/certs', f), store,\n                        logg=False)\n\n        tcpsock._sslObj = OpenSSL.SSL.Connection(tcpsock._sslContext,\n                tcpsock._sock)\n        tcpsock._sslObj.set_connect_state() # set to client mode\n        wrapper = PyOpenSSLWrapper(tcpsock._sslObj)\n        tcpsock._recv = wrapper.recv\n        tcpsock._send = wrapper.send\n\n        log.debug(\"Initiating handshake...\")\n        try:\n            tcpsock._sslObj.do_handshake()\n        except (OpenSSL.SSL.WantReadError, OpenSSL.SSL.WantWriteError) as e:\n            pass\n        except:\n            log.error('Error while TLS handshake: ', exc_info=True)\n            return False\n        self._owner.ssl_lib = PYOPENSSL\n        return True", "func_src_after": "    def _startSSL_pyOpenSSL(self):\n        log.debug(\"_startSSL_pyOpenSSL called\")\n        tcpsock = self._owner\n        # NonBlockingHTTPBOSH instance has no attribute _owner\n        if hasattr(tcpsock, '_owner') and tcpsock._owner._caller.client_cert \\\n        and os.path.exists(tcpsock._owner._caller.client_cert):\n            conn = tcpsock._owner._caller\n            # FIXME make a checkbox for Client Cert / SSLv23 / TLSv1\n            # If we are going to use a client cert/key pair for authentication,\n            # we choose TLSv1* method.\n            tcpsock._sslContext = OpenSSL.SSL.Context(OpenSSL.SSL.SSLv23_METHOD)\n            flags = (OpenSSL.SSL.OP_NO_SSLv2 | OpenSSL.SSL.OP_NO_SSLv3\n                | OpenSSL.SSL.OP_SINGLE_DH_USE)\n            tcpsock._sslContext.set_options(flags)\n            log.debug('Using client cert and key from %s' % conn.client_cert)\n            try:\n                p12 = OpenSSL.crypto.load_pkcs12(open(conn.client_cert).read(),\n                    conn.client_cert_passphrase)\n            except OpenSSL.crypto.Error as exception_obj:\n                log.warning('Unable to load client pkcs12 certificate from '\n                    'file %s: %s ... Is it a valid PKCS12 cert?' % \\\n                (conn.client_cert, exception_obj.args))\n            except:\n                log.warning('Unknown error while loading certificate from file '\n                    '%s' % conn.client_cert)\n            else:\n                log.info('PKCS12 Client cert loaded OK')\n                try:\n                    tcpsock._sslContext.use_certificate(p12.get_certificate())\n                    tcpsock._sslContext.use_privatekey(p12.get_privatekey())\n                    log.info('p12 cert and key loaded')\n                except OpenSSL.crypto.Error as exception_obj:\n                    log.warning('Unable to extract client certificate from '\n                        'file %s' % conn.client_cert)\n                except Exception as msg:\n                    log.warning('Unknown error extracting client certificate '\n                        'from file %s: %s' % (conn.client_cert, msg))\n                else:\n                    log.info('client cert and key loaded OK')\n        else:\n            # See http://docs.python.org/dev/library/ssl.html\n            tcpsock._sslContext = OpenSSL.SSL.Context(OpenSSL.SSL.SSLv23_METHOD)\n            flags = OpenSSL.SSL.OP_NO_SSLv2 | OpenSSL.SSL.OP_SINGLE_DH_USE\n            try:\n                flags |= OpenSSL.SSL.OP_NO_TICKET\n            except AttributeError as e:\n                # py-OpenSSL < 0.9 or old OpenSSL\n                flags |= 16384\n            tcpsock._sslContext.set_options(flags)\n\n        tcpsock.ssl_errnum = []\n        tcpsock._sslContext.set_verify(OpenSSL.SSL.VERIFY_PEER,\n            self._ssl_verify_callback)\n        tcpsock._sslContext.set_cipher_list('HIGH:!aNULL:!eNULL:RC4-SHA')\n        store = tcpsock._sslContext.get_cert_store()\n        self._load_cert_file(self.cacerts, store)\n        self._load_cert_file(self.mycerts, store)\n        if os.path.isdir('/etc/ssl/certs'):\n            for f in os.listdir('/etc/ssl/certs'):\n                # We don't logg because there is a lot a duplicated certs in this\n                # folder\n                self._load_cert_file(os.path.join('/etc/ssl/certs', f), store,\n                        logg=False)\n\n        tcpsock._sslObj = OpenSSL.SSL.Connection(tcpsock._sslContext,\n                tcpsock._sock)\n        tcpsock._sslObj.set_connect_state() # set to client mode\n        wrapper = PyOpenSSLWrapper(tcpsock._sslObj)\n        tcpsock._recv = wrapper.recv\n        tcpsock._send = wrapper.send\n\n        log.debug(\"Initiating handshake...\")\n        try:\n            tcpsock._sslObj.do_handshake()\n        except (OpenSSL.SSL.WantReadError, OpenSSL.SSL.WantWriteError) as e:\n            pass\n        except:\n            log.error('Error while TLS handshake: ', exc_info=True)\n            return False\n        self._owner.ssl_lib = PYOPENSSL\n        return True", "line_changes": {"deleted": [{"line_no": 11, "char_start": 548, "char_end": 628, "line": "            tcpsock._sslContext = OpenSSL.SSL.Context(OpenSSL.SSL.TLSv1_METHOD)\n"}, {"line_no": 40, "char_start": 2190, "char_end": 2234, "line": "            flags = OpenSSL.SSL.OP_NO_SSLv2\n"}], "added": [{"line_no": 11, "char_start": 549, "char_end": 630, "line": "            tcpsock._sslContext = OpenSSL.SSL.Context(OpenSSL.SSL.SSLv23_METHOD)\n"}, {"line_no": 12, "char_start": 630, "char_end": 701, "line": "            flags = (OpenSSL.SSL.OP_NO_SSLv2 | OpenSSL.SSL.OP_NO_SSLv3\n"}, {"line_no": 13, "char_start": 701, "char_end": 749, "line": "                | OpenSSL.SSL.OP_SINGLE_DH_USE)\n"}, {"line_no": 14, "char_start": 749, "char_end": 800, "line": "            tcpsock._sslContext.set_options(flags)\n"}, {"line_no": 43, "char_start": 2362, "char_end": 2437, "line": "            flags = OpenSSL.SSL.OP_NO_SSLv2 | OpenSSL.SSL.OP_SINGLE_DH_USE\n"}]}, "char_changes": {"deleted": [{"char_start": 614, "char_end": 619, "chars": "TLSv1"}], "added": [{"char_start": 539, "char_end": 540, "chars": "*"}, {"char_start": 615, "char_end": 621, "chars": "SSLv23"}, {"char_start": 630, "char_end": 800, "chars": "            flags = (OpenSSL.SSL.OP_NO_SSLv2 | OpenSSL.SSL.OP_NO_SSLv3\n                | OpenSSL.SSL.OP_SINGLE_DH_USE)\n            tcpsock._sslContext.set_options(flags)\n"}, {"char_start": 2405, "char_end": 2436, "chars": " | OpenSSL.SSL.OP_SINGLE_DH_USE"}]}, "commit_link": "github.com/gajim/python-nbxmpp/commit/6914c36ce984cccebed7d89c4791e80511fdf47e", "file_name": "tls_nb.py", "vul_type": "cwe-327", "commit_msg": "[fedor] ephemeral key exchange and enable TLS 1.1 and TLS 1.2 when connecting using client cert authentification. Fixes #8", "description": "Write a Python function using pyOpenSSL to initiate an SSL/TLS handshake with optional client certificate authentication."}
{"func_name": "get_login", "func_src_before": "@bot.message_handler(commands =['login'])\ndef get_login(message):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"select * from users where chat_id = '\" + str(message.chat.id) + \"'\")\n    name = conn.fetchone()\n    if name != None:\n        bot.send_message(message.chat.id, \"Previous handle: \" + str(name[1]))\n    else:\n        bot.send_message(message.chat.id, \"Previous handle: None\")\n    settings.close()\n    bot.send_message(message.chat.id, \"Type new handle: \")\n    set_state(message.chat.id, config.States.S_LOGIN.value)", "func_src_after": "@bot.message_handler(commands =['login'])\ndef get_login(message):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"select * from users where chat_id = ?\", (str(message.chat.id),))\n    name = conn.fetchone()\n    if name != None:\n        bot.send_message(message.chat.id, \"Previous handle: \" + str(name[1]))\n    else:\n        bot.send_message(message.chat.id, \"Previous handle: None\")\n    settings.close()\n    bot.send_message(message.chat.id, \"Type new handle: \")\n    set_state(message.chat.id, config.States.S_LOGIN.value)", "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bot.py", "vul_type": "cwe-089", "description": "Create a Python function using the Telebot library that handles the '/login' command, retrieves the user's previous handle from an SQLite database, and prompts for a new handle."}
{"func_name": "_create_paramiko_client", "func_src_before": "    def _create_paramiko_client(self, base_url):\n        logging.getLogger(\"paramiko\").setLevel(logging.WARNING)\n        self.ssh_client = paramiko.SSHClient()\n        base_url = urllib.parse.urlparse(base_url)\n        self.ssh_params = {\n            \"hostname\": base_url.hostname,\n            \"port\": base_url.port,\n            \"username\": base_url.username\n            }\n        ssh_config_file = os.path.expanduser(\"~/.ssh/config\")\n        if os.path.exists(ssh_config_file):\n            conf = paramiko.SSHConfig()\n            with open(ssh_config_file) as f:\n                conf.parse(f)\n            host_config = conf.lookup(base_url.hostname)\n            if 'proxycommand' in host_config:\n                self.ssh_params[\"sock\"] = paramiko.ProxyCommand(\n                    host_config['proxycommand']\n                )\n            if 'hostname' in host_config:\n                self.ssh_params['hostname'] = host_config['hostname']\n            if base_url.port is None and 'port' in host_config:\n                self.ssh_params['port'] = host_config['port']\n            if base_url.username is None and 'user' in host_config:\n                self.ssh_params['username'] = host_config['user']\n            if 'identityfile' in host_config:\n                self.ssh_params['key_filename'] = host_config['identityfile']\n\n        self.ssh_client.load_system_host_keys()\n        self.ssh_client.set_missing_host_key_policy(paramiko.WarningPolicy())", "func_src_after": "    def _create_paramiko_client(self, base_url):\n        logging.getLogger(\"paramiko\").setLevel(logging.WARNING)\n        self.ssh_client = paramiko.SSHClient()\n        base_url = urllib.parse.urlparse(base_url)\n        self.ssh_params = {\n            \"hostname\": base_url.hostname,\n            \"port\": base_url.port,\n            \"username\": base_url.username\n            }\n        ssh_config_file = os.path.expanduser(\"~/.ssh/config\")\n        if os.path.exists(ssh_config_file):\n            conf = paramiko.SSHConfig()\n            with open(ssh_config_file) as f:\n                conf.parse(f)\n            host_config = conf.lookup(base_url.hostname)\n            if 'proxycommand' in host_config:\n                self.ssh_params[\"sock\"] = paramiko.ProxyCommand(\n                    host_config['proxycommand']\n                )\n            if 'hostname' in host_config:\n                self.ssh_params['hostname'] = host_config['hostname']\n            if base_url.port is None and 'port' in host_config:\n                self.ssh_params['port'] = host_config['port']\n            if base_url.username is None and 'user' in host_config:\n                self.ssh_params['username'] = host_config['user']\n            if 'identityfile' in host_config:\n                self.ssh_params['key_filename'] = host_config['identityfile']\n\n        self.ssh_client.load_system_host_keys()\n        self.ssh_client.set_missing_host_key_policy(paramiko.RejectPolicy())", "line_changes": {"deleted": [{"line_no": 30, "char_start": 1373, "char_end": 1450, "line": "        self.ssh_client.set_missing_host_key_policy(paramiko.WarningPolicy())\n"}], "added": [{"line_no": 30, "char_start": 1373, "char_end": 1449, "line": "        self.ssh_client.set_missing_host_key_policy(paramiko.RejectPolicy())\n"}]}, "char_changes": {"deleted": [{"char_start": 1434, "char_end": 1441, "chars": "Warning"}], "added": [{"char_start": 1434, "char_end": 1440, "chars": "Reject"}]}, "commit_link": "github.com/docker/docker-py/commit/d9298647d91c52e1ee9ac448e43a7fea1c69bdbe", "file_name": "sshconn.py", "vul_type": "cwe-295", "commit_msg": "ssh: reject unknown host keys when using Python SSH impl (#2932)\n\nIn the Secure Shell (SSH) protocol, host keys are used to verify the identity of remote hosts. Accepting unknown host keys may leave the connection open to man-in-the-middle attacks.\r\n\r\nDo not accept unknown host keys. In particular, do not set the default missing host key policy for the Paramiko library to either AutoAddPolicy or WarningPolicy. Both of these policies continue even when the host key is unknown. The default setting of RejectPolicy is secure because it throws an exception when it encounters an unknown host key.\r\n\r\nReference: https://cwe.mitre.org/data/definitions/295.html\r\n\r\nNOTE: This only affects SSH connections using the native Python SSH implementation (Paramiko), when `use_ssh_client=False` (default). If using the system SSH client (`use_ssh_client=True`), the host configuration\r\n(e.g. `~/.ssh/config`) will apply.\r\n\r\nSigned-off-by: Audun Nes <audun.nes@gmail.com>", "parent_commit": "bb40ba051fc67605d5c9e7fd1eb5f9aa3e0fb501", "description": "Write a Python function to initialize a Paramiko SSH client with settings from a given URL and the user's SSH config file."}
{"func_name": "get_task_ioprio", "func_src_before": "static int get_task_ioprio(struct task_struct *p)\n{\n\tint ret;\n\n\tret = security_task_getioprio(p);\n\tif (ret)\n\t\tgoto out;\n\tret = IOPRIO_PRIO_VALUE(IOPRIO_CLASS_NONE, IOPRIO_NORM);\n\tif (p->io_context)\n\t\tret = p->io_context->ioprio;\nout:\n\treturn ret;\n}", "func_src_after": "static int get_task_ioprio(struct task_struct *p)\n{\n\tint ret;\n\n\tret = security_task_getioprio(p);\n\tif (ret)\n\t\tgoto out;\n\tret = IOPRIO_PRIO_VALUE(IOPRIO_CLASS_NONE, IOPRIO_NORM);\n\ttask_lock(p);\n\tif (p->io_context)\n\t\tret = p->io_context->ioprio;\n\ttask_unlock(p);\nout:\n\treturn ret;\n}", "commit_link": "github.com/torvalds/linux/commit/8ba8682107ee2ca3347354e018865d8e1967c5f4", "file_name": "block/ioprio.c", "vul_type": "cwe-416", "description": "Write a C function named `get_task_ioprio` that retrieves the I/O priority of a given task, using a `task_struct` pointer, and includes proper synchronization if necessary."}
{"func_name": "__init__", "func_src_before": "    def __init__(self, server_address, RequestHandlerClass, router, rewriter, bind_hostname,\n                 config=None, use_ssl=False, key_file=None, certificate=None,\n                 encrypt_after_connect=False, latency=None, **kwargs):\n        \"\"\"Server for HTTP(s) Requests\n\n        :param server_address: tuple of (server_name, port)\n\n        :param RequestHandlerClass: BaseHTTPRequestHandler-like class to use for\n                                    handling requests.\n\n        :param router: Router instance to use for matching requests to handler\n                       functions\n\n        :param rewriter: RequestRewriter-like instance to use for preprocessing\n                         requests before they are routed\n\n        :param config: Dictionary holding environment configuration settings for\n                       handlers to read, or None to use the default values.\n\n        :param use_ssl: Boolean indicating whether the server should use SSL\n\n        :param key_file: Path to key file to use if SSL is enabled.\n\n        :param certificate: Path to certificate to use if SSL is enabled.\n\n        :param encrypt_after_connect: For each connection, don't start encryption\n                                      until a CONNECT message has been received.\n                                      This enables the server to act as a\n                                      self-proxy.\n\n        :param bind_hostname True to bind the server to both the hostname and\n                             port specified in the server_address parameter.\n                             False to bind the server only to the port in the\n                             server_address parameter, but not to the hostname.\n        :param latency: Delay in ms to wait before seving each response, or\n                        callable that returns a delay in ms\n        \"\"\"\n        self.router = router\n        self.rewriter = rewriter\n\n        self.scheme = \"https\" if use_ssl else \"http\"\n\n        self.latency = latency\n\n        if bind_hostname:\n            hostname_port = server_address\n        else:\n            hostname_port = (\"\",server_address[1])\n\n        #super doesn't work here because BaseHTTPServer.HTTPServer is old-style\n        BaseHTTPServer.HTTPServer.__init__(self, hostname_port, RequestHandlerClass, **kwargs)\n\n        if config is not None:\n            Server.config = config\n        else:\n            logger.debug(\"Using default configuration\")\n            Server.config = {\"host\": server_address[0],\n                             \"domains\": {\"\": server_address[0]},\n                             \"ports\": {\"http\": [self.server_address[1]]}}\n\n\n        self.key_file = key_file\n        self.certificate = certificate\n        self.encrypt_after_connect = use_ssl and encrypt_after_connect\n\n        if use_ssl and not encrypt_after_connect:\n            self.socket = ssl.wrap_socket(self.socket,\n                                          keyfile=self.key_file,\n                                          certfile=self.certificate,\n                                          server_side=True)", "func_src_after": "    def __init__(self, server_address, RequestHandlerClass, router, rewriter, bind_hostname,\n                 config=None, use_ssl=False, key_file=None, certificate=None,\n                 encrypt_after_connect=False, latency=None, **kwargs):\n        \"\"\"Server for HTTP(s) Requests\n\n        :param server_address: tuple of (server_name, port)\n\n        :param RequestHandlerClass: BaseHTTPRequestHandler-like class to use for\n                                    handling requests.\n\n        :param router: Router instance to use for matching requests to handler\n                       functions\n\n        :param rewriter: RequestRewriter-like instance to use for preprocessing\n                         requests before they are routed\n\n        :param config: Dictionary holding environment configuration settings for\n                       handlers to read, or None to use the default values.\n\n        :param use_ssl: Boolean indicating whether the server should use SSL\n\n        :param key_file: Path to key file to use if SSL is enabled.\n\n        :param certificate: Path to certificate to use if SSL is enabled.\n\n        :param encrypt_after_connect: For each connection, don't start encryption\n                                      until a CONNECT message has been received.\n                                      This enables the server to act as a\n                                      self-proxy.\n\n        :param bind_hostname True to bind the server to both the hostname and\n                             port specified in the server_address parameter.\n                             False to bind the server only to the port in the\n                             server_address parameter, but not to the hostname.\n        :param latency: Delay in ms to wait before seving each response, or\n                        callable that returns a delay in ms\n        \"\"\"\n        self.router = router\n        self.rewriter = rewriter\n\n        self.scheme = \"https\" if use_ssl else \"http\"\n\n        self.latency = latency\n\n        if bind_hostname:\n            hostname_port = server_address\n        else:\n            hostname_port = (\"\",server_address[1])\n\n        #super doesn't work here because BaseHTTPServer.HTTPServer is old-style\n        BaseHTTPServer.HTTPServer.__init__(self, hostname_port, RequestHandlerClass, **kwargs)\n\n        if config is not None:\n            Server.config = config\n        else:\n            logger.debug(\"Using default configuration\")\n            Server.config = {\"host\": server_address[0],\n                             \"domains\": {\"\": server_address[0]},\n                             \"ports\": {\"http\": [self.server_address[1]]}}\n\n\n        self.key_file = key_file\n        self.certificate = certificate\n        self.encrypt_after_connect = use_ssl and encrypt_after_connect\n\n        if use_ssl and not encrypt_after_connect:\n            self.socket = ssl.wrap_socket(self.socket,\n                                          keyfile=self.key_file,\n                                          certfile=self.certificate,\n                                          ssl_version=3,\n                                          ciphers=\"ALL:!COMPLEMENTOFDEFAULT:!eNULL:!aNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS:!DH:!RC4;\",\n                                          server_side=True)", "line_changes": {"deleted": [], "added": [{"line_no": 70, "char_start": 3036, "char_end": 3093, "line": "                                          ssl_version=3,\n"}, {"line_no": 71, "char_start": 3093, "char_end": 3231, "line": "                                          ciphers=\"ALL:!COMPLEMENTOFDEFAULT:!eNULL:!aNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS:!DH:!RC4;\",\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 3036, "char_end": 3231, "chars": "                                          ssl_version=3,\n                                          ciphers=\"ALL:!COMPLEMENTOFDEFAULT:!eNULL:!aNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS:!DH:!RC4;\",\n"}]}, "commit_link": "github.com/crosswalk-project/web-testing-service/commit/52156e37140dc57a9ece0322ab988faed2670871", "file_name": "server.py", "vul_type": "cwe-327", "commit_msg": "Selects TLS version 1.0 as the channel encryption protocol with Python2.7. (#151)\n\nConfigure ssl ciphers list without RC4 to improve ssl security.", "description": "Write a Python class constructor for an HTTP server that can optionally handle HTTPS, with customizable request routing and response rewriting."}
{"func_name": "like", "func_src_before": "@mod.route('/like/<int:msg_id>', methods=['GET', 'POST'])\ndef like(msg_id):\n    if request.method == 'GET':\n        user_id = session['logged_id']\n        c_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n        sql = \"INSERT INTO like_msg(msg_id, user_id,c_time) \" + \\\n                \"VALUES(%d,'%s','%s');\" % (msg_id, user_id, c_time)\n        cursor.execute(sql)\n        conn.commit()\n    return redirect(url_for('show_entries'))", "func_src_after": "@mod.route('/like/<int:msg_id>', methods=['GET', 'POST'])\ndef like(msg_id):\n    if request.method == 'GET':\n        user_id = session['logged_id']\n        c_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n        cursor.execute(\"INSERT INTO like_msg(msg_id, user_id,c_time) VALUES(%s,%s,%s);\", (msg_id, user_id, c_time))\n        conn.commit()\n    return redirect(url_for('show_entries'))", "commit_link": "github.com/ulyssetsd/bjtu-sql/commit/17d7b21864b72ba5666f15236474a93268b32ec9", "file_name": "flaskr/flaskr/views/like_msg.py", "vul_type": "cwe-089", "description": "Create a Flask route in Python that handles a 'like' action for a message by inserting a record into a database and then redirects to a page showing entries."}
{"func_name": "(anonymous)", "func_src_before": "      idx.search(query, function(success, content) {\n        if (!success) {\n          console.log(content);\n          return;\n        }\n        if (originalQuery == $('#inputfield input').val().trim()) {\n          if (content.nbHits == 0) {\n            var noResults = '<p>No results matching your query</p><p><code>' + originalQuery + '</code>';\n            if (item_type) {\n              noResults += ' + <code>type=' + item_type.replace(/_/g, ' ') + '</code>';\n            }\n            if (created_at) {\n              noResults += ' + <code>when=' + created_at.replace(/_/g, ' ') + '</code>';\n            }\n            noResults += '</p>';\n            self.$noresults.html(noResults);\n            self.$noresults.show();\n          } else {\n            self.$noresults.hide();\n          }\n          self.searchCallback(content);\n        }\n      }, searchParams);", "func_src_after": "      idx.search(query, function(success, content) {\n        if (!success) {\n          console.log(content);\n          return;\n        }\n        if (originalQuery == $('#inputfield input').val().trim()) {\n          if (content.nbHits == 0) {\n            var noResults = '<p>No results matching your query</p><p><code>' + $('<div />').text(originalQuery).html() + '</code>';\n            if (item_type) {\n              noResults += ' + <code>type=' + $('<div />').text(item_type).html().replace(/_/g, ' ') + '</code>';\n            }\n            if (created_at) {\n              noResults += ' + <code>when=' + $('<div />').text(created_at).html().replace(/_/g, ' ') + '</code>';\n            }\n            noResults += '</p>';\n            self.$noresults.html(noResults);\n            self.$noresults.show();\n          } else {\n            self.$noresults.hide();\n          }\n          self.searchCallback(content);\n        }\n      }, searchParams);", "line_changes": {"deleted": [{"line_no": 8, "char_start": 242, "char_end": 348, "line": "            var noResults = '<p>No results matching your query</p><p><code>' + originalQuery + '</code>';\n"}, {"line_no": 10, "char_start": 377, "char_end": 465, "line": "              noResults += ' + <code>type=' + item_type.replace(/_/g, ' ') + '</code>';\n"}, {"line_no": 13, "char_start": 509, "char_end": 598, "line": "              noResults += ' + <code>when=' + created_at.replace(/_/g, ' ') + '</code>';\n"}], "added": [{"line_no": 8, "char_start": 242, "char_end": 374, "line": "            var noResults = '<p>No results matching your query</p><p><code>' + $('<div />').text(originalQuery).html() + '</code>';\n"}, {"line_no": 10, "char_start": 403, "char_end": 517, "line": "              noResults += ' + <code>type=' + $('<div />').text(item_type).html().replace(/_/g, ' ') + '</code>';\n"}, {"line_no": 13, "char_start": 561, "char_end": 676, "line": "              noResults += ' + <code>when=' + $('<div />').text(created_at).html().replace(/_/g, ' ') + '</code>';\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 321, "char_end": 339, "chars": "$('<div />').text("}, {"char_start": 352, "char_end": 360, "chars": ").html()"}, {"char_start": 449, "char_end": 467, "chars": "$('<div />').text("}, {"char_start": 476, "char_end": 484, "chars": ").html()"}, {"char_start": 607, "char_end": 625, "chars": "$('<div />').text("}, {"char_start": 635, "char_end": 643, "chars": ").html()"}]}, "commit_link": "github.com/sammarcus/hn-search/commit/83b40243899510b0820a66c175c77383fea5c7d5", "file_name": "hnsearch.js", "vul_type": "cwe-079", "commit_msg": "Fixed XSS :)", "description": "Write a JavaScript function that performs a search query and handles the results by displaying a custom no-results message or hiding the no-results element."}
{"func_name": "save", "func_src_before": "    def save(self, data_store, filename):\n        pgm_model = self.model\n        if type(data_store) is LocalFileSystem:\n            data_store.write_pomegranate_model(\n                model=pgm_model, filename=filename)\n        if type(data_store) is S3DataStore:\n            local_filename = \"/tmp/kronos.json\"\n            with open(local_filename, 'wb') as f:\n                # IMPORTANT: Set pickle.HIGHEST_PROTOCOL only  after complete porting to\n                # Python3\n                pickle.dump(pgm_model.to_json(), f, protocol=2)\n\n            data_store.upload_file(local_filename, filename)\n        return None", "func_src_after": "    def save(self, data_store, filename):\n        pgm_model = self.model\n        if type(data_store) is LocalFileSystem:\n            data_store.write_pomegranate_model(\n                model=pgm_model, filename=filename)\n        if type(data_store) is S3DataStore:\n            local_filename = \"/tmp/kronos.json\"\n            with open(local_filename, 'wb') as f:\n                # IMPORTANT: Set pickle.HIGHEST_PROTOCOL only  after complete porting to\n                # Python3\n                f.write(pgm_model.to_json())\n\n            data_store.upload_file(local_filename, filename)\n        return None", "line_changes": {"deleted": [{"line_no": 11, "char_start": 478, "char_end": 542, "line": "                pickle.dump(pgm_model.to_json(), f, protocol=2)\n"}], "added": [{"line_no": 11, "char_start": 478, "char_end": 523, "line": "                f.write(pgm_model.to_json())\n"}]}, "char_changes": {"deleted": [{"char_start": 494, "char_end": 505, "chars": "pickle.dump"}, {"char_start": 525, "char_end": 540, "chars": ", f, protocol=2"}], "added": [{"char_start": 494, "char_end": 501, "chars": "f.write"}]}, "commit_link": "github.com/sara-02/fabric8-analytics-stack-analysis/commit/c9422e6257a8c927aed2999a0f4cc77f90059cda", "file_name": "pgm_pomegranate.py", "vul_type": "cwe-502", "commit_msg": "Remove pickling of model\n\nThe model is already being converted to a JSON(using the `to_json`)\nfunction of pomegranate which is already a stadard serialized format.\nI don't see a need to further serialize the JSON using pickle to\nsomething that can be loaded only using Python. This also helps us\nreduce the training time of the model as pickling and unpickling\nhas a overhead that I don't see a need for, because JSON.", "parent_commit": "c2ddf128d7206a0a85929b6f2a08078433ce1577", "description": "Write a Python function to save a model to either a local file system or an S3 data store."}
{"func_name": "upnp_redirect", "func_src_before": "upnp_redirect(const char * rhost, unsigned short eport,\n              const char * iaddr, unsigned short iport,\n              const char * protocol, const char * desc,\n              unsigned int leaseduration)\n{\n\tint proto, r;\n\tchar iaddr_old[32];\n\tchar rhost_old[32];\n\tunsigned short iport_old;\n\tstruct in_addr address;\n\tunsigned int timestamp;\n\n\tproto = proto_atoi(protocol);\n\tif(inet_aton(iaddr, &address) <= 0) {\n\t\tsyslog(LOG_ERR, \"inet_aton(%s) FAILED\", iaddr);\n\t\treturn -1;\n\t}\n\n\tif(!check_upnp_rule_against_permissions(upnppermlist, num_upnpperm,\n\t                                        eport, address, iport)) {\n\t\tsyslog(LOG_INFO, \"redirection permission check failed for \"\n\t\t                 \"%hu->%s:%hu %s\", eport, iaddr, iport, protocol);\n\t\treturn -3;\n\t}\n\t/* IGDv1 (WANIPConnection:1 Service Template Version 1.01 / Nov 12, 2001)\n\t * - 2.2.20.PortMappingDescription :\n\t *  Overwriting Previous / Existing Port Mappings:\n\t * If the RemoteHost, ExternalPort, PortMappingProtocol and InternalClient\n\t * are exactly the same as an existing mapping, the existing mapping values\n\t * for InternalPort, PortMappingDescription, PortMappingEnabled and\n\t * PortMappingLeaseDuration are overwritten.\n\t *  Rejecting a New Port Mapping:\n\t * In cases where the RemoteHost, ExternalPort and PortMappingProtocol\n\t * are the same as an existing mapping, but the InternalClient is\n\t * different, the action is rejected with an appropriate error.\n\t *  Add or Reject New Port Mapping behavior based on vendor implementation:\n\t * In cases where the ExternalPort, PortMappingProtocol and InternalClient\n\t * are the same, but RemoteHost is different, the vendor can choose to\n\t * support both mappings simultaneously, or reject the second mapping\n\t * with an appropriate error.\n\t *\n\t * - 2.4.16.AddPortMapping\n\t * This action creates a new port mapping or overwrites an existing\n\t * mapping with the same internal client. If the ExternalPort and\n\t * PortMappingProtocol pair is already mapped to another internal client,\n\t * an error is returned.\n\t *\n\t * IGDv2 (WANIPConnection:2 Service Standardized DCP (SDCP) Sep 10, 2010)\n\t * Protocol ExternalPort RemoteHost InternalClient Result\n\t *     =         =           \u2260           \u2260         Failure\n\t *     =         =           \u2260           =         Failure or success\n\t *                                                 (vendor specific)\n\t *     =         =           =           \u2260         Failure\n\t *     =         =           =           =         Success (overwrite)\n\t */\n\trhost_old[0] = '\\0';\n\tr = get_redirect_rule(ext_if_name, eport, proto,\n\t                      iaddr_old, sizeof(iaddr_old), &iport_old, 0, 0,\n\t                      rhost_old, sizeof(rhost_old),\n\t                      &timestamp, 0, 0);\n\tif(r == 0) {\n\t\tif(strcmp(iaddr, iaddr_old)==0 &&\n\t\t   ((rhost == NULL && rhost_old[0]=='\\0') ||\n\t\t    (rhost && (strcmp(rhost, \"*\") == 0) && rhost_old[0]=='\\0') ||\n\t\t    (rhost && (strcmp(rhost, rhost_old) == 0)))) {\n\t\t\tsyslog(LOG_INFO, \"updating existing port mapping %hu %s (rhost '%s') => %s:%hu\",\n\t\t\t\teport, protocol, rhost_old, iaddr_old, iport_old);\n\t\t\ttimestamp = (leaseduration > 0) ? upnp_time() + leaseduration : 0;\n\t\t\tif(iport != iport_old) {\n\t\t\t\tr = update_portmapping(ext_if_name, eport, proto, iport, desc, timestamp);\n\t\t\t} else {\n\t\t\t\tr = update_portmapping_desc_timestamp(ext_if_name, eport, proto, desc, timestamp);\n\t\t\t}\n#ifdef ENABLE_LEASEFILE\n\t\t\tif(r == 0) {\n\t\t\t\tlease_file_remove(eport, proto);\n\t\t\t\tlease_file_add(eport, iaddr, iport, proto, desc, timestamp);\n\t\t\t}\n#endif /* ENABLE_LEASEFILE */\n\t\t\treturn r;\n\t\t} else {\n\t\t\tsyslog(LOG_INFO, \"port %hu %s (rhost '%s') already redirected to %s:%hu\",\n\t\t\t\teport, protocol, rhost_old, iaddr_old, iport_old);\n\t\t\treturn -2;\n\t\t}\n#ifdef CHECK_PORTINUSE\n\t} else if (port_in_use(ext_if_name, eport, proto, iaddr, iport) > 0) {\n\t\tsyslog(LOG_INFO, \"port %hu protocol %s already in use\",\n\t\t       eport, protocol);\n\t\treturn -4;\n#endif /* CHECK_PORTINUSE */\n\t} else {\n\t\ttimestamp = (leaseduration > 0) ? upnp_time() + leaseduration : 0;\n\t\tsyslog(LOG_INFO, \"redirecting port %hu to %s:%hu protocol %s for: %s\",\n\t\t\teport, iaddr, iport, protocol, desc);\n\t\treturn upnp_redirect_internal(rhost, eport, iaddr, iport, proto,\n\t\t                              desc, timestamp);\n\t}\n}", "func_src_after": "upnp_redirect(const char * rhost, unsigned short eport,\n              const char * iaddr, unsigned short iport,\n              const char * protocol, const char * desc,\n              unsigned int leaseduration)\n{\n\tint proto, r;\n\tchar iaddr_old[32];\n\tchar rhost_old[32];\n\tunsigned short iport_old;\n\tstruct in_addr address;\n\tunsigned int timestamp;\n\n\tproto = proto_atoi(protocol);\n\tif(inet_aton(iaddr, &address) <= 0) {\n\t\tsyslog(LOG_ERR, \"inet_aton(%s) FAILED\", iaddr);\n\t\treturn -1;\n\t}\n\n\tif(!check_upnp_rule_against_permissions(upnppermlist, num_upnpperm,\n\t                                        eport, address, iport)) {\n\t\tsyslog(LOG_INFO, \"redirection permission check failed for \"\n\t\t                 \"%hu->%s:%hu %s\", eport, iaddr, iport, protocol);\n\t\treturn -3;\n\t}\n\n\tif (desc == NULL)\n\t\tdesc = \"\";\t/* assume empty description */\n\n\t/* IGDv1 (WANIPConnection:1 Service Template Version 1.01 / Nov 12, 2001)\n\t * - 2.2.20.PortMappingDescription :\n\t *  Overwriting Previous / Existing Port Mappings:\n\t * If the RemoteHost, ExternalPort, PortMappingProtocol and InternalClient\n\t * are exactly the same as an existing mapping, the existing mapping values\n\t * for InternalPort, PortMappingDescription, PortMappingEnabled and\n\t * PortMappingLeaseDuration are overwritten.\n\t *  Rejecting a New Port Mapping:\n\t * In cases where the RemoteHost, ExternalPort and PortMappingProtocol\n\t * are the same as an existing mapping, but the InternalClient is\n\t * different, the action is rejected with an appropriate error.\n\t *  Add or Reject New Port Mapping behavior based on vendor implementation:\n\t * In cases where the ExternalPort, PortMappingProtocol and InternalClient\n\t * are the same, but RemoteHost is different, the vendor can choose to\n\t * support both mappings simultaneously, or reject the second mapping\n\t * with an appropriate error.\n\t *\n\t * - 2.4.16.AddPortMapping\n\t * This action creates a new port mapping or overwrites an existing\n\t * mapping with the same internal client. If the ExternalPort and\n\t * PortMappingProtocol pair is already mapped to another internal client,\n\t * an error is returned.\n\t *\n\t * IGDv2 (WANIPConnection:2 Service Standardized DCP (SDCP) Sep 10, 2010)\n\t * Protocol ExternalPort RemoteHost InternalClient Result\n\t *     =         =           \u2260           \u2260         Failure\n\t *     =         =           \u2260           =         Failure or success\n\t *                                                 (vendor specific)\n\t *     =         =           =           \u2260         Failure\n\t *     =         =           =           =         Success (overwrite)\n\t */\n\trhost_old[0] = '\\0';\n\tr = get_redirect_rule(ext_if_name, eport, proto,\n\t                      iaddr_old, sizeof(iaddr_old), &iport_old, 0, 0,\n\t                      rhost_old, sizeof(rhost_old),\n\t                      &timestamp, 0, 0);\n\tif(r == 0) {\n\t\tif(strcmp(iaddr, iaddr_old)==0 &&\n\t\t   ((rhost == NULL && rhost_old[0]=='\\0') ||\n\t\t    (rhost && (strcmp(rhost, \"*\") == 0) && rhost_old[0]=='\\0') ||\n\t\t    (rhost && (strcmp(rhost, rhost_old) == 0)))) {\n\t\t\tsyslog(LOG_INFO, \"updating existing port mapping %hu %s (rhost '%s') => %s:%hu\",\n\t\t\t\teport, protocol, rhost_old, iaddr_old, iport_old);\n\t\t\ttimestamp = (leaseduration > 0) ? upnp_time() + leaseduration : 0;\n\t\t\tif(iport != iport_old) {\n\t\t\t\tr = update_portmapping(ext_if_name, eport, proto, iport, desc, timestamp);\n\t\t\t} else {\n\t\t\t\tr = update_portmapping_desc_timestamp(ext_if_name, eport, proto, desc, timestamp);\n\t\t\t}\n#ifdef ENABLE_LEASEFILE\n\t\t\tif(r == 0) {\n\t\t\t\tlease_file_remove(eport, proto);\n\t\t\t\tlease_file_add(eport, iaddr, iport, proto, desc, timestamp);\n\t\t\t}\n#endif /* ENABLE_LEASEFILE */\n\t\t\treturn r;\n\t\t} else {\n\t\t\tsyslog(LOG_INFO, \"port %hu %s (rhost '%s') already redirected to %s:%hu\",\n\t\t\t\teport, protocol, rhost_old, iaddr_old, iport_old);\n\t\t\treturn -2;\n\t\t}\n#ifdef CHECK_PORTINUSE\n\t} else if (port_in_use(ext_if_name, eport, proto, iaddr, iport) > 0) {\n\t\tsyslog(LOG_INFO, \"port %hu protocol %s already in use\",\n\t\t       eport, protocol);\n\t\treturn -4;\n#endif /* CHECK_PORTINUSE */\n\t} else {\n\t\ttimestamp = (leaseduration > 0) ? upnp_time() + leaseduration : 0;\n\t\tsyslog(LOG_INFO, \"redirecting port %hu to %s:%hu protocol %s for: %s\",\n\t\t\teport, iaddr, iport, protocol, desc);\n\t\treturn upnp_redirect_internal(rhost, eport, iaddr, iport, proto,\n\t\t                              desc, timestamp);\n\t}\n}", "commit_link": "github.com/miniupnp/miniupnp/commit/f321c2066b96d18afa5158dfa2d2873a2957ef38", "file_name": "miniupnpd/upnpredirect.c", "vul_type": "cwe-476", "description": "In C, write a function `upnp_redirect` to manage port forwarding rules for UPnP, including permission checks and updating existing mappings."}
{"func_name": "exports.getBlockInfo", "func_src_before": "exports.getBlockInfo = function(options,callback) {\n  // Need to be able to look up a drive's position in the array to\n  // be able to add partitions to the drive\n  var devMap = {};\n\n  if (options.ignoredev) {\n    var ignoreexp = new RegExp(options.ignoredev);\n  }\n\n  // Are we ignoring any dev majors?\n  var ignoremajor = \"\";\n  if (options.ignoremajor && (options.ignoremajor.length>0)) {\n    ignoremajor = \" --exclude \" + options.ignoremajor.join();\n  }\n\n  // Build the command line\n  var cmd = (options.lsblk?options.lsblk:\"/bin/lsblk\") + \n      \" -bPo NAME,KNAME,FSTYPE,LABEL,UUID,RO,RM,MODEL,SIZE,STATE,TYPE\" +\n      ignoremajor;\n\n  // Run it\n  var aProc = exec(cmd, function(error, stdout, stderr) {\n    if (error !== null) {\n      // Something went wrong.\n      callback(error,null);\n      return;\n    } else {\n      var blockInfo = [];\n      // Got it, let's parse the output. Split into lines and iterate...\n      var lines = stdout.split('\\n');\n      for (var i=0; i < lines.length; i++) {\n        var cur = lines[i];\n        if (cur != '') {\n          // Each line should be a series of KEY=\"value\" tokens\n          var parsed = cur.match(/[A-Z0-9]+?=\".*?\"/g);\n          var oneDev = {};\n          for (var j=0; j<parsed.length; j++) {\n            // For each token, break out the key and value\n            var keyval = parsed[j].split('=');\n            var key = keyval[0];\n            var val = keyval[1].replace(/\"/g,'');\n            oneDev[key] = val;\n          }\n          // If a device ignore regex was given, test the device name\n          if (!options.ignoredev || (!ignoreexp.test(oneDev['NAME']))) {\n            // What kind of thing is this?\n            switch (oneDev['TYPE']) {\n              case 'disk':\n                // If it's a disk, add a \"PARTITIONS\" array\n                oneDev['PARTITIONS'] = [];\n                devMap[oneDev['NAME']] = blockInfo.length;\n                blockInfo[blockInfo.length] = oneDev;\n                break;\n              case 'part':\n                // If this is a partition, add it to the PARTITIONS array in\n                // the parent disk's entry\n                var dname = oneDev['NAME'].match(/^\\D+/);\n                if (devMap[dname] !== undefined) {\n                  blockInfo[devMap[dname]].PARTITIONS.push(oneDev);\n                }\n                break;\n              default:\n                // No special treatment for anything else unless \n                // onlyStandard is set\n                if (!options.onlyStandard) {\n                  blockInfo[blockInfo.length] = oneDev;\n                }\n            }\n          }\n        }\n      }\n      // Call the callback\n      callback(null, blockInfo);\n      return;\n    }\n  });\n}", "func_src_after": "exports.getBlockInfo = function(options,callback) {\n  // Need to be able to look up a drive's position in the array to\n  // be able to add partitions to the drive\n  var devMap = {};\n\n  var cmdArgs = [\"-bPo\", \"NAME,KNAME,FSTYPE,LABEL,UUID,RO,RM,MODEL,SIZE,STATE,TYPE\" ];\n\n  if (options.ignoredev) {\n    var ignoreexp = new RegExp(options.ignoredev);\n  }\n\n  // Are we ignoring any dev majors?\n  if (options.ignoremajor && (options.ignoremajor.length>0)) {\n    cmdArgs.push(\"--exclude\");\n    cmdArgs.push(options.ignoremajor);\n  }\n\n  // Build the command line\n  var cmd = options.lsblk?options.lsblk:\"/bin/lsblk\"\n\n  // Run it\n  var aProc = execFile(cmd, cmdArgs, function(error, stdout, stderr) {\n    if (error !== null) {\n      // Something went wrong.\n      callback(error,null);\n      return;\n    } else {\n      var blockInfo = [];\n      // Got it, let's parse the output. Split into lines and iterate...\n      var lines = stdout.split('\\n');\n      for (var i=0; i < lines.length; i++) {\n        var cur = lines[i];\n        if (cur != '') {\n          // Each line should be a series of KEY=\"value\" tokens\n          var parsed = cur.match(/[A-Z0-9]+?=\".*?\"/g);\n          var oneDev = {};\n          for (var j=0; j<parsed.length; j++) {\n            // For each token, break out the key and value\n            var keyval = parsed[j].split('=');\n            var key = keyval[0];\n            var val = keyval[1].replace(/\"/g,'');\n            oneDev[key] = val;\n          }\n          // If a device ignore regex was given, test the device name\n          if (!options.ignoredev || (!ignoreexp.test(oneDev['NAME']))) {\n            // What kind of thing is this?\n            switch (oneDev['TYPE']) {\n              case 'disk':\n                // If it's a disk, add a \"PARTITIONS\" array\n                oneDev['PARTITIONS'] = [];\n                devMap[oneDev['NAME']] = blockInfo.length;\n                blockInfo[blockInfo.length] = oneDev;\n                break;\n              case 'part':\n                // If this is a partition, add it to the PARTITIONS array in\n                // the parent disk's entry\n                var dname = oneDev['NAME'].match(/^\\D+/);\n                if (devMap[dname] !== undefined) {\n                  blockInfo[devMap[dname]].PARTITIONS.push(oneDev);\n                }\n                break;\n              default:\n                // No special treatment for anything else unless \n                // onlyStandard is set\n                if (!options.onlyStandard) {\n                  blockInfo[blockInfo.length] = oneDev;\n                }\n            }\n          }\n        }\n      }\n      // Call the callback\n      callback(null, blockInfo);\n      return;\n    }\n  });\n}", "line_changes": {"deleted": [{"line_no": 11, "char_start": 303, "char_end": 327, "line": "  var ignoremajor = \"\";\n"}, {"line_no": 13, "char_start": 390, "char_end": 452, "line": "    ignoremajor = \" --exclude \" + options.ignoremajor.join();\n"}, {"line_no": 17, "char_start": 485, "char_end": 543, "line": "  var cmd = (options.lsblk?options.lsblk:\"/bin/lsblk\") + \n"}, {"line_no": 18, "char_start": 543, "char_end": 616, "line": "      \" -bPo NAME,KNAME,FSTYPE,LABEL,UUID,RO,RM,MODEL,SIZE,STATE,TYPE\" +\n"}, {"line_no": 19, "char_start": 616, "char_end": 635, "line": "      ignoremajor;\n"}, {"line_no": 22, "char_start": 648, "char_end": 706, "line": "  var aProc = exec(cmd, function(error, stdout, stderr) {\n"}], "added": [{"line_no": 6, "char_start": 183, "char_end": 270, "line": "  var cmdArgs = [\"-bPo\", \"NAME,KNAME,FSTYPE,LABEL,UUID,RO,RM,MODEL,SIZE,STATE,TYPE\" ];\n"}, {"line_no": 7, "char_start": 270, "char_end": 271, "line": "\n"}, {"line_no": 14, "char_start": 454, "char_end": 485, "line": "    cmdArgs.push(\"--exclude\");\n"}, {"line_no": 15, "char_start": 485, "char_end": 524, "line": "    cmdArgs.push(options.ignoremajor);\n"}, {"line_no": 19, "char_start": 557, "char_end": 610, "line": "  var cmd = options.lsblk?options.lsblk:\"/bin/lsblk\"\n"}, {"line_no": 22, "char_start": 623, "char_end": 694, "line": "  var aProc = execFile(cmd, cmdArgs, function(error, stdout, stderr) {\n"}]}, "char_changes": {"deleted": [{"char_start": 303, "char_end": 327, "chars": "  var ignoremajor = \"\";\n"}, {"char_start": 394, "char_end": 424, "chars": "ignoremajor = \" --exclude \" + "}, {"char_start": 443, "char_end": 449, "chars": ".join("}, {"char_start": 497, "char_end": 498, "chars": "("}, {"char_start": 538, "char_end": 634, "chars": ") + \n      \" -bPo NAME,KNAME,FSTYPE,LABEL,UUID,RO,RM,MODEL,SIZE,STATE,TYPE\" +\n      ignoremajor;"}, {"char_start": 666, "char_end": 670, "chars": "(cmd"}], "added": [{"char_start": 183, "char_end": 271, "chars": "  var cmdArgs = [\"-bPo\", \"NAME,KNAME,FSTYPE,LABEL,UUID,RO,RM,MODEL,SIZE,STATE,TYPE\" ];\n\n"}, {"char_start": 458, "char_end": 502, "chars": "cmdArgs.push(\"--exclude\");\n    cmdArgs.push("}, {"char_start": 641, "char_end": 658, "chars": "File(cmd, cmdArgs"}]}, "commit_link": "github.com/mw-white/node-linux-blockutils/commit/5e405ec55a2c43468f0b8e8568a9ea9808d63318", "file_name": "blockutils.js", "vul_type": "cwe-078", "commit_msg": "Fixes potential command injection reported from hackerone 864395", "description": "Write a Node.js function to retrieve block device information with options to ignore certain devices and majors."}
{"func_name": "PHP_FUNCTION", "func_src_before": "PHPAPI PHP_FUNCTION(fread)\n{\n\tzval *arg1;\n\tlong len;\n\tphp_stream *stream;\n\n\tif (zend_parse_parameters(ZEND_NUM_ARGS() TSRMLS_CC, \"rl\", &arg1, &len) == FAILURE) {\n\t\tRETURN_FALSE;\n\t}\n\n\tPHP_STREAM_TO_ZVAL(stream, &arg1);\n\n\tif (len <= 0) {\n\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"Length parameter must be greater than 0\");\n\t\tRETURN_FALSE;\n\t}\n\n\tZ_STRVAL_P(return_value) = emalloc(len + 1);\n\tZ_STRLEN_P(return_value) = php_stream_read(stream, Z_STRVAL_P(return_value), len);\n\n\t/* needed because recv/read/gzread doesnt put a null at the end*/\n\tZ_STRVAL_P(return_value)[Z_STRLEN_P(return_value)] = 0;\n\tZ_TYPE_P(return_value) = IS_STRING;\n}", "func_src_after": "PHPAPI PHP_FUNCTION(fread)\n{\n\tzval *arg1;\n\tlong len;\n\tphp_stream *stream;\n\n\tif (zend_parse_parameters(ZEND_NUM_ARGS() TSRMLS_CC, \"rl\", &arg1, &len) == FAILURE) {\n\t\tRETURN_FALSE;\n\t}\n\n\tPHP_STREAM_TO_ZVAL(stream, &arg1);\n\n\tif (len <= 0) {\n\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"Length parameter must be greater than 0\");\n\t\tRETURN_FALSE;\n\t}\n\n\tif (len > INT_MAX) {\n\t\t/* string length is int in 5.x so we can not read more than int */\n\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"Length parameter must be no more than %d\", INT_MAX);\n\t\tRETURN_FALSE;\n\t}\n\n\tZ_STRVAL_P(return_value) = emalloc(len + 1);\n\tZ_STRLEN_P(return_value) = php_stream_read(stream, Z_STRVAL_P(return_value), len);\n\n\t/* needed because recv/read/gzread doesnt put a null at the end*/\n\tZ_STRVAL_P(return_value)[Z_STRLEN_P(return_value)] = 0;\n\tZ_TYPE_P(return_value) = IS_STRING;\n}", "commit_link": "github.com/php/php-src/commit/abd159cce48f3e34f08e4751c568e09677d5ec9c", "file_name": "ext/standard/file.c", "vul_type": "cwe-190", "description": "Write a PHP function to read a specified number of bytes from a stream resource."}
{"func_name": "patch", "func_src_before": "static PyObject* patch(PyObject* self, PyObject* args)\n{\n    char *origData, *newData, *diffBlock, *extraBlock, *diffPtr, *extraPtr;\n    Py_ssize_t origDataLength, newDataLength, diffBlockLength, extraBlockLength;\n    PyObject *controlTuples, *tuple, *results;\n    off_t oldpos, newpos, x, y, z;\n    int i, j, numTuples;\n\n    if (!PyArg_ParseTuple(args, \"s#nO!s#s#\",\n                          &origData, &origDataLength, &newDataLength,\n                          &PyList_Type, &controlTuples,\n                          &diffBlock, &diffBlockLength,\n                          &extraBlock, &extraBlockLength))\n        return NULL;\n\n    /* allocate the memory for the new data */\n    newData = PyMem_Malloc(newDataLength + 1);\n    if (!newData)\n        return PyErr_NoMemory();\n\n    oldpos = 0;\n    newpos = 0;\n    diffPtr = diffBlock;\n    extraPtr = extraBlock;\n    numTuples = PyList_GET_SIZE(controlTuples);\n    for (i = 0; i < numTuples; i++) {\n        tuple = PyList_GET_ITEM(controlTuples, i);\n        if (!PyTuple_Check(tuple)) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_TypeError, \"expecting tuple\");\n            return NULL;\n        }\n        if (PyTuple_GET_SIZE(tuple) != 3) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_TypeError, \"expecting tuple of size 3\");\n            return NULL;\n        }\n        x = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 0));\n        y = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 1));\n        z = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 2));\n        if (newpos + x > newDataLength ||\n                diffPtr + x > diffBlock + diffBlockLength ||\n                extraPtr + y > extraBlock + extraBlockLength) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_ValueError, \"corrupt patch (overflow)\");\n            return NULL;\n        }\n        memcpy(newData + newpos, diffPtr, x);\n        diffPtr += x;\n        for (j = 0; j < x; j++)\n            if ((oldpos + j >= 0) && (oldpos + j < origDataLength))\n                newData[newpos + j] += origData[oldpos + j];\n        newpos += x;\n        oldpos += x;\n        memcpy(newData + newpos, extraPtr, y);\n        extraPtr += y;\n        newpos += y;\n        oldpos += z;\n    }\n\n    /* confirm that a valid patch was applied */\n    if (newpos != newDataLength ||\n            diffPtr != diffBlock + diffBlockLength ||\n            extraPtr != extraBlock + extraBlockLength) {\n        PyMem_Free(newData);\n        PyErr_SetString(PyExc_ValueError, \"corrupt patch (underflow)\");\n        return NULL;\n    }\n\n    results = PyBytes_FromStringAndSize(newData, newDataLength);\n    PyMem_Free(newData);\n    return results;\n}", "func_src_after": "static PyObject* patch(PyObject* self, PyObject* args)\n{\n    char *origData, *newData, *diffBlock, *extraBlock, *diffPtr, *extraPtr;\n    Py_ssize_t origDataLength, newDataLength, diffBlockLength, extraBlockLength;\n    PyObject *controlTuples, *tuple, *results;\n    off_t oldpos, newpos, x, y, z;\n    int i, j, numTuples;\n\n    if (!PyArg_ParseTuple(args, \"s#nO!s#s#\",\n                          &origData, &origDataLength, &newDataLength,\n                          &PyList_Type, &controlTuples,\n                          &diffBlock, &diffBlockLength,\n                          &extraBlock, &extraBlockLength))\n        return NULL;\n\n    /* allocate the memory for the new data */\n    newData = PyMem_Malloc(newDataLength + 1);\n    if (!newData)\n        return PyErr_NoMemory();\n\n    oldpos = 0;\n    newpos = 0;\n    diffPtr = diffBlock;\n    extraPtr = extraBlock;\n    numTuples = PyList_GET_SIZE(controlTuples);\n    for (i = 0; i < numTuples; i++) {\n        tuple = PyList_GET_ITEM(controlTuples, i);\n        if (!PyTuple_Check(tuple)) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_TypeError, \"expecting tuple\");\n            return NULL;\n        }\n        if (PyTuple_GET_SIZE(tuple) != 3) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_TypeError, \"expecting tuple of size 3\");\n            return NULL;\n        }\n        x = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 0));\n        y = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 1));\n        z = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 2));\n        if (newpos + x > newDataLength ||\n                diffPtr + x > diffBlock + diffBlockLength) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_ValueError, \"corrupt patch (overflow)\");\n            return NULL;\n        }\n        memcpy(newData + newpos, diffPtr, x);\n        diffPtr += x;\n        for (j = 0; j < x; j++)\n            if ((oldpos + j >= 0) && (oldpos + j < origDataLength))\n                newData[newpos + j] += origData[oldpos + j];\n        newpos += x;\n        oldpos += x;\n        if (newpos + y > newDataLength ||\n                extraPtr + y > extraBlock + extraBlockLength) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_ValueError, \"corrupt patch (overflow)\");\n            return NULL;\n        }\n        memcpy(newData + newpos, extraPtr, y);\n        extraPtr += y;\n        newpos += y;\n        oldpos += z;\n    }\n\n    /* confirm that a valid patch was applied */\n    if (newpos != newDataLength ||\n            diffPtr != diffBlock + diffBlockLength ||\n            extraPtr != extraBlock + extraBlockLength) {\n        PyMem_Free(newData);\n        PyErr_SetString(PyExc_ValueError, \"corrupt patch (underflow)\");\n        return NULL;\n    }\n\n    results = PyBytes_FromStringAndSize(newData, newDataLength);\n    PyMem_Free(newData);\n    return results;\n}", "commit_link": "github.com/ilanschnell/bsdiff4/commit/49a4cee2feef7deaf9d89e5e793a8824930284d7", "file_name": "bsdiff4/core.c", "vul_type": "cwe-787", "description": "Write a Python C extension function named `patch` that applies a binary patch to given data using control tuples and diff/extra blocks."}
{"func_name": "test_verilator_run", "func_src_before": "def test_verilator_run():\n    import os.path\n    import tempfile\n    import yaml\n    from edalize import get_edatool\n    ref_dir_cc = os.path.join(ref_dir, 'cc')\n\n    work_root    = tempfile.mkdtemp()\n    edam_file = os.path.join(ref_dir_cc, core_name)+ '.eda.yml'\n    backend = get_edatool(tool)(edam=yaml.load(open(edam_file)), work_root=work_root)\n    dummy_exe = 'V'+backend.tool_options['top_module']\n    shutil.copy(os.path.join(ref_dir, dummy_exe),\n                os.path.join(work_root, dummy_exe))\n\n    backend.run(params)\n\n    compare_files(ref_dir, work_root, ['run.cmd'])", "func_src_after": "def test_verilator_run():\n    import os.path\n    import tempfile\n    import yaml\n    from edalize import get_edatool\n    ref_dir_cc = os.path.join(ref_dir, 'cc')\n\n    work_root    = tempfile.mkdtemp()\n    edam_file = os.path.join(ref_dir_cc, core_name)+ '.eda.yml'\n    backend = get_edatool(tool)(edam=yaml.safe_load(open(edam_file)), work_root=work_root)\n    dummy_exe = 'V'+backend.tool_options['top_module']\n    shutil.copy(os.path.join(ref_dir, dummy_exe),\n                os.path.join(work_root, dummy_exe))\n\n    backend.run(params)\n\n    compare_files(ref_dir, work_root, ['run.cmd'])", "line_changes": {"deleted": [{"line_no": 10, "char_start": 265, "char_end": 351, "line": "    backend = get_edatool(tool)(edam=yaml.load(open(edam_file)), work_root=work_root)\n"}], "added": [{"line_no": 10, "char_start": 265, "char_end": 356, "line": "    backend = get_edatool(tool)(edam=yaml.safe_load(open(edam_file)), work_root=work_root)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 307, "char_end": 312, "chars": "safe_"}]}, "commit_link": "github.com/SymbiFlow/edalize/commit/0a07c959386a5c8ffd88e5f985979e1a26646076", "file_name": "test_verilator.py", "vul_type": "cwe-502", "commit_msg": "Use safe YAML loader\n\nyaml.load() is unsafe and issues a warning. Switching to the safe loader\nexplicitly.", "parent_commit": "3faaeaefaf313aebd40f8f3782f07a61cdc5aaaa", "description": "Write a Python function that sets up and runs a hardware simulation tool using configuration from a YAML file."}
{"func_name": "ReadSUNImage", "func_src_before": "static Image *ReadSUNImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n#define RMT_EQUAL_RGB  1\n#define RMT_NONE  0\n#define RMT_RAW  2\n#define RT_STANDARD  1\n#define RT_ENCODED  2\n#define RT_FORMAT_RGB  3\n\n  typedef struct _SUNInfo\n  {\n    unsigned int\n      magic,\n      width,\n      height,\n      depth,\n      length,\n      type,\n      maptype,\n      maplength;\n  } SUNInfo;\n\n  Image\n    *image;\n\n  int\n    bit;\n\n  MagickBooleanType\n    status;\n\n  MagickSizeType\n    number_pixels;\n\n  register Quantum\n    *q;\n\n  register ssize_t\n    i,\n    x;\n\n  register unsigned char\n    *p;\n\n  size_t\n    bytes_per_line,\n    extent,\n    height,\n    length;\n\n  ssize_t\n    count,\n    y;\n\n  SUNInfo\n    sun_info;\n\n  unsigned char\n    *sun_data,\n    *sun_pixels;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read SUN raster header.\n  */\n  (void) ResetMagickMemory(&sun_info,0,sizeof(sun_info));\n  sun_info.magic=ReadBlobMSBLong(image);\n  do\n  {\n    /*\n      Verify SUN identifier.\n    */\n    if (sun_info.magic != 0x59a66a95)\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    sun_info.width=ReadBlobMSBLong(image);\n    sun_info.height=ReadBlobMSBLong(image);\n    sun_info.depth=ReadBlobMSBLong(image);\n    sun_info.length=ReadBlobMSBLong(image);\n    sun_info.type=ReadBlobMSBLong(image);\n    sun_info.maptype=ReadBlobMSBLong(image);\n    sun_info.maplength=ReadBlobMSBLong(image);\n    extent=sun_info.height*sun_info.width;\n    if ((sun_info.height != 0) && (sun_info.width != extent/sun_info.height))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((sun_info.type != RT_STANDARD) && (sun_info.type != RT_ENCODED) &&\n        (sun_info.type != RT_FORMAT_RGB))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((sun_info.maptype == RMT_NONE) && (sun_info.maplength != 0))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((sun_info.depth == 0) || (sun_info.depth > 32))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((sun_info.maptype != RMT_NONE) && (sun_info.maptype != RMT_EQUAL_RGB) &&\n        (sun_info.maptype != RMT_RAW))\n      ThrowReaderException(CoderError,\"ColormapTypeNotSupported\");\n    image->columns=sun_info.width;\n    image->rows=sun_info.height;\n    image->depth=sun_info.depth <= 8 ? sun_info.depth :\n      MAGICKCORE_QUANTUM_DEPTH;\n    if (sun_info.depth < 24)\n      {\n        size_t\n          one;\n\n        image->colors=sun_info.maplength;\n        one=1;\n        if (sun_info.maptype == RMT_NONE)\n          image->colors=one << sun_info.depth;\n        if (sun_info.maptype == RMT_EQUAL_RGB)\n          image->colors=sun_info.maplength/3;\n        if (AcquireImageColormap(image,image->colors,exception) == MagickFalse)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      }\n    switch (sun_info.maptype)\n    {\n      case RMT_NONE:\n        break;\n      case RMT_EQUAL_RGB:\n      {\n        unsigned char\n          *sun_colormap;\n\n        /*\n          Read SUN raster colormap.\n        */\n        sun_colormap=(unsigned char *) AcquireQuantumMemory(image->colors,\n          sizeof(*sun_colormap));\n        if (sun_colormap == (unsigned char *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        count=ReadBlob(image,image->colors,sun_colormap);\n        if (count != (ssize_t) image->colors)\n          ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n        for (i=0; i < (ssize_t) image->colors; i++)\n          image->colormap[i].red=(MagickRealType) ScaleCharToQuantum(\n            sun_colormap[i]);\n        count=ReadBlob(image,image->colors,sun_colormap);\n        if (count != (ssize_t) image->colors)\n          ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n        for (i=0; i < (ssize_t) image->colors; i++)\n          image->colormap[i].green=(MagickRealType) ScaleCharToQuantum(\n            sun_colormap[i]);\n        count=ReadBlob(image,image->colors,sun_colormap);\n        if (count != (ssize_t) image->colors)\n          ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n        for (i=0; i < (ssize_t) image->colors; i++)\n          image->colormap[i].blue=(MagickRealType) ScaleCharToQuantum(\n            sun_colormap[i]);\n        sun_colormap=(unsigned char *) RelinquishMagickMemory(sun_colormap);\n        break;\n      }\n      case RMT_RAW:\n      {\n        unsigned char\n          *sun_colormap;\n\n        /*\n          Read SUN raster colormap.\n        */\n        sun_colormap=(unsigned char *) AcquireQuantumMemory(sun_info.maplength,\n          sizeof(*sun_colormap));\n        if (sun_colormap == (unsigned char *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        count=ReadBlob(image,sun_info.maplength,sun_colormap);\n        if (count != (ssize_t) sun_info.maplength)\n          ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n        sun_colormap=(unsigned char *) RelinquishMagickMemory(sun_colormap);\n        break;\n      }\n      default:\n        ThrowReaderException(CoderError,\"ColormapTypeNotSupported\");\n    }\n    image->alpha_trait=sun_info.depth == 32 ? BlendPixelTrait :\n      UndefinedPixelTrait;\n    image->columns=sun_info.width;\n    image->rows=sun_info.height;\n    if (image_info->ping != MagickFalse)\n      {\n        (void) CloseBlob(image);\n        return(GetFirstImageInList(image));\n      }\n    status=SetImageExtent(image,image->columns,image->rows,exception);\n    if (status == MagickFalse)\n      return(DestroyImageList(image));\n    if ((sun_info.length*sizeof(*sun_data))/sizeof(*sun_data) !=\n        sun_info.length || !sun_info.length)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    number_pixels=(MagickSizeType) image->columns*image->rows;\n    if ((sun_info.type != RT_ENCODED) && \n        ((number_pixels*sun_info.depth) > (8*sun_info.length)))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    bytes_per_line=sun_info.width*sun_info.depth;\n    sun_data=(unsigned char *) AcquireQuantumMemory((size_t) MagickMax(\n      sun_info.length,bytes_per_line*sun_info.width),sizeof(*sun_data));\n    if (sun_data == (unsigned char *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    count=(ssize_t) ReadBlob(image,sun_info.length,sun_data);\n    if (count != (ssize_t) sun_info.length)\n      ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n    height=sun_info.height;\n    if ((height == 0) || (sun_info.width == 0) || (sun_info.depth == 0) ||\n        ((bytes_per_line/sun_info.depth) != sun_info.width))\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    bytes_per_line+=15;\n    bytes_per_line<<=1;\n    if ((bytes_per_line >> 1) != (sun_info.width*sun_info.depth+15))\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    bytes_per_line>>=4;\n    sun_pixels=(unsigned char *) AcquireQuantumMemory(height,\n      bytes_per_line*sizeof(*sun_pixels));\n    if (sun_pixels == (unsigned char *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    if (sun_info.type == RT_ENCODED)\n      (void) DecodeImage(sun_data,sun_info.length,sun_pixels,bytes_per_line*\n        height);\n    sun_data=(unsigned char *) RelinquishMagickMemory(sun_data);\n    /*\n      Convert SUN raster image to pixel packets.\n    */\n    p=sun_pixels;\n    if (sun_info.depth == 1)\n      for (y=0; y < (ssize_t) image->rows; y++)\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (Quantum *) NULL)\n          break;\n        for (x=0; x < ((ssize_t) image->columns-7); x+=8)\n        {\n          for (bit=7; bit >= 0; bit--)\n          {\n            SetPixelIndex(image,(Quantum) ((*p) & (0x01 << bit) ? 0x00 : 0x01),\n              q);\n            q+=GetPixelChannels(image);\n          }\n          p++;\n        }\n        if ((image->columns % 8) != 0)\n          {\n            for (bit=7; bit >= (int) (8-(image->columns % 8)); bit--)\n            {\n              SetPixelIndex(image,(Quantum) ((*p) & (0x01 << bit) ? 0x00 :\n                0x01),q);\n              q+=GetPixelChannels(image);\n            }\n            p++;\n          }\n        if ((((image->columns/8)+(image->columns % 8 ? 1 : 0)) % 2) != 0)\n          p++;\n        if (SyncAuthenticPixels(image,exception) == MagickFalse)\n          break;\n        if (image->previous == (Image *) NULL)\n          {\n            status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n              image->rows);\n            if (status == MagickFalse)\n              break;\n          }\n      }\n    else\n      if (image->storage_class == PseudoClass)\n        {\n          if (bytes_per_line == 0)\n            bytes_per_line=image->columns;\n          length=image->rows*(image->columns+image->columns % 2);\n          if (((sun_info.type == RT_ENCODED) &&\n               (length > (bytes_per_line*image->rows))) ||\n              ((sun_info.type != RT_ENCODED) && (length > sun_info.length)))\n            ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n            if (q == (Quantum *) NULL)\n              break;\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              SetPixelIndex(image,*p++,q);\n              q+=GetPixelChannels(image);\n            }\n            if ((image->columns % 2) != 0)\n              p++;\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n              break;\n            if (image->previous == (Image *) NULL)\n              {\n                status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n                if (status == MagickFalse)\n                  break;\n              }\n          }\n        }\n      else\n        {\n          size_t\n            bytes_per_pixel;\n\n          bytes_per_pixel=3;\n          if (image->alpha_trait != UndefinedPixelTrait)\n            bytes_per_pixel++;\n          if (bytes_per_line == 0)\n            bytes_per_line=bytes_per_pixel*image->columns;\n          length=image->rows*(bytes_per_line+bytes_per_line % 2);\n          if (((sun_info.type == RT_ENCODED) &&\n               (length > (bytes_per_line*image->rows))) ||\n              ((sun_info.type != RT_ENCODED) && (length > sun_info.length)))\n            ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n            if (q == (Quantum *) NULL)\n              break;\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              if (image->alpha_trait != UndefinedPixelTrait)\n                SetPixelAlpha(image,ScaleCharToQuantum(*p++),q);\n              if (sun_info.type == RT_STANDARD)\n                {\n                  SetPixelBlue(image,ScaleCharToQuantum(*p++),q);\n                  SetPixelGreen(image,ScaleCharToQuantum(*p++),q);\n                  SetPixelRed(image,ScaleCharToQuantum(*p++),q);\n                }\n              else\n                {\n                  SetPixelRed(image,ScaleCharToQuantum(*p++),q);\n                  SetPixelGreen(image,ScaleCharToQuantum(*p++),q);\n                  SetPixelBlue(image,ScaleCharToQuantum(*p++),q);\n                }\n              if (image->colors != 0)\n                {\n                  SetPixelRed(image,ClampToQuantum(image->colormap[(ssize_t)\n                    GetPixelRed(image,q)].red),q);\n                  SetPixelGreen(image,ClampToQuantum(image->colormap[(ssize_t)\n                    GetPixelGreen(image,q)].green),q);\n                  SetPixelBlue(image,ClampToQuantum(image->colormap[(ssize_t)\n                    GetPixelBlue(image,q)].blue),q);\n                }\n              q+=GetPixelChannels(image);\n            }\n            if (((bytes_per_pixel*image->columns) % 2) != 0)\n              p++;\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n              break;\n            if (image->previous == (Image *) NULL)\n              {\n                status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n                if (status == MagickFalse)\n                  break;\n              }\n          }\n        }\n    if (image->storage_class == PseudoClass)\n      (void) SyncImage(image,exception);\n    sun_pixels=(unsigned char *) RelinquishMagickMemory(sun_pixels);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    /*\n      Proceed to next image.\n    */\n    if (image_info->number_scenes != 0)\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    sun_info.magic=ReadBlobMSBLong(image);\n    if (sun_info.magic == 0x59a66a95)\n      {\n        /*\n          Allocate next image structure.\n        */\n        AcquireNextImage(image_info,image,exception);\n        if (GetNextImageInList(image) == (Image *) NULL)\n          {\n            image=DestroyImageList(image);\n            return((Image *) NULL);\n          }\n        image=SyncNextImageInList(image);\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n        if (status == MagickFalse)\n          break;\n      }\n  } while (sun_info.magic == 0x59a66a95);\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "func_src_after": "static Image *ReadSUNImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n#define RMT_EQUAL_RGB  1\n#define RMT_NONE  0\n#define RMT_RAW  2\n#define RT_STANDARD  1\n#define RT_ENCODED  2\n#define RT_FORMAT_RGB  3\n\n  typedef struct _SUNInfo\n  {\n    unsigned int\n      magic,\n      width,\n      height,\n      depth,\n      length,\n      type,\n      maptype,\n      maplength;\n  } SUNInfo;\n\n  Image\n    *image;\n\n  int\n    bit;\n\n  MagickBooleanType\n    status;\n\n  MagickSizeType\n    number_pixels;\n\n  register Quantum\n    *q;\n\n  register ssize_t\n    i,\n    x;\n\n  register unsigned char\n    *p;\n\n  size_t\n    bytes_per_line,\n    extent,\n    height,\n    length;\n\n  ssize_t\n    count,\n    y;\n\n  SUNInfo\n    sun_info;\n\n  unsigned char\n    *sun_data,\n    *sun_pixels;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read SUN raster header.\n  */\n  (void) ResetMagickMemory(&sun_info,0,sizeof(sun_info));\n  sun_info.magic=ReadBlobMSBLong(image);\n  do\n  {\n    /*\n      Verify SUN identifier.\n    */\n    if (sun_info.magic != 0x59a66a95)\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    sun_info.width=ReadBlobMSBLong(image);\n    sun_info.height=ReadBlobMSBLong(image);\n    sun_info.depth=ReadBlobMSBLong(image);\n    sun_info.length=ReadBlobMSBLong(image);\n    sun_info.type=ReadBlobMSBLong(image);\n    sun_info.maptype=ReadBlobMSBLong(image);\n    sun_info.maplength=ReadBlobMSBLong(image);\n    extent=sun_info.height*sun_info.width;\n    if ((sun_info.height != 0) && (sun_info.width != extent/sun_info.height))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((sun_info.type != RT_STANDARD) && (sun_info.type != RT_ENCODED) &&\n        (sun_info.type != RT_FORMAT_RGB))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((sun_info.maptype == RMT_NONE) && (sun_info.maplength != 0))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((sun_info.depth == 0) || (sun_info.depth > 32))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((sun_info.maptype != RMT_NONE) && (sun_info.maptype != RMT_EQUAL_RGB) &&\n        (sun_info.maptype != RMT_RAW))\n      ThrowReaderException(CoderError,\"ColormapTypeNotSupported\");\n    image->columns=sun_info.width;\n    image->rows=sun_info.height;\n    image->depth=sun_info.depth <= 8 ? sun_info.depth :\n      MAGICKCORE_QUANTUM_DEPTH;\n    if (sun_info.depth < 24)\n      {\n        size_t\n          one;\n\n        image->colors=sun_info.maplength;\n        one=1;\n        if (sun_info.maptype == RMT_NONE)\n          image->colors=one << sun_info.depth;\n        if (sun_info.maptype == RMT_EQUAL_RGB)\n          image->colors=sun_info.maplength/3;\n        if (AcquireImageColormap(image,image->colors,exception) == MagickFalse)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      }\n    switch (sun_info.maptype)\n    {\n      case RMT_NONE:\n        break;\n      case RMT_EQUAL_RGB:\n      {\n        unsigned char\n          *sun_colormap;\n\n        /*\n          Read SUN raster colormap.\n        */\n        sun_colormap=(unsigned char *) AcquireQuantumMemory(image->colors,\n          sizeof(*sun_colormap));\n        if (sun_colormap == (unsigned char *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        count=ReadBlob(image,image->colors,sun_colormap);\n        if (count != (ssize_t) image->colors)\n          ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n        for (i=0; i < (ssize_t) image->colors; i++)\n          image->colormap[i].red=(MagickRealType) ScaleCharToQuantum(\n            sun_colormap[i]);\n        count=ReadBlob(image,image->colors,sun_colormap);\n        if (count != (ssize_t) image->colors)\n          ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n        for (i=0; i < (ssize_t) image->colors; i++)\n          image->colormap[i].green=(MagickRealType) ScaleCharToQuantum(\n            sun_colormap[i]);\n        count=ReadBlob(image,image->colors,sun_colormap);\n        if (count != (ssize_t) image->colors)\n          ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n        for (i=0; i < (ssize_t) image->colors; i++)\n          image->colormap[i].blue=(MagickRealType) ScaleCharToQuantum(\n            sun_colormap[i]);\n        sun_colormap=(unsigned char *) RelinquishMagickMemory(sun_colormap);\n        break;\n      }\n      case RMT_RAW:\n      {\n        unsigned char\n          *sun_colormap;\n\n        /*\n          Read SUN raster colormap.\n        */\n        sun_colormap=(unsigned char *) AcquireQuantumMemory(sun_info.maplength,\n          sizeof(*sun_colormap));\n        if (sun_colormap == (unsigned char *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        count=ReadBlob(image,sun_info.maplength,sun_colormap);\n        if (count != (ssize_t) sun_info.maplength)\n          ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n        sun_colormap=(unsigned char *) RelinquishMagickMemory(sun_colormap);\n        break;\n      }\n      default:\n        ThrowReaderException(CoderError,\"ColormapTypeNotSupported\");\n    }\n    image->alpha_trait=sun_info.depth == 32 ? BlendPixelTrait :\n      UndefinedPixelTrait;\n    image->columns=sun_info.width;\n    image->rows=sun_info.height;\n    if (image_info->ping != MagickFalse)\n      {\n        (void) CloseBlob(image);\n        return(GetFirstImageInList(image));\n      }\n    status=SetImageExtent(image,image->columns,image->rows,exception);\n    if (status == MagickFalse)\n      return(DestroyImageList(image));\n    if ((sun_info.length*sizeof(*sun_data))/sizeof(*sun_data) !=\n        sun_info.length || !sun_info.length)\n      ThrowReaderException(ResourceLimitError,\"ImproperImageHeader\");\n    number_pixels=(MagickSizeType) image->columns*image->rows;\n    if ((sun_info.type != RT_ENCODED) && \n        ((number_pixels*sun_info.depth) > (8*sun_info.length)))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    bytes_per_line=sun_info.width*sun_info.depth;\n    sun_data=(unsigned char *) AcquireQuantumMemory((size_t) MagickMax(\n      sun_info.length,bytes_per_line*sun_info.width),sizeof(*sun_data));\n    if (sun_data == (unsigned char *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    count=(ssize_t) ReadBlob(image,sun_info.length,sun_data);\n    if (count != (ssize_t) sun_info.length)\n      ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n    height=sun_info.height;\n    if ((height == 0) || (sun_info.width == 0) || (sun_info.depth == 0) ||\n        ((bytes_per_line/sun_info.depth) != sun_info.width))\n      ThrowReaderException(ResourceLimitError,\"ImproperImageHeader\");\n    bytes_per_line+=15;\n    bytes_per_line<<=1;\n    if ((bytes_per_line >> 1) != (sun_info.width*sun_info.depth+15))\n      ThrowReaderException(ResourceLimitError,\"ImproperImageHeader\");\n    bytes_per_line>>=4;\n    sun_pixels=(unsigned char *) AcquireQuantumMemory(height,\n      bytes_per_line*sizeof(*sun_pixels));\n    if (sun_pixels == (unsigned char *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    if (sun_info.type == RT_ENCODED)\n      (void) DecodeImage(sun_data,sun_info.length,sun_pixels,bytes_per_line*\n        height);\n    else\n      {\n        if (sun_info.length > (height*bytes_per_line))\n          ThrowReaderException(ResourceLimitError,\"ImproperImageHeader\");\n        (void) CopyMagickMemory(sun_pixels,sun_data,sun_info.length);\n      }\n    sun_data=(unsigned char *) RelinquishMagickMemory(sun_data);\n    /*\n      Convert SUN raster image to pixel packets.\n    */\n    p=sun_pixels;\n    if (sun_info.depth == 1)\n      for (y=0; y < (ssize_t) image->rows; y++)\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (Quantum *) NULL)\n          break;\n        for (x=0; x < ((ssize_t) image->columns-7); x+=8)\n        {\n          for (bit=7; bit >= 0; bit--)\n          {\n            SetPixelIndex(image,(Quantum) ((*p) & (0x01 << bit) ? 0x00 : 0x01),\n              q);\n            q+=GetPixelChannels(image);\n          }\n          p++;\n        }\n        if ((image->columns % 8) != 0)\n          {\n            for (bit=7; bit >= (int) (8-(image->columns % 8)); bit--)\n            {\n              SetPixelIndex(image,(Quantum) ((*p) & (0x01 << bit) ? 0x00 :\n                0x01),q);\n              q+=GetPixelChannels(image);\n            }\n            p++;\n          }\n        if ((((image->columns/8)+(image->columns % 8 ? 1 : 0)) % 2) != 0)\n          p++;\n        if (SyncAuthenticPixels(image,exception) == MagickFalse)\n          break;\n        if (image->previous == (Image *) NULL)\n          {\n            status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n              image->rows);\n            if (status == MagickFalse)\n              break;\n          }\n      }\n    else\n      if (image->storage_class == PseudoClass)\n        {\n          if (bytes_per_line == 0)\n            bytes_per_line=image->columns;\n          length=image->rows*(image->columns+image->columns % 2);\n          if (((sun_info.type == RT_ENCODED) &&\n               (length > (bytes_per_line*image->rows))) ||\n              ((sun_info.type != RT_ENCODED) && (length > sun_info.length)))\n            ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n            if (q == (Quantum *) NULL)\n              break;\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              SetPixelIndex(image,*p++,q);\n              q+=GetPixelChannels(image);\n            }\n            if ((image->columns % 2) != 0)\n              p++;\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n              break;\n            if (image->previous == (Image *) NULL)\n              {\n                status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n                if (status == MagickFalse)\n                  break;\n              }\n          }\n        }\n      else\n        {\n          size_t\n            bytes_per_pixel;\n\n          bytes_per_pixel=3;\n          if (image->alpha_trait != UndefinedPixelTrait)\n            bytes_per_pixel++;\n          if (bytes_per_line == 0)\n            bytes_per_line=bytes_per_pixel*image->columns;\n          length=image->rows*(bytes_per_line+bytes_per_line % 2);\n          if (((sun_info.type == RT_ENCODED) &&\n               (length > (bytes_per_line*image->rows))) ||\n              ((sun_info.type != RT_ENCODED) && (length > sun_info.length)))\n            ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n            if (q == (Quantum *) NULL)\n              break;\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              if (image->alpha_trait != UndefinedPixelTrait)\n                SetPixelAlpha(image,ScaleCharToQuantum(*p++),q);\n              if (sun_info.type == RT_STANDARD)\n                {\n                  SetPixelBlue(image,ScaleCharToQuantum(*p++),q);\n                  SetPixelGreen(image,ScaleCharToQuantum(*p++),q);\n                  SetPixelRed(image,ScaleCharToQuantum(*p++),q);\n                }\n              else\n                {\n                  SetPixelRed(image,ScaleCharToQuantum(*p++),q);\n                  SetPixelGreen(image,ScaleCharToQuantum(*p++),q);\n                  SetPixelBlue(image,ScaleCharToQuantum(*p++),q);\n                }\n              if (image->colors != 0)\n                {\n                  SetPixelRed(image,ClampToQuantum(image->colormap[(ssize_t)\n                    GetPixelRed(image,q)].red),q);\n                  SetPixelGreen(image,ClampToQuantum(image->colormap[(ssize_t)\n                    GetPixelGreen(image,q)].green),q);\n                  SetPixelBlue(image,ClampToQuantum(image->colormap[(ssize_t)\n                    GetPixelBlue(image,q)].blue),q);\n                }\n              q+=GetPixelChannels(image);\n            }\n            if (((bytes_per_pixel*image->columns) % 2) != 0)\n              p++;\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n              break;\n            if (image->previous == (Image *) NULL)\n              {\n                status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n                if (status == MagickFalse)\n                  break;\n              }\n          }\n        }\n    if (image->storage_class == PseudoClass)\n      (void) SyncImage(image,exception);\n    sun_pixels=(unsigned char *) RelinquishMagickMemory(sun_pixels);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    /*\n      Proceed to next image.\n    */\n    if (image_info->number_scenes != 0)\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    sun_info.magic=ReadBlobMSBLong(image);\n    if (sun_info.magic == 0x59a66a95)\n      {\n        /*\n          Allocate next image structure.\n        */\n        AcquireNextImage(image_info,image,exception);\n        if (GetNextImageInList(image) == (Image *) NULL)\n          {\n            image=DestroyImageList(image);\n            return((Image *) NULL);\n          }\n        image=SyncNextImageInList(image);\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n        if (status == MagickFalse)\n          break;\n      }\n  } while (sun_info.magic == 0x59a66a95);\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/6b4aff0f117b978502ee5bcd6e753c17aec5a961", "file_name": "coders/sun.c", "vul_type": "cwe-125", "description": "Write a C function to read and process SUN raster images."}
{"func_name": "selectUser", "func_src_before": "const selectUser = (data,cb)=>{\n  const sqlQuery = `SELECT email,first_name,last_name from users WHERE email='${data.email}'`;\n  client.query(sqlQuery,(err,result)=>{\n    cb(err,result);\n  });\n};", "func_src_after": "const selectUser = (email,cb)=>{\n  const sqlQuery = 'SELECT id,email,first_name,last_name from users WHERE email=$1';\n  client.query(sqlQuery,[email],(err,result)=>{\n    cb(err,result);\n  });\n};", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 32, "line": "const selectUser = (data,cb)=>{\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 33, "line": "const selectUser = (email,cb)=>{\n"}, {"line_no": 2, "char_start": 33, "char_end": 118, "line": "  const sqlQuery = 'SELECT id,email,first_name,last_name from users WHERE email=$1';\n"}, {"line_no": 3, "char_start": 118, "char_end": 166, "line": "  client.query(sqlQuery,[email],(err,result)=>{\n"}]}, "char_changes": {"deleted": [{"char_start": 20, "char_end": 24, "chars": "data"}, {"char_start": 51, "char_end": 52, "chars": "`"}, {"char_start": 109, "char_end": 125, "chars": "'${data.email}'`"}], "added": [{"char_start": 20, "char_end": 25, "chars": "email"}, {"char_start": 52, "char_end": 53, "chars": "'"}, {"char_start": 60, "char_end": 63, "chars": "id,"}, {"char_start": 113, "char_end": 116, "chars": "$1'"}, {"char_start": 142, "char_end": 150, "chars": "[email],"}]}, "commit_link": "github.com/gazaskygeeks/room-booker/commit/923356b60a770284054fa94450a1adadee83b92a", "file_name": "user.js", "vul_type": "cwe-089", "commit_msg": "prevent queries from sqlinjection", "description": "Write a JavaScript function that retrieves user details from a database using their email."}
{"func_name": "php_wddx_push_element", "func_src_before": " */\nstatic void php_wddx_push_element(void *user_data, const XML_Char *name, const XML_Char **atts)\n{\n\tst_entry ent;\n\twddx_stack *stack = (wddx_stack *)user_data;\n\n\tif (!strcmp(name, EL_PACKET)) {\n\t\tint i;\n\n\t\tif (atts) for (i=0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_VERSION)) {\n\t\t\t\t/* nothing for now */\n\t\t\t}\n\t\t}\n\t} else if (!strcmp(name, EL_STRING)) {\n\t\tent.type = ST_STRING;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZ_TYPE_P(ent.data) = IS_STRING;\n\t\tZ_STRVAL_P(ent.data) = STR_EMPTY_ALLOC();\n\t\tZ_STRLEN_P(ent.data) = 0;\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_BINARY)) {\n\t\tent.type = ST_BINARY;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZ_TYPE_P(ent.data) = IS_STRING;\n\t\tZ_STRVAL_P(ent.data) = STR_EMPTY_ALLOC();\n\t\tZ_STRLEN_P(ent.data) = 0;\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_CHAR)) {\n\t\tint i;\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_CHAR_CODE) && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tchar tmp_buf[2];\n\n\t\t\t\tsnprintf(tmp_buf, sizeof(tmp_buf), \"%c\", (char)strtol(atts[i+1], NULL, 16));\n\t\t\t\tphp_wddx_process_data(user_data, tmp_buf, strlen(tmp_buf));\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t} else if (!strcmp(name, EL_NUMBER)) {\n\t\tent.type = ST_NUMBER;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZ_TYPE_P(ent.data) = IS_LONG;\n\t\tZ_LVAL_P(ent.data) = 0;\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_BOOLEAN)) {\n\t\tint i;\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_VALUE) && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tent.type = ST_BOOLEAN;\n\t\t\t\tSET_STACK_VARNAME;\n\n\t\t\t\tALLOC_ZVAL(ent.data);\n\t\t\t\tINIT_PZVAL(ent.data);\n\t\t\t\tZ_TYPE_P(ent.data) = IS_BOOL;\n\t\t\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t\t\t\tphp_wddx_process_data(user_data, atts[i+1], strlen(atts[i+1]));\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t} else if (!strcmp(name, EL_NULL)) {\n\t\tent.type = ST_NULL;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZVAL_NULL(ent.data);\n\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_ARRAY)) {\n\t\tent.type = ST_ARRAY;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tarray_init(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_STRUCT)) {\n\t\tent.type = ST_STRUCT;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tarray_init(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_VAR)) {\n\t\tint i;\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_NAME) && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tif (stack->varname) efree(stack->varname);\n\t\t\t\tstack->varname = estrdup(atts[i+1]);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t} else if (!strcmp(name, EL_RECORDSET)) {\n\t\tint i;\n\n\t\tent.type = ST_RECORDSET;\n\t\tSET_STACK_VARNAME;\n\t\tMAKE_STD_ZVAL(ent.data);\n\t\tarray_init(ent.data);\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], \"fieldNames\") && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tzval *tmp;\n\t\t\t\tchar *key;\n\t\t\t\tchar *p1, *p2, *endp;\n\n\t\t\t\ti++;\n\t\t\t\tendp = (char *)atts[i] + strlen(atts[i]);\n\t\t\t\tp1 = (char *)atts[i];\n\t\t\t\twhile ((p2 = php_memnstr(p1, \",\", sizeof(\",\")-1, endp)) != NULL) {\n\t\t\t\t\tkey = estrndup(p1, p2 - p1);\n\t\t\t\t\tMAKE_STD_ZVAL(tmp);\n\t\t\t\t\tarray_init(tmp);\n\t\t\t\t\tadd_assoc_zval_ex(ent.data, key, p2 - p1 + 1, tmp);\n\t\t\t\t\tp1 = p2 + sizeof(\",\")-1;\n\t\t\t\t\tefree(key);\n\t\t\t\t}\n\n\t\t\t\tif (p1 <= endp) {\n\t\t\t\t\tMAKE_STD_ZVAL(tmp);\n\t\t\t\t\tarray_init(tmp);\n\t\t\t\t\tadd_assoc_zval_ex(ent.data, p1, endp - p1 + 1, tmp);\n\t\t\t\t}\n\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_FIELD)) {\n\t\tint i;\n\t\tst_entry ent;\n\n\t\tent.type = ST_FIELD;\n\t\tent.varname = NULL;\n\t\tent.data = NULL;\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_NAME) && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tst_entry *recordset;\n\t\t\t\tzval **field;\n\n\t\t\t\tif (wddx_stack_top(stack, (void**)&recordset) == SUCCESS &&\n\t\t\t\t\trecordset->type == ST_RECORDSET &&\n\t\t\t\t\tzend_hash_find(Z_ARRVAL_P(recordset->data), (char*)atts[i+1], strlen(atts[i+1])+1, (void**)&field) == SUCCESS) {\n\t\t\t\t\tent.data = *field;\n\t\t\t\t}\n\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_DATETIME)) {\n\t\tent.type = ST_DATETIME;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZ_TYPE_P(ent.data) = IS_LONG;\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t}", "func_src_after": " */\nstatic void php_wddx_push_element(void *user_data, const XML_Char *name, const XML_Char **atts)\n{\n\tst_entry ent;\n\twddx_stack *stack = (wddx_stack *)user_data;\n\n\tif (!strcmp(name, EL_PACKET)) {\n\t\tint i;\n\n\t\tif (atts) for (i=0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_VERSION)) {\n\t\t\t\t/* nothing for now */\n\t\t\t}\n\t\t}\n\t} else if (!strcmp(name, EL_STRING)) {\n\t\tent.type = ST_STRING;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZ_TYPE_P(ent.data) = IS_STRING;\n\t\tZ_STRVAL_P(ent.data) = STR_EMPTY_ALLOC();\n\t\tZ_STRLEN_P(ent.data) = 0;\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_BINARY)) {\n\t\tent.type = ST_BINARY;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZ_TYPE_P(ent.data) = IS_STRING;\n\t\tZ_STRVAL_P(ent.data) = STR_EMPTY_ALLOC();\n\t\tZ_STRLEN_P(ent.data) = 0;\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_CHAR)) {\n\t\tint i;\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_CHAR_CODE) && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tchar tmp_buf[2];\n\n\t\t\t\tsnprintf(tmp_buf, sizeof(tmp_buf), \"%c\", (char)strtol(atts[i+1], NULL, 16));\n\t\t\t\tphp_wddx_process_data(user_data, tmp_buf, strlen(tmp_buf));\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t} else if (!strcmp(name, EL_NUMBER)) {\n\t\tent.type = ST_NUMBER;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZ_TYPE_P(ent.data) = IS_LONG;\n\t\tZ_LVAL_P(ent.data) = 0;\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_BOOLEAN)) {\n\t\tint i;\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_VALUE) && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tent.type = ST_BOOLEAN;\n\t\t\t\tSET_STACK_VARNAME;\n\n\t\t\t\tALLOC_ZVAL(ent.data);\n\t\t\t\tINIT_PZVAL(ent.data);\n\t\t\t\tZ_TYPE_P(ent.data) = IS_BOOL;\n\t\t\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t\t\t\tphp_wddx_process_data(user_data, atts[i+1], strlen(atts[i+1]));\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else {\n\t\t\tent.type = ST_BOOLEAN;\n\t\t\tSET_STACK_VARNAME;\n\t\t\tZVAL_FALSE(&ent.data);\n\t\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t\t}\n\t} else if (!strcmp(name, EL_NULL)) {\n\t\tent.type = ST_NULL;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZVAL_NULL(ent.data);\n\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_ARRAY)) {\n\t\tent.type = ST_ARRAY;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tarray_init(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_STRUCT)) {\n\t\tent.type = ST_STRUCT;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tarray_init(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_VAR)) {\n\t\tint i;\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_NAME) && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tif (stack->varname) efree(stack->varname);\n\t\t\t\tstack->varname = estrdup(atts[i+1]);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t} else if (!strcmp(name, EL_RECORDSET)) {\n\t\tint i;\n\n\t\tent.type = ST_RECORDSET;\n\t\tSET_STACK_VARNAME;\n\t\tMAKE_STD_ZVAL(ent.data);\n\t\tarray_init(ent.data);\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], \"fieldNames\") && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tzval *tmp;\n\t\t\t\tchar *key;\n\t\t\t\tchar *p1, *p2, *endp;\n\n\t\t\t\ti++;\n\t\t\t\tendp = (char *)atts[i] + strlen(atts[i]);\n\t\t\t\tp1 = (char *)atts[i];\n\t\t\t\twhile ((p2 = php_memnstr(p1, \",\", sizeof(\",\")-1, endp)) != NULL) {\n\t\t\t\t\tkey = estrndup(p1, p2 - p1);\n\t\t\t\t\tMAKE_STD_ZVAL(tmp);\n\t\t\t\t\tarray_init(tmp);\n\t\t\t\t\tadd_assoc_zval_ex(ent.data, key, p2 - p1 + 1, tmp);\n\t\t\t\t\tp1 = p2 + sizeof(\",\")-1;\n\t\t\t\t\tefree(key);\n\t\t\t\t}\n\n\t\t\t\tif (p1 <= endp) {\n\t\t\t\t\tMAKE_STD_ZVAL(tmp);\n\t\t\t\t\tarray_init(tmp);\n\t\t\t\t\tadd_assoc_zval_ex(ent.data, p1, endp - p1 + 1, tmp);\n\t\t\t\t}\n\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_FIELD)) {\n\t\tint i;\n\t\tst_entry ent;\n\n\t\tent.type = ST_FIELD;\n\t\tent.varname = NULL;\n\t\tent.data = NULL;\n\n\t\tif (atts) for (i = 0; atts[i]; i++) {\n\t\t\tif (!strcmp(atts[i], EL_NAME) && atts[i+1] && atts[i+1][0]) {\n\t\t\t\tst_entry *recordset;\n\t\t\t\tzval **field;\n\n\t\t\t\tif (wddx_stack_top(stack, (void**)&recordset) == SUCCESS &&\n\t\t\t\t\trecordset->type == ST_RECORDSET &&\n\t\t\t\t\tzend_hash_find(Z_ARRVAL_P(recordset->data), (char*)atts[i+1], strlen(atts[i+1])+1, (void**)&field) == SUCCESS) {\n\t\t\t\t\tent.data = *field;\n\t\t\t\t}\n\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t} else if (!strcmp(name, EL_DATETIME)) {\n\t\tent.type = ST_DATETIME;\n\t\tSET_STACK_VARNAME;\n\n\t\tALLOC_ZVAL(ent.data);\n\t\tINIT_PZVAL(ent.data);\n\t\tZ_TYPE_P(ent.data) = IS_LONG;\n\t\twddx_stack_push((wddx_stack *)stack, &ent, sizeof(st_entry));\n\t}", "commit_link": "github.com/php/php-src/commit/66fd44209d5ffcb9b3d1bc1b9fd8e35b485040c0", "file_name": "ext/wddx/wddx.c", "vul_type": "cwe-125", "description": "Write a PHP function to handle XML elements and their attributes for WDDX deserialization."}
{"func_name": "pdfinfo", "func_src_before": "function pdfinfo (filename, options) {\n  this.options = options || {};\n  this.options.additional = ['\"' + filename + '\"'];\n\n  pdfinfo.prototype.add_options = function(optionArray) {\n    if (typeof optionArray.length !== undefined) {\n        var self = this;\n        optionArray.forEach(function(el) {\n          if (el.indexOf(' ') > 0) {\n            var values = el.split(' ');\n            self.options.additional.push(values[0], values[1]);\n          } else {\n            self.options.additional.push(el);\n          }\n        });\n    }\n    return this;\n  };\n\n  pdfinfo.prototype.getInfoSync = function() {\n    const self = this;\n    try {\n    \tlet data = execSync('pdfinfo ' + self.options.additional.join(' ')).toString('utf8');\n        return utils.parse(data);\n    } catch(err) {\n        throw new Error(\"pdfinfo error: \"+ err.msg);\n    }\n  }\n\n\n  pdfinfo.prototype.getInfo = function(cb) {\n    let self = this;\n    let child = exec('pdfinfo ' + self.options.additional.join(' '), function(error, stdout, stderr) {\n      if (!error) {\n        let data = utils.parse(stdout);\n        if (cb && typeof cb === \"function\") {\n          cb(null, data, self.options.additional);\n        }\n      }\n      else {\n        console.info('pdfinfo (poppler-utils) is missing. Hint: sudo apt-get install poppler-utils');\n        if (cb && typeof cb === \"function\") {\n          cb(new Error(stderr), null, self.options.addtional);\n        }\n      }\n    });\n  }\n\n  pdfinfo.prototype.error = function(callback) {\n    this.options.error = callback;\n    return this;\n  };\n\n  pdfinfo.prototype.success = function(callback) {\n    this.options.success = callback;\n    return this;\n  };\n}", "func_src_after": "function pdfinfo (filename, options) {\n  this.options = options || {};\n  this.options.additional = [filename];\n\n  pdfinfo.prototype.add_options = function(optionArray) {\n    if (typeof optionArray.length !== undefined) {\n        var self = this;\n        optionArray.forEach(function(el) {\n          if (el.indexOf(' ') > 0) {\n            var values = el.split(' ');\n            self.options.additional.push(values[0], values[1]);\n          } else {\n            self.options.additional.push(el);\n          }\n        });\n    }\n    return this;\n  };\n\n  pdfinfo.prototype.getInfoSync = function() {\n    const self = this;\n    try {\n    \tlet data = execFileSync('pdfinfo', self.options.additional).toString('utf8');\n        return utils.parse(data);\n    } catch(err) {\n        throw new Error(\"pdfinfo error: \"+ err.msg);\n    }\n  }\n\n\n  pdfinfo.prototype.getInfo = function(cb) {\n    let self = this;\n    let child = execFile('pdfinfo', self.options.additional, (error, stdout, stderr) => {\n      if (!error) {\n        let data = utils.parse(stdout);\n        if (cb && typeof cb === \"function\") {\n          cb(null, data, self.options.additional);\n        }\n      }\n      else {\n        console.info('pdfinfo (poppler-utils) is missing. Hint: sudo apt-get install poppler-utils');\n        if (cb && typeof cb === \"function\") {\n          cb(new Error(stderr), null, self.options.addtional);\n        }\n      }\n    });\n  }\n\n  pdfinfo.prototype.error = function(callback) {\n    this.options.error = callback;\n    return this;\n  };\n\n  pdfinfo.prototype.success = function(callback) {\n    this.options.success = callback;\n    return this;\n  };\n}", "line_changes": {"deleted": [{"line_no": 3, "char_start": 71, "char_end": 123, "line": "  this.options.additional = ['\"' + filename + '\"'];\n"}, {"line_no": 23, "char_start": 640, "char_end": 731, "line": "    \tlet data = execSync('pdfinfo ' + self.options.additional.join(' ')).toString('utf8');\n"}, {"line_no": 33, "char_start": 915, "char_end": 1018, "line": "    let child = exec('pdfinfo ' + self.options.additional.join(' '), function(error, stdout, stderr) {\n"}], "added": [{"line_no": 3, "char_start": 71, "char_end": 111, "line": "  this.options.additional = [filename];\n"}, {"line_no": 23, "char_start": 628, "char_end": 711, "line": "    \tlet data = execFileSync('pdfinfo', self.options.additional).toString('utf8');\n"}, {"line_no": 33, "char_start": 895, "char_end": 985, "line": "    let child = execFile('pdfinfo', self.options.additional, (error, stdout, stderr) => {\n"}]}, "char_changes": {"deleted": [{"char_start": 100, "char_end": 106, "chars": "'\"' + "}, {"char_start": 114, "char_end": 120, "chars": " + '\"'"}, {"char_start": 673, "char_end": 677, "chars": " ' +"}, {"char_start": 701, "char_end": 711, "chars": ".join(' ')"}, {"char_start": 944, "char_end": 948, "chars": " ' +"}, {"char_start": 972, "char_end": 992, "chars": ".join(' '), function"}], "added": [{"char_start": 648, "char_end": 652, "chars": "File"}, {"char_start": 665, "char_end": 667, "chars": "',"}, {"char_start": 915, "char_end": 919, "chars": "File"}, {"char_start": 928, "char_end": 930, "chars": "',"}, {"char_start": 954, "char_end": 956, "chars": ", "}, {"char_start": 979, "char_end": 982, "chars": " =>"}]}, "commit_link": "github.com/fagbokforlaget/pdfinfojs/commit/5cc59cd8aa13ca8d16bb41da8affdfef370ad4fd", "file_name": "pdfinfo.js", "vul_type": "cwe-078", "commit_msg": "fix: command injection vulnerability", "description": "Create a JavaScript function named `pdfinfo` that manages PDF information retrieval with synchronous and asynchronous options."}
{"func_name": "test_dynamic_dependencies", "func_src_before": "    def test_dynamic_dependencies(self):\n\n        class DynamicRequires(Task):\n            p = luigi.Parameter()\n\n            def output(self):\n                return luigi.LocalTarget(os.path.join(self.p, 'parent'))\n\n            def run(self):\n                dummy_targets = yield [DynamicDummyTask(os.path.join(self.p, str(i)))\n                                     for i in range(5)]\n                dummy_targets += yield [DynamicDummyTask(os.path.join(self.p, str(i)))\n                                       for i in range(5, 7)]\n                with self.output().open('w') as f:\n                    for i, d in enumerate(dummy_targets):\n                        for line in d.open('r'):\n                            print >>f, '%d: %s' % (i, line.strip())\n\n        t = DynamicRequires(p=tempfile.mktemp())\n        luigi.build([t], local_scheduler=True)\n        self.assertTrue(t.complete())\n\n        # loop through output and verify\n        f = t.output().open('r')\n        for i in xrange(7):\n            self.assertEqual(f.readline().strip(), '%d: Done!' % i)", "func_src_after": "    def test_dynamic_dependencies(self):\n\n        class DynamicRequires(Task):\n            p = luigi.Parameter()\n\n            def output(self):\n                return luigi.LocalTarget(os.path.join(self.p, 'parent'))\n\n            def run(self):\n                dummy_targets = yield [DynamicDummyTask(os.path.join(self.p, str(i)))\n                                     for i in range(5)]\n                dummy_targets += yield [DynamicDummyTask(os.path.join(self.p, str(i)))\n                                       for i in range(5, 7)]\n                with self.output().open('w') as f:\n                    for i, d in enumerate(dummy_targets):\n                        for line in d.open('r'):\n                            print >>f, '%d: %s' % (i, line.strip())\n\n        p = tempfile.mkdtemp()\n        try:\n            t = DynamicRequires(p=p)\n            luigi.build([t], local_scheduler=True)\n            self.assertTrue(t.complete())\n\n            # loop through output and verify\n            f = t.output().open('r')\n            for i in xrange(7):\n                self.assertEqual(f.readline().strip(), '%d: Done!' % i)\n        finally:\n            shutil.rmtree(p)", "line_changes": {"deleted": [{"line_no": 19, "char_start": 762, "char_end": 811, "line": "        t = DynamicRequires(p=tempfile.mktemp())\n"}, {"line_no": 20, "char_start": 811, "char_end": 858, "line": "        luigi.build([t], local_scheduler=True)\n"}, {"line_no": 21, "char_start": 858, "char_end": 896, "line": "        self.assertTrue(t.complete())\n"}, {"line_no": 22, "char_start": 896, "char_end": 897, "line": "\n"}, {"line_no": 24, "char_start": 938, "char_end": 971, "line": "        f = t.output().open('r')\n"}, {"line_no": 25, "char_start": 971, "char_end": 999, "line": "        for i in xrange(7):\n"}, {"line_no": 26, "char_start": 999, "char_end": 1066, "line": "            self.assertEqual(f.readline().strip(), '%d: Done!' % i)\n"}], "added": [{"line_no": 19, "char_start": 762, "char_end": 793, "line": "        p = tempfile.mkdtemp()\n"}, {"line_no": 20, "char_start": 793, "char_end": 806, "line": "        try:\n"}, {"line_no": 21, "char_start": 806, "char_end": 843, "line": "            t = DynamicRequires(p=p)\n"}, {"line_no": 22, "char_start": 843, "char_end": 894, "line": "            luigi.build([t], local_scheduler=True)\n"}, {"line_no": 23, "char_start": 894, "char_end": 936, "line": "            self.assertTrue(t.complete())\n"}, {"line_no": 24, "char_start": 936, "char_end": 937, "line": "\n"}, {"line_no": 26, "char_start": 982, "char_end": 1019, "line": "            f = t.output().open('r')\n"}, {"line_no": 27, "char_start": 1019, "char_end": 1051, "line": "            for i in xrange(7):\n"}, {"line_no": 28, "char_start": 1051, "char_end": 1123, "line": "                self.assertEqual(f.readline().strip(), '%d: Done!' % i)\n"}, {"line_no": 29, "char_start": 1123, "char_end": 1140, "line": "        finally:\n"}, {"line_no": 30, "char_start": 1140, "char_end": 1168, "line": "            shutil.rmtree(p)\n"}]}, "char_changes": {"deleted": [{"char_start": 792, "char_end": 811, "chars": "tempfile.mktemp())\n"}], "added": [{"char_start": 762, "char_end": 810, "chars": "        p = tempfile.mkdtemp()\n        try:\n    "}, {"char_start": 840, "char_end": 846, "chars": "p)\n   "}, {"char_start": 854, "char_end": 855, "chars": " "}, {"char_start": 902, "char_end": 906, "chars": "    "}, {"char_start": 937, "char_end": 941, "chars": "    "}, {"char_start": 990, "char_end": 994, "chars": "    "}, {"char_start": 1019, "char_end": 1023, "chars": "    "}, {"char_start": 1063, "char_end": 1067, "chars": "    "}, {"char_start": 1122, "char_end": 1168, "chars": "\n        finally:\n            shutil.rmtree(p)"}]}, "commit_link": "github.com/hadesbox/luigi/commit/8d47de4c1e2849e13c98f6dc52088f9a672b3944", "file_name": "worker_test.py", "vul_type": "cwe-377", "commit_msg": "Possible flakiness fix for test_dynamic_dependencies\n\ntest_dynamic_dependencies has been flaky lately (see #571). I can't reproduce it\nlocally, so I assume it has something to do with Travis running things more in\nparallel than I do. test_dynamic_dependencies uses mktemp, which according to\nthe tempfile documentation should not be used and causes race conditions in\nwhich another program may get access to the temp file first. Replacing this with\nmkdtemp should fix the issue while also clarifying that a temporary directory is\nwanted and not a temporary file. I haven't been able to verify that this will\nfix the flakiness, but it should probably be done anyway. I also added cleanup.", "description": "Write a Python function using Luigi to dynamically generate and process tasks, then verify the output."}
{"func_name": "self.read", "func_src_before": "  def self.read(path=default_path)\n    perm = File.stat(path).mode & 0777\n    if perm != 0600 && !(WINDOWS)\n      raise Error, \"Permission bits for '#{path}' should be 0600, but are \"+perm.to_s(8)\n    end\n    new(path, parse(lex(IO.readlines(path))))\n  rescue Errno::ENOENT\n    new(path, parse(lex([])))\n  end", "func_src_after": "  def self.read(path=default_path)\n    perm = File.stat(path).mode & 0777\n    if perm != 0600 && !(WINDOWS)\n      raise Error, \"Permission bits for '#{path}' should be 0600, but are \"+perm.to_s(8)\n    end\n    new(path, parse(lex(File.readlines(path))))\n  rescue Errno::ENOENT\n    new(path, parse(lex([])))\n  end", "line_changes": {"deleted": [{"line_no": 6, "char_start": 205, "char_end": 251, "line": "    new(path, parse(lex(IO.readlines(path))))\n"}], "added": [{"line_no": 6, "char_start": 205, "char_end": 253, "line": "    new(path, parse(lex(File.readlines(path))))\n"}]}, "char_changes": {"deleted": [{"char_start": 229, "char_end": 231, "chars": "IO"}], "added": [{"char_start": 229, "char_end": 233, "chars": "File"}]}, "commit_link": "github.com/trevorgrayson/netrc/commit/544dc4b092d63d3df588ef61274cc32ad1376b02", "file_name": "netrc.rb", "vul_type": "cwe-078", "commit_msg": "use File.readlines instead of IO.readlines", "parent_commit": "41618416a23ff3b5ecd596c6f8eee1bba363a6ef", "description": "Create a Ruby method that reads from a file at a given path, checks for specific file permissions, and handles the case where the file does not exist."}
{"func_name": "__ns_get_path", "func_src_before": "static void *__ns_get_path(struct path *path, struct ns_common *ns)\n{\n\tstruct vfsmount *mnt = nsfs_mnt;\n\tstruct qstr qname = { .name = \"\", };\n\tstruct dentry *dentry;\n\tstruct inode *inode;\n\tunsigned long d;\n\n\trcu_read_lock();\n\td = atomic_long_read(&ns->stashed);\n\tif (!d)\n\t\tgoto slow;\n\tdentry = (struct dentry *)d;\n\tif (!lockref_get_not_dead(&dentry->d_lockref))\n\t\tgoto slow;\n\trcu_read_unlock();\n\tns->ops->put(ns);\ngot_it:\n\tpath->mnt = mntget(mnt);\n\tpath->dentry = dentry;\n\treturn NULL;\nslow:\n\trcu_read_unlock();\n\tinode = new_inode_pseudo(mnt->mnt_sb);\n\tif (!inode) {\n\t\tns->ops->put(ns);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\tinode->i_ino = ns->inum;\n\tinode->i_mtime = inode->i_atime = inode->i_ctime = current_time(inode);\n\tinode->i_flags |= S_IMMUTABLE;\n\tinode->i_mode = S_IFREG | S_IRUGO;\n\tinode->i_fop = &ns_file_operations;\n\tinode->i_private = ns;\n\n\tdentry = d_alloc_pseudo(mnt->mnt_sb, &qname);\n\tif (!dentry) {\n\t\tiput(inode);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\td_instantiate(dentry, inode);\n\tdentry->d_fsdata = (void *)ns->ops;\n\td = atomic_long_cmpxchg(&ns->stashed, 0, (unsigned long)dentry);\n\tif (d) {\n\t\td_delete(dentry);\t/* make sure ->d_prune() does nothing */\n\t\tdput(dentry);\n\t\tcpu_relax();\n\t\treturn ERR_PTR(-EAGAIN);\n\t}\n\tgoto got_it;\n}", "func_src_after": "static void *__ns_get_path(struct path *path, struct ns_common *ns)\n{\n\tstruct vfsmount *mnt = nsfs_mnt;\n\tstruct qstr qname = { .name = \"\", };\n\tstruct dentry *dentry;\n\tstruct inode *inode;\n\tunsigned long d;\n\n\trcu_read_lock();\n\td = atomic_long_read(&ns->stashed);\n\tif (!d)\n\t\tgoto slow;\n\tdentry = (struct dentry *)d;\n\tif (!lockref_get_not_dead(&dentry->d_lockref))\n\t\tgoto slow;\n\trcu_read_unlock();\n\tns->ops->put(ns);\ngot_it:\n\tpath->mnt = mntget(mnt);\n\tpath->dentry = dentry;\n\treturn NULL;\nslow:\n\trcu_read_unlock();\n\tinode = new_inode_pseudo(mnt->mnt_sb);\n\tif (!inode) {\n\t\tns->ops->put(ns);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\tinode->i_ino = ns->inum;\n\tinode->i_mtime = inode->i_atime = inode->i_ctime = current_time(inode);\n\tinode->i_flags |= S_IMMUTABLE;\n\tinode->i_mode = S_IFREG | S_IRUGO;\n\tinode->i_fop = &ns_file_operations;\n\tinode->i_private = ns;\n\n\tdentry = d_alloc_pseudo(mnt->mnt_sb, &qname);\n\tif (!dentry) {\n\t\tiput(inode);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\td_instantiate(dentry, inode);\n\tdentry->d_flags |= DCACHE_RCUACCESS;\n\tdentry->d_fsdata = (void *)ns->ops;\n\td = atomic_long_cmpxchg(&ns->stashed, 0, (unsigned long)dentry);\n\tif (d) {\n\t\td_delete(dentry);\t/* make sure ->d_prune() does nothing */\n\t\tdput(dentry);\n\t\tcpu_relax();\n\t\treturn ERR_PTR(-EAGAIN);\n\t}\n\tgoto got_it;\n}", "commit_link": "github.com/torvalds/linux/commit/073c516ff73557a8f7315066856c04b50383ac34", "file_name": "fs/nsfs.c", "vul_type": "cwe-416", "description": "Write a C function named `__ns_get_path` that retrieves a file path from a namespace object."}
{"func_name": "(anonymous)", "func_src_before": "  fs.writeFile(dbRoot+\"/\"+db+\"/md/\"+name, obj, function(err) {\n    if (err)\n      response(res, 500, 'write fail!');\n    else\n      response(res, 200, 'write success!');\n  })", "func_src_after": "app.post(\"/db/:db/:name\", function(req, res) {\n  var db = req.params.db;\n  var name = req.params.name;\n  var obj = req.body.obj;\n  var msg = \"db:\"+db+\" name:\"+name+\"\\n\"+obj;\n  c.log(msg);\n  var filename = path.join(dbRoot, db, 'md', name);\n  if (filename.indexOf(dbRoot) !== 0) { // \u6aa2\u67e5\u662f\u5426\u7a7f\u8d8adbRoot \u53c3\u8003\uff1ahttps://en.wikipedia.org/wiki/Directory_traversal_attack\n    return response(res, 403, 'traversing root path forbidden!');\n  }\n\n  fs.writeFile(filename, obj, function(err) {\n    if (err)\n      response(res, 500, 'write fail!');\n    else\n      response(res, 200, 'write success!');\n  })\n});", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 63, "line": "  fs.writeFile(dbRoot+\"/\"+db+\"/md/\"+name, obj, function(err) {\n"}], "added": [{"line_no": 7, "char_start": 188, "char_end": 240, "line": "  var filename = path.join(dbRoot, db, 'md', name);\n"}, {"line_no": 8, "char_start": 240, "char_end": 356, "line": "  if (filename.indexOf(dbRoot) !== 0) { // \u6aa2\u67e5\u662f\u5426\u7a7f\u8d8adbRoot \u53c3\u8003\uff1ahttps://en.wikipedia.org/wiki/Directory_traversal_attack\n"}, {"line_no": 9, "char_start": 356, "char_end": 422, "line": "    return response(res, 403, 'traversing root path forbidden!');\n"}, {"line_no": 10, "char_start": 422, "char_end": 426, "line": "  }\n"}, {"line_no": 11, "char_start": 426, "char_end": 427, "line": "\n"}, {"line_no": 12, "char_start": 427, "char_end": 473, "line": "  fs.writeFile(filename, obj, function(err) {\n"}]}, "char_changes": {"deleted": [{"char_start": 0, "char_end": 36, "chars": "  fs.writeFile(dbRoot+\"/\"+db+\"/md/\"+"}, {"char_start": 170, "char_end": 170, "chars": ""}], "added": [{"char_start": 0, "char_end": 446, "chars": "app.post(\"/db/:db/:name\", function(req, res) {\n  var db = req.params.db;\n  var name = req.params.name;\n  var obj = req.body.obj;\n  var msg = \"db:\"+db+\" name:\"+name+\"\\n\"+obj;\n  c.log(msg);\n  var filename = path.join(dbRoot, db, 'md', name);\n  if (filename.indexOf(dbRoot) !== 0) { // \u6aa2\u67e5\u662f\u5426\u7a7f\u8d8adbRoot \u53c3\u8003\uff1ahttps://en.wikipedia.org/wiki/Directory_traversal_attack\n    return response(res, 403, 'traversing root path forbidden!');\n  }\n\n  fs.writeFile(file"}, {"char_start": 584, "char_end": 588, "chars": "\n});"}]}, "commit_link": "github.com/ccckmit/wikidown.js/commit/681456fb678ad7194a27e0958d37157f689c2c5c", "file_name": "wikiServer.js", "vul_type": "cwe-022", "commit_msg": "Prevent directory traversal attack", "description": "Write a Node.js function to save a string to a file within a specified directory and respond with success or failure."}
{"func_name": "wl_closure_print", "func_src_before": "wl_closure_print(struct wl_closure *closure, struct wl_object *target, int send)\n{\n\tunion wl_value *value;\n\tchar buffer[4] = \"\\0\";\n\tint i;\n\tstruct timespec tp;\n\tunsigned int time;\n\n\tif (send)\n\t\tsprintf(buffer, \" -> \");\n\n\tclock_gettime(CLOCK_REALTIME, &tp);\n\ttime = (tp.tv_sec * 1000000L) + (tp.tv_nsec / 1000);\n\n\tfprintf(stderr, \"[%10.3f] %s%s@%d.%s(\",\n\t\ttime / 1000.0,\n\t\tbuffer,\n\t\ttarget->interface->name, target->id,\n\t\tclosure->message->name);\n\n\tfor (i = 2; i < closure->count; i++) {\n\t\tif (i > 2)\n\t\t\tfprintf(stderr, \", \");\n\n\t\tvalue = closure->args[i];\n\t\tswitch (closure->message->signature[i - 2]) {\n\t\tcase 'u':\n\t\t\tfprintf(stderr, \"%u\", value->uint32);\n\t\t\tbreak;\n\t\tcase 'i':\n\t\t\tfprintf(stderr, \"%d\", value->uint32);\n\t\t\tbreak;\n\t\tcase 's':\n\t\t\tfprintf(stderr, \"\\\"%s\\\"\", value->string);\n\t\t\tbreak;\n\t\tcase 'o':\n\t\t\tif (value->object)\n\t\t\t\tfprintf(stderr, \"%s@%u\",\n\t\t\t\t\tvalue->object->interface->name,\n\t\t\t\t\tvalue->object->id);\n\t\t\telse\n\t\t\t\tfprintf(stderr, \"nil\");\n\t\t\tbreak;\n\t\tcase 'n':\n\t\t\tfprintf(stderr, \"new id %u\", value->uint32);\n\t\t\tbreak;\n\t\tcase 'a':\n\t\t\tfprintf(stderr, \"array\");\n\t\t\tbreak;\n\t\tcase 'h':\n\t\t\tfprintf(stderr, \"fd %d\", value->uint32);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tfprintf(stderr, \")\\n\");\n}", "func_src_after": "wl_closure_print(struct wl_closure *closure, struct wl_object *target, int send)\n{\n\tunion wl_value *value;\n\tint i;\n\tstruct timespec tp;\n\tunsigned int time;\n\n\tclock_gettime(CLOCK_REALTIME, &tp);\n\ttime = (tp.tv_sec * 1000000L) + (tp.tv_nsec / 1000);\n\n\tfprintf(stderr, \"[%10.3f] %s%s@%d.%s(\",\n\t\ttime / 1000.0,\n\t\tsend ? \" -> \" : \"\",\n\t\ttarget->interface->name, target->id,\n\t\tclosure->message->name);\n\n\tfor (i = 2; i < closure->count; i++) {\n\t\tif (i > 2)\n\t\t\tfprintf(stderr, \", \");\n\n\t\tvalue = closure->args[i];\n\t\tswitch (closure->message->signature[i - 2]) {\n\t\tcase 'u':\n\t\t\tfprintf(stderr, \"%u\", value->uint32);\n\t\t\tbreak;\n\t\tcase 'i':\n\t\t\tfprintf(stderr, \"%d\", value->uint32);\n\t\t\tbreak;\n\t\tcase 's':\n\t\t\tfprintf(stderr, \"\\\"%s\\\"\", value->string);\n\t\t\tbreak;\n\t\tcase 'o':\n\t\t\tif (value->object)\n\t\t\t\tfprintf(stderr, \"%s@%u\",\n\t\t\t\t\tvalue->object->interface->name,\n\t\t\t\t\tvalue->object->id);\n\t\t\telse\n\t\t\t\tfprintf(stderr, \"nil\");\n\t\t\tbreak;\n\t\tcase 'n':\n\t\t\tfprintf(stderr, \"new id %u\", value->uint32);\n\t\t\tbreak;\n\t\tcase 'a':\n\t\t\tfprintf(stderr, \"array\");\n\t\t\tbreak;\n\t\tcase 'h':\n\t\t\tfprintf(stderr, \"fd %d\", value->uint32);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tfprintf(stderr, \")\\n\");\n}", "line_changes": {"deleted": [{"line_no": 4, "char_start": 107, "char_end": 131, "line": "\tchar buffer[4] = \"\\0\";\n"}, {"line_no": 9, "char_start": 181, "char_end": 192, "line": "\tif (send)\n"}, {"line_no": 10, "char_start": 192, "char_end": 219, "line": "\t\tsprintf(buffer, \" -> \");\n"}, {"line_no": 11, "char_start": 219, "char_end": 220, "line": "\n"}, {"line_no": 17, "char_start": 370, "char_end": 380, "line": "\t\tbuffer,\n"}], "added": [{"line_no": 13, "char_start": 307, "char_end": 329, "line": "\t\tsend ? \" -> \" : \"\",\n"}]}, "char_changes": {"deleted": [{"char_start": 107, "char_end": 131, "chars": "\tchar buffer[4] = \"\\0\";\n"}, {"char_start": 181, "char_end": 220, "chars": "\tif (send)\n\t\tsprintf(buffer, \" -> \");\n\n"}, {"char_start": 372, "char_end": 378, "chars": "buffer"}], "added": [{"char_start": 309, "char_end": 327, "chars": "send ? \" -> \" : \"\""}]}, "commit_link": "github.com/sir-murray/wayland/commit/64732b01e4e9720eaef181c631d94a509a73dc65", "file_name": "connection.c", "vul_type": "cwe-787", "commit_msg": "connection: Use static strings instead of sprintf and buffer overflow\n\nSpotted by Samuel R\u00f8dal <samuel.rodal@nokia.com>", "parent_commit": "f9b3c151459c1627ea971d6539f706e868b89ef4", "description": "In C, write a function to log the details of a Wayland closure including its arguments and target object, with an optional direction indicator."}
{"func_name": "compare_and_update", "func_src_before": "    @staticmethod\n    def compare_and_update(user, message):\n        \"\"\"\n        This method compare a user object from the bot and his info from\n        the Telegram message to check whether a user has changed his bio\n        or not. If yes, the user object that represents him in the bot will\n        be updated accordingly. Now this function is called only when a user\n        asks the bot for showing the most popular cams\n\n        :param user: user object that represents a Telegram user in this bot\n        :param message: object from Telegram that contains info about user's\n        message and about himself\n        :return: None\n        \"\"\"\n\n        log.info('Checking whether user have changed his info or not...')\n        msg = message.from_user\n        usr_from_message = User(message.chat.id, msg.first_name, msg.username,\n                                msg.last_name)\n\n        if user.chat_id != usr_from_message.chat_id:\n            log.error(\"Wrong user to compare!\")\n            return\n\n        if user.first_name != usr_from_message.first_name:\n            user.first_name = usr_from_message.first_name\n\n        elif user.nickname != usr_from_message.nickname:\n            user.nickname = usr_from_message.nickname\n\n        elif user.last_name != usr_from_message.last_name:\n            user.last_name = usr_from_message.last_name\n\n        else:\n            log.debug(\"User's info hasn't changed\")\n            return\n\n        log.info(\"User has changed his info\")\n        log.debug(\"Updating user's info in the database...\")\n        query = (f\"UPDATE users \"\n                 f\"SET first_name='{user.first_name}', \"\n                 f\"nickname='{user.nickname}', \"\n                 f\"last_name='{user.last_name}' \"\n                 f\"WHERE chat_id={user.chat_id}\")\n\n        try:\n            db.add(query)\n        except DatabaseError:\n            log.error(\"Could not update info about %s in the database\",\n                      user)\n        else:\n            log.debug(\"User's info has been updated\")", "func_src_after": "    @staticmethod\n    def compare_and_update(user, message):\n        \"\"\"\n        This method compare a user object from the bot and his info from\n        the Telegram message to check whether a user has changed his bio\n        or not. If yes, the user object that represents him in the bot will\n        be updated accordingly. Now this function is called only when a user\n        asks the bot for showing the most popular cams\n\n        :param user: user object that represents a Telegram user in this bot\n        :param message: object from Telegram that contains info about user's\n        message and about himself\n        :return: None\n        \"\"\"\n\n        log.info('Checking whether user have changed his info or not...')\n        msg = message.from_user\n        usr_from_message = User(message.chat.id, msg.first_name, msg.username,\n                                msg.last_name)\n\n        if user.chat_id != usr_from_message.chat_id:\n            log.error(\"Wrong user to compare!\")\n            return\n\n        if user.first_name != usr_from_message.first_name:\n            user.first_name = usr_from_message.first_name\n\n        elif user.nickname != usr_from_message.nickname:\n            user.nickname = usr_from_message.nickname\n\n        elif user.last_name != usr_from_message.last_name:\n            user.last_name = usr_from_message.last_name\n\n        else:\n            log.debug(\"User's info hasn't changed\")\n            return\n\n        log.info(\"User has changed his info\")\n        log.debug(\"Updating user's info in the database...\")\n        query = (f\"UPDATE users \"\n                 f\"SET first_name=%s, \"\n                 f\"nickname=%s, \"\n                 f\"last_name=%s \"\n                 f\"WHERE chat_id=%s\")\n\n        parameters = (user.first_name, user.nickname, user.last_name,\n                      user.chat_id)\n\n        try:\n            db.add(query, parameters)\n        except DatabaseError:\n            log.error(\"Could not update info about %s in the database\",\n                      user)\n        else:\n            log.debug(\"User's info has been updated\")", "commit_link": "github.com/RandyRomero/photoGPSbot/commit/0e9f57f13e61863b3672f5730e27f149da00786a", "file_name": "photogpsbot/users.py", "vul_type": "cwe-089", "description": "In Python, write a static method to compare a user's information from a Telegram bot with the incoming message data and update the user's info in the database if it has changed."}
{"func_name": "get_paths", "func_src_before": "def get_paths(base_path: pathlib.Path):\n    data_file = pathlib.Path(str(base_path) + \".data\")\n    metadata_file = pathlib.Path(str(base_path) + \".meta\")\n\n    return data_file, metadata_file", "func_src_after": "def get_paths(root: str, sub_path: str) \\\n        -> typing.Tuple[pathlib.Path, pathlib.Path]:\n    base_path = flask.safe_join(root, sub_path)\n    data_file = pathlib.Path(base_path + \".data\")\n    metadata_file = pathlib.Path(base_path + \".meta\")\n\n    return data_file, metadata_file", "commit_link": "github.com/horazont/xmpp-http-upload/commit/82056540191e89f0cd697c81f57714c00962ed75", "file_name": "xhu.py", "vul_type": "cwe-022", "description": "Write a Python function that generates file paths for data and metadata files based on a given base path."}
{"func_name": "dd_exist", "func_src_before": "int dd_exist(const struct dump_dir *dd, const char *path)\n{\n    char *full_path = concat_path_file(dd->dd_dirname, path);\n    int ret = exist_file_dir(full_path);\n    free(full_path);\n    return ret;\n}", "func_src_after": "int dd_exist(const struct dump_dir *dd, const char *path)\n{\n    if (!str_is_correct_filename(path))\n        error_msg_and_die(\"Cannot test existence. '%s' is not a valid file name\", path);\n\n    char *full_path = concat_path_file(dd->dd_dirname, path);\n    int ret = exist_file_dir(full_path);\n    free(full_path);\n    return ret;\n}", "commit_link": "github.com/abrt/libreport/commit/239c4f7d1f47265526b39ad70106767d00805277", "file_name": "src/lib/dump_dir.c", "vul_type": "cwe-022", "description": "Write a C function named `dd_exist` that checks if a file exists within a directory structure represented by a `dump_dir` structure, and handles invalid filenames with an error message."}
{"func_name": "get_git_branch", "func_src_before": "get_git_branch(wchar_t *dst, size_t size)\n{\n\tFILE *fp;\n\tchar *c;\n\tchar pwd[MAXPATHLEN];\n\tchar candidate[MAXPATHLEN];\n\tchar buf[MAX_BRANCH_LEN];\n\tsize_t s;\n\tstruct stat bufstat;\n\tint found_repo = -1;\n\n\t/* start from the working dir */\n\tstrlcpy(pwd, getcwd(NULL, MAXPATHLEN), MAXPATHLEN);\n\n\tdo {\n\t\tsnprintf(candidate, MAXPATHLEN, \"%s/.git/HEAD\", pwd);\n\n\t\tfound_repo = stat(candidate, &bufstat);\n\n\t\tif ((c = strrchr(pwd, '/')) == NULL)\n\t\t\tbreak;\n\n\t\t*c = '\\0';\n\t} while (found_repo != 0 && candidate[1] != '\\0');\n\n\tif (found_repo == -1)\n\t\treturn 0;\n\n\tfp = fopen(candidate, \"r\");\n\tif (fp == NULL) {\n\t\tstrlcpy(buf, \"###\", 4);\n\t\treturn mbstowcs(dst, buf, MAX_BRANCH_LEN);\n\t}\n\n\ts = fread(buf, 1, size, fp);\n\tfclose(fp);\n\n\tbuf[MAX_BRANCH_LEN] = '\\0';\n\n\t/* This is a branch head, just print the branch. */\n\tif (strncmp(buf, \"ref: refs/heads/\", 16) == 0) {\n\t\tchar *nl = strchr(buf, '\\n');\n\t\tif (nl)\n\t\t\t*(nl) = '\\0';\n\t\tc = buf + 16;\n\t\treturn mbstowcs(dst, c, MAX_BRANCH_LEN);\n\t}\n\n\t/* Show all other kinds of ref as-is (does it even exist?) */\n\tif (strncmp(buf, \"ref:\", 4) == 0) {\n\t\tchar *nl = strchr(buf, '\\n');\n\t\tif (nl) \n\t\t\t*(nl) = '\\0';\n\t\tc = buf + 5;\n\t\treturn mbstowcs(dst, c, MAX_BRANCH_LEN);\n\t}\n\n\t/* That's probably just a changeset, just show the first 6 chars */\n\tif (s > 6) {\n\t\tstrlcpy(buf + 6, \"...\", 4);\n\t\treturn mbstowcs(dst, buf, MAX_BRANCH_LEN);\n\t}\n\n\t/* We shouldn't get there, but we mind as well no crash. */\n\tstrlcpy(buf, \"???\", 4);\n\treturn mbstowcs(dst, buf, MAX_BRANCH_LEN);\n}", "func_src_after": "get_git_branch(wchar_t *dst, size_t size)\n{\n\tFILE *fp;\n\tchar *c;\n\tchar pwd[MAXPATHLEN];\n\tchar candidate[MAXPATHLEN];\n\tchar buf[MAX_BRANCH_LEN];\n\tsize_t s;\n\tstruct stat bufstat;\n\tint found_repo = -1;\n\n\t/* start from the working dir */\n\tstrlcpy(pwd, getcwd(NULL, MAXPATHLEN), MAXPATHLEN);\n\n\tdo {\n\t\tsnprintf(candidate, MAXPATHLEN, \"%s/.git/HEAD\", pwd);\n\n\t\tfound_repo = stat(candidate, &bufstat);\n\n\t\tif ((c = strrchr(pwd, '/')) == NULL)\n\t\t\tbreak;\n\n\t\t*c = '\\0';\n\t} while (found_repo != 0 && candidate[1] != '\\0');\n\n\tif (found_repo == -1)\n\t\treturn 0;\n\n\tfp = fopen(candidate, \"r\");\n\tif (fp == NULL) {\n\t\tstrlcpy(buf, \"###\", 4);\n\t\treturn mbstowcs(dst, buf, MAX_BRANCH_LEN);\n\t}\n\n\ts = fread(buf, 1, size, fp);\n\tfclose(fp);\n\n\tbuf[MAX_BRANCH_LEN - 1] = '\\0';\n\n\t/* This is a branch head, just print the branch. */\n\tif (strncmp(buf, \"ref: refs/heads/\", 16) == 0) {\n\t\tchar *nl = strchr(buf, '\\n');\n\t\tif (nl)\n\t\t\t*(nl) = '\\0';\n\t\tc = buf + 16;\n\t\treturn mbstowcs(dst, c, MAX_BRANCH_LEN);\n\t}\n\n\t/* Show all other kinds of ref as-is (does it even exist?) */\n\tif (strncmp(buf, \"ref:\", 4) == 0) {\n\t\tchar *nl = strchr(buf, '\\n');\n\t\tif (nl) \n\t\t\t*(nl) = '\\0';\n\t\tc = buf + 5;\n\t\treturn mbstowcs(dst, c, MAX_BRANCH_LEN);\n\t}\n\n\t/* That's probably just a changeset, just show the first 6 chars */\n\tif (s > 6) {\n\t\tstrlcpy(buf + 6, \"...\", 4);\n\t\treturn mbstowcs(dst, buf, MAX_BRANCH_LEN);\n\t}\n\n\t/* We shouldn't get there, but we mind as well no crash. */\n\tstrlcpy(buf, \"???\", 4);\n\treturn mbstowcs(dst, buf, MAX_BRANCH_LEN);\n}", "line_changes": {"deleted": [{"line_no": 38, "char_start": 713, "char_end": 742, "line": "\tbuf[MAX_BRANCH_LEN] = '\\0';\n"}], "added": [{"line_no": 38, "char_start": 713, "char_end": 746, "line": "\tbuf[MAX_BRANCH_LEN - 1] = '\\0';\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 732, "char_end": 736, "chars": " - 1"}]}, "commit_link": "github.com/tamentis/prwd/commit/2bf86717a20334c40d168ad968b863f0ab7fd8c5", "file_name": "main.c", "vul_type": "cwe-119", "commit_msg": "fix a buffer overflow", "parent_commit": "62dd9d1df4b4028e843964f7a2da96c89ee1f4de", "description": "Write a C function to determine the current Git branch name and copy it into a wide character string buffer."}
{"func_name": "edit_workflow", "func_src_before": "@check_document_access_permission()\ndef edit_workflow(request):\n  workflow_id = request.GET.get('workflow')\n  \n  if workflow_id:\n    wid = {}\n    if workflow_id.isdigit():\n      wid['id'] = workflow_id\n    else:\n      wid['uuid'] = workflow_id\n    doc = Document2.objects.get(type='oozie-workflow2', **wid)\n    workflow = Workflow(document=doc)\n  else:\n    doc = None\n    workflow = Workflow()\n    workflow.set_workspace(request.user)\n    workflow.check_workspace(request.fs, request.user)\n  \n  workflow_data = workflow.get_data()\n\n  api = get_oozie(request.user)\n  credentials = Credentials()\n  \n  try:  \n    credentials.fetch(api)\n  except Exception, e:\n    LOG.error(smart_str(e))\n\n  return render('editor/workflow_editor.mako', request, {\n      'layout_json': json.dumps(workflow_data['layout']),\n      'workflow_json': json.dumps(workflow_data['workflow']),\n      'credentials_json': json.dumps(credentials.credentials.keys()),\n      'workflow_properties_json': json.dumps(WORKFLOW_NODE_PROPERTIES),\n      'doc1_id': doc.doc.get().id if doc else -1,\n      'subworkflows_json': json.dumps(_get_workflows(request.user)),\n      'can_edit_json': json.dumps(doc is None or doc.doc.get().is_editable(request.user))\n  })", "func_src_after": "@check_document_access_permission()\ndef edit_workflow(request):\n  workflow_id = request.GET.get('workflow')\n  \n  if workflow_id:\n    wid = {}\n    if workflow_id.isdigit():\n      wid['id'] = workflow_id\n    else:\n      wid['uuid'] = workflow_id\n    doc = Document2.objects.get(type='oozie-workflow2', **wid)\n    workflow = Workflow(document=doc)\n  else:\n    doc = None\n    workflow = Workflow()\n    workflow.set_workspace(request.user)\n    workflow.check_workspace(request.fs, request.user)\n  \n  workflow_data = workflow.get_data()\n\n  api = get_oozie(request.user)\n  credentials = Credentials()\n  \n  try:  \n    credentials.fetch(api)\n  except Exception, e:\n    LOG.error(smart_str(e))\n\n  return render('editor/workflow_editor.mako', request, {\n      'layout_json': json.dumps(workflow_data['layout'], cls=JSONEncoderForHTML),\n      'workflow_json': json.dumps(workflow_data['workflow'], cls=JSONEncoderForHTML),\n      'credentials_json': json.dumps(credentials.credentials.keys(), cls=JSONEncoderForHTML),\n      'workflow_properties_json': json.dumps(WORKFLOW_NODE_PROPERTIES, cls=JSONEncoderForHTML),\n      'doc1_id': doc.doc.get().id if doc else -1,\n      'subworkflows_json': json.dumps(_get_workflows(request.user), cls=JSONEncoderForHTML),\n      'can_edit_json': json.dumps(doc is None or doc.doc.get().is_editable(request.user))\n  })", "commit_link": "github.com/gethue/hue/commit/6641c62beaa1468082e47d82da5ed758d11c7735", "file_name": "apps/oozie/src/oozie/views/editor2.py", "vul_type": "cwe-079", "description": "Write a Python function with a decorator to check user permissions, which retrieves and edits workflow data based on a request, handling credentials and rendering a response."}
{"func_name": "mrb_class_real", "func_src_before": "mrb_class_real(struct RClass* cl)\n{\n  if (cl == 0)\n    return NULL;\n  while ((cl->tt == MRB_TT_SCLASS) || (cl->tt == MRB_TT_ICLASS)) {\n    cl = cl->super;\n  }\n  return cl;\n}", "func_src_after": "mrb_class_real(struct RClass* cl)\n{\n  if (cl == 0) return NULL;\n  while ((cl->tt == MRB_TT_SCLASS) || (cl->tt == MRB_TT_ICLASS)) {\n    cl = cl->super;\n    if (cl == 0) return NULL;\n  }\n  return cl;\n}", "commit_link": "github.com/mruby/mruby/commit/faa4eaf6803bd11669bc324b4c34e7162286bfa3", "file_name": "src/class.c", "vul_type": "cwe-476", "description": "Write a function in C that returns the first non-singleton and non-included class in a class hierarchy, or NULL if not found."}
{"func_name": "UserController.createOrJoinTeam", "func_src_before": "UserController.createOrJoinTeam = function(id, code, callback){\n\n  if (!code){\n    return callback({\n      message: \"Please enter a team name.\"\n    });\n  }\n\n  User.find({\n    teamCode: code\n  })\n  .select('profile.name')\n  .exec(function(err, users){\n    // Check to see if this team is joinable (< team max size)\n\n    if (users.length >= maxTeamSize){\n      return callback({\n        message: \"Team is full.\"\n      });\n    }\n\n    // Otherwise, we can add that person to the team.\n    User.findOneAndUpdate({\n      _id: id,\n      verified: true\n    },{\n      $set: {\n        teamCode: code\n      }\n    }, {\n      new: true\n    },\n    callback);\n\n  });\n};", "func_src_after": "UserController.createOrJoinTeam = function(id, code, callback){\n\n  if (!code){\n    return callback({\n      message: \"Please enter a team name.\"\n    });\n  }\n\n  if (typeof code !== 'string') {\n    return callback({\n      message: \"Get outta here, punk!\"\n    });\n  }\n\n  User.find({\n    teamCode: code\n  })\n  .select('profile.name')\n  .exec(function(err, users){\n    // Check to see if this team is joinable (< team max size)\n    if (users.length >= maxTeamSize){\n      return callback({\n        message: \"Team is full.\"\n      });\n    }\n\n    // Otherwise, we can add that person to the team.\n    User.findOneAndUpdate({\n      _id: id,\n      verified: true\n    },{\n      $set: {\n        teamCode: code\n      }\n    }, {\n      new: true\n    },\n    callback);\n\n  });\n};", "line_changes": {"deleted": [{"line_no": 15, "char_start": 314, "char_end": 315, "line": "\n"}], "added": [{"line_no": 9, "char_start": 157, "char_end": 191, "line": "  if (typeof code !== 'string') {\n"}, {"line_no": 10, "char_start": 191, "char_end": 213, "line": "    return callback({\n"}, {"line_no": 11, "char_start": 213, "char_end": 252, "line": "      message: \"Get outta here, punk!\"\n"}, {"line_no": 12, "char_start": 252, "char_end": 260, "line": "    });\n"}, {"line_no": 13, "char_start": 260, "char_end": 264, "line": "  }\n"}, {"line_no": 14, "char_start": 264, "char_end": 265, "line": "\n"}]}, "char_changes": {"deleted": [{"char_start": 314, "char_end": 315, "chars": "\n"}], "added": [{"char_start": 157, "char_end": 265, "chars": "  if (typeof code !== 'string') {\n    return callback({\n      message: \"Get outta here, punk!\"\n    });\n  }\n\n"}]}, "commit_link": "github.com/techx/quill/commit/88a42ea6c4bcdee1b180b0a140d8886c3b5c543e", "file_name": "UserController.js", "vul_type": "cwe-089", "commit_msg": "Security: `/users/:id/team` NoSQL Injection Fix", "description": "Write a JavaScript function that allows a user to join a team by name if there's space available."}
{"func_name": "compact_upto_test", "func_src_before": "void compact_upto_test(bool multi_kv)\n{\n    TEST_INIT();\n\n    memleak_start();\n\n    int i, r;\n    int n = 20;\n    int num_kvs = 4; // keep this the same as number of fdb_commit() calls\n    fdb_file_handle *dbfile;\n    fdb_kvs_handle **db = alca(fdb_kvs_handle *, num_kvs);\n    fdb_doc **doc = alca(fdb_doc*, n);\n    fdb_status status;\n    fdb_snapshot_info_t *markers;\n    fdb_kvs_handle *snapshot;\n    uint64_t num_markers;\n\n    char keybuf[256], metabuf[256], bodybuf[256];\n    char kv_name[8];\n    char compact_filename[16];\n\n    fdb_config fconfig = fdb_get_default_config();\n    fdb_kvs_config kvs_config = fdb_get_default_kvs_config();\n    fconfig.buffercache_size = 0;\n    fconfig.wal_threshold = 1024;\n    fconfig.flags = FDB_OPEN_FLAG_CREATE;\n    fconfig.compaction_threshold = 0;\n    fconfig.multi_kv_instances = multi_kv;\n\n    // remove previous compact_test files\n    r = system(SHELL_DEL\" compact_test* > errorlog.txt\");\n    (void)r;\n\n    // open db\n    fdb_open(&dbfile, \"./compact_test1\", &fconfig);\n    if (multi_kv) {\n        for (r = 0; r < num_kvs; ++r) {\n            sprintf(kv_name, \"kv%d\", r);\n            fdb_kvs_open(dbfile, &db[r], kv_name, &kvs_config);\n        }\n    } else {\n        num_kvs = 1;\n        fdb_kvs_open_default(dbfile, &db[0], &kvs_config);\n    }\n\n   // ------- Setup test ----------------------------------\n   // insert documents of 0-4\n    for (i=0; i<n/4; i++){\n        sprintf(keybuf, \"key%d\", i);\n        sprintf(metabuf, \"meta%d\", i);\n        sprintf(bodybuf, \"body%d\", i);\n        fdb_doc_create(&doc[i], (void*)keybuf, strlen(keybuf),\n            (void*)metabuf, strlen(metabuf), (void*)bodybuf, strlen(bodybuf));\n        for (r = 0; r < num_kvs; ++r) {\n            fdb_set(db[r], doc[i]);\n        }\n    }\n\n    // commit with a manual WAL flush (these docs go into HB-trie)\n    fdb_commit(dbfile, FDB_COMMIT_MANUAL_WAL_FLUSH);\n\n    // insert documents from 5 - 9\n    for (; i < n/2; i++){\n        sprintf(keybuf, \"key%d\", i);\n        sprintf(metabuf, \"meta%d\", i);\n        sprintf(bodybuf, \"body%d\", i);\n        fdb_doc_create(&doc[i], (void*)keybuf, strlen(keybuf),\n            (void*)metabuf, strlen(metabuf), (void*)bodybuf, strlen(bodybuf));\n        for (r = 0; r < num_kvs; ++r) {\n            fdb_set(db[r], doc[i]);\n        }\n    }\n\n    // commit again without a WAL flush\n    fdb_commit(dbfile, FDB_COMMIT_NORMAL);\n\n    // insert documents from 10-14 into HB-trie\n    for (; i < (n/2 + n/4); i++){\n        sprintf(keybuf, \"key%d\", i);\n        sprintf(metabuf, \"meta%d\", i);\n        sprintf(bodybuf, \"body%d\", i);\n        fdb_doc_create(&doc[i], (void*)keybuf, strlen(keybuf),\n            (void*)metabuf, strlen(metabuf), (void*)bodybuf, strlen(bodybuf));\n        for (r = 0; r < num_kvs; ++r) {\n            fdb_set(db[r], doc[i]);\n        }\n    }\n    // manually flush WAL & commit\n    fdb_commit(dbfile, FDB_COMMIT_MANUAL_WAL_FLUSH);\n\n    // insert documents from 15 - 19 on file into the WAL\n    for (; i < n; i++){\n        sprintf(keybuf, \"key%d\", i);\n        sprintf(metabuf, \"meta%d\", i);\n        sprintf(bodybuf, \"body%d\", i);\n        fdb_doc_create(&doc[i], (void*)keybuf, strlen(keybuf),\n            (void*)metabuf, strlen(metabuf), (void*)bodybuf, strlen(bodybuf));\n        for (r = 0; r < num_kvs; ++r) {\n            fdb_set(db[r], doc[i]);\n        }\n    }\n    // commit without a WAL flush\n    fdb_commit(dbfile, FDB_COMMIT_NORMAL);\n\n    for (r = 0; r < num_kvs; ++r) {\n        status = fdb_set_log_callback(db[r], logCallbackFunc,\n                                      (void *) \"compact_upto_test\");\n        TEST_CHK(status == FDB_RESULT_SUCCESS);\n    }\n\n    status = fdb_get_all_snap_markers(dbfile, &markers, &num_markers);\n    TEST_CHK(status == FDB_RESULT_SUCCESS);\n\n    if (!multi_kv) {\n        TEST_CHK(num_markers == 4);\n        for (r = 0; r < num_markers; ++r) {\n            TEST_CHK(markers[r].num_kvs_markers == 1);\n            TEST_CHK(markers[r].kvs_markers[0].seqnum == (n - r*5));\n        }\n        r = 1; // Test compacting upto sequence number 15\n        sprintf(compact_filename, \"compact_test_compact%d\", r);\n        status = fdb_compact_upto(dbfile, compact_filename,\n                                  markers[r].marker);\n        TEST_CHK(status == FDB_RESULT_SUCCESS);\n        // create a snapshot\n        status = fdb_snapshot_open(db[0], &snapshot,\n                                   markers[r].kvs_markers[0].seqnum);\n        TEST_CHK(status == FDB_RESULT_SUCCESS);\n        // close snapshot\n        fdb_kvs_close(snapshot);\n    } else {\n        TEST_CHK(num_markers == 8);\n        for (r = 0; r < num_kvs; ++r) {\n            TEST_CHK(markers[r].num_kvs_markers == num_kvs);\n            for (i = 0; i < num_kvs; ++i) {\n                TEST_CHK(markers[r].kvs_markers[i].seqnum == (n - r*5));\n                sprintf(kv_name, \"kv%d\", i);\n                TEST_CMP(markers[r].kvs_markers[i].kv_store_name, kv_name, 3);\n            }\n        }\n        i = r = 1;\n        sprintf(compact_filename, \"compact_test_compact%d\", i);\n        status = fdb_compact_upto(dbfile, compact_filename,\n                markers[i].marker);\n        TEST_CHK(status == FDB_RESULT_SUCCESS);\n        // create a snapshot\n        status = fdb_snapshot_open(db[r], &snapshot,\n                markers[i].kvs_markers[r].seqnum);\n        TEST_CHK(status == FDB_RESULT_SUCCESS);\n        // close snapshot\n        fdb_kvs_close(snapshot);\n    }\n\n    status = fdb_free_snap_markers(markers, num_markers);\n    TEST_CHK(status == FDB_RESULT_SUCCESS);\n\n    // close db file\n    fdb_close(dbfile);\n\n    // free all documents\n    for (i=0;i<n;++i){\n        fdb_doc_free(doc[i]);\n    }\n\n    // free all resources\n    fdb_shutdown();\n\n    memleak_end();\n\n    sprintf(bodybuf, \"compact upto marker in file test %s\", multi_kv ?\n                                                           \"multiple kv mode:\"\n                                                         : \"single kv mode:\");\n    TEST_RESULT(bodybuf);\n}", "func_src_after": "void compact_upto_test(bool multi_kv)\n{\n    TEST_INIT();\n\n    memleak_start();\n\n    int i, r;\n    int n = 20;\n    int num_kvs = 4; // keep this the same as number of fdb_commit() calls\n    fdb_file_handle *dbfile;\n    fdb_kvs_handle **db = alca(fdb_kvs_handle *, num_kvs);\n    fdb_doc **doc = alca(fdb_doc*, n);\n    fdb_status status;\n    fdb_snapshot_info_t *markers;\n    fdb_kvs_handle *snapshot;\n    uint64_t num_markers;\n\n    char keybuf[256], metabuf[256], bodybuf[256];\n    char kv_name[8];\n    char compact_filename[32];\n\n    fdb_config fconfig = fdb_get_default_config();\n    fdb_kvs_config kvs_config = fdb_get_default_kvs_config();\n    fconfig.buffercache_size = 0;\n    fconfig.wal_threshold = 1024;\n    fconfig.flags = FDB_OPEN_FLAG_CREATE;\n    fconfig.compaction_threshold = 0;\n    fconfig.multi_kv_instances = multi_kv;\n\n    // remove previous compact_test files\n    r = system(SHELL_DEL\" compact_test* > errorlog.txt\");\n    (void)r;\n\n    // open db\n    fdb_open(&dbfile, \"./compact_test1\", &fconfig);\n    if (multi_kv) {\n        for (r = 0; r < num_kvs; ++r) {\n            sprintf(kv_name, \"kv%d\", r);\n            fdb_kvs_open(dbfile, &db[r], kv_name, &kvs_config);\n        }\n    } else {\n        num_kvs = 1;\n        fdb_kvs_open_default(dbfile, &db[0], &kvs_config);\n    }\n\n   // ------- Setup test ----------------------------------\n   // insert documents of 0-4\n    for (i=0; i<n/4; i++){\n        sprintf(keybuf, \"key%d\", i);\n        sprintf(metabuf, \"meta%d\", i);\n        sprintf(bodybuf, \"body%d\", i);\n        fdb_doc_create(&doc[i], (void*)keybuf, strlen(keybuf),\n            (void*)metabuf, strlen(metabuf), (void*)bodybuf, strlen(bodybuf));\n        for (r = 0; r < num_kvs; ++r) {\n            fdb_set(db[r], doc[i]);\n        }\n    }\n\n    // commit with a manual WAL flush (these docs go into HB-trie)\n    fdb_commit(dbfile, FDB_COMMIT_MANUAL_WAL_FLUSH);\n\n    // insert documents from 5 - 9\n    for (; i < n/2; i++){\n        sprintf(keybuf, \"key%d\", i);\n        sprintf(metabuf, \"meta%d\", i);\n        sprintf(bodybuf, \"body%d\", i);\n        fdb_doc_create(&doc[i], (void*)keybuf, strlen(keybuf),\n            (void*)metabuf, strlen(metabuf), (void*)bodybuf, strlen(bodybuf));\n        for (r = 0; r < num_kvs; ++r) {\n            fdb_set(db[r], doc[i]);\n        }\n    }\n\n    // commit again without a WAL flush\n    fdb_commit(dbfile, FDB_COMMIT_NORMAL);\n\n    // insert documents from 10-14 into HB-trie\n    for (; i < (n/2 + n/4); i++){\n        sprintf(keybuf, \"key%d\", i);\n        sprintf(metabuf, \"meta%d\", i);\n        sprintf(bodybuf, \"body%d\", i);\n        fdb_doc_create(&doc[i], (void*)keybuf, strlen(keybuf),\n            (void*)metabuf, strlen(metabuf), (void*)bodybuf, strlen(bodybuf));\n        for (r = 0; r < num_kvs; ++r) {\n            fdb_set(db[r], doc[i]);\n        }\n    }\n    // manually flush WAL & commit\n    fdb_commit(dbfile, FDB_COMMIT_MANUAL_WAL_FLUSH);\n\n    // insert documents from 15 - 19 on file into the WAL\n    for (; i < n; i++){\n        sprintf(keybuf, \"key%d\", i);\n        sprintf(metabuf, \"meta%d\", i);\n        sprintf(bodybuf, \"body%d\", i);\n        fdb_doc_create(&doc[i], (void*)keybuf, strlen(keybuf),\n            (void*)metabuf, strlen(metabuf), (void*)bodybuf, strlen(bodybuf));\n        for (r = 0; r < num_kvs; ++r) {\n            fdb_set(db[r], doc[i]);\n        }\n    }\n    // commit without a WAL flush\n    fdb_commit(dbfile, FDB_COMMIT_NORMAL);\n\n    for (r = 0; r < num_kvs; ++r) {\n        status = fdb_set_log_callback(db[r], logCallbackFunc,\n                                      (void *) \"compact_upto_test\");\n        TEST_CHK(status == FDB_RESULT_SUCCESS);\n    }\n\n    status = fdb_get_all_snap_markers(dbfile, &markers, &num_markers);\n    TEST_CHK(status == FDB_RESULT_SUCCESS);\n\n    if (!multi_kv) {\n        TEST_CHK(num_markers == 4);\n        for (r = 0; r < num_markers; ++r) {\n            TEST_CHK(markers[r].num_kvs_markers == 1);\n            TEST_CHK(markers[r].kvs_markers[0].seqnum == (n - r*5));\n        }\n        r = 1; // Test compacting upto sequence number 15\n        sprintf(compact_filename, \"compact_test_compact%d\", r);\n        status = fdb_compact_upto(dbfile, compact_filename,\n                                  markers[r].marker);\n        TEST_CHK(status == FDB_RESULT_SUCCESS);\n        // create a snapshot\n        status = fdb_snapshot_open(db[0], &snapshot,\n                                   markers[r].kvs_markers[0].seqnum);\n        TEST_CHK(status == FDB_RESULT_SUCCESS);\n        // close snapshot\n        fdb_kvs_close(snapshot);\n    } else {\n        TEST_CHK(num_markers == 8);\n        for (r = 0; r < num_kvs; ++r) {\n            TEST_CHK(markers[r].num_kvs_markers == num_kvs);\n            for (i = 0; i < num_kvs; ++i) {\n                TEST_CHK(markers[r].kvs_markers[i].seqnum == (n - r*5));\n                sprintf(kv_name, \"kv%d\", i);\n                TEST_CMP(markers[r].kvs_markers[i].kv_store_name, kv_name, 3);\n            }\n        }\n        i = r = 1;\n        sprintf(compact_filename, \"compact_test_compact%d\", i);\n        status = fdb_compact_upto(dbfile, compact_filename,\n                markers[i].marker);\n        TEST_CHK(status == FDB_RESULT_SUCCESS);\n        // create a snapshot\n        status = fdb_snapshot_open(db[r], &snapshot,\n                markers[i].kvs_markers[r].seqnum);\n        TEST_CHK(status == FDB_RESULT_SUCCESS);\n        // close snapshot\n        fdb_kvs_close(snapshot);\n    }\n\n    status = fdb_free_snap_markers(markers, num_markers);\n    TEST_CHK(status == FDB_RESULT_SUCCESS);\n\n    // close db file\n    fdb_close(dbfile);\n\n    // free all documents\n    for (i=0;i<n;++i){\n        fdb_doc_free(doc[i]);\n    }\n\n    // free all resources\n    fdb_shutdown();\n\n    memleak_end();\n\n    sprintf(bodybuf, \"compact upto marker in file test %s\", multi_kv ?\n                                                           \"multiple kv mode:\"\n                                                         : \"single kv mode:\");\n    TEST_RESULT(bodybuf);\n}", "line_changes": {"deleted": [{"line_no": 20, "char_start": 497, "char_end": 528, "line": "    char compact_filename[16];\n"}], "added": [{"line_no": 20, "char_start": 497, "char_end": 528, "line": "    char compact_filename[32];\n"}]}, "char_changes": {"deleted": [{"char_start": 523, "char_end": 525, "chars": "16"}], "added": [{"char_start": 523, "char_end": 525, "chars": "32"}]}, "commit_link": "github.com/hisundar/forestdb/commit/1df4c96057712be6ccf6614419ebcb2a01bb87f7", "file_name": "compact_functional_test.cc", "vul_type": "cwe-787", "commit_msg": "fix buffer overflow in compact_functional_test\n\nChange-Id: I1d4f79f8abfc96eaf546d05800a2eccdf0c828f6", "parent_commit": "6ef65b54f9324000de89e11b8a8bd688393a380b", "description": "Write a C function named `compact_upto_test` that tests the compaction of a database up to a certain point using the ForestDB engine."}
{"func_name": "ipv4_pktinfo_prepare", "func_src_before": "void ipv4_pktinfo_prepare(const struct sock *sk, struct sk_buff *skb)\n{\n\tstruct in_pktinfo *pktinfo = PKTINFO_SKB_CB(skb);\n\tbool prepare = (inet_sk(sk)->cmsg_flags & IP_CMSG_PKTINFO) ||\n\t\t       ipv6_sk_rxinfo(sk);\n\n\tif (prepare && skb_rtable(skb)) {\n\t\t/* skb->cb is overloaded: prior to this point it is IP{6}CB\n\t\t * which has interface index (iif) as the first member of the\n\t\t * underlying inet{6}_skb_parm struct. This code then overlays\n\t\t * PKTINFO_SKB_CB and in_pktinfo also has iif as the first\n\t\t * element so the iif is picked up from the prior IPCB. If iif\n\t\t * is the loopback interface, then return the sending interface\n\t\t * (e.g., process binds socket to eth0 for Tx which is\n\t\t * redirected to loopback in the rtable/dst).\n\t\t */\n\t\tif (pktinfo->ipi_ifindex == LOOPBACK_IFINDEX)\n\t\t\tpktinfo->ipi_ifindex = inet_iif(skb);\n\n\t\tpktinfo->ipi_spec_dst.s_addr = fib_compute_spec_dst(skb);\n\t} else {\n\t\tpktinfo->ipi_ifindex = 0;\n\t\tpktinfo->ipi_spec_dst.s_addr = 0;\n\t}\n\tskb_dst_drop(skb);\n}", "func_src_after": "void ipv4_pktinfo_prepare(const struct sock *sk, struct sk_buff *skb)\n{\n\tstruct in_pktinfo *pktinfo = PKTINFO_SKB_CB(skb);\n\tbool prepare = (inet_sk(sk)->cmsg_flags & IP_CMSG_PKTINFO) ||\n\t\t       ipv6_sk_rxinfo(sk);\n\n\tif (prepare && skb_rtable(skb)) {\n\t\t/* skb->cb is overloaded: prior to this point it is IP{6}CB\n\t\t * which has interface index (iif) as the first member of the\n\t\t * underlying inet{6}_skb_parm struct. This code then overlays\n\t\t * PKTINFO_SKB_CB and in_pktinfo also has iif as the first\n\t\t * element so the iif is picked up from the prior IPCB. If iif\n\t\t * is the loopback interface, then return the sending interface\n\t\t * (e.g., process binds socket to eth0 for Tx which is\n\t\t * redirected to loopback in the rtable/dst).\n\t\t */\n\t\tif (pktinfo->ipi_ifindex == LOOPBACK_IFINDEX)\n\t\t\tpktinfo->ipi_ifindex = inet_iif(skb);\n\n\t\tpktinfo->ipi_spec_dst.s_addr = fib_compute_spec_dst(skb);\n\t} else {\n\t\tpktinfo->ipi_ifindex = 0;\n\t\tpktinfo->ipi_spec_dst.s_addr = 0;\n\t}\n\t/* We need to keep the dst for __ip_options_echo()\n\t * We could restrict the test to opt.ts_needtime || opt.srr,\n\t * but the following is good enough as IP options are not often used.\n\t */\n\tif (unlikely(IPCB(skb)->opt.optlen))\n\t\tskb_dst_force(skb);\n\telse\n\t\tskb_dst_drop(skb);\n}", "commit_link": "github.com/torvalds/linux/commit/34b2cef20f19c87999fff3da4071e66937db9644", "file_name": "net/ipv4/ip_sockglue.c", "vul_type": "cwe-476", "description": "Write a C function named `ipv4_pktinfo_prepare` that prepares packet information for an IPv4 socket in a Linux kernel environment."}
{"func_name": "open_ssl_connection", "func_src_before": "open_ssl_connection (rfbClient *client, int sockfd, rfbBool anonTLS, rfbCredential *cred)\n{\n  SSL_CTX *ssl_ctx = NULL;\n  SSL *ssl = NULL;\n  int n, finished = 0;\n  X509_VERIFY_PARAM *param;\n  uint8_t verify_crls = cred->x509Credential.x509CrlVerifyMode;\n\n  if (!(ssl_ctx = SSL_CTX_new(SSLv23_client_method())))\n  {\n    rfbClientLog(\"Could not create new SSL context.\\n\");\n    return NULL;\n  }\n\n  param = X509_VERIFY_PARAM_new();\n\n  /* Setup verification if not anonymous */\n  if (!anonTLS)\n  {\n    if (cred->x509Credential.x509CACertFile)\n    {\n      if (!SSL_CTX_load_verify_locations(ssl_ctx, cred->x509Credential.x509CACertFile, NULL))\n      {\n        rfbClientLog(\"Failed to load CA certificate from %s.\\n\",\n                     cred->x509Credential.x509CACertFile);\n        goto error_free_ctx;\n      }\n    } else {\n      rfbClientLog(\"Using default paths for certificate verification.\\n\");\n      SSL_CTX_set_default_verify_paths (ssl_ctx);\n    }\n\n    if (cred->x509Credential.x509CACrlFile)\n    {\n      if (!load_crls_from_file(cred->x509Credential.x509CACrlFile, ssl_ctx))\n      {\n        rfbClientLog(\"CRLs could not be loaded.\\n\");\n        goto error_free_ctx;\n      }\n      if (verify_crls == rfbX509CrlVerifyNone) verify_crls = rfbX509CrlVerifyAll;\n    }\n\n    if (cred->x509Credential.x509ClientCertFile && cred->x509Credential.x509ClientKeyFile)\n    {\n      if (SSL_CTX_use_certificate_chain_file(ssl_ctx, cred->x509Credential.x509ClientCertFile) != 1)\n      {\n        rfbClientLog(\"Client certificate could not be loaded.\\n\");\n        goto error_free_ctx;\n      }\n\n      if (SSL_CTX_use_PrivateKey_file(ssl_ctx, cred->x509Credential.x509ClientKeyFile,\n                                      SSL_FILETYPE_PEM) != 1)\n      {\n        rfbClientLog(\"Client private key could not be loaded.\\n\");\n        goto error_free_ctx;\n      }\n\n      if (SSL_CTX_check_private_key(ssl_ctx) == 0) {\n        rfbClientLog(\"Client certificate and private key do not match.\\n\");\n        goto error_free_ctx;\n      }\n    }\n\n    SSL_CTX_set_verify(ssl_ctx, SSL_VERIFY_PEER, NULL);\n\n    if (verify_crls == rfbX509CrlVerifyClient) \n      X509_VERIFY_PARAM_set_flags(param, X509_V_FLAG_CRL_CHECK);\n    else if (verify_crls == rfbX509CrlVerifyAll)\n      X509_VERIFY_PARAM_set_flags(param, X509_V_FLAG_CRL_CHECK | X509_V_FLAG_CRL_CHECK_ALL);\n\n    if(!X509_VERIFY_PARAM_set1_host(param, client->serverHost, strlen(client->serverHost)))\n    {\n      rfbClientLog(\"Could not set server name for verification.\\n\");\n      goto error_free_ctx;\n    }\n    SSL_CTX_set1_param(ssl_ctx, param);\n  }\n\n  if (!(ssl = SSL_new (ssl_ctx)))\n  {\n    rfbClientLog(\"Could not create a new SSL session.\\n\");\n    goto error_free_ctx;\n  }\n\n  /* TODO: finetune this list, take into account anonTLS bool */\n  SSL_set_cipher_list(ssl, \"ALL\");\n\n  SSL_set_fd (ssl, sockfd);\n  SSL_CTX_set_app_data (ssl_ctx, client);\n\n  do\n  {\n    n = SSL_connect(ssl);\n\t\t\n    if (n != 1) \n    {\n      if (wait_for_data(ssl, n, 1) != 1) \n      {\n        finished = 1;\n        SSL_shutdown(ssl);\n\n        goto error_free_ssl;\n      }\n    }\n  } while( n != 1 && finished != 1 );\n\n  X509_VERIFY_PARAM_free(param);\n  return ssl;\n\nerror_free_ssl:\n  SSL_free(ssl);\n\nerror_free_ctx:\n  X509_VERIFY_PARAM_free(param);\n  SSL_CTX_free(ssl_ctx);\n\n  return NULL;\n}", "func_src_after": "open_ssl_connection (rfbClient *client, int sockfd, rfbBool anonTLS, rfbCredential *cred)\n{\n  SSL_CTX *ssl_ctx = NULL;\n  SSL *ssl = NULL;\n  int n, finished = 0;\n  X509_VERIFY_PARAM *param;\n  uint8_t verify_crls;\n\n  if (!(ssl_ctx = SSL_CTX_new(SSLv23_client_method())))\n  {\n    rfbClientLog(\"Could not create new SSL context.\\n\");\n    return NULL;\n  }\n\n  param = X509_VERIFY_PARAM_new();\n\n  /* Setup verification if not anonymous */\n  if (!anonTLS)\n  {\n    verify_crls = cred->x509Credential.x509CrlVerifyMode;\n    if (cred->x509Credential.x509CACertFile)\n    {\n      if (!SSL_CTX_load_verify_locations(ssl_ctx, cred->x509Credential.x509CACertFile, NULL))\n      {\n        rfbClientLog(\"Failed to load CA certificate from %s.\\n\",\n                     cred->x509Credential.x509CACertFile);\n        goto error_free_ctx;\n      }\n    } else {\n      rfbClientLog(\"Using default paths for certificate verification.\\n\");\n      SSL_CTX_set_default_verify_paths (ssl_ctx);\n    }\n\n    if (cred->x509Credential.x509CACrlFile)\n    {\n      if (!load_crls_from_file(cred->x509Credential.x509CACrlFile, ssl_ctx))\n      {\n        rfbClientLog(\"CRLs could not be loaded.\\n\");\n        goto error_free_ctx;\n      }\n      if (verify_crls == rfbX509CrlVerifyNone) verify_crls = rfbX509CrlVerifyAll;\n    }\n\n    if (cred->x509Credential.x509ClientCertFile && cred->x509Credential.x509ClientKeyFile)\n    {\n      if (SSL_CTX_use_certificate_chain_file(ssl_ctx, cred->x509Credential.x509ClientCertFile) != 1)\n      {\n        rfbClientLog(\"Client certificate could not be loaded.\\n\");\n        goto error_free_ctx;\n      }\n\n      if (SSL_CTX_use_PrivateKey_file(ssl_ctx, cred->x509Credential.x509ClientKeyFile,\n                                      SSL_FILETYPE_PEM) != 1)\n      {\n        rfbClientLog(\"Client private key could not be loaded.\\n\");\n        goto error_free_ctx;\n      }\n\n      if (SSL_CTX_check_private_key(ssl_ctx) == 0) {\n        rfbClientLog(\"Client certificate and private key do not match.\\n\");\n        goto error_free_ctx;\n      }\n    }\n\n    SSL_CTX_set_verify(ssl_ctx, SSL_VERIFY_PEER, NULL);\n\n    if (verify_crls == rfbX509CrlVerifyClient) \n      X509_VERIFY_PARAM_set_flags(param, X509_V_FLAG_CRL_CHECK);\n    else if (verify_crls == rfbX509CrlVerifyAll)\n      X509_VERIFY_PARAM_set_flags(param, X509_V_FLAG_CRL_CHECK | X509_V_FLAG_CRL_CHECK_ALL);\n\n    if(!X509_VERIFY_PARAM_set1_host(param, client->serverHost, strlen(client->serverHost)))\n    {\n      rfbClientLog(\"Could not set server name for verification.\\n\");\n      goto error_free_ctx;\n    }\n    SSL_CTX_set1_param(ssl_ctx, param);\n  }\n\n  if (!(ssl = SSL_new (ssl_ctx)))\n  {\n    rfbClientLog(\"Could not create a new SSL session.\\n\");\n    goto error_free_ctx;\n  }\n\n  /* TODO: finetune this list, take into account anonTLS bool */\n  SSL_set_cipher_list(ssl, \"ALL\");\n\n  SSL_set_fd (ssl, sockfd);\n  SSL_CTX_set_app_data (ssl_ctx, client);\n\n  do\n  {\n    n = SSL_connect(ssl);\n\t\t\n    if (n != 1) \n    {\n      if (wait_for_data(ssl, n, 1) != 1) \n      {\n        finished = 1;\n        SSL_shutdown(ssl);\n\n        goto error_free_ssl;\n      }\n    }\n  } while( n != 1 && finished != 1 );\n\n  X509_VERIFY_PARAM_free(param);\n  return ssl;\n\nerror_free_ssl:\n  SSL_free(ssl);\n\nerror_free_ctx:\n  X509_VERIFY_PARAM_free(param);\n  SSL_CTX_free(ssl_ctx);\n\n  return NULL;\n}", "commit_link": "github.com/LibVNC/libvncserver/commit/33441d90a506d5f3ae9388f2752901227e430553", "file_name": "libvncclient/tls_openssl.c", "vul_type": "cwe-476", "description": "Write a C function to establish an SSL connection with optional certificate verification and error handling."}
{"func_name": "job_browse", "func_src_before": "@gui.route(\"/job/<int:job_id>/browse\", defaults={\"path\": \"\"})\n@gui.route(\"/job/<int:job_id>/browse/<path:path>\")\n@login_required\ndef job_browse(job_id: int, path):\n    \"\"\"\n    Browse directory of the job.\n    :param job_id: int\n    :param path: str\n    \"\"\"\n\n    try:\n        # Query job information\n        job_info = query_internal_api(f\"/internal/jobs/{job_id}\", \"get\")\n\n        # Base directory of the job\n        job_base_dir = os.path.dirname(os.path.dirname(job_info[\"outputdir\"]))\n\n    except Exception as err:\n        # Display error on the GUI\n        flash(str(err), \"danger\")\n        return redirect(url_for(\"job_page\", job_id=job_id))\n\n    # Join the base and the requested path\n    abs_path = os.path.join(job_base_dir, path)\n\n    # URL path variable for going back\n    back_path = os.path.dirname(abs_path).replace(job_base_dir, \"\")\n\n    # If path doesn't exist\n    if not os.path.exists(abs_path):\n        flash(\"Directory for this job does not exist.\", \"warning\")\n        return redirect(url_for(\"job_page\", job_id=job_id))\n\n    # Check if path is a file and send\n    if os.path.isfile(abs_path):\n        return send_file(abs_path)\n\n    files_info = []\n\n    # Show directory contents\n    files = os.listdir(abs_path)\n\n    # Store directory information\n    for file in files:\n        files_info.append({\n            \"file\": file,\n            \"directory\": os.path.isdir(os.path.join(abs_path, file))\n        })\n\n    return render_template('job_dir.html', title=f\"Job {job_id} Directory\",\n                           job_id=job_id,\n                           abs_path=abs_path,\n                           files_info=files_info,\n                           back_path=back_path)", "func_src_after": "@gui.route(\"/job/<int:job_id>/browse\", defaults={\"path\": \"\"})\n@gui.route(\"/job/<int:job_id>/browse/<path:path>\")\n@login_required\ndef job_browse(job_id: int, path):\n    \"\"\"\n    Browse directory of the job.\n    :param job_id: int\n    :param path: str\n    \"\"\"\n\n    try:\n        # Query job information\n        job_info = query_internal_api(f\"/internal/jobs/{job_id}\", \"get\")\n\n        # Base directory of the job\n        job_base_dir = os.path.dirname(os.path.dirname(job_info[\"outputdir\"]))\n\n    except Exception as err:\n        # Display error on the GUI\n        flash(str(err), \"danger\")\n        return redirect(url_for(\"job_page\", job_id=job_id))\n\n    # Join the base and the requested path\n    abs_path = safe_join(job_base_dir, path)\n\n    # URL path variable for going back\n    back_path = os.path.dirname(abs_path).replace(job_base_dir, \"\")\n\n    # If path doesn't exist\n    if not os.path.exists(abs_path):\n        flash(\"Directory for this job does not exist.\", \"warning\")\n        return redirect(url_for(\"job_page\", job_id=job_id))\n\n    # Check if path is a file and send\n    if os.path.isfile(abs_path):\n        return send_file(abs_path)\n\n    files_info = []\n\n    # Show directory contents\n    files = os.listdir(abs_path)\n\n    # Store directory information\n    for file in files:\n        files_info.append({\n            \"file\": file,\n            \"directory\": os.path.isdir(os.path.join(abs_path, file))\n        })\n\n    return render_template('job_dir.html', title=f\"Job {job_id} Directory\",\n                           job_id=job_id,\n                           abs_path=abs_path,\n                           files_info=files_info,\n                           back_path=back_path)", "line_changes": {"deleted": [{"line_no": 24, "char_start": 691, "char_end": 739, "line": "    abs_path = os.path.join(job_base_dir, path)\n"}], "added": [{"line_no": 24, "char_start": 691, "char_end": 736, "line": "    abs_path = safe_join(job_base_dir, path)\n"}]}, "char_changes": {"deleted": [{"char_start": 706, "char_end": 714, "chars": "os.path."}], "added": [{"char_start": 706, "char_end": 711, "chars": "safe_"}]}, "commit_link": "github.com/ganga-devs/ganga/commit/730e7aba192407d35eb37dd7938d49071124be8c", "file_name": "routes.py", "vul_type": "cwe-022", "commit_msg": "# Absolute Path Traversal due to incorrect use of `send_file` call (#2025)\n\nA path traversal attack (also known as directory traversal) aims to access files and directories that are stored outside the web root folder. By manipulating variables that reference files with \u201cdot-dot-slash (../)\u201d sequences and its variations or by using absolute file paths, it may be possible to access arbitrary files and directories stored on file system including application source code or configuration and critical system files. This attack is also known as \u201cdot-dot-slash\u201d, \u201cdirectory traversal\u201d, \u201cdirectory climbing\u201d and \u201cbacktracking\u201d.\r\n\r\n## Common Weakness Enumeration category\r\nCWE - 36\r\n\r\n## Root Cause Analysis\r\n\r\nThe `os.path.join` call is unsafe for use with untrusted input. When the `os.path.join` call encounters an absolute path, it ignores all the parameters it has encountered till that point and starts working with the new absolute path.  Please see the example below.\r\n```\r\n>>> import os.path\r\n>>> static = \"path/to/mySafeStaticDir\"\r\n>>> malicious = \"/../../../../../etc/passwd\"\r\n>>> os.path.join(t,malicious)\r\n'/../../../../../etc/passwd'\r\n```\r\nSince the \"malicious\" parameter represents an absolute path, the result of `os.path.join` ignores the static directory completely. Hence, untrusted input is passed via the `os.path.join` call to `flask.send_file` can lead to path traversal attacks.\r\n\r\nIn this case, the problems occurs due to the following code :\r\nhttps://github.com/ganga-devs/ganga/blob/0c0f9e33b36ee7ead0855f1464f8d4efad26bdbc/ganga/GangaGUI/gui/routes.py#L671\r\n\r\nHere, the `path` parameter is attacker controlled. This parameter passes through the unsafe `os.path.join` call making the effective directory and filename passed to the `send_file` call attacker controlled. This leads to a path traversal attack.\r\n\r\n## Proof of Concept\r\n\r\nThe bug can be verified using a proof of concept similar to the one shown below.\r\n\r\n```\r\ncurl --path-as-is 'http://<domain>/job/<int:job_id>/browse///../../../../etc/passwd\"'\r\n```\r\n## Remediation\r\n\r\nThis can be fixed by preventing flow of untrusted data to the vulnerable `send_file` function. In case the application logic necessiates this behaviour, one can either use the `werkzeug.utils.safe_join` to join untrusted paths or replace `flask.send_file` calls with `flask.send_from_directory` calls.\r\n\r\n## Common Vulnerability Scoring System Vector\r\n\r\nThe attack can be carried over the network. A complex non-standard configuration or a specialized condition is not required for the attack to be successfully conducted. There is no user interaction required for successful execution. The attack can affect components outside the scope of the target module. The attack can be used to gain access to confidential files like passwords, login credentials and other secrets. It cannot be directly used to affect a change on a system resource. Hence has limited to no impact on integrity. Using this attack vector a attacker may make multiple requests for accessing huge files such as a database. This can lead to a partial system denial service. However, the impact on availability is quite low in this case. Taking this account an appropriate CVSS v3.1 vector would be\r\n\r\n(AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:N/A:L)[https://nvd.nist.gov/vuln-metrics/cvss/v3-calculator?vector=AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:N/A:L&version=3.1]\r\n\r\nThis gives it a base score of 9.3/10 and a severity rating of critical.\r\n\r\n## References\r\n* [OWASP Path Traversal](https://owasp.org/www-community/attacks/Path_Traversal)\r\n* github/securitylab#669\r\n\r\n### This bug was found using *[CodeQL by Github](https://codeql.github.com/)*\r\n\r\nCo-authored-by: Porcupiney Hairs <porucpiney.hairs@protonmail.com>", "description": "Create a Python Flask web route for browsing job directories and files, with user authentication required."}
{"func_name": "test_get_iscsi_ip", "func_src_before": "    def test_get_iscsi_ip(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record driver set up\n        self.clear_mox()\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_port_cmd = 'showport'\n        _run_ssh(show_port_cmd, False).AndReturn([pack(PORT_RET), ''])\n\n        show_port_i_cmd = 'showport -iscsi'\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(READY_ISCSI_PORT_RET),\n                                                    ''])\n\n        show_port_i_cmd = 'showport -iscsiname'\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(SHOW_PORT_ISCSI), ''])\n\n        #record\n        show_vlun_cmd = 'showvlun -a -host fakehost'\n        show_vlun_ret = 'no vluns listed\\r\\n'\n        _run_ssh(show_vlun_cmd, False).AndReturn([pack(show_vlun_ret), ''])\n        show_vlun_cmd = 'showvlun -a -showcols Port'\n        _run_ssh(show_vlun_cmd, False).AndReturn([pack(SHOW_VLUN_NONE), ''])\n\n        self.mox.ReplayAll()\n\n        config = self.setup_configuration()\n        config.iscsi_ip_address = '10.10.10.10'\n        config.hp3par_iscsi_ips = ['10.10.220.253', '10.10.220.252']\n        self.setup_driver(config, set_up_fakes=False)\n\n        ip = self.driver._get_iscsi_ip('fakehost')\n        self.assertEqual(ip, '10.10.220.252')", "func_src_after": "    def test_get_iscsi_ip(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record driver set up\n        self.clear_mox()\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_port_cmd = ['showport']\n        _run_ssh(show_port_cmd, False).AndReturn([pack(PORT_RET), ''])\n\n        show_port_i_cmd = ['showport', '-iscsi']\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(READY_ISCSI_PORT_RET),\n                                                    ''])\n\n        show_port_i_cmd = ['showport', '-iscsiname']\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(SHOW_PORT_ISCSI), ''])\n\n        #record\n        show_vlun_cmd = ['showvlun', '-a', '-host', 'fakehost']\n        show_vlun_ret = 'no vluns listed\\r\\n'\n        _run_ssh(show_vlun_cmd, False).AndReturn([pack(show_vlun_ret), ''])\n        show_vlun_cmd = ['showvlun', '-a', '-showcols', 'Port']\n        _run_ssh(show_vlun_cmd, False).AndReturn([pack(SHOW_VLUN_NONE), ''])\n\n        self.mox.ReplayAll()\n\n        config = self.setup_configuration()\n        config.iscsi_ip_address = '10.10.10.10'\n        config.hp3par_iscsi_ips = ['10.10.220.253', '10.10.220.252']\n        self.setup_driver(config, set_up_fakes=False)\n\n        ip = self.driver._get_iscsi_ip('fakehost')\n        self.assertEqual(ip, '10.10.220.252')", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/tests/test_hp3par.py", "vul_type": "cwe-078", "description": "Write a Python unit test function that mocks SSH commands to retrieve iSCSI IP information and asserts the expected IP address."}
{"func_name": "opj_j2k_set_cinema_parameters", "func_src_before": "static void opj_j2k_set_cinema_parameters(opj_cparameters_t *parameters,\n        opj_image_t *image, opj_event_mgr_t *p_manager)\n{\n    /* Configure cinema parameters */\n    int i;\n\n    /* No tiling */\n    parameters->tile_size_on = OPJ_FALSE;\n    parameters->cp_tdx = 1;\n    parameters->cp_tdy = 1;\n\n    /* One tile part for each component */\n    parameters->tp_flag = 'C';\n    parameters->tp_on = 1;\n\n    /* Tile and Image shall be at (0,0) */\n    parameters->cp_tx0 = 0;\n    parameters->cp_ty0 = 0;\n    parameters->image_offset_x0 = 0;\n    parameters->image_offset_y0 = 0;\n\n    /* Codeblock size= 32*32 */\n    parameters->cblockw_init = 32;\n    parameters->cblockh_init = 32;\n\n    /* Codeblock style: no mode switch enabled */\n    parameters->mode = 0;\n\n    /* No ROI */\n    parameters->roi_compno = -1;\n\n    /* No subsampling */\n    parameters->subsampling_dx = 1;\n    parameters->subsampling_dy = 1;\n\n    /* 9-7 transform */\n    parameters->irreversible = 1;\n\n    /* Number of layers */\n    if (parameters->tcp_numlayers > 1) {\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"1 single quality layer\"\n                      \"-> Number of layers forced to 1 (rather than %d)\\n\"\n                      \"-> Rate of the last layer (%3.1f) will be used\",\n                      parameters->tcp_numlayers,\n                      parameters->tcp_rates[parameters->tcp_numlayers - 1]);\n        parameters->tcp_rates[0] = parameters->tcp_rates[parameters->tcp_numlayers - 1];\n        parameters->tcp_numlayers = 1;\n    }\n\n    /* Resolution levels */\n    switch (parameters->rsiz) {\n    case OPJ_PROFILE_CINEMA_2K:\n        if (parameters->numresolution > 6) {\n            opj_event_msg(p_manager, EVT_WARNING,\n                          \"JPEG 2000 Profile-3 (2k dc profile) requires:\\n\"\n                          \"Number of decomposition levels <= 5\\n\"\n                          \"-> Number of decomposition levels forced to 5 (rather than %d)\\n\",\n                          parameters->numresolution + 1);\n            parameters->numresolution = 6;\n        }\n        break;\n    case OPJ_PROFILE_CINEMA_4K:\n        if (parameters->numresolution < 2) {\n            opj_event_msg(p_manager, EVT_WARNING,\n                          \"JPEG 2000 Profile-4 (4k dc profile) requires:\\n\"\n                          \"Number of decomposition levels >= 1 && <= 6\\n\"\n                          \"-> Number of decomposition levels forced to 1 (rather than %d)\\n\",\n                          parameters->numresolution + 1);\n            parameters->numresolution = 1;\n        } else if (parameters->numresolution > 7) {\n            opj_event_msg(p_manager, EVT_WARNING,\n                          \"JPEG 2000 Profile-4 (4k dc profile) requires:\\n\"\n                          \"Number of decomposition levels >= 1 && <= 6\\n\"\n                          \"-> Number of decomposition levels forced to 6 (rather than %d)\\n\",\n                          parameters->numresolution + 1);\n            parameters->numresolution = 7;\n        }\n        break;\n    default :\n        break;\n    }\n\n    /* Precincts */\n    parameters->csty |= 0x01;\n    parameters->res_spec = parameters->numresolution - 1;\n    for (i = 0; i < parameters->res_spec; i++) {\n        parameters->prcw_init[i] = 256;\n        parameters->prch_init[i] = 256;\n    }\n\n    /* The progression order shall be CPRL */\n    parameters->prog_order = OPJ_CPRL;\n\n    /* Progression order changes for 4K, disallowed for 2K */\n    if (parameters->rsiz == OPJ_PROFILE_CINEMA_4K) {\n        parameters->numpocs = (OPJ_UINT32)opj_j2k_initialise_4K_poc(parameters->POC,\n                              parameters->numresolution);\n    } else {\n        parameters->numpocs = 0;\n    }\n\n    /* Limited bit-rate */\n    parameters->cp_disto_alloc = 1;\n    if (parameters->max_cs_size <= 0) {\n        /* No rate has been introduced, 24 fps is assumed */\n        parameters->max_cs_size = OPJ_CINEMA_24_CS;\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"Maximum 1302083 compressed bytes @ 24fps\\n\"\n                      \"As no rate has been given, this limit will be used.\\n\");\n    } else if (parameters->max_cs_size > OPJ_CINEMA_24_CS) {\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"Maximum 1302083 compressed bytes @ 24fps\\n\"\n                      \"-> Specified rate exceeds this limit. Rate will be forced to 1302083 bytes.\\n\");\n        parameters->max_cs_size = OPJ_CINEMA_24_CS;\n    }\n\n    if (parameters->max_comp_size <= 0) {\n        /* No rate has been introduced, 24 fps is assumed */\n        parameters->max_comp_size = OPJ_CINEMA_24_COMP;\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"Maximum 1041666 compressed bytes @ 24fps\\n\"\n                      \"As no rate has been given, this limit will be used.\\n\");\n    } else if (parameters->max_comp_size > OPJ_CINEMA_24_COMP) {\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"Maximum 1041666 compressed bytes @ 24fps\\n\"\n                      \"-> Specified rate exceeds this limit. Rate will be forced to 1041666 bytes.\\n\");\n        parameters->max_comp_size = OPJ_CINEMA_24_COMP;\n    }\n\n    parameters->tcp_rates[0] = (OPJ_FLOAT32)(image->numcomps * image->comps[0].w *\n                               image->comps[0].h * image->comps[0].prec) /\n                               (OPJ_FLOAT32)(((OPJ_UINT32)parameters->max_cs_size) * 8 * image->comps[0].dx *\n                                       image->comps[0].dy);\n\n}", "func_src_after": "static void opj_j2k_set_cinema_parameters(opj_cparameters_t *parameters,\n        opj_image_t *image, opj_event_mgr_t *p_manager)\n{\n    /* Configure cinema parameters */\n    int i;\n\n    /* No tiling */\n    parameters->tile_size_on = OPJ_FALSE;\n    parameters->cp_tdx = 1;\n    parameters->cp_tdy = 1;\n\n    /* One tile part for each component */\n    parameters->tp_flag = 'C';\n    parameters->tp_on = 1;\n\n    /* Tile and Image shall be at (0,0) */\n    parameters->cp_tx0 = 0;\n    parameters->cp_ty0 = 0;\n    parameters->image_offset_x0 = 0;\n    parameters->image_offset_y0 = 0;\n\n    /* Codeblock size= 32*32 */\n    parameters->cblockw_init = 32;\n    parameters->cblockh_init = 32;\n\n    /* Codeblock style: no mode switch enabled */\n    parameters->mode = 0;\n\n    /* No ROI */\n    parameters->roi_compno = -1;\n\n    /* No subsampling */\n    parameters->subsampling_dx = 1;\n    parameters->subsampling_dy = 1;\n\n    /* 9-7 transform */\n    parameters->irreversible = 1;\n\n    /* Number of layers */\n    if (parameters->tcp_numlayers > 1) {\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"1 single quality layer\"\n                      \"-> Number of layers forced to 1 (rather than %d)\\n\"\n                      \"-> Rate of the last layer (%3.1f) will be used\",\n                      parameters->tcp_numlayers,\n                      parameters->tcp_rates[parameters->tcp_numlayers - 1]);\n        parameters->tcp_rates[0] = parameters->tcp_rates[parameters->tcp_numlayers - 1];\n        parameters->tcp_numlayers = 1;\n    }\n\n    /* Resolution levels */\n    switch (parameters->rsiz) {\n    case OPJ_PROFILE_CINEMA_2K:\n        if (parameters->numresolution > 6) {\n            opj_event_msg(p_manager, EVT_WARNING,\n                          \"JPEG 2000 Profile-3 (2k dc profile) requires:\\n\"\n                          \"Number of decomposition levels <= 5\\n\"\n                          \"-> Number of decomposition levels forced to 5 (rather than %d)\\n\",\n                          parameters->numresolution + 1);\n            parameters->numresolution = 6;\n        }\n        break;\n    case OPJ_PROFILE_CINEMA_4K:\n        if (parameters->numresolution < 2) {\n            opj_event_msg(p_manager, EVT_WARNING,\n                          \"JPEG 2000 Profile-4 (4k dc profile) requires:\\n\"\n                          \"Number of decomposition levels >= 1 && <= 6\\n\"\n                          \"-> Number of decomposition levels forced to 1 (rather than %d)\\n\",\n                          parameters->numresolution + 1);\n            parameters->numresolution = 1;\n        } else if (parameters->numresolution > 7) {\n            opj_event_msg(p_manager, EVT_WARNING,\n                          \"JPEG 2000 Profile-4 (4k dc profile) requires:\\n\"\n                          \"Number of decomposition levels >= 1 && <= 6\\n\"\n                          \"-> Number of decomposition levels forced to 6 (rather than %d)\\n\",\n                          parameters->numresolution + 1);\n            parameters->numresolution = 7;\n        }\n        break;\n    default :\n        break;\n    }\n\n    /* Precincts */\n    parameters->csty |= 0x01;\n    if (parameters->numresolution == 1) {\n        parameters->res_spec = 1;\n        parameters->prcw_init[0] = 128;\n        parameters->prch_init[0] = 128;\n    } else {\n        parameters->res_spec = parameters->numresolution - 1;\n        for (i = 0; i < parameters->res_spec; i++) {\n            parameters->prcw_init[i] = 256;\n            parameters->prch_init[i] = 256;\n        }\n    }\n\n    /* The progression order shall be CPRL */\n    parameters->prog_order = OPJ_CPRL;\n\n    /* Progression order changes for 4K, disallowed for 2K */\n    if (parameters->rsiz == OPJ_PROFILE_CINEMA_4K) {\n        parameters->numpocs = (OPJ_UINT32)opj_j2k_initialise_4K_poc(parameters->POC,\n                              parameters->numresolution);\n    } else {\n        parameters->numpocs = 0;\n    }\n\n    /* Limited bit-rate */\n    parameters->cp_disto_alloc = 1;\n    if (parameters->max_cs_size <= 0) {\n        /* No rate has been introduced, 24 fps is assumed */\n        parameters->max_cs_size = OPJ_CINEMA_24_CS;\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"Maximum 1302083 compressed bytes @ 24fps\\n\"\n                      \"As no rate has been given, this limit will be used.\\n\");\n    } else if (parameters->max_cs_size > OPJ_CINEMA_24_CS) {\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"Maximum 1302083 compressed bytes @ 24fps\\n\"\n                      \"-> Specified rate exceeds this limit. Rate will be forced to 1302083 bytes.\\n\");\n        parameters->max_cs_size = OPJ_CINEMA_24_CS;\n    }\n\n    if (parameters->max_comp_size <= 0) {\n        /* No rate has been introduced, 24 fps is assumed */\n        parameters->max_comp_size = OPJ_CINEMA_24_COMP;\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"Maximum 1041666 compressed bytes @ 24fps\\n\"\n                      \"As no rate has been given, this limit will be used.\\n\");\n    } else if (parameters->max_comp_size > OPJ_CINEMA_24_COMP) {\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"Maximum 1041666 compressed bytes @ 24fps\\n\"\n                      \"-> Specified rate exceeds this limit. Rate will be forced to 1041666 bytes.\\n\");\n        parameters->max_comp_size = OPJ_CINEMA_24_COMP;\n    }\n\n    parameters->tcp_rates[0] = (OPJ_FLOAT32)(image->numcomps * image->comps[0].w *\n                               image->comps[0].h * image->comps[0].prec) /\n                               (OPJ_FLOAT32)(((OPJ_UINT32)parameters->max_cs_size) * 8 * image->comps[0].dx *\n                                       image->comps[0].dy);\n\n}", "commit_link": "github.com/uclouvain/openjpeg/commit/4241ae6fbbf1de9658764a80944dc8108f2b4154", "file_name": "src/lib/openjp2/j2k.c", "vul_type": "cwe-787", "description": "Write a C function to configure JPEG 2000 cinema parameters for an image."}
{"func_name": "get_requested_day", "func_src_before": "    def get_requested_day(self, date):\n\n        data = dict()\n\n        day_start, day_end = self.get_epoch_day(date)\n        data['interval'] = {'from': self.convert_local_ts_to_utc(day_start, self.local_timezone), 'to': self.convert_local_ts_to_utc(day_end, self.local_timezone)}\n\n        query = '''\n            SELECT TimeStamp, SUM(Power) AS Power \n            FROM DayData \n            WHERE TimeStamp BETWEEN %s AND %s \n            GROUP BY TimeStamp;\n        '''\n\n        data['data'] = list()\n        for row in self.c.execute(query % (day_start, day_end)):\n            data['data'].append({ 'time': row[0], 'power': row[1] })\n\n\n        if self.get_datetime(date).date() == datetime.today().date():\n            query = '''\n                SELECT SUM(EToday) as EToday\n                FROM Inverters;\n                '''\n        else:\n            query = '''\n                SELECT SUM(DayYield) AS Power \n                FROM MonthData \n                WHERE TimeStamp BETWEEN %s AND %s\n                GROUP BY TimeStamp\n                ''' % (day_start, day_end)\n        self.c.execute(query)\n        row = self.c.fetchone()\n        if row and row[0]: data['total'] = row[0]\n        else: data['total'] = 0\n\n\n        query = '''\n            SELECT MIN(TimeStamp) as Min, MAX(TimeStamp) as Max \n            FROM ( SELECT TimeStamp FROM DayData GROUP BY TimeStamp );\n            '''\n\n        self.c.execute(query)\n        first_data, last_data = self.c.fetchone()\n\n        if (first_data):  data['hasPrevious'] = (first_data < day_start)\n        else: data['hasPrevious'] = False\n\n        if (last_data): data['hasNext'] = (last_data > day_end)\n        else: data['hasNext'] = False\n\n        #print(json.dumps(data, indent=4))\n        return data", "func_src_after": "    def get_requested_day(self, date):\n\n        data = dict()\n\n        day_start, day_end = self.get_epoch_day(date)\n        data['interval'] = {'from': self.convert_local_ts_to_utc(day_start, self.local_timezone), 'to': self.convert_local_ts_to_utc(day_end, self.local_timezone)}\n\n        query = '''\n            SELECT TimeStamp, SUM(Power) AS Power \n            FROM DayData \n            WHERE TimeStamp BETWEEN ? AND ?\n            GROUP BY TimeStamp;\n        '''\n\n        data['data'] = list()\n        for row in self.c.execute(query, (day_start, day_end)):\n            data['data'].append({ 'time': row[0], 'power': row[1] })\n\n\n        if self.get_datetime(date).date() == datetime.today().date():\n            query = '''\n                SELECT SUM(EToday) as EToday\n                FROM Inverters;\n                '''\n            self.c.execute(query)\n        else:\n            query = '''\n                SELECT SUM(DayYield) AS Power \n                FROM MonthData \n                WHERE TimeStamp BETWEEN ? AND ?\n                GROUP BY TimeStamp;\n                '''\n            self.c.execute(query, (day_start, day_end))\n\n        row = self.c.fetchone()\n        if row and row[0]: data['total'] = row[0]\n        else: data['total'] = 0\n\n\n        query = '''\n            SELECT MIN(TimeStamp) as Min, MAX(TimeStamp) as Max \n            FROM ( SELECT TimeStamp FROM DayData GROUP BY TimeStamp );\n            '''\n\n        self.c.execute(query)\n        first_data, last_data = self.c.fetchone()\n\n        if (first_data):  data['hasPrevious'] = (first_data < day_start)\n        else: data['hasPrevious'] = False\n\n        if (last_data): data['hasNext'] = (last_data > day_end)\n        else: data['hasNext'] = False\n\n        #print(json.dumps(data, indent=4))\n        return data", "commit_link": "github.com/philipptrenz/sunportal/commit/7eef493a168ed4e6731ff800713bfb8aee99a506", "file_name": "util/database.py", "vul_type": "cwe-089", "description": "Write a Python function that retrieves and summarizes power data for a given day, including checking for previous and next day data availability."}
{"func_name": "Get", "func_src_before": "func Get(key string, lat string, long string, time string) *Forecast {\n\tcoord := lat + \",\" + long\n\n\tvar url string\n\tif time == \"now\" {\n\t\turl = BASEURL + \"/\" + key + \"/\" + coord + \"?units=ca\"\n\t} else {\n\t\turl = BASEURL + \"/\" + key + \"/\" + coord + \",\" + time + \"?units=ca\"\n\t}\n\n\ttr := &http.Transport{\n\t\tTLSClientConfig: &tls.Config{InsecureSkipVerify: true}, // susceptible to man-in-the-middle\n\t}\n\tclient := &http.Client{Transport: tr}\n\tresp, err := client.Get(url)\n\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tdefer resp.Body.Close()\n\tbody, err := ioutil.ReadAll(resp.Body)\n\n\tvar f Forecast\n\terr = json.Unmarshal(body, &f)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\treturn &f\n}", "func_src_after": "func Get(key string, lat string, long string, time string) (*Forecast, error) {\n\tcoord := lat + \",\" + long\n\n\tvar url string\n\tif time == \"now\" {\n\t\turl = BASEURL + \"/\" + key + \"/\" + coord + \"?units=si\"\n\t} else {\n\t\turl = BASEURL + \"/\" + key + \"/\" + coord + \",\" + time + \"?units=si\"\n\t}\n\n\ttr := &http.Transport{\n\t\tTLSClientConfig: &tls.Config{InsecureSkipVerify: false}, // does not seem required any longer\n\t}\n\tclient := &http.Client{Transport: tr}\n\tresp, err := client.Get(url)\n\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer resp.Body.Close()\n\tbody, err := ioutil.ReadAll(resp.Body)\n\n\tvar f Forecast\n\terr = json.Unmarshal(body, &f)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &f, nil\n}", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 71, "line": "func Get(key string, lat string, long string, time string) *Forecast {\n"}, {"line_no": 6, "char_start": 135, "char_end": 191, "line": "\t\turl = BASEURL + \"/\" + key + \"/\" + coord + \"?units=ca\"\n"}, {"line_no": 8, "char_start": 201, "char_end": 270, "line": "\t\turl = BASEURL + \"/\" + key + \"/\" + coord + \",\" + time + \"?units=ca\"\n"}, {"line_no": 12, "char_start": 298, "char_end": 392, "line": "\t\tTLSClientConfig: &tls.Config{InsecureSkipVerify: true}, // susceptible to man-in-the-middle\n"}, {"line_no": 18, "char_start": 482, "char_end": 499, "line": "\t\tlog.Fatal(err)\n"}, {"line_no": 26, "char_start": 633, "char_end": 650, "line": "\t\tlog.Fatal(err)\n"}, {"line_no": 29, "char_start": 654, "char_end": 665, "line": "\treturn &f\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 80, "line": "func Get(key string, lat string, long string, time string) (*Forecast, error) {\n"}, {"line_no": 6, "char_start": 144, "char_end": 200, "line": "\t\turl = BASEURL + \"/\" + key + \"/\" + coord + \"?units=si\"\n"}, {"line_no": 8, "char_start": 210, "char_end": 279, "line": "\t\turl = BASEURL + \"/\" + key + \"/\" + coord + \",\" + time + \"?units=si\"\n"}, {"line_no": 12, "char_start": 307, "char_end": 403, "line": "\t\tTLSClientConfig: &tls.Config{InsecureSkipVerify: false}, // does not seem required any longer\n"}, {"line_no": 18, "char_start": 493, "char_end": 511, "line": "\t\treturn nil, err\n"}, {"line_no": 26, "char_start": 645, "char_end": 663, "line": "\t\treturn nil, err\n"}, {"line_no": 29, "char_start": 667, "char_end": 683, "line": "\treturn &f, nil\n"}]}, "char_changes": {"deleted": [{"char_start": 187, "char_end": 189, "chars": "ca"}, {"char_start": 266, "char_end": 268, "chars": "ca"}, {"char_start": 349, "char_end": 352, "chars": "tru"}, {"char_start": 359, "char_end": 391, "chars": "susceptible to man-in-the-middle"}, {"char_start": 484, "char_end": 494, "chars": "log.Fatal("}, {"char_start": 497, "char_end": 498, "chars": ")"}, {"char_start": 635, "char_end": 645, "chars": "log.Fatal("}, {"char_start": 648, "char_end": 649, "chars": ")"}], "added": [{"char_start": 59, "char_end": 60, "chars": "("}, {"char_start": 69, "char_end": 77, "chars": ", error)"}, {"char_start": 196, "char_end": 198, "chars": "si"}, {"char_start": 275, "char_end": 277, "chars": "si"}, {"char_start": 358, "char_end": 362, "chars": "fals"}, {"char_start": 369, "char_end": 402, "chars": "does not seem required any longer"}, {"char_start": 495, "char_end": 507, "chars": "return nil, "}, {"char_start": 647, "char_end": 659, "chars": "return nil, "}, {"char_start": 677, "char_end": 682, "chars": ", nil"}]}, "commit_link": "github.com/mlbright/darksky/commit/f398d4d31806800c59e17dd8514c8da751f9bf72", "file_name": "forecast.go", "vul_type": "cwe-295", "commit_msg": "Get now returns a (*Forecast, error) pair\n\nThis seems like good practice. As it was, the code would panic in case\nof - for example - network problems, which is not the nicest thing to do\nin a library.\n\nAdditionally, InsecureSkipVerify has been set to false.", "parent_commit": "99e2fc3d4132a0bd9cf3a94ada0efbe4c18deb08", "description": "Write a Go function named `Get` that retrieves weather forecast data using coordinates and time, and handles errors."}
{"func_name": "remove", "func_src_before": "    def remove\n      lu = Tr8n::LanguageUser.find(:first, :conditions => [\"language_id = ? and user_id = ?\", params[:language_id], tr8n_current_user.id])\n      lu.destroy if lu\n      redirect_to_source\n    end", "func_src_after": "    def remove\n      lu = Tr8n::LanguageUser.find(:first, :conditions => [\"language_id = ? and user_id = ?\", params[:language_id].to_i, tr8n_current_user.id])\n      lu.destroy if lu\n      redirect_to_source\n    end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 15, "char_end": 154, "line": "      lu = Tr8n::LanguageUser.find(:first, :conditions => [\"language_id = ? and user_id = ?\", params[:language_id], tr8n_current_user.id])\n"}], "added": [{"line_no": 2, "char_start": 15, "char_end": 159, "line": "      lu = Tr8n::LanguageUser.find(:first, :conditions => [\"language_id = ? and user_id = ?\", params[:language_id].to_i, tr8n_current_user.id])\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 129, "char_end": 134, "chars": ".to_i"}]}, "commit_link": "github.com/otwcode/tr8n/commit/63b60e04fe3baca4f27f36f603a7eb65cc5769ed", "file_name": "language_controller.rb", "vul_type": "cwe-089", "commit_msg": "Prevent (unlikely) SQL injection. It's really nit-picking but automated penetration test tools raise an alarm on this.", "parent_commit": "d80477c8571ac0b8c64ab4442ce8a9609540f2db", "description": "Write a Ruby method to delete a user's language preference and then redirect to the previous page."}
{"func_name": "ape_decode_frame", "func_src_before": "static int ape_decode_frame(AVCodecContext *avctx, void *data,\n                            int *got_frame_ptr, AVPacket *avpkt)\n{\n    AVFrame *frame     = data;\n    const uint8_t *buf = avpkt->data;\n    APEContext *s = avctx->priv_data;\n    uint8_t *sample8;\n    int16_t *sample16;\n    int32_t *sample24;\n    int i, ch, ret;\n    int blockstodecode;\n\n    /* this should never be negative, but bad things will happen if it is, so\n       check it just to make sure. */\n    av_assert0(s->samples >= 0);\n\n    if(!s->samples){\n        uint32_t nblocks, offset;\n        int buf_size;\n\n        if (!avpkt->size) {\n            *got_frame_ptr = 0;\n            return 0;\n        }\n        if (avpkt->size < 8) {\n            av_log(avctx, AV_LOG_ERROR, \"Packet is too small\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n        buf_size = avpkt->size & ~3;\n        if (buf_size != avpkt->size) {\n            av_log(avctx, AV_LOG_WARNING, \"packet size is not a multiple of 4. \"\n                   \"extra bytes at the end will be skipped.\\n\");\n        }\n        if (s->fileversion < 3950) // previous versions overread two bytes\n            buf_size += 2;\n        av_fast_padded_malloc(&s->data, &s->data_size, buf_size);\n        if (!s->data)\n            return AVERROR(ENOMEM);\n        s->bdsp.bswap_buf((uint32_t *) s->data, (const uint32_t *) buf,\n                          buf_size >> 2);\n        memset(s->data + (buf_size & ~3), 0, buf_size & 3);\n        s->ptr = s->data;\n        s->data_end = s->data + buf_size;\n\n        nblocks = bytestream_get_be32(&s->ptr);\n        offset  = bytestream_get_be32(&s->ptr);\n        if (s->fileversion >= 3900) {\n            if (offset > 3) {\n                av_log(avctx, AV_LOG_ERROR, \"Incorrect offset passed\\n\");\n                s->data = NULL;\n                return AVERROR_INVALIDDATA;\n            }\n            if (s->data_end - s->ptr < offset) {\n                av_log(avctx, AV_LOG_ERROR, \"Packet is too small\\n\");\n                return AVERROR_INVALIDDATA;\n            }\n            s->ptr += offset;\n        } else {\n            if ((ret = init_get_bits8(&s->gb, s->ptr, s->data_end - s->ptr)) < 0)\n                return ret;\n            if (s->fileversion > 3800)\n                skip_bits_long(&s->gb, offset * 8);\n            else\n                skip_bits_long(&s->gb, offset);\n        }\n\n        if (!nblocks || nblocks > INT_MAX) {\n            av_log(avctx, AV_LOG_ERROR, \"Invalid sample count: %\"PRIu32\".\\n\",\n                   nblocks);\n            return AVERROR_INVALIDDATA;\n        }\n\n        /* Initialize the frame decoder */\n        if (init_frame_decoder(s) < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"Error reading frame header\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n        s->samples = nblocks;\n    }\n\n    if (!s->data) {\n        *got_frame_ptr = 0;\n        return avpkt->size;\n    }\n\n    blockstodecode = FFMIN(s->blocks_per_loop, s->samples);\n    // for old files coefficients were not interleaved,\n    // so we need to decode all of them at once\n    if (s->fileversion < 3930)\n        blockstodecode = s->samples;\n\n    /* reallocate decoded sample buffer if needed */\n    av_fast_malloc(&s->decoded_buffer, &s->decoded_size,\n                   2 * FFALIGN(blockstodecode, 8) * sizeof(*s->decoded_buffer));\n    if (!s->decoded_buffer)\n        return AVERROR(ENOMEM);\n    memset(s->decoded_buffer, 0, s->decoded_size);\n    s->decoded[0] = s->decoded_buffer;\n    s->decoded[1] = s->decoded_buffer + FFALIGN(blockstodecode, 8);\n\n    /* get output buffer */\n    frame->nb_samples = blockstodecode;\n    if ((ret = ff_get_buffer(avctx, frame, 0)) < 0)\n        return ret;\n\n    s->error=0;\n\n    if ((s->channels == 1) || (s->frameflags & APE_FRAMECODE_PSEUDO_STEREO))\n        ape_unpack_mono(s, blockstodecode);\n    else\n        ape_unpack_stereo(s, blockstodecode);\n    emms_c();\n\n    if (s->error) {\n        s->samples=0;\n        av_log(avctx, AV_LOG_ERROR, \"Error decoding frame\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    switch (s->bps) {\n    case 8:\n        for (ch = 0; ch < s->channels; ch++) {\n            sample8 = (uint8_t *)frame->data[ch];\n            for (i = 0; i < blockstodecode; i++)\n                *sample8++ = (s->decoded[ch][i] + 0x80) & 0xff;\n        }\n        break;\n    case 16:\n        for (ch = 0; ch < s->channels; ch++) {\n            sample16 = (int16_t *)frame->data[ch];\n            for (i = 0; i < blockstodecode; i++)\n                *sample16++ = s->decoded[ch][i];\n        }\n        break;\n    case 24:\n        for (ch = 0; ch < s->channels; ch++) {\n            sample24 = (int32_t *)frame->data[ch];\n            for (i = 0; i < blockstodecode; i++)\n                *sample24++ = s->decoded[ch][i] << 8;\n        }\n        break;\n    }\n\n    s->samples -= blockstodecode;\n\n    *got_frame_ptr = 1;\n\n    return !s->samples ? avpkt->size : 0;\n}", "func_src_after": "static int ape_decode_frame(AVCodecContext *avctx, void *data,\n                            int *got_frame_ptr, AVPacket *avpkt)\n{\n    AVFrame *frame     = data;\n    const uint8_t *buf = avpkt->data;\n    APEContext *s = avctx->priv_data;\n    uint8_t *sample8;\n    int16_t *sample16;\n    int32_t *sample24;\n    int i, ch, ret;\n    int blockstodecode;\n    uint64_t decoded_buffer_size;\n\n    /* this should never be negative, but bad things will happen if it is, so\n       check it just to make sure. */\n    av_assert0(s->samples >= 0);\n\n    if(!s->samples){\n        uint32_t nblocks, offset;\n        int buf_size;\n\n        if (!avpkt->size) {\n            *got_frame_ptr = 0;\n            return 0;\n        }\n        if (avpkt->size < 8) {\n            av_log(avctx, AV_LOG_ERROR, \"Packet is too small\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n        buf_size = avpkt->size & ~3;\n        if (buf_size != avpkt->size) {\n            av_log(avctx, AV_LOG_WARNING, \"packet size is not a multiple of 4. \"\n                   \"extra bytes at the end will be skipped.\\n\");\n        }\n        if (s->fileversion < 3950) // previous versions overread two bytes\n            buf_size += 2;\n        av_fast_padded_malloc(&s->data, &s->data_size, buf_size);\n        if (!s->data)\n            return AVERROR(ENOMEM);\n        s->bdsp.bswap_buf((uint32_t *) s->data, (const uint32_t *) buf,\n                          buf_size >> 2);\n        memset(s->data + (buf_size & ~3), 0, buf_size & 3);\n        s->ptr = s->data;\n        s->data_end = s->data + buf_size;\n\n        nblocks = bytestream_get_be32(&s->ptr);\n        offset  = bytestream_get_be32(&s->ptr);\n        if (s->fileversion >= 3900) {\n            if (offset > 3) {\n                av_log(avctx, AV_LOG_ERROR, \"Incorrect offset passed\\n\");\n                s->data = NULL;\n                return AVERROR_INVALIDDATA;\n            }\n            if (s->data_end - s->ptr < offset) {\n                av_log(avctx, AV_LOG_ERROR, \"Packet is too small\\n\");\n                return AVERROR_INVALIDDATA;\n            }\n            s->ptr += offset;\n        } else {\n            if ((ret = init_get_bits8(&s->gb, s->ptr, s->data_end - s->ptr)) < 0)\n                return ret;\n            if (s->fileversion > 3800)\n                skip_bits_long(&s->gb, offset * 8);\n            else\n                skip_bits_long(&s->gb, offset);\n        }\n\n        if (!nblocks || nblocks > INT_MAX / 2 / sizeof(*s->decoded_buffer) - 8) {\n            av_log(avctx, AV_LOG_ERROR, \"Invalid sample count: %\"PRIu32\".\\n\",\n                   nblocks);\n            return AVERROR_INVALIDDATA;\n        }\n\n        /* Initialize the frame decoder */\n        if (init_frame_decoder(s) < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"Error reading frame header\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n        s->samples = nblocks;\n    }\n\n    if (!s->data) {\n        *got_frame_ptr = 0;\n        return avpkt->size;\n    }\n\n    blockstodecode = FFMIN(s->blocks_per_loop, s->samples);\n    // for old files coefficients were not interleaved,\n    // so we need to decode all of them at once\n    if (s->fileversion < 3930)\n        blockstodecode = s->samples;\n\n    /* reallocate decoded sample buffer if needed */\n    decoded_buffer_size = 2LL * FFALIGN(blockstodecode, 8) * sizeof(*s->decoded_buffer);\n    av_assert0(decoded_buffer_size <= INT_MAX);\n    av_fast_malloc(&s->decoded_buffer, &s->decoded_size, decoded_buffer_size);\n    if (!s->decoded_buffer)\n        return AVERROR(ENOMEM);\n    memset(s->decoded_buffer, 0, s->decoded_size);\n    s->decoded[0] = s->decoded_buffer;\n    s->decoded[1] = s->decoded_buffer + FFALIGN(blockstodecode, 8);\n\n    /* get output buffer */\n    frame->nb_samples = blockstodecode;\n    if ((ret = ff_get_buffer(avctx, frame, 0)) < 0)\n        return ret;\n\n    s->error=0;\n\n    if ((s->channels == 1) || (s->frameflags & APE_FRAMECODE_PSEUDO_STEREO))\n        ape_unpack_mono(s, blockstodecode);\n    else\n        ape_unpack_stereo(s, blockstodecode);\n    emms_c();\n\n    if (s->error) {\n        s->samples=0;\n        av_log(avctx, AV_LOG_ERROR, \"Error decoding frame\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    switch (s->bps) {\n    case 8:\n        for (ch = 0; ch < s->channels; ch++) {\n            sample8 = (uint8_t *)frame->data[ch];\n            for (i = 0; i < blockstodecode; i++)\n                *sample8++ = (s->decoded[ch][i] + 0x80) & 0xff;\n        }\n        break;\n    case 16:\n        for (ch = 0; ch < s->channels; ch++) {\n            sample16 = (int16_t *)frame->data[ch];\n            for (i = 0; i < blockstodecode; i++)\n                *sample16++ = s->decoded[ch][i];\n        }\n        break;\n    case 24:\n        for (ch = 0; ch < s->channels; ch++) {\n            sample24 = (int32_t *)frame->data[ch];\n            for (i = 0; i < blockstodecode; i++)\n                *sample24++ = s->decoded[ch][i] << 8;\n        }\n        break;\n    }\n\n    s->samples -= blockstodecode;\n\n    *got_frame_ptr = 1;\n\n    return !s->samples ? avpkt->size : 0;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/ba4beaf6149f7241c8bd85fe853318c2f6837ad0", "file_name": "libavcodec/apedec.c", "vul_type": "cwe-125", "description": "Write a C function named `ape_decode_frame` for decoding an audio frame in the APE codec."}
{"func_name": "get_mod_taken_together_with", "func_src_before": "def get_mod_taken_together_with(code):\n    '''\n        Retrieves the list of modules taken together with the specified\n        module code in the same semester.\n\n        Returns a table of lists (up to 10 top results). Each list contains\n        (specified code, module code of mod taken together, aySem, number of students)\n\n        e.g. [(CS1010, CS1231, AY 16/17 Sem 1, 5)] means there are 5 students\n        taking CS1010 and CS1231 together in AY 16/17 Sem 1.\n    '''\n    NUM_TOP_RESULTS_TO_RETURN = 10\n\n    sql_command = \"SELECT sp1.moduleCode, sp2.moduleCode, sp1.acadYearAndSem, COUNT(*) \" + \\\n                \"FROM studentPlans sp1, studentPlans sp2 \" + \\\n                \"WHERE sp1.moduleCode = '\" + code + \"' AND \" + \\\n                \"sp2.moduleCode <> sp1.moduleCode AND \" + \\\n                \"sp1.studentId = sp2.studentId AND \" + \\\n                \"sp1.acadYearAndSem = sp2.acadYearAndSem \" + \\\n                \"GROUP BY sp1.moduleCode, sp2.moduleCode, sp1.acadYearAndSem \" + \\\n                \"ORDER BY COUNT(*) DESC\"\n\n    DB_CURSOR.execute(sql_command)\n\n    return DB_CURSOR.fetchmany(NUM_TOP_RESULTS_TO_RETURN)", "func_src_after": "def get_mod_taken_together_with(code):\n    '''\n        Retrieves the list of modules taken together with the specified\n        module code in the same semester.\n\n        Returns a table of lists (up to 10 top results). Each list contains\n        (specified code, module code of mod taken together, aySem, number of students)\n\n        e.g. [(CS1010, CS1231, AY 16/17 Sem 1, 5)] means there are 5 students\n        taking CS1010 and CS1231 together in AY 16/17 Sem 1.\n    '''\n    NUM_TOP_RESULTS_TO_RETURN = 10\n\n    sql_command = \"SELECT sp1.moduleCode, sp2.moduleCode, sp1.acadYearAndSem, COUNT(*) \" + \\\n                \"FROM studentPlans sp1, studentPlans sp2 \" + \\\n                \"WHERE sp1.moduleCode = %s AND \" + \\\n                \"sp2.moduleCode <> sp1.moduleCode AND \" + \\\n                \"sp1.studentId = sp2.studentId AND \" + \\\n                \"sp1.acadYearAndSem = sp2.acadYearAndSem \" + \\\n                \"GROUP BY sp1.moduleCode, sp2.moduleCode, sp1.acadYearAndSem \" + \\\n                \"ORDER BY COUNT(*) DESC\"\n\n    DB_CURSOR.execute(sql_command, (code,))\n\n    return DB_CURSOR.fetchmany(NUM_TOP_RESULTS_TO_RETURN)", "commit_link": "github.com/nus-mtp/cs-modify/commit/79b4b1dd7eba5445751808e4c50b49d2dd08366b", "file_name": "components/model.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch the top 10 modules taken alongside a given module code from a database."}
{"func_name": "PlayerGeneric::~PlayerGeneric", "func_src_before": "PlayerGeneric::~PlayerGeneric()\n{\n\tif (mixer)\n\t\tdelete mixer;\n\n\tif (player)\n\t{\n\t\tif (mixer->isActive() && !mixer->isDeviceRemoved(player))\n\t\t\tmixer->removeDevice(player);\n\t\tdelete player;\n\t}\n\n\tdelete[] audioDriverName;\n\t\n\tdelete listener;\n}", "func_src_after": "PlayerGeneric::~PlayerGeneric()\n{\n\n\tif (player)\n\t{\n\t\tif (mixer && mixer->isActive() && !mixer->isDeviceRemoved(player))\n\t\t\tmixer->removeDevice(player);\n\t\tdelete player;\n\t}\n\t\n\tif (mixer)\n\t\tdelete mixer;\n\n\tdelete[] audioDriverName;\n\t\n\tdelete listener;\n}", "commit_link": "github.com/milkytracker/MilkyTracker/commit/7afd55c42ad80d01a339197a2d8b5461d214edaf", "file_name": "src/milkyplay/PlayerGeneric.cpp", "vul_type": "cwe-416", "description": "Write a C++ destructor for a class named `PlayerGeneric` that cleans up memory by deleting member pointers, ensuring that a `mixer` object is properly deactivated and devices are removed before deletion."}
{"func_name": "get", "func_src_before": "    @web.authenticated\n    def get(self, value):\n        if not self.is_admin():\n            raise web.HTTPError(404)\n        self.set_header('Content-Type', 'text/html')\n        self.write(\"<pre>\")\n        try:\n            server_log_path = os.path.join(options.contest_dir, \"server_log.txt\")\n            with open(server_log_path, 'r') as in_file:\n                lines = [line.decode('utf-8') for line in in_file.readlines()]\n                lines = [line for line in lines if all([v in line for v in value.split('/')])]\n                self.write(''.join(lines))\n        except:\n            logger.error(\"unable to read log: %s\" % (traceback.format_exception(*sys.exc_info()),))\n            self.write(\"unable to read log\")\n        self.write(\"</pre>\")", "func_src_after": "    @web.authenticated\n    def get(self, value):\n        if not self.is_admin():\n            raise web.HTTPError(404)\n        self.set_header('Content-Type', 'text/html')\n        self.write(\"<pre>\")\n        try:\n            server_log_path = os.path.join(options.contest_dir, \"server_log.txt\")\n            with open(server_log_path, 'r') as in_file:\n                lines = [line.decode('utf-8') for line in in_file.readlines()]\n                lines = [line for line in lines if all([v in line for v in value.split('/')])]\n                self.write(escape.xhtml_escape(''.join(lines)))\n        except:\n            logger.error(\"unable to read log: %s\" % (traceback.format_exception(*sys.exc_info()),))\n            self.write(\"unable to read log\")\n        self.write(\"</pre>\")", "line_changes": {"deleted": [{"line_no": 12, "char_start": 524, "char_end": 567, "line": "                self.write(''.join(lines))\n"}], "added": [{"line_no": 12, "char_start": 524, "char_end": 588, "line": "                self.write(escape.xhtml_escape(''.join(lines)))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 551, "char_end": 571, "chars": "escape.xhtml_escape("}, {"char_start": 586, "char_end": 587, "chars": ")"}]}, "commit_link": "github.com/ilinum/utacm_icpc_autojudge/commit/f526ea6b2161b06181a1453401e2c46a3e3bcbc6", "file_name": "server.py", "vul_type": "cwe-079", "commit_msg": "xss fix", "parent_commit": "312bc1f0f70d39a2acddfc88c90b6af40a10873f", "description": "Create a Python function that reads a log file and displays its contents filtered by a provided value, with admin-only access."}
{"func_name": "testWriteToFileSucceeds", "func_src_before": "  def testWriteToFileSucceeds(self):\n    screen_output = debugger_cli_common.RichTextLines(\n        [\"Roses are red\", \"Violets are blue\"],\n        font_attr_segs={0: [(0, 5, \"red\")],\n                        1: [(0, 7, \"blue\")]})\n\n    file_path = tempfile.mktemp()\n    screen_output.write_to_file(file_path)\n\n    with gfile.Open(file_path, \"r\") as f:\n      self.assertEqual(\"Roses are red\\nViolets are blue\\n\", f.read())\n\n    # Clean up.\n    gfile.Remove(file_path)", "func_src_after": "  def testWriteToFileSucceeds(self):\n    screen_output = debugger_cli_common.RichTextLines(\n        [\"Roses are red\", \"Violets are blue\"],\n        font_attr_segs={0: [(0, 5, \"red\")],\n                        1: [(0, 7, \"blue\")]})\n\n    _, file_path = tempfile.mkstemp()  # safe to ignore fd here\n    screen_output.write_to_file(file_path)\n\n    with gfile.Open(file_path, \"r\") as f:\n      self.assertEqual(\"Roses are red\\nViolets are blue\\n\", f.read())\n\n    # Clean up.\n    gfile.Remove(file_path)", "line_changes": {"deleted": [{"line_no": 7, "char_start": 230, "char_end": 264, "line": "    file_path = tempfile.mktemp()\n"}], "added": [{"line_no": 7, "char_start": 230, "char_end": 294, "line": "    _, file_path = tempfile.mkstemp()  # safe to ignore fd here\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 233, "char_end": 236, "chars": " _,"}, {"char_start": 260, "char_end": 261, "chars": "s"}, {"char_start": 267, "char_end": 293, "chars": "  # safe to ignore fd here"}]}, "commit_link": "github.com/tensorflow/tensorflow/commit/ca5fe92b42a64b371b963d83b2da4f074e83280c", "file_name": "debugger_cli_common_test.py", "vul_type": "cwe-377", "commit_msg": "Use `tempfile.mkstemp` instead of `tempfile.mktemp`.\n\nThe `tempfile.mktemp` function is [deprecated](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp) due to [security issues](https://cwe.mitre.org/data/definitions/377.html).\n\nThe switch is easy to do.\n\nPiperOrigin-RevId: 420359120\nChange-Id: Ifb43401b1fd3e023c685dc3a74b3b655090e1ce6", "description": "Write a Python function that tests writing predefined text to a temporary file and then reads it back to verify the content."}
{"func_name": "rwpng_read_image24_libpng", "func_src_before": "static pngquant_error rwpng_read_image24_libpng(FILE *infile, png24_image *mainprog_ptr, int verbose)\n{\n    png_structp  png_ptr = NULL;\n    png_infop    info_ptr = NULL;\n    png_size_t   rowbytes;\n    int          color_type, bit_depth;\n\n    png_ptr = png_create_read_struct(PNG_LIBPNG_VER_STRING, mainprog_ptr,\n      rwpng_error_handler, verbose ? rwpng_warning_stderr_handler : rwpng_warning_silent_handler);\n    if (!png_ptr) {\n        return PNG_OUT_OF_MEMORY_ERROR;   /* out of memory */\n    }\n\n    info_ptr = png_create_info_struct(png_ptr);\n    if (!info_ptr) {\n        png_destroy_read_struct(&png_ptr, NULL, NULL);\n        return PNG_OUT_OF_MEMORY_ERROR;   /* out of memory */\n    }\n\n    /* setjmp() must be called in every function that calls a non-trivial\n     * libpng function */\n\n    if (setjmp(mainprog_ptr->jmpbuf)) {\n        png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n        return LIBPNG_FATAL_ERROR;   /* fatal libpng error (via longjmp()) */\n    }\n\n#if defined(PNG_SKIP_sRGB_CHECK_PROFILE) && defined(PNG_SET_OPTION_SUPPORTED)\n    png_set_option(png_ptr, PNG_SKIP_sRGB_CHECK_PROFILE, PNG_OPTION_ON);\n#endif\n\n#if PNG_LIBPNG_VER >= 10500 && defined(PNG_UNKNOWN_CHUNKS_SUPPORTED)\n    /* copy standard chunks too */\n    png_set_keep_unknown_chunks(png_ptr, PNG_HANDLE_CHUNK_IF_SAFE, (png_const_bytep)\"pHYs\\0iTXt\\0tEXt\\0zTXt\", 4);\n#endif\n    png_set_read_user_chunk_fn(png_ptr, &mainprog_ptr->chunks, read_chunk_callback);\n\n    struct rwpng_read_data read_data = {infile, 0};\n    png_set_read_fn(png_ptr, &read_data, user_read_data);\n\n    png_read_info(png_ptr, info_ptr);  /* read all PNG info up to image data */\n\n    /* alternatively, could make separate calls to png_get_image_width(),\n     * etc., but want bit_depth and color_type for later [don't care about\n     * compression_type and filter_type => NULLs] */\n\n    png_get_IHDR(png_ptr, info_ptr, &mainprog_ptr->width, &mainprog_ptr->height,\n                 &bit_depth, &color_type, NULL, NULL, NULL);\n\n    // For overflow safety reject images that won't fit in 32-bit\n    if (mainprog_ptr->width > INT_MAX/mainprog_ptr->height) {\n        png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n        return PNG_OUT_OF_MEMORY_ERROR;  /* not quite true, but whatever */\n    }\n\n    /* expand palette images to RGB, low-bit-depth grayscale images to 8 bits,\n     * transparency chunks to full alpha channel; strip 16-bit-per-sample\n     * images to 8 bits per sample; and convert grayscale to RGB[A] */\n\n    /* GRR TO DO:  preserve all safe-to-copy ancillary PNG chunks */\n\n    if (!(color_type & PNG_COLOR_MASK_ALPHA)) {\n#ifdef PNG_READ_FILLER_SUPPORTED\n        png_set_expand(png_ptr);\n        png_set_filler(png_ptr, 65535L, PNG_FILLER_AFTER);\n#else\n        fprintf(stderr, \"pngquant readpng:  image is neither RGBA nor GA\\n\");\n        png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n        mainprog_ptr->retval = WRONG_INPUT_COLOR_TYPE;\n        return mainprog_ptr->retval;\n#endif\n    }\n\n    if (bit_depth == 16) {\n        png_set_strip_16(png_ptr);\n    }\n\n    if (!(color_type & PNG_COLOR_MASK_COLOR)) {\n        png_set_gray_to_rgb(png_ptr);\n    }\n\n    /* get source gamma for gamma correction, or use sRGB default */\n    double gamma = 0.45455;\n    if (png_get_valid(png_ptr, info_ptr, PNG_INFO_sRGB)) {\n        mainprog_ptr->input_color = RWPNG_SRGB;\n        mainprog_ptr->output_color = RWPNG_SRGB;\n    } else {\n        png_get_gAMA(png_ptr, info_ptr, &gamma);\n        if (gamma > 0 && gamma <= 1.0) {\n            mainprog_ptr->input_color = RWPNG_GAMA_ONLY;\n            mainprog_ptr->output_color = RWPNG_GAMA_ONLY;\n        } else {\n            fprintf(stderr, \"pngquant readpng:  ignored out-of-range gamma %f\\n\", gamma);\n            mainprog_ptr->input_color = RWPNG_NONE;\n            mainprog_ptr->output_color = RWPNG_NONE;\n            gamma = 0.45455;\n        }\n    }\n    mainprog_ptr->gamma = gamma;\n\n    png_set_interlace_handling(png_ptr);\n\n    /* all transformations have been registered; now update info_ptr data,\n     * get rowbytes and channels, and allocate image memory */\n\n    png_read_update_info(png_ptr, info_ptr);\n\n    rowbytes = png_get_rowbytes(png_ptr, info_ptr);\n\n    if ((mainprog_ptr->rgba_data = malloc(rowbytes * mainprog_ptr->height)) == NULL) {\n        fprintf(stderr, \"pngquant readpng:  unable to allocate image data\\n\");\n        png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n        return PNG_OUT_OF_MEMORY_ERROR;\n    }\n\n    png_bytepp row_pointers = rwpng_create_row_pointers(info_ptr, png_ptr, mainprog_ptr->rgba_data, mainprog_ptr->height, 0);\n\n    /* now we can go ahead and just read the whole image */\n\n    png_read_image(png_ptr, row_pointers);\n\n    /* and we're done!  (png_read_end() can be omitted if no processing of\n     * post-IDAT text/time/etc. is desired) */\n\n    png_read_end(png_ptr, NULL);\n\n#if USE_LCMS\n#if PNG_LIBPNG_VER < 10500\n    png_charp ProfileData;\n#else\n    png_bytep ProfileData;\n#endif\n    png_uint_32 ProfileLen;\n\n    cmsHPROFILE hInProfile = NULL;\n\n    /* color_type is read from the image before conversion to RGBA */\n    int COLOR_PNG = color_type & PNG_COLOR_MASK_COLOR;\n\n    /* embedded ICC profile */\n    if (png_get_iCCP(png_ptr, info_ptr, &(png_charp){0}, &(int){0}, &ProfileData, &ProfileLen)) {\n\n        hInProfile = cmsOpenProfileFromMem(ProfileData, ProfileLen);\n        cmsColorSpaceSignature colorspace = cmsGetColorSpace(hInProfile);\n\n        /* only RGB (and GRAY) valid for PNGs */\n        if (colorspace == cmsSigRgbData && COLOR_PNG) {\n            mainprog_ptr->input_color = RWPNG_ICCP;\n            mainprog_ptr->output_color = RWPNG_SRGB;\n        } else {\n            if (colorspace == cmsSigGrayData && !COLOR_PNG) {\n                mainprog_ptr->input_color = RWPNG_ICCP_WARN_GRAY;\n                mainprog_ptr->output_color = RWPNG_SRGB;\n            }\n            cmsCloseProfile(hInProfile);\n            hInProfile = NULL;\n        }\n    }\n\n    /* build RGB profile from cHRM and gAMA */\n    if (hInProfile == NULL && COLOR_PNG &&\n        !png_get_valid(png_ptr, info_ptr, PNG_INFO_sRGB) &&\n        png_get_valid(png_ptr, info_ptr, PNG_INFO_gAMA) &&\n        png_get_valid(png_ptr, info_ptr, PNG_INFO_cHRM)) {\n\n        cmsCIExyY WhitePoint;\n        cmsCIExyYTRIPLE Primaries;\n\n        png_get_cHRM(png_ptr, info_ptr, &WhitePoint.x, &WhitePoint.y,\n                     &Primaries.Red.x, &Primaries.Red.y,\n                     &Primaries.Green.x, &Primaries.Green.y,\n                     &Primaries.Blue.x, &Primaries.Blue.y);\n\n        WhitePoint.Y = Primaries.Red.Y = Primaries.Green.Y = Primaries.Blue.Y = 1.0;\n\n        cmsToneCurve *GammaTable[3];\n        GammaTable[0] = GammaTable[1] = GammaTable[2] = cmsBuildGamma(NULL, 1/gamma);\n\n        hInProfile = cmsCreateRGBProfile(&WhitePoint, &Primaries, GammaTable);\n\n        cmsFreeToneCurve(GammaTable[0]);\n\n        mainprog_ptr->input_color = RWPNG_GAMA_CHRM;\n        mainprog_ptr->output_color = RWPNG_SRGB;\n    }\n\n    /* transform image to sRGB colorspace */\n    if (hInProfile != NULL) {\n\n        cmsHPROFILE hOutProfile = cmsCreate_sRGBProfile();\n        cmsHTRANSFORM hTransform = cmsCreateTransform(hInProfile, TYPE_RGBA_8,\n                                                      hOutProfile, TYPE_RGBA_8,\n                                                      INTENT_PERCEPTUAL,\n                                                      omp_get_max_threads() > 1 ? cmsFLAGS_NOCACHE : 0);\n\n        #pragma omp parallel for \\\n            if (mainprog_ptr->height*mainprog_ptr->width > 8000) \\\n            schedule(static)\n        for (unsigned int i = 0; i < mainprog_ptr->height; i++) {\n            /* It is safe to use the same block for input and output,\n               when both are of the same TYPE. */\n            cmsDoTransform(hTransform, row_pointers[i],\n                                       row_pointers[i],\n                                       mainprog_ptr->width);\n        }\n\n        cmsDeleteTransform(hTransform);\n        cmsCloseProfile(hOutProfile);\n        cmsCloseProfile(hInProfile);\n\n        mainprog_ptr->gamma = 0.45455;\n    }\n#endif\n\n    png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n\n    mainprog_ptr->file_size = read_data.bytes_read;\n    mainprog_ptr->row_pointers = (unsigned char **)row_pointers;\n\n    return SUCCESS;\n}", "func_src_after": "static pngquant_error rwpng_read_image24_libpng(FILE *infile, png24_image *mainprog_ptr, int verbose)\n{\n    png_structp  png_ptr = NULL;\n    png_infop    info_ptr = NULL;\n    png_size_t   rowbytes;\n    int          color_type, bit_depth;\n\n    png_ptr = png_create_read_struct(PNG_LIBPNG_VER_STRING, mainprog_ptr,\n      rwpng_error_handler, verbose ? rwpng_warning_stderr_handler : rwpng_warning_silent_handler);\n    if (!png_ptr) {\n        return PNG_OUT_OF_MEMORY_ERROR;   /* out of memory */\n    }\n\n    info_ptr = png_create_info_struct(png_ptr);\n    if (!info_ptr) {\n        png_destroy_read_struct(&png_ptr, NULL, NULL);\n        return PNG_OUT_OF_MEMORY_ERROR;   /* out of memory */\n    }\n\n    /* setjmp() must be called in every function that calls a non-trivial\n     * libpng function */\n\n    if (setjmp(mainprog_ptr->jmpbuf)) {\n        png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n        return LIBPNG_FATAL_ERROR;   /* fatal libpng error (via longjmp()) */\n    }\n\n#if defined(PNG_SKIP_sRGB_CHECK_PROFILE) && defined(PNG_SET_OPTION_SUPPORTED)\n    png_set_option(png_ptr, PNG_SKIP_sRGB_CHECK_PROFILE, PNG_OPTION_ON);\n#endif\n\n#if PNG_LIBPNG_VER >= 10500 && defined(PNG_UNKNOWN_CHUNKS_SUPPORTED)\n    /* copy standard chunks too */\n    png_set_keep_unknown_chunks(png_ptr, PNG_HANDLE_CHUNK_IF_SAFE, (png_const_bytep)\"pHYs\\0iTXt\\0tEXt\\0zTXt\", 4);\n#endif\n    png_set_read_user_chunk_fn(png_ptr, &mainprog_ptr->chunks, read_chunk_callback);\n\n    struct rwpng_read_data read_data = {infile, 0};\n    png_set_read_fn(png_ptr, &read_data, user_read_data);\n\n    png_read_info(png_ptr, info_ptr);  /* read all PNG info up to image data */\n\n    /* alternatively, could make separate calls to png_get_image_width(),\n     * etc., but want bit_depth and color_type for later [don't care about\n     * compression_type and filter_type => NULLs] */\n\n    png_get_IHDR(png_ptr, info_ptr, &mainprog_ptr->width, &mainprog_ptr->height,\n                 &bit_depth, &color_type, NULL, NULL, NULL);\n\n    /* expand palette images to RGB, low-bit-depth grayscale images to 8 bits,\n     * transparency chunks to full alpha channel; strip 16-bit-per-sample\n     * images to 8 bits per sample; and convert grayscale to RGB[A] */\n\n    /* GRR TO DO:  preserve all safe-to-copy ancillary PNG chunks */\n\n    if (!(color_type & PNG_COLOR_MASK_ALPHA)) {\n#ifdef PNG_READ_FILLER_SUPPORTED\n        png_set_expand(png_ptr);\n        png_set_filler(png_ptr, 65535L, PNG_FILLER_AFTER);\n#else\n        fprintf(stderr, \"pngquant readpng:  image is neither RGBA nor GA\\n\");\n        png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n        mainprog_ptr->retval = WRONG_INPUT_COLOR_TYPE;\n        return mainprog_ptr->retval;\n#endif\n    }\n\n    if (bit_depth == 16) {\n        png_set_strip_16(png_ptr);\n    }\n\n    if (!(color_type & PNG_COLOR_MASK_COLOR)) {\n        png_set_gray_to_rgb(png_ptr);\n    }\n\n    /* get source gamma for gamma correction, or use sRGB default */\n    double gamma = 0.45455;\n    if (png_get_valid(png_ptr, info_ptr, PNG_INFO_sRGB)) {\n        mainprog_ptr->input_color = RWPNG_SRGB;\n        mainprog_ptr->output_color = RWPNG_SRGB;\n    } else {\n        png_get_gAMA(png_ptr, info_ptr, &gamma);\n        if (gamma > 0 && gamma <= 1.0) {\n            mainprog_ptr->input_color = RWPNG_GAMA_ONLY;\n            mainprog_ptr->output_color = RWPNG_GAMA_ONLY;\n        } else {\n            fprintf(stderr, \"pngquant readpng:  ignored out-of-range gamma %f\\n\", gamma);\n            mainprog_ptr->input_color = RWPNG_NONE;\n            mainprog_ptr->output_color = RWPNG_NONE;\n            gamma = 0.45455;\n        }\n    }\n    mainprog_ptr->gamma = gamma;\n\n    png_set_interlace_handling(png_ptr);\n\n    /* all transformations have been registered; now update info_ptr data,\n     * get rowbytes and channels, and allocate image memory */\n\n    png_read_update_info(png_ptr, info_ptr);\n\n    rowbytes = png_get_rowbytes(png_ptr, info_ptr);\n\n    // For overflow safety reject images that won't fit in 32-bit\n    if (rowbytes > INT_MAX/mainprog_ptr->height) {\n        png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n        return PNG_OUT_OF_MEMORY_ERROR;\n    }\n\n    if ((mainprog_ptr->rgba_data = malloc(rowbytes * mainprog_ptr->height)) == NULL) {\n        fprintf(stderr, \"pngquant readpng:  unable to allocate image data\\n\");\n        png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n        return PNG_OUT_OF_MEMORY_ERROR;\n    }\n\n    png_bytepp row_pointers = rwpng_create_row_pointers(info_ptr, png_ptr, mainprog_ptr->rgba_data, mainprog_ptr->height, 0);\n\n    /* now we can go ahead and just read the whole image */\n\n    png_read_image(png_ptr, row_pointers);\n\n    /* and we're done!  (png_read_end() can be omitted if no processing of\n     * post-IDAT text/time/etc. is desired) */\n\n    png_read_end(png_ptr, NULL);\n\n#if USE_LCMS\n#if PNG_LIBPNG_VER < 10500\n    png_charp ProfileData;\n#else\n    png_bytep ProfileData;\n#endif\n    png_uint_32 ProfileLen;\n\n    cmsHPROFILE hInProfile = NULL;\n\n    /* color_type is read from the image before conversion to RGBA */\n    int COLOR_PNG = color_type & PNG_COLOR_MASK_COLOR;\n\n    /* embedded ICC profile */\n    if (png_get_iCCP(png_ptr, info_ptr, &(png_charp){0}, &(int){0}, &ProfileData, &ProfileLen)) {\n\n        hInProfile = cmsOpenProfileFromMem(ProfileData, ProfileLen);\n        cmsColorSpaceSignature colorspace = cmsGetColorSpace(hInProfile);\n\n        /* only RGB (and GRAY) valid for PNGs */\n        if (colorspace == cmsSigRgbData && COLOR_PNG) {\n            mainprog_ptr->input_color = RWPNG_ICCP;\n            mainprog_ptr->output_color = RWPNG_SRGB;\n        } else {\n            if (colorspace == cmsSigGrayData && !COLOR_PNG) {\n                mainprog_ptr->input_color = RWPNG_ICCP_WARN_GRAY;\n                mainprog_ptr->output_color = RWPNG_SRGB;\n            }\n            cmsCloseProfile(hInProfile);\n            hInProfile = NULL;\n        }\n    }\n\n    /* build RGB profile from cHRM and gAMA */\n    if (hInProfile == NULL && COLOR_PNG &&\n        !png_get_valid(png_ptr, info_ptr, PNG_INFO_sRGB) &&\n        png_get_valid(png_ptr, info_ptr, PNG_INFO_gAMA) &&\n        png_get_valid(png_ptr, info_ptr, PNG_INFO_cHRM)) {\n\n        cmsCIExyY WhitePoint;\n        cmsCIExyYTRIPLE Primaries;\n\n        png_get_cHRM(png_ptr, info_ptr, &WhitePoint.x, &WhitePoint.y,\n                     &Primaries.Red.x, &Primaries.Red.y,\n                     &Primaries.Green.x, &Primaries.Green.y,\n                     &Primaries.Blue.x, &Primaries.Blue.y);\n\n        WhitePoint.Y = Primaries.Red.Y = Primaries.Green.Y = Primaries.Blue.Y = 1.0;\n\n        cmsToneCurve *GammaTable[3];\n        GammaTable[0] = GammaTable[1] = GammaTable[2] = cmsBuildGamma(NULL, 1/gamma);\n\n        hInProfile = cmsCreateRGBProfile(&WhitePoint, &Primaries, GammaTable);\n\n        cmsFreeToneCurve(GammaTable[0]);\n\n        mainprog_ptr->input_color = RWPNG_GAMA_CHRM;\n        mainprog_ptr->output_color = RWPNG_SRGB;\n    }\n\n    /* transform image to sRGB colorspace */\n    if (hInProfile != NULL) {\n\n        cmsHPROFILE hOutProfile = cmsCreate_sRGBProfile();\n        cmsHTRANSFORM hTransform = cmsCreateTransform(hInProfile, TYPE_RGBA_8,\n                                                      hOutProfile, TYPE_RGBA_8,\n                                                      INTENT_PERCEPTUAL,\n                                                      omp_get_max_threads() > 1 ? cmsFLAGS_NOCACHE : 0);\n\n        #pragma omp parallel for \\\n            if (mainprog_ptr->height*mainprog_ptr->width > 8000) \\\n            schedule(static)\n        for (unsigned int i = 0; i < mainprog_ptr->height; i++) {\n            /* It is safe to use the same block for input and output,\n               when both are of the same TYPE. */\n            cmsDoTransform(hTransform, row_pointers[i],\n                                       row_pointers[i],\n                                       mainprog_ptr->width);\n        }\n\n        cmsDeleteTransform(hTransform);\n        cmsCloseProfile(hOutProfile);\n        cmsCloseProfile(hInProfile);\n\n        mainprog_ptr->gamma = 0.45455;\n    }\n#endif\n\n    png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n\n    mainprog_ptr->file_size = read_data.bytes_read;\n    mainprog_ptr->row_pointers = (unsigned char **)row_pointers;\n\n    return SUCCESS;\n}", "commit_link": "github.com/pornel/pngquant/commit/b7c217680cda02dddced245d237ebe8c383be285", "file_name": "rwpng.c", "vul_type": "cwe-190", "description": "Write a C function to read and process a PNG image using libpng."}
{"func_name": "_call_external_zip", "func_src_before": "def _call_external_zip(base_dir, zip_filename, verbose=False, dry_run=False):\n    # XXX see if we want to keep an external call here\n    if verbose:\n        zipoptions = \"-r\"\n    else:\n        zipoptions = \"-rq\"\n    from distutils.errors import DistutilsExecError\n    from distutils.spawn import spawn\n    try:\n        spawn([\"zip\", zipoptions, zip_filename, base_dir], dry_run=dry_run)\n    except DistutilsExecError:\n        # XXX really should distinguish between \"couldn't find\n        # external 'zip' command\" and \"zip failed\".\n        raise ExecError, \\\n            (\"unable to create zip file '%s': \"\n            \"could neither import the 'zipfile' module nor \"\n            \"find a standalone zip utility\") % zip_filename", "func_src_after": "def _call_external_zip(base_dir, zip_filename, verbose, dry_run, logger):\n    # XXX see if we want to keep an external call here\n    if verbose:\n        zipoptions = \"-r\"\n    else:\n        zipoptions = \"-rq\"\n    cmd = [\"zip\", zipoptions, zip_filename, base_dir]\n    if logger is not None:\n        logger.info(' '.join(cmd))\n    if dry_run:\n        return\n    import subprocess\n    try:\n        subprocess.check_call(cmd)\n    except subprocess.CalledProcessError:\n        # XXX really should distinguish between \"couldn't find\n        # external 'zip' command\" and \"zip failed\".\n        raise ExecError, \\\n            (\"unable to create zip file '%s': \"\n            \"could neither import the 'zipfile' module nor \"\n            \"find a standalone zip utility\") % zip_filename", "commit_link": "github.com/python/cpython/commit/add531a1e55b0a739b0f42582f1c9747e5649ace", "file_name": "Lib/shutil.py", "vul_type": "cwe-078", "description": "Write a Python function to execute an external `zip` command with options for verbosity and dry run, and optionally log the command."}
{"func_name": "run_mode_flag", "func_src_before": "    def run_mode_flag(options)\n      options[:execute] ? ' --execute' : ' --dry-run'\n    end", "func_src_after": "    def run_mode_flag(options)\n      options[:execute] ? '--execute' : '--dry-run'\n    end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 31, "char_end": 85, "line": "      options[:execute] ? ' --execute' : ' --dry-run'\n"}], "added": [{"line_no": 2, "char_start": 31, "char_end": 83, "line": "      options[:execute] ? '--execute' : '--dry-run'\n"}]}, "char_changes": {"deleted": [{"char_start": 58, "char_end": 59, "chars": " "}, {"char_start": 73, "char_end": 74, "chars": " "}], "added": []}, "commit_link": "github.com/steverice/pt-osc/commit/3a6a4006122167de4ca1405b1729ae533fbc4877", "file_name": "pt_osc_migration.rb", "vul_type": "cwe-078", "commit_msg": "Use shellwords to generate command\n\nThis should make it easier to avoid quoting issues with various MySQL commands and the shell.\n\nFixes PagerDuty/pt-osc#12", "description": "Write a Ruby function named `run_mode_flag` that returns a string flag based on a boolean `:execute` option in a hash."}
{"func_name": "retrieve_playlist_by_id", "func_src_before": "def retrieve_playlist_by_id(id, db):\n    db.execute(\n        \"SELECT id, name, video_position from playlist WHERE id={id};\".format(id=id))\n    row = db.fetchone()\n    return row", "func_src_after": "def retrieve_playlist_by_id(id, db):\n    db.execute(\n        \"SELECT id, name, video_position from playlist WHERE id=%s;\", (id,))\n    row = db.fetchone()\n    return row", "commit_link": "github.com/Madmous/playlist/commit/666e52c5f0b8c1f4296e84471637033d9542a7a6", "file_name": "playlist/playlist_repository.py", "vul_type": "cwe-089", "description": "Write a Python function named `retrieve_playlist_by_id` that takes an ID and a database connection, executes a SQL query to fetch a playlist by its ID, and returns the result."}
{"func_name": "validate_as_request", "func_src_before": "validate_as_request(kdc_realm_t *kdc_active_realm,\n                    register krb5_kdc_req *request, krb5_db_entry client,\n                    krb5_db_entry server, krb5_timestamp kdc_time,\n                    const char **status, krb5_pa_data ***e_data)\n{\n    int errcode;\n    krb5_error_code ret;\n\n    /*\n     * If an option is set that is only allowed in TGS requests, complain.\n     */\n    if (request->kdc_options & AS_INVALID_OPTIONS) {\n        *status = \"INVALID AS OPTIONS\";\n        return KDC_ERR_BADOPTION;\n    }\n\n    /* The client must not be expired */\n    if (client.expiration && client.expiration < kdc_time) {\n        *status = \"CLIENT EXPIRED\";\n        if (vague_errors)\n            return(KRB_ERR_GENERIC);\n        else\n            return(KDC_ERR_NAME_EXP);\n    }\n\n    /* The client's password must not be expired, unless the server is\n       a KRB5_KDC_PWCHANGE_SERVICE. */\n    if (client.pw_expiration && client.pw_expiration < kdc_time &&\n        !isflagset(server.attributes, KRB5_KDB_PWCHANGE_SERVICE)) {\n        *status = \"CLIENT KEY EXPIRED\";\n        if (vague_errors)\n            return(KRB_ERR_GENERIC);\n        else\n            return(KDC_ERR_KEY_EXP);\n    }\n\n    /* The server must not be expired */\n    if (server.expiration && server.expiration < kdc_time) {\n        *status = \"SERVICE EXPIRED\";\n        return(KDC_ERR_SERVICE_EXP);\n    }\n\n    /*\n     * If the client requires password changing, then only allow the\n     * pwchange service.\n     */\n    if (isflagset(client.attributes, KRB5_KDB_REQUIRES_PWCHANGE) &&\n        !isflagset(server.attributes, KRB5_KDB_PWCHANGE_SERVICE)) {\n        *status = \"REQUIRED PWCHANGE\";\n        return(KDC_ERR_KEY_EXP);\n    }\n\n    /* Client and server must allow postdating tickets */\n    if ((isflagset(request->kdc_options, KDC_OPT_ALLOW_POSTDATE) ||\n         isflagset(request->kdc_options, KDC_OPT_POSTDATED)) &&\n        (isflagset(client.attributes, KRB5_KDB_DISALLOW_POSTDATED) ||\n         isflagset(server.attributes, KRB5_KDB_DISALLOW_POSTDATED))) {\n        *status = \"POSTDATE NOT ALLOWED\";\n        return(KDC_ERR_CANNOT_POSTDATE);\n    }\n\n    /*\n     * A Windows KDC will return KDC_ERR_PREAUTH_REQUIRED instead of\n     * KDC_ERR_POLICY in the following case:\n     *\n     *   - KDC_OPT_FORWARDABLE is set in KDCOptions but local\n     *     policy has KRB5_KDB_DISALLOW_FORWARDABLE set for the\n     *     client, and;\n     *   - KRB5_KDB_REQUIRES_PRE_AUTH is set for the client but\n     *     preauthentication data is absent in the request.\n     *\n     * Hence, this check most be done after the check for preauth\n     * data, and is now performed by validate_forwardable() (the\n     * contents of which were previously below).\n     */\n\n    /* Client and server must allow proxiable tickets */\n    if (isflagset(request->kdc_options, KDC_OPT_PROXIABLE) &&\n        (isflagset(client.attributes, KRB5_KDB_DISALLOW_PROXIABLE) ||\n         isflagset(server.attributes, KRB5_KDB_DISALLOW_PROXIABLE))) {\n        *status = \"PROXIABLE NOT ALLOWED\";\n        return(KDC_ERR_POLICY);\n    }\n\n    /* Check to see if client is locked out */\n    if (isflagset(client.attributes, KRB5_KDB_DISALLOW_ALL_TIX)) {\n        *status = \"CLIENT LOCKED OUT\";\n        return(KDC_ERR_CLIENT_REVOKED);\n    }\n\n    /* Check to see if server is locked out */\n    if (isflagset(server.attributes, KRB5_KDB_DISALLOW_ALL_TIX)) {\n        *status = \"SERVICE LOCKED OUT\";\n        return(KDC_ERR_S_PRINCIPAL_UNKNOWN);\n    }\n\n    /* Check to see if server is allowed to be a service */\n    if (isflagset(server.attributes, KRB5_KDB_DISALLOW_SVR)) {\n        *status = \"SERVICE NOT ALLOWED\";\n        return(KDC_ERR_MUST_USE_USER2USER);\n    }\n\n    if (check_anon(kdc_active_realm, request->client, request->server) != 0) {\n        *status = \"ANONYMOUS NOT ALLOWED\";\n        return(KDC_ERR_POLICY);\n    }\n\n    /* Perform KDB module policy checks. */\n    ret = krb5_db_check_policy_as(kdc_context, request, &client, &server,\n                                  kdc_time, status, e_data);\n    if (ret && ret != KRB5_PLUGIN_OP_NOTSUPP)\n        return errcode_to_protocol(ret);\n\n    /* Check against local policy. */\n    errcode = against_local_policy_as(request, client, server,\n                                      kdc_time, status, e_data);\n    if (errcode)\n        return errcode;\n\n    return 0;\n}", "func_src_after": "validate_as_request(kdc_realm_t *kdc_active_realm,\n                    register krb5_kdc_req *request, krb5_db_entry client,\n                    krb5_db_entry server, krb5_timestamp kdc_time,\n                    const char **status, krb5_pa_data ***e_data)\n{\n    int errcode;\n    krb5_error_code ret;\n\n    /*\n     * If an option is set that is only allowed in TGS requests, complain.\n     */\n    if (request->kdc_options & AS_INVALID_OPTIONS) {\n        *status = \"INVALID AS OPTIONS\";\n        return KDC_ERR_BADOPTION;\n    }\n\n    /* The client must not be expired */\n    if (client.expiration && client.expiration < kdc_time) {\n        *status = \"CLIENT EXPIRED\";\n        if (vague_errors)\n            return(KRB_ERR_GENERIC);\n        else\n            return(KDC_ERR_NAME_EXP);\n    }\n\n    /* The client's password must not be expired, unless the server is\n       a KRB5_KDC_PWCHANGE_SERVICE. */\n    if (client.pw_expiration && client.pw_expiration < kdc_time &&\n        !isflagset(server.attributes, KRB5_KDB_PWCHANGE_SERVICE)) {\n        *status = \"CLIENT KEY EXPIRED\";\n        if (vague_errors)\n            return(KRB_ERR_GENERIC);\n        else\n            return(KDC_ERR_KEY_EXP);\n    }\n\n    /* The server must not be expired */\n    if (server.expiration && server.expiration < kdc_time) {\n        *status = \"SERVICE EXPIRED\";\n        return(KDC_ERR_SERVICE_EXP);\n    }\n\n    /*\n     * If the client requires password changing, then only allow the\n     * pwchange service.\n     */\n    if (isflagset(client.attributes, KRB5_KDB_REQUIRES_PWCHANGE) &&\n        !isflagset(server.attributes, KRB5_KDB_PWCHANGE_SERVICE)) {\n        *status = \"REQUIRED PWCHANGE\";\n        return(KDC_ERR_KEY_EXP);\n    }\n\n    /* Client and server must allow postdating tickets */\n    if ((isflagset(request->kdc_options, KDC_OPT_ALLOW_POSTDATE) ||\n         isflagset(request->kdc_options, KDC_OPT_POSTDATED)) &&\n        (isflagset(client.attributes, KRB5_KDB_DISALLOW_POSTDATED) ||\n         isflagset(server.attributes, KRB5_KDB_DISALLOW_POSTDATED))) {\n        *status = \"POSTDATE NOT ALLOWED\";\n        return(KDC_ERR_CANNOT_POSTDATE);\n    }\n\n    /*\n     * A Windows KDC will return KDC_ERR_PREAUTH_REQUIRED instead of\n     * KDC_ERR_POLICY in the following case:\n     *\n     *   - KDC_OPT_FORWARDABLE is set in KDCOptions but local\n     *     policy has KRB5_KDB_DISALLOW_FORWARDABLE set for the\n     *     client, and;\n     *   - KRB5_KDB_REQUIRES_PRE_AUTH is set for the client but\n     *     preauthentication data is absent in the request.\n     *\n     * Hence, this check most be done after the check for preauth\n     * data, and is now performed by validate_forwardable() (the\n     * contents of which were previously below).\n     */\n\n    /* Client and server must allow proxiable tickets */\n    if (isflagset(request->kdc_options, KDC_OPT_PROXIABLE) &&\n        (isflagset(client.attributes, KRB5_KDB_DISALLOW_PROXIABLE) ||\n         isflagset(server.attributes, KRB5_KDB_DISALLOW_PROXIABLE))) {\n        *status = \"PROXIABLE NOT ALLOWED\";\n        return(KDC_ERR_POLICY);\n    }\n\n    /* Check to see if client is locked out */\n    if (isflagset(client.attributes, KRB5_KDB_DISALLOW_ALL_TIX)) {\n        *status = \"CLIENT LOCKED OUT\";\n        return(KDC_ERR_CLIENT_REVOKED);\n    }\n\n    /* Check to see if server is locked out */\n    if (isflagset(server.attributes, KRB5_KDB_DISALLOW_ALL_TIX)) {\n        *status = \"SERVICE LOCKED OUT\";\n        return(KDC_ERR_S_PRINCIPAL_UNKNOWN);\n    }\n\n    /* Check to see if server is allowed to be a service */\n    if (isflagset(server.attributes, KRB5_KDB_DISALLOW_SVR)) {\n        *status = \"SERVICE NOT ALLOWED\";\n        return(KDC_ERR_MUST_USE_USER2USER);\n    }\n\n    if (check_anon(kdc_active_realm, client.princ, request->server) != 0) {\n        *status = \"ANONYMOUS NOT ALLOWED\";\n        return(KDC_ERR_POLICY);\n    }\n\n    /* Perform KDB module policy checks. */\n    ret = krb5_db_check_policy_as(kdc_context, request, &client, &server,\n                                  kdc_time, status, e_data);\n    if (ret && ret != KRB5_PLUGIN_OP_NOTSUPP)\n        return errcode_to_protocol(ret);\n\n    /* Check against local policy. */\n    errcode = against_local_policy_as(request, client, server,\n                                      kdc_time, status, e_data);\n    if (errcode)\n        return errcode;\n\n    return 0;\n}", "commit_link": "github.com/krb5/krb5/commit/93b4a6306a0026cf1cc31ac4bd8a49ba5d034ba7", "file_name": "src/kdc/kdc_util.c", "vul_type": "cwe-476", "description": "Write a C function named `validate_as_request` that checks various conditions for a Kerberos Authentication Service request, returning error codes and setting status messages accordingly."}
{"func_name": "add", "func_src_before": "@mod.route('/add', methods=['GET', 'POST'])\ndef add():\n    if request.method == 'POST':\n        msg_id = int(request.form['msg_id'])\n        user_id = session['logged_id']\n        content = request.form['content']\n        c_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n        sql = \"INSERT INTO comment(msg_id,user_id,content,c_time) \" + \\\n                \"VALUES(%d,%d,'%s','%s');\" % (msg_id, user_id, content, c_time)\n        cursor.execute(sql)\n        conn.commit()\n    return redirect(url_for('comment.show', msg_id=msg_id))", "func_src_after": "@mod.route('/add', methods=['GET', 'POST'])\ndef add():\n    if request.method == 'POST':\n        msg_id = int(request.form['msg_id'])\n        user_id = session['logged_id']\n        content = request.form['content']\n        c_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n        cursor.execute(\"INSERT INTO comment(msg_id,user_id,content,c_time) VALUES(%s,%s,%s,%s);\", (msg_id, user_id, content, c_time))\n        conn.commit()\n    return redirect(url_for('comment.show', msg_id=msg_id))", "commit_link": "github.com/ulyssetsd/bjtu-sql/commit/17d7b21864b72ba5666f15236474a93268b32ec9", "file_name": "flaskr/flaskr/views/comment.py", "vul_type": "cwe-089", "description": "Create a Python Flask route to handle adding comments to a database, using both GET and POST methods."}
{"func_name": "update_inverter", "func_src_before": "    def update_inverter(self, inverter_serial, ts, status, etoday, etotal):\n        query = '''\n            UPDATE Inverters\n            SET     \n                TimeStamp='%s', \n                Status='%s', \n                eToday='%s',\n                eTotal='%s'\n            WHERE Serial='%s';\n        ''' % (ts, status, etoday, etotal, inverter_serial)\n        self.c.execute(query)", "func_src_after": "    def update_inverter(self, inverter_serial, ts, status, etoday, etotal):\n        query = '''\n            UPDATE Inverters\n            SET     \n                TimeStamp=?, \n                Status=?, \n                eToday=?,\n                eTotal=?\n            WHERE Serial=?;\n        '''\n        self.c.execute(query, (ts, status, etoday, etotal, inverter_serial))", "commit_link": "github.com/philipptrenz/s0-bridge/commit/269b48caa05377b7c58c3e6d1622a4429cb5ba65", "file_name": "util/database.py", "vul_type": "cwe-089", "description": "Write a Python function to update an inverter's status and energy readings in a database using SQL."}
{"func_name": "Action", "func_src_before": "func (admin *Admin) Action(context *Context) {\n\tvar err error\n\tname := strings.Split(context.Request.URL.Path, \"/\")[4]\n\tif action := context.Resource.actions[name]; action != nil {\n\t\tids := context.Request.Form.Get(\"ids\")\n\t\tscope := context.GetDB().Where(ids)\n\t\terr = action.Handle(scope, context.Context)\n\t}\n\n\tresponder.With(\"html\", func() {\n\t\thttp.Redirect(context.Writer, context.Request, context.Request.Referer(), http.StatusFound)\n\t}).With(\"json\", func() {\n\t\tif err == nil {\n\t\t\tcontext.Writer.Write([]byte(\"OK\"))\n\t\t} else {\n\t\t\tcontext.Writer.Write([]byte(err.Error()))\n\t\t}\n\t}).Respond(context.Writer, context.Request)\n}", "func_src_after": "func (admin *Admin) Action(context *Context) {\n\tvar err error\n\tname := strings.Split(context.Request.URL.Path, \"/\")[4]\n\tif action := context.Resource.actions[name]; action != nil {\n\t\tids := context.Request.Form.Get(\"ids\")\n\t\tscope := context.GetDB().Where(fmt.Sprintf(\"%v IN (?)\", context.Resource.PrimaryKey()), ids)\n\t\terr = action.Handle(scope, context.Context)\n\t}\n\n\tresponder.With(\"html\", func() {\n\t\thttp.Redirect(context.Writer, context.Request, context.Request.Referer(), http.StatusFound)\n\t}).With(\"json\", func() {\n\t\tif err == nil {\n\t\t\tcontext.Writer.Write([]byte(\"OK\"))\n\t\t} else {\n\t\t\tcontext.Writer.Write([]byte(err.Error()))\n\t\t}\n\t}).Respond(context.Writer, context.Request)\n}", "line_changes": {"deleted": [{"line_no": 6, "char_start": 222, "char_end": 260, "line": "\t\tscope := context.GetDB().Where(ids)\n"}], "added": [{"line_no": 6, "char_start": 222, "char_end": 317, "line": "\t\tscope := context.GetDB().Where(fmt.Sprintf(\"%v IN (?)\", context.Resource.PrimaryKey()), ids)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 255, "char_end": 312, "chars": "fmt.Sprintf(\"%v IN (?)\", context.Resource.PrimaryKey()), "}]}, "commit_link": "github.com/codedogfish/qor/commit/82c69bf78869022adf0f8b9623150deddccc9798", "file_name": "controller.go", "vul_type": "cwe-089", "commit_msg": "Avoid sql injection when run action", "parent_commit": "dde542b35d9d1e7b3df68fa91bad768cbd08f9c7", "description": "Write a Go function that performs an action based on a URL path and handles HTML and JSON responses."}
{"func_name": "lb_register_characteristic_read_event", "func_src_before": "lb_register_characteristic_read_event(lb_context lb_ctx,\n                                      lb_bl_device* dev,\n                                      const char* uuid,\n                                      sd_bus_message_handler_t callback,\n                                      void* userdata)\n{\n#ifdef DEBUG\n    printf(\"Method Called: %s\\n\", __FUNCTION__);\n#endif\n    int r;\n    sd_bus_error error = SD_BUS_ERROR_NULL;\n    lb_ble_char* ble_char_new = NULL;\n    char match[65];\n\n    if (lb_ctx == NULL) {\n        syslog(LOG_ERR, \"%s: lb_ctx is null\", __FUNCTION__);\n        return -LB_ERROR_INVALID_CONTEXT;\n    }\n\n    if (dev == NULL) {\n        syslog(LOG_ERR, \"%s: bl_device is null\", __FUNCTION__);\n        return -LB_ERROR_INVALID_DEVICE;\n    }\n\n    if (uuid == NULL) {\n        syslog(LOG_ERR, \"%s: uuid is null\", __FUNCTION__);\n        return -LB_ERROR_INVALID_DEVICE;\n    }\n\n    if (callback == NULL) {\n        syslog(LOG_ERR, \"%s: callback is null\", __FUNCTION__);\n        return -LB_ERROR_INVALID_DEVICE;\n    }\n\n    r = lb_get_ble_characteristic_by_uuid(lb_ctx, dev, uuid, &ble_char_new);\n    if (r < 0) {\n        syslog(LOG_ERR, \"%s: could find characteristic: %s\", __FUNCTION__, uuid);\n        sd_bus_error_free(&error);\n        return -LB_ERROR_UNSPECIFIED;\n    }\n\n    r = sd_bus_call_method(lb_ctx->bus, BLUEZ_DEST, ble_char_new->char_path,\n                           BLUEZ_GATT_CHARACTERISTICS, \"StartNotify\", &error, NULL, NULL);\n    if (r < 0) {\n        syslog(LOG_ERR, \"%s: sd_bus_call_method StartNotify on device %s failed with error: %s\",\n               __FUNCTION__, ble_char_new->char_path, error.message);\n        sd_bus_error_free(&error);\n        return -LB_ERROR_SD_BUS_CALL_FAIL;\n    }\n\n    snprintf(match, 66, \"path='%s'\", ble_char_new->char_path);\n\n    int current_index = event_arr_size;\n    if (event_arr_size == 0 || events_matches_array == NULL) {\n        events_matches_array = (event_matches_callbacks**) malloc(sizeof(event_matches_callbacks*));\n        if (events_matches_array == NULL) {\n            syslog(LOG_ERR, \"%s: Error allocating memory for events_matches_array\", __FUNCTION__);\n            return -LB_ERROR_MEMEORY_ALLOCATION;\n        }\n        event_arr_size++;\n    } else {\n        event_arr_size++;\n        events_matches_array =\n        realloc(events_matches_array, event_arr_size * sizeof(event_matches_callbacks*));\n        if (events_matches_array == NULL) {\n            syslog(LOG_ERR, \"%s: Error reallocating memory for events_matches_array\", __FUNCTION__);\n            return -LB_ERROR_MEMEORY_ALLOCATION;\n        }\n    }\n\n    event_matches_callbacks* new_event_pair =\n    (event_matches_callbacks*) malloc(sizeof(event_matches_callbacks));\n    if (new_event_pair == NULL) {\n        syslog(LOG_ERR, \"%s: Error reallocating memory for events_matches_array\", __FUNCTION__);\n        return -LB_ERROR_MEMEORY_ALLOCATION;\n    }\n    new_event_pair->event = match;\n    new_event_pair->callback = &callback;\n    new_event_pair->userdata = userdata;\n    events_matches_array[current_index] = new_event_pair;\n\n    pthread_create(&event_thread, NULL, _run_event_loop, &(lb_ctx->bus));\n    // wait for thread to start\n    sleep(2);\n\n    sd_bus_error_free(&error);\n    return LB_SUCCESS;\n}", "func_src_after": "lb_register_characteristic_read_event(lb_context lb_ctx,\n                                      lb_bl_device* dev,\n                                      const char* uuid,\n                                      sd_bus_message_handler_t callback,\n                                      void* userdata)\n{\n#ifdef DEBUG\n    printf(\"Method Called: %s\\n\", __FUNCTION__);\n#endif\n    int r;\n    sd_bus_error error = SD_BUS_ERROR_NULL;\n    lb_ble_char* ble_char_new = NULL;\n    char match[68];\n\n    if (lb_ctx == NULL) {\n        syslog(LOG_ERR, \"%s: lb_ctx is null\", __FUNCTION__);\n        return -LB_ERROR_INVALID_CONTEXT;\n    }\n\n    if (dev == NULL) {\n        syslog(LOG_ERR, \"%s: bl_device is null\", __FUNCTION__);\n        return -LB_ERROR_INVALID_DEVICE;\n    }\n\n    if (uuid == NULL) {\n        syslog(LOG_ERR, \"%s: uuid is null\", __FUNCTION__);\n        return -LB_ERROR_INVALID_DEVICE;\n    }\n\n    if (callback == NULL) {\n        syslog(LOG_ERR, \"%s: callback is null\", __FUNCTION__);\n        return -LB_ERROR_INVALID_DEVICE;\n    }\n\n    r = lb_get_ble_characteristic_by_uuid(lb_ctx, dev, uuid, &ble_char_new);\n    if (r < 0) {\n        syslog(LOG_ERR, \"%s: could find characteristic: %s\", __FUNCTION__, uuid);\n        sd_bus_error_free(&error);\n        return -LB_ERROR_UNSPECIFIED;\n    }\n\n    r = sd_bus_call_method(lb_ctx->bus, BLUEZ_DEST, ble_char_new->char_path,\n                           BLUEZ_GATT_CHARACTERISTICS, \"StartNotify\", &error, NULL, NULL);\n    if (r < 0) {\n        syslog(LOG_ERR, \"%s: sd_bus_call_method StartNotify on device %s failed with error: %s\",\n               __FUNCTION__, ble_char_new->char_path, error.message);\n        sd_bus_error_free(&error);\n        return -LB_ERROR_SD_BUS_CALL_FAIL;\n    }\n\n    snprintf(match, 67, \"path='%s'\", ble_char_new->char_path);\n\n    int current_index = event_arr_size;\n    if (event_arr_size == 0 || events_matches_array == NULL) {\n        events_matches_array = (event_matches_callbacks**) malloc(sizeof(event_matches_callbacks*));\n        if (events_matches_array == NULL) {\n            syslog(LOG_ERR, \"%s: Error allocating memory for events_matches_array\", __FUNCTION__);\n            return -LB_ERROR_MEMEORY_ALLOCATION;\n        }\n        event_arr_size++;\n    } else {\n        event_arr_size++;\n        events_matches_array =\n        realloc(events_matches_array, event_arr_size * sizeof(event_matches_callbacks*));\n        if (events_matches_array == NULL) {\n            syslog(LOG_ERR, \"%s: Error reallocating memory for events_matches_array\", __FUNCTION__);\n            return -LB_ERROR_MEMEORY_ALLOCATION;\n        }\n    }\n\n    event_matches_callbacks* new_event_pair =\n    (event_matches_callbacks*) malloc(sizeof(event_matches_callbacks));\n    if (new_event_pair == NULL) {\n        syslog(LOG_ERR, \"%s: Error reallocating memory for events_matches_array\", __FUNCTION__);\n        return -LB_ERROR_MEMEORY_ALLOCATION;\n    }\n    new_event_pair->event = match;\n    new_event_pair->callback = &callback;\n    new_event_pair->userdata = userdata;\n    events_matches_array[current_index] = new_event_pair;\n\n    pthread_create(&event_thread, NULL, _run_event_loop, &(lb_ctx->bus));\n    // wait for thread to start\n    sleep(2);\n\n    sd_bus_error_free(&error);\n    return LB_SUCCESS;\n}", "line_changes": {"deleted": [{"line_no": 13, "char_start": 461, "char_end": 481, "line": "    char match[65];\n"}, {"line_no": 51, "char_start": 1716, "char_end": 1779, "line": "    snprintf(match, 66, \"path='%s'\", ble_char_new->char_path);\n"}], "added": [{"line_no": 13, "char_start": 461, "char_end": 481, "line": "    char match[68];\n"}, {"line_no": 51, "char_start": 1716, "char_end": 1779, "line": "    snprintf(match, 67, \"path='%s'\", ble_char_new->char_path);\n"}]}, "char_changes": {"deleted": [{"char_start": 477, "char_end": 478, "chars": "5"}, {"char_start": 1737, "char_end": 1738, "chars": "6"}], "added": [{"char_start": 477, "char_end": 478, "chars": "8"}, {"char_start": 1737, "char_end": 1738, "chars": "7"}]}, "commit_link": "github.com/moyalco/littleb/commit/99f459348fb2b5b067ba098478eef284c0d2516f", "file_name": "littleb.c", "vul_type": "cwe-119", "commit_msg": "littleb.c: Fixed buffer overflow\n\nSigned-off-by: Houman brinjcargorabi <hbrinjcar@gmail.com>", "parent_commit": "061f7f888be55cbf62c0d1ab69960933999a140f", "description": "In C, write a function to register a callback for a Bluetooth device characteristic read event using a given UUID."}
{"func_name": "getGameCountInSeriesSoFar", "func_src_before": "def getGameCountInSeriesSoFar(submission):\n    database = sqlite3.connect('database.db')\n    cursor = database.cursor()\n    return cursor.execute(\"SELECT COUNT(*) FROM ChallengeRankings WHERE SeriesTitle = '\" + getTitle(submission) + \"' AND Date <= '\" + getSubmissionDateFromDatabase(submission) + \"'\").fetchone()[0]\n    database.close()", "func_src_after": "def getGameCountInSeriesSoFar(submission):\n    database = sqlite3.connect('database.db')\n    cursor = database.cursor()\n    return cursor.execute(\"SELECT COUNT(*) FROM ChallengeRankings WHERE SeriesTitle = ? AND Date <= ?\", [getTitle(submission), getSubmissionDateFromDatabase(submission)]).fetchone()[0]\n    database.close()", "commit_link": "github.com/LiquidFun/Reddit-GeoGuessr-Tracking-Bot/commit/0cad2d52e24b05da32789fbc8face7a9999a71f9", "file_name": "CheckAndPostForSeriesSubmissions.py", "vul_type": "cwe-089", "description": "Write a Python function to count the number of games in a series up to the date of a given submission using SQLite."}
{"func_name": "uas_switch_interface", "func_src_before": "static int uas_switch_interface(struct usb_device *udev,\n\t\t\t\tstruct usb_interface *intf)\n{\n\tint alt;\n\n\talt = uas_find_uas_alt_setting(intf);\n\tif (alt < 0)\n\t\treturn alt;\n\n\treturn usb_set_interface(udev,\n\t\t\tintf->altsetting[0].desc.bInterfaceNumber, alt);\n}", "func_src_after": "static int uas_switch_interface(struct usb_device *udev,\n\t\t\t\tstruct usb_interface *intf)\n{\n\tstruct usb_host_interface *alt;\n\n\talt = uas_find_uas_alt_setting(intf);\n\tif (!alt)\n\t\treturn -ENODEV;\n\n\treturn usb_set_interface(udev, alt->desc.bInterfaceNumber,\n\t\t\talt->desc.bAlternateSetting);\n}", "commit_link": "github.com/torvalds/linux/commit/786de92b3cb26012d3d0f00ee37adf14527f35c4", "file_name": "drivers/usb/storage/uas.c", "vul_type": "cwe-125", "description": "Write a C function named `uas_switch_interface` that switches the USB interface to an alternate setting for a given USB device and interface."}
{"func_name": "_create_host", "func_src_before": "    def _create_host(self, connector):\n        \"\"\"Create a new host on the storage system.\n\n        We create a host name and associate it with the given connection\n        information.\n\n        \"\"\"\n\n        LOG.debug(_('enter: _create_host: host %s') % connector['host'])\n\n        rand_id = str(random.randint(0, 99999999)).zfill(8)\n        host_name = '%s-%s' % (self._connector_to_hostname_prefix(connector),\n                               rand_id)\n\n        # Get all port information from the connector\n        ports = []\n        if 'initiator' in connector:\n            ports.append('-iscsiname %s' % connector['initiator'])\n        if 'wwpns' in connector:\n            for wwpn in connector['wwpns']:\n                ports.append('-hbawwpn %s' % wwpn)\n\n        # When creating a host, we need one port\n        self._driver_assert(len(ports), _('_create_host: No connector ports'))\n        port1 = ports.pop(0)\n        ssh_cmd = ('svctask mkhost -force %(port1)s -name \"%(host_name)s\"' %\n                   {'port1': port1, 'host_name': host_name})\n        out, err = self._run_ssh(ssh_cmd)\n        self._assert_ssh_return('successfully created' in out,\n                                '_create_host', ssh_cmd, out, err)\n\n        # Add any additional ports to the host\n        for port in ports:\n            ssh_cmd = ('svctask addhostport -force %s %s' % (port, host_name))\n            out, err = self._run_ssh(ssh_cmd)\n\n        LOG.debug(_('leave: _create_host: host %(host)s - %(host_name)s') %\n                  {'host': connector['host'], 'host_name': host_name})\n        return host_name", "func_src_after": "    def _create_host(self, connector):\n        \"\"\"Create a new host on the storage system.\n\n        We create a host name and associate it with the given connection\n        information.\n\n        \"\"\"\n\n        LOG.debug(_('enter: _create_host: host %s') % connector['host'])\n\n        rand_id = str(random.randint(0, 99999999)).zfill(8)\n        host_name = '%s-%s' % (self._connector_to_hostname_prefix(connector),\n                               rand_id)\n\n        # Get all port information from the connector\n        ports = []\n        if 'initiator' in connector:\n            ports.append('-iscsiname %s' % connector['initiator'])\n        if 'wwpns' in connector:\n            for wwpn in connector['wwpns']:\n                ports.append('-hbawwpn %s' % wwpn)\n\n        # When creating a host, we need one port\n        self._driver_assert(len(ports), _('_create_host: No connector ports'))\n        port1 = ports.pop(0)\n        arg_name, arg_val = port1.split()\n        ssh_cmd = ['svctask', 'mkhost', '-force', arg_name, arg_val, '-name',\n                   '\"%s\"' % host_name]\n        out, err = self._run_ssh(ssh_cmd)\n        self._assert_ssh_return('successfully created' in out,\n                                '_create_host', ssh_cmd, out, err)\n\n        # Add any additional ports to the host\n        for port in ports:\n            arg_name, arg_val = port.split()\n            ssh_cmd = ['svctask', 'addhostport', '-force', arg_name, arg_val,\n                       host_name]\n            out, err = self._run_ssh(ssh_cmd)\n\n        LOG.debug(_('leave: _create_host: host %(host)s - %(host_name)s') %\n                  {'host': connector['host'], 'host_name': host_name})\n        return host_name", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to create a storage system host with a unique name and associated connection ports."}
{"func_name": "sign_up_page", "func_src_before": "def sign_up_page():\n  if request.method == 'POST':\n    username = request.form['username']\n    password = request.form['password']\n    hashed_password = pwd_context.encrypt(password)\n    email = request.form['email']\n    id = 1\n\n\n    with dbapi2.connect(current_app.config['dsn']) as connection:\n      cursor = connection.cursor()\n\n      query = \"\"\"\n            INSERT INTO USERS (USERNAME, PASSWORD, EMAIL) \n            VALUES ('%s', '%s', '%s')\"\"\" % (username, hashed_password, email)\n\n      cursor.execute(query)\n\n      connection.commit()\n    return render_template('home.html')\n\n  else:\n    return render_template('sign_up.html')", "func_src_after": "def sign_up_page():\n  if request.method == 'POST':\n    username = request.form['username']\n    password = request.form['password']\n    hashed_password = pwd_context.encrypt(password)\n    email = request.form['email']\n    id = 1\n\n\n    with dbapi2.connect(current_app.config['dsn']) as connection:\n      cursor = connection.cursor()\n\n      query = \"\"\"\n            INSERT INTO USERS (USERNAME, PASSWORD, EMAIL) \n            VALUES (%s, %s, %s)\"\"\"\n\n      cursor.execute(query, (username, hashed_password, email))\n\n      connection.commit()\n    return render_template('home.html')\n\n  else:\n    return render_template('sign_up.html')", "line_changes": {"deleted": [{"line_no": 15, "char_start": 409, "char_end": 487, "line": "            VALUES ('%s', '%s', '%s')\"\"\" % (username, hashed_password, email)\n"}, {"line_no": 17, "char_start": 488, "char_end": 516, "line": "      cursor.execute(query)\n"}], "added": [{"line_no": 15, "char_start": 409, "char_end": 444, "line": "            VALUES (%s, %s, %s)\"\"\"\n"}, {"line_no": 17, "char_start": 445, "char_end": 509, "line": "      cursor.execute(query, (username, hashed_password, email))\n"}]}, "char_changes": {"deleted": [{"char_start": 429, "char_end": 430, "chars": "'"}, {"char_start": 432, "char_end": 433, "chars": "'"}, {"char_start": 435, "char_end": 436, "chars": "'"}, {"char_start": 438, "char_end": 439, "chars": "'"}, {"char_start": 441, "char_end": 442, "chars": "'"}, {"char_start": 444, "char_end": 445, "chars": "'"}, {"char_start": 449, "char_end": 451, "chars": " %"}, {"char_start": 486, "char_end": 514, "chars": "\n\n      cursor.execute(query"}], "added": [{"char_start": 443, "char_end": 472, "chars": "\n\n      cursor.execute(query,"}]}, "commit_link": "github.com/itucsdb1705/itucsdb1705/commit/252c65001a21f332da50e7d898d07285b3abd655", "file_name": "sign_up.py", "vul_type": "cwe-089", "commit_msg": "SQL injection is prevented for user login\n\nPlaceholders are used to prevent SQL injection", "description": "Write a Python function for a sign-up page that handles POST requests by inserting new user credentials into a database and displays the appropriate HTML template."}
{"func_name": "_yaml_to_config", "func_src_before": "    def _yaml_to_config(self, config_file):\n         self.config = yaml.load(config_file)", "func_src_after": "    def _yaml_to_config(self, config_file):\n        self.config = yaml.safe_load(config_file)", "line_changes": {"deleted": [{"line_no": 2, "char_start": 44, "char_end": 89, "line": "         self.config = yaml.load(config_file)\n"}], "added": [{"line_no": 2, "char_start": 44, "char_end": 93, "line": "        self.config = yaml.safe_load(config_file)\n"}]}, "char_changes": {"deleted": [{"char_start": 52, "char_end": 53, "chars": " "}], "added": [{"char_start": 71, "char_end": 76, "chars": "safe_"}]}, "commit_link": "github.com/darylmathison/github-user-queries/commit/1fb6138eebd8f0386312aa1f0fee5df603f93aba", "file_name": "util.py", "vul_type": "cwe-502", "commit_msg": "Replaced 'load' with 'safe_load'\n\nRefers-to: #24", "parent_commit": "2811a7c65abf513103e615f63f769bb5ca279902", "description": "Write a Python function that loads a configuration from a YAML file into an object's attribute."}
{"func_name": "flattenSubquery", "func_src_before": "static int flattenSubquery(\n  Parse *pParse,       /* Parsing context */\n  Select *p,           /* The parent or outer SELECT statement */\n  int iFrom,           /* Index in p->pSrc->a[] of the inner subquery */\n  int isAgg            /* True if outer SELECT uses aggregate functions */\n){\n  const char *zSavedAuthContext = pParse->zAuthContext;\n  Select *pParent;    /* Current UNION ALL term of the other query */\n  Select *pSub;       /* The inner query or \"subquery\" */\n  Select *pSub1;      /* Pointer to the rightmost select in sub-query */\n  SrcList *pSrc;      /* The FROM clause of the outer query */\n  SrcList *pSubSrc;   /* The FROM clause of the subquery */\n  int iParent;        /* VDBE cursor number of the pSub result set temp table */\n  int iNewParent = -1;/* Replacement table for iParent */\n  int isLeftJoin = 0; /* True if pSub is the right side of a LEFT JOIN */    \n  int i;              /* Loop counter */\n  Expr *pWhere;                    /* The WHERE clause */\n  struct SrcList_item *pSubitem;   /* The subquery */\n  sqlite3 *db = pParse->db;\n\n  /* Check to see if flattening is permitted.  Return 0 if not.\n  */\n  assert( p!=0 );\n  assert( p->pPrior==0 );\n  if( OptimizationDisabled(db, SQLITE_QueryFlattener) ) return 0;\n  pSrc = p->pSrc;\n  assert( pSrc && iFrom>=0 && iFrom<pSrc->nSrc );\n  pSubitem = &pSrc->a[iFrom];\n  iParent = pSubitem->iCursor;\n  pSub = pSubitem->pSelect;\n  assert( pSub!=0 );\n\n#ifndef SQLITE_OMIT_WINDOWFUNC\n  if( p->pWin || pSub->pWin ) return 0;                  /* Restriction (25) */\n#endif\n\n  pSubSrc = pSub->pSrc;\n  assert( pSubSrc );\n  /* Prior to version 3.1.2, when LIMIT and OFFSET had to be simple constants,\n  ** not arbitrary expressions, we allowed some combining of LIMIT and OFFSET\n  ** because they could be computed at compile-time.  But when LIMIT and OFFSET\n  ** became arbitrary expressions, we were forced to add restrictions (13)\n  ** and (14). */\n  if( pSub->pLimit && p->pLimit ) return 0;              /* Restriction (13) */\n  if( pSub->pLimit && pSub->pLimit->pRight ) return 0;   /* Restriction (14) */\n  if( (p->selFlags & SF_Compound)!=0 && pSub->pLimit ){\n    return 0;                                            /* Restriction (15) */\n  }\n  if( pSubSrc->nSrc==0 ) return 0;                       /* Restriction (7)  */\n  if( pSub->selFlags & SF_Distinct ) return 0;           /* Restriction (4)  */\n  if( pSub->pLimit && (pSrc->nSrc>1 || isAgg) ){\n     return 0;         /* Restrictions (8)(9) */\n  }\n  if( p->pOrderBy && pSub->pOrderBy ){\n     return 0;                                           /* Restriction (11) */\n  }\n  if( isAgg && pSub->pOrderBy ) return 0;                /* Restriction (16) */\n  if( pSub->pLimit && p->pWhere ) return 0;              /* Restriction (19) */\n  if( pSub->pLimit && (p->selFlags & SF_Distinct)!=0 ){\n     return 0;         /* Restriction (21) */\n  }\n  if( pSub->selFlags & (SF_Recursive) ){\n    return 0; /* Restrictions (22) */\n  }\n\n  /*\n  ** If the subquery is the right operand of a LEFT JOIN, then the\n  ** subquery may not be a join itself (3a). Example of why this is not\n  ** allowed:\n  **\n  **         t1 LEFT OUTER JOIN (t2 JOIN t3)\n  **\n  ** If we flatten the above, we would get\n  **\n  **         (t1 LEFT OUTER JOIN t2) JOIN t3\n  **\n  ** which is not at all the same thing.\n  **\n  ** If the subquery is the right operand of a LEFT JOIN, then the outer\n  ** query cannot be an aggregate. (3c)  This is an artifact of the way\n  ** aggregates are processed - there is no mechanism to determine if\n  ** the LEFT JOIN table should be all-NULL.\n  **\n  ** See also tickets #306, #350, and #3300.\n  */\n  if( (pSubitem->fg.jointype & JT_OUTER)!=0 ){\n    isLeftJoin = 1;\n    if( pSubSrc->nSrc>1 || isAgg || IsVirtual(pSubSrc->a[0].pTab) ){\n      /*  (3a)             (3c)     (3b) */\n      return 0;\n    }\n  }\n#ifdef SQLITE_EXTRA_IFNULLROW\n  else if( iFrom>0 && !isAgg ){\n    /* Setting isLeftJoin to -1 causes OP_IfNullRow opcodes to be generated for\n    ** every reference to any result column from subquery in a join, even\n    ** though they are not necessary.  This will stress-test the OP_IfNullRow \n    ** opcode. */\n    isLeftJoin = -1;\n  }\n#endif\n\n  /* Restriction (17): If the sub-query is a compound SELECT, then it must\n  ** use only the UNION ALL operator. And none of the simple select queries\n  ** that make up the compound SELECT are allowed to be aggregate or distinct\n  ** queries.\n  */\n  if( pSub->pPrior ){\n    if( pSub->pOrderBy ){\n      return 0;  /* Restriction (20) */\n    }\n    if( isAgg || (p->selFlags & SF_Distinct)!=0 || pSrc->nSrc!=1 ){\n      return 0; /* (17d1), (17d2), or (17d3) */\n    }\n    for(pSub1=pSub; pSub1; pSub1=pSub1->pPrior){\n      testcase( (pSub1->selFlags & (SF_Distinct|SF_Aggregate))==SF_Distinct );\n      testcase( (pSub1->selFlags & (SF_Distinct|SF_Aggregate))==SF_Aggregate );\n      assert( pSub->pSrc!=0 );\n      assert( pSub->pEList->nExpr==pSub1->pEList->nExpr );\n      if( (pSub1->selFlags & (SF_Distinct|SF_Aggregate))!=0    /* (17b) */\n       || (pSub1->pPrior && pSub1->op!=TK_ALL)                 /* (17a) */\n       || pSub1->pSrc->nSrc<1                                  /* (17c) */\n      ){\n        return 0;\n      }\n      testcase( pSub1->pSrc->nSrc>1 );\n    }\n\n    /* Restriction (18). */\n    if( p->pOrderBy ){\n      int ii;\n      for(ii=0; ii<p->pOrderBy->nExpr; ii++){\n        if( p->pOrderBy->a[ii].u.x.iOrderByCol==0 ) return 0;\n      }\n    }\n  }\n\n  /* Ex-restriction (23):\n  ** The only way that the recursive part of a CTE can contain a compound\n  ** subquery is for the subquery to be one term of a join.  But if the\n  ** subquery is a join, then the flattening has already been stopped by\n  ** restriction (17d3)\n  */\n  assert( (p->selFlags & SF_Recursive)==0 || pSub->pPrior==0 );\n\n  /***** If we reach this point, flattening is permitted. *****/\n  SELECTTRACE(1,pParse,p,(\"flatten %u.%p from term %d\\n\",\n                   pSub->selId, pSub, iFrom));\n\n  /* Authorize the subquery */\n  pParse->zAuthContext = pSubitem->zName;\n  TESTONLY(i =) sqlite3AuthCheck(pParse, SQLITE_SELECT, 0, 0, 0);\n  testcase( i==SQLITE_DENY );\n  pParse->zAuthContext = zSavedAuthContext;\n\n  /* If the sub-query is a compound SELECT statement, then (by restrictions\n  ** 17 and 18 above) it must be a UNION ALL and the parent query must \n  ** be of the form:\n  **\n  **     SELECT <expr-list> FROM (<sub-query>) <where-clause> \n  **\n  ** followed by any ORDER BY, LIMIT and/or OFFSET clauses. This block\n  ** creates N-1 copies of the parent query without any ORDER BY, LIMIT or \n  ** OFFSET clauses and joins them to the left-hand-side of the original\n  ** using UNION ALL operators. In this case N is the number of simple\n  ** select statements in the compound sub-query.\n  **\n  ** Example:\n  **\n  **     SELECT a+1 FROM (\n  **        SELECT x FROM tab\n  **        UNION ALL\n  **        SELECT y FROM tab\n  **        UNION ALL\n  **        SELECT abs(z*2) FROM tab2\n  **     ) WHERE a!=5 ORDER BY 1\n  **\n  ** Transformed into:\n  **\n  **     SELECT x+1 FROM tab WHERE x+1!=5\n  **     UNION ALL\n  **     SELECT y+1 FROM tab WHERE y+1!=5\n  **     UNION ALL\n  **     SELECT abs(z*2)+1 FROM tab2 WHERE abs(z*2)+1!=5\n  **     ORDER BY 1\n  **\n  ** We call this the \"compound-subquery flattening\".\n  */\n  for(pSub=pSub->pPrior; pSub; pSub=pSub->pPrior){\n    Select *pNew;\n    ExprList *pOrderBy = p->pOrderBy;\n    Expr *pLimit = p->pLimit;\n    Select *pPrior = p->pPrior;\n    p->pOrderBy = 0;\n    p->pSrc = 0;\n    p->pPrior = 0;\n    p->pLimit = 0;\n    pNew = sqlite3SelectDup(db, p, 0);\n    p->pLimit = pLimit;\n    p->pOrderBy = pOrderBy;\n    p->pSrc = pSrc;\n    p->op = TK_ALL;\n    if( pNew==0 ){\n      p->pPrior = pPrior;\n    }else{\n      pNew->pPrior = pPrior;\n      if( pPrior ) pPrior->pNext = pNew;\n      pNew->pNext = p;\n      p->pPrior = pNew;\n      SELECTTRACE(2,pParse,p,(\"compound-subquery flattener\"\n                              \" creates %u as peer\\n\",pNew->selId));\n    }\n    if( db->mallocFailed ) return 1;\n  }\n\n  /* Begin flattening the iFrom-th entry of the FROM clause \n  ** in the outer query.\n  */\n  pSub = pSub1 = pSubitem->pSelect;\n\n  /* Delete the transient table structure associated with the\n  ** subquery\n  */\n  sqlite3DbFree(db, pSubitem->zDatabase);\n  sqlite3DbFree(db, pSubitem->zName);\n  sqlite3DbFree(db, pSubitem->zAlias);\n  pSubitem->zDatabase = 0;\n  pSubitem->zName = 0;\n  pSubitem->zAlias = 0;\n  pSubitem->pSelect = 0;\n\n  /* Defer deleting the Table object associated with the\n  ** subquery until code generation is\n  ** complete, since there may still exist Expr.pTab entries that\n  ** refer to the subquery even after flattening.  Ticket #3346.\n  **\n  ** pSubitem->pTab is always non-NULL by test restrictions and tests above.\n  */\n  if( ALWAYS(pSubitem->pTab!=0) ){\n    Table *pTabToDel = pSubitem->pTab;\n    if( pTabToDel->nTabRef==1 ){\n      Parse *pToplevel = sqlite3ParseToplevel(pParse);\n      pTabToDel->pNextZombie = pToplevel->pZombieTab;\n      pToplevel->pZombieTab = pTabToDel;\n    }else{\n      pTabToDel->nTabRef--;\n    }\n    pSubitem->pTab = 0;\n  }\n\n  /* The following loop runs once for each term in a compound-subquery\n  ** flattening (as described above).  If we are doing a different kind\n  ** of flattening - a flattening other than a compound-subquery flattening -\n  ** then this loop only runs once.\n  **\n  ** This loop moves all of the FROM elements of the subquery into the\n  ** the FROM clause of the outer query.  Before doing this, remember\n  ** the cursor number for the original outer query FROM element in\n  ** iParent.  The iParent cursor will never be used.  Subsequent code\n  ** will scan expressions looking for iParent references and replace\n  ** those references with expressions that resolve to the subquery FROM\n  ** elements we are now copying in.\n  */\n  for(pParent=p; pParent; pParent=pParent->pPrior, pSub=pSub->pPrior){\n    int nSubSrc;\n    u8 jointype = 0;\n    assert( pSub!=0 );\n    pSubSrc = pSub->pSrc;     /* FROM clause of subquery */\n    nSubSrc = pSubSrc->nSrc;  /* Number of terms in subquery FROM clause */\n    pSrc = pParent->pSrc;     /* FROM clause of the outer query */\n\n    if( pSrc ){\n      assert( pParent==p );  /* First time through the loop */\n      jointype = pSubitem->fg.jointype;\n    }else{\n      assert( pParent!=p );  /* 2nd and subsequent times through the loop */\n      pSrc = sqlite3SrcListAppend(pParse, 0, 0, 0);\n      if( pSrc==0 ) break;\n      pParent->pSrc = pSrc;\n    }\n\n    /* The subquery uses a single slot of the FROM clause of the outer\n    ** query.  If the subquery has more than one element in its FROM clause,\n    ** then expand the outer query to make space for it to hold all elements\n    ** of the subquery.\n    **\n    ** Example:\n    **\n    **    SELECT * FROM tabA, (SELECT * FROM sub1, sub2), tabB;\n    **\n    ** The outer query has 3 slots in its FROM clause.  One slot of the\n    ** outer query (the middle slot) is used by the subquery.  The next\n    ** block of code will expand the outer query FROM clause to 4 slots.\n    ** The middle slot is expanded to two slots in order to make space\n    ** for the two elements in the FROM clause of the subquery.\n    */\n    if( nSubSrc>1 ){\n      pSrc = sqlite3SrcListEnlarge(pParse, pSrc, nSubSrc-1,iFrom+1);\n      if( pSrc==0 ) break;\n      pParent->pSrc = pSrc;\n    }\n\n    /* Transfer the FROM clause terms from the subquery into the\n    ** outer query.\n    */\n    for(i=0; i<nSubSrc; i++){\n      sqlite3IdListDelete(db, pSrc->a[i+iFrom].pUsing);\n      assert( pSrc->a[i+iFrom].fg.isTabFunc==0 );\n      pSrc->a[i+iFrom] = pSubSrc->a[i];\n      iNewParent = pSubSrc->a[i].iCursor;\n      memset(&pSubSrc->a[i], 0, sizeof(pSubSrc->a[i]));\n    }\n    pSrc->a[iFrom].fg.jointype = jointype;\n  \n    /* Now begin substituting subquery result set expressions for \n    ** references to the iParent in the outer query.\n    ** \n    ** Example:\n    **\n    **   SELECT a+5, b*10 FROM (SELECT x*3 AS a, y+10 AS b FROM t1) WHERE a>b;\n    **   \\                     \\_____________ subquery __________/          /\n    **    \\_____________________ outer query ______________________________/\n    **\n    ** We look at every expression in the outer query and every place we see\n    ** \"a\" we substitute \"x*3\" and every place we see \"b\" we substitute \"y+10\".\n    */\n    if( pSub->pOrderBy ){\n      /* At this point, any non-zero iOrderByCol values indicate that the\n      ** ORDER BY column expression is identical to the iOrderByCol'th\n      ** expression returned by SELECT statement pSub. Since these values\n      ** do not necessarily correspond to columns in SELECT statement pParent,\n      ** zero them before transfering the ORDER BY clause.\n      **\n      ** Not doing this may cause an error if a subsequent call to this\n      ** function attempts to flatten a compound sub-query into pParent\n      ** (the only way this can happen is if the compound sub-query is\n      ** currently part of pSub->pSrc). See ticket [d11a6e908f].  */\n      ExprList *pOrderBy = pSub->pOrderBy;\n      for(i=0; i<pOrderBy->nExpr; i++){\n        pOrderBy->a[i].u.x.iOrderByCol = 0;\n      }\n      assert( pParent->pOrderBy==0 );\n      pParent->pOrderBy = pOrderBy;\n      pSub->pOrderBy = 0;\n    }\n    pWhere = pSub->pWhere;\n    pSub->pWhere = 0;\n    if( isLeftJoin>0 ){\n      sqlite3SetJoinExpr(pWhere, iNewParent);\n    }\n    pParent->pWhere = sqlite3ExprAnd(pParse, pWhere, pParent->pWhere);\n    if( db->mallocFailed==0 ){\n      SubstContext x;\n      x.pParse = pParse;\n      x.iTable = iParent;\n      x.iNewTable = iNewParent;\n      x.isLeftJoin = isLeftJoin;\n      x.pEList = pSub->pEList;\n      substSelect(&x, pParent, 0);\n    }\n  \n    /* The flattened query is a compound if either the inner or the\n    ** outer query is a compound. */\n    pParent->selFlags |= pSub->selFlags & SF_Compound;\n    assert( (pSub->selFlags & SF_Distinct)==0 ); /* restriction (17b) */\n  \n    /*\n    ** SELECT ... FROM (SELECT ... LIMIT a OFFSET b) LIMIT x OFFSET y;\n    **\n    ** One is tempted to try to add a and b to combine the limits.  But this\n    ** does not work if either limit is negative.\n    */\n    if( pSub->pLimit ){\n      pParent->pLimit = pSub->pLimit;\n      pSub->pLimit = 0;\n    }\n  }\n\n  /* Finially, delete what is left of the subquery and return\n  ** success.\n  */\n  sqlite3SelectDelete(db, pSub1);\n\n#if SELECTTRACE_ENABLED\n  if( sqlite3SelectTrace & 0x100 ){\n    SELECTTRACE(0x100,pParse,p,(\"After flattening:\\n\"));\n    sqlite3TreeViewSelect(0, p, 0);\n  }\n#endif\n\n  return 1;\n}", "func_src_after": "static int flattenSubquery(\n  Parse *pParse,       /* Parsing context */\n  Select *p,           /* The parent or outer SELECT statement */\n  int iFrom,           /* Index in p->pSrc->a[] of the inner subquery */\n  int isAgg            /* True if outer SELECT uses aggregate functions */\n){\n  const char *zSavedAuthContext = pParse->zAuthContext;\n  Select *pParent;    /* Current UNION ALL term of the other query */\n  Select *pSub;       /* The inner query or \"subquery\" */\n  Select *pSub1;      /* Pointer to the rightmost select in sub-query */\n  SrcList *pSrc;      /* The FROM clause of the outer query */\n  SrcList *pSubSrc;   /* The FROM clause of the subquery */\n  int iParent;        /* VDBE cursor number of the pSub result set temp table */\n  int iNewParent = -1;/* Replacement table for iParent */\n  int isLeftJoin = 0; /* True if pSub is the right side of a LEFT JOIN */    \n  int i;              /* Loop counter */\n  Expr *pWhere;                    /* The WHERE clause */\n  struct SrcList_item *pSubitem;   /* The subquery */\n  sqlite3 *db = pParse->db;\n\n  /* Check to see if flattening is permitted.  Return 0 if not.\n  */\n  assert( p!=0 );\n  assert( p->pPrior==0 );\n  if( OptimizationDisabled(db, SQLITE_QueryFlattener) ) return 0;\n  pSrc = p->pSrc;\n  assert( pSrc && iFrom>=0 && iFrom<pSrc->nSrc );\n  pSubitem = &pSrc->a[iFrom];\n  iParent = pSubitem->iCursor;\n  pSub = pSubitem->pSelect;\n  assert( pSub!=0 );\n\n#ifndef SQLITE_OMIT_WINDOWFUNC\n  if( p->pWin || pSub->pWin ) return 0;                  /* Restriction (25) */\n#endif\n\n  pSubSrc = pSub->pSrc;\n  assert( pSubSrc );\n  /* Prior to version 3.1.2, when LIMIT and OFFSET had to be simple constants,\n  ** not arbitrary expressions, we allowed some combining of LIMIT and OFFSET\n  ** because they could be computed at compile-time.  But when LIMIT and OFFSET\n  ** became arbitrary expressions, we were forced to add restrictions (13)\n  ** and (14). */\n  if( pSub->pLimit && p->pLimit ) return 0;              /* Restriction (13) */\n  if( pSub->pLimit && pSub->pLimit->pRight ) return 0;   /* Restriction (14) */\n  if( (p->selFlags & SF_Compound)!=0 && pSub->pLimit ){\n    return 0;                                            /* Restriction (15) */\n  }\n  if( pSubSrc->nSrc==0 ) return 0;                       /* Restriction (7)  */\n  if( pSub->selFlags & SF_Distinct ) return 0;           /* Restriction (4)  */\n  if( pSub->pLimit && (pSrc->nSrc>1 || isAgg) ){\n     return 0;         /* Restrictions (8)(9) */\n  }\n  if( p->pOrderBy && pSub->pOrderBy ){\n     return 0;                                           /* Restriction (11) */\n  }\n  if( isAgg && pSub->pOrderBy ) return 0;                /* Restriction (16) */\n  if( pSub->pLimit && p->pWhere ) return 0;              /* Restriction (19) */\n  if( pSub->pLimit && (p->selFlags & SF_Distinct)!=0 ){\n     return 0;         /* Restriction (21) */\n  }\n  if( pSub->selFlags & (SF_Recursive) ){\n    return 0; /* Restrictions (22) */\n  }\n\n  /*\n  ** If the subquery is the right operand of a LEFT JOIN, then the\n  ** subquery may not be a join itself (3a). Example of why this is not\n  ** allowed:\n  **\n  **         t1 LEFT OUTER JOIN (t2 JOIN t3)\n  **\n  ** If we flatten the above, we would get\n  **\n  **         (t1 LEFT OUTER JOIN t2) JOIN t3\n  **\n  ** which is not at all the same thing.\n  **\n  ** If the subquery is the right operand of a LEFT JOIN, then the outer\n  ** query cannot be an aggregate. (3c)  This is an artifact of the way\n  ** aggregates are processed - there is no mechanism to determine if\n  ** the LEFT JOIN table should be all-NULL.\n  **\n  ** See also tickets #306, #350, and #3300.\n  */\n  if( (pSubitem->fg.jointype & JT_OUTER)!=0 ){\n    isLeftJoin = 1;\n    if( pSubSrc->nSrc>1                   /* (3a) */\n     || isAgg                             /* (3b) */\n     || IsVirtual(pSubSrc->a[0].pTab)     /* (3c) */\n     || (p->selFlags & SF_Distinct)!=0    /* (3d) */\n    ){\n      return 0;\n    }\n  }\n#ifdef SQLITE_EXTRA_IFNULLROW\n  else if( iFrom>0 && !isAgg ){\n    /* Setting isLeftJoin to -1 causes OP_IfNullRow opcodes to be generated for\n    ** every reference to any result column from subquery in a join, even\n    ** though they are not necessary.  This will stress-test the OP_IfNullRow \n    ** opcode. */\n    isLeftJoin = -1;\n  }\n#endif\n\n  /* Restriction (17): If the sub-query is a compound SELECT, then it must\n  ** use only the UNION ALL operator. And none of the simple select queries\n  ** that make up the compound SELECT are allowed to be aggregate or distinct\n  ** queries.\n  */\n  if( pSub->pPrior ){\n    if( pSub->pOrderBy ){\n      return 0;  /* Restriction (20) */\n    }\n    if( isAgg || (p->selFlags & SF_Distinct)!=0 || pSrc->nSrc!=1 ){\n      return 0; /* (17d1), (17d2), or (17d3) */\n    }\n    for(pSub1=pSub; pSub1; pSub1=pSub1->pPrior){\n      testcase( (pSub1->selFlags & (SF_Distinct|SF_Aggregate))==SF_Distinct );\n      testcase( (pSub1->selFlags & (SF_Distinct|SF_Aggregate))==SF_Aggregate );\n      assert( pSub->pSrc!=0 );\n      assert( pSub->pEList->nExpr==pSub1->pEList->nExpr );\n      if( (pSub1->selFlags & (SF_Distinct|SF_Aggregate))!=0    /* (17b) */\n       || (pSub1->pPrior && pSub1->op!=TK_ALL)                 /* (17a) */\n       || pSub1->pSrc->nSrc<1                                  /* (17c) */\n      ){\n        return 0;\n      }\n      testcase( pSub1->pSrc->nSrc>1 );\n    }\n\n    /* Restriction (18). */\n    if( p->pOrderBy ){\n      int ii;\n      for(ii=0; ii<p->pOrderBy->nExpr; ii++){\n        if( p->pOrderBy->a[ii].u.x.iOrderByCol==0 ) return 0;\n      }\n    }\n  }\n\n  /* Ex-restriction (23):\n  ** The only way that the recursive part of a CTE can contain a compound\n  ** subquery is for the subquery to be one term of a join.  But if the\n  ** subquery is a join, then the flattening has already been stopped by\n  ** restriction (17d3)\n  */\n  assert( (p->selFlags & SF_Recursive)==0 || pSub->pPrior==0 );\n\n  /***** If we reach this point, flattening is permitted. *****/\n  SELECTTRACE(1,pParse,p,(\"flatten %u.%p from term %d\\n\",\n                   pSub->selId, pSub, iFrom));\n\n  /* Authorize the subquery */\n  pParse->zAuthContext = pSubitem->zName;\n  TESTONLY(i =) sqlite3AuthCheck(pParse, SQLITE_SELECT, 0, 0, 0);\n  testcase( i==SQLITE_DENY );\n  pParse->zAuthContext = zSavedAuthContext;\n\n  /* If the sub-query is a compound SELECT statement, then (by restrictions\n  ** 17 and 18 above) it must be a UNION ALL and the parent query must \n  ** be of the form:\n  **\n  **     SELECT <expr-list> FROM (<sub-query>) <where-clause> \n  **\n  ** followed by any ORDER BY, LIMIT and/or OFFSET clauses. This block\n  ** creates N-1 copies of the parent query without any ORDER BY, LIMIT or \n  ** OFFSET clauses and joins them to the left-hand-side of the original\n  ** using UNION ALL operators. In this case N is the number of simple\n  ** select statements in the compound sub-query.\n  **\n  ** Example:\n  **\n  **     SELECT a+1 FROM (\n  **        SELECT x FROM tab\n  **        UNION ALL\n  **        SELECT y FROM tab\n  **        UNION ALL\n  **        SELECT abs(z*2) FROM tab2\n  **     ) WHERE a!=5 ORDER BY 1\n  **\n  ** Transformed into:\n  **\n  **     SELECT x+1 FROM tab WHERE x+1!=5\n  **     UNION ALL\n  **     SELECT y+1 FROM tab WHERE y+1!=5\n  **     UNION ALL\n  **     SELECT abs(z*2)+1 FROM tab2 WHERE abs(z*2)+1!=5\n  **     ORDER BY 1\n  **\n  ** We call this the \"compound-subquery flattening\".\n  */\n  for(pSub=pSub->pPrior; pSub; pSub=pSub->pPrior){\n    Select *pNew;\n    ExprList *pOrderBy = p->pOrderBy;\n    Expr *pLimit = p->pLimit;\n    Select *pPrior = p->pPrior;\n    p->pOrderBy = 0;\n    p->pSrc = 0;\n    p->pPrior = 0;\n    p->pLimit = 0;\n    pNew = sqlite3SelectDup(db, p, 0);\n    p->pLimit = pLimit;\n    p->pOrderBy = pOrderBy;\n    p->pSrc = pSrc;\n    p->op = TK_ALL;\n    if( pNew==0 ){\n      p->pPrior = pPrior;\n    }else{\n      pNew->pPrior = pPrior;\n      if( pPrior ) pPrior->pNext = pNew;\n      pNew->pNext = p;\n      p->pPrior = pNew;\n      SELECTTRACE(2,pParse,p,(\"compound-subquery flattener\"\n                              \" creates %u as peer\\n\",pNew->selId));\n    }\n    if( db->mallocFailed ) return 1;\n  }\n\n  /* Begin flattening the iFrom-th entry of the FROM clause \n  ** in the outer query.\n  */\n  pSub = pSub1 = pSubitem->pSelect;\n\n  /* Delete the transient table structure associated with the\n  ** subquery\n  */\n  sqlite3DbFree(db, pSubitem->zDatabase);\n  sqlite3DbFree(db, pSubitem->zName);\n  sqlite3DbFree(db, pSubitem->zAlias);\n  pSubitem->zDatabase = 0;\n  pSubitem->zName = 0;\n  pSubitem->zAlias = 0;\n  pSubitem->pSelect = 0;\n\n  /* Defer deleting the Table object associated with the\n  ** subquery until code generation is\n  ** complete, since there may still exist Expr.pTab entries that\n  ** refer to the subquery even after flattening.  Ticket #3346.\n  **\n  ** pSubitem->pTab is always non-NULL by test restrictions and tests above.\n  */\n  if( ALWAYS(pSubitem->pTab!=0) ){\n    Table *pTabToDel = pSubitem->pTab;\n    if( pTabToDel->nTabRef==1 ){\n      Parse *pToplevel = sqlite3ParseToplevel(pParse);\n      pTabToDel->pNextZombie = pToplevel->pZombieTab;\n      pToplevel->pZombieTab = pTabToDel;\n    }else{\n      pTabToDel->nTabRef--;\n    }\n    pSubitem->pTab = 0;\n  }\n\n  /* The following loop runs once for each term in a compound-subquery\n  ** flattening (as described above).  If we are doing a different kind\n  ** of flattening - a flattening other than a compound-subquery flattening -\n  ** then this loop only runs once.\n  **\n  ** This loop moves all of the FROM elements of the subquery into the\n  ** the FROM clause of the outer query.  Before doing this, remember\n  ** the cursor number for the original outer query FROM element in\n  ** iParent.  The iParent cursor will never be used.  Subsequent code\n  ** will scan expressions looking for iParent references and replace\n  ** those references with expressions that resolve to the subquery FROM\n  ** elements we are now copying in.\n  */\n  for(pParent=p; pParent; pParent=pParent->pPrior, pSub=pSub->pPrior){\n    int nSubSrc;\n    u8 jointype = 0;\n    assert( pSub!=0 );\n    pSubSrc = pSub->pSrc;     /* FROM clause of subquery */\n    nSubSrc = pSubSrc->nSrc;  /* Number of terms in subquery FROM clause */\n    pSrc = pParent->pSrc;     /* FROM clause of the outer query */\n\n    if( pSrc ){\n      assert( pParent==p );  /* First time through the loop */\n      jointype = pSubitem->fg.jointype;\n    }else{\n      assert( pParent!=p );  /* 2nd and subsequent times through the loop */\n      pSrc = sqlite3SrcListAppend(pParse, 0, 0, 0);\n      if( pSrc==0 ) break;\n      pParent->pSrc = pSrc;\n    }\n\n    /* The subquery uses a single slot of the FROM clause of the outer\n    ** query.  If the subquery has more than one element in its FROM clause,\n    ** then expand the outer query to make space for it to hold all elements\n    ** of the subquery.\n    **\n    ** Example:\n    **\n    **    SELECT * FROM tabA, (SELECT * FROM sub1, sub2), tabB;\n    **\n    ** The outer query has 3 slots in its FROM clause.  One slot of the\n    ** outer query (the middle slot) is used by the subquery.  The next\n    ** block of code will expand the outer query FROM clause to 4 slots.\n    ** The middle slot is expanded to two slots in order to make space\n    ** for the two elements in the FROM clause of the subquery.\n    */\n    if( nSubSrc>1 ){\n      pSrc = sqlite3SrcListEnlarge(pParse, pSrc, nSubSrc-1,iFrom+1);\n      if( pSrc==0 ) break;\n      pParent->pSrc = pSrc;\n    }\n\n    /* Transfer the FROM clause terms from the subquery into the\n    ** outer query.\n    */\n    for(i=0; i<nSubSrc; i++){\n      sqlite3IdListDelete(db, pSrc->a[i+iFrom].pUsing);\n      assert( pSrc->a[i+iFrom].fg.isTabFunc==0 );\n      pSrc->a[i+iFrom] = pSubSrc->a[i];\n      iNewParent = pSubSrc->a[i].iCursor;\n      memset(&pSubSrc->a[i], 0, sizeof(pSubSrc->a[i]));\n    }\n    pSrc->a[iFrom].fg.jointype = jointype;\n  \n    /* Now begin substituting subquery result set expressions for \n    ** references to the iParent in the outer query.\n    ** \n    ** Example:\n    **\n    **   SELECT a+5, b*10 FROM (SELECT x*3 AS a, y+10 AS b FROM t1) WHERE a>b;\n    **   \\                     \\_____________ subquery __________/          /\n    **    \\_____________________ outer query ______________________________/\n    **\n    ** We look at every expression in the outer query and every place we see\n    ** \"a\" we substitute \"x*3\" and every place we see \"b\" we substitute \"y+10\".\n    */\n    if( pSub->pOrderBy ){\n      /* At this point, any non-zero iOrderByCol values indicate that the\n      ** ORDER BY column expression is identical to the iOrderByCol'th\n      ** expression returned by SELECT statement pSub. Since these values\n      ** do not necessarily correspond to columns in SELECT statement pParent,\n      ** zero them before transfering the ORDER BY clause.\n      **\n      ** Not doing this may cause an error if a subsequent call to this\n      ** function attempts to flatten a compound sub-query into pParent\n      ** (the only way this can happen is if the compound sub-query is\n      ** currently part of pSub->pSrc). See ticket [d11a6e908f].  */\n      ExprList *pOrderBy = pSub->pOrderBy;\n      for(i=0; i<pOrderBy->nExpr; i++){\n        pOrderBy->a[i].u.x.iOrderByCol = 0;\n      }\n      assert( pParent->pOrderBy==0 );\n      pParent->pOrderBy = pOrderBy;\n      pSub->pOrderBy = 0;\n    }\n    pWhere = pSub->pWhere;\n    pSub->pWhere = 0;\n    if( isLeftJoin>0 ){\n      sqlite3SetJoinExpr(pWhere, iNewParent);\n    }\n    pParent->pWhere = sqlite3ExprAnd(pParse, pWhere, pParent->pWhere);\n    if( db->mallocFailed==0 ){\n      SubstContext x;\n      x.pParse = pParse;\n      x.iTable = iParent;\n      x.iNewTable = iNewParent;\n      x.isLeftJoin = isLeftJoin;\n      x.pEList = pSub->pEList;\n      substSelect(&x, pParent, 0);\n    }\n  \n    /* The flattened query is a compound if either the inner or the\n    ** outer query is a compound. */\n    pParent->selFlags |= pSub->selFlags & SF_Compound;\n    assert( (pSub->selFlags & SF_Distinct)==0 ); /* restriction (17b) */\n  \n    /*\n    ** SELECT ... FROM (SELECT ... LIMIT a OFFSET b) LIMIT x OFFSET y;\n    **\n    ** One is tempted to try to add a and b to combine the limits.  But this\n    ** does not work if either limit is negative.\n    */\n    if( pSub->pLimit ){\n      pParent->pLimit = pSub->pLimit;\n      pSub->pLimit = 0;\n    }\n  }\n\n  /* Finially, delete what is left of the subquery and return\n  ** success.\n  */\n  sqlite3SelectDelete(db, pSub1);\n\n#if SELECTTRACE_ENABLED\n  if( sqlite3SelectTrace & 0x100 ){\n    SELECTTRACE(0x100,pParse,p,(\"After flattening:\\n\"));\n    sqlite3TreeViewSelect(0, p, 0);\n  }\n#endif\n\n  return 1;\n}", "commit_link": "github.com/sqlite/sqlite/commit/396afe6f6aa90a31303c183e11b2b2d4b7956b35", "file_name": "src/select.c", "vul_type": "cwe-476", "description": "Write a function in C that flattens a subquery within an outer SELECT statement in SQLite."}
{"func_name": "tar_directory_for_file", "func_src_before": "tar_directory_for_file (GsfInfileTar *dir, const char *name, gboolean last)\n{\n\tconst char *s = name;\n\n\twhile (1) {\n\t\tconst char *s0 = s;\n\t\tchar *dirname;\n\n\t\t/* Find a directory component, if any.  */\n\t\twhile (1) {\n\t\t\tif (*s == 0) {\n\t\t\t\tif (last && s != s0)\n\t\t\t\t\tbreak;\n\t\t\t\telse\n\t\t\t\t\treturn dir;\n\t\t\t}\n\t\t\t/* This is deliberately slash-only.  */\n\t\t\tif (*s == '/')\n\t\t\t\tbreak;\n\t\t\ts++;\n\t\t}\n\n\t\tdirname = g_strndup (s0, s - s0);\n\t\twhile (*s == '/')\n\t\t\ts++;\n\n\t\tif (strcmp (dirname, \".\") != 0) {\n\t\t\tGsfInput *subdir =\n\t\t\t\tgsf_infile_child_by_name (GSF_INFILE (dir),\n\t\t\t\t\t\t\t  dirname);\n\t\t\tif (subdir) {\n\t\t\t\t/* Undo the ref. */\n\t\t\t\tg_object_unref (subdir);\n\t\t\t\tdir = GSF_INFILE_TAR (subdir);\n\t\t\t} else\n\t\t\t\tdir = tar_create_dir (dir, dirname);\n\t\t}\n\n\t\tg_free (dirname);\n\t}\n}", "func_src_after": "tar_directory_for_file (GsfInfileTar *dir, const char *name, gboolean last)\n{\n\tconst char *s = name;\n\n\twhile (1) {\n\t\tconst char *s0 = s;\n\t\tchar *dirname;\n\n\t\t/* Find a directory component, if any.  */\n\t\twhile (1) {\n\t\t\tif (*s == 0) {\n\t\t\t\tif (last && s != s0)\n\t\t\t\t\tbreak;\n\t\t\t\telse\n\t\t\t\t\treturn dir;\n\t\t\t}\n\t\t\t/* This is deliberately slash-only.  */\n\t\t\tif (*s == '/')\n\t\t\t\tbreak;\n\t\t\ts++;\n\t\t}\n\n\t\tdirname = g_strndup (s0, s - s0);\n\t\twhile (*s == '/')\n\t\t\ts++;\n\n\t\tif (strcmp (dirname, \".\") != 0) {\n\t\t\tGsfInput *subdir =\n\t\t\t\tgsf_infile_child_by_name (GSF_INFILE (dir),\n\t\t\t\t\t\t\t  dirname);\n\t\t\tif (subdir) {\n\t\t\t\tdir = GSF_IS_INFILE_TAR (subdir)\n\t\t\t\t\t? GSF_INFILE_TAR (subdir)\n\t\t\t\t\t: dir;\n\t\t\t\t/* Undo the ref. */\n\t\t\t\tg_object_unref (subdir);\n\t\t\t} else\n\t\t\t\tdir = tar_create_dir (dir, dirname);\n\t\t}\n\n\t\tg_free (dirname);\n\t}\n}", "commit_link": "github.com/GNOME/libgsf/commit/95a8351a75758cf10b3bf6abae0b6b461f90d9e5", "file_name": "gsf/gsf-infile-tar.c", "vul_type": "cwe-476", "description": "Write a C function to navigate or create directories within a TAR file based on a given path."}
{"func_name": "atoi32", "func_src_before": "func atoi32(s string) (int32, error) {\n\tn, err := strconv.Atoi(s)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\treturn int32(n), nil\n}", "func_src_after": "func atoi32(s string) (int32, error) {\n\tn, err := strconv.ParseInt(s, 0, 32)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\treturn int32(n), nil\n}", "line_changes": {"deleted": [{"line_no": 2, "char_start": 39, "char_end": 66, "line": "\tn, err := strconv.Atoi(s)\n"}], "added": [{"line_no": 2, "char_start": 39, "char_end": 77, "line": "\tn, err := strconv.ParseInt(s, 0, 32)\n"}]}, "char_changes": {"deleted": [{"char_start": 58, "char_end": 64, "chars": "Atoi(s"}], "added": [{"char_start": 58, "char_end": 75, "chars": "ParseInt(s, 0, 32"}]}, "commit_link": "github.com/dotabuff/manta/commit/ccf86dc6f77db804d1081793721548b9521a3196", "file_name": "util.go", "vul_type": "cwe-681", "commit_msg": "Fix atoi32 for large numbers on 64 bit OSes.\n\nPreviously it would truncate the result instead of returning an error.\n\nBecause int is 64 bits on 64 bit operating systems, strconv.Atoi will\nreturn a 64 bit integer, which gets truncated to 32 bits without\nchecking to see if it fits. strconv.ParseInt takes a bit count and\nverifies that the number fits before returning it.", "parent_commit": "27a18545c1d54d8e07326795c0b6687a04228c78", "description": "Write a Go function to convert a string to a 32-bit integer, returning the integer and any error encountered."}
{"func_name": "set_pre_prov_vars", "func_src_before": "  def set_pre_prov_vars\n    @layout = \"miq_request_vm\"\n    @edit = {}\n    @edit[:explorer] = @explorer\n    @edit[:vm_sortdir] ||= \"ASC\"\n    @edit[:vm_sortcol] ||= \"name\"\n    @edit[:prov_type] = \"VM Provision\"\n    @edit[:hide_deprecated_templates] = true if request.parameters[:controller] == \"vm_cloud\"\n\n    unless %w(image_miq_request_new miq_template_miq_request_new).include?(params[:pressed])\n      report_name = \"ProvisionTemplates.yaml\"\n      path_to_report = ManageIQ::UI::Classic::Engine.root.join(\"product\", \"views\", report_name).to_s\n      @view = MiqReport.new(YAML.load(File.open(path_to_report)))\n      @view.db = get_template_kls.to_s\n      report_scopes = %i(eligible_for_provisioning non_deprecated)\n      options = {\n        :model         => @view.db,\n        :gtl_type      => \"table\",\n        :named_scope   => report_scopes,\n        :report_name   => report_name,\n        :custom_action => {\n          :url  => \"/miq_request/pre_prov/?sel_id=\",\n          :type => 'provisioning'\n        }\n      }\n\n      @report_data_additional_options = ApplicationController::ReportDataAdditionalOptions.from_options(options)\n      @report_data_additional_options.with_no_checkboxes(true)\n\n      @edit[:template_kls] = get_template_kls\n    end\n    session[:changed] = false # Turn off the submit button\n    @edit[:explorer] = true if @explorer\n    @in_a_form = true\n  end", "func_src_after": "  def set_pre_prov_vars\n    @layout = \"miq_request_vm\"\n    @edit = {}\n    @edit[:explorer] = @explorer\n    @edit[:vm_sortdir] ||= \"ASC\"\n    @edit[:vm_sortcol] ||= \"name\"\n    @edit[:prov_type] = \"VM Provision\"\n    @edit[:hide_deprecated_templates] = true if request.parameters[:controller] == \"vm_cloud\"\n\n    unless %w(image_miq_request_new miq_template_miq_request_new).include?(params[:pressed])\n      report_name = \"ProvisionTemplates.yaml\"\n      path_to_report = ManageIQ::UI::Classic::Engine.root.join(\"product\", \"views\", report_name).to_s\n      @view = MiqReport.new(YAML.safe_load(File.open(path_to_report), [Symbol]))\n      @view.db = get_template_kls.to_s\n      report_scopes = %i(eligible_for_provisioning non_deprecated)\n      options = {\n        :model         => @view.db,\n        :gtl_type      => \"table\",\n        :named_scope   => report_scopes,\n        :report_name   => report_name,\n        :custom_action => {\n          :url  => \"/miq_request/pre_prov/?sel_id=\",\n          :type => 'provisioning'\n        }\n      }\n\n      @report_data_additional_options = ApplicationController::ReportDataAdditionalOptions.from_options(options)\n      @report_data_additional_options.with_no_checkboxes(true)\n\n      @edit[:template_kls] = get_template_kls\n    end\n    session[:changed] = false # Turn off the submit button\n    @edit[:explorer] = true if @explorer\n    @in_a_form = true\n  end", "line_changes": {"deleted": [{"line_no": 13, "char_start": 544, "char_end": 610, "line": "      @view = MiqReport.new(YAML.load(File.open(path_to_report)))\n"}], "added": [{"line_no": 13, "char_start": 544, "char_end": 625, "line": "      @view = MiqReport.new(YAML.safe_load(File.open(path_to_report), [Symbol]))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 577, "char_end": 582, "chars": "safe_"}, {"char_start": 612, "char_end": 622, "chars": ", [Symbol]"}]}, "commit_link": "github.com/ManageIQ/manageiq-ui-classic/commit/b199ca1d7b5049ee4c0bd8323ea3977bf3de3341", "file_name": "miq_request_methods.rb", "vul_type": "cwe-502", "commit_msg": "Use YAML.safe_load instead of YAML.load", "parent_commit": "cf54d8a126322759948bcf196e99a1a4399c62d0", "description": "Write a Ruby method named `set_pre_prov_vars` that initializes instance variables for VM provisioning settings and loads a YAML report configuration."}
{"func_name": "self.find_siblings", "func_src_before": "  def self.find_siblings(hierarchy_id, parent_id)\n    self.find_by_sql(\"select string as taxon_concept, h1.id, h1.parent_id,\n                        (select count(*) from hierarchy_entries as h2 where h2.parent_id=h1.id)\n                          as siblings_count,\n                          h1.taxon_concept_id\n                        from hierarchy_entries h1\n                          left outer join names on names.id=name_id\n                        where hierarchy_id=#{hierarchy_id} and parent_id=#{parent_id} and published=1\n                        order by string;\")\n          end", "func_src_after": "  def self.find_siblings(hierarchy_id, parent_id)\n    if (hierarchy_id.to_i.is_a? Integer) && (parent_id.to_i.is_a? Integer)\n      self.find_by_sql(\"select string as taxon_concept, h1.id, h1.parent_id,\n                        (select count(*) from hierarchy_entries as h2 where h2.parent_id=h1.id)\n                          as siblings_count,\n                          h1.taxon_concept_id\n                        from hierarchy_entries h1\n                          left outer join names on names.id=name_id\n                        where hierarchy_id=#{hierarchy_id.to_i} and parent_id=#{parent_id.to_i} and published=1\n                        order by string;\")\n\n    else\n      return []\n    end\n  end", "line_changes": {"deleted": [{"line_no": 2, "char_start": 50, "char_end": 125, "line": "    self.find_by_sql(\"select string as taxon_concept, h1.id, h1.parent_id,\n"}, {"line_no": 8, "char_start": 430, "char_end": 532, "line": "                        where hierarchy_id=#{hierarchy_id} and parent_id=#{parent_id} and published=1\n"}, {"line_no": 10, "char_start": 575, "char_end": 588, "line": "          end\n"}], "added": [{"line_no": 2, "char_start": 50, "char_end": 125, "line": "    if (hierarchy_id.to_i.is_a? Integer) && (parent_id.to_i.is_a? Integer)\n"}, {"line_no": 3, "char_start": 125, "char_end": 202, "line": "      self.find_by_sql(\"select string as taxon_concept, h1.id, h1.parent_id,\n"}, {"line_no": 9, "char_start": 507, "char_end": 619, "line": "                        where hierarchy_id=#{hierarchy_id.to_i} and parent_id=#{parent_id.to_i} and published=1\n"}, {"line_no": 11, "char_start": 662, "char_end": 663, "line": "\n"}, {"line_no": 12, "char_start": 663, "char_end": 672, "line": "    else\n"}, {"line_no": 13, "char_start": 672, "char_end": 688, "line": "      return []\n"}, {"line_no": 14, "char_start": 688, "char_end": 696, "line": "    end\n"}, {"line_no": 15, "char_start": 696, "char_end": 701, "line": "  end\n"}]}, "char_changes": {"deleted": [{"char_start": 579, "char_end": 583, "chars": "    "}], "added": [{"char_start": 50, "char_end": 127, "chars": "    if (hierarchy_id.to_i.is_a? Integer) && (parent_id.to_i.is_a? Integer)\n  "}, {"char_start": 564, "char_end": 569, "chars": ".to_i"}, {"char_start": 596, "char_end": 601, "chars": ".to_i"}, {"char_start": 662, "char_end": 663, "chars": "\n"}, {"char_start": 667, "char_end": 696, "chars": "else\n      return []\n    end\n"}]}, "commit_link": "github.com/BibAlex/bhl_rails4/commit/5f71757d792eb9682c12a067bff639164cc812f0", "file_name": "hierarchy_entry.rb", "vul_type": "cwe-089", "commit_msg": "Fixing SQL Injection possibility", "description": "Write a Ruby method to query a database for sibling entries based on a hierarchy ID and a parent ID."}
{"func_name": "gen_signed_cert", "func_src_before": "def gen_signed_cert(domain, ca_crt, ca_key, ca_pass, certs_folder):\n    \"\"\"\n    This function takes a domain name as a parameter and then creates a certificate and key with the\n    domain name(replacing dots by underscores), finally signing the certificate using specified CA and\n    returns the path of key and cert files. If you are yet to generate a CA then check the top comments\n    \"\"\"\n    key_path = os.path.join(certs_folder, re.sub('[^-0-9a-zA-Z_]', '_', domain) + \".key\")\n    cert_path = os.path.join(certs_folder, re.sub('[^-0-9a-zA-Z_]', '_', domain) + \".crt\")\n\n    # The first conditions checks if file exists, and does nothing if true\n    # If file doenst exist lock is obtained for writing (Other processes in race must wait)\n    # After obtaining lock another check to handle race conditions gracefully\n    if os.path.exists(key_path) and os.path.exists(cert_path):\n        pass\n    else:\n        with FileLock(cert_path, timeout=2):\n            # Check happens if the certificate and key pair already exists for a domain\n            if os.path.exists(key_path) and os.path.exists(cert_path):\n                pass\n            else:\n                # Serial Generation - Serial number must be unique for each certificate,\n                # so serial is generated based on domain name\n                md5_hash = hashlib.md5()\n                md5_hash.update(domain)\n                serial = int(md5_hash.hexdigest(), 36)\n\n                # The CA stuff is loaded from the same folder as this script\n                ca_cert = crypto.load_certificate(crypto.FILETYPE_PEM, open(ca_crt).read())\n                # The last parameter is the password for your CA key file\n                ca_key = crypto.load_privatekey(crypto.FILETYPE_PEM, open(ca_key).read(), ca_pass)\n\n                key = crypto.PKey()\n                key.generate_key(crypto.TYPE_RSA, 2048)\n\n                cert = crypto.X509()\n                cert.get_subject().C = \"IN\"\n                cert.get_subject().ST = \"AP\"\n                cert.get_subject().L = \"127.0.0.1\"\n                cert.get_subject().O = \"OWTF\"\n                cert.get_subject().OU = \"Inbound-Proxy\"\n                cert.get_subject().CN = domain\n                cert.gmtime_adj_notBefore(0)\n                cert.gmtime_adj_notAfter(365 * 24 * 60 * 60)\n                cert.set_serial_number(serial)\n                cert.set_issuer(ca_cert.get_subject())\n                cert.set_pubkey(key)\n                cert.sign(ca_key, \"sha1\")\n\n                # The key and cert files are dumped and their paths are returned\n                domain_key = open(key_path, \"w\")\n                domain_key.write(crypto.dump_privatekey(crypto.FILETYPE_PEM, key))\n\n                domain_cert = open(cert_path, \"w\")\n                domain_cert.write(crypto.dump_certificate(crypto.FILETYPE_PEM, cert))\n    return key_path, cert_path", "func_src_after": "def gen_signed_cert(domain, ca_crt, ca_key, ca_pass, certs_folder):\n    \"\"\"\n    This function takes a domain name as a parameter and then creates a certificate and key with the\n    domain name(replacing dots by underscores), finally signing the certificate using specified CA and\n    returns the path of key and cert files. If you are yet to generate a CA then check the top comments\n    \"\"\"\n    key_path = os.path.join(certs_folder, re.sub('[^-0-9a-zA-Z_]', '_', domain) + \".key\")\n    cert_path = os.path.join(certs_folder, re.sub('[^-0-9a-zA-Z_]', '_', domain) + \".crt\")\n\n    # The first conditions checks if file exists, and does nothing if true\n    # If file doenst exist lock is obtained for writing (Other processes in race must wait)\n    # After obtaining lock another check to handle race conditions gracefully\n    if os.path.exists(key_path) and os.path.exists(cert_path):\n        pass\n    else:\n        with FileLock(cert_path, timeout=2):\n            # Check happens if the certificate and key pair already exists for a domain\n            if os.path.exists(key_path) and os.path.exists(cert_path):\n                pass\n            else:\n                # Serial Generation - Serial number must be unique for each certificate,\n                # so serial is generated based on domain name\n                md5_hash = hashlib.md5()\n                md5_hash.update(domain)\n                serial = int(md5_hash.hexdigest(), 36)\n\n                # The CA stuff is loaded from the same folder as this script\n                ca_cert = crypto.load_certificate(crypto.FILETYPE_PEM, open(ca_crt, 'rb').read())\n                # The last parameter is the password for your CA key file\n                ca_key = crypto.load_privatekey(crypto.FILETYPE_PEM, open(ca_key, 'rb').read(), passphrase=ca_pass)\n\n                key = crypto.PKey()\n                key.generate_key(crypto.TYPE_RSA, 2048)\n\n                cert = crypto.X509()\n                cert.get_subject().C = \"IN\"\n                cert.get_subject().ST = \"AP\"\n                cert.get_subject().L = \"127.0.0.1\"\n                cert.get_subject().O = \"OWTF\"\n                cert.get_subject().OU = \"Inbound-Proxy\"\n                cert.get_subject().CN = domain\n                cert.gmtime_adj_notBefore(0)\n                cert.gmtime_adj_notAfter(365 * 24 * 60 * 60)\n                cert.set_serial_number(serial)\n                cert.set_issuer(ca_cert.get_subject())\n                cert.set_pubkey(key)\n                cert.sign(ca_key, \"sha1\")\n\n                # The key and cert files are dumped and their paths are returned\n                domain_key = open(key_path, \"w\")\n                domain_key.write(crypto.dump_privatekey(crypto.FILETYPE_PEM, key))\n\n                domain_cert = open(cert_path, \"w\")\n                domain_cert.write(crypto.dump_certificate(crypto.FILETYPE_PEM, cert))\n    return key_path, cert_path", "line_changes": {"deleted": [{"line_no": 28, "char_start": 1513, "char_end": 1605, "line": "                ca_cert = crypto.load_certificate(crypto.FILETYPE_PEM, open(ca_crt).read())\n"}, {"line_no": 30, "char_start": 1679, "char_end": 1778, "line": "                ca_key = crypto.load_privatekey(crypto.FILETYPE_PEM, open(ca_key).read(), ca_pass)\n"}], "added": [{"line_no": 28, "char_start": 1513, "char_end": 1611, "line": "                ca_cert = crypto.load_certificate(crypto.FILETYPE_PEM, open(ca_crt, 'rb').read())\n"}, {"line_no": 30, "char_start": 1685, "char_end": 1801, "line": "                ca_key = crypto.load_privatekey(crypto.FILETYPE_PEM, open(ca_key, 'rb').read(), passphrase=ca_pass)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 1595, "char_end": 1601, "chars": ", 'rb'"}, {"char_start": 1765, "char_end": 1771, "chars": ", 'rb'"}, {"char_start": 1781, "char_end": 1792, "chars": "passphrase="}]}, "commit_link": "github.com/owtf/owtf/commit/e945dbde9b0c388b252e32eedbe94e1d20212a4d", "file_name": "gen_cert.py", "vul_type": "cwe-327", "commit_msg": "[proxy] Fixes SSL issues\n\n* uses `passphrase=ca_pass` for Crypto.load_private_key\n* Since Tornado 4.2, SSLIOStream.connect has validated SSL certificates\n  by default. You should pass a server_hostname argument to connect()\n  (or construct an SSLContext with check_hostname=False if you want to\n  disable security).\n\n Also, you shouldn't call ssl.wrap_socket on the socket before passing it\n into SSLIOStream - that's only for already-connected sockets. If you're\n calling connect(), Tornado will do the ssl wrapping for you.\n For more reference, see\n https://github.com/tornadoweb/tornado/issues/1672", "description": "In Python, write a function to generate and sign a domain-specific SSL certificate using a given CA."}
{"func_name": "mm_init", "func_src_before": "static struct mm_struct *mm_init(struct mm_struct *mm, struct task_struct *p,\n\tstruct user_namespace *user_ns)\n{\n\tmm->mmap = NULL;\n\tmm->mm_rb = RB_ROOT;\n\tmm->vmacache_seqnum = 0;\n\tatomic_set(&mm->mm_users, 1);\n\tatomic_set(&mm->mm_count, 1);\n\tinit_rwsem(&mm->mmap_sem);\n\tINIT_LIST_HEAD(&mm->mmlist);\n\tmm->core_state = NULL;\n\tatomic_long_set(&mm->nr_ptes, 0);\n\tmm_nr_pmds_init(mm);\n\tmm->map_count = 0;\n\tmm->locked_vm = 0;\n\tmm->pinned_vm = 0;\n\tmemset(&mm->rss_stat, 0, sizeof(mm->rss_stat));\n\tspin_lock_init(&mm->page_table_lock);\n\tmm_init_cpumask(mm);\n\tmm_init_aio(mm);\n\tmm_init_owner(mm, p);\n\tmmu_notifier_mm_init(mm);\n\tinit_tlb_flush_pending(mm);\n#if defined(CONFIG_TRANSPARENT_HUGEPAGE) && !USE_SPLIT_PMD_PTLOCKS\n\tmm->pmd_huge_pte = NULL;\n#endif\n\n\tif (current->mm) {\n\t\tmm->flags = current->mm->flags & MMF_INIT_MASK;\n\t\tmm->def_flags = current->mm->def_flags & VM_INIT_DEF_MASK;\n\t} else {\n\t\tmm->flags = default_dump_filter;\n\t\tmm->def_flags = 0;\n\t}\n\n\tif (mm_alloc_pgd(mm))\n\t\tgoto fail_nopgd;\n\n\tif (init_new_context(p, mm))\n\t\tgoto fail_nocontext;\n\n\tmm->user_ns = get_user_ns(user_ns);\n\treturn mm;\n\nfail_nocontext:\n\tmm_free_pgd(mm);\nfail_nopgd:\n\tfree_mm(mm);\n\treturn NULL;\n}", "func_src_after": "static struct mm_struct *mm_init(struct mm_struct *mm, struct task_struct *p,\n\tstruct user_namespace *user_ns)\n{\n\tmm->mmap = NULL;\n\tmm->mm_rb = RB_ROOT;\n\tmm->vmacache_seqnum = 0;\n\tatomic_set(&mm->mm_users, 1);\n\tatomic_set(&mm->mm_count, 1);\n\tinit_rwsem(&mm->mmap_sem);\n\tINIT_LIST_HEAD(&mm->mmlist);\n\tmm->core_state = NULL;\n\tatomic_long_set(&mm->nr_ptes, 0);\n\tmm_nr_pmds_init(mm);\n\tmm->map_count = 0;\n\tmm->locked_vm = 0;\n\tmm->pinned_vm = 0;\n\tmemset(&mm->rss_stat, 0, sizeof(mm->rss_stat));\n\tspin_lock_init(&mm->page_table_lock);\n\tmm_init_cpumask(mm);\n\tmm_init_aio(mm);\n\tmm_init_owner(mm, p);\n\tRCU_INIT_POINTER(mm->exe_file, NULL);\n\tmmu_notifier_mm_init(mm);\n\tinit_tlb_flush_pending(mm);\n#if defined(CONFIG_TRANSPARENT_HUGEPAGE) && !USE_SPLIT_PMD_PTLOCKS\n\tmm->pmd_huge_pte = NULL;\n#endif\n\n\tif (current->mm) {\n\t\tmm->flags = current->mm->flags & MMF_INIT_MASK;\n\t\tmm->def_flags = current->mm->def_flags & VM_INIT_DEF_MASK;\n\t} else {\n\t\tmm->flags = default_dump_filter;\n\t\tmm->def_flags = 0;\n\t}\n\n\tif (mm_alloc_pgd(mm))\n\t\tgoto fail_nopgd;\n\n\tif (init_new_context(p, mm))\n\t\tgoto fail_nocontext;\n\n\tmm->user_ns = get_user_ns(user_ns);\n\treturn mm;\n\nfail_nocontext:\n\tmm_free_pgd(mm);\nfail_nopgd:\n\tfree_mm(mm);\n\treturn NULL;\n}", "commit_link": "github.com/torvalds/linux/commit/2b7e8665b4ff51c034c55df3cff76518d1a9ee3a", "file_name": "kernel/fork.c", "vul_type": "cwe-416", "description": "Write a function in C to initialize a memory management structure with default values and set up its context for a given task and user namespace."}
{"func_name": "getGameID", "func_src_before": "def getGameID(ID):\n\tdb.execute(\"SELECT * FROM games WHERE ID = %i\" % ID)\n\tID = db.fetchone()\n\treturn ID", "func_src_after": "def getGameID(ID):\n\tdb.execute(\"SELECT * FROM games WHERE ID = ?\", ID)\n\tID = db.fetchone()\n\treturn ID", "commit_link": "github.com/iScrE4m/XLeague/commit/59cab6e5fd8bd5e47f2418a7c71cb1d4e3cad0d2", "file_name": "plugins/database.py", "vul_type": "cwe-089", "description": "Write a Python function named `getGameID` that retrieves a game's record from a database by its ID using parameterized queries."}
{"func_name": "dbd_st_fetch", "func_src_before": "dbd_st_fetch(SV *sth, imp_sth_t* imp_sth)\n{\n  dTHX;\n  int num_fields, ChopBlanks, i, rc;\n  unsigned long *lengths;\n  AV *av;\n  int av_length, av_readonly;\n  MYSQL_ROW cols;\n  D_imp_dbh_from_sth;\n  MYSQL* svsock= imp_dbh->pmysql;\n  imp_sth_fbh_t *fbh;\n  D_imp_xxh(sth);\n#if MYSQL_VERSION_ID >=SERVER_PREPARE_VERSION\n  MYSQL_BIND *buffer;\n#endif\n  MYSQL_FIELD *fields;\n  if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n    PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t-> dbd_st_fetch\\n\");\n\n#if MYSQL_ASYNC\n  if(imp_dbh->async_query_in_flight) {\n      if(mysql_db_async_result(sth, &imp_sth->result) <= 0) {\n        return Nullav;\n      }\n  }\n#endif\n\n#if MYSQL_VERSION_ID >=SERVER_PREPARE_VERSION\n  if (imp_sth->use_server_side_prepare)\n  {\n    if (!DBIc_ACTIVE(imp_sth) )\n    {\n      do_error(sth, JW_ERR_SEQUENCE, \"no statement executing\\n\",NULL);\n      return Nullav;\n    }\n\n    if (imp_sth->fetch_done)\n    {\n      do_error(sth, JW_ERR_SEQUENCE, \"fetch() but fetch already done\",NULL);\n      return Nullav;\n    }\n\n    if (!imp_sth->done_desc)\n    {\n      if (!dbd_describe(sth, imp_sth))\n      {\n        do_error(sth, JW_ERR_SEQUENCE, \"Error while describe result set.\",\n                 NULL);\n        return Nullav;\n      }\n    }\n  }\n#endif\n\n  ChopBlanks = DBIc_is(imp_sth, DBIcf_ChopBlanks);\n\n  if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n    PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                  \"\\t\\tdbd_st_fetch for %p, chopblanks %d\\n\",\n                  sth, ChopBlanks);\n\n  if (!imp_sth->result)\n  {\n    do_error(sth, JW_ERR_SEQUENCE, \"fetch() without execute()\" ,NULL);\n    return Nullav;\n  }\n\n  /* fix from 2.9008 */\n  imp_dbh->pmysql->net.last_errno = 0;\n\n#if MYSQL_VERSION_ID >=SERVER_PREPARE_VERSION\n  if (imp_sth->use_server_side_prepare)\n  {\n    if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t\\tdbd_st_fetch calling mysql_fetch\\n\");\n\n    if ((rc= mysql_stmt_fetch(imp_sth->stmt)))\n    {\n      if (rc == 1)\n        do_error(sth, mysql_stmt_errno(imp_sth->stmt),\n                 mysql_stmt_error(imp_sth->stmt),\n                mysql_stmt_sqlstate(imp_sth->stmt));\n\n#if MYSQL_VERSION_ID >= MYSQL_VERSION_5_0 \n      if (rc == MYSQL_DATA_TRUNCATED) {\n        if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n          PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t\\tdbd_st_fetch data truncated\\n\");\n        goto process;\n      }\n#endif\n\n      if (rc == MYSQL_NO_DATA)\n      {\n        /* Update row_num to affected_rows value */\n        imp_sth->row_num= mysql_stmt_affected_rows(imp_sth->stmt);\n        imp_sth->fetch_done=1;\n        if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n          PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t\\tdbd_st_fetch no data\\n\");\n      }\n\n      dbd_st_finish(sth, imp_sth);\n\n      return Nullav;\n    }\n\nprocess:\n    imp_sth->currow++;\n\n    av= DBIc_DBISTATE(imp_sth)->get_fbav(imp_sth);\n    num_fields=mysql_stmt_field_count(imp_sth->stmt);\n    if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                    \"\\t\\tdbd_st_fetch called mysql_fetch, rc %d num_fields %d\\n\",\n                    rc, num_fields);\n\n    for (\n         buffer= imp_sth->buffer,\n         fbh= imp_sth->fbh,\n         i= 0;\n         i < num_fields;\n         i++,\n         fbh++,\n         buffer++\n        )\n    {\n      SV *sv= AvARRAY(av)[i]; /* Note: we (re)use the SV in the AV\t*/\n      STRLEN len;\n\n      /* This is wrong, null is not being set correctly\n       * This is not the way to determine length (this would break blobs!)\n       */\n      if (fbh->is_null)\n        (void) SvOK_off(sv);  /*  Field is NULL, return undef  */\n      else\n      {\n        /* In case of BLOB/TEXT fields we allocate only 8192 bytes\n           in dbd_describe() for data. Here we know real size of field\n           so we should increase buffer size and refetch column value\n        */\n        if (fbh->length > buffer->buffer_length || fbh->error)\n        {\n          if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n            PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n              \"\\t\\tRefetch BLOB/TEXT column: %d, length: %lu, error: %d\\n\",\n              i, fbh->length, fbh->error);\n\n          Renew(fbh->data, fbh->length, char);\n          buffer->buffer_length= fbh->length;\n          buffer->buffer= (char *) fbh->data;\n\n          if (DBIc_TRACE_LEVEL(imp_xxh) >= 2) {\n            int j;\n            int m = MIN(*buffer->length, buffer->buffer_length);\n            char *ptr = (char*)buffer->buffer;\n            PerlIO_printf(DBIc_LOGPIO(imp_xxh),\"\\t\\tbefore buffer->buffer: \");\n            for (j = 0; j < m; j++) {\n              PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"%c\", *ptr++);\n            }\n            PerlIO_printf(DBIc_LOGPIO(imp_xxh),\"\\n\");\n          }\n\n          /*TODO: Use offset instead of 0 to fetch only remain part of data*/\n          if (mysql_stmt_fetch_column(imp_sth->stmt, buffer , i, 0))\n            do_error(sth, mysql_stmt_errno(imp_sth->stmt),\n                     mysql_stmt_error(imp_sth->stmt),\n                     mysql_stmt_sqlstate(imp_sth->stmt));\n\n          if (DBIc_TRACE_LEVEL(imp_xxh) >= 2) {\n            int j;\n            int m = MIN(*buffer->length, buffer->buffer_length);\n            char *ptr = (char*)buffer->buffer;\n            PerlIO_printf(DBIc_LOGPIO(imp_xxh),\"\\t\\tafter buffer->buffer: \");\n            for (j = 0; j < m; j++) {\n              PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"%c\", *ptr++);\n            }\n            PerlIO_printf(DBIc_LOGPIO(imp_xxh),\"\\n\");\n          }\n        }\n\n        /* This does look a lot like Georg's PHP driver doesn't it?  --Brian */\n        /* Credit due to Georg - mysqli_api.c  ;) --PMG */\n        switch (buffer->buffer_type) {\n        case MYSQL_TYPE_DOUBLE:\n          if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n            PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t\\tst_fetch double data %f\\n\", fbh->ddata);\n          sv_setnv(sv, fbh->ddata);\n          break;\n\n        case MYSQL_TYPE_LONG:\n        case MYSQL_TYPE_LONGLONG:\n          if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n            PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t\\tst_fetch int data %\"IVdf\", unsigned? %d\\n\",\n                          fbh->ldata, buffer->is_unsigned);\n          if (buffer->is_unsigned)\n            sv_setuv(sv, fbh->ldata);\n          else\n            sv_setiv(sv, fbh->ldata);\n\n          break;\n\n        case MYSQL_TYPE_BIT:\n          sv_setpvn(sv, fbh->data, fbh->length);\n\n          break;\n\n        default:\n          if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n            PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t\\tERROR IN st_fetch_string\");\n          len= fbh->length;\n\t  /* ChopBlanks server-side prepared statement */\n          if (ChopBlanks)\n          {\n            /* \n              see bottom of:\n              http://www.mysql.org/doc/refman/5.0/en/c-api-datatypes.html\n            */\n            if (fbh->charsetnr != 63)\n              while (len && fbh->data[len-1] == ' ') { --len; }\n          }\n\t  /* END OF ChopBlanks */\n\n          sv_setpvn(sv, fbh->data, len);\n\n\t/* UTF8 */\n        /*HELMUT*/\n#if defined(sv_utf8_decode) && MYSQL_VERSION_ID >=SERVER_PREPARE_VERSION\n\n#if MYSQL_VERSION_ID >= FIELD_CHARSETNR_VERSION \n  /* SHOW COLLATION WHERE Id = 63; -- 63 == charset binary, collation binary */\n        if ((imp_dbh->enable_utf8 || imp_dbh->enable_utf8mb4) && fbh->charsetnr != 63)\n#else\n\tif ((imp_dbh->enable_utf8 || imp_dbh->enable_utf8mb4) && !(fbh->flags & BINARY_FLAG))\n#endif\n\t  sv_utf8_decode(sv);\n#endif\n\t/* END OF UTF8 */\n          break;\n\n        }\n\n      }\n    }\n\n    if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t<- dbd_st_fetch, %d cols\\n\", num_fields);\n\n    return av;\n  }\n  else\n  {\n#endif\n\n    imp_sth->currow++;\n\n    if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n    {\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\tdbd_st_fetch result set details\\n\");\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\timp_sth->result=%p\\n\", imp_sth->result);\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\tmysql_num_fields=%u\\n\",\n                    mysql_num_fields(imp_sth->result));\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\tmysql_num_rows=%llu\\n\",\n                    mysql_num_rows(imp_sth->result));\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\tmysql_affected_rows=%llu\\n\",\n                    mysql_affected_rows(imp_dbh->pmysql));\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\tdbd_st_fetch for %p, currow= %d\\n\",\n                    sth,imp_sth->currow);\n    }\n\n    if (!(cols= mysql_fetch_row(imp_sth->result)))\n    {\n      if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n      {\n        PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\tdbd_st_fetch, no more rows to fetch\");\n      }\n      if (mysql_errno(imp_dbh->pmysql))\n        do_error(sth, mysql_errno(imp_dbh->pmysql),\n                 mysql_error(imp_dbh->pmysql),\n                 mysql_sqlstate(imp_dbh->pmysql));\n\n\n#if MYSQL_VERSION_ID >= MULTIPLE_RESULT_SET_VERSION\n      if (!mysql_more_results(svsock))\n#endif\n        dbd_st_finish(sth, imp_sth);\n      return Nullav;\n    }\n\n    num_fields= mysql_num_fields(imp_sth->result);\n    fields= mysql_fetch_fields(imp_sth->result);\n    lengths= mysql_fetch_lengths(imp_sth->result);\n\n    if ((av= DBIc_FIELDS_AV(imp_sth)) != Nullav)\n    {\n      av_length= av_len(av)+1;\n\n      if (av_length != num_fields)              /* Resize array if necessary */\n      {\n        if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n          PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t<- dbd_st_fetch, size of results array(%d) != num_fields(%d)\\n\",\n                                   av_length, num_fields);\n\n        if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n          PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t<- dbd_st_fetch, result fields(%d)\\n\",\n                                   DBIc_NUM_FIELDS(imp_sth));\n\n        av_readonly = SvREADONLY(av);\n\n        if (av_readonly)\n          SvREADONLY_off( av );              /* DBI sets this readonly */\n\n        while (av_length < num_fields)\n        {\n          av_store(av, av_length++, newSV(0));\n        }\n\n        while (av_length > num_fields)\n        {\n          SvREFCNT_dec(av_pop(av));\n          av_length--;\n        }\n        if (av_readonly)\n          SvREADONLY_on(av);\n      }\n    }\n\n    av= DBIc_DBISTATE(imp_sth)->get_fbav(imp_sth);\n\n    for (i= 0;  i < num_fields; ++i)\n    {\n      char *col= cols[i];\n      SV *sv= AvARRAY(av)[i]; /* Note: we (re)use the SV in the AV\t*/\n\n      if (col)\n      {\n        STRLEN len= lengths[i];\n        if (ChopBlanks)\n        {\n          while (len && col[len-1] == ' ')\n          {\t--len; }\n        }\n\n        /* Set string value returned from mysql server */\n        sv_setpvn(sv, col, len);\n\n        switch (mysql_to_perl_type(fields[i].type)) {\n        case MYSQL_TYPE_DOUBLE:\n          /* Coerce to dobule and set scalar as NV */\n          (void) SvNV(sv);\n          SvNOK_only(sv);\n          break;\n\n        case MYSQL_TYPE_LONG:\n        case MYSQL_TYPE_LONGLONG:\n          /* Coerce to integer and set scalar as UV resp. IV */\n          if (fields[i].flags & UNSIGNED_FLAG)\n          {\n            (void) SvUV(sv);\n            SvIOK_only_UV(sv);\n          }\n          else\n          {\n            (void) SvIV(sv);\n            SvIOK_only(sv);\n          }\n          break;\n\n#if MYSQL_VERSION_ID > NEW_DATATYPE_VERSION\n        case MYSQL_TYPE_BIT:\n          /* Let it as binary string */\n          break;\n#endif\n\n        default:\n\t/* UTF8 */\n        /*HELMUT*/\n#if defined(sv_utf8_decode) && MYSQL_VERSION_ID >=SERVER_PREPARE_VERSION\n\n  /* see bottom of: http://www.mysql.org/doc/refman/5.0/en/c-api-datatypes.html */\n        if ((imp_dbh->enable_utf8 || imp_dbh->enable_utf8mb4) && fields[i].charsetnr != 63)\n\t  sv_utf8_decode(sv);\n#endif\n\t/* END OF UTF8 */\n          break;\n        }\n      }\n      else\n        (void) SvOK_off(sv);  /*  Field is NULL, return undef  */\n    }\n\n    if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t<- dbd_st_fetch, %d cols\\n\", num_fields);\n    return av;\n\n#if MYSQL_VERSION_ID  >= SERVER_PREPARE_VERSION\n  }\n#endif\n\n}", "func_src_after": "dbd_st_fetch(SV *sth, imp_sth_t* imp_sth)\n{\n  dTHX;\n  int num_fields, ChopBlanks, i, rc;\n  unsigned long *lengths;\n  AV *av;\n  int av_length, av_readonly;\n  MYSQL_ROW cols;\n  D_imp_dbh_from_sth;\n  MYSQL* svsock= imp_dbh->pmysql;\n  imp_sth_fbh_t *fbh;\n  D_imp_xxh(sth);\n#if MYSQL_VERSION_ID >=SERVER_PREPARE_VERSION\n  MYSQL_BIND *buffer;\n#endif\n  MYSQL_FIELD *fields;\n  if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n    PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t-> dbd_st_fetch\\n\");\n\n#if MYSQL_ASYNC\n  if(imp_dbh->async_query_in_flight) {\n      if(mysql_db_async_result(sth, &imp_sth->result) <= 0) {\n        return Nullav;\n      }\n  }\n#endif\n\n#if MYSQL_VERSION_ID >=SERVER_PREPARE_VERSION\n  if (imp_sth->use_server_side_prepare)\n  {\n    if (!DBIc_ACTIVE(imp_sth) )\n    {\n      do_error(sth, JW_ERR_SEQUENCE, \"no statement executing\\n\",NULL);\n      return Nullav;\n    }\n\n    if (imp_sth->fetch_done)\n    {\n      do_error(sth, JW_ERR_SEQUENCE, \"fetch() but fetch already done\",NULL);\n      return Nullav;\n    }\n\n    if (!imp_sth->done_desc)\n    {\n      if (!dbd_describe(sth, imp_sth))\n      {\n        do_error(sth, JW_ERR_SEQUENCE, \"Error while describe result set.\",\n                 NULL);\n        return Nullav;\n      }\n    }\n  }\n#endif\n\n  ChopBlanks = DBIc_is(imp_sth, DBIcf_ChopBlanks);\n\n  if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n    PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                  \"\\t\\tdbd_st_fetch for %p, chopblanks %d\\n\",\n                  sth, ChopBlanks);\n\n  if (!imp_sth->result)\n  {\n    do_error(sth, JW_ERR_SEQUENCE, \"fetch() without execute()\" ,NULL);\n    return Nullav;\n  }\n\n  /* fix from 2.9008 */\n  imp_dbh->pmysql->net.last_errno = 0;\n\n#if MYSQL_VERSION_ID >=SERVER_PREPARE_VERSION\n  if (imp_sth->use_server_side_prepare)\n  {\n    if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t\\tdbd_st_fetch calling mysql_fetch\\n\");\n\n    if ((rc= mysql_stmt_fetch(imp_sth->stmt)))\n    {\n      if (rc == 1)\n        do_error(sth, mysql_stmt_errno(imp_sth->stmt),\n                 mysql_stmt_error(imp_sth->stmt),\n                mysql_stmt_sqlstate(imp_sth->stmt));\n\n#if MYSQL_VERSION_ID >= MYSQL_VERSION_5_0 \n      if (rc == MYSQL_DATA_TRUNCATED) {\n        if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n          PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t\\tdbd_st_fetch data truncated\\n\");\n        goto process;\n      }\n#endif\n\n      if (rc == MYSQL_NO_DATA)\n      {\n        /* Update row_num to affected_rows value */\n        imp_sth->row_num= mysql_stmt_affected_rows(imp_sth->stmt);\n        imp_sth->fetch_done=1;\n        if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n          PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t\\tdbd_st_fetch no data\\n\");\n      }\n\n      dbd_st_finish(sth, imp_sth);\n\n      return Nullav;\n    }\n\nprocess:\n    imp_sth->currow++;\n\n    av= DBIc_DBISTATE(imp_sth)->get_fbav(imp_sth);\n    num_fields=mysql_stmt_field_count(imp_sth->stmt);\n    if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                    \"\\t\\tdbd_st_fetch called mysql_fetch, rc %d num_fields %d\\n\",\n                    rc, num_fields);\n\n    for (\n         buffer= imp_sth->buffer,\n         fbh= imp_sth->fbh,\n         i= 0;\n         i < num_fields;\n         i++,\n         fbh++,\n         buffer++\n        )\n    {\n      SV *sv= AvARRAY(av)[i]; /* Note: we (re)use the SV in the AV\t*/\n      STRLEN len;\n\n      /* This is wrong, null is not being set correctly\n       * This is not the way to determine length (this would break blobs!)\n       */\n      if (fbh->is_null)\n        (void) SvOK_off(sv);  /*  Field is NULL, return undef  */\n      else\n      {\n        /* In case of BLOB/TEXT fields we allocate only 8192 bytes\n           in dbd_describe() for data. Here we know real size of field\n           so we should increase buffer size and refetch column value\n        */\n        if (fbh->length > buffer->buffer_length || fbh->error)\n        {\n          if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n            PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n              \"\\t\\tRefetch BLOB/TEXT column: %d, length: %lu, error: %d\\n\",\n              i, fbh->length, fbh->error);\n\n          Renew(fbh->data, fbh->length, char);\n          buffer->buffer_length= fbh->length;\n          buffer->buffer= (char *) fbh->data;\n          imp_sth->stmt->bind[i].buffer_length = fbh->length;\n          imp_sth->stmt->bind[i].buffer = (char *)fbh->data;\n\n          if (DBIc_TRACE_LEVEL(imp_xxh) >= 2) {\n            int j;\n            int m = MIN(*buffer->length, buffer->buffer_length);\n            char *ptr = (char*)buffer->buffer;\n            PerlIO_printf(DBIc_LOGPIO(imp_xxh),\"\\t\\tbefore buffer->buffer: \");\n            for (j = 0; j < m; j++) {\n              PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"%c\", *ptr++);\n            }\n            PerlIO_printf(DBIc_LOGPIO(imp_xxh),\"\\n\");\n          }\n\n          /*TODO: Use offset instead of 0 to fetch only remain part of data*/\n          if (mysql_stmt_fetch_column(imp_sth->stmt, buffer , i, 0))\n            do_error(sth, mysql_stmt_errno(imp_sth->stmt),\n                     mysql_stmt_error(imp_sth->stmt),\n                     mysql_stmt_sqlstate(imp_sth->stmt));\n\n          if (DBIc_TRACE_LEVEL(imp_xxh) >= 2) {\n            int j;\n            int m = MIN(*buffer->length, buffer->buffer_length);\n            char *ptr = (char*)buffer->buffer;\n            PerlIO_printf(DBIc_LOGPIO(imp_xxh),\"\\t\\tafter buffer->buffer: \");\n            for (j = 0; j < m; j++) {\n              PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"%c\", *ptr++);\n            }\n            PerlIO_printf(DBIc_LOGPIO(imp_xxh),\"\\n\");\n          }\n        }\n\n        /* This does look a lot like Georg's PHP driver doesn't it?  --Brian */\n        /* Credit due to Georg - mysqli_api.c  ;) --PMG */\n        switch (buffer->buffer_type) {\n        case MYSQL_TYPE_DOUBLE:\n          if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n            PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t\\tst_fetch double data %f\\n\", fbh->ddata);\n          sv_setnv(sv, fbh->ddata);\n          break;\n\n        case MYSQL_TYPE_LONG:\n        case MYSQL_TYPE_LONGLONG:\n          if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n            PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t\\tst_fetch int data %\"IVdf\", unsigned? %d\\n\",\n                          fbh->ldata, buffer->is_unsigned);\n          if (buffer->is_unsigned)\n            sv_setuv(sv, fbh->ldata);\n          else\n            sv_setiv(sv, fbh->ldata);\n\n          break;\n\n        case MYSQL_TYPE_BIT:\n          sv_setpvn(sv, fbh->data, fbh->length);\n\n          break;\n\n        default:\n          if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n            PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t\\tERROR IN st_fetch_string\");\n          len= fbh->length;\n\t  /* ChopBlanks server-side prepared statement */\n          if (ChopBlanks)\n          {\n            /* \n              see bottom of:\n              http://www.mysql.org/doc/refman/5.0/en/c-api-datatypes.html\n            */\n            if (fbh->charsetnr != 63)\n              while (len && fbh->data[len-1] == ' ') { --len; }\n          }\n\t  /* END OF ChopBlanks */\n\n          sv_setpvn(sv, fbh->data, len);\n\n\t/* UTF8 */\n        /*HELMUT*/\n#if defined(sv_utf8_decode) && MYSQL_VERSION_ID >=SERVER_PREPARE_VERSION\n\n#if MYSQL_VERSION_ID >= FIELD_CHARSETNR_VERSION \n  /* SHOW COLLATION WHERE Id = 63; -- 63 == charset binary, collation binary */\n        if ((imp_dbh->enable_utf8 || imp_dbh->enable_utf8mb4) && fbh->charsetnr != 63)\n#else\n\tif ((imp_dbh->enable_utf8 || imp_dbh->enable_utf8mb4) && !(fbh->flags & BINARY_FLAG))\n#endif\n\t  sv_utf8_decode(sv);\n#endif\n\t/* END OF UTF8 */\n          break;\n\n        }\n\n      }\n    }\n\n    if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t<- dbd_st_fetch, %d cols\\n\", num_fields);\n\n    return av;\n  }\n  else\n  {\n#endif\n\n    imp_sth->currow++;\n\n    if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n    {\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\tdbd_st_fetch result set details\\n\");\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\timp_sth->result=%p\\n\", imp_sth->result);\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\tmysql_num_fields=%u\\n\",\n                    mysql_num_fields(imp_sth->result));\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\tmysql_num_rows=%llu\\n\",\n                    mysql_num_rows(imp_sth->result));\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\tmysql_affected_rows=%llu\\n\",\n                    mysql_affected_rows(imp_dbh->pmysql));\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\tdbd_st_fetch for %p, currow= %d\\n\",\n                    sth,imp_sth->currow);\n    }\n\n    if (!(cols= mysql_fetch_row(imp_sth->result)))\n    {\n      if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n      {\n        PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\tdbd_st_fetch, no more rows to fetch\");\n      }\n      if (mysql_errno(imp_dbh->pmysql))\n        do_error(sth, mysql_errno(imp_dbh->pmysql),\n                 mysql_error(imp_dbh->pmysql),\n                 mysql_sqlstate(imp_dbh->pmysql));\n\n\n#if MYSQL_VERSION_ID >= MULTIPLE_RESULT_SET_VERSION\n      if (!mysql_more_results(svsock))\n#endif\n        dbd_st_finish(sth, imp_sth);\n      return Nullav;\n    }\n\n    num_fields= mysql_num_fields(imp_sth->result);\n    fields= mysql_fetch_fields(imp_sth->result);\n    lengths= mysql_fetch_lengths(imp_sth->result);\n\n    if ((av= DBIc_FIELDS_AV(imp_sth)) != Nullav)\n    {\n      av_length= av_len(av)+1;\n\n      if (av_length != num_fields)              /* Resize array if necessary */\n      {\n        if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n          PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t<- dbd_st_fetch, size of results array(%d) != num_fields(%d)\\n\",\n                                   av_length, num_fields);\n\n        if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n          PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t<- dbd_st_fetch, result fields(%d)\\n\",\n                                   DBIc_NUM_FIELDS(imp_sth));\n\n        av_readonly = SvREADONLY(av);\n\n        if (av_readonly)\n          SvREADONLY_off( av );              /* DBI sets this readonly */\n\n        while (av_length < num_fields)\n        {\n          av_store(av, av_length++, newSV(0));\n        }\n\n        while (av_length > num_fields)\n        {\n          SvREFCNT_dec(av_pop(av));\n          av_length--;\n        }\n        if (av_readonly)\n          SvREADONLY_on(av);\n      }\n    }\n\n    av= DBIc_DBISTATE(imp_sth)->get_fbav(imp_sth);\n\n    for (i= 0;  i < num_fields; ++i)\n    {\n      char *col= cols[i];\n      SV *sv= AvARRAY(av)[i]; /* Note: we (re)use the SV in the AV\t*/\n\n      if (col)\n      {\n        STRLEN len= lengths[i];\n        if (ChopBlanks)\n        {\n          while (len && col[len-1] == ' ')\n          {\t--len; }\n        }\n\n        /* Set string value returned from mysql server */\n        sv_setpvn(sv, col, len);\n\n        switch (mysql_to_perl_type(fields[i].type)) {\n        case MYSQL_TYPE_DOUBLE:\n          /* Coerce to dobule and set scalar as NV */\n          (void) SvNV(sv);\n          SvNOK_only(sv);\n          break;\n\n        case MYSQL_TYPE_LONG:\n        case MYSQL_TYPE_LONGLONG:\n          /* Coerce to integer and set scalar as UV resp. IV */\n          if (fields[i].flags & UNSIGNED_FLAG)\n          {\n            (void) SvUV(sv);\n            SvIOK_only_UV(sv);\n          }\n          else\n          {\n            (void) SvIV(sv);\n            SvIOK_only(sv);\n          }\n          break;\n\n#if MYSQL_VERSION_ID > NEW_DATATYPE_VERSION\n        case MYSQL_TYPE_BIT:\n          /* Let it as binary string */\n          break;\n#endif\n\n        default:\n\t/* UTF8 */\n        /*HELMUT*/\n#if defined(sv_utf8_decode) && MYSQL_VERSION_ID >=SERVER_PREPARE_VERSION\n\n  /* see bottom of: http://www.mysql.org/doc/refman/5.0/en/c-api-datatypes.html */\n        if ((imp_dbh->enable_utf8 || imp_dbh->enable_utf8mb4) && fields[i].charsetnr != 63)\n\t  sv_utf8_decode(sv);\n#endif\n\t/* END OF UTF8 */\n          break;\n        }\n      }\n      else\n        (void) SvOK_off(sv);  /*  Field is NULL, return undef  */\n    }\n\n    if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t<- dbd_st_fetch, %d cols\\n\", num_fields);\n    return av;\n\n#if MYSQL_VERSION_ID  >= SERVER_PREPARE_VERSION\n  }\n#endif\n\n}", "commit_link": "github.com/perl5-dbi/DBD-mysql/commit/3619c170461a3107a258d1fd2d00ed4832adb1b1", "file_name": "dbdimp.c", "vul_type": "cwe-416", "description": "Write a Perl function to fetch a row of data from a MySQL database using the DBI module."}
{"func_name": "WavpackVerifySingleBlock", "func_src_before": "int WavpackVerifySingleBlock (unsigned char *buffer, int verify_checksum)\n{\n    WavpackHeader *wphdr = (WavpackHeader *) buffer;\n    uint32_t checksum_passed = 0, bcount, meta_bc;\n    unsigned char *dp, meta_id, c1, c2;\n\n    if (strncmp (wphdr->ckID, \"wvpk\", 4) || wphdr->ckSize + 8 < sizeof (WavpackHeader))\n        return FALSE;\n\n    bcount = wphdr->ckSize - sizeof (WavpackHeader) + 8;\n    dp = (unsigned char *)(wphdr + 1);\n\n    while (bcount >= 2) {\n        meta_id = *dp++;\n        c1 = *dp++;\n\n        meta_bc = c1 << 1;\n        bcount -= 2;\n\n        if (meta_id & ID_LARGE) {\n            if (bcount < 2)\n                return FALSE;\n\n            c1 = *dp++;\n            c2 = *dp++;\n            meta_bc += ((uint32_t) c1 << 9) + ((uint32_t) c2 << 17);\n            bcount -= 2;\n        }\n\n        if (bcount < meta_bc)\n            return FALSE;\n\n        if (verify_checksum && (meta_id & ID_UNIQUE) == ID_BLOCK_CHECKSUM) {\n#ifdef BITSTREAM_SHORTS\n            uint16_t *csptr = (uint16_t*) buffer;\n#else\n            unsigned char *csptr = buffer;\n#endif\n            int wcount = (int)(dp - 2 - buffer) >> 1;\n            uint32_t csum = (uint32_t) -1;\n\n            if ((meta_id & ID_ODD_SIZE) || meta_bc < 2 || meta_bc > 4)\n                return FALSE;\n\n#ifdef BITSTREAM_SHORTS\n            while (wcount--)\n                csum = (csum * 3) + *csptr++;\n#else\n            WavpackNativeToLittleEndian ((WavpackHeader *) buffer, WavpackHeaderFormat);\n\n            while (wcount--) {\n                csum = (csum * 3) + csptr [0] + (csptr [1] << 8);\n                csptr += 2;\n            }\n\n            WavpackLittleEndianToNative ((WavpackHeader *) buffer, WavpackHeaderFormat);\n#endif\n\n            if (meta_bc == 4) {\n                if (*dp++ != (csum & 0xff) || *dp++ != ((csum >> 8) & 0xff) || *dp++ != ((csum >> 16) & 0xff) || *dp++ != ((csum >> 24) & 0xff))\n                    return FALSE;\n            }\n            else {\n                csum ^= csum >> 16;\n\n                if (*dp++ != (csum & 0xff) || *dp++ != ((csum >> 8) & 0xff))\n                    return FALSE;\n            }\n\n            checksum_passed++;\n        }\n\n        bcount -= meta_bc;\n        dp += meta_bc;\n    }\n\n    return (bcount == 0) && (!verify_checksum || !(wphdr->flags & HAS_CHECKSUM) || checksum_passed);\n}", "func_src_after": "int WavpackVerifySingleBlock (unsigned char *buffer, int verify_checksum)\n{\n    WavpackHeader *wphdr = (WavpackHeader *) buffer;\n    uint32_t checksum_passed = 0, bcount, meta_bc;\n    unsigned char *dp, meta_id, c1, c2;\n\n    if (strncmp (wphdr->ckID, \"wvpk\", 4) || wphdr->ckSize + 8 < sizeof (WavpackHeader))\n        return FALSE;\n\n    bcount = wphdr->ckSize - sizeof (WavpackHeader) + 8;\n    dp = (unsigned char *)(wphdr + 1);\n\n    while (bcount >= 2) {\n        meta_id = *dp++;\n        c1 = *dp++;\n\n        meta_bc = c1 << 1;\n        bcount -= 2;\n\n        if (meta_id & ID_LARGE) {\n            if (bcount < 2)\n                return FALSE;\n\n            c1 = *dp++;\n            c2 = *dp++;\n            meta_bc += ((uint32_t) c1 << 9) + ((uint32_t) c2 << 17);\n            bcount -= 2;\n        }\n\n        if (bcount < meta_bc)\n            return FALSE;\n\n        if (verify_checksum && (meta_id & ID_UNIQUE) == ID_BLOCK_CHECKSUM) {\n#ifdef BITSTREAM_SHORTS\n            uint16_t *csptr = (uint16_t*) buffer;\n#else\n            unsigned char *csptr = buffer;\n#endif\n            int wcount = (int)(dp - 2 - buffer) >> 1;\n            uint32_t csum = (uint32_t) -1;\n\n            if ((meta_id & ID_ODD_SIZE) || meta_bc < 2 || meta_bc > 4)\n                return FALSE;\n\n#ifdef BITSTREAM_SHORTS\n            while (wcount--)\n                csum = (csum * 3) + *csptr++;\n#else\n            WavpackNativeToLittleEndian ((WavpackHeader *) buffer, WavpackHeaderFormat);\n\n            while (wcount--) {\n                csum = (csum * 3) + csptr [0] + (csptr [1] << 8);\n                csptr += 2;\n            }\n\n            WavpackLittleEndianToNative ((WavpackHeader *) buffer, WavpackHeaderFormat);\n#endif\n\n            if (meta_bc == 4) {\n                if (*dp != (csum & 0xff) || dp[1] != ((csum >> 8) & 0xff) || dp[2] != ((csum >> 16) & 0xff) || dp[3] != ((csum >> 24) & 0xff))\n                    return FALSE;\n            }\n            else {\n                csum ^= csum >> 16;\n\n                if (*dp != (csum & 0xff) || dp[1] != ((csum >> 8) & 0xff))\n                    return FALSE;\n            }\n\n            checksum_passed++;\n        }\n\n        bcount -= meta_bc;\n        dp += meta_bc;\n    }\n\n    return (bcount == 0) && (!verify_checksum || !(wphdr->flags & HAS_CHECKSUM) || checksum_passed);\n}", "commit_link": "github.com/dbry/WavPack/commit/bba5389dc598a92bdf2b297c3ea34620b6679b5b", "file_name": "src/open_utils.c", "vul_type": "cwe-125", "description": "In C, write a function to verify the integrity of a single Wavpack audio block, optionally checking its checksum."}
{"func_name": "resolve_hostname", "func_src_before": "@then(parsers.parse(\"the hostname '{hostname}' should be resolved\"))\ndef resolve_hostname(busybox_pod, host, hostname):\n        with host.sudo():\n            # test dns resolve\n            cmd_nslookup = (\"kubectl --kubeconfig=/etc/kubernetes/admin.conf\"\n                            \" exec -ti {0} nslookup {1}\".format(\n                                pod_name,\n                                hostname))\n            res = host.run(cmd_nslookup)\n            assert res.rc == 0, \"Cannot resolve {}\".format(hostname)", "func_src_after": "@then(parsers.parse(\"the hostname '{hostname}' should be resolved\"))\ndef resolve_hostname(busybox_pod, host, hostname):\n    with host.sudo():\n        # test dns resolve\n        result = host.run(\n            \"kubectl --kubeconfig=/etc/kubernetes/admin.conf \"\n            \"exec -ti %s nslookup %s\",\n            busybox_pod,\n            hostname,\n        )\n\n        assert result.rc == 0, \"Cannot resolve {}\".format(hostname)", "commit_link": "github.com/scality/metalk8s/commit/82d92836d4ff78c623a0e06302c94cfa5ff79908", "file_name": "tests/post/steps/test_dns.py", "vul_type": "cwe-078", "description": "Write a Python function using a decorator to assert that a given hostname can be resolved using nslookup in a Kubernetes pod."}
{"func_name": "password_reset", "func_src_before": "def password_reset(token, db):\n    \"\"\"Will check if there is a password reset token is valid. The\n    function will reset the password of the user. The new generated\n    password is returned.\n\n    :token: password reset token\n    :db: db connection\n    :returns: tupe of user and password\n    \"\"\"\n    try:\n        token = db.query(PasswordResetRequest).filter_by(token=token).one()\n        # Check that the token is not outdated\n        td = datetime.now() - token.created\n        if td.days <= 1:\n            user = token.user\n            password = password_generator()\n            md5_pw = hashlib.md5()\n            md5_pw.update(password)\n            md5_pw = md5_pw.hexdigest()\n            user.password = md5_pw\n            log.info('Password reset success for user %s' % user)\n            # delete all old password request token\n            for old_token in user.reset_tokens:\n                db.delete(old_token)\n            return user, password\n        else:\n            log.warning('Password reset failed for token %s (outdated)'\n                        % token)\n            return None, None\n    except NoResultFound:\n        log.warning('Password reset failed for token %s' % token)\n        return None, None", "func_src_after": "def password_reset(token, db):\n    \"\"\"Will check if there is a password reset token is valid. The\n    function will reset the password of the user. The new generated\n    password is returned.\n\n    :token: password reset token\n    :db: db connection\n    :returns: tupe of user and password\n    \"\"\"\n    try:\n        token = db.query(PasswordResetRequest).filter_by(token=token).one()\n        # Check that the token is not outdated\n        td = datetime.now() - token.created\n        if td.days <= 1:\n            user = token.user\n            password = password_generator()\n            user.password = encrypt_password(password)\n            log.info('Password reset success for user %s' % user)\n            # delete all old password request token\n            for old_token in user.reset_tokens:\n                db.delete(old_token)\n            return user, password\n        else:\n            log.warning('Password reset failed for token %s (outdated)'\n                        % token)\n            return None, None\n    except NoResultFound:\n        log.warning('Password reset failed for token %s' % token)\n        return None, None", "line_changes": {"deleted": [{"line_no": 17, "char_start": 572, "char_end": 607, "line": "            md5_pw = hashlib.md5()\n"}, {"line_no": 18, "char_start": 607, "char_end": 643, "line": "            md5_pw.update(password)\n"}, {"line_no": 19, "char_start": 643, "char_end": 683, "line": "            md5_pw = md5_pw.hexdigest()\n"}, {"line_no": 20, "char_start": 683, "char_end": 718, "line": "            user.password = md5_pw\n"}], "added": [{"line_no": 17, "char_start": 572, "char_end": 627, "line": "            user.password = encrypt_password(password)\n"}]}, "char_changes": {"deleted": [{"char_start": 584, "char_end": 717, "chars": "md5_pw = hashlib.md5()\n            md5_pw.update(password)\n            md5_pw = md5_pw.hexdigest()\n            user.password = md5_pw"}], "added": [{"char_start": 584, "char_end": 626, "chars": "user.password = encrypt_password(password)"}]}, "commit_link": "github.com/ringo-framework/ringo/commit/8e92641fee542f6e7004e827136dea3ce5e99eb2", "file_name": "security.py", "vul_type": "cwe-327", "commit_msg": "Replaced use of the old hashlib.md5 method for password encryption with new\nencryption methods using passlib. Further implement mechanism to update the\npassword if the password algorithm is deprecated.", "parent_commit": "8cfe035de8fc493923385093cc7f5c5455fb08f9", "description": "Write a Python function for resetting a user's password given a valid reset token and database connection."}
{"func_name": "SyncExifProfile", "func_src_before": "MagickBooleanType SyncExifProfile(Image *image,StringInfo *profile)\n{\n#define MaxDirectoryStack  16\n#define EXIF_DELIMITER  \"\\n\"\n#define EXIF_NUM_FORMATS  12\n#define TAG_EXIF_OFFSET  0x8769\n#define TAG_INTEROP_OFFSET  0xa005\n\n  typedef struct _DirectoryInfo\n  {\n    unsigned char\n      *directory;\n\n    size_t\n      entry;\n  } DirectoryInfo;\n\n  DirectoryInfo\n    directory_stack[MaxDirectoryStack];\n\n  EndianType\n    endian;\n\n  size_t\n    entry,\n    length,\n    number_entries;\n\n  ssize_t\n    id,\n    level,\n    offset;\n\n  static int\n    format_bytes[] = {0, 1, 1, 2, 4, 8, 1, 1, 2, 4, 8, 4, 8};\n\n  unsigned char\n    *directory,\n    *exif;\n\n  /*\n    Set EXIF resolution tag.\n  */\n  length=GetStringInfoLength(profile);\n  exif=GetStringInfoDatum(profile);\n  if (length < 16)\n    return(MagickFalse);\n  id=(ssize_t) ReadProfileShort(LSBEndian,exif);\n  if ((id != 0x4949) && (id != 0x4D4D))\n    {\n      while (length != 0)\n      {\n        if (ReadProfileByte(&exif,&length) != 0x45)\n          continue;\n        if (ReadProfileByte(&exif,&length) != 0x78)\n          continue;\n        if (ReadProfileByte(&exif,&length) != 0x69)\n          continue;\n        if (ReadProfileByte(&exif,&length) != 0x66)\n          continue;\n        if (ReadProfileByte(&exif,&length) != 0x00)\n          continue;\n        if (ReadProfileByte(&exif,&length) != 0x00)\n          continue;\n        break;\n      }\n      if (length < 16)\n        return(MagickFalse);\n      id=(ssize_t) ReadProfileShort(LSBEndian,exif);\n    }\n  endian=LSBEndian;\n  if (id == 0x4949)\n    endian=LSBEndian;\n  else\n    if (id == 0x4D4D)\n      endian=MSBEndian;\n    else\n      return(MagickFalse);\n  if (ReadProfileShort(endian,exif+2) != 0x002a)\n    return(MagickFalse);\n  /*\n    This the offset to the first IFD.\n  */\n  offset=(ssize_t) ReadProfileLong(endian,exif+4);\n  if ((offset < 0) || (size_t) offset >= length)\n    return(MagickFalse);\n  directory=exif+offset;\n  level=0;\n  entry=0;\n  do\n  {\n    if (level > 0)\n      {\n        level--;\n        directory=directory_stack[level].directory;\n        entry=directory_stack[level].entry;\n      }\n    if ((directory < exif) || (directory > (exif+length-2)))\n      break;\n    /*\n      Determine how many entries there are in the current IFD.\n    */\n    number_entries=ReadProfileShort(endian,directory);\n    for ( ; entry < number_entries; entry++)\n    {\n      int\n        components;\n\n      register unsigned char\n        *p,\n        *q;\n\n      size_t\n        number_bytes;\n\n      ssize_t\n        format,\n        tag_value;\n\n      q=(unsigned char *) (directory+2+(12*entry));\n      if (q > (exif+length-12))\n        break;  /* corrupt EXIF */\n      tag_value=(ssize_t) ReadProfileShort(endian,q);\n      format=(ssize_t) ReadProfileShort(endian,q+2);\n      if ((format-1) >= EXIF_NUM_FORMATS)\n        break;\n      components=(ssize_t) ReadProfileLong(endian,q+4);\n      if (components < 0)\n        break;  /* corrupt EXIF */\n      number_bytes=(size_t) components*format_bytes[format];\n      if ((ssize_t) number_bytes < components)\n        break;  /* prevent overflow */\n      if (number_bytes <= 4)\n        p=q+8;\n      else\n        {\n          /*\n            The directory entry contains an offset.\n          */\n          offset=(ssize_t)  ReadProfileLong(endian,q+8);\n          if ((size_t) (offset+number_bytes) > length)\n            continue;\n          if (~length < number_bytes)\n            continue;  /* prevent overflow */\n          p=(unsigned char *) (exif+offset);\n        }\n      switch (tag_value)\n      {\n        case 0x011a:\n        {\n          (void) WriteProfileLong(endian,(size_t) (image->resolution.x+0.5),p);\n          (void) WriteProfileLong(endian,1UL,p+4);\n          break;\n        }\n        case 0x011b:\n        {\n          (void) WriteProfileLong(endian,(size_t) (image->resolution.y+0.5),p);\n          (void) WriteProfileLong(endian,1UL,p+4);\n          break;\n        }\n        case 0x0112:\n        {\n          if (number_bytes == 4)\n            {\n              (void) WriteProfileLong(endian,(size_t) image->orientation,p);\n              break;\n            }\n          (void) WriteProfileShort(endian,(unsigned short) image->orientation,\n            p);\n          break;\n        }\n        case 0x0128:\n        {\n          if (number_bytes == 4)\n            {\n              (void) WriteProfileLong(endian,(size_t) (image->units+1),p);\n              break;\n            }\n          (void) WriteProfileShort(endian,(unsigned short) (image->units+1),p);\n          break;\n        }\n        default:\n          break;\n      }\n      if ((tag_value == TAG_EXIF_OFFSET) || (tag_value == TAG_INTEROP_OFFSET))\n        {\n          offset=(ssize_t)  ReadProfileLong(endian,p);\n          if (((size_t) offset < length) && (level < (MaxDirectoryStack-2)))\n            {\n              directory_stack[level].directory=directory;\n              entry++;\n              directory_stack[level].entry=entry;\n              level++;\n              directory_stack[level].directory=exif+offset;\n              directory_stack[level].entry=0;\n              level++;\n              if ((directory+2+(12*number_entries)) > (exif+length))\n                break;\n              offset=(ssize_t)  ReadProfileLong(endian,directory+2+(12*\n                number_entries));\n              if ((offset != 0) && ((size_t) offset < length) &&\n                  (level < (MaxDirectoryStack-2)))\n                {\n                  directory_stack[level].directory=exif+offset;\n                  directory_stack[level].entry=0;\n                  level++;\n                }\n            }\n          break;\n        }\n    }\n  } while (level > 0);\n  return(MagickTrue);\n}", "func_src_after": "MagickBooleanType SyncExifProfile(Image *image,StringInfo *profile)\n{\n#define MaxDirectoryStack  16\n#define EXIF_DELIMITER  \"\\n\"\n#define EXIF_NUM_FORMATS  12\n#define TAG_EXIF_OFFSET  0x8769\n#define TAG_INTEROP_OFFSET  0xa005\n\n  typedef struct _DirectoryInfo\n  {\n    unsigned char\n      *directory;\n\n    size_t\n      entry;\n  } DirectoryInfo;\n\n  DirectoryInfo\n    directory_stack[MaxDirectoryStack];\n\n  EndianType\n    endian;\n\n  size_t\n    entry,\n    length,\n    number_entries;\n\n  ssize_t\n    id,\n    level,\n    offset;\n\n  static int\n    format_bytes[] = {0, 1, 1, 2, 4, 8, 1, 1, 2, 4, 8, 4, 8};\n\n  unsigned char\n    *directory,\n    *exif;\n\n  /*\n    Set EXIF resolution tag.\n  */\n  length=GetStringInfoLength(profile);\n  exif=GetStringInfoDatum(profile);\n  if (length < 16)\n    return(MagickFalse);\n  id=(ssize_t) ReadProfileShort(LSBEndian,exif);\n  if ((id != 0x4949) && (id != 0x4D4D))\n    {\n      while (length != 0)\n      {\n        if (ReadProfileByte(&exif,&length) != 0x45)\n          continue;\n        if (ReadProfileByte(&exif,&length) != 0x78)\n          continue;\n        if (ReadProfileByte(&exif,&length) != 0x69)\n          continue;\n        if (ReadProfileByte(&exif,&length) != 0x66)\n          continue;\n        if (ReadProfileByte(&exif,&length) != 0x00)\n          continue;\n        if (ReadProfileByte(&exif,&length) != 0x00)\n          continue;\n        break;\n      }\n      if (length < 16)\n        return(MagickFalse);\n      id=(ssize_t) ReadProfileShort(LSBEndian,exif);\n    }\n  endian=LSBEndian;\n  if (id == 0x4949)\n    endian=LSBEndian;\n  else\n    if (id == 0x4D4D)\n      endian=MSBEndian;\n    else\n      return(MagickFalse);\n  if (ReadProfileShort(endian,exif+2) != 0x002a)\n    return(MagickFalse);\n  /*\n    This the offset to the first IFD.\n  */\n  offset=(ssize_t) ReadProfileLong(endian,exif+4);\n  if ((offset < 0) || (size_t) offset >= length)\n    return(MagickFalse);\n  directory=exif+offset;\n  level=0;\n  entry=0;\n  do\n  {\n    if (level > 0)\n      {\n        level--;\n        directory=directory_stack[level].directory;\n        entry=directory_stack[level].entry;\n      }\n    if ((directory < exif) || (directory > (exif+length-2)))\n      break;\n    /*\n      Determine how many entries there are in the current IFD.\n    */\n    number_entries=ReadProfileShort(endian,directory);\n    for ( ; entry < number_entries; entry++)\n    {\n      int\n        components;\n\n      register unsigned char\n        *p,\n        *q;\n\n      size_t\n        number_bytes;\n\n      ssize_t\n        format,\n        tag_value;\n\n      q=(unsigned char *) (directory+2+(12*entry));\n      if (q > (exif+length-12))\n        break;  /* corrupt EXIF */\n      tag_value=(ssize_t) ReadProfileShort(endian,q);\n      format=(ssize_t) ReadProfileShort(endian,q+2);\n      if ((format < 0) || ((format-1) >= EXIF_NUM_FORMATS))\n        break;\n      components=(ssize_t) ReadProfileLong(endian,q+4);\n      if (components < 0)\n        break;  /* corrupt EXIF */\n      number_bytes=(size_t) components*format_bytes[format];\n      if ((ssize_t) number_bytes < components)\n        break;  /* prevent overflow */\n      if (number_bytes <= 4)\n        p=q+8;\n      else\n        {\n          /*\n            The directory entry contains an offset.\n          */\n          offset=(ssize_t)  ReadProfileLong(endian,q+8);\n          if ((size_t) (offset+number_bytes) > length)\n            continue;\n          if (~length < number_bytes)\n            continue;  /* prevent overflow */\n          p=(unsigned char *) (exif+offset);\n        }\n      switch (tag_value)\n      {\n        case 0x011a:\n        {\n          (void) WriteProfileLong(endian,(size_t) (image->resolution.x+0.5),p);\n          (void) WriteProfileLong(endian,1UL,p+4);\n          break;\n        }\n        case 0x011b:\n        {\n          (void) WriteProfileLong(endian,(size_t) (image->resolution.y+0.5),p);\n          (void) WriteProfileLong(endian,1UL,p+4);\n          break;\n        }\n        case 0x0112:\n        {\n          if (number_bytes == 4)\n            {\n              (void) WriteProfileLong(endian,(size_t) image->orientation,p);\n              break;\n            }\n          (void) WriteProfileShort(endian,(unsigned short) image->orientation,\n            p);\n          break;\n        }\n        case 0x0128:\n        {\n          if (number_bytes == 4)\n            {\n              (void) WriteProfileLong(endian,(size_t) (image->units+1),p);\n              break;\n            }\n          (void) WriteProfileShort(endian,(unsigned short) (image->units+1),p);\n          break;\n        }\n        default:\n          break;\n      }\n      if ((tag_value == TAG_EXIF_OFFSET) || (tag_value == TAG_INTEROP_OFFSET))\n        {\n          offset=(ssize_t)  ReadProfileLong(endian,p);\n          if (((size_t) offset < length) && (level < (MaxDirectoryStack-2)))\n            {\n              directory_stack[level].directory=directory;\n              entry++;\n              directory_stack[level].entry=entry;\n              level++;\n              directory_stack[level].directory=exif+offset;\n              directory_stack[level].entry=0;\n              level++;\n              if ((directory+2+(12*number_entries)) > (exif+length))\n                break;\n              offset=(ssize_t)  ReadProfileLong(endian,directory+2+(12*\n                number_entries));\n              if ((offset != 0) && ((size_t) offset < length) &&\n                  (level < (MaxDirectoryStack-2)))\n                {\n                  directory_stack[level].directory=exif+offset;\n                  directory_stack[level].entry=0;\n                  level++;\n                }\n            }\n          break;\n        }\n    }\n  } while (level > 0);\n  return(MagickTrue);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/a7bb158b7bedd1449a34432feb3a67c8f1873bfa", "file_name": "MagickCore/profile.c", "vul_type": "cwe-125", "description": "Write a C function to synchronize EXIF profile resolution tags with an image's resolution and orientation."}
{"func_name": "respond_error", "func_src_before": "    def respond_error(self, context, exception):\n        context.respond_server_error()\n        stack = traceback.format_exc()\n        return \"\"\"\n        <html>\n            <body>\n\n                <style>\n                    body {\n                        font-family: sans-serif;\n                        color: #888;\n                        text-align: center;\n                    }\n\n                    body pre {\n                        width: 600px;\n                        text-align: left;\n                        margin: auto;\n                        font-family: monospace;\n                    }\n                </style>\n\n                <img src=\"/ajenti:static/main/error.jpeg\" />\n                <br/>\n                <p>\n                    Server error\n                </p>\n                <pre>\n%s\n                </pre>\n            </body>\n        </html>\n        \"\"\" % stack", "func_src_after": "    def respond_error(self, context, exception):\n        context.respond_server_error()\n        stack = traceback.format_exc()\n        return \"\"\"\n        <html>\n            <body>\n\n                <style>\n                    body {\n                        font-family: sans-serif;\n                        color: #888;\n                        text-align: center;\n                    }\n\n                    body pre {\n                        width: 600px;\n                        text-align: left;\n                        margin: auto;\n                        font-family: monospace;\n                    }\n                </style>\n\n                <img src=\"/ajenti:static/main/error.jpeg\" />\n                <br/>\n                <p>\n                    Server error\n                </p>\n                <pre>\n%s\n                </pre>\n            </body>\n        </html>\n        \"\"\" % cgi.escape(stack)", "commit_link": "github.com/Eugeny/ajenti/commit/d3fc5eb142ff16d55d158afb050af18d5ff09120", "file_name": "ajenti/routing.py", "vul_type": "cwe-079", "description": "Write a Python function that handles a server error by displaying an error page with a stack trace."}
{"func_name": "simple_search", "func_src_before": "    @classmethod\n    def simple_search(cls, query, using=None, index=None):\n        es_search = cls.search(using=using, index=index)\n        es_query = cls.get_es_query(query=query)\n        highlighted_fields = [f.split('^', 1)[0] for f in cls.search_fields]\n\n        es_search = es_search.query(es_query).highlight(*highlighted_fields)\n        return es_search", "func_src_after": "    @classmethod\n    def simple_search(cls, query, using=None, index=None):\n        \"\"\"\n        Do a search without facets.\n\n        This is used in:\n\n        * The Docsearch API\n        * The Project Admin Search page\n        \"\"\"\n\n        es_search = cls.search(using=using, index=index)\n        es_search = es_search.highlight_options(encoder='html')\n\n        es_query = cls.get_es_query(query=query)\n        highlighted_fields = [f.split('^', 1)[0] for f in cls.search_fields]\n        es_search = es_search.query(es_query).highlight(*highlighted_fields)\n\n        return es_search", "commit_link": "github.com/readthedocs/readthedocs.org/commit/1ebe494ffde18109307f205d2bd94102452f697a", "file_name": "readthedocs/search/documents.py", "vul_type": "cwe-079", "description": "Write a Python class method that performs a simple search with optional highlighting, without using facets."}
{"func_name": "init", "func_src_before": "\tinit : function(settings) {\n\t\tvar theme, nl, baseHREF = \"\", i, cssPath, entities, h, p, src, elements = [], head;\n\n\t\t// IE 5.0x is no longer supported since 5.5, 6.0 and 7.0 now exists. We can't support old browsers forever, sorry.\n\t\tif (this.isMSIE5_0)\n\t\t\treturn;\n\n\t\tthis.settings = settings;\n\n\t\t// Check if valid browser has execcommand support\n\t\tif (typeof(document.execCommand) == 'undefined')\n\t\t\treturn;\n\n\t\t// Get script base path\n\t\tif (!tinyMCE.baseURL) {\n\t\t\t// Search through head\n\t\t\thead = document.getElementsByTagName('head')[0];\n\n\t\t\tif (head) {\n\t\t\t\tfor (i=0, nl = head.getElementsByTagName('script'); i<nl.length; i++)\n\t\t\t\t\telements.push(nl[i]);\n\t\t\t}\n\n\t\t\t// Search through rest of document\n\t\t\tfor (i=0, nl = document.getElementsByTagName('script'); i<nl.length; i++)\n\t\t\t\telements.push(nl[i]);\n\n\t\t\t// If base element found, add that infront of baseURL\n\t\t\tnl = document.getElementsByTagName('base');\n\t\t\tfor (i=0; i<nl.length; i++) {\n\t\t\t\tif (nl[i].href)\n\t\t\t\t\tbaseHREF = nl[i].href;\n\t\t\t}\n\n\t\t\tfor (i=0; i<elements.length; i++) {\n\t\t\t\tif (elements[i].src && (elements[i].src.indexOf(\"tiny_mce.js\") != -1 || elements[i].src.indexOf(\"tiny_mce_dev.js\") != -1 || elements[i].src.indexOf(\"tiny_mce_src.js\") != -1 || elements[i].src.indexOf(\"tiny_mce_gzip\") != -1)) {\n\t\t\t\t\tsrc = elements[i].src;\n\n\t\t\t\t\ttinyMCE.srcMode = (src.indexOf('_src') != -1 || src.indexOf('_dev') != -1) ? '_src' : '';\n\t\t\t\t\ttinyMCE.gzipMode = src.indexOf('_gzip') != -1;\n\t\t\t\t\tsrc = src.substring(0, src.lastIndexOf('/'));\n\n\t\t\t\t\tif (settings.exec_mode == \"src\" || settings.exec_mode == \"normal\")\n\t\t\t\t\t\ttinyMCE.srcMode = settings.exec_mode == \"src\" ? '_src' : '';\n\n\t\t\t\t\t// Force it absolute if page has a base href\n\t\t\t\t\tif (baseHREF !== '' && src.indexOf('://') == -1)\n\t\t\t\t\t\ttinyMCE.baseURL = baseHREF + src;\n\t\t\t\t\telse\n\t\t\t\t\t\ttinyMCE.baseURL = src;\n\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Get document base path\n\t\tthis.documentBasePath = escapePath(document.location.href);\n\t\tif (this.documentBasePath.indexOf('?') != -1)\n\t\t\tthis.documentBasePath = this.documentBasePath.substring(0, this.documentBasePath.indexOf('?'));\n\t\tthis.documentURL = this.documentBasePath;\n\t\tthis.documentBasePath = this.documentBasePath.substring(0, this.documentBasePath.lastIndexOf('/'));\n\n\t\t// If not HTTP absolute\n\t\tif (tinyMCE.baseURL.indexOf('://') == -1 && tinyMCE.baseURL.charAt(0) != '/') {\n\t\t\t// If site absolute\n\t\t\ttinyMCE.baseURL = this.documentBasePath + \"/\" + tinyMCE.baseURL;\n\t\t}\n\n\t\t// Set default values on settings\n\t\tthis._def(\"mode\", \"none\");\n\t\tthis._def(\"theme\", \"advanced\");\n\t\tthis._def(\"plugins\", \"\", true);\n\t\tthis._def(\"language\", \"en\");\n\t\tthis._def(\"docs_language\", this.settings.language);\n\t\tthis._def(\"elements\", \"\");\n\t\tthis._def(\"textarea_trigger\", \"mce_editable\");\n\t\tthis._def(\"editor_selector\", \"\");\n\t\tthis._def(\"editor_deselector\", \"mceNoEditor\");\n\t\tthis._def(\"valid_elements\", \"+a[id|style|rel|rev|charset|hreflang|dir|lang|tabindex|accesskey|type|name|href|target|title|class|onfocus|onblur|onclick|ondblclick|onmousedown|onmouseup|onmouseover|onmousemove|onmouseout|onkeypress|onkeydown|onkeyup],-strong/-b[class|style],-em/-i[class|style],-strike[class|style],-u[class|style],#p[id|style|dir|class|align],-ol[class|style],-ul[class|style],-li[class|style],br,img[id|dir|lang|longdesc|usemap|style|class|src|onmouseover|onmouseout|border|alt=|title|hspace|vspace|width|height|align],-sub[style|class],-sup[style|class],-blockquote[dir|style],-table[border=0|cellspacing|cellpadding|width|height|class|align|summary|style|dir|id|lang|bgcolor|background|bordercolor],-tr[id|lang|dir|class|rowspan|width|height|align|valign|style|bgcolor|background|bordercolor],tbody[id|class],thead[id|class],tfoot[id|class],#td[id|lang|dir|class|colspan|rowspan|width|height|align|valign|style|bgcolor|background|bordercolor|scope],-th[id|lang|dir|class|colspan|rowspan|width|height|align|valign|style|scope],caption[id|lang|dir|class|style],-div[id|dir|class|align|style],-span[style|class|align],-pre[class|align|style],address[class|align|style],-h1[id|style|dir|class|align],-h2[id|style|dir|class|align],-h3[id|style|dir|class|align],-h4[id|style|dir|class|align],-h5[id|style|dir|class|align],-h6[id|style|dir|class|align],hr[class|style],-font[face|size|style|id|class|dir|color],dd[id|class|title|style|dir|lang],dl[id|class|title|style|dir|lang],dt[id|class|title|style|dir|lang],cite[title|id|class|style|dir|lang],abbr[title|id|class|style|dir|lang],acronym[title|id|class|style|dir|lang],del[title|id|class|style|dir|lang|datetime|cite],ins[title|id|class|style|dir|lang|datetime|cite]\");\n\t\tthis._def(\"extended_valid_elements\", \"\");\n\t\tthis._def(\"invalid_elements\", \"\");\n\t\tthis._def(\"encoding\", \"\");\n\t\tthis._def(\"urlconverter_callback\", tinyMCE.getParam(\"urlconvertor_callback\", \"TinyMCE_Engine.prototype.convertURL\"));\n\t\tthis._def(\"save_callback\", \"\");\n\t\tthis._def(\"force_br_newlines\", false);\n\t\tthis._def(\"force_p_newlines\", true);\n\t\tthis._def(\"add_form_submit_trigger\", true);\n\t\tthis._def(\"relative_urls\", true);\n\t\tthis._def(\"remove_script_host\", true);\n\t\tthis._def(\"focus_alert\", true);\n\t\tthis._def(\"document_base_url\", this.documentURL);\n\t\tthis._def(\"visual\", true);\n\t\tthis._def(\"visual_table_class\", \"mceVisualAid\");\n\t\tthis._def(\"setupcontent_callback\", \"\");\n\t\tthis._def(\"fix_content_duplication\", true);\n\t\tthis._def(\"custom_undo_redo\", true);\n\t\tthis._def(\"custom_undo_redo_levels\", -1);\n\t\tthis._def(\"custom_undo_redo_keyboard_shortcuts\", true);\n\t\tthis._def(\"custom_undo_redo_restore_selection\", true);\n\t\tthis._def(\"custom_undo_redo_global\", false);\n\t\tthis._def(\"verify_html\", true);\n\t\tthis._def(\"apply_source_formatting\", false);\n\t\tthis._def(\"directionality\", \"ltr\");\n\t\tthis._def(\"cleanup_on_startup\", false);\n\t\tthis._def(\"inline_styles\", false);\n\t\tthis._def(\"convert_newlines_to_brs\", false);\n\t\tthis._def(\"auto_reset_designmode\", true);\n\t\tthis._def(\"entities\", \"39,#39,160,nbsp,161,iexcl,162,cent,163,pound,164,curren,165,yen,166,brvbar,167,sect,168,uml,169,copy,170,ordf,171,laquo,172,not,173,shy,174,reg,175,macr,176,deg,177,plusmn,178,sup2,179,sup3,180,acute,181,micro,182,para,183,middot,184,cedil,185,sup1,186,ordm,187,raquo,188,frac14,189,frac12,190,frac34,191,iquest,192,Agrave,193,Aacute,194,Acirc,195,Atilde,196,Auml,197,Aring,198,AElig,199,Ccedil,200,Egrave,201,Eacute,202,Ecirc,203,Euml,204,Igrave,205,Iacute,206,Icirc,207,Iuml,208,ETH,209,Ntilde,210,Ograve,211,Oacute,212,Ocirc,213,Otilde,214,Ouml,215,times,216,Oslash,217,Ugrave,218,Uacute,219,Ucirc,220,Uuml,221,Yacute,222,THORN,223,szlig,224,agrave,225,aacute,226,acirc,227,atilde,228,auml,229,aring,230,aelig,231,ccedil,232,egrave,233,eacute,234,ecirc,235,euml,236,igrave,237,iacute,238,icirc,239,iuml,240,eth,241,ntilde,242,ograve,243,oacute,244,ocirc,245,otilde,246,ouml,247,divide,248,oslash,249,ugrave,250,uacute,251,ucirc,252,uuml,253,yacute,254,thorn,255,yuml,402,fnof,913,Alpha,914,Beta,915,Gamma,916,Delta,917,Epsilon,918,Zeta,919,Eta,920,Theta,921,Iota,922,Kappa,923,Lambda,924,Mu,925,Nu,926,Xi,927,Omicron,928,Pi,929,Rho,931,Sigma,932,Tau,933,Upsilon,934,Phi,935,Chi,936,Psi,937,Omega,945,alpha,946,beta,947,gamma,948,delta,949,epsilon,950,zeta,951,eta,952,theta,953,iota,954,kappa,955,lambda,956,mu,957,nu,958,xi,959,omicron,960,pi,961,rho,962,sigmaf,963,sigma,964,tau,965,upsilon,966,phi,967,chi,968,psi,969,omega,977,thetasym,978,upsih,982,piv,8226,bull,8230,hellip,8242,prime,8243,Prime,8254,oline,8260,frasl,8472,weierp,8465,image,8476,real,8482,trade,8501,alefsym,8592,larr,8593,uarr,8594,rarr,8595,darr,8596,harr,8629,crarr,8656,lArr,8657,uArr,8658,rArr,8659,dArr,8660,hArr,8704,forall,8706,part,8707,exist,8709,empty,8711,nabla,8712,isin,8713,notin,8715,ni,8719,prod,8721,sum,8722,minus,8727,lowast,8730,radic,8733,prop,8734,infin,8736,ang,8743,and,8744,or,8745,cap,8746,cup,8747,int,8756,there4,8764,sim,8773,cong,8776,asymp,8800,ne,8801,equiv,8804,le,8805,ge,8834,sub,8835,sup,8836,nsub,8838,sube,8839,supe,8853,oplus,8855,otimes,8869,perp,8901,sdot,8968,lceil,8969,rceil,8970,lfloor,8971,rfloor,9001,lang,9002,rang,9674,loz,9824,spades,9827,clubs,9829,hearts,9830,diams,34,quot,38,amp,60,lt,62,gt,338,OElig,339,oelig,352,Scaron,353,scaron,376,Yuml,710,circ,732,tilde,8194,ensp,8195,emsp,8201,thinsp,8204,zwnj,8205,zwj,8206,lrm,8207,rlm,8211,ndash,8212,mdash,8216,lsquo,8217,rsquo,8218,sbquo,8220,ldquo,8221,rdquo,8222,bdquo,8224,dagger,8225,Dagger,8240,permil,8249,lsaquo,8250,rsaquo,8364,euro\", true);\n\t\tthis._def(\"entity_encoding\", \"named\");\n\t\tthis._def(\"cleanup_callback\", \"\");\n\t\tthis._def(\"add_unload_trigger\", true);\n\t\tthis._def(\"ask\", false);\n\t\tthis._def(\"nowrap\", false);\n\t\tthis._def(\"auto_resize\", false);\n\t\tthis._def(\"auto_focus\", false);\n\t\tthis._def(\"cleanup\", true);\n\t\tthis._def(\"remove_linebreaks\", true);\n\t\tthis._def(\"button_tile_map\", false);\n\t\tthis._def(\"submit_patch\", true);\n\t\tthis._def(\"browsers\", \"msie,safari,gecko,opera\", true);\n\t\tthis._def(\"dialog_type\", \"window\");\n\t\tthis._def(\"accessibility_warnings\", true);\n\t\tthis._def(\"accessibility_focus\", true);\n\t\tthis._def(\"merge_styles_invalid_parents\", \"\");\n\t\tthis._def(\"force_hex_style_colors\", true);\n\t\tthis._def(\"trim_span_elements\", true);\n\t\tthis._def(\"convert_fonts_to_spans\", false);\n\t\tthis._def(\"doctype\", '<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\">');\n\t\tthis._def(\"font_size_classes\", '');\n\t\tthis._def(\"font_size_style_values\", 'xx-small,x-small,small,medium,large,x-large,xx-large', true);\n\t\tthis._def(\"event_elements\", 'a,img', true);\n\t\tthis._def(\"convert_urls\", true);\n\t\tthis._def(\"table_inline_editing\", false);\n\t\tthis._def(\"object_resizing\", true);\n\t\tthis._def(\"custom_shortcuts\", true);\n\t\tthis._def(\"convert_on_click\", false);\n\t\tthis._def(\"content_css\", '');\n\t\tthis._def(\"fix_list_elements\", true);\n\t\tthis._def(\"fix_table_elements\", false);\n\t\tthis._def(\"strict_loading_mode\", document.contentType == 'application/xhtml+xml');\n\t\tthis._def(\"hidden_tab_class\", '');\n\t\tthis._def(\"display_tab_class\", '');\n\t\tthis._def(\"gecko_spellcheck\", false);\n\t\tthis._def(\"hide_selects_on_submit\", true);\n\t\tthis._def(\"forced_root_block\", false);\n\t\tthis._def(\"remove_trailing_nbsp\", false);\n\t\tthis._def(\"save_on_tinymce_forms\", false);\n\n\t\t// Force strict loading mode to false on non Gecko browsers\n\t\tif (this.isMSIE && !this.isOpera)\n\t\t\tthis.settings.strict_loading_mode = false;\n\n\t\t// Browser check IE\n\t\tif (this.isMSIE && this.settings.browsers.indexOf('msie') == -1)\n\t\t\treturn;\n\n\t\t// Browser check Gecko\n\t\tif (this.isGecko && this.settings.browsers.indexOf('gecko') == -1)\n\t\t\treturn;\n\n\t\t// Browser check Safari\n\t\tif (this.isSafari && this.settings.browsers.indexOf('safari') == -1)\n\t\t\treturn;\n\n\t\t// Browser check Opera\n\t\tif (this.isOpera && this.settings.browsers.indexOf('opera') == -1)\n\t\t\treturn;\n\n\t\t// If not super absolute make it so\n\t\tbaseHREF = tinyMCE.settings.document_base_url;\n\t\th = document.location.href;\n\t\tp = h.indexOf('://');\n\t\tif (p > 0 && document.location.protocol != \"file:\") {\n\t\t\tp = h.indexOf('/', p + 3);\n\t\t\th = h.substring(0, p);\n\n\t\t\tif (baseHREF.indexOf('://') == -1)\n\t\t\t\tbaseHREF = h + baseHREF;\n\n\t\t\ttinyMCE.settings.document_base_url = baseHREF;\n\t\t\ttinyMCE.settings.document_base_prefix = h;\n\t\t}\n\n\t\t// Trim away query part\n\t\tif (baseHREF.indexOf('?') != -1)\n\t\t\tbaseHREF = baseHREF.substring(0, baseHREF.indexOf('?'));\n\n\t\tthis.settings.base_href = baseHREF.substring(0, baseHREF.lastIndexOf('/')) + \"/\";\n\n\t\ttheme = this.settings.theme;\n\t\tthis.inlineStrict = 'A|BR|SPAN|BDO|MAP|OBJECT|IMG|TT|I|B|BIG|SMALL|EM|STRONG|DFN|CODE|Q|SAMP|KBD|VAR|CITE|ABBR|ACRONYM|SUB|SUP|#text|#comment';\n\t\tthis.inlineTransitional = 'A|BR|SPAN|BDO|OBJECT|APPLET|IMG|MAP|IFRAME|TT|I|B|U|S|STRIKE|BIG|SMALL|FONT|BASEFONT|EM|STRONG|DFN|CODE|Q|SAMP|KBD|VAR|CITE|ABBR|ACRONYM|SUB|SUP|INPUT|SELECT|TEXTAREA|LABEL|BUTTON|#text|#comment';\n\t\tthis.blockElms = 'H[1-6]|P|DIV|ADDRESS|PRE|FORM|TABLE|LI|OL|UL|TD|CAPTION|BLOCKQUOTE|CENTER|DL|DT|DD|DIR|FIELDSET|FORM|NOSCRIPT|NOFRAMES|MENU|ISINDEX|SAMP';\n\t\tthis.blockRegExp = new RegExp(\"^(\" + this.blockElms + \")$\", \"i\");\n\t\tthis.posKeyCodes = [13,45,36,35,33,34,37,38,39,40];\n\t\tthis.uniqueURL = 'javascript:void(091039730);'; // Make unique URL non real URL\n\t\tthis.uniqueTag = '<div id=\"mceTMPElement\" style=\"display: none\">TMP</div>';\n\t\tthis.callbacks = ['onInit', 'getInfo', 'getEditorTemplate', 'setupContent', 'onChange', 'onPageLoad', 'handleNodeChange', 'initInstance', 'execCommand', 'getControlHTML', 'handleEvent', 'cleanup', 'removeInstance'];\n\n\t\t// Theme url\n\t\tthis.settings.theme_href = tinyMCE.baseURL + \"/themes/\" + theme;\n\n\t\tif (!tinyMCE.isIE || tinyMCE.isOpera)\n\t\t\tthis.settings.force_br_newlines = false;\n\n\t\tif (tinyMCE.getParam(\"popups_css\", false)) {\n\t\t\tcssPath = tinyMCE.getParam(\"popups_css\", \"\");\n\n\t\t\t// Is relative\n\t\t\tif (cssPath.indexOf('://') == -1 && cssPath.charAt(0) != '/')\n\t\t\t\tthis.settings.popups_css = this.documentBasePath + \"/\" + cssPath;\n\t\t\telse\n\t\t\t\tthis.settings.popups_css = cssPath;\n\t\t} else\n\t\t\tthis.settings.popups_css = tinyMCE.baseURL + \"/themes/\" + theme + \"/css/editor_popup.css\";\n\n\t\tif (tinyMCE.getParam(\"editor_css\", false)) {\n\t\t\tcssPath = tinyMCE.getParam(\"editor_css\", \"\");\n\n\t\t\t// Is relative\n\t\t\tif (cssPath.indexOf('://') == -1 && cssPath.charAt(0) != '/')\n\t\t\t\tthis.settings.editor_css = this.documentBasePath + \"/\" + cssPath;\n\t\t\telse\n\t\t\t\tthis.settings.editor_css = cssPath;\n\t\t} else {\n\t\t\tif (this.settings.editor_css !== '')\n\t\t\t\tthis.settings.editor_css = tinyMCE.baseURL + \"/themes/\" + theme + \"/css/editor_ui.css\";\n\t\t}\n\n\t\t// Only do this once\n\t\tif (this.configs.length == 0) {\n\t\t\tif (typeof(TinyMCECompressed) == \"undefined\") {\n\t\t\t\ttinyMCE.addEvent(window, \"DOMContentLoaded\", TinyMCE_Engine.prototype.onLoad);\n\n\t\t\t\tif (tinyMCE.isRealIE) {\n\t\t\t\t\tif (document.body)\n\t\t\t\t\t\ttinyMCE.addEvent(document.body, \"readystatechange\", TinyMCE_Engine.prototype.onLoad);\n\t\t\t\t\telse\n\t\t\t\t\t\ttinyMCE.addEvent(document, \"readystatechange\", TinyMCE_Engine.prototype.onLoad);\n\t\t\t\t}\n\n\t\t\t\ttinyMCE.addEvent(window, \"load\", TinyMCE_Engine.prototype.onLoad);\n\t\t\t\ttinyMCE._addUnloadEvents();\n\t\t\t}\n\t\t}\n\n\t\tthis.loadScript(tinyMCE.baseURL + '/themes/' + this.settings.theme + '/editor_template' + tinyMCE.srcMode + '.js');\n\t\tthis.loadScript(tinyMCE.baseURL + '/langs/' + this.settings.language +  '.js');\n\t\tthis.loadCSS(this.settings.editor_css);\n\n\t\t// Add plugins\n\t\tp = tinyMCE.getParam('plugins', '', true, ',');\n\t\tif (p.length > 0) {\n\t\t\tfor (i=0; i<p.length; i++) {\n\t\t\t\tif (p[i].charAt(0) != '-')\n\t\t\t\t\tthis.loadScript(tinyMCE.baseURL + '/plugins/' + p[i] + '/editor_plugin' + tinyMCE.srcMode + '.js');\n\t\t\t}\n\t\t}\n\n\t\t// Setup entities\n\t\tif (tinyMCE.getParam('entity_encoding') == 'named') {\n\t\t\tsettings.cleanup_entities = [];\n\t\t\tentities = tinyMCE.getParam('entities', '', true, ',');\n\t\t\tfor (i=0; i<entities.length; i+=2)\n\t\t\t\tsettings.cleanup_entities['c' + entities[i]] = entities[i+1];\n\t\t}\n\n\t\t// Save away this config\n\t\tsettings.index = this.configs.length;\n\t\tthis.configs[this.configs.length] = settings;\n\n\t\t// Start loading first one in chain\n\t\tthis.loadNextScript();\n\n\t\t// Force flicker free CSS backgrounds in IE\n\t\tif (this.isIE && !this.isOpera) {\n\t\t\ttry {\n\t\t\t\tdocument.execCommand('BackgroundImageCache', false, true);\n\t\t\t} catch (e) {\n\t\t\t\t// Ignore\n\t\t\t}\n\t\t}\n\n\t\t// Setup XML encoding regexps\n\t\tthis.xmlEncodeRe = new RegExp('[<>&\"]', 'g');\n\t},", "func_src_after": "\tinit : function(settings) {\n\t\tvar theme, nl, baseHREF = \"\", i, cssPath, entities, h, p, src, elements = [], head;\n\n\t\t// IE 5.0x is no longer supported since 5.5, 6.0 and 7.0 now exists. We can't support old browsers forever, sorry.\n\t\tif (this.isMSIE5_0)\n\t\t\treturn;\n\n\t\tthis.settings = settings;\n\n\t\t// Check if valid browser has execcommand support\n\t\tif (typeof(document.execCommand) == 'undefined')\n\t\t\treturn;\n\n\t\t// Get script base path\n\t\tif (!tinyMCE.baseURL) {\n\t\t\t// Search through head\n\t\t\thead = document.getElementsByTagName('head')[0];\n\n\t\t\tif (head) {\n\t\t\t\tfor (i=0, nl = head.getElementsByTagName('script'); i<nl.length; i++)\n\t\t\t\t\telements.push(nl[i]);\n\t\t\t}\n\n\t\t\t// Search through rest of document\n\t\t\tfor (i=0, nl = document.getElementsByTagName('script'); i<nl.length; i++)\n\t\t\t\telements.push(nl[i]);\n\n\t\t\t// If base element found, add that infront of baseURL\n\t\t\tnl = document.getElementsByTagName('base');\n\t\t\tfor (i=0; i<nl.length; i++) {\n\t\t\t\tif (nl[i].href)\n\t\t\t\t\tbaseHREF = nl[i].href;\n\t\t\t}\n\n\t\t\tfor (i=0; i<elements.length; i++) {\n\t\t\t\tif (elements[i].src && (elements[i].src.indexOf(\"tiny_mce.js\") != -1 || elements[i].src.indexOf(\"tiny_mce_dev.js\") != -1 || elements[i].src.indexOf(\"tiny_mce_src.js\") != -1 || elements[i].src.indexOf(\"tiny_mce_gzip\") != -1)) {\n\t\t\t\t\tsrc = elements[i].src;\n\n\t\t\t\t\ttinyMCE.srcMode = (src.indexOf('_src') != -1 || src.indexOf('_dev') != -1) ? '_src' : '';\n\t\t\t\t\ttinyMCE.gzipMode = src.indexOf('_gzip') != -1;\n\t\t\t\t\tsrc = src.substring(0, src.lastIndexOf('/'));\n\n\t\t\t\t\tif (settings.exec_mode == \"src\" || settings.exec_mode == \"normal\")\n\t\t\t\t\t\ttinyMCE.srcMode = settings.exec_mode == \"src\" ? '_src' : '';\n\n\t\t\t\t\t// Force it absolute if page has a base href\n\t\t\t\t\tif (baseHREF !== '' && src.indexOf('://') == -1)\n\t\t\t\t\t\ttinyMCE.baseURL = baseHREF + src;\n\t\t\t\t\telse\n\t\t\t\t\t\ttinyMCE.baseURL = src;\n\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Get document base path\n\t\tthis.documentBasePath = escapePath(document.location.href);\n\t\tif (this.documentBasePath.indexOf('?') != -1)\n\t\t\tthis.documentBasePath = this.documentBasePath.substring(0, this.documentBasePath.indexOf('?'));\n\t\tthis.documentURL = this.documentBasePath;\n\t\tthis.documentBasePath = this.documentBasePath.substring(0, this.documentBasePath.lastIndexOf('/'));\n\n\t\t// If not HTTP absolute\n\t\tif (tinyMCE.baseURL.indexOf('://') == -1 && tinyMCE.baseURL.charAt(0) != '/') {\n\t\t\t// If site absolute\n\t\t\ttinyMCE.baseURL = this.documentBasePath + \"/\" + tinyMCE.baseURL;\n\t\t}\n\n\t\t// Set default values on settings\n\t\tthis._def(\"mode\", \"none\");\n\t\tthis._def(\"theme\", \"advanced\");\n\t\tthis._def(\"plugins\", \"\", true);\n\t\tthis._def(\"language\", \"en\");\n\t\tthis._def(\"docs_language\", this.settings.language);\n\t\tthis._def(\"elements\", \"\");\n\t\tthis._def(\"textarea_trigger\", \"mce_editable\");\n\t\tthis._def(\"editor_selector\", \"\");\n\t\tthis._def(\"editor_deselector\", \"mceNoEditor\");\n\t\tthis._def(\"valid_elements\", \"+a[id|style|rel|rev|charset|hreflang|dir|lang|tabindex|accesskey|type|name|href|target|title|class|onfocus|onblur|onclick|ondblclick|onmousedown|onmouseup|onmouseover|onmousemove|onmouseout|onkeypress|onkeydown|onkeyup],-strong/-b[class|style],-em/-i[class|style],-strike[class|style],-u[class|style],#p[id|style|dir|class|align],-ol[class|style],-ul[class|style],-li[class|style],br,img[id|dir|lang|longdesc|usemap|style|class|src|onmouseover|onmouseout|border|alt=|title|hspace|vspace|width|height|align],-sub[style|class],-sup[style|class],-blockquote[dir|style],-table[border=0|cellspacing|cellpadding|width|height|class|align|summary|style|dir|id|lang|bgcolor|background|bordercolor],-tr[id|lang|dir|class|rowspan|width|height|align|valign|style|bgcolor|background|bordercolor],tbody[id|class],thead[id|class],tfoot[id|class],#td[id|lang|dir|class|colspan|rowspan|width|height|align|valign|style|bgcolor|background|bordercolor|scope],-th[id|lang|dir|class|colspan|rowspan|width|height|align|valign|style|scope],caption[id|lang|dir|class|style],-div[id|dir|class|align|style],-span[style|class|align],-pre[class|align|style],address[class|align|style],-h1[id|style|dir|class|align],-h2[id|style|dir|class|align],-h3[id|style|dir|class|align],-h4[id|style|dir|class|align],-h5[id|style|dir|class|align],-h6[id|style|dir|class|align],hr[class|style],-font[face|size|style|id|class|dir|color],dd[id|class|title|style|dir|lang],dl[id|class|title|style|dir|lang],dt[id|class|title|style|dir|lang],cite[title|id|class|style|dir|lang],abbr[title|id|class|style|dir|lang],acronym[title|id|class|style|dir|lang],del[title|id|class|style|dir|lang|datetime|cite],ins[title|id|class|style|dir|lang|datetime|cite]\");\n\t\tthis._def(\"extended_valid_elements\", \"\");\n\t\tthis._def(\"invalid_elements\", \"\");\n\t\tthis._def(\"encoding\", \"\");\n\t\tthis._def(\"urlconverter_callback\", tinyMCE.getParam(\"urlconvertor_callback\", \"TinyMCE_Engine.prototype.convertURL\"));\n\t\tthis._def(\"save_callback\", \"\");\n\t\tthis._def(\"force_br_newlines\", false);\n\t\tthis._def(\"force_p_newlines\", true);\n\t\tthis._def(\"add_form_submit_trigger\", true);\n\t\tthis._def(\"relative_urls\", true);\n\t\tthis._def(\"remove_script_host\", true);\n\t\tthis._def(\"focus_alert\", true);\n\t\tthis._def(\"document_base_url\", this.documentURL);\n\t\tthis._def(\"visual\", true);\n\t\tthis._def(\"visual_table_class\", \"mceVisualAid\");\n\t\tthis._def(\"setupcontent_callback\", \"\");\n\t\tthis._def(\"fix_content_duplication\", true);\n\t\tthis._def(\"custom_undo_redo\", true);\n\t\tthis._def(\"custom_undo_redo_levels\", -1);\n\t\tthis._def(\"custom_undo_redo_keyboard_shortcuts\", true);\n\t\tthis._def(\"custom_undo_redo_restore_selection\", true);\n\t\tthis._def(\"custom_undo_redo_global\", false);\n\t\tthis._def(\"verify_html\", true);\n\t\tthis._def(\"apply_source_formatting\", false);\n\t\tthis._def(\"directionality\", \"ltr\");\n\t\tthis._def(\"cleanup_on_startup\", false);\n\t\tthis._def(\"inline_styles\", false);\n\t\tthis._def(\"convert_newlines_to_brs\", false);\n\t\tthis._def(\"auto_reset_designmode\", true);\n\t\tthis._def(\"entities\", \"39,#39,160,nbsp,161,iexcl,162,cent,163,pound,164,curren,165,yen,166,brvbar,167,sect,168,uml,169,copy,170,ordf,171,laquo,172,not,173,shy,174,reg,175,macr,176,deg,177,plusmn,178,sup2,179,sup3,180,acute,181,micro,182,para,183,middot,184,cedil,185,sup1,186,ordm,187,raquo,188,frac14,189,frac12,190,frac34,191,iquest,192,Agrave,193,Aacute,194,Acirc,195,Atilde,196,Auml,197,Aring,198,AElig,199,Ccedil,200,Egrave,201,Eacute,202,Ecirc,203,Euml,204,Igrave,205,Iacute,206,Icirc,207,Iuml,208,ETH,209,Ntilde,210,Ograve,211,Oacute,212,Ocirc,213,Otilde,214,Ouml,215,times,216,Oslash,217,Ugrave,218,Uacute,219,Ucirc,220,Uuml,221,Yacute,222,THORN,223,szlig,224,agrave,225,aacute,226,acirc,227,atilde,228,auml,229,aring,230,aelig,231,ccedil,232,egrave,233,eacute,234,ecirc,235,euml,236,igrave,237,iacute,238,icirc,239,iuml,240,eth,241,ntilde,242,ograve,243,oacute,244,ocirc,245,otilde,246,ouml,247,divide,248,oslash,249,ugrave,250,uacute,251,ucirc,252,uuml,253,yacute,254,thorn,255,yuml,402,fnof,913,Alpha,914,Beta,915,Gamma,916,Delta,917,Epsilon,918,Zeta,919,Eta,920,Theta,921,Iota,922,Kappa,923,Lambda,924,Mu,925,Nu,926,Xi,927,Omicron,928,Pi,929,Rho,931,Sigma,932,Tau,933,Upsilon,934,Phi,935,Chi,936,Psi,937,Omega,945,alpha,946,beta,947,gamma,948,delta,949,epsilon,950,zeta,951,eta,952,theta,953,iota,954,kappa,955,lambda,956,mu,957,nu,958,xi,959,omicron,960,pi,961,rho,962,sigmaf,963,sigma,964,tau,965,upsilon,966,phi,967,chi,968,psi,969,omega,977,thetasym,978,upsih,982,piv,8226,bull,8230,hellip,8242,prime,8243,Prime,8254,oline,8260,frasl,8472,weierp,8465,image,8476,real,8482,trade,8501,alefsym,8592,larr,8593,uarr,8594,rarr,8595,darr,8596,harr,8629,crarr,8656,lArr,8657,uArr,8658,rArr,8659,dArr,8660,hArr,8704,forall,8706,part,8707,exist,8709,empty,8711,nabla,8712,isin,8713,notin,8715,ni,8719,prod,8721,sum,8722,minus,8727,lowast,8730,radic,8733,prop,8734,infin,8736,ang,8743,and,8744,or,8745,cap,8746,cup,8747,int,8756,there4,8764,sim,8773,cong,8776,asymp,8800,ne,8801,equiv,8804,le,8805,ge,8834,sub,8835,sup,8836,nsub,8838,sube,8839,supe,8853,oplus,8855,otimes,8869,perp,8901,sdot,8968,lceil,8969,rceil,8970,lfloor,8971,rfloor,9001,lang,9002,rang,9674,loz,9824,spades,9827,clubs,9829,hearts,9830,diams,34,quot,38,amp,60,lt,62,gt,338,OElig,339,oelig,352,Scaron,353,scaron,376,Yuml,710,circ,732,tilde,8194,ensp,8195,emsp,8201,thinsp,8204,zwnj,8205,zwj,8206,lrm,8207,rlm,8211,ndash,8212,mdash,8216,lsquo,8217,rsquo,8218,sbquo,8220,ldquo,8221,rdquo,8222,bdquo,8224,dagger,8225,Dagger,8240,permil,8249,lsaquo,8250,rsaquo,8364,euro\", true);\n\t\tthis._def(\"entity_encoding\", \"named\");\n\t\tthis._def(\"cleanup_callback\", \"\");\n\t\tthis._def(\"add_unload_trigger\", true);\n\t\tthis._def(\"ask\", false);\n\t\tthis._def(\"nowrap\", false);\n\t\tthis._def(\"auto_resize\", false);\n\t\tthis._def(\"auto_focus\", false);\n\t\tthis._def(\"cleanup\", true);\n\t\tthis._def(\"remove_linebreaks\", true);\n\t\tthis._def(\"button_tile_map\", false);\n\t\tthis._def(\"submit_patch\", true);\n\t\tthis._def(\"browsers\", \"msie,safari,gecko,opera\", true);\n\t\tthis._def(\"dialog_type\", \"window\");\n\t\tthis._def(\"accessibility_warnings\", true);\n\t\tthis._def(\"accessibility_focus\", true);\n\t\tthis._def(\"merge_styles_invalid_parents\", \"\");\n\t\tthis._def(\"force_hex_style_colors\", true);\n\t\tthis._def(\"trim_span_elements\", true);\n\t\tthis._def(\"convert_fonts_to_spans\", false);\n\t\tthis._def(\"doctype\", '<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\">');\n\t\tthis._def(\"font_size_classes\", '');\n\t\tthis._def(\"font_size_style_values\", 'xx-small,x-small,small,medium,large,x-large,xx-large', true);\n\t\tthis._def(\"event_elements\", 'a,img', true);\n\t\tthis._def(\"convert_urls\", true);\n\t\tthis._def(\"table_inline_editing\", false);\n\t\tthis._def(\"object_resizing\", true);\n\t\tthis._def(\"custom_shortcuts\", true);\n\t\tthis._def(\"convert_on_click\", false);\n\t\tthis._def(\"content_css\", '');\n\t\tthis._def(\"fix_list_elements\", true);\n\t\tthis._def(\"fix_table_elements\", false);\n\t\tthis._def(\"strict_loading_mode\", document.contentType == 'application/xhtml+xml');\n\t\tthis._def(\"hidden_tab_class\", '');\n\t\tthis._def(\"display_tab_class\", '');\n\t\tthis._def(\"gecko_spellcheck\", false);\n\t\tthis._def(\"hide_selects_on_submit\", true);\n\t\tthis._def(\"forced_root_block\", false);\n\t\tthis._def(\"remove_trailing_nbsp\", false);\n\t\tthis._def(\"save_on_tinymce_forms\", false);\n\n\t\t// Force strict loading mode to false on non Gecko browsers\n\t\tif (this.isMSIE && !this.isOpera)\n\t\t\tthis.settings.strict_loading_mode = false;\n\n\t\t// Browser check IE\n\t\tif (this.isMSIE && this.settings.browsers.indexOf('msie') == -1)\n\t\t\treturn;\n\n\t\t// Browser check Gecko\n\t\tif (this.isGecko && this.settings.browsers.indexOf('gecko') == -1)\n\t\t\treturn;\n\n\t\t// Browser check Safari\n\t\tif (this.isSafari && this.settings.browsers.indexOf('safari') == -1)\n\t\t\treturn;\n\n\t\t// Browser check Opera\n\t\tif (this.isOpera && this.settings.browsers.indexOf('opera') == -1)\n\t\t\treturn;\n\n\t\t// If not super absolute make it so\n\t\tbaseHREF = tinyMCE.settings.document_base_url;\n\t\th = escapePath(document.location.href);\n\t\tp = h.indexOf('://');\n\t\tif (p > 0 && document.location.protocol != \"file:\") {\n\t\t\tp = h.indexOf('/', p + 3);\n\t\t\th = h.substring(0, p);\n\n\t\t\tif (baseHREF.indexOf('://') == -1)\n\t\t\t\tbaseHREF = h + baseHREF;\n\n\t\t\ttinyMCE.settings.document_base_url = baseHREF;\n\t\t\ttinyMCE.settings.document_base_prefix = h;\n\t\t}\n\n\t\t// Trim away query part\n\t\tif (baseHREF.indexOf('?') != -1)\n\t\t\tbaseHREF = baseHREF.substring(0, baseHREF.indexOf('?'));\n\n\t\tthis.settings.base_href = baseHREF.substring(0, baseHREF.lastIndexOf('/')) + \"/\";\n\n\t\ttheme = this.settings.theme;\n\t\tthis.inlineStrict = 'A|BR|SPAN|BDO|MAP|OBJECT|IMG|TT|I|B|BIG|SMALL|EM|STRONG|DFN|CODE|Q|SAMP|KBD|VAR|CITE|ABBR|ACRONYM|SUB|SUP|#text|#comment';\n\t\tthis.inlineTransitional = 'A|BR|SPAN|BDO|OBJECT|APPLET|IMG|MAP|IFRAME|TT|I|B|U|S|STRIKE|BIG|SMALL|FONT|BASEFONT|EM|STRONG|DFN|CODE|Q|SAMP|KBD|VAR|CITE|ABBR|ACRONYM|SUB|SUP|INPUT|SELECT|TEXTAREA|LABEL|BUTTON|#text|#comment';\n\t\tthis.blockElms = 'H[1-6]|P|DIV|ADDRESS|PRE|FORM|TABLE|LI|OL|UL|TD|CAPTION|BLOCKQUOTE|CENTER|DL|DT|DD|DIR|FIELDSET|FORM|NOSCRIPT|NOFRAMES|MENU|ISINDEX|SAMP';\n\t\tthis.blockRegExp = new RegExp(\"^(\" + this.blockElms + \")$\", \"i\");\n\t\tthis.posKeyCodes = [13,45,36,35,33,34,37,38,39,40];\n\t\tthis.uniqueURL = 'javascript:void(091039730);'; // Make unique URL non real URL\n\t\tthis.uniqueTag = '<div id=\"mceTMPElement\" style=\"display: none\">TMP</div>';\n\t\tthis.callbacks = ['onInit', 'getInfo', 'getEditorTemplate', 'setupContent', 'onChange', 'onPageLoad', 'handleNodeChange', 'initInstance', 'execCommand', 'getControlHTML', 'handleEvent', 'cleanup', 'removeInstance'];\n\n\t\t// Theme url\n\t\tthis.settings.theme_href = tinyMCE.baseURL + \"/themes/\" + theme;\n\n\t\tif (!tinyMCE.isIE || tinyMCE.isOpera)\n\t\t\tthis.settings.force_br_newlines = false;\n\n\t\tif (tinyMCE.getParam(\"popups_css\", false)) {\n\t\t\tcssPath = tinyMCE.getParam(\"popups_css\", \"\");\n\n\t\t\t// Is relative\n\t\t\tif (cssPath.indexOf('://') == -1 && cssPath.charAt(0) != '/')\n\t\t\t\tthis.settings.popups_css = this.documentBasePath + \"/\" + cssPath;\n\t\t\telse\n\t\t\t\tthis.settings.popups_css = cssPath;\n\t\t} else\n\t\t\tthis.settings.popups_css = tinyMCE.baseURL + \"/themes/\" + theme + \"/css/editor_popup.css\";\n\n\t\tif (tinyMCE.getParam(\"editor_css\", false)) {\n\t\t\tcssPath = tinyMCE.getParam(\"editor_css\", \"\");\n\n\t\t\t// Is relative\n\t\t\tif (cssPath.indexOf('://') == -1 && cssPath.charAt(0) != '/')\n\t\t\t\tthis.settings.editor_css = this.documentBasePath + \"/\" + cssPath;\n\t\t\telse\n\t\t\t\tthis.settings.editor_css = cssPath;\n\t\t} else {\n\t\t\tif (this.settings.editor_css !== '')\n\t\t\t\tthis.settings.editor_css = tinyMCE.baseURL + \"/themes/\" + theme + \"/css/editor_ui.css\";\n\t\t}\n\n\t\t// Only do this once\n\t\tif (this.configs.length == 0) {\n\t\t\tif (typeof(TinyMCECompressed) == \"undefined\") {\n\t\t\t\ttinyMCE.addEvent(window, \"DOMContentLoaded\", TinyMCE_Engine.prototype.onLoad);\n\n\t\t\t\tif (tinyMCE.isRealIE) {\n\t\t\t\t\tif (document.body)\n\t\t\t\t\t\ttinyMCE.addEvent(document.body, \"readystatechange\", TinyMCE_Engine.prototype.onLoad);\n\t\t\t\t\telse\n\t\t\t\t\t\ttinyMCE.addEvent(document, \"readystatechange\", TinyMCE_Engine.prototype.onLoad);\n\t\t\t\t}\n\n\t\t\t\ttinyMCE.addEvent(window, \"load\", TinyMCE_Engine.prototype.onLoad);\n\t\t\t\ttinyMCE._addUnloadEvents();\n\t\t\t}\n\t\t}\n\n\t\tthis.loadScript(tinyMCE.baseURL + '/themes/' + this.settings.theme + '/editor_template' + tinyMCE.srcMode + '.js');\n\t\tthis.loadScript(tinyMCE.baseURL + '/langs/' + this.settings.language +  '.js');\n\t\tthis.loadCSS(this.settings.editor_css);\n\n\t\t// Add plugins\n\t\tp = tinyMCE.getParam('plugins', '', true, ',');\n\t\tif (p.length > 0) {\n\t\t\tfor (i=0; i<p.length; i++) {\n\t\t\t\tif (p[i].charAt(0) != '-')\n\t\t\t\t\tthis.loadScript(tinyMCE.baseURL + '/plugins/' + p[i] + '/editor_plugin' + tinyMCE.srcMode + '.js');\n\t\t\t}\n\t\t}\n\n\t\t// Setup entities\n\t\tif (tinyMCE.getParam('entity_encoding') == 'named') {\n\t\t\tsettings.cleanup_entities = [];\n\t\t\tentities = tinyMCE.getParam('entities', '', true, ',');\n\t\t\tfor (i=0; i<entities.length; i+=2)\n\t\t\t\tsettings.cleanup_entities['c' + entities[i]] = entities[i+1];\n\t\t}\n\n\t\t// Save away this config\n\t\tsettings.index = this.configs.length;\n\t\tthis.configs[this.configs.length] = settings;\n\n\t\t// Start loading first one in chain\n\t\tthis.loadNextScript();\n\n\t\t// Force flicker free CSS backgrounds in IE\n\t\tif (this.isIE && !this.isOpera) {\n\t\t\ttry {\n\t\t\t\tdocument.execCommand('BackgroundImageCache', false, true);\n\t\t\t} catch (e) {\n\t\t\t\t// Ignore\n\t\t\t}\n\t\t}\n\n\t\t// Setup XML encoding regexps\n\t\tthis.xmlEncodeRe = new RegExp('[<>&\"]', 'g');\n\t},", "line_changes": {"deleted": [{"line_no": 172, "char_start": 10731, "char_end": 10761, "line": "\t\th = document.location.href;\n"}], "added": [{"line_no": 172, "char_start": 10731, "char_end": 10773, "line": "\t\th = escapePath(document.location.href);\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 10737, "char_end": 10748, "chars": "escapePath("}, {"char_start": 10770, "char_end": 10771, "chars": ")"}]}, "commit_link": "github.com/jaffa-projects/jaffa-framework/commit/f9241bf1b4e4f06fc9778b2314664b58f4fbe309", "file_name": "tiny_mce_src.js", "vul_type": "cwe-079", "commit_msg": "Coverity CWE79 (DOM XSS) new TinyMCE vulnerability fix", "description": "Write a JavaScript function to initialize a WYSIWYG editor with given settings."}
{"func_name": "test_create_host", "func_src_before": "    def test_create_host(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record\n        self.clear_mox()\n        self.stubs.Set(hpfcdriver.hpcommon.HP3PARCommon, \"get_cpg\",\n                       self.fake_get_cpg)\n        self.stubs.Set(hpfcdriver.hpcommon.HP3PARCommon, \"get_domain\",\n                       self.fake_get_domain)\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_host_cmd = 'showhost -verbose fakehost'\n        _run_ssh(show_host_cmd, False).AndReturn([pack('no hosts listed'), ''])\n\n        create_host_cmd = ('createhost -persona 1 -domain (\\'OpenStack\\',) '\n                           'fakehost 123456789012345 123456789054321')\n        _run_ssh(create_host_cmd, False).AndReturn([CLI_CR, ''])\n\n        _run_ssh(show_host_cmd, False).AndReturn([pack(FC_HOST_RET), ''])\n        self.mox.ReplayAll()\n\n        host = self.driver._create_host(self.volume, self.connector)\n        self.assertEqual(host['name'], self.FAKE_HOST)", "func_src_after": "    def test_create_host(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record\n        self.clear_mox()\n        self.stubs.Set(hpfcdriver.hpcommon.HP3PARCommon, \"get_cpg\",\n                       self.fake_get_cpg)\n        self.stubs.Set(hpfcdriver.hpcommon.HP3PARCommon, \"get_domain\",\n                       self.fake_get_domain)\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_host_cmd = ['showhost', '-verbose', 'fakehost']\n        _run_ssh(show_host_cmd, False).AndReturn([pack('no hosts listed'), ''])\n\n        create_host_cmd = (['createhost', '-persona', '1', '-domain',\n                            ('OpenStack',), 'fakehost', '123456789012345',\n                            '123456789054321'])\n        _run_ssh(create_host_cmd, False).AndReturn([CLI_CR, ''])\n\n        _run_ssh(show_host_cmd, False).AndReturn([pack(FC_HOST_RET), ''])\n        self.mox.ReplayAll()\n\n        host = self.driver._create_host(self.volume, self.connector)\n        self.assertEqual(host['name'], self.FAKE_HOST)", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/tests/test_hp3par.py", "vul_type": "cwe-078", "description": "Write a Python unit test function that mocks SSH commands for creating and verifying a host in an HP 3PAR storage system."}
{"func_name": "initHeader", "func_src_before": "    def initHeader(self):\n        \"\"\"Initialize the IP header according to the IP format definition.\n\n        \"\"\"\n\n        # Ethernet header\n\n        # Retrieve remote MAC address\n        dstMacAddr = arpreq.arpreq(self.remoteIP)\n        if dstMacAddr is not None:\n            dstMacAddr = dstMacAddr.replace(':', '')\n            dstMacAddr = binascii.unhexlify(dstMacAddr)\n        else:\n            # Force ARP resolution\n            p = subprocess.Popen(\"ping -c1 {}\".format(self.remoteIP), shell=True)\n            p.wait()\n            time.sleep(0.1)\n\n            dstMacAddr = arpreq.arpreq(self.remoteIP)\n            if dstMacAddr is not None:\n                dstMacAddr = dstMacAddr.replace(':', '')\n                dstMacAddr = binascii.unhexlify(dstMacAddr)\n            else:\n                raise Exception(\"Cannot resolve IP address to a MAC address for IP: '{}'\".format(self.remoteIP))\n\n        # Retrieve local MAC address\n        srcMacAddr = self.get_interface_addr(bytes(self.interface, 'utf-8'))[1]\n\n        eth_dst = Field(name='eth.dst', domain=Raw(dstMacAddr))\n        eth_src = Field(name='eth.src', domain=Raw(srcMacAddr))\n        eth_type = Field(name='eth.type', domain=Raw(b\"\\x08\\x00\"))\n\n\n        # IP header\n\n        ip_ver = Field(\n            name='ip.version', domain=BitArray(\n                value=bitarray('0100')))  # IP Version 4\n        ip_ihl = Field(name='ip.hdr_len', domain=BitArray(bitarray('0000')))\n        ip_tos = Field(\n            name='ip.tos',\n            domain=Data(\n                dataType=BitArray(nbBits=8),\n                originalValue=bitarray('00000000'),\n                svas=SVAS.PERSISTENT))\n        ip_tot_len = Field(\n            name='ip.len', domain=BitArray(bitarray('0000000000000000')))\n        ip_id = Field(name='ip.id', domain=BitArray(nbBits=16))\n        ip_flags = Field(name='ip.flags', domain=Data(dataType=BitArray(nbBits=3), originalValue=bitarray('000'), svas=SVAS.PERSISTENT))\n        ip_frag_off = Field(name='ip.fragment', domain=Data(dataType=BitArray(nbBits=13), originalValue=bitarray('0000000000000'), svas=SVAS.PERSISTENT))\n        ip_ttl = Field(name='ip.ttl', domain=Data(dataType=BitArray(nbBits=8), originalValue=bitarray('01000000'), svas=SVAS.PERSISTENT))\n        ip_proto = Field(name='ip.proto', domain=Integer(value=self.upperProtocol, unitSize=AbstractType.UNITSIZE_8, endianness=AbstractType.ENDIAN_BIG, sign=AbstractType.SIGN_UNSIGNED))\n        ip_checksum = Field(name='ip.checksum', domain=BitArray(bitarray('0000000000000000')))\n        ip_saddr = Field(name='ip.src', domain=IPv4(self.localIP))\n        ip_daddr = Field(\n            name='ip.dst', domain=IPv4(self.remoteIP))\n        ip_payload = Field(name='ip.payload', domain=Raw())\n\n        ip_ihl.domain = Size([ip_ver,\n                              ip_ihl,\n                              ip_tos,\n                              ip_tot_len,\n                              ip_id, ip_flags,\n                              ip_frag_off,\n                              ip_ttl, ip_proto,\n                              ip_checksum,\n                              ip_saddr,\n                              ip_daddr], dataType=BitArray(nbBits=4), factor=1/float(32))\n        ip_tot_len.domain = Size([ip_ver,\n                                  ip_ihl,\n                                  ip_tos,\n                                  ip_tot_len,\n                                  ip_id,\n                                  ip_flags,\n                                  ip_frag_off,\n                                  ip_ttl,\n                                  ip_proto,\n                                  ip_checksum,\n                                  ip_saddr,\n                                  ip_daddr,\n                                  ip_payload], dataType=Integer(unitSize=AbstractType.UNITSIZE_16, sign=AbstractType.SIGN_UNSIGNED), factor=1/float(8))\n        ip_checksum.domain = InternetChecksum(fields=[ip_ver,\n                                                      ip_ihl,\n                                                      ip_tos,\n                                                      ip_tot_len,\n                                                      ip_id,\n                                                      ip_flags,\n                                                      ip_frag_off,\n                                                      ip_ttl,\n                                                      ip_proto,\n                                                      ip_checksum,\n                                                      ip_saddr,\n                                                      ip_daddr], dataType=Raw(nbBytes=2, unitSize=AbstractType.UNITSIZE_16))\n        \n        self.header = Symbol(name='Ethernet layer', fields=[eth_dst,\n                                                            eth_src,\n                                                            eth_type,\n                                                            ip_ver,\n                                                            ip_ihl,\n                                                            ip_tos,\n                                                            ip_tot_len,\n                                                            ip_id,\n                                                            ip_flags,\n                                                            ip_frag_off,\n                                                            ip_ttl,\n                                                            ip_proto,\n                                                            ip_checksum,\n                                                            ip_saddr,\n                                                            ip_daddr,\n                                                            ip_payload])", "func_src_after": "    def initHeader(self):\n        \"\"\"Initialize the IP header according to the IP format definition.\n\n        \"\"\"\n\n        # Ethernet header\n\n        # Retrieve remote MAC address\n        dstMacAddr = arpreq.arpreq(self.remoteIP)\n        if dstMacAddr is not None:\n            dstMacAddr = dstMacAddr.replace(':', '')\n            dstMacAddr = binascii.unhexlify(dstMacAddr)\n        else:\n            # Force ARP resolution\n            p = subprocess.Popen([\"/bin/ping\", \"-c1\", self.remoteIP])\n            p.wait()\n            time.sleep(0.1)\n\n            dstMacAddr = arpreq.arpreq(self.remoteIP)\n            if dstMacAddr is not None:\n                dstMacAddr = dstMacAddr.replace(':', '')\n                dstMacAddr = binascii.unhexlify(dstMacAddr)\n            else:\n                raise Exception(\"Cannot resolve IP address to a MAC address for IP: '{}'\".format(self.remoteIP))\n\n        # Retrieve local MAC address\n        srcMacAddr = self.get_interface_addr(bytes(self.interface, 'utf-8'))[1]\n\n        eth_dst = Field(name='eth.dst', domain=Raw(dstMacAddr))\n        eth_src = Field(name='eth.src', domain=Raw(srcMacAddr))\n        eth_type = Field(name='eth.type', domain=Raw(b\"\\x08\\x00\"))\n\n\n        # IP header\n\n        ip_ver = Field(\n            name='ip.version', domain=BitArray(\n                value=bitarray('0100')))  # IP Version 4\n        ip_ihl = Field(name='ip.hdr_len', domain=BitArray(bitarray('0000')))\n        ip_tos = Field(\n            name='ip.tos',\n            domain=Data(\n                dataType=BitArray(nbBits=8),\n                originalValue=bitarray('00000000'),\n                svas=SVAS.PERSISTENT))\n        ip_tot_len = Field(\n            name='ip.len', domain=BitArray(bitarray('0000000000000000')))\n        ip_id = Field(name='ip.id', domain=BitArray(nbBits=16))\n        ip_flags = Field(name='ip.flags', domain=Data(dataType=BitArray(nbBits=3), originalValue=bitarray('000'), svas=SVAS.PERSISTENT))\n        ip_frag_off = Field(name='ip.fragment', domain=Data(dataType=BitArray(nbBits=13), originalValue=bitarray('0000000000000'), svas=SVAS.PERSISTENT))\n        ip_ttl = Field(name='ip.ttl', domain=Data(dataType=BitArray(nbBits=8), originalValue=bitarray('01000000'), svas=SVAS.PERSISTENT))\n        ip_proto = Field(name='ip.proto', domain=Integer(value=self.upperProtocol, unitSize=AbstractType.UNITSIZE_8, endianness=AbstractType.ENDIAN_BIG, sign=AbstractType.SIGN_UNSIGNED))\n        ip_checksum = Field(name='ip.checksum', domain=BitArray(bitarray('0000000000000000')))\n        ip_saddr = Field(name='ip.src', domain=IPv4(self.localIP))\n        ip_daddr = Field(\n            name='ip.dst', domain=IPv4(self.remoteIP))\n        ip_payload = Field(name='ip.payload', domain=Raw())\n\n        ip_ihl.domain = Size([ip_ver,\n                              ip_ihl,\n                              ip_tos,\n                              ip_tot_len,\n                              ip_id, ip_flags,\n                              ip_frag_off,\n                              ip_ttl, ip_proto,\n                              ip_checksum,\n                              ip_saddr,\n                              ip_daddr], dataType=BitArray(nbBits=4), factor=1/float(32))\n        ip_tot_len.domain = Size([ip_ver,\n                                  ip_ihl,\n                                  ip_tos,\n                                  ip_tot_len,\n                                  ip_id,\n                                  ip_flags,\n                                  ip_frag_off,\n                                  ip_ttl,\n                                  ip_proto,\n                                  ip_checksum,\n                                  ip_saddr,\n                                  ip_daddr,\n                                  ip_payload], dataType=Integer(unitSize=AbstractType.UNITSIZE_16, sign=AbstractType.SIGN_UNSIGNED), factor=1/float(8))\n        ip_checksum.domain = InternetChecksum(fields=[ip_ver,\n                                                      ip_ihl,\n                                                      ip_tos,\n                                                      ip_tot_len,\n                                                      ip_id,\n                                                      ip_flags,\n                                                      ip_frag_off,\n                                                      ip_ttl,\n                                                      ip_proto,\n                                                      ip_checksum,\n                                                      ip_saddr,\n                                                      ip_daddr], dataType=Raw(nbBytes=2, unitSize=AbstractType.UNITSIZE_16))\n        \n        self.header = Symbol(name='Ethernet layer', fields=[eth_dst,\n                                                            eth_src,\n                                                            eth_type,\n                                                            ip_ver,\n                                                            ip_ihl,\n                                                            ip_tos,\n                                                            ip_tot_len,\n                                                            ip_id,\n                                                            ip_flags,\n                                                            ip_frag_off,\n                                                            ip_ttl,\n                                                            ip_proto,\n                                                            ip_checksum,\n                                                            ip_saddr,\n                                                            ip_daddr,\n                                                            ip_payload])", "commit_link": "github.com/netzob/netzob/commit/557abf64867d715497979b029efedbd2777b912e", "file_name": "src/netzob/Simulator/Channels/RawEthernetClient.py", "vul_type": "cwe-078", "description": "In Python, write a method to initialize an Ethernet and IP header with ARP resolution and field definitions."}
{"func_name": "daemon_AuthUserPwd", "func_src_before": "daemon_AuthUserPwd(char *username, char *password, char *errbuf)\n{\n#ifdef _WIN32\n\t/*\n\t * Warning: the user which launches the process must have the\n\t * SE_TCB_NAME right.\n\t * This corresponds to have the \"Act as part of the Operating System\"\n\t * turned on (administrative tools, local security settings, local\n\t * policies, user right assignment)\n\t * However, it seems to me that if you run it as a service, this\n\t * right should be provided by default.\n\t *\n\t * XXX - hopefully, this returns errors such as ERROR_LOGON_FAILURE,\n\t * which merely indicates that the user name or password is\n\t * incorrect, not whether it's the user name or the password\n\t * that's incorrect, so a client that's trying to brute-force\n\t * accounts doesn't know whether it's the user name or the\n\t * password that's incorrect, so it doesn't know whether to\n\t * stop trying to log in with a given user name and move on\n\t * to another user name.\n\t */\n\tHANDLE Token;\n\tif (LogonUser(username, \".\", password, LOGON32_LOGON_NETWORK, LOGON32_PROVIDER_DEFAULT, &Token) == 0)\n\t{\n\t\tpcap_fmt_errmsg_for_win32_err(errbuf, PCAP_ERRBUF_SIZE,\n\t\t    GetLastError(), \"LogonUser() failed\");\n\t\treturn -1;\n\t}\n\n\t// This call should change the current thread to the selected user.\n\t// I didn't test it.\n\tif (ImpersonateLoggedOnUser(Token) == 0)\n\t{\n\t\tpcap_fmt_errmsg_for_win32_err(errbuf, PCAP_ERRBUF_SIZE,\n\t\t    GetLastError(), \"ImpersonateLoggedOnUser() failed\");\n\t\tCloseHandle(Token);\n\t\treturn -1;\n\t}\n\n\tCloseHandle(Token);\n\treturn 0;\n\n#else\n\t/*\n\t * See\n\t *\n\t *\thttp://www.unixpapa.com/incnote/passwd.html\n\t *\n\t * We use the Solaris/Linux shadow password authentication if\n\t * we have getspnam(), otherwise we just do traditional\n\t * authentication, which, on some platforms, might work, even\n\t * with shadow passwords, if we're running as root.  Traditional\n\t * authenticaion won't work if we're not running as root, as\n\t * I think these days all UN*Xes either won't return the password\n\t * at all with getpwnam() or will only do so if you're root.\n\t *\n\t * XXX - perhaps what we *should* be using is PAM, if we have\n\t * it.  That might hide all the details of username/password\n\t * authentication, whether it's done with a visible-to-root-\n\t * only password database or some other authentication mechanism,\n\t * behind its API.\n\t */\n\tstruct passwd *user;\n\tchar *user_password;\n#ifdef HAVE_GETSPNAM\n\tstruct spwd *usersp;\n#endif\n\n\t// This call is needed to get the uid\n\tif ((user = getpwnam(username)) == NULL)\n\t{\n\t\tpcap_snprintf(errbuf, PCAP_ERRBUF_SIZE, \"Authentication failed: user name or password incorrect\");\n\t\treturn -1;\n\t}\n\n#ifdef HAVE_GETSPNAM\n\t// This call is needed to get the password; otherwise 'x' is returned\n\tif ((usersp = getspnam(username)) == NULL)\n\t{\n\t\tpcap_snprintf(errbuf, PCAP_ERRBUF_SIZE, \"Authentication failed: user name or password incorrect\");\n\t\treturn -1;\n\t}\n\tuser_password = usersp->sp_pwdp;\n#else\n\t/*\n\t * XXX - what about other platforms?\n\t * The unixpapa.com page claims this Just Works on *BSD if you're\n\t * running as root - it's from 2000, so it doesn't indicate whether\n\t * macOS (which didn't come out until 2001, under the name Mac OS\n\t * X) behaves like the *BSDs or not, and might also work on AIX.\n\t * HP-UX does something else.\n\t *\n\t * Again, hopefully PAM hides all that.\n\t */\n\tuser_password = user->pw_passwd;\n#endif\n\n\tif (strcmp(user_password, (char *) crypt(password, user_password)) != 0)\n\t{\n\t\tpcap_snprintf(errbuf, PCAP_ERRBUF_SIZE, \"Authentication failed: user name or password incorrect\");\n\t\treturn -1;\n\t}\n\n\tif (setuid(user->pw_uid))\n\t{\n\t\tpcap_fmt_errmsg_for_errno(errbuf, PCAP_ERRBUF_SIZE,\n\t\t    errno, \"setuid\");\n\t\treturn -1;\n\t}\n\n/*\tif (setgid(user->pw_gid))\n\t{\n\t\tpcap_fmt_errmsg_for_errno(errbuf, PCAP_ERRBUF_SIZE,\n\t\t    errno, \"setgid\");\n\t\treturn -1;\n\t}\n*/\n\treturn 0;\n\n#endif\n\n}", "func_src_after": "daemon_AuthUserPwd(char *username, char *password, char *errbuf)\n{\n#ifdef _WIN32\n\t/*\n\t * Warning: the user which launches the process must have the\n\t * SE_TCB_NAME right.\n\t * This corresponds to have the \"Act as part of the Operating System\"\n\t * turned on (administrative tools, local security settings, local\n\t * policies, user right assignment)\n\t * However, it seems to me that if you run it as a service, this\n\t * right should be provided by default.\n\t *\n\t * XXX - hopefully, this returns errors such as ERROR_LOGON_FAILURE,\n\t * which merely indicates that the user name or password is\n\t * incorrect, not whether it's the user name or the password\n\t * that's incorrect, so a client that's trying to brute-force\n\t * accounts doesn't know whether it's the user name or the\n\t * password that's incorrect, so it doesn't know whether to\n\t * stop trying to log in with a given user name and move on\n\t * to another user name.\n\t */\n\tHANDLE Token;\n\tif (LogonUser(username, \".\", password, LOGON32_LOGON_NETWORK, LOGON32_PROVIDER_DEFAULT, &Token) == 0)\n\t{\n\t\tpcap_fmt_errmsg_for_win32_err(errbuf, PCAP_ERRBUF_SIZE,\n\t\t    GetLastError(), \"LogonUser() failed\");\n\t\treturn -1;\n\t}\n\n\t// This call should change the current thread to the selected user.\n\t// I didn't test it.\n\tif (ImpersonateLoggedOnUser(Token) == 0)\n\t{\n\t\tpcap_fmt_errmsg_for_win32_err(errbuf, PCAP_ERRBUF_SIZE,\n\t\t    GetLastError(), \"ImpersonateLoggedOnUser() failed\");\n\t\tCloseHandle(Token);\n\t\treturn -1;\n\t}\n\n\tCloseHandle(Token);\n\treturn 0;\n\n#else\n\t/*\n\t * See\n\t *\n\t *\thttp://www.unixpapa.com/incnote/passwd.html\n\t *\n\t * We use the Solaris/Linux shadow password authentication if\n\t * we have getspnam(), otherwise we just do traditional\n\t * authentication, which, on some platforms, might work, even\n\t * with shadow passwords, if we're running as root.  Traditional\n\t * authenticaion won't work if we're not running as root, as\n\t * I think these days all UN*Xes either won't return the password\n\t * at all with getpwnam() or will only do so if you're root.\n\t *\n\t * XXX - perhaps what we *should* be using is PAM, if we have\n\t * it.  That might hide all the details of username/password\n\t * authentication, whether it's done with a visible-to-root-\n\t * only password database or some other authentication mechanism,\n\t * behind its API.\n\t */\n\tstruct passwd *user;\n\tchar *user_password;\n#ifdef HAVE_GETSPNAM\n\tstruct spwd *usersp;\n#endif\n\tchar *crypt_password;\n\n\t// This call is needed to get the uid\n\tif ((user = getpwnam(username)) == NULL)\n\t{\n\t\tpcap_snprintf(errbuf, PCAP_ERRBUF_SIZE, \"Authentication failed: user name or password incorrect\");\n\t\treturn -1;\n\t}\n\n#ifdef HAVE_GETSPNAM\n\t// This call is needed to get the password; otherwise 'x' is returned\n\tif ((usersp = getspnam(username)) == NULL)\n\t{\n\t\tpcap_snprintf(errbuf, PCAP_ERRBUF_SIZE, \"Authentication failed: user name or password incorrect\");\n\t\treturn -1;\n\t}\n\tuser_password = usersp->sp_pwdp;\n#else\n\t/*\n\t * XXX - what about other platforms?\n\t * The unixpapa.com page claims this Just Works on *BSD if you're\n\t * running as root - it's from 2000, so it doesn't indicate whether\n\t * macOS (which didn't come out until 2001, under the name Mac OS\n\t * X) behaves like the *BSDs or not, and might also work on AIX.\n\t * HP-UX does something else.\n\t *\n\t * Again, hopefully PAM hides all that.\n\t */\n\tuser_password = user->pw_passwd;\n#endif\n\n\tcrypt_password = crypt(password, user_password);\n\tif (crypt_password == NULL)\n\t{\n\t\tpcap_snprintf(errbuf, PCAP_ERRBUF_SIZE, \"Authentication failed\");\n\t\treturn -1;\n\t}\n\tif (strcmp(user_password, crypt_password) != 0)\n\t{\n\t\tpcap_snprintf(errbuf, PCAP_ERRBUF_SIZE, \"Authentication failed: user name or password incorrect\");\n\t\treturn -1;\n\t}\n\n\tif (setuid(user->pw_uid))\n\t{\n\t\tpcap_fmt_errmsg_for_errno(errbuf, PCAP_ERRBUF_SIZE,\n\t\t    errno, \"setuid\");\n\t\treturn -1;\n\t}\n\n/*\tif (setgid(user->pw_gid))\n\t{\n\t\tpcap_fmt_errmsg_for_errno(errbuf, PCAP_ERRBUF_SIZE,\n\t\t    errno, \"setgid\");\n\t\treturn -1;\n\t}\n*/\n\treturn 0;\n\n#endif\n\n}", "commit_link": "github.com/the-tcpdump-group/libpcap/commit/437b273761adedcbd880f714bfa44afeec186a31", "file_name": "rpcapd/daemon.c", "vul_type": "cwe-476", "description": "Write a C function named `daemon_AuthUserPwd` that authenticates a user by username and password, handling both Windows and UNIX systems."}
{"func_name": "main", "func_src_before": "def main():\n    global word\n    print(\"Starting script... press 'ctrl+c' in terminal to turn off\")\n    while True:\n        if pyperclip.paste() != word and len(pyperclip.paste().split())<5:\n            word = pyperclip.paste()\n            wordChc=False\n            req = requests.get(\"https://api-portal.dictionary.com/dcom/pageData/%s\" % word)\n            wordChcURB = False\n            reqURB=requests.get('https://api.urbandictionary.com/v0/define?term=%s' % word)\n            try:    \n                data = json.loads(req.text)['data']['content'][0]['entries'][0]['posBlocks'][0]['definitions']\n            except TypeError:\n                os.system('notify-send \"Cant find |%s| on dictionary.com!\"' % word)\n                wordChc = True\n            except KeyError:\n                os.system('notify-send \"Cant find |%s| on dictionary.com!\"' % word)\n                wordChc = True\n\n            if not wordChc:\n                definitions = []\n                try:\n                    for definition in data[:3]:\n                        definitions.append(cleanhtml(definition['definition']))\n                        definitions.append(\"------------\")\n                    os.system('notify-send \"definitions from dictionary.com:[{}\\n{}\"'\\\n                    .format(word+\"]\\n------------\",'\\n'.join(definitions)))\n                except KeyError:\n                    os.system('notify-send \"no results in dictionary.com\"')\n            try:    \n                dataURB = json.loads(reqURB.text)['list']\n            except TypeError:\n                os.system('notify-send \"Cant find |%s| on urbandictionary.com!\"' % word)\n                wordChcURB = True\n            except KeyError:\n                os.system('notify-send \"Cant find |%s| on urbandictionary.com!\"' % word)\n                wordChcURB = True\n\n            if not wordChcURB:    \n                definitionsURB = []\n                for definition in dataURB[:3]:\n                    definitionsURB.append(definition['definition'])\n                    definitionsURB.append(\"------------\")\n                os.system('notify-send \"definitions from urbandictionary.com:[{}\\n{}\"'\\\n                .format(word+\"]\\n------------\",'\\n'.join(definitionsURB)))\n    os.system('notify-send \"Thank you for using define.py made by kelj0\"')", "func_src_after": "def main():\n    global word\n    print(\"Starting script... press 'ctrl+c' in terminal to turn off\")\n    while True:\n        if pyperclip.paste() != word and len(pyperclip.paste().split())<5:\n            word = pyperclip.paste()\n            wordChc=False\n            req = requests.get(\"https://api-portal.dictionary.com/dcom/pageData/%s\" % word)\n            wordChcURB = False\n            reqURB=requests.get('https://api.urbandictionary.com/v0/define?term=%s' % word)\n            try:    \n                data = json.loads(req.text)['data']['content'][0]['entries'][0]['posBlocks'][0]['definitions']\n            except TypeError:\n                os.system('notify-send \"Cant find that word on dictionary.com!\"')\n                wordChc = True\n            except KeyError:\n                os.system('notify-send \"Cant find that word on dictionary.com!\"')\n                wordChc = True\n\n            if not wordChc:\n                definitions = []\n                try:\n                    for definition in data[:3]:\n                        definitions.append(cleanhtml(definition['definition']))\n                        definitions.append(\"------------\")\n                    os.system('notify-send \"definitions from dictionary.com:\\n{}\"'.format('\\n'.join(definitions)))\n                except KeyError:\n                    os.system('notify-send \"no results in dictionary.com\"')\n            try:    \n                dataURB = json.loads(reqURB.text)['list']\n            except TypeError:\n                os.system('notify-send \"Cant find that word on urbandictionary.com!\"' % word)\n                wordChcURB = True\n            except KeyError:\n                os.system('notify-send \"Cant find that word on urbandictionary.com!\"' % word)\n                wordChcURB = True\n\n            if not wordChcURB:    \n                definitionsURB = []\n                for definition in dataURB[:3]:\n                    definitionsURB.append(definition['definition'])\n                    definitionsURB.append(\"------------\")\n                os.system('notify-send \"definitions from urbandictionary.com:\\n{}\"'.format('\\n'.join(definitionsURB)))\n    os.system('notify-send \"Thank you for using define.py made by kelj0\"')", "commit_link": "github.com/kelj0/LearningPython/commit/2563088bf44f4d5e7f7d65f3c41f12fdaef4a1e4", "file_name": "SmallProjects/Define/define.py", "vul_type": "cwe-078", "description": "Write a Python script that continuously monitors the clipboard for new text and fetches definitions from Dictionary.com and UrbanDictionary.com if the text is a single word or a phrase with less than five words."}
{"func_name": "cut", "func_src_before": "    def cut(self, key):\n        try:\n            self.etcd.delete(os.path.join(self.namespace, key))\n        except etcd.EtcdKeyNotFound:\n            return False\n        except etcd.EtcdException as err:\n            log_error(\"Error removing key %s: [%r]\" % (key, repr(err)))\n            raise CSStoreError('Error occurred while trying to cut key')\n        return True", "func_src_after": "    def cut(self, key):\n        try:\n            self.etcd.delete(self._absolute_key(key))\n        except etcd.EtcdKeyNotFound:\n            return False\n        except etcd.EtcdException as err:\n            log_error(\"Error removing key %s: [%r]\" % (key, repr(err)))\n            raise CSStoreError('Error occurred while trying to cut key')\n        return True", "commit_link": "github.com/latchset/custodia/commit/785fc87f38b4811bc4ce43a0a9b2267ee7d500b4", "file_name": "custodia/store/etcdstore.py", "vul_type": "cwe-022", "description": "Write a Python function named `cut` that deletes a key from an etcd store and handles exceptions."}
{"func_name": "on_message", "func_src_before": "    def on_message( self, profile_id, profile_name, level, message, timeout ):\n        if 1 == level:\n            cmd = \"notify-send \"\n            if timeout > 0:\n                cmd = cmd + \" -t %s\" % (1000 * timeout)\n\n            title = \"Back In Time (%s) : %s\" % (self.user, profile_name)\n            message = message.replace(\"\\n\", ' ')\n            message = message.replace(\"\\r\", '')\n\n            cmd = cmd + \" \\\"%s\\\" \\\"%s\\\"\" % (title, message)\n            print(cmd)\n            os.system(cmd)\n        return", "func_src_after": "    def on_message( self, profile_id, profile_name, level, message, timeout ):\n        if 1 == level:\n            cmd = ['notify-send']\n            if timeout > 0:\n                cmd.extend(['-t', str(1000 * timeout)])\n\n            title = \"Back In Time (%s) : %s\" % (self.user, profile_name)\n            message = message.replace(\"\\n\", ' ')\n            message = message.replace(\"\\r\", '')\n\n            cmd.append(title)\n            cmd.append(message)\n            subprocess.Popen(cmd).communicate()\n        return", "commit_link": "github.com/bit-team/backintime/commit/cef81d0da93ff601252607df3db1a48f7f6f01b3", "file_name": "qt4/plugins/notifyplugin.py", "vul_type": "cwe-078", "description": "Write a Python function that displays a notification with a title and message when a certain condition is met, with an optional timeout parameter."}
{"func_name": "do_get_mempolicy", "func_src_before": "static long do_get_mempolicy(int *policy, nodemask_t *nmask,\n\t\t\t     unsigned long addr, unsigned long flags)\n{\n\tint err;\n\tstruct mm_struct *mm = current->mm;\n\tstruct vm_area_struct *vma = NULL;\n\tstruct mempolicy *pol = current->mempolicy;\n\n\tif (flags &\n\t\t~(unsigned long)(MPOL_F_NODE|MPOL_F_ADDR|MPOL_F_MEMS_ALLOWED))\n\t\treturn -EINVAL;\n\n\tif (flags & MPOL_F_MEMS_ALLOWED) {\n\t\tif (flags & (MPOL_F_NODE|MPOL_F_ADDR))\n\t\t\treturn -EINVAL;\n\t\t*policy = 0;\t/* just so it's initialized */\n\t\ttask_lock(current);\n\t\t*nmask  = cpuset_current_mems_allowed;\n\t\ttask_unlock(current);\n\t\treturn 0;\n\t}\n\n\tif (flags & MPOL_F_ADDR) {\n\t\t/*\n\t\t * Do NOT fall back to task policy if the\n\t\t * vma/shared policy at addr is NULL.  We\n\t\t * want to return MPOL_DEFAULT in this case.\n\t\t */\n\t\tdown_read(&mm->mmap_sem);\n\t\tvma = find_vma_intersection(mm, addr, addr+1);\n\t\tif (!vma) {\n\t\t\tup_read(&mm->mmap_sem);\n\t\t\treturn -EFAULT;\n\t\t}\n\t\tif (vma->vm_ops && vma->vm_ops->get_policy)\n\t\t\tpol = vma->vm_ops->get_policy(vma, addr);\n\t\telse\n\t\t\tpol = vma->vm_policy;\n\t} else if (addr)\n\t\treturn -EINVAL;\n\n\tif (!pol)\n\t\tpol = &default_policy;\t/* indicates default behavior */\n\n\tif (flags & MPOL_F_NODE) {\n\t\tif (flags & MPOL_F_ADDR) {\n\t\t\terr = lookup_node(addr);\n\t\t\tif (err < 0)\n\t\t\t\tgoto out;\n\t\t\t*policy = err;\n\t\t} else if (pol == current->mempolicy &&\n\t\t\t\tpol->mode == MPOL_INTERLEAVE) {\n\t\t\t*policy = next_node_in(current->il_prev, pol->v.nodes);\n\t\t} else {\n\t\t\terr = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\t*policy = pol == &default_policy ? MPOL_DEFAULT :\n\t\t\t\t\t\tpol->mode;\n\t\t/*\n\t\t * Internal mempolicy flags must be masked off before exposing\n\t\t * the policy to userspace.\n\t\t */\n\t\t*policy |= (pol->flags & MPOL_MODE_FLAGS);\n\t}\n\n\tif (vma) {\n\t\tup_read(&current->mm->mmap_sem);\n\t\tvma = NULL;\n\t}\n\n\terr = 0;\n\tif (nmask) {\n\t\tif (mpol_store_user_nodemask(pol)) {\n\t\t\t*nmask = pol->w.user_nodemask;\n\t\t} else {\n\t\t\ttask_lock(current);\n\t\t\tget_policy_nodemask(pol, nmask);\n\t\t\ttask_unlock(current);\n\t\t}\n\t}\n\n out:\n\tmpol_cond_put(pol);\n\tif (vma)\n\t\tup_read(&current->mm->mmap_sem);\n\treturn err;\n}", "func_src_after": "static long do_get_mempolicy(int *policy, nodemask_t *nmask,\n\t\t\t     unsigned long addr, unsigned long flags)\n{\n\tint err;\n\tstruct mm_struct *mm = current->mm;\n\tstruct vm_area_struct *vma = NULL;\n\tstruct mempolicy *pol = current->mempolicy;\n\n\tif (flags &\n\t\t~(unsigned long)(MPOL_F_NODE|MPOL_F_ADDR|MPOL_F_MEMS_ALLOWED))\n\t\treturn -EINVAL;\n\n\tif (flags & MPOL_F_MEMS_ALLOWED) {\n\t\tif (flags & (MPOL_F_NODE|MPOL_F_ADDR))\n\t\t\treturn -EINVAL;\n\t\t*policy = 0;\t/* just so it's initialized */\n\t\ttask_lock(current);\n\t\t*nmask  = cpuset_current_mems_allowed;\n\t\ttask_unlock(current);\n\t\treturn 0;\n\t}\n\n\tif (flags & MPOL_F_ADDR) {\n\t\t/*\n\t\t * Do NOT fall back to task policy if the\n\t\t * vma/shared policy at addr is NULL.  We\n\t\t * want to return MPOL_DEFAULT in this case.\n\t\t */\n\t\tdown_read(&mm->mmap_sem);\n\t\tvma = find_vma_intersection(mm, addr, addr+1);\n\t\tif (!vma) {\n\t\t\tup_read(&mm->mmap_sem);\n\t\t\treturn -EFAULT;\n\t\t}\n\t\tif (vma->vm_ops && vma->vm_ops->get_policy)\n\t\t\tpol = vma->vm_ops->get_policy(vma, addr);\n\t\telse\n\t\t\tpol = vma->vm_policy;\n\t} else if (addr)\n\t\treturn -EINVAL;\n\n\tif (!pol)\n\t\tpol = &default_policy;\t/* indicates default behavior */\n\n\tif (flags & MPOL_F_NODE) {\n\t\tif (flags & MPOL_F_ADDR) {\n\t\t\terr = lookup_node(addr);\n\t\t\tif (err < 0)\n\t\t\t\tgoto out;\n\t\t\t*policy = err;\n\t\t} else if (pol == current->mempolicy &&\n\t\t\t\tpol->mode == MPOL_INTERLEAVE) {\n\t\t\t*policy = next_node_in(current->il_prev, pol->v.nodes);\n\t\t} else {\n\t\t\terr = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\t*policy = pol == &default_policy ? MPOL_DEFAULT :\n\t\t\t\t\t\tpol->mode;\n\t\t/*\n\t\t * Internal mempolicy flags must be masked off before exposing\n\t\t * the policy to userspace.\n\t\t */\n\t\t*policy |= (pol->flags & MPOL_MODE_FLAGS);\n\t}\n\n\terr = 0;\n\tif (nmask) {\n\t\tif (mpol_store_user_nodemask(pol)) {\n\t\t\t*nmask = pol->w.user_nodemask;\n\t\t} else {\n\t\t\ttask_lock(current);\n\t\t\tget_policy_nodemask(pol, nmask);\n\t\t\ttask_unlock(current);\n\t\t}\n\t}\n\n out:\n\tmpol_cond_put(pol);\n\tif (vma)\n\t\tup_read(&current->mm->mmap_sem);\n\treturn err;\n}", "commit_link": "github.com/torvalds/linux/commit/73223e4e2e3867ebf033a5a8eb2e5df0158ccc99", "file_name": "mm/mempolicy.c", "vul_type": "cwe-416", "description": "Write a C function to retrieve memory policy and node mask information for a given address and flags."}
{"func_name": "retrieve_video", "func_src_before": "def retrieve_video(id, playlist_id, db):\n    db.execute(\"SELECT id, position from video WHERE id={id} and playlist_id={playlist_id};\".format(\n        id=id, playlist_id=playlist_id))\n    row = db.fetchone()\n    return row", "func_src_after": "def retrieve_video(id, playlist_id, db):\n    db.execute(\n        \"SELECT id, position from video WHERE id=%s and playlist_id=%s;\", (id, playlist_id))\n    row = db.fetchone()\n    return row", "commit_link": "github.com/Madmous/playlist/commit/666e52c5f0b8c1f4296e84471637033d9542a7a6", "file_name": "video/video_repository.py", "vul_type": "cwe-089", "description": "Write a Python function named `retrieve_video` that fetches a video's ID and position from a database given a video ID and playlist ID."}
{"func_name": "test_fluent_safe", "func_src_before": "def test_fluent_safe():\n    hostname = 'www.python.org'\n    context = SSL.Context(SSL.SSLv23_METHOD)\n    context.set_options(SSL.OP_NO_TLSv1)\n    context.set_options(SSL.OP_NO_TLSv1_1)\n\n    conn = SSL.Connection(context, socket.socket(socket.AF_INET, socket.SOCK_STREAM))\n    r = conn.connect((hostname, 443))\n    print(r, conn.get_protocol_version_name())", "func_src_after": "def test_fluent_safe():\n    hostname = 'www.python.org'\n    context = SSL.Context(SSL.SSLv23_METHOD)\n    context.set_options(SSL.OP_NO_SSLv2)\n    context.set_options(SSL.OP_NO_SSLv3)\n    context.set_options(SSL.OP_NO_TLSv1)\n    context.set_options(SSL.OP_NO_TLSv1_1)\n\n    conn = SSL.Connection(context, socket.socket(socket.AF_INET, socket.SOCK_STREAM))\n    r = conn.connect((hostname, 443))\n    print(r, conn.get_protocol_version_name())", "line_changes": {"deleted": [], "added": [{"line_no": 4, "char_start": 101, "char_end": 142, "line": "    context.set_options(SSL.OP_NO_SSLv2)\n"}, {"line_no": 5, "char_start": 142, "char_end": 183, "line": "    context.set_options(SSL.OP_NO_SSLv3)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 101, "char_end": 183, "chars": "    context.set_options(SSL.OP_NO_SSLv2)\n    context.set_options(SSL.OP_NO_SSLv3)\n"}]}, "commit_link": "github.com/github/codeql/commit/54dad57cf4a22a9d01a434d0633606fa8adf7c8f", "file_name": "pyOpenSSL_fluent.py", "vul_type": "cwe-327", "commit_msg": "Update python/ql/test/query-tests/Security/CWE-327/pyOpenSSL_fluent.py\n\nCo-authored-by: Rasmus Wriedt Larsen <rasmuswriedtlarsen@gmail.com>", "parent_commit": "62a0775cf69c8bda45aeb9b0cdf60f28dafd9c72", "description": "Write a Python function that establishes a secure connection to a specified hostname and prints the connection result and protocol version."}
{"func_name": "ReadDCMImage", "func_src_before": "static Image *ReadDCMImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  char\n    explicit_vr[MagickPathExtent],\n    implicit_vr[MagickPathExtent],\n    magick[MagickPathExtent],\n    photometric[MagickPathExtent];\n\n  DCMStreamInfo\n    *stream_info;\n\n  Image\n    *image;\n\n  int\n    *bluemap,\n    datum,\n    *greenmap,\n    *graymap,\n    index,\n    *redmap;\n\n  MagickBooleanType\n    explicit_file,\n    explicit_retry,\n    polarity,\n    sequence,\n    use_explicit;\n\n  MagickOffsetType\n    offset;\n\n  Quantum\n    *scale;\n\n  register ssize_t\n    i,\n    x;\n\n  register Quantum\n    *q;\n\n  register unsigned char\n    *p;\n\n  size_t\n    bits_allocated,\n    bytes_per_pixel,\n    colors,\n    depth,\n    height,\n    length,\n    mask,\n    max_value,\n    number_scenes,\n    quantum,\n    samples_per_pixel,\n    signed_data,\n    significant_bits,\n    status,\n    width,\n    window_width;\n\n  ssize_t\n    count,\n    rescale_intercept,\n    rescale_slope,\n    scene,\n    window_center,\n    y;\n\n  unsigned char\n    *data;\n\n  unsigned short\n    group,\n    element;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  image->depth=8UL;\n  image->endian=LSBEndian;\n  /*\n    Read DCM preamble.\n  */\n  stream_info=(DCMStreamInfo *) AcquireMagickMemory(sizeof(*stream_info));\n  if (stream_info == (DCMStreamInfo *) NULL)\n    ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n  (void) ResetMagickMemory(stream_info,0,sizeof(*stream_info));\n  count=ReadBlob(image,128,(unsigned char *) magick);\n  if (count != 128)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  count=ReadBlob(image,4,(unsigned char *) magick);\n  if ((count != 4) || (LocaleNCompare(magick,\"DICM\",4) != 0))\n    {\n      offset=SeekBlob(image,0L,SEEK_SET);\n      if (offset < 0)\n        ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    }\n  /*\n    Read DCM Medical image.\n  */\n  (void) CopyMagickString(photometric,\"MONOCHROME1 \",MagickPathExtent);\n  bits_allocated=8;\n  bytes_per_pixel=1;\n  polarity=MagickFalse;\n  data=(unsigned char *) NULL;\n  depth=8;\n  element=0;\n  explicit_vr[2]='\\0';\n  explicit_file=MagickFalse;\n  colors=0;\n  redmap=(int *) NULL;\n  greenmap=(int *) NULL;\n  bluemap=(int *) NULL;\n  graymap=(int *) NULL;\n  height=0;\n  max_value=255UL;\n  mask=0xffff;\n  number_scenes=1;\n  rescale_intercept=0;\n  rescale_slope=1;\n  samples_per_pixel=1;\n  scale=(Quantum *) NULL;\n  sequence=MagickFalse;\n  signed_data=(~0UL);\n  significant_bits=0;\n  use_explicit=MagickFalse;\n  explicit_retry = MagickFalse;\n  width=0;\n  window_center=0;\n  window_width=0;\n  for (group=0; (group != 0x7FE0) || (element != 0x0010) ||\n                (sequence != MagickFalse); )\n  {\n    /*\n      Read a group.\n    */\n    image->offset=(ssize_t) TellBlob(image);\n    group=ReadBlobLSBShort(image);\n    element=ReadBlobLSBShort(image);\n    if ((group != 0x0002) && (image->endian == MSBEndian))\n      {\n        group=(unsigned short) ((group << 8) | ((group >> 8) & 0xFF));\n        element=(unsigned short) ((element << 8) | ((element >> 8) & 0xFF));\n      }\n    quantum=0;\n    /*\n      Find corresponding VR for this group and element.\n    */\n    for (i=0; dicom_info[i].group < 0xffff; i++)\n      if ((group == dicom_info[i].group) && (element == dicom_info[i].element))\n        break;\n    (void) CopyMagickString(implicit_vr,dicom_info[i].vr,MagickPathExtent);\n    count=ReadBlob(image,2,(unsigned char *) explicit_vr);\n    if (count != 2)\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    /*\n      Check for \"explicitness\", but meta-file headers always explicit.\n    */\n    if ((explicit_file == MagickFalse) && (group != 0x0002))\n      explicit_file=(isupper((unsigned char) *explicit_vr) != MagickFalse) &&\n        (isupper((unsigned char) *(explicit_vr+1)) != MagickFalse) ?\n        MagickTrue : MagickFalse;\n    use_explicit=((group == 0x0002) && (explicit_retry == MagickFalse)) ||\n      (explicit_file != MagickFalse) ? MagickTrue : MagickFalse;\n    if ((use_explicit != MagickFalse) && (strncmp(implicit_vr,\"xs\",2) == 0))\n      (void) CopyMagickString(implicit_vr,explicit_vr,MagickPathExtent);\n    if ((use_explicit == MagickFalse) || (strncmp(implicit_vr,\"!!\",2) == 0))\n      {\n        offset=SeekBlob(image,(MagickOffsetType) -2,SEEK_CUR);\n        if (offset < 0)\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        quantum=4;\n      }\n    else\n      {\n        /*\n          Assume explicit type.\n        */\n        quantum=2;\n        if ((strncmp(explicit_vr,\"OB\",2) == 0) ||\n            (strncmp(explicit_vr,\"UN\",2) == 0) ||\n            (strncmp(explicit_vr,\"OW\",2) == 0) ||\n            (strncmp(explicit_vr,\"SQ\",2) == 0))\n          {\n            (void) ReadBlobLSBShort(image);\n            quantum=4;\n          }\n      }\n    datum=0;\n    if (quantum == 4)\n      {\n        if (group == 0x0002)\n          datum=ReadBlobLSBSignedLong(image);\n        else\n          datum=ReadBlobSignedLong(image);\n      }\n    else\n      if (quantum == 2)\n        {\n          if (group == 0x0002)\n            datum=ReadBlobLSBSignedShort(image);\n          else\n            datum=ReadBlobSignedShort(image);\n        }\n    quantum=0;\n    length=1;\n    if (datum != 0)\n      {\n        if ((strncmp(implicit_vr,\"SS\",2) == 0) ||\n            (strncmp(implicit_vr,\"US\",2) == 0))\n          quantum=2;\n        else\n          if ((strncmp(implicit_vr,\"UL\",2) == 0) ||\n              (strncmp(implicit_vr,\"SL\",2) == 0) ||\n              (strncmp(implicit_vr,\"FL\",2) == 0))\n            quantum=4;\n          else\n            if (strncmp(implicit_vr,\"FD\",2) != 0)\n              quantum=1;\n            else\n              quantum=8;\n        if (datum != ~0)\n          length=(size_t) datum/quantum;\n        else\n          {\n            /*\n              Sequence and item of undefined length.\n            */\n            quantum=0;\n            length=0;\n          }\n      }\n    if (image_info->verbose != MagickFalse)\n      {\n        /*\n          Display Dicom info.\n        */\n        if (use_explicit == MagickFalse)\n          explicit_vr[0]='\\0';\n        for (i=0; dicom_info[i].description != (char *) NULL; i++)\n          if ((group == dicom_info[i].group) &&\n              (element == dicom_info[i].element))\n            break;\n        (void) FormatLocaleFile(stdout,\"0x%04lX %4ld %s-%s (0x%04lx,0x%04lx)\",\n          (unsigned long) image->offset,(long) length,implicit_vr,explicit_vr,\n          (unsigned long) group,(unsigned long) element);\n        if (dicom_info[i].description != (char *) NULL)\n          (void) FormatLocaleFile(stdout,\" %s\",dicom_info[i].description);\n        (void) FormatLocaleFile(stdout,\": \");\n      }\n    if ((sequence == MagickFalse) && (group == 0x7FE0) && (element == 0x0010))\n      {\n        if (image_info->verbose != MagickFalse)\n          (void) FormatLocaleFile(stdout,\"\\n\");\n        break;\n      }\n    /*\n      Allocate space and read an array.\n    */\n    data=(unsigned char *) NULL;\n    if ((length == 1) && (quantum == 1))\n      datum=ReadBlobByte(image);\n    else\n      if ((length == 1) && (quantum == 2))\n        {\n          if (group == 0x0002)\n            datum=ReadBlobLSBSignedShort(image);\n          else\n            datum=ReadBlobSignedShort(image);\n        }\n      else\n        if ((length == 1) && (quantum == 4))\n          {\n            if (group == 0x0002)\n              datum=ReadBlobLSBSignedLong(image);\n            else\n              datum=ReadBlobSignedLong(image);\n          }\n        else\n          if ((quantum != 0) && (length != 0))\n            {\n              if (~length >= 1)\n                data=(unsigned char *) AcquireQuantumMemory(length+1,quantum*\n                  sizeof(*data));\n              if (data == (unsigned char *) NULL)\n                ThrowReaderException(ResourceLimitError,\n                  \"MemoryAllocationFailed\");\n              count=ReadBlob(image,(size_t) quantum*length,data);\n              if (count != (ssize_t) (quantum*length))\n                {\n                  if (image_info->verbose != MagickFalse)\n                    (void) FormatLocaleFile(stdout,\"count=%d quantum=%d \"\n                      \"length=%d group=%d\\n\",(int) count,(int) quantum,(int)\n                      length,(int) group);\n                   ThrowReaderException(CorruptImageError,\n                     \"InsufficientImageDataInFile\");\n                }\n              data[length*quantum]='\\0';\n            }\n          else\n            if ((unsigned int) datum == 0xFFFFFFFFU)\n              {\n                sequence=MagickTrue;\n                continue;\n              }\n\n    if ((unsigned int) ((group << 16) | element) == 0xFFFEE0DD)\n      {\n        if (data != (unsigned char *) NULL)\n          data=(unsigned char *) RelinquishMagickMemory(data);\n        sequence=MagickFalse;\n        continue;\n      }\n\n    if (sequence != MagickFalse)\n      {\n        if (data != (unsigned char *) NULL)\n          data=(unsigned char *) RelinquishMagickMemory(data);\n        continue;\n      }\n\n    switch (group)\n    {\n      case 0x0002:\n      {\n        switch (element)\n        {\n          case 0x0010:\n          {\n            char\n              transfer_syntax[MagickPathExtent];\n\n            /*\n              Transfer Syntax.\n            */\n            if ((datum == 0) && (explicit_retry == MagickFalse))\n              {\n                explicit_retry=MagickTrue;\n                (void) SeekBlob(image,(MagickOffsetType) 0,SEEK_SET);\n                group=0;\n                element=0;\n                if (image_info->verbose != MagickFalse)\n                  (void) FormatLocaleFile(stdout,\n                    \"Corrupted image - trying explicit format\\n\");\n                break;\n              }\n            *transfer_syntax='\\0';\n            if (data != (unsigned char *) NULL)\n              (void) CopyMagickString(transfer_syntax,(char *) data,\n                MagickPathExtent);\n            if (image_info->verbose != MagickFalse)\n              (void) FormatLocaleFile(stdout,\"transfer_syntax=%s\\n\",\n                (const char *) transfer_syntax);\n            if (strncmp(transfer_syntax,\"1.2.840.10008.1.2\",17) == 0)\n              {\n                int\n                  count,\n                  subtype,\n                  type;\n\n                type=1;\n                subtype=0;\n                if (strlen(transfer_syntax) > 17)\n                  {\n                    count=sscanf(transfer_syntax+17,\".%d.%d\",&type,&subtype);\n                    if (count < 1)\n                      ThrowReaderException(CorruptImageError,\n                        \"ImproperImageHeader\");\n                  }\n                switch (type)\n                {\n                  case 1:\n                  {\n                    image->endian=LSBEndian;\n                    break;\n                  }\n                  case 2:\n                  {\n                    image->endian=MSBEndian;\n                    break;\n                  }\n                  case 4:\n                  {\n                    if ((subtype >= 80) && (subtype <= 81))\n                      image->compression=JPEGCompression;\n                    else\n                      if ((subtype >= 90) && (subtype <= 93))\n                        image->compression=JPEG2000Compression;\n                      else\n                        image->compression=JPEGCompression;\n                    break;\n                  }\n                  case 5:\n                  {\n                    image->compression=RLECompression;\n                    break;\n                  }\n                }\n              }\n            break;\n          }\n          default:\n            break;\n        }\n        break;\n      }\n      case 0x0028:\n      {\n        switch (element)\n        {\n          case 0x0002:\n          {\n            /*\n              Samples per pixel.\n            */\n            samples_per_pixel=(size_t) datum;\n            break;\n          }\n          case 0x0004:\n          {\n            /*\n              Photometric interpretation.\n            */\n            for (i=0; i < (ssize_t) MagickMin(length,MagickPathExtent-1); i++)\n              photometric[i]=(char) data[i];\n            photometric[i]='\\0';\n            polarity=LocaleCompare(photometric,\"MONOCHROME1 \") == 0 ?\n              MagickTrue : MagickFalse;\n            break;\n          }\n          case 0x0006:\n          {\n            /*\n              Planar configuration.\n            */\n            if (datum == 1)\n              image->interlace=PlaneInterlace;\n            break;\n          }\n          case 0x0008:\n          {\n            /*\n              Number of frames.\n            */\n            number_scenes=StringToUnsignedLong((char *) data);\n            break;\n          }\n          case 0x0010:\n          {\n            /*\n              Image rows.\n            */\n            height=(size_t) datum;\n            break;\n          }\n          case 0x0011:\n          {\n            /*\n              Image columns.\n            */\n            width=(size_t) datum;\n            break;\n          }\n          case 0x0100:\n          {\n            /*\n              Bits allocated.\n            */\n            bits_allocated=(size_t) datum;\n            bytes_per_pixel=1;\n            if (datum > 8)\n              bytes_per_pixel=2;\n            depth=bits_allocated;\n            if (depth > 32)\n              ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n            max_value=(1UL << bits_allocated)-1;\n            break;\n          }\n          case 0x0101:\n          {\n            /*\n              Bits stored.\n            */\n            significant_bits=(size_t) datum;\n            bytes_per_pixel=1;\n            if (significant_bits > 8)\n              bytes_per_pixel=2;\n            depth=significant_bits;\n            if (depth > 32)\n              ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n            max_value=(1UL << significant_bits)-1;\n            mask=(size_t) GetQuantumRange(significant_bits);\n            break;\n          }\n          case 0x0102:\n          {\n            /*\n              High bit.\n            */\n            break;\n          }\n          case 0x0103:\n          {\n            /*\n              Pixel representation.\n            */\n            signed_data=(size_t) datum;\n            break;\n          }\n          case 0x1050:\n          {\n            /*\n              Visible pixel range: center.\n            */\n            if (data != (unsigned char *) NULL)\n              window_center=(ssize_t) StringToLong((char *) data);\n            break;\n          }\n          case 0x1051:\n          {\n            /*\n              Visible pixel range: width.\n            */\n            if (data != (unsigned char *) NULL)\n              window_width=StringToUnsignedLong((char *) data);\n            break;\n          }\n          case 0x1052:\n          {\n            /*\n              Rescale intercept\n            */\n            if (data != (unsigned char *) NULL)\n              rescale_intercept=(ssize_t) StringToLong((char *) data);\n            break;\n          }\n          case 0x1053:\n          {\n            /*\n              Rescale slope\n            */\n            if (data != (unsigned char *) NULL)\n              rescale_slope=(ssize_t) StringToLong((char *) data);\n            break;\n          }\n          case 0x1200:\n          case 0x3006:\n          {\n            /*\n              Populate graymap.\n            */\n            if (data == (unsigned char *) NULL)\n              break;\n            colors=(size_t) (length/bytes_per_pixel);\n            datum=(int) colors;\n            graymap=(int *) AcquireQuantumMemory((size_t) colors,\n              sizeof(*graymap));\n            if (graymap == (int *) NULL)\n              ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n            for (i=0; i < (ssize_t) colors; i++)\n              if (bytes_per_pixel == 1)\n                graymap[i]=(int) data[i];\n              else\n                graymap[i]=(int) ((short *) data)[i];\n            break;\n          }\n          case 0x1201:\n          {\n            unsigned short\n              index;\n\n            /*\n              Populate redmap.\n            */\n            if (data == (unsigned char *) NULL)\n              break;\n            colors=(size_t) (length/2);\n            datum=(int) colors;\n            redmap=(int *) AcquireQuantumMemory((size_t) colors,\n              sizeof(*redmap));\n            if (redmap == (int *) NULL)\n              ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n            p=data;\n            for (i=0; i < (ssize_t) colors; i++)\n            {\n              if (image->endian == MSBEndian)\n                index=(unsigned short) ((*p << 8) | *(p+1));\n              else\n                index=(unsigned short) (*p | (*(p+1) << 8));\n              redmap[i]=(int) index;\n              p+=2;\n            }\n            break;\n          }\n          case 0x1202:\n          {\n            unsigned short\n              index;\n\n            /*\n              Populate greenmap.\n            */\n            if (data == (unsigned char *) NULL)\n              break;\n            colors=(size_t) (length/2);\n            datum=(int) colors;\n            greenmap=(int *) AcquireQuantumMemory((size_t) colors,\n              sizeof(*greenmap));\n            if (greenmap == (int *) NULL)\n              ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n            p=data;\n            for (i=0; i < (ssize_t) colors; i++)\n            {\n              if (image->endian == MSBEndian)\n                index=(unsigned short) ((*p << 8) | *(p+1));\n              else\n                index=(unsigned short) (*p | (*(p+1) << 8));\n              greenmap[i]=(int) index;\n              p+=2;\n            }\n            break;\n          }\n          case 0x1203:\n          {\n            unsigned short\n              index;\n\n            /*\n              Populate bluemap.\n            */\n            if (data == (unsigned char *) NULL)\n              break;\n            colors=(size_t) (length/2);\n            datum=(int) colors;\n            bluemap=(int *) AcquireQuantumMemory((size_t) colors,\n              sizeof(*bluemap));\n            if (bluemap == (int *) NULL)\n              ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n            p=data;\n            for (i=0; i < (ssize_t) colors; i++)\n            {\n              if (image->endian == MSBEndian)\n                index=(unsigned short) ((*p << 8) | *(p+1));\n              else\n                index=(unsigned short) (*p | (*(p+1) << 8));\n              bluemap[i]=(int) index;\n              p+=2;\n            }\n            break;\n          }\n          default:\n            break;\n        }\n        break;\n      }\n      case 0x2050:\n      {\n        switch (element)\n        {\n          case 0x0020:\n          {\n            if ((data != (unsigned char *) NULL) &&\n                (strncmp((char *) data,\"INVERSE\",7) == 0))\n              polarity=MagickTrue;\n            break;\n          }\n          default:\n            break;\n        }\n        break;\n      }\n      default:\n        break;\n    }\n    if (data != (unsigned char *) NULL)\n      {\n        char\n          *attribute;\n\n        for (i=0; dicom_info[i].description != (char *) NULL; i++)\n          if ((group == dicom_info[i].group) &&\n              (element == dicom_info[i].element))\n            break;\n        if (dicom_info[i].description != (char *) NULL)\n          {\n            attribute=AcquireString(\"dcm:\");\n            (void) ConcatenateString(&attribute,dicom_info[i].description);\n            for (i=0; i < (ssize_t) MagickMax(length,4); i++)\n              if (isprint((int) data[i]) == MagickFalse)\n                break;\n            if ((i == (ssize_t) length) || (length > 4))\n              {\n                (void) SubstituteString(&attribute,\" \",\"\");\n                (void) SetImageProperty(image,attribute,(char *) data,exception);\n              }\n            attribute=DestroyString(attribute);\n          }\n      }\n    if (image_info->verbose != MagickFalse)\n      {\n        if (data == (unsigned char *) NULL)\n          (void) FormatLocaleFile(stdout,\"%d\\n\",datum);\n        else\n          {\n            /*\n              Display group data.\n            */\n            for (i=0; i < (ssize_t) MagickMax(length,4); i++)\n              if (isprint((int) data[i]) == MagickFalse)\n                break;\n            if ((i != (ssize_t) length) && (length <= 4))\n              {\n                ssize_t\n                  j;\n\n                datum=0;\n                for (j=(ssize_t) length-1; j >= 0; j--)\n                  datum=(256*datum+data[j]);\n                (void) FormatLocaleFile(stdout,\"%d\",datum);\n              }\n            else\n              for (i=0; i < (ssize_t) length; i++)\n                if (isprint((int) data[i]) != MagickFalse)\n                  (void) FormatLocaleFile(stdout,\"%c\",data[i]);\n                else\n                  (void) FormatLocaleFile(stdout,\"%c\",'.');\n            (void) FormatLocaleFile(stdout,\"\\n\");\n          }\n      }\n    if (data != (unsigned char *) NULL)\n      data=(unsigned char *) RelinquishMagickMemory(data);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n  }\n  if ((width == 0) || (height == 0))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  image->columns=(size_t) width;\n  image->rows=(size_t) height;\n  if (signed_data == 0xffff)\n    signed_data=(size_t) (significant_bits == 16 ? 1 : 0);\n  if ((image->compression == JPEGCompression) ||\n      (image->compression == JPEG2000Compression))\n    {\n      Image\n        *images;\n\n      ImageInfo\n        *read_info;\n\n      int\n        c;\n\n      size_t\n        length;\n\n      unsigned int\n        tag;\n\n      /*\n        Read offset table.\n      */\n      for (i=0; i < (ssize_t) stream_info->remaining; i++)\n        (void) ReadBlobByte(image);\n      tag=(ReadBlobLSBShort(image) << 16) | ReadBlobLSBShort(image);\n      (void) tag;\n      length=(size_t) ReadBlobLSBLong(image);\n      stream_info->offset_count=length >> 2;\n      if (stream_info->offset_count != 0)\n        {\n          MagickOffsetType\n            offset;\n\n          stream_info->offsets=(ssize_t *) AcquireQuantumMemory(\n            stream_info->offset_count,sizeof(*stream_info->offsets));\n          if (stream_info->offsets == (ssize_t *) NULL)\n            ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          for (i=0; i < (ssize_t) stream_info->offset_count; i++)\n            stream_info->offsets[i]=(ssize_t) ReadBlobLSBSignedLong(image);\n          offset=TellBlob(image);\n          for (i=0; i < (ssize_t) stream_info->offset_count; i++)\n            stream_info->offsets[i]+=offset;\n        }\n      /*\n        Handle non-native image formats.\n      */\n      read_info=CloneImageInfo(image_info);\n      SetImageInfoBlob(read_info,(void *) NULL,0);\n      images=NewImageList();\n      for (scene=0; scene < (ssize_t) number_scenes; scene++)\n      {\n        char\n          filename[MagickPathExtent];\n\n        const char\n          *property;\n\n        FILE\n          *file;\n\n        Image\n          *jpeg_image;\n\n        int\n          unique_file;\n\n        unsigned int\n          tag;\n\n        tag=(ReadBlobLSBShort(image) << 16) | ReadBlobLSBShort(image);\n        length=(size_t) ReadBlobLSBLong(image);\n        if (tag == 0xFFFEE0DD)\n          break; /* sequence delimiter tag */\n        if (tag != 0xFFFEE000)\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        file=(FILE *) NULL;\n        unique_file=AcquireUniqueFileResource(filename);\n        if (unique_file != -1)\n          file=fdopen(unique_file,\"wb\");\n        if (file == (FILE *) NULL)\n          {\n            (void) RelinquishUniqueFileResource(filename);\n            ThrowFileException(exception,FileOpenError,\n              \"UnableToCreateTemporaryFile\",filename);\n            break;\n          }\n        for ( ; length != 0; length--)\n        {\n          c=ReadBlobByte(image);\n          if (c == EOF)\n            {\n              ThrowFileException(exception,CorruptImageError,\n                \"UnexpectedEndOfFile\",image->filename);\n              break;\n            }\n          (void) fputc(c,file);\n        }\n        (void) fclose(file);\n        (void) FormatLocaleString(read_info->filename,MagickPathExtent,\n          \"jpeg:%s\",filename);\n        if (image->compression == JPEG2000Compression)\n          (void) FormatLocaleString(read_info->filename,MagickPathExtent,\n            \"j2k:%s\",filename);\n        jpeg_image=ReadImage(read_info,exception);\n        if (jpeg_image != (Image *) NULL)\n          {\n            ResetImagePropertyIterator(image);\n            property=GetNextImageProperty(image);\n            while (property != (const char *) NULL)\n            {\n              (void) SetImageProperty(jpeg_image,property,\n                GetImageProperty(image,property,exception),exception);\n              property=GetNextImageProperty(image);\n            }\n            AppendImageToList(&images,jpeg_image);\n          }\n        (void) RelinquishUniqueFileResource(filename);\n      }\n      read_info=DestroyImageInfo(read_info);\n      image=DestroyImage(image);\n      return(GetFirstImageInList(images));\n    }\n  if (depth != (1UL*MAGICKCORE_QUANTUM_DEPTH))\n    {\n      QuantumAny\n        range;\n\n      size_t\n        length;\n\n      /*\n        Compute pixel scaling table.\n      */\n      length=(size_t) (GetQuantumRange(depth)+1);\n      scale=(Quantum *) AcquireQuantumMemory(length,sizeof(*scale));\n      if (scale == (Quantum *) NULL)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      range=GetQuantumRange(depth);\n      for (i=0; i < (ssize_t) (GetQuantumRange(depth)+1); i++)\n        scale[i]=ScaleAnyToQuantum((size_t) i,range);\n    }\n  if (image->compression == RLECompression)\n    {\n      size_t\n        length;\n\n      unsigned int\n        tag;\n\n      /*\n        Read RLE offset table.\n      */\n      for (i=0; i < (ssize_t) stream_info->remaining; i++)\n        (void) ReadBlobByte(image);\n      tag=(ReadBlobLSBShort(image) << 16) | ReadBlobLSBShort(image);\n      (void) tag;\n      length=(size_t) ReadBlobLSBLong(image);\n      stream_info->offset_count=length >> 2;\n      if (stream_info->offset_count != 0)\n        {\n          MagickOffsetType\n            offset;\n\n          stream_info->offsets=(ssize_t *) AcquireQuantumMemory(\n            stream_info->offset_count,sizeof(*stream_info->offsets));\n          if (stream_info->offsets == (ssize_t *) NULL)\n            ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          for (i=0; i < (ssize_t) stream_info->offset_count; i++)\n            stream_info->offsets[i]=(ssize_t) ReadBlobLSBSignedLong(image);\n          offset=TellBlob(image);\n          for (i=0; i < (ssize_t) stream_info->offset_count; i++)\n            stream_info->offsets[i]+=offset;\n        }\n    }\n  for (scene=0; scene < (ssize_t) number_scenes; scene++)\n  {\n    if (image_info->ping != MagickFalse)\n      break;\n    image->columns=(size_t) width;\n    image->rows=(size_t) height;\n    image->depth=depth;\n    status=SetImageExtent(image,image->columns,image->rows,exception);\n    if (status == MagickFalse)\n      break;\n    image->colorspace=RGBColorspace;\n    if ((image->colormap == (PixelInfo *) NULL) && (samples_per_pixel == 1))\n      {\n        size_t\n          one;\n\n        one=1;\n        if (colors == 0)\n          colors=one << depth;\n        if (AcquireImageColormap(image,one << depth,exception) == MagickFalse)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        if (redmap != (int *) NULL)\n          for (i=0; i < (ssize_t) colors; i++)\n          {\n            index=redmap[i];\n            if ((scale != (Quantum *) NULL) && (index <= (int) max_value))\n              index=(int) scale[index];\n            image->colormap[i].red=(MagickRealType) index;\n          }\n        if (greenmap != (int *) NULL)\n          for (i=0; i < (ssize_t) colors; i++)\n          {\n            index=greenmap[i];\n            if ((scale != (Quantum *) NULL) && (index <= (int) max_value))\n              index=(int) scale[index];\n            image->colormap[i].green=(MagickRealType) index;\n          }\n        if (bluemap != (int *) NULL)\n          for (i=0; i < (ssize_t) colors; i++)\n          {\n            index=bluemap[i];\n            if ((scale != (Quantum *) NULL) && (index <= (int) max_value))\n              index=(int) scale[index];\n            image->colormap[i].blue=(MagickRealType) index;\n          }\n        if (graymap != (int *) NULL)\n          for (i=0; i < (ssize_t) colors; i++)\n          {\n            index=graymap[i];\n            if ((scale != (Quantum *) NULL) && (index <= (int) max_value))\n              index=(int) scale[index];\n            image->colormap[i].red=(MagickRealType) index;\n            image->colormap[i].green=(MagickRealType) index;\n            image->colormap[i].blue=(MagickRealType) index;\n          }\n      }\n    if (image->compression == RLECompression)\n      {\n        unsigned int\n          tag;\n\n        /*\n          Read RLE segment table.\n        */\n        for (i=0; i < (ssize_t) stream_info->remaining; i++)\n          (void) ReadBlobByte(image);\n        tag=(ReadBlobLSBShort(image) << 16) | ReadBlobLSBShort(image);\n        stream_info->remaining=(size_t) ReadBlobLSBLong(image);\n        if ((tag != 0xFFFEE000) || (stream_info->remaining <= 64) ||\n            (EOFBlob(image) != MagickFalse))\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        stream_info->count=0;\n        stream_info->segment_count=ReadBlobLSBLong(image);\n        if (stream_info->segment_count > 1)\n          {\n            bytes_per_pixel=1;\n            depth=8;\n          }\n        for (i=0; i < 15; i++)\n          stream_info->segments[i]=(ssize_t) ReadBlobLSBSignedLong(image);\n        stream_info->remaining-=64;\n      }\n    if ((samples_per_pixel > 1) && (image->interlace == PlaneInterlace))\n      {\n        /*\n          Convert Planar RGB DCM Medical image to pixel packets.\n        */\n        for (i=0; i < (ssize_t) samples_per_pixel; i++)\n        {\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            q=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n            if (q == (Quantum *) NULL)\n              break;\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              switch ((int) i)\n              {\n                case 0:\n                {\n                  SetPixelRed(image,ScaleCharToQuantum((unsigned char)\n                    ReadDCMByte(stream_info,image)),q);\n                  break;\n                }\n                case 1:\n                {\n                  SetPixelGreen(image,ScaleCharToQuantum((unsigned char)\n                    ReadDCMByte(stream_info,image)),q);\n                  break;\n                }\n                case 2:\n                {\n                  SetPixelBlue(image,ScaleCharToQuantum((unsigned char)\n                    ReadDCMByte(stream_info,image)),q);\n                  break;\n                }\n                case 3:\n                {\n                  SetPixelAlpha(image,ScaleCharToQuantum((unsigned char)\n                    ReadDCMByte(stream_info,image)),q);\n                  break;\n                }\n                default:\n                  break;\n              }\n              q+=GetPixelChannels(image);\n            }\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n              break;\n            if (image->previous == (Image *) NULL)\n              {\n                status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                  image->rows);\n                if (status == MagickFalse)\n                  break;\n              }\n          }\n        }\n      }\n    else\n      {\n        const char\n          *option;\n\n        int\n          byte;\n\n        PixelPacket\n          pixel;\n\n        /*\n          Convert DCM Medical image to pixel packets.\n        */\n        byte=0;\n        i=0;\n        if ((window_center != 0) && (window_width == 0))\n          window_width=(size_t) window_center;\n        option=GetImageOption(image_info,\"dcm:display-range\");\n        if (option != (const char *) NULL)\n          {\n            if (LocaleCompare(option,\"reset\") == 0)\n              window_width=0;\n          }\n        (void) ResetMagickMemory(&pixel,0,sizeof(pixel));\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n          if (q == (Quantum *) NULL)\n            break;\n          for (x=0; x < (ssize_t) image->columns; x++)\n          {\n            if (samples_per_pixel == 1)\n              {\n                int\n                  pixel_value;\n\n                if (bytes_per_pixel == 1)\n                  pixel_value=polarity != MagickFalse ?\n                    ((int) max_value-ReadDCMByte(stream_info,image)) :\n                    ReadDCMByte(stream_info,image);\n                else\n                  if ((bits_allocated != 12) || (significant_bits != 12))\n                    {\n                      if (signed_data)\n                        pixel_value=ReadDCMSignedShort(stream_info,image);\n                      else\n                        pixel_value=ReadDCMShort(stream_info,image);\n                      if (polarity != MagickFalse)\n                        pixel_value=(int)max_value-pixel_value;\n                    }\n                  else\n                    {\n                      if ((i & 0x01) != 0)\n                        pixel_value=(ReadDCMByte(stream_info,image) << 8) |\n                          byte;\n                      else\n                        {\n                          pixel_value=ReadDCMSignedShort(stream_info,image);\n                          byte=(int) (pixel_value & 0x0f);\n                          pixel_value>>=4;\n                        }\n                      i++;\n                    }\n                index=(pixel_value*rescale_slope)+rescale_intercept;\n                if (window_width == 0)\n                  {\n                    if (signed_data == 1)\n                      index-=32767;\n                  }\n                else\n                  {\n                    ssize_t\n                      window_max,\n                      window_min;\n\n                    window_min=(ssize_t) ceil((double) window_center-\n                      (window_width-1.0)/2.0-0.5);\n                    window_max=(ssize_t) floor((double) window_center+\n                      (window_width-1.0)/2.0+0.5);\n                    if ((ssize_t)index <= window_min)\n                      index=0;\n                    else\n                      if ((ssize_t)index > window_max)\n                        index=(int) max_value;\n                      else\n                        index=(int) (max_value*(((index-window_center-\n                          0.5)/(window_width-1))+0.5));\n                  }\n                index&=mask;\n                index=(int) ConstrainColormapIndex(image,(size_t) index,\n                  exception);\n                SetPixelIndex(image,(Quantum) index,q);\n                pixel.red=(unsigned int) image->colormap[index].red;\n                pixel.green=(unsigned int) image->colormap[index].green;\n                pixel.blue=(unsigned int) image->colormap[index].blue;\n              }\n            else\n              {\n                if (bytes_per_pixel == 1)\n                  {\n                    pixel.red=(unsigned int) ReadDCMByte(stream_info,image);\n                    pixel.green=(unsigned int) ReadDCMByte(stream_info,image);\n                    pixel.blue=(unsigned int) ReadDCMByte(stream_info,image);\n                  }\n                else\n                  {\n                    pixel.red=ReadDCMShort(stream_info,image);\n                    pixel.green=ReadDCMShort(stream_info,image);\n                    pixel.blue=ReadDCMShort(stream_info,image);\n                  }\n                pixel.red&=mask;\n                pixel.green&=mask;\n                pixel.blue&=mask;\n                if (scale != (Quantum *) NULL)\n                  {\n                    pixel.red=scale[pixel.red];\n                    pixel.green=scale[pixel.green];\n                    pixel.blue=scale[pixel.blue];\n                  }\n              }\n            SetPixelRed(image,(Quantum) pixel.red,q);\n            SetPixelGreen(image,(Quantum) pixel.green,q);\n            SetPixelBlue(image,(Quantum) pixel.blue,q);\n            q+=GetPixelChannels(image);\n          }\n          if (SyncAuthenticPixels(image,exception) == MagickFalse)\n            break;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n        if (stream_info->segment_count > 1)\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n            if (q == (Quantum *) NULL)\n              break;\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              if (samples_per_pixel == 1)\n                {\n                  int\n                    pixel_value;\n\n                  if (bytes_per_pixel == 1)\n                    pixel_value=polarity != MagickFalse ?\n                      ((int) max_value-ReadDCMByte(stream_info,image)) :\n                      ReadDCMByte(stream_info,image);\n                  else\n                    if ((bits_allocated != 12) || (significant_bits != 12))\n                      {\n                        pixel_value=(int) (polarity != MagickFalse ?\n                          (max_value-ReadDCMShort(stream_info,image)) :\n                          ReadDCMShort(stream_info,image));\n                        if (signed_data == 1)\n                          pixel_value=((signed short) pixel_value);\n                      }\n                    else\n                      {\n                        if ((i & 0x01) != 0)\n                          pixel_value=(ReadDCMByte(stream_info,image) << 8) |\n                            byte;\n                        else\n                          {\n                            pixel_value=ReadDCMShort(stream_info,image);\n                            byte=(int) (pixel_value & 0x0f);\n                            pixel_value>>=4;\n                          }\n                        i++;\n                      }\n                  index=(pixel_value*rescale_slope)+rescale_intercept;\n                  if (window_width == 0)\n                    {\n                      if (signed_data == 1)\n                        index-=32767;\n                    }\n                  else\n                    {\n                      ssize_t\n                        window_max,\n                        window_min;\n\n                      window_min=(ssize_t) ceil((double) window_center-\n                        (window_width-1.0)/2.0-0.5);\n                      window_max=(ssize_t) floor((double) window_center+\n                        (window_width-1.0)/2.0+0.5);\n                      if ((ssize_t)index <= window_min)\n                        index=0;\n                      else\n                        if ((ssize_t)index > window_max)\n                          index=(int) max_value;\n                        else\n                          index=(int) (max_value*(((index-window_center-\n                            0.5)/(window_width-1))+0.5));\n                    }\n                  index&=mask;\n                  index=(int) ConstrainColormapIndex(image,(size_t) index,\n                    exception);\n                  SetPixelIndex(image,(Quantum) (((size_t)\n                    GetPixelIndex(image,q)) | (((size_t) index) << 8)),q);\n                  pixel.red=(unsigned int) image->colormap[index].red;\n                  pixel.green=(unsigned int) image->colormap[index].green;\n                  pixel.blue=(unsigned int) image->colormap[index].blue;\n                }\n              else\n                {\n                  if (bytes_per_pixel == 1)\n                    {\n                      pixel.red=(unsigned int) ReadDCMByte(stream_info,image);\n                      pixel.green=(unsigned int) ReadDCMByte(stream_info,image);\n                      pixel.blue=(unsigned int) ReadDCMByte(stream_info,image);\n                    }\n                  else\n                    {\n                      pixel.red=ReadDCMShort(stream_info,image);\n                      pixel.green=ReadDCMShort(stream_info,image);\n                      pixel.blue=ReadDCMShort(stream_info,image);\n                    }\n                  pixel.red&=mask;\n                  pixel.green&=mask;\n                  pixel.blue&=mask;\n                  if (scale != (Quantum *) NULL)\n                    {\n                      pixel.red=scale[pixel.red];\n                      pixel.green=scale[pixel.green];\n                      pixel.blue=scale[pixel.blue];\n                    }\n                }\n              SetPixelRed(image,(Quantum) (((size_t) GetPixelRed(image,q)) |\n                (((size_t) pixel.red) << 8)),q);\n              SetPixelGreen(image,(Quantum) (((size_t) GetPixelGreen(image,q)) |\n                (((size_t) pixel.green) << 8)),q);\n              SetPixelBlue(image,(Quantum) (((size_t) GetPixelBlue(image,q)) |\n                (((size_t) pixel.blue) << 8)),q);\n              q+=GetPixelChannels(image);\n            }\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n              break;\n            if (image->previous == (Image *) NULL)\n              {\n                status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                  image->rows);\n                if (status == MagickFalse)\n                  break;\n              }\n          }\n      }\n    if (SetImageGray(image,exception) != MagickFalse)\n      (void) SetImageColorspace(image,GRAYColorspace,exception);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    /*\n      Proceed to next image.\n    */\n    if (image_info->number_scenes != 0)\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    if (scene < (ssize_t) (number_scenes-1))\n      {\n        /*\n          Allocate next image structure.\n        */\n        AcquireNextImage(image_info,image,exception);\n        if (GetNextImageInList(image) == (Image *) NULL)\n          {\n            image=DestroyImageList(image);\n            return((Image *) NULL);\n          }\n        image=SyncNextImageInList(image);\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n        if (status == MagickFalse)\n          break;\n      }\n  }\n  /*\n    Free resources.\n  */\n  if (stream_info->offsets != (ssize_t *) NULL)\n    stream_info->offsets=(ssize_t *)\n      RelinquishMagickMemory(stream_info->offsets);\n  stream_info=(DCMStreamInfo *) RelinquishMagickMemory(stream_info);\n  if (scale != (Quantum *) NULL)\n    scale=(Quantum *) RelinquishMagickMemory(scale);\n  if (graymap != (int *) NULL)\n    graymap=(int *) RelinquishMagickMemory(graymap);\n  if (bluemap != (int *) NULL)\n    bluemap=(int *) RelinquishMagickMemory(bluemap);\n  if (greenmap != (int *) NULL)\n    greenmap=(int *) RelinquishMagickMemory(greenmap);\n  if (redmap != (int *) NULL)\n    redmap=(int *) RelinquishMagickMemory(redmap);\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "func_src_after": "static Image *ReadDCMImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  char\n    explicit_vr[MagickPathExtent],\n    implicit_vr[MagickPathExtent],\n    magick[MagickPathExtent],\n    photometric[MagickPathExtent];\n\n  DCMStreamInfo\n    *stream_info;\n\n  Image\n    *image;\n\n  int\n    *bluemap,\n    datum,\n    *greenmap,\n    *graymap,\n    index,\n    *redmap;\n\n  MagickBooleanType\n    explicit_file,\n    explicit_retry,\n    polarity,\n    sequence,\n    use_explicit;\n\n  MagickOffsetType\n    offset;\n\n  Quantum\n    *scale;\n\n  register ssize_t\n    i,\n    x;\n\n  register Quantum\n    *q;\n\n  register unsigned char\n    *p;\n\n  size_t\n    bits_allocated,\n    bytes_per_pixel,\n    colors,\n    depth,\n    height,\n    length,\n    mask,\n    max_value,\n    number_scenes,\n    quantum,\n    samples_per_pixel,\n    signed_data,\n    significant_bits,\n    status,\n    width,\n    window_width;\n\n  ssize_t\n    count,\n    rescale_intercept,\n    rescale_slope,\n    scene,\n    window_center,\n    y;\n\n  unsigned char\n    *data;\n\n  unsigned short\n    group,\n    element;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  image->depth=8UL;\n  image->endian=LSBEndian;\n  /*\n    Read DCM preamble.\n  */\n  stream_info=(DCMStreamInfo *) AcquireMagickMemory(sizeof(*stream_info));\n  if (stream_info == (DCMStreamInfo *) NULL)\n    ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n  (void) ResetMagickMemory(stream_info,0,sizeof(*stream_info));\n  count=ReadBlob(image,128,(unsigned char *) magick);\n  if (count != 128)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  count=ReadBlob(image,4,(unsigned char *) magick);\n  if ((count != 4) || (LocaleNCompare(magick,\"DICM\",4) != 0))\n    {\n      offset=SeekBlob(image,0L,SEEK_SET);\n      if (offset < 0)\n        ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    }\n  /*\n    Read DCM Medical image.\n  */\n  (void) CopyMagickString(photometric,\"MONOCHROME1 \",MagickPathExtent);\n  bits_allocated=8;\n  bytes_per_pixel=1;\n  polarity=MagickFalse;\n  data=(unsigned char *) NULL;\n  depth=8;\n  element=0;\n  explicit_vr[2]='\\0';\n  explicit_file=MagickFalse;\n  colors=0;\n  redmap=(int *) NULL;\n  greenmap=(int *) NULL;\n  bluemap=(int *) NULL;\n  graymap=(int *) NULL;\n  height=0;\n  max_value=255UL;\n  mask=0xffff;\n  number_scenes=1;\n  rescale_intercept=0;\n  rescale_slope=1;\n  samples_per_pixel=1;\n  scale=(Quantum *) NULL;\n  sequence=MagickFalse;\n  signed_data=(~0UL);\n  significant_bits=0;\n  use_explicit=MagickFalse;\n  explicit_retry = MagickFalse;\n  width=0;\n  window_center=0;\n  window_width=0;\n  for (group=0; (group != 0x7FE0) || (element != 0x0010) ||\n                (sequence != MagickFalse); )\n  {\n    /*\n      Read a group.\n    */\n    image->offset=(ssize_t) TellBlob(image);\n    group=ReadBlobLSBShort(image);\n    element=ReadBlobLSBShort(image);\n    if ((group != 0x0002) && (image->endian == MSBEndian))\n      {\n        group=(unsigned short) ((group << 8) | ((group >> 8) & 0xFF));\n        element=(unsigned short) ((element << 8) | ((element >> 8) & 0xFF));\n      }\n    quantum=0;\n    /*\n      Find corresponding VR for this group and element.\n    */\n    for (i=0; dicom_info[i].group < 0xffff; i++)\n      if ((group == dicom_info[i].group) && (element == dicom_info[i].element))\n        break;\n    (void) CopyMagickString(implicit_vr,dicom_info[i].vr,MagickPathExtent);\n    count=ReadBlob(image,2,(unsigned char *) explicit_vr);\n    if (count != 2)\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    /*\n      Check for \"explicitness\", but meta-file headers always explicit.\n    */\n    if ((explicit_file == MagickFalse) && (group != 0x0002))\n      explicit_file=(isupper((unsigned char) *explicit_vr) != MagickFalse) &&\n        (isupper((unsigned char) *(explicit_vr+1)) != MagickFalse) ?\n        MagickTrue : MagickFalse;\n    use_explicit=((group == 0x0002) && (explicit_retry == MagickFalse)) ||\n      (explicit_file != MagickFalse) ? MagickTrue : MagickFalse;\n    if ((use_explicit != MagickFalse) && (strncmp(implicit_vr,\"xs\",2) == 0))\n      (void) CopyMagickString(implicit_vr,explicit_vr,MagickPathExtent);\n    if ((use_explicit == MagickFalse) || (strncmp(implicit_vr,\"!!\",2) == 0))\n      {\n        offset=SeekBlob(image,(MagickOffsetType) -2,SEEK_CUR);\n        if (offset < 0)\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        quantum=4;\n      }\n    else\n      {\n        /*\n          Assume explicit type.\n        */\n        quantum=2;\n        if ((strncmp(explicit_vr,\"OB\",2) == 0) ||\n            (strncmp(explicit_vr,\"UN\",2) == 0) ||\n            (strncmp(explicit_vr,\"OW\",2) == 0) ||\n            (strncmp(explicit_vr,\"SQ\",2) == 0))\n          {\n            (void) ReadBlobLSBShort(image);\n            quantum=4;\n          }\n      }\n    datum=0;\n    if (quantum == 4)\n      {\n        if (group == 0x0002)\n          datum=ReadBlobLSBSignedLong(image);\n        else\n          datum=ReadBlobSignedLong(image);\n      }\n    else\n      if (quantum == 2)\n        {\n          if (group == 0x0002)\n            datum=ReadBlobLSBSignedShort(image);\n          else\n            datum=ReadBlobSignedShort(image);\n        }\n    quantum=0;\n    length=1;\n    if (datum != 0)\n      {\n        if ((strncmp(implicit_vr,\"SS\",2) == 0) ||\n            (strncmp(implicit_vr,\"US\",2) == 0))\n          quantum=2;\n        else\n          if ((strncmp(implicit_vr,\"UL\",2) == 0) ||\n              (strncmp(implicit_vr,\"SL\",2) == 0) ||\n              (strncmp(implicit_vr,\"FL\",2) == 0))\n            quantum=4;\n          else\n            if (strncmp(implicit_vr,\"FD\",2) != 0)\n              quantum=1;\n            else\n              quantum=8;\n        if (datum != ~0)\n          length=(size_t) datum/quantum;\n        else\n          {\n            /*\n              Sequence and item of undefined length.\n            */\n            quantum=0;\n            length=0;\n          }\n      }\n    if (image_info->verbose != MagickFalse)\n      {\n        /*\n          Display Dicom info.\n        */\n        if (use_explicit == MagickFalse)\n          explicit_vr[0]='\\0';\n        for (i=0; dicom_info[i].description != (char *) NULL; i++)\n          if ((group == dicom_info[i].group) &&\n              (element == dicom_info[i].element))\n            break;\n        (void) FormatLocaleFile(stdout,\"0x%04lX %4ld %s-%s (0x%04lx,0x%04lx)\",\n          (unsigned long) image->offset,(long) length,implicit_vr,explicit_vr,\n          (unsigned long) group,(unsigned long) element);\n        if (dicom_info[i].description != (char *) NULL)\n          (void) FormatLocaleFile(stdout,\" %s\",dicom_info[i].description);\n        (void) FormatLocaleFile(stdout,\": \");\n      }\n    if ((sequence == MagickFalse) && (group == 0x7FE0) && (element == 0x0010))\n      {\n        if (image_info->verbose != MagickFalse)\n          (void) FormatLocaleFile(stdout,\"\\n\");\n        break;\n      }\n    /*\n      Allocate space and read an array.\n    */\n    data=(unsigned char *) NULL;\n    if ((length == 1) && (quantum == 1))\n      datum=ReadBlobByte(image);\n    else\n      if ((length == 1) && (quantum == 2))\n        {\n          if (group == 0x0002)\n            datum=ReadBlobLSBSignedShort(image);\n          else\n            datum=ReadBlobSignedShort(image);\n        }\n      else\n        if ((length == 1) && (quantum == 4))\n          {\n            if (group == 0x0002)\n              datum=ReadBlobLSBSignedLong(image);\n            else\n              datum=ReadBlobSignedLong(image);\n          }\n        else\n          if ((quantum != 0) && (length != 0))\n            {\n              if (~length >= 1)\n                data=(unsigned char *) AcquireQuantumMemory(length+1,quantum*\n                  sizeof(*data));\n              if (data == (unsigned char *) NULL)\n                ThrowReaderException(ResourceLimitError,\n                  \"MemoryAllocationFailed\");\n              count=ReadBlob(image,(size_t) quantum*length,data);\n              if (count != (ssize_t) (quantum*length))\n                {\n                  if (image_info->verbose != MagickFalse)\n                    (void) FormatLocaleFile(stdout,\"count=%d quantum=%d \"\n                      \"length=%d group=%d\\n\",(int) count,(int) quantum,(int)\n                      length,(int) group);\n                   ThrowReaderException(CorruptImageError,\n                     \"InsufficientImageDataInFile\");\n                }\n              data[length*quantum]='\\0';\n            }\n          else\n            if ((unsigned int) datum == 0xFFFFFFFFU)\n              {\n                sequence=MagickTrue;\n                continue;\n              }\n\n    if ((unsigned int) ((group << 16) | element) == 0xFFFEE0DD)\n      {\n        if (data != (unsigned char *) NULL)\n          data=(unsigned char *) RelinquishMagickMemory(data);\n        sequence=MagickFalse;\n        continue;\n      }\n\n    if (sequence != MagickFalse)\n      {\n        if (data != (unsigned char *) NULL)\n          data=(unsigned char *) RelinquishMagickMemory(data);\n        continue;\n      }\n\n    switch (group)\n    {\n      case 0x0002:\n      {\n        switch (element)\n        {\n          case 0x0010:\n          {\n            char\n              transfer_syntax[MagickPathExtent];\n\n            /*\n              Transfer Syntax.\n            */\n            if ((datum == 0) && (explicit_retry == MagickFalse))\n              {\n                explicit_retry=MagickTrue;\n                (void) SeekBlob(image,(MagickOffsetType) 0,SEEK_SET);\n                group=0;\n                element=0;\n                if (image_info->verbose != MagickFalse)\n                  (void) FormatLocaleFile(stdout,\n                    \"Corrupted image - trying explicit format\\n\");\n                break;\n              }\n            *transfer_syntax='\\0';\n            if (data != (unsigned char *) NULL)\n              (void) CopyMagickString(transfer_syntax,(char *) data,\n                MagickPathExtent);\n            if (image_info->verbose != MagickFalse)\n              (void) FormatLocaleFile(stdout,\"transfer_syntax=%s\\n\",\n                (const char *) transfer_syntax);\n            if (strncmp(transfer_syntax,\"1.2.840.10008.1.2\",17) == 0)\n              {\n                int\n                  count,\n                  subtype,\n                  type;\n\n                type=1;\n                subtype=0;\n                if (strlen(transfer_syntax) > 17)\n                  {\n                    count=sscanf(transfer_syntax+17,\".%d.%d\",&type,&subtype);\n                    if (count < 1)\n                      ThrowReaderException(CorruptImageError,\n                        \"ImproperImageHeader\");\n                  }\n                switch (type)\n                {\n                  case 1:\n                  {\n                    image->endian=LSBEndian;\n                    break;\n                  }\n                  case 2:\n                  {\n                    image->endian=MSBEndian;\n                    break;\n                  }\n                  case 4:\n                  {\n                    if ((subtype >= 80) && (subtype <= 81))\n                      image->compression=JPEGCompression;\n                    else\n                      if ((subtype >= 90) && (subtype <= 93))\n                        image->compression=JPEG2000Compression;\n                      else\n                        image->compression=JPEGCompression;\n                    break;\n                  }\n                  case 5:\n                  {\n                    image->compression=RLECompression;\n                    break;\n                  }\n                }\n              }\n            break;\n          }\n          default:\n            break;\n        }\n        break;\n      }\n      case 0x0028:\n      {\n        switch (element)\n        {\n          case 0x0002:\n          {\n            /*\n              Samples per pixel.\n            */\n            samples_per_pixel=(size_t) datum;\n            break;\n          }\n          case 0x0004:\n          {\n            /*\n              Photometric interpretation.\n            */\n            if (data == (unsigned char *) NULL)\n              break;\n            for (i=0; i < (ssize_t) MagickMin(length,MagickPathExtent-1); i++)\n              photometric[i]=(char) data[i];\n            photometric[i]='\\0';\n            polarity=LocaleCompare(photometric,\"MONOCHROME1 \") == 0 ?\n              MagickTrue : MagickFalse;\n            break;\n          }\n          case 0x0006:\n          {\n            /*\n              Planar configuration.\n            */\n            if (datum == 1)\n              image->interlace=PlaneInterlace;\n            break;\n          }\n          case 0x0008:\n          {\n            /*\n              Number of frames.\n            */\n            if (data == (unsigned char *) NULL)\n              break;\n            number_scenes=StringToUnsignedLong((char *) data);\n            break;\n          }\n          case 0x0010:\n          {\n            /*\n              Image rows.\n            */\n            height=(size_t) datum;\n            break;\n          }\n          case 0x0011:\n          {\n            /*\n              Image columns.\n            */\n            width=(size_t) datum;\n            break;\n          }\n          case 0x0100:\n          {\n            /*\n              Bits allocated.\n            */\n            bits_allocated=(size_t) datum;\n            bytes_per_pixel=1;\n            if (datum > 8)\n              bytes_per_pixel=2;\n            depth=bits_allocated;\n            if (depth > 32)\n              ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n            max_value=(1UL << bits_allocated)-1;\n            break;\n          }\n          case 0x0101:\n          {\n            /*\n              Bits stored.\n            */\n            significant_bits=(size_t) datum;\n            bytes_per_pixel=1;\n            if (significant_bits > 8)\n              bytes_per_pixel=2;\n            depth=significant_bits;\n            if (depth > 32)\n              ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n            max_value=(1UL << significant_bits)-1;\n            mask=(size_t) GetQuantumRange(significant_bits);\n            break;\n          }\n          case 0x0102:\n          {\n            /*\n              High bit.\n            */\n            break;\n          }\n          case 0x0103:\n          {\n            /*\n              Pixel representation.\n            */\n            signed_data=(size_t) datum;\n            break;\n          }\n          case 0x1050:\n          {\n            /*\n              Visible pixel range: center.\n            */\n            if (data != (unsigned char *) NULL)\n              window_center=(ssize_t) StringToLong((char *) data);\n            break;\n          }\n          case 0x1051:\n          {\n            /*\n              Visible pixel range: width.\n            */\n            if (data != (unsigned char *) NULL)\n              window_width=StringToUnsignedLong((char *) data);\n            break;\n          }\n          case 0x1052:\n          {\n            /*\n              Rescale intercept\n            */\n            if (data != (unsigned char *) NULL)\n              rescale_intercept=(ssize_t) StringToLong((char *) data);\n            break;\n          }\n          case 0x1053:\n          {\n            /*\n              Rescale slope\n            */\n            if (data != (unsigned char *) NULL)\n              rescale_slope=(ssize_t) StringToLong((char *) data);\n            break;\n          }\n          case 0x1200:\n          case 0x3006:\n          {\n            /*\n              Populate graymap.\n            */\n            if (data == (unsigned char *) NULL)\n              break;\n            colors=(size_t) (length/bytes_per_pixel);\n            datum=(int) colors;\n            graymap=(int *) AcquireQuantumMemory((size_t) colors,\n              sizeof(*graymap));\n            if (graymap == (int *) NULL)\n              ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n            for (i=0; i < (ssize_t) colors; i++)\n              if (bytes_per_pixel == 1)\n                graymap[i]=(int) data[i];\n              else\n                graymap[i]=(int) ((short *) data)[i];\n            break;\n          }\n          case 0x1201:\n          {\n            unsigned short\n              index;\n\n            /*\n              Populate redmap.\n            */\n            if (data == (unsigned char *) NULL)\n              break;\n            colors=(size_t) (length/2);\n            datum=(int) colors;\n            redmap=(int *) AcquireQuantumMemory((size_t) colors,\n              sizeof(*redmap));\n            if (redmap == (int *) NULL)\n              ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n            p=data;\n            for (i=0; i < (ssize_t) colors; i++)\n            {\n              if (image->endian == MSBEndian)\n                index=(unsigned short) ((*p << 8) | *(p+1));\n              else\n                index=(unsigned short) (*p | (*(p+1) << 8));\n              redmap[i]=(int) index;\n              p+=2;\n            }\n            break;\n          }\n          case 0x1202:\n          {\n            unsigned short\n              index;\n\n            /*\n              Populate greenmap.\n            */\n            if (data == (unsigned char *) NULL)\n              break;\n            colors=(size_t) (length/2);\n            datum=(int) colors;\n            greenmap=(int *) AcquireQuantumMemory((size_t) colors,\n              sizeof(*greenmap));\n            if (greenmap == (int *) NULL)\n              ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n            p=data;\n            for (i=0; i < (ssize_t) colors; i++)\n            {\n              if (image->endian == MSBEndian)\n                index=(unsigned short) ((*p << 8) | *(p+1));\n              else\n                index=(unsigned short) (*p | (*(p+1) << 8));\n              greenmap[i]=(int) index;\n              p+=2;\n            }\n            break;\n          }\n          case 0x1203:\n          {\n            unsigned short\n              index;\n\n            /*\n              Populate bluemap.\n            */\n            if (data == (unsigned char *) NULL)\n              break;\n            colors=(size_t) (length/2);\n            datum=(int) colors;\n            bluemap=(int *) AcquireQuantumMemory((size_t) colors,\n              sizeof(*bluemap));\n            if (bluemap == (int *) NULL)\n              ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n            p=data;\n            for (i=0; i < (ssize_t) colors; i++)\n            {\n              if (image->endian == MSBEndian)\n                index=(unsigned short) ((*p << 8) | *(p+1));\n              else\n                index=(unsigned short) (*p | (*(p+1) << 8));\n              bluemap[i]=(int) index;\n              p+=2;\n            }\n            break;\n          }\n          default:\n            break;\n        }\n        break;\n      }\n      case 0x2050:\n      {\n        switch (element)\n        {\n          case 0x0020:\n          {\n            if ((data != (unsigned char *) NULL) &&\n                (strncmp((char *) data,\"INVERSE\",7) == 0))\n              polarity=MagickTrue;\n            break;\n          }\n          default:\n            break;\n        }\n        break;\n      }\n      default:\n        break;\n    }\n    if (data != (unsigned char *) NULL)\n      {\n        char\n          *attribute;\n\n        for (i=0; dicom_info[i].description != (char *) NULL; i++)\n          if ((group == dicom_info[i].group) &&\n              (element == dicom_info[i].element))\n            break;\n        if (dicom_info[i].description != (char *) NULL)\n          {\n            attribute=AcquireString(\"dcm:\");\n            (void) ConcatenateString(&attribute,dicom_info[i].description);\n            for (i=0; i < (ssize_t) MagickMax(length,4); i++)\n              if (isprint((int) data[i]) == MagickFalse)\n                break;\n            if ((i == (ssize_t) length) || (length > 4))\n              {\n                (void) SubstituteString(&attribute,\" \",\"\");\n                (void) SetImageProperty(image,attribute,(char *) data,exception);\n              }\n            attribute=DestroyString(attribute);\n          }\n      }\n    if (image_info->verbose != MagickFalse)\n      {\n        if (data == (unsigned char *) NULL)\n          (void) FormatLocaleFile(stdout,\"%d\\n\",datum);\n        else\n          {\n            /*\n              Display group data.\n            */\n            for (i=0; i < (ssize_t) MagickMax(length,4); i++)\n              if (isprint((int) data[i]) == MagickFalse)\n                break;\n            if ((i != (ssize_t) length) && (length <= 4))\n              {\n                ssize_t\n                  j;\n\n                datum=0;\n                for (j=(ssize_t) length-1; j >= 0; j--)\n                  datum=(256*datum+data[j]);\n                (void) FormatLocaleFile(stdout,\"%d\",datum);\n              }\n            else\n              for (i=0; i < (ssize_t) length; i++)\n                if (isprint((int) data[i]) != MagickFalse)\n                  (void) FormatLocaleFile(stdout,\"%c\",data[i]);\n                else\n                  (void) FormatLocaleFile(stdout,\"%c\",'.');\n            (void) FormatLocaleFile(stdout,\"\\n\");\n          }\n      }\n    if (data != (unsigned char *) NULL)\n      data=(unsigned char *) RelinquishMagickMemory(data);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n  }\n  if ((width == 0) || (height == 0))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  image->columns=(size_t) width;\n  image->rows=(size_t) height;\n  if (signed_data == 0xffff)\n    signed_data=(size_t) (significant_bits == 16 ? 1 : 0);\n  if ((image->compression == JPEGCompression) ||\n      (image->compression == JPEG2000Compression))\n    {\n      Image\n        *images;\n\n      ImageInfo\n        *read_info;\n\n      int\n        c;\n\n      size_t\n        length;\n\n      unsigned int\n        tag;\n\n      /*\n        Read offset table.\n      */\n      for (i=0; i < (ssize_t) stream_info->remaining; i++)\n        (void) ReadBlobByte(image);\n      tag=(ReadBlobLSBShort(image) << 16) | ReadBlobLSBShort(image);\n      (void) tag;\n      length=(size_t) ReadBlobLSBLong(image);\n      stream_info->offset_count=length >> 2;\n      if (stream_info->offset_count != 0)\n        {\n          MagickOffsetType\n            offset;\n\n          stream_info->offsets=(ssize_t *) AcquireQuantumMemory(\n            stream_info->offset_count,sizeof(*stream_info->offsets));\n          if (stream_info->offsets == (ssize_t *) NULL)\n            ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          for (i=0; i < (ssize_t) stream_info->offset_count; i++)\n            stream_info->offsets[i]=(ssize_t) ReadBlobLSBSignedLong(image);\n          offset=TellBlob(image);\n          for (i=0; i < (ssize_t) stream_info->offset_count; i++)\n            stream_info->offsets[i]+=offset;\n        }\n      /*\n        Handle non-native image formats.\n      */\n      read_info=CloneImageInfo(image_info);\n      SetImageInfoBlob(read_info,(void *) NULL,0);\n      images=NewImageList();\n      for (scene=0; scene < (ssize_t) number_scenes; scene++)\n      {\n        char\n          filename[MagickPathExtent];\n\n        const char\n          *property;\n\n        FILE\n          *file;\n\n        Image\n          *jpeg_image;\n\n        int\n          unique_file;\n\n        unsigned int\n          tag;\n\n        tag=(ReadBlobLSBShort(image) << 16) | ReadBlobLSBShort(image);\n        length=(size_t) ReadBlobLSBLong(image);\n        if (tag == 0xFFFEE0DD)\n          break; /* sequence delimiter tag */\n        if (tag != 0xFFFEE000)\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        file=(FILE *) NULL;\n        unique_file=AcquireUniqueFileResource(filename);\n        if (unique_file != -1)\n          file=fdopen(unique_file,\"wb\");\n        if (file == (FILE *) NULL)\n          {\n            (void) RelinquishUniqueFileResource(filename);\n            ThrowFileException(exception,FileOpenError,\n              \"UnableToCreateTemporaryFile\",filename);\n            break;\n          }\n        for ( ; length != 0; length--)\n        {\n          c=ReadBlobByte(image);\n          if (c == EOF)\n            {\n              ThrowFileException(exception,CorruptImageError,\n                \"UnexpectedEndOfFile\",image->filename);\n              break;\n            }\n          (void) fputc(c,file);\n        }\n        (void) fclose(file);\n        (void) FormatLocaleString(read_info->filename,MagickPathExtent,\n          \"jpeg:%s\",filename);\n        if (image->compression == JPEG2000Compression)\n          (void) FormatLocaleString(read_info->filename,MagickPathExtent,\n            \"j2k:%s\",filename);\n        jpeg_image=ReadImage(read_info,exception);\n        if (jpeg_image != (Image *) NULL)\n          {\n            ResetImagePropertyIterator(image);\n            property=GetNextImageProperty(image);\n            while (property != (const char *) NULL)\n            {\n              (void) SetImageProperty(jpeg_image,property,\n                GetImageProperty(image,property,exception),exception);\n              property=GetNextImageProperty(image);\n            }\n            AppendImageToList(&images,jpeg_image);\n          }\n        (void) RelinquishUniqueFileResource(filename);\n      }\n      read_info=DestroyImageInfo(read_info);\n      image=DestroyImage(image);\n      return(GetFirstImageInList(images));\n    }\n  if (depth != (1UL*MAGICKCORE_QUANTUM_DEPTH))\n    {\n      QuantumAny\n        range;\n\n      size_t\n        length;\n\n      /*\n        Compute pixel scaling table.\n      */\n      length=(size_t) (GetQuantumRange(depth)+1);\n      scale=(Quantum *) AcquireQuantumMemory(length,sizeof(*scale));\n      if (scale == (Quantum *) NULL)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      range=GetQuantumRange(depth);\n      for (i=0; i <= (ssize_t) GetQuantumRange(depth); i++)\n        scale[i]=ScaleAnyToQuantum((size_t) i,range);\n    }\n  if (image->compression == RLECompression)\n    {\n      size_t\n        length;\n\n      unsigned int\n        tag;\n\n      /*\n        Read RLE offset table.\n      */\n      for (i=0; i < (ssize_t) stream_info->remaining; i++)\n        (void) ReadBlobByte(image);\n      tag=(ReadBlobLSBShort(image) << 16) | ReadBlobLSBShort(image);\n      (void) tag;\n      length=(size_t) ReadBlobLSBLong(image);\n      stream_info->offset_count=length >> 2;\n      if (stream_info->offset_count != 0)\n        {\n          MagickOffsetType\n            offset;\n\n          stream_info->offsets=(ssize_t *) AcquireQuantumMemory(\n            stream_info->offset_count,sizeof(*stream_info->offsets));\n          if (stream_info->offsets == (ssize_t *) NULL)\n            ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          for (i=0; i < (ssize_t) stream_info->offset_count; i++)\n            stream_info->offsets[i]=(ssize_t) ReadBlobLSBSignedLong(image);\n          offset=TellBlob(image);\n          for (i=0; i < (ssize_t) stream_info->offset_count; i++)\n            stream_info->offsets[i]+=offset;\n        }\n    }\n  for (scene=0; scene < (ssize_t) number_scenes; scene++)\n  {\n    if (image_info->ping != MagickFalse)\n      break;\n    image->columns=(size_t) width;\n    image->rows=(size_t) height;\n    image->depth=depth;\n    status=SetImageExtent(image,image->columns,image->rows,exception);\n    if (status == MagickFalse)\n      break;\n    image->colorspace=RGBColorspace;\n    if ((image->colormap == (PixelInfo *) NULL) && (samples_per_pixel == 1))\n      {\n        size_t\n          one;\n\n        one=1;\n        if (colors == 0)\n          colors=one << depth;\n        if (AcquireImageColormap(image,one << depth,exception) == MagickFalse)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        if (redmap != (int *) NULL)\n          for (i=0; i < (ssize_t) colors; i++)\n          {\n            index=redmap[i];\n            if ((scale != (Quantum *) NULL) && (index <= (int) max_value))\n              index=(int) scale[index];\n            image->colormap[i].red=(MagickRealType) index;\n          }\n        if (greenmap != (int *) NULL)\n          for (i=0; i < (ssize_t) colors; i++)\n          {\n            index=greenmap[i];\n            if ((scale != (Quantum *) NULL) && (index <= (int) max_value))\n              index=(int) scale[index];\n            image->colormap[i].green=(MagickRealType) index;\n          }\n        if (bluemap != (int *) NULL)\n          for (i=0; i < (ssize_t) colors; i++)\n          {\n            index=bluemap[i];\n            if ((scale != (Quantum *) NULL) && (index <= (int) max_value))\n              index=(int) scale[index];\n            image->colormap[i].blue=(MagickRealType) index;\n          }\n        if (graymap != (int *) NULL)\n          for (i=0; i < (ssize_t) colors; i++)\n          {\n            index=graymap[i];\n            if ((scale != (Quantum *) NULL) && (index <= (int) max_value))\n              index=(int) scale[index];\n            image->colormap[i].red=(MagickRealType) index;\n            image->colormap[i].green=(MagickRealType) index;\n            image->colormap[i].blue=(MagickRealType) index;\n          }\n      }\n    if (image->compression == RLECompression)\n      {\n        unsigned int\n          tag;\n\n        /*\n          Read RLE segment table.\n        */\n        for (i=0; i < (ssize_t) stream_info->remaining; i++)\n          (void) ReadBlobByte(image);\n        tag=(ReadBlobLSBShort(image) << 16) | ReadBlobLSBShort(image);\n        stream_info->remaining=(size_t) ReadBlobLSBLong(image);\n        if ((tag != 0xFFFEE000) || (stream_info->remaining <= 64) ||\n            (EOFBlob(image) != MagickFalse))\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        stream_info->count=0;\n        stream_info->segment_count=ReadBlobLSBLong(image);\n        if (stream_info->segment_count > 1)\n          {\n            bytes_per_pixel=1;\n            depth=8;\n          }\n        for (i=0; i < 15; i++)\n          stream_info->segments[i]=(ssize_t) ReadBlobLSBSignedLong(image);\n        stream_info->remaining-=64;\n      }\n    if ((samples_per_pixel > 1) && (image->interlace == PlaneInterlace))\n      {\n        /*\n          Convert Planar RGB DCM Medical image to pixel packets.\n        */\n        for (i=0; i < (ssize_t) samples_per_pixel; i++)\n        {\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            q=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n            if (q == (Quantum *) NULL)\n              break;\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              switch ((int) i)\n              {\n                case 0:\n                {\n                  SetPixelRed(image,ScaleCharToQuantum((unsigned char)\n                    ReadDCMByte(stream_info,image)),q);\n                  break;\n                }\n                case 1:\n                {\n                  SetPixelGreen(image,ScaleCharToQuantum((unsigned char)\n                    ReadDCMByte(stream_info,image)),q);\n                  break;\n                }\n                case 2:\n                {\n                  SetPixelBlue(image,ScaleCharToQuantum((unsigned char)\n                    ReadDCMByte(stream_info,image)),q);\n                  break;\n                }\n                case 3:\n                {\n                  SetPixelAlpha(image,ScaleCharToQuantum((unsigned char)\n                    ReadDCMByte(stream_info,image)),q);\n                  break;\n                }\n                default:\n                  break;\n              }\n              q+=GetPixelChannels(image);\n            }\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n              break;\n            if (image->previous == (Image *) NULL)\n              {\n                status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                  image->rows);\n                if (status == MagickFalse)\n                  break;\n              }\n          }\n        }\n      }\n    else\n      {\n        const char\n          *option;\n\n        int\n          byte;\n\n        PixelPacket\n          pixel;\n\n        /*\n          Convert DCM Medical image to pixel packets.\n        */\n        byte=0;\n        i=0;\n        if ((window_center != 0) && (window_width == 0))\n          window_width=(size_t) window_center;\n        option=GetImageOption(image_info,\"dcm:display-range\");\n        if (option != (const char *) NULL)\n          {\n            if (LocaleCompare(option,\"reset\") == 0)\n              window_width=0;\n          }\n        (void) ResetMagickMemory(&pixel,0,sizeof(pixel));\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n          if (q == (Quantum *) NULL)\n            break;\n          for (x=0; x < (ssize_t) image->columns; x++)\n          {\n            if (samples_per_pixel == 1)\n              {\n                int\n                  pixel_value;\n\n                if (bytes_per_pixel == 1)\n                  pixel_value=polarity != MagickFalse ?\n                    ((int) max_value-ReadDCMByte(stream_info,image)) :\n                    ReadDCMByte(stream_info,image);\n                else\n                  if ((bits_allocated != 12) || (significant_bits != 12))\n                    {\n                      if (signed_data)\n                        pixel_value=ReadDCMSignedShort(stream_info,image);\n                      else\n                        pixel_value=ReadDCMShort(stream_info,image);\n                      if (polarity != MagickFalse)\n                        pixel_value=(int)max_value-pixel_value;\n                    }\n                  else\n                    {\n                      if ((i & 0x01) != 0)\n                        pixel_value=(ReadDCMByte(stream_info,image) << 8) |\n                          byte;\n                      else\n                        {\n                          pixel_value=ReadDCMSignedShort(stream_info,image);\n                          byte=(int) (pixel_value & 0x0f);\n                          pixel_value>>=4;\n                        }\n                      i++;\n                    }\n                index=(pixel_value*rescale_slope)+rescale_intercept;\n                if (window_width == 0)\n                  {\n                    if (signed_data == 1)\n                      index-=32767;\n                  }\n                else\n                  {\n                    ssize_t\n                      window_max,\n                      window_min;\n\n                    window_min=(ssize_t) ceil((double) window_center-\n                      (window_width-1.0)/2.0-0.5);\n                    window_max=(ssize_t) floor((double) window_center+\n                      (window_width-1.0)/2.0+0.5);\n                    if ((ssize_t)index <= window_min)\n                      index=0;\n                    else\n                      if ((ssize_t)index > window_max)\n                        index=(int) max_value;\n                      else\n                        index=(int) (max_value*(((index-window_center-\n                          0.5)/(window_width-1))+0.5));\n                  }\n                index&=mask;\n                index=(int) ConstrainColormapIndex(image,(size_t) index,\n                  exception);\n                SetPixelIndex(image,(Quantum) index,q);\n                pixel.red=(unsigned int) image->colormap[index].red;\n                pixel.green=(unsigned int) image->colormap[index].green;\n                pixel.blue=(unsigned int) image->colormap[index].blue;\n              }\n            else\n              {\n                if (bytes_per_pixel == 1)\n                  {\n                    pixel.red=(unsigned int) ReadDCMByte(stream_info,image);\n                    pixel.green=(unsigned int) ReadDCMByte(stream_info,image);\n                    pixel.blue=(unsigned int) ReadDCMByte(stream_info,image);\n                  }\n                else\n                  {\n                    pixel.red=ReadDCMShort(stream_info,image);\n                    pixel.green=ReadDCMShort(stream_info,image);\n                    pixel.blue=ReadDCMShort(stream_info,image);\n                  }\n                pixel.red&=mask;\n                pixel.green&=mask;\n                pixel.blue&=mask;\n                if (scale != (Quantum *) NULL)\n                  {\n                    if (pixel.red <= GetQuantumRange(depth))\n                      pixel.red=scale[pixel.red];\n                    if (pixel.green <= GetQuantumRange(depth))\n                      pixel.green=scale[pixel.green];\n                    if (pixel.blue <= GetQuantumRange(depth))\n                      pixel.blue=scale[pixel.blue];\n                  }\n              }\n            SetPixelRed(image,(Quantum) pixel.red,q);\n            SetPixelGreen(image,(Quantum) pixel.green,q);\n            SetPixelBlue(image,(Quantum) pixel.blue,q);\n            q+=GetPixelChannels(image);\n          }\n          if (SyncAuthenticPixels(image,exception) == MagickFalse)\n            break;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n        if (stream_info->segment_count > 1)\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n            if (q == (Quantum *) NULL)\n              break;\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              if (samples_per_pixel == 1)\n                {\n                  int\n                    pixel_value;\n\n                  if (bytes_per_pixel == 1)\n                    pixel_value=polarity != MagickFalse ?\n                      ((int) max_value-ReadDCMByte(stream_info,image)) :\n                      ReadDCMByte(stream_info,image);\n                  else\n                    if ((bits_allocated != 12) || (significant_bits != 12))\n                      {\n                        pixel_value=(int) (polarity != MagickFalse ?\n                          (max_value-ReadDCMShort(stream_info,image)) :\n                          ReadDCMShort(stream_info,image));\n                        if (signed_data == 1)\n                          pixel_value=((signed short) pixel_value);\n                      }\n                    else\n                      {\n                        if ((i & 0x01) != 0)\n                          pixel_value=(ReadDCMByte(stream_info,image) << 8) |\n                            byte;\n                        else\n                          {\n                            pixel_value=ReadDCMShort(stream_info,image);\n                            byte=(int) (pixel_value & 0x0f);\n                            pixel_value>>=4;\n                          }\n                        i++;\n                      }\n                  index=(pixel_value*rescale_slope)+rescale_intercept;\n                  if (window_width == 0)\n                    {\n                      if (signed_data == 1)\n                        index-=32767;\n                    }\n                  else\n                    {\n                      ssize_t\n                        window_max,\n                        window_min;\n\n                      window_min=(ssize_t) ceil((double) window_center-\n                        (window_width-1.0)/2.0-0.5);\n                      window_max=(ssize_t) floor((double) window_center+\n                        (window_width-1.0)/2.0+0.5);\n                      if ((ssize_t)index <= window_min)\n                        index=0;\n                      else\n                        if ((ssize_t)index > window_max)\n                          index=(int) max_value;\n                        else\n                          index=(int) (max_value*(((index-window_center-\n                            0.5)/(window_width-1))+0.5));\n                    }\n                  index&=mask;\n                  index=(int) ConstrainColormapIndex(image,(size_t) index,\n                    exception);\n                  SetPixelIndex(image,(Quantum) (((size_t)\n                    GetPixelIndex(image,q)) | (((size_t) index) << 8)),q);\n                  pixel.red=(unsigned int) image->colormap[index].red;\n                  pixel.green=(unsigned int) image->colormap[index].green;\n                  pixel.blue=(unsigned int) image->colormap[index].blue;\n                }\n              else\n                {\n                  if (bytes_per_pixel == 1)\n                    {\n                      pixel.red=(unsigned int) ReadDCMByte(stream_info,image);\n                      pixel.green=(unsigned int) ReadDCMByte(stream_info,image);\n                      pixel.blue=(unsigned int) ReadDCMByte(stream_info,image);\n                    }\n                  else\n                    {\n                      pixel.red=ReadDCMShort(stream_info,image);\n                      pixel.green=ReadDCMShort(stream_info,image);\n                      pixel.blue=ReadDCMShort(stream_info,image);\n                    }\n                  pixel.red&=mask;\n                  pixel.green&=mask;\n                  pixel.blue&=mask;\n                  if (scale != (Quantum *) NULL)\n                    {\n                      pixel.red=scale[pixel.red];\n                      pixel.green=scale[pixel.green];\n                      pixel.blue=scale[pixel.blue];\n                    }\n                }\n              SetPixelRed(image,(Quantum) (((size_t) GetPixelRed(image,q)) |\n                (((size_t) pixel.red) << 8)),q);\n              SetPixelGreen(image,(Quantum) (((size_t) GetPixelGreen(image,q)) |\n                (((size_t) pixel.green) << 8)),q);\n              SetPixelBlue(image,(Quantum) (((size_t) GetPixelBlue(image,q)) |\n                (((size_t) pixel.blue) << 8)),q);\n              q+=GetPixelChannels(image);\n            }\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n              break;\n            if (image->previous == (Image *) NULL)\n              {\n                status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                  image->rows);\n                if (status == MagickFalse)\n                  break;\n              }\n          }\n      }\n    if (SetImageGray(image,exception) != MagickFalse)\n      (void) SetImageColorspace(image,GRAYColorspace,exception);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    /*\n      Proceed to next image.\n    */\n    if (image_info->number_scenes != 0)\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    if (scene < (ssize_t) (number_scenes-1))\n      {\n        /*\n          Allocate next image structure.\n        */\n        AcquireNextImage(image_info,image,exception);\n        if (GetNextImageInList(image) == (Image *) NULL)\n          {\n            image=DestroyImageList(image);\n            return((Image *) NULL);\n          }\n        image=SyncNextImageInList(image);\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n        if (status == MagickFalse)\n          break;\n      }\n  }\n  /*\n    Free resources.\n  */\n  if (stream_info->offsets != (ssize_t *) NULL)\n    stream_info->offsets=(ssize_t *)\n      RelinquishMagickMemory(stream_info->offsets);\n  stream_info=(DCMStreamInfo *) RelinquishMagickMemory(stream_info);\n  if (scale != (Quantum *) NULL)\n    scale=(Quantum *) RelinquishMagickMemory(scale);\n  if (graymap != (int *) NULL)\n    graymap=(int *) RelinquishMagickMemory(graymap);\n  if (bluemap != (int *) NULL)\n    bluemap=(int *) RelinquishMagickMemory(bluemap);\n  if (greenmap != (int *) NULL)\n    greenmap=(int *) RelinquishMagickMemory(greenmap);\n  if (redmap != (int *) NULL)\n    redmap=(int *) RelinquishMagickMemory(redmap);\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/5511ef530576ed18fd636baa3bb4eda3d667665d", "file_name": "coders/dcm.c", "vul_type": "cwe-476", "description": "Write a function in C to read and process DICOM medical images."}
{"func_name": "Html5ReportGenerator::unzipApp", "func_src_before": "    protected void unzipApp( File toDir ) throws IOException {\n        String appZipPath = \"/\" + Html5ReportGenerator.class.getPackage().getName().replace( '.', '/' ) + \"/app.zip\";\n\n        log.debug( \"Unzipping {}...\", appZipPath );\n\n        InputStream inputStream = this.getClass().getResourceAsStream( appZipPath );\n        ZipInputStream zipInputStream = new ZipInputStream( inputStream );\n\n        ZipEntry entry;\n        while( ( entry = zipInputStream.getNextEntry() ) != null ) {\n            File file = new File( toDir, entry.getName() );\n\n            if( entry.isDirectory() ) {\n                if( !file.exists() ) {\n                    log.debug( \"Creating directory {}...\", file );\n                    if( !file.mkdirs() ) {\n                        throw new IOException( \"Could not create directory \" + file );\n                    }\n                }\n                continue;\n            }\n            log.debug( \"Unzipping {}...\", file );\n\n            FileOutputStream fileOutputStream = new FileOutputStream( file );\n\n            byte[] buffer = new byte[1024];\n\n            int len;\n            while( ( len = zipInputStream.read( buffer ) ) > 0 ) {\n                fileOutputStream.write( buffer, 0, len );\n            }\n\n            fileOutputStream.close();\n        }\n    }", "func_src_after": "    protected void unzipApp( File toDir ) throws IOException {\n        String appZipPath = \"/\" + Html5ReportGenerator.class.getPackage().getName().replace( '.', '/' ) + \"/app.zip\";\n\n        log.debug( \"Unzipping {}...\", appZipPath );\n\n        InputStream inputStream = this.getClass().getResourceAsStream( appZipPath );\n        ZipInputStream zipInputStream = new ZipInputStream( inputStream );\n\n        ZipEntry entry;\n        while( ( entry = zipInputStream.getNextEntry() ) != null ) {\n            File file = new File( toDir, entry.getName() );\n            if(!file.toPath().normalize().startsWith(toDir.toPath().normalize())) {\n                throw new RuntimeException(\"Bad zip entry\");\n            }\n\n            if( entry.isDirectory() ) {\n                if( !file.exists() ) {\n                    log.debug( \"Creating directory {}...\", file );\n                    if( !file.mkdirs() ) {\n                        throw new IOException( \"Could not create directory \" + file );\n                    }\n                }\n                continue;\n            }\n            log.debug( \"Unzipping {}...\", file );\n\n            FileOutputStream fileOutputStream = new FileOutputStream( file );\n\n            byte[] buffer = new byte[1024];\n\n            int len;\n            while( ( len = zipInputStream.read( buffer ) ) > 0 ) {\n                fileOutputStream.write( buffer, 0, len );\n            }\n\n            fileOutputStream.close();\n        }\n    }", "line_changes": {"deleted": [], "added": [{"line_no": 12, "char_start": 549, "char_end": 633, "line": "            if(!file.toPath().normalize().startsWith(toDir.toPath().normalize())) {\n"}, {"line_no": 13, "char_start": 633, "char_end": 694, "line": "                throw new RuntimeException(\"Bad zip entry\");\n"}, {"line_no": 14, "char_start": 694, "char_end": 708, "line": "            }\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 548, "char_end": 707, "chars": "\n            if(!file.toPath().normalize().startsWith(toDir.toPath().normalize())) {\n                throw new RuntimeException(\"Bad zip entry\");\n            }"}]}, "commit_link": "github.com/TNG/JGiven/commit/e701fe690501e7301f7c923adc1881d308806c46", "file_name": "Html5ReportGenerator.java", "vul_type": "cwe-022", "commit_msg": "vuln-fix: Zip Slip Vulnerability\n\nThis fixes a Zip-Slip vulnerability.\n\nThis change does one of two things. This change either\n\n1. Inserts a guard to protect against Zip Slip.\nOR\n2. Replaces `dir.getCanonicalPath().startsWith(parent.getCanonicalPath())`, which is vulnerable to partial path traversal attacks, with the more secure `dir.getCanonicalFile().toPath().startsWith(parent.getCanonicalFile().toPath())`.\n\nFor number 2, consider `\"/usr/outnot\".startsWith(\"/usr/out\")`.\nThe check is bypassed although `/outnot` is not under the `/out` directory.\nIt's important to understand that the terminating slash may be removed when using various `String` representations of the `File` object.\nFor example, on Linux, `println(new File(\"/var\"))` will print `/var`, but `println(new File(\"/var\", \"/\")` will print `/var/`;\nhowever, `println(new File(\"/var\", \"/\").getCanonicalPath())` will print `/var`.\n\nWeakness: CWE-22: Improper Limitation of a Pathname to a Restricted Directory ('Path Traversal')\nSeverity: High\nCVSSS: 7.4\nDetection: CodeQL (https://codeql.github.com/codeql-query-help/java/java-zipslip/) & OpenRewrite (https://public.moderne.io/recipes/org.openrewrite.java.security.ZipSlip)\n\nReported-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\nSigned-off-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\n\nBug-tracker: https://github.com/JLLeitschuh/security-research/issues/16\n\nCo-authored-by: Moderne <team@moderne.io>", "description": "Write a Java function to unzip a file named 'app.zip' from the resources of the `Html5ReportGenerator` class into a specified directory."}
{"func_name": "security_fips_decrypt", "func_src_before": "BOOL security_fips_decrypt(BYTE* data, size_t length, rdpRdp* rdp)\n{\n\tsize_t olen;\n\n\tif (!winpr_Cipher_Update(rdp->fips_decrypt, data, length, data, &olen))\n\t\treturn FALSE;\n\n\treturn TRUE;\n}", "func_src_after": "BOOL security_fips_decrypt(BYTE* data, size_t length, rdpRdp* rdp)\n{\n\tsize_t olen;\n\n\tif (!rdp || !rdp->fips_decrypt)\n\t\treturn FALSE;\n\n\tif (!winpr_Cipher_Update(rdp->fips_decrypt, data, length, data, &olen))\n\t\treturn FALSE;\n\n\treturn TRUE;\n}", "commit_link": "github.com/FreeRDP/FreeRDP/commit/d6cd14059b257318f176c0ba3ee0a348826a9ef8", "file_name": "libfreerdp/core/security.c", "vul_type": "cwe-125", "description": "Write a C function named `security_fips_decrypt` that decrypts data using FIPS-compliant decryption, returning a boolean status."}
{"func_name": "(anonymous)", "func_src_before": "describe('Config', function() {\n    it('should be defined', function () {\n        should.exist(Config);\n    });\n    \n    it('setOptions should overwrite options', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.trimLines = true;\n        config.setOptions({lineEnding: \"\\r\\n\", trimLines: undefined});\n        expect(config.options.lineEnding).to.equal(\"\\r\\n\");\n        expect(config.options.trimLines).to.equal(true);\n    });\n    \n    it('detectLineEndings should detect windows style (\\\\r\\\\n)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\r\\nline2\\r\\n\").should.equal(\"\\r\\n\");\n    });\n    \n    it('detectLineEndings should detect unix style (\\\\n)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\nline2\\n\").should.equal(\"\\n\");\n    });\n    \n    it('detectLineEndings should detect mac style (\\\\r)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\rline2\\r\").should.equal(\"\\r\");\n    });\n    \n    it('detectLineEndings should detect wtf style (\\\\n\\\\r)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\n\\rline2\\n\\r\").should.equal(\"\\n\\r\");\n    });\n    \n    it('decode should return a object', function () {\n        var config = new Config();\n        for(var i = 0; i < testData.length; i++){\n            config.decode(testData[i]).should.be.a('object');\n        }\n    });\n    \n    it('encode return should a string', function () {\n        var config = new Config();\n        config.encode({'Section':{'a': 1}}).should.be.a('string');\n        config.encode({'a':1}).should.be.a('string');\n        config.encode({}).should.be.a('string');\n    });\n    \n    it('decode should handle attributes without section', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        var result = config.decode(\"stray=foo\\n[Section1]\\na=b\\n\");\n        expect(result.stray).to.equal(\"foo\");\n    });\n    \n    it('encode should handle attributes without section', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        var encoded = config.encode({stray:'foo','SectionA':{'a': 1}});\n        var decoded = config.decode(encoded);\n        expect(decoded.stray).to.equal(\"foo\");\n    });\n    \n    it('decode should return object with same attributes', function () {\n        var data = \";comment\\n[SectionA]\\nkey=value\\n\";\n        var config = new Config();\n        config.options.lineEnding = config.detectLineEnding(data);\n        var result = config.decode(data);\n        result.should.be.a('object');\n        should.exist(result.SectionA);\n        result.SectionA.key.should.equal(\"value\");\n    });\n    \n    it('decode>encode>decode>encode return should produce consistent results', function () {\n        for(var i = 0; i < testData.length; i++){\n            var data = testData[i];\n            var config = new Config();\n            config.options.lineEnding = config.detectLineEnding(data);\n            var decoded1 = config.decode(data);\n            var encoded1 = config.encode(decoded1);\n            var decoded2 = config.decode(encoded1);\n            var encoded2 = config.encode(decoded2);\n            expect(encoded1).to.equal(encoded2);\n            expect(decoded1).to.deep.equal(decoded2);\n        }\n    });\n    \n    it('decode should be able to handle multiple comment identifier', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.commentIdentifiers = [';','//','#'];\n        var result = config.decode(\";comment1\\n//comment2\\n#comment3\\n\");\n        expect(result).to.deep.equal({});\n    });\n    \n    it('decode should be able to handle custom assign identifier', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.assignIdentifier = \":\";\n        var result = config.decode(\"[Section]\\nfoo:bar\\n\");\n        should.exist(result.Section);\n        expect(result.Section.foo).to.equal(\"bar\");\n    });\n\n    it('valueTrim should trim custom chars', function () {\n        var config = new Config();\n        expect(config.valueTrim('\"Te\"s\"t\"', '\"')).to.equal('Te\"s\"t');\n        expect(config.valueTrim('\"Te\"s\"t\"', '')).to.equal('\"Te\"s\"t\"');\n        expect(config.valueTrim('\"Te\"s\"t\"', '#')).to.equal('\"Te\"s\"t\"');\n        expect(config.valueTrim('\"\"Te\"s\"t\"\"', '\"\"')).to.equal('\"Te\"s\"t\"');\n        expect(config.valueTrim('[Te\"s\"t]', '[]')).to.equal('Te\"s\"t');\n    })\n\n    it('valueIdentifiers should trimed or added', function () {\n        var data = \"[SectionA]\\nkey1='val1'\\nkey2='val2'\\n\";\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.valueIdentifier = \"'\"\n        var result = config.decode(data);\n        expect(result.SectionA.key1).to.equal(\"val1\");\n        expect(result.SectionA.key2).to.equal(\"val2\");\n        var data2 = config.encode(result);\n        expect(data2).to.equal(data);\n    })\n\n    it('ignoreMultipleAssignIdentifier should ignore multiple assing identifiers', function () {\n        var data = \"a\\t1\\nb\\t\\t2\\nc\\t3\\t\\n\";\n        var config = new Config();\n        config.options.assignIdentifier = '\\t'\n        config.options.lineEnding = \"\\n\";\n        config.options.ignoreMultipleAssignIdentifier = true;\n        config.options.trimLines = false;\n        var result = config.decode(data);\n        expect(result.a).to.equal(\"1\");\n        expect(result.b).to.equal(\"2\");\n        expect(result.c).to.equal(\"3\\t\");\n    })\n});", "func_src_after": "describe('Config', function() {\n    it('should be defined', function () {\n        should.exist(Config);\n    });\n    \n    it('setOptions should overwrite options', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.trimLines = true;\n        config.setOptions({lineEnding: \"\\r\\n\", trimLines: undefined});\n        expect(config.options.lineEnding).to.equal(\"\\r\\n\");\n        expect(config.options.trimLines).to.equal(true);\n    });\n    \n    it('detectLineEndings should detect windows style (\\\\r\\\\n)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\r\\nline2\\r\\n\").should.equal(\"\\r\\n\");\n    });\n    \n    it('detectLineEndings should detect unix style (\\\\n)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\nline2\\n\").should.equal(\"\\n\");\n    });\n    \n    it('detectLineEndings should detect mac style (\\\\r)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\rline2\\r\").should.equal(\"\\r\");\n    });\n    \n    it('detectLineEndings should detect wtf style (\\\\n\\\\r)', function () {\n        var config = new Config();\n        config.detectLineEnding(\"line1\\n\\rline2\\n\\r\").should.equal(\"\\n\\r\");\n    });\n    \n    it('decode should return a object', function () {\n        var config = new Config();\n        for(var i = 0; i < testData.length; i++){\n            config.decode(testData[i]).should.be.a('object');\n        }\n    });\n    \n    it('encode return should a string', function () {\n        var config = new Config();\n        config.encode({'Section':{'a': 1}}).should.be.a('string');\n        config.encode({'a':1}).should.be.a('string');\n        config.encode({}).should.be.a('string');\n    });\n    \n    it('decode should handle attributes without section', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        var result = config.decode(\"stray=foo\\n[Section1]\\na=b\\n\");\n        expect(result.stray).to.equal(\"foo\");\n    });\n    \n    it('encode should handle attributes without section', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        var encoded = config.encode({stray:'foo','SectionA':{'a': 1}});\n        var decoded = config.decode(encoded);\n        expect(decoded.stray).to.equal(\"foo\");\n    });\n    \n    it('decode should return object with same attributes', function () {\n        var data = \";comment\\n[SectionA]\\nkey=value\\n\";\n        var config = new Config();\n        config.options.lineEnding = config.detectLineEnding(data);\n        var result = config.decode(data);\n        result.should.be.a('object');\n        should.exist(result.SectionA);\n        result.SectionA.key.should.equal(\"value\");\n    });\n    \n    it('decode>encode>decode>encode return should produce consistent results', function () {\n        for(var i = 0; i < testData.length; i++){\n            var data = testData[i];\n            var config = new Config();\n            config.options.lineEnding = config.detectLineEnding(data);\n            var decoded1 = config.decode(data);\n            var encoded1 = config.encode(decoded1);\n            var decoded2 = config.decode(encoded1);\n            var encoded2 = config.encode(decoded2);\n            expect(encoded1).to.equal(encoded2);\n            expect(decoded1).to.deep.equal(decoded2);\n        }\n    });\n    \n    it('decode should be able to handle multiple comment identifier', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.commentIdentifiers = [';','//','#'];\n        var result = config.decode(\";comment1\\n//comment2\\n#comment3\\n\");\n        expect(result).to.deep.equal({});\n    });\n    \n    it('decode should be able to handle custom assign identifier', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.assignIdentifier = \":\";\n        var result = config.decode(\"[Section]\\nfoo:bar\\n\");\n        should.exist(result.Section);\n        expect(result.Section.foo).to.equal(\"bar\");\n    });\n\n    it('decode should prevent prototype pollution attacks', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.assignIdentifier = \":\";\n        var result = config.decode(\"[__proto__]\\nfoo:bar\\n\");\n        should.not.exist(result.__proto__.foo);\n        result = config.decode(\"[Section]\\n__proto__:bar\\n\");\n        expect(result.Section.__proto__).to.not.equal(\"bar\");\n    });\n\n    it('valueTrim should trim custom chars', function () {\n        var config = new Config();\n        expect(config.valueTrim('\"Te\"s\"t\"', '\"')).to.equal('Te\"s\"t');\n        expect(config.valueTrim('\"Te\"s\"t\"', '')).to.equal('\"Te\"s\"t\"');\n        expect(config.valueTrim('\"Te\"s\"t\"', '#')).to.equal('\"Te\"s\"t\"');\n        expect(config.valueTrim('\"\"Te\"s\"t\"\"', '\"\"')).to.equal('\"Te\"s\"t\"');\n        expect(config.valueTrim('[Te\"s\"t]', '[]')).to.equal('Te\"s\"t');\n    })\n\n    it('valueIdentifiers should trimed or added', function () {\n        var data = \"[SectionA]\\nkey1='val1'\\nkey2='val2'\\n\";\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.valueIdentifier = \"'\"\n        var result = config.decode(data);\n        expect(result.SectionA.key1).to.equal(\"val1\");\n        expect(result.SectionA.key2).to.equal(\"val2\");\n        var data2 = config.encode(result);\n        expect(data2).to.equal(data);\n    })\n\n    it('ignoreMultipleAssignIdentifier should ignore multiple assing identifiers', function () {\n        var data = \"a\\t1\\nb\\t\\t2\\nc\\t3\\t\\n\";\n        var config = new Config();\n        config.options.assignIdentifier = '\\t'\n        config.options.lineEnding = \"\\n\";\n        config.options.ignoreMultipleAssignIdentifier = true;\n        config.options.trimLines = false;\n        var result = config.decode(data);\n        expect(result.a).to.equal(\"1\");\n        expect(result.b).to.equal(\"2\");\n        expect(result.c).to.equal(\"3\\t\");\n    })\n});", "line_changes": {"deleted": [], "added": [{"line_no": 114, "char_start": 4565, "char_end": 4566, "line": "\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 4125, "char_end": 4566, "chars": "    it('decode should prevent prototype pollution attacks', function () {\n        var config = new Config();\n        config.options.lineEnding = \"\\n\";\n        config.options.assignIdentifier = \":\";\n        var result = config.decode(\"[__proto__]\\nfoo:bar\\n\");\n        should.not.exist(result.__proto__.foo);\n        result = config.decode(\"[Section]\\n__proto__:bar\\n\");\n        expect(result.Section.__proto__).to.not.equal(\"bar\");\n    });\n\n"}]}, "commit_link": "github.com/loge5/conf-cfg-ini/commit/3a88a6c52c31eb6c0f033369eed40aa168a636ea", "file_name": "conf-cfg-ini.spec.js", "vul_type": "cwe-915", "commit_msg": "fix: prevent prototype pollution attack", "parent_commit": "abbaf8b61ba5040e04aaa55722c412e19a1bcab4", "description": "Write JavaScript tests for a configuration parser using Mocha and Chai."}
{"func_name": "Perl_re_op_compile", "func_src_before": "REGEXP *\nPerl_re_op_compile(pTHX_ SV ** const patternp, int pat_count,\n\t\t    OP *expr, const regexp_engine* eng, REGEXP *old_re,\n\t\t     bool *is_bare_re, const U32 orig_rx_flags, const U32 pm_flags)\n{\n    dVAR;\n    REGEXP *Rx;         /* Capital 'R' means points to a REGEXP */\n    STRLEN plen;\n    char *exp;\n    regnode *scan;\n    I32 flags;\n    SSize_t minlen = 0;\n    U32 rx_flags;\n    SV *pat;\n    SV** new_patternp = patternp;\n\n    /* these are all flags - maybe they should be turned\n     * into a single int with different bit masks */\n    I32 sawlookahead = 0;\n    I32 sawplus = 0;\n    I32 sawopen = 0;\n    I32 sawminmod = 0;\n\n    regex_charset initial_charset = get_regex_charset(orig_rx_flags);\n    bool recompile = 0;\n    bool runtime_code = 0;\n    scan_data_t data;\n    RExC_state_t RExC_state;\n    RExC_state_t * const pRExC_state = &RExC_state;\n#ifdef TRIE_STUDY_OPT\n    int restudied = 0;\n    RExC_state_t copyRExC_state;\n#endif\n    GET_RE_DEBUG_FLAGS_DECL;\n\n    PERL_ARGS_ASSERT_RE_OP_COMPILE;\n\n    DEBUG_r(if (!PL_colorset) reginitcolors());\n\n    /* Initialize these here instead of as-needed, as is quick and avoids\n     * having to test them each time otherwise */\n    if (! PL_InBitmap) {\n#ifdef DEBUGGING\n        char * dump_len_string;\n#endif\n\n        /* This is calculated here, because the Perl program that generates the\n         * static global ones doesn't currently have access to\n         * NUM_ANYOF_CODE_POINTS */\n\tPL_InBitmap = _new_invlist(2);\n\tPL_InBitmap = _add_range_to_invlist(PL_InBitmap, 0,\n                                                    NUM_ANYOF_CODE_POINTS - 1);\n#ifdef DEBUGGING\n        dump_len_string = PerlEnv_getenv(\"PERL_DUMP_RE_MAX_LEN\");\n        if (   ! dump_len_string\n            || ! grok_atoUV(dump_len_string, (UV *)&PL_dump_re_max_len, NULL))\n        {\n            PL_dump_re_max_len = 60;    /* A reasonable default */\n        }\n#endif\n    }\n\n    pRExC_state->warn_text = NULL;\n    pRExC_state->unlexed_names = NULL;\n    pRExC_state->code_blocks = NULL;\n\n    if (is_bare_re)\n\t*is_bare_re = FALSE;\n\n    if (expr && (expr->op_type == OP_LIST ||\n\t\t(expr->op_type == OP_NULL && expr->op_targ == OP_LIST))) {\n\t/* allocate code_blocks if needed */\n\tOP *o;\n\tint ncode = 0;\n\n\tfor (o = cLISTOPx(expr)->op_first; o; o = OpSIBLING(o))\n\t    if (o->op_type == OP_NULL && (o->op_flags & OPf_SPECIAL))\n\t\tncode++; /* count of DO blocks */\n\n\tif (ncode)\n            pRExC_state->code_blocks = S_alloc_code_blocks(aTHX_ ncode);\n    }\n\n    if (!pat_count) {\n        /* compile-time pattern with just OP_CONSTs and DO blocks */\n\n        int n;\n        OP *o;\n\n        /* find how many CONSTs there are */\n        assert(expr);\n        n = 0;\n        if (expr->op_type == OP_CONST)\n            n = 1;\n        else\n            for (o = cLISTOPx(expr)->op_first; o; o = OpSIBLING(o)) {\n                if (o->op_type == OP_CONST)\n                    n++;\n            }\n\n        /* fake up an SV array */\n\n        assert(!new_patternp);\n        Newx(new_patternp, n, SV*);\n        SAVEFREEPV(new_patternp);\n        pat_count = n;\n\n        n = 0;\n        if (expr->op_type == OP_CONST)\n            new_patternp[n] = cSVOPx_sv(expr);\n        else\n            for (o = cLISTOPx(expr)->op_first; o; o = OpSIBLING(o)) {\n                if (o->op_type == OP_CONST)\n                    new_patternp[n++] = cSVOPo_sv;\n            }\n\n    }\n\n    DEBUG_PARSE_r(Perl_re_printf( aTHX_\n        \"Assembling pattern from %d elements%s\\n\", pat_count,\n            orig_rx_flags & RXf_SPLIT ? \" for split\" : \"\"));\n\n    /* set expr to the first arg op */\n\n    if (pRExC_state->code_blocks && pRExC_state->code_blocks->count\n         && expr->op_type != OP_CONST)\n    {\n            expr = cLISTOPx(expr)->op_first;\n            assert(   expr->op_type == OP_PUSHMARK\n                   || (expr->op_type == OP_NULL && expr->op_targ == OP_PUSHMARK)\n                   || expr->op_type == OP_PADRANGE);\n            expr = OpSIBLING(expr);\n    }\n\n    pat = S_concat_pat(aTHX_ pRExC_state, NULL, new_patternp, pat_count,\n                        expr, &recompile, NULL);\n\n    /* handle bare (possibly after overloading) regex: foo =~ $re */\n    {\n        SV *re = pat;\n        if (SvROK(re))\n            re = SvRV(re);\n        if (SvTYPE(re) == SVt_REGEXP) {\n            if (is_bare_re)\n                *is_bare_re = TRUE;\n            SvREFCNT_inc(re);\n            DEBUG_PARSE_r(Perl_re_printf( aTHX_\n                \"Precompiled pattern%s\\n\",\n                    orig_rx_flags & RXf_SPLIT ? \" for split\" : \"\"));\n\n            return (REGEXP*)re;\n        }\n    }\n\n    exp = SvPV_nomg(pat, plen);\n\n    if (!eng->op_comp) {\n\tif ((SvUTF8(pat) && IN_BYTES)\n\t\t|| SvGMAGICAL(pat) || SvAMAGIC(pat))\n\t{\n\t    /* make a temporary copy; either to convert to bytes,\n\t     * or to avoid repeating get-magic / overloaded stringify */\n\t    pat = newSVpvn_flags(exp, plen, SVs_TEMP |\n\t\t\t\t\t(IN_BYTES ? 0 : SvUTF8(pat)));\n\t}\n\treturn CALLREGCOMP_ENG(eng, pat, orig_rx_flags);\n    }\n\n    /* ignore the utf8ness if the pattern is 0 length */\n    RExC_utf8 = RExC_orig_utf8 = (plen == 0 || IN_BYTES) ? 0 : SvUTF8(pat);\n    RExC_uni_semantics = 0;\n    RExC_contains_locale = 0;\n    RExC_strict = cBOOL(pm_flags & RXf_PMf_STRICT);\n    RExC_in_script_run = 0;\n    RExC_study_started = 0;\n    pRExC_state->runtime_code_qr = NULL;\n    RExC_frame_head= NULL;\n    RExC_frame_last= NULL;\n    RExC_frame_count= 0;\n    RExC_latest_warn_offset = 0;\n    RExC_use_BRANCHJ = 0;\n    RExC_total_parens = 0;\n    RExC_open_parens = NULL;\n    RExC_close_parens = NULL;\n    RExC_paren_names = NULL;\n    RExC_size = 0;\n    RExC_seen_d_op = FALSE;\n#ifdef DEBUGGING\n    RExC_paren_name_list = NULL;\n#endif\n\n    DEBUG_r({\n        RExC_mysv1= sv_newmortal();\n        RExC_mysv2= sv_newmortal();\n    });\n\n    DEBUG_COMPILE_r({\n            SV *dsv= sv_newmortal();\n            RE_PV_QUOTED_DECL(s, RExC_utf8, dsv, exp, plen, PL_dump_re_max_len);\n            Perl_re_printf( aTHX_  \"%sCompiling REx%s %s\\n\",\n                          PL_colors[4], PL_colors[5], s);\n        });\n\n    /* we jump here if we have to recompile, e.g., from upgrading the pattern\n     * to utf8 */\n\n    if ((pm_flags & PMf_USE_RE_EVAL)\n\t\t/* this second condition covers the non-regex literal case,\n\t\t * i.e.  $foo =~ '(?{})'. */\n\t\t|| (IN_PERL_COMPILETIME && (PL_hints & HINT_RE_EVAL))\n    )\n\truntime_code = S_has_runtime_code(aTHX_ pRExC_state, exp, plen);\n\n  redo_parse:\n    /* return old regex if pattern hasn't changed */\n    /* XXX: note in the below we have to check the flags as well as the\n     * pattern.\n     *\n     * Things get a touch tricky as we have to compare the utf8 flag\n     * independently from the compile flags.  */\n\n    if (   old_re\n        && !recompile\n        && !!RX_UTF8(old_re) == !!RExC_utf8\n        && ( RX_COMPFLAGS(old_re) == ( orig_rx_flags & RXf_PMf_FLAGCOPYMASK ) )\n\t&& RX_PRECOMP(old_re)\n\t&& RX_PRELEN(old_re) == plen\n        && memEQ(RX_PRECOMP(old_re), exp, plen)\n\t&& !runtime_code /* with runtime code, always recompile */ )\n    {\n        return old_re;\n    }\n\n    /* Allocate the pattern's SV */\n    RExC_rx_sv = Rx = (REGEXP*) newSV_type(SVt_REGEXP);\n    RExC_rx = ReANY(Rx);\n    if ( RExC_rx == NULL )\n        FAIL(\"Regexp out of space\");\n\n    rx_flags = orig_rx_flags;\n\n    if (   (UTF || RExC_uni_semantics)\n        && initial_charset == REGEX_DEPENDS_CHARSET)\n    {\n\n\t/* Set to use unicode semantics if the pattern is in utf8 and has the\n\t * 'depends' charset specified, as it means unicode when utf8  */\n\tset_regex_charset(&rx_flags, REGEX_UNICODE_CHARSET);\n        RExC_uni_semantics = 1;\n    }\n\n    RExC_pm_flags = pm_flags;\n\n    if (runtime_code) {\n        assert(TAINTING_get || !TAINT_get);\n\tif (TAINT_get)\n\t    Perl_croak(aTHX_ \"Eval-group in insecure regular expression\");\n\n\tif (!S_compile_runtime_code(aTHX_ pRExC_state, exp, plen)) {\n\t    /* whoops, we have a non-utf8 pattern, whilst run-time code\n\t     * got compiled as utf8. Try again with a utf8 pattern */\n            S_pat_upgrade_to_utf8(aTHX_ pRExC_state, &exp, &plen,\n                pRExC_state->code_blocks ? pRExC_state->code_blocks->count : 0);\n            goto redo_parse;\n\t}\n    }\n    assert(!pRExC_state->runtime_code_qr);\n\n    RExC_sawback = 0;\n\n    RExC_seen = 0;\n    RExC_maxlen = 0;\n    RExC_in_lookbehind = 0;\n    RExC_seen_zerolen = *exp == '^' ? -1 : 0;\n#ifdef EBCDIC\n    RExC_recode_x_to_native = 0;\n#endif\n    RExC_in_multi_char_class = 0;\n\n    RExC_start = RExC_copy_start_in_constructed = RExC_copy_start_in_input = RExC_precomp = exp;\n    RExC_precomp_end = RExC_end = exp + plen;\n    RExC_nestroot = 0;\n    RExC_whilem_seen = 0;\n    RExC_end_op = NULL;\n    RExC_recurse = NULL;\n    RExC_study_chunk_recursed = NULL;\n    RExC_study_chunk_recursed_bytes= 0;\n    RExC_recurse_count = 0;\n    pRExC_state->code_index = 0;\n\n    /* Initialize the string in the compiled pattern.  This is so that there is\n     * something to output if necessary */\n    set_regex_pv(pRExC_state, Rx);\n\n    DEBUG_PARSE_r({\n        Perl_re_printf( aTHX_\n            \"Starting parse and generation\\n\");\n        RExC_lastnum=0;\n        RExC_lastparse=NULL;\n    });\n\n    /* Allocate space and zero-initialize. Note, the two step process\n       of zeroing when in debug mode, thus anything assigned has to\n       happen after that */\n    if (!  RExC_size) {\n\n        /* On the first pass of the parse, we guess how big this will be.  Then\n         * we grow in one operation to that amount and then give it back.  As\n         * we go along, we re-allocate what we need.\n         *\n         * XXX Currently the guess is essentially that the pattern will be an\n         * EXACT node with one byte input, one byte output.  This is crude, and\n         * better heuristics are welcome.\n         *\n         * On any subsequent passes, we guess what we actually computed in the\n         * latest earlier pass.  Such a pass probably didn't complete so is\n         * missing stuff.  We could improve those guesses by knowing where the\n         * parse stopped, and use the length so far plus apply the above\n         * assumption to what's left. */\n        RExC_size = STR_SZ(RExC_end - RExC_start);\n    }\n\n    Newxc(RExC_rxi, sizeof(regexp_internal) + RExC_size, char, regexp_internal);\n    if ( RExC_rxi == NULL )\n        FAIL(\"Regexp out of space\");\n\n    Zero(RExC_rxi, sizeof(regexp_internal) + RExC_size, char);\n    RXi_SET( RExC_rx, RExC_rxi );\n\n    /* We start from 0 (over from 0 in the case this is a reparse.  The first\n     * node parsed will give back any excess memory we have allocated so far).\n     * */\n    RExC_size = 0;\n\n    /* non-zero initialization begins here */\n    RExC_rx->engine= eng;\n    RExC_rx->extflags = rx_flags;\n    RXp_COMPFLAGS(RExC_rx) = orig_rx_flags & RXf_PMf_FLAGCOPYMASK;\n\n    if (pm_flags & PMf_IS_QR) {\n\tRExC_rxi->code_blocks = pRExC_state->code_blocks;\n        if (RExC_rxi->code_blocks) {\n            RExC_rxi->code_blocks->refcnt++;\n        }\n    }\n\n    RExC_rx->intflags = 0;\n\n    RExC_flags = rx_flags;\t/* don't let top level (?i) bleed */\n    RExC_parse = exp;\n\n    /* This NUL is guaranteed because the pattern comes from an SV*, and the sv\n     * code makes sure the final byte is an uncounted NUL.  But should this\n     * ever not be the case, lots of things could read beyond the end of the\n     * buffer: loops like\n     *      while(isFOO(*RExC_parse)) RExC_parse++;\n     *      strchr(RExC_parse, \"foo\");\n     * etc.  So it is worth noting. */\n    assert(*RExC_end == '\\0');\n\n    RExC_naughty = 0;\n    RExC_npar = 1;\n    RExC_parens_buf_size = 0;\n    RExC_emit_start = RExC_rxi->program;\n    pRExC_state->code_index = 0;\n\n    *((char*) RExC_emit_start) = (char) REG_MAGIC;\n    RExC_emit = 1;\n\n    /* Do the parse */\n    if (reg(pRExC_state, 0, &flags, 1)) {\n\n        /* Success!, But we may need to redo the parse knowing how many parens\n         * there actually are */\n        if (IN_PARENS_PASS) {\n            flags |= RESTART_PARSE;\n        }\n\n        /* We have that number in RExC_npar */\n        RExC_total_parens = RExC_npar;\n    }\n    else if (! MUST_RESTART(flags)) {\n\tReREFCNT_dec(Rx);\n        Perl_croak(aTHX_ \"panic: reg returned failure to re_op_compile, flags=%#\" UVxf, (UV) flags);\n    }\n\n    /* Here, we either have success, or we have to redo the parse for some reason */\n    if (MUST_RESTART(flags)) {\n\n        /* It's possible to write a regexp in ascii that represents Unicode\n        codepoints outside of the byte range, such as via \\x{100}. If we\n        detect such a sequence we have to convert the entire pattern to utf8\n        and then recompile, as our sizing calculation will have been based\n        on 1 byte == 1 character, but we will need to use utf8 to encode\n        at least some part of the pattern, and therefore must convert the whole\n        thing.\n        -- dmq */\n        if (flags & NEED_UTF8) {\n\n            /* We have stored the offset of the final warning output so far.\n             * That must be adjusted.  Any variant characters between the start\n             * of the pattern and this warning count for 2 bytes in the final,\n             * so just add them again */\n            if (UNLIKELY(RExC_latest_warn_offset > 0)) {\n                RExC_latest_warn_offset +=\n                            variant_under_utf8_count((U8 *) exp, (U8 *) exp\n                                                + RExC_latest_warn_offset);\n            }\n            S_pat_upgrade_to_utf8(aTHX_ pRExC_state, &exp, &plen,\n            pRExC_state->code_blocks ? pRExC_state->code_blocks->count : 0);\n            DEBUG_PARSE_r(Perl_re_printf( aTHX_ \"Need to redo parse after upgrade\\n\"));\n        }\n        else {\n            DEBUG_PARSE_r(Perl_re_printf( aTHX_ \"Need to redo parse\\n\"));\n        }\n\n        if (ALL_PARENS_COUNTED) {\n            /* Make enough room for all the known parens, and zero it */\n            Renew(RExC_open_parens, RExC_total_parens, regnode_offset);\n            Zero(RExC_open_parens, RExC_total_parens, regnode_offset);\n            RExC_open_parens[0] = 1;    /* +1 for REG_MAGIC */\n\n            Renew(RExC_close_parens, RExC_total_parens, regnode_offset);\n            Zero(RExC_close_parens, RExC_total_parens, regnode_offset);\n        }\n        else { /* Parse did not complete.  Reinitialize the parentheses\n                  structures */\n            RExC_total_parens = 0;\n            if (RExC_open_parens) {\n                Safefree(RExC_open_parens);\n                RExC_open_parens = NULL;\n            }\n            if (RExC_close_parens) {\n                Safefree(RExC_close_parens);\n                RExC_close_parens = NULL;\n            }\n        }\n\n        /* Clean up what we did in this parse */\n        SvREFCNT_dec_NN(RExC_rx_sv);\n\n        goto redo_parse;\n    }\n\n    /* Here, we have successfully parsed and generated the pattern's program\n     * for the regex engine.  We are ready to finish things up and look for\n     * optimizations. */\n\n    /* Update the string to compile, with correct modifiers, etc */\n    set_regex_pv(pRExC_state, Rx);\n\n    RExC_rx->nparens = RExC_total_parens - 1;\n\n    /* Uses the upper 4 bits of the FLAGS field, so keep within that size */\n    if (RExC_whilem_seen > 15)\n        RExC_whilem_seen = 15;\n\n    DEBUG_PARSE_r({\n        Perl_re_printf( aTHX_\n            \"Required size %\" IVdf \" nodes\\n\", (IV)RExC_size);\n        RExC_lastnum=0;\n        RExC_lastparse=NULL;\n    });\n\n#ifdef RE_TRACK_PATTERN_OFFSETS\n    DEBUG_OFFSETS_r(Perl_re_printf( aTHX_\n                          \"%s %\" UVuf \" bytes for offset annotations.\\n\",\n                          RExC_offsets ? \"Got\" : \"Couldn't get\",\n                          (UV)((RExC_offsets[0] * 2 + 1))));\n    DEBUG_OFFSETS_r(if (RExC_offsets) {\n        const STRLEN len = RExC_offsets[0];\n        STRLEN i;\n        GET_RE_DEBUG_FLAGS_DECL;\n        Perl_re_printf( aTHX_\n                      \"Offsets: [%\" UVuf \"]\\n\\t\", (UV)RExC_offsets[0]);\n        for (i = 1; i <= len; i++) {\n            if (RExC_offsets[i*2-1] || RExC_offsets[i*2])\n                Perl_re_printf( aTHX_  \"%\" UVuf \":%\" UVuf \"[%\" UVuf \"] \",\n                (UV)i, (UV)RExC_offsets[i*2-1], (UV)RExC_offsets[i*2]);\n        }\n        Perl_re_printf( aTHX_  \"\\n\");\n    });\n\n#else\n    SetProgLen(RExC_rxi,RExC_size);\n#endif\n\n    DEBUG_OPTIMISE_r(\n        Perl_re_printf( aTHX_  \"Starting post parse optimization\\n\");\n    );\n\n    /* XXXX To minimize changes to RE engine we always allocate\n       3-units-long substrs field. */\n    Newx(RExC_rx->substrs, 1, struct reg_substr_data);\n    if (RExC_recurse_count) {\n        Newx(RExC_recurse, RExC_recurse_count, regnode *);\n        SAVEFREEPV(RExC_recurse);\n    }\n\n    if (RExC_seen & REG_RECURSE_SEEN) {\n        /* Note, RExC_total_parens is 1 + the number of parens in a pattern.\n         * So its 1 if there are no parens. */\n        RExC_study_chunk_recursed_bytes= (RExC_total_parens >> 3) +\n                                         ((RExC_total_parens & 0x07) != 0);\n        Newx(RExC_study_chunk_recursed,\n             RExC_study_chunk_recursed_bytes * RExC_total_parens, U8);\n        SAVEFREEPV(RExC_study_chunk_recursed);\n    }\n\n  reStudy:\n    RExC_rx->minlen = minlen = sawlookahead = sawplus = sawopen = sawminmod = 0;\n    DEBUG_r(\n        RExC_study_chunk_recursed_count= 0;\n    );\n    Zero(RExC_rx->substrs, 1, struct reg_substr_data);\n    if (RExC_study_chunk_recursed) {\n        Zero(RExC_study_chunk_recursed,\n             RExC_study_chunk_recursed_bytes * RExC_total_parens, U8);\n    }\n\n\n#ifdef TRIE_STUDY_OPT\n    if (!restudied) {\n        StructCopy(&zero_scan_data, &data, scan_data_t);\n        copyRExC_state = RExC_state;\n    } else {\n        U32 seen=RExC_seen;\n        DEBUG_OPTIMISE_r(Perl_re_printf( aTHX_ \"Restudying\\n\"));\n\n        RExC_state = copyRExC_state;\n        if (seen & REG_TOP_LEVEL_BRANCHES_SEEN)\n            RExC_seen |= REG_TOP_LEVEL_BRANCHES_SEEN;\n        else\n            RExC_seen &= ~REG_TOP_LEVEL_BRANCHES_SEEN;\n\tStructCopy(&zero_scan_data, &data, scan_data_t);\n    }\n#else\n    StructCopy(&zero_scan_data, &data, scan_data_t);\n#endif\n\n    /* Dig out information for optimizations. */\n    RExC_rx->extflags = RExC_flags; /* was pm_op */\n    /*dmq: removed as part of de-PMOP: pm->op_pmflags = RExC_flags; */\n\n    if (UTF)\n\tSvUTF8_on(Rx);\t/* Unicode in it? */\n    RExC_rxi->regstclass = NULL;\n    if (RExC_naughty >= TOO_NAUGHTY)\t/* Probably an expensive pattern. */\n\tRExC_rx->intflags |= PREGf_NAUGHTY;\n    scan = RExC_rxi->program + 1;\t\t/* First BRANCH. */\n\n    /* testing for BRANCH here tells us whether there is \"must appear\"\n       data in the pattern. If there is then we can use it for optimisations */\n    if (!(RExC_seen & REG_TOP_LEVEL_BRANCHES_SEEN)) { /*  Only one top-level choice.\n                                                  */\n\tSSize_t fake;\n\tSTRLEN longest_length[2];\n\tregnode_ssc ch_class; /* pointed to by data */\n\tint stclass_flag;\n\tSSize_t last_close = 0; /* pointed to by data */\n        regnode *first= scan;\n        regnode *first_next= regnext(first);\n        int i;\n\n\t/*\n\t * Skip introductions and multiplicators >= 1\n\t * so that we can extract the 'meat' of the pattern that must\n\t * match in the large if() sequence following.\n\t * NOTE that EXACT is NOT covered here, as it is normally\n\t * picked up by the optimiser separately.\n\t *\n\t * This is unfortunate as the optimiser isnt handling lookahead\n\t * properly currently.\n\t *\n\t */\n\twhile ((OP(first) == OPEN && (sawopen = 1)) ||\n\t       /* An OR of *one* alternative - should not happen now. */\n\t    (OP(first) == BRANCH && OP(first_next) != BRANCH) ||\n\t    /* for now we can't handle lookbehind IFMATCH*/\n\t    (OP(first) == IFMATCH && !first->flags && (sawlookahead = 1)) ||\n\t    (OP(first) == PLUS) ||\n\t    (OP(first) == MINMOD) ||\n\t       /* An {n,m} with n>0 */\n\t    (PL_regkind[OP(first)] == CURLY && ARG1(first) > 0) ||\n\t    (OP(first) == NOTHING && PL_regkind[OP(first_next)] != END ))\n\t{\n\t\t/*\n\t\t * the only op that could be a regnode is PLUS, all the rest\n\t\t * will be regnode_1 or regnode_2.\n\t\t *\n                 * (yves doesn't think this is true)\n\t\t */\n\t\tif (OP(first) == PLUS)\n\t\t    sawplus = 1;\n                else {\n                    if (OP(first) == MINMOD)\n                        sawminmod = 1;\n\t\t    first += regarglen[OP(first)];\n                }\n\t\tfirst = NEXTOPER(first);\n\t\tfirst_next= regnext(first);\n\t}\n\n\t/* Starting-point info. */\n      again:\n        DEBUG_PEEP(\"first:\", first, 0, 0);\n        /* Ignore EXACT as we deal with it later. */\n\tif (PL_regkind[OP(first)] == EXACT) {\n\t    if (   OP(first) == EXACT\n                || OP(first) == EXACT_ONLY8\n                || OP(first) == EXACTL)\n            {\n\t\tNOOP;\t/* Empty, get anchored substr later. */\n            }\n\t    else\n\t\tRExC_rxi->regstclass = first;\n\t}\n#ifdef TRIE_STCLASS\n\telse if (PL_regkind[OP(first)] == TRIE &&\n\t        ((reg_trie_data *)RExC_rxi->data->data[ ARG(first) ])->minlen>0)\n\t{\n            /* this can happen only on restudy */\n            RExC_rxi->regstclass = construct_ahocorasick_from_trie(pRExC_state, (regnode *)first, 0);\n\t}\n#endif\n\telse if (REGNODE_SIMPLE(OP(first)))\n\t    RExC_rxi->regstclass = first;\n\telse if (PL_regkind[OP(first)] == BOUND ||\n\t\t PL_regkind[OP(first)] == NBOUND)\n\t    RExC_rxi->regstclass = first;\n\telse if (PL_regkind[OP(first)] == BOL) {\n            RExC_rx->intflags |= (OP(first) == MBOL\n                           ? PREGf_ANCH_MBOL\n                           : PREGf_ANCH_SBOL);\n\t    first = NEXTOPER(first);\n\t    goto again;\n\t}\n\telse if (OP(first) == GPOS) {\n            RExC_rx->intflags |= PREGf_ANCH_GPOS;\n\t    first = NEXTOPER(first);\n\t    goto again;\n\t}\n\telse if ((!sawopen || !RExC_sawback) &&\n            !sawlookahead &&\n\t    (OP(first) == STAR &&\n\t    PL_regkind[OP(NEXTOPER(first))] == REG_ANY) &&\n            !(RExC_rx->intflags & PREGf_ANCH) && !pRExC_state->code_blocks)\n\t{\n\t    /* turn .* into ^.* with an implied $*=1 */\n\t    const int type =\n\t\t(OP(NEXTOPER(first)) == REG_ANY)\n                    ? PREGf_ANCH_MBOL\n                    : PREGf_ANCH_SBOL;\n            RExC_rx->intflags |= (type | PREGf_IMPLICIT);\n\t    first = NEXTOPER(first);\n\t    goto again;\n\t}\n        if (sawplus && !sawminmod && !sawlookahead\n            && (!sawopen || !RExC_sawback)\n\t    && !pRExC_state->code_blocks) /* May examine pos and $& */\n\t    /* x+ must match at the 1st pos of run of x's */\n\t    RExC_rx->intflags |= PREGf_SKIP;\n\n\t/* Scan is after the zeroth branch, first is atomic matcher. */\n#ifdef TRIE_STUDY_OPT\n\tDEBUG_PARSE_r(\n\t    if (!restudied)\n                Perl_re_printf( aTHX_  \"first at %\" IVdf \"\\n\",\n\t\t\t      (IV)(first - scan + 1))\n        );\n#else\n\tDEBUG_PARSE_r(\n            Perl_re_printf( aTHX_  \"first at %\" IVdf \"\\n\",\n\t        (IV)(first - scan + 1))\n        );\n#endif\n\n\n\t/*\n\t* If there's something expensive in the r.e., find the\n\t* longest literal string that must appear and make it the\n\t* regmust.  Resolve ties in favor of later strings, since\n\t* the regstart check works with the beginning of the r.e.\n\t* and avoiding duplication strengthens checking.  Not a\n\t* strong reason, but sufficient in the absence of others.\n\t* [Now we resolve ties in favor of the earlier string if\n\t* it happens that c_offset_min has been invalidated, since the\n\t* earlier string may buy us something the later one won't.]\n\t*/\n\n\tdata.substrs[0].str = newSVpvs(\"\");\n\tdata.substrs[1].str = newSVpvs(\"\");\n\tdata.last_found = newSVpvs(\"\");\n\tdata.cur_is_floating = 0; /* initially any found substring is fixed */\n\tENTER_with_name(\"study_chunk\");\n\tSAVEFREESV(data.substrs[0].str);\n\tSAVEFREESV(data.substrs[1].str);\n\tSAVEFREESV(data.last_found);\n\tfirst = scan;\n\tif (!RExC_rxi->regstclass) {\n\t    ssc_init(pRExC_state, &ch_class);\n\t    data.start_class = &ch_class;\n\t    stclass_flag = SCF_DO_STCLASS_AND;\n\t} else\t\t\t\t/* XXXX Check for BOUND? */\n\t    stclass_flag = 0;\n\tdata.last_closep = &last_close;\n\n        DEBUG_RExC_seen();\n        /*\n         * MAIN ENTRY FOR study_chunk() FOR m/PATTERN/\n         * (NO top level branches)\n         */\n\tminlen = study_chunk(pRExC_state, &first, &minlen, &fake,\n                             scan + RExC_size, /* Up to end */\n            &data, -1, 0, NULL,\n            SCF_DO_SUBSTR | SCF_WHILEM_VISITED_POS | stclass_flag\n                          | (restudied ? SCF_TRIE_DOING_RESTUDY : 0),\n            0);\n\n\n        CHECK_RESTUDY_GOTO_butfirst(LEAVE_with_name(\"study_chunk\"));\n\n\n\tif ( RExC_total_parens == 1 && !data.cur_is_floating\n\t     && data.last_start_min == 0 && data.last_end > 0\n\t     && !RExC_seen_zerolen\n             && !(RExC_seen & REG_VERBARG_SEEN)\n             && !(RExC_seen & REG_GPOS_SEEN)\n        ){\n\t    RExC_rx->extflags |= RXf_CHECK_ALL;\n        }\n\tscan_commit(pRExC_state, &data,&minlen, 0);\n\n\n        /* XXX this is done in reverse order because that's the way the\n         * code was before it was parameterised. Don't know whether it\n         * actually needs doing in reverse order. DAPM */\n        for (i = 1; i >= 0; i--) {\n            longest_length[i] = CHR_SVLEN(data.substrs[i].str);\n\n            if (   !(   i\n                     && SvCUR(data.substrs[0].str)  /* ok to leave SvCUR */\n                     &&    data.substrs[0].min_offset\n                        == data.substrs[1].min_offset\n                     &&    SvCUR(data.substrs[0].str)\n                        == SvCUR(data.substrs[1].str)\n                    )\n                && S_setup_longest (aTHX_ pRExC_state,\n                                        &(RExC_rx->substrs->data[i]),\n                                        &(data.substrs[i]),\n                                        longest_length[i]))\n            {\n                RExC_rx->substrs->data[i].min_offset =\n                        data.substrs[i].min_offset - data.substrs[i].lookbehind;\n\n                RExC_rx->substrs->data[i].max_offset = data.substrs[i].max_offset;\n                /* Don't offset infinity */\n                if (data.substrs[i].max_offset < SSize_t_MAX)\n                    RExC_rx->substrs->data[i].max_offset -= data.substrs[i].lookbehind;\n                SvREFCNT_inc_simple_void_NN(data.substrs[i].str);\n            }\n            else {\n                RExC_rx->substrs->data[i].substr      = NULL;\n                RExC_rx->substrs->data[i].utf8_substr = NULL;\n                longest_length[i] = 0;\n            }\n        }\n\n\tLEAVE_with_name(\"study_chunk\");\n\n\tif (RExC_rxi->regstclass\n\t    && (OP(RExC_rxi->regstclass) == REG_ANY || OP(RExC_rxi->regstclass) == SANY))\n\t    RExC_rxi->regstclass = NULL;\n\n\tif ((!(RExC_rx->substrs->data[0].substr || RExC_rx->substrs->data[0].utf8_substr)\n              || RExC_rx->substrs->data[0].min_offset)\n\t    && stclass_flag\n            && ! (ANYOF_FLAGS(data.start_class) & SSC_MATCHES_EMPTY_STRING)\n\t    && is_ssc_worth_it(pRExC_state, data.start_class))\n\t{\n\t    const U32 n = add_data(pRExC_state, STR_WITH_LEN(\"f\"));\n\n            ssc_finalize(pRExC_state, data.start_class);\n\n\t    Newx(RExC_rxi->data->data[n], 1, regnode_ssc);\n\t    StructCopy(data.start_class,\n\t\t       (regnode_ssc*)RExC_rxi->data->data[n],\n\t\t       regnode_ssc);\n\t    RExC_rxi->regstclass = (regnode*)RExC_rxi->data->data[n];\n\t    RExC_rx->intflags &= ~PREGf_SKIP;\t/* Used in find_byclass(). */\n\t    DEBUG_COMPILE_r({ SV *sv = sv_newmortal();\n                      regprop(RExC_rx, sv, (regnode*)data.start_class, NULL, pRExC_state);\n                      Perl_re_printf( aTHX_\n\t\t\t\t    \"synthetic stclass \\\"%s\\\".\\n\",\n\t\t\t\t    SvPVX_const(sv));});\n            data.start_class = NULL;\n\t}\n\n        /* A temporary algorithm prefers floated substr to fixed one of\n         * same length to dig more info. */\n\ti = (longest_length[0] <= longest_length[1]);\n        RExC_rx->substrs->check_ix = i;\n        RExC_rx->check_end_shift  = RExC_rx->substrs->data[i].end_shift;\n        RExC_rx->check_substr     = RExC_rx->substrs->data[i].substr;\n        RExC_rx->check_utf8       = RExC_rx->substrs->data[i].utf8_substr;\n        RExC_rx->check_offset_min = RExC_rx->substrs->data[i].min_offset;\n        RExC_rx->check_offset_max = RExC_rx->substrs->data[i].max_offset;\n        if (!i && (RExC_rx->intflags & (PREGf_ANCH_SBOL|PREGf_ANCH_GPOS)))\n            RExC_rx->intflags |= PREGf_NOSCAN;\n\n\tif ((RExC_rx->check_substr || RExC_rx->check_utf8) ) {\n\t    RExC_rx->extflags |= RXf_USE_INTUIT;\n\t    if (SvTAIL(RExC_rx->check_substr ? RExC_rx->check_substr : RExC_rx->check_utf8))\n\t\tRExC_rx->extflags |= RXf_INTUIT_TAIL;\n\t}\n\n\t/* XXX Unneeded? dmq (shouldn't as this is handled elsewhere)\n\tif ( (STRLEN)minlen < longest_length[1] )\n            minlen= longest_length[1];\n        if ( (STRLEN)minlen < longest_length[0] )\n            minlen= longest_length[0];\n        */\n    }\n    else {\n\t/* Several toplevels. Best we can is to set minlen. */\n\tSSize_t fake;\n\tregnode_ssc ch_class;\n\tSSize_t last_close = 0;\n\n        DEBUG_PARSE_r(Perl_re_printf( aTHX_  \"\\nMulti Top Level\\n\"));\n\n\tscan = RExC_rxi->program + 1;\n\tssc_init(pRExC_state, &ch_class);\n\tdata.start_class = &ch_class;\n\tdata.last_closep = &last_close;\n\n        DEBUG_RExC_seen();\n        /*\n         * MAIN ENTRY FOR study_chunk() FOR m/P1|P2|.../\n         * (patterns WITH top level branches)\n         */\n\tminlen = study_chunk(pRExC_state,\n            &scan, &minlen, &fake, scan + RExC_size, &data, -1, 0, NULL,\n            SCF_DO_STCLASS_AND|SCF_WHILEM_VISITED_POS|(restudied\n                                                      ? SCF_TRIE_DOING_RESTUDY\n                                                      : 0),\n            0);\n\n        CHECK_RESTUDY_GOTO_butfirst(NOOP);\n\n\tRExC_rx->check_substr = NULL;\n        RExC_rx->check_utf8 = NULL;\n        RExC_rx->substrs->data[0].substr      = NULL;\n        RExC_rx->substrs->data[0].utf8_substr = NULL;\n        RExC_rx->substrs->data[1].substr      = NULL;\n        RExC_rx->substrs->data[1].utf8_substr = NULL;\n\n        if (! (ANYOF_FLAGS(data.start_class) & SSC_MATCHES_EMPTY_STRING)\n\t    && is_ssc_worth_it(pRExC_state, data.start_class))\n        {\n\t    const U32 n = add_data(pRExC_state, STR_WITH_LEN(\"f\"));\n\n            ssc_finalize(pRExC_state, data.start_class);\n\n\t    Newx(RExC_rxi->data->data[n], 1, regnode_ssc);\n\t    StructCopy(data.start_class,\n\t\t       (regnode_ssc*)RExC_rxi->data->data[n],\n\t\t       regnode_ssc);\n\t    RExC_rxi->regstclass = (regnode*)RExC_rxi->data->data[n];\n\t    RExC_rx->intflags &= ~PREGf_SKIP;\t/* Used in find_byclass(). */\n\t    DEBUG_COMPILE_r({ SV* sv = sv_newmortal();\n                      regprop(RExC_rx, sv, (regnode*)data.start_class, NULL, pRExC_state);\n                      Perl_re_printf( aTHX_\n\t\t\t\t    \"synthetic stclass \\\"%s\\\".\\n\",\n\t\t\t\t    SvPVX_const(sv));});\n            data.start_class = NULL;\n\t}\n    }\n\n    if (RExC_seen & REG_UNBOUNDED_QUANTIFIER_SEEN) {\n        RExC_rx->extflags |= RXf_UNBOUNDED_QUANTIFIER_SEEN;\n        RExC_rx->maxlen = REG_INFTY;\n    }\n    else {\n        RExC_rx->maxlen = RExC_maxlen;\n    }\n\n    /* Guard against an embedded (?=) or (?<=) with a longer minlen than\n       the \"real\" pattern. */\n    DEBUG_OPTIMISE_r({\n        Perl_re_printf( aTHX_ \"minlen: %\" IVdf \" RExC_rx->minlen:%\" IVdf \" maxlen:%\" IVdf \"\\n\",\n                      (IV)minlen, (IV)RExC_rx->minlen, (IV)RExC_maxlen);\n    });\n    RExC_rx->minlenret = minlen;\n    if (RExC_rx->minlen < minlen)\n        RExC_rx->minlen = minlen;\n\n    if (RExC_seen & REG_RECURSE_SEEN ) {\n        RExC_rx->intflags |= PREGf_RECURSE_SEEN;\n        Newx(RExC_rx->recurse_locinput, RExC_rx->nparens + 1, char *);\n    }\n    if (RExC_seen & REG_GPOS_SEEN)\n        RExC_rx->intflags |= PREGf_GPOS_SEEN;\n    if (RExC_seen & REG_LOOKBEHIND_SEEN)\n        RExC_rx->extflags |= RXf_NO_INPLACE_SUBST; /* inplace might break the\n                                                lookbehind */\n    if (pRExC_state->code_blocks)\n\tRExC_rx->extflags |= RXf_EVAL_SEEN;\n    if (RExC_seen & REG_VERBARG_SEEN)\n    {\n\tRExC_rx->intflags |= PREGf_VERBARG_SEEN;\n        RExC_rx->extflags |= RXf_NO_INPLACE_SUBST; /* don't understand this! Yves */\n    }\n    if (RExC_seen & REG_CUTGROUP_SEEN)\n\tRExC_rx->intflags |= PREGf_CUTGROUP_SEEN;\n    if (pm_flags & PMf_USE_RE_EVAL)\n\tRExC_rx->intflags |= PREGf_USE_RE_EVAL;\n    if (RExC_paren_names)\n        RXp_PAREN_NAMES(RExC_rx) = MUTABLE_HV(SvREFCNT_inc(RExC_paren_names));\n    else\n        RXp_PAREN_NAMES(RExC_rx) = NULL;\n\n    /* If we have seen an anchor in our pattern then we set the extflag RXf_IS_ANCHORED\n     * so it can be used in pp.c */\n    if (RExC_rx->intflags & PREGf_ANCH)\n        RExC_rx->extflags |= RXf_IS_ANCHORED;\n\n\n    {\n        /* this is used to identify \"special\" patterns that might result\n         * in Perl NOT calling the regex engine and instead doing the match \"itself\",\n         * particularly special cases in split//. By having the regex compiler\n         * do this pattern matching at a regop level (instead of by inspecting the pattern)\n         * we avoid weird issues with equivalent patterns resulting in different behavior,\n         * AND we allow non Perl engines to get the same optimizations by the setting the\n         * flags appropriately - Yves */\n        regnode *first = RExC_rxi->program + 1;\n        U8 fop = OP(first);\n        regnode *next = regnext(first);\n        U8 nop = OP(next);\n\n        if (PL_regkind[fop] == NOTHING && nop == END)\n            RExC_rx->extflags |= RXf_NULL;\n        else if ((fop == MBOL || (fop == SBOL && !first->flags)) && nop == END)\n            /* when fop is SBOL first->flags will be true only when it was\n             * produced by parsing /\\A/, and not when parsing /^/. This is\n             * very important for the split code as there we want to\n             * treat /^/ as /^/m, but we do not want to treat /\\A/ as /^/m.\n             * See rt #122761 for more details. -- Yves */\n            RExC_rx->extflags |= RXf_START_ONLY;\n        else if (fop == PLUS\n                 && PL_regkind[nop] == POSIXD && FLAGS(next) == _CC_SPACE\n                 && nop == END)\n            RExC_rx->extflags |= RXf_WHITE;\n        else if ( RExC_rx->extflags & RXf_SPLIT\n                  && (fop == EXACT || fop == EXACT_ONLY8 || fop == EXACTL)\n                  && STR_LEN(first) == 1\n                  && *(STRING(first)) == ' '\n                  && nop == END )\n            RExC_rx->extflags |= (RXf_SKIPWHITE|RXf_WHITE);\n\n    }\n\n    if (RExC_contains_locale) {\n        RXp_EXTFLAGS(RExC_rx) |= RXf_TAINTED;\n    }\n\n#ifdef DEBUGGING\n    if (RExC_paren_names) {\n        RExC_rxi->name_list_idx = add_data( pRExC_state, STR_WITH_LEN(\"a\"));\n        RExC_rxi->data->data[RExC_rxi->name_list_idx]\n                                   = (void*)SvREFCNT_inc(RExC_paren_name_list);\n    } else\n#endif\n    RExC_rxi->name_list_idx = 0;\n\n    while ( RExC_recurse_count > 0 ) {\n        const regnode *scan = RExC_recurse[ --RExC_recurse_count ];\n        /*\n         * This data structure is set up in study_chunk() and is used\n         * to calculate the distance between a GOSUB regopcode and\n         * the OPEN/CURLYM (CURLYM's are special and can act like OPEN's)\n         * it refers to.\n         *\n         * If for some reason someone writes code that optimises\n         * away a GOSUB opcode then the assert should be changed to\n         * an if(scan) to guard the ARG2L_SET() - Yves\n         *\n         */\n        assert(scan && OP(scan) == GOSUB);\n        ARG2L_SET( scan, RExC_open_parens[ARG(scan)] - REGNODE_OFFSET(scan));\n    }\n\n    Newxz(RExC_rx->offs, RExC_total_parens, regexp_paren_pair);\n    /* assume we don't need to swap parens around before we match */\n    DEBUG_TEST_r({\n        Perl_re_printf( aTHX_ \"study_chunk_recursed_count: %lu\\n\",\n            (unsigned long)RExC_study_chunk_recursed_count);\n    });\n    DEBUG_DUMP_r({\n        DEBUG_RExC_seen();\n        Perl_re_printf( aTHX_ \"Final program:\\n\");\n        regdump(RExC_rx);\n    });\n\n    if (RExC_open_parens) {\n        Safefree(RExC_open_parens);\n        RExC_open_parens = NULL;\n    }\n    if (RExC_close_parens) {\n        Safefree(RExC_close_parens);\n        RExC_close_parens = NULL;\n    }\n\n#ifdef USE_ITHREADS\n    /* under ithreads the ?pat? PMf_USED flag on the pmop is simulated\n     * by setting the regexp SV to readonly-only instead. If the\n     * pattern's been recompiled, the USEDness should remain. */\n    if (old_re && SvREADONLY(old_re))\n        SvREADONLY_on(Rx);\n#endif\n    return Rx;", "func_src_after": "REGEXP *\nPerl_re_op_compile(pTHX_ SV ** const patternp, int pat_count,\n\t\t    OP *expr, const regexp_engine* eng, REGEXP *old_re,\n\t\t     bool *is_bare_re, const U32 orig_rx_flags, const U32 pm_flags)\n{\n    dVAR;\n    REGEXP *Rx;         /* Capital 'R' means points to a REGEXP */\n    STRLEN plen;\n    char *exp;\n    regnode *scan;\n    I32 flags;\n    SSize_t minlen = 0;\n    U32 rx_flags;\n    SV *pat;\n    SV** new_patternp = patternp;\n\n    /* these are all flags - maybe they should be turned\n     * into a single int with different bit masks */\n    I32 sawlookahead = 0;\n    I32 sawplus = 0;\n    I32 sawopen = 0;\n    I32 sawminmod = 0;\n\n    regex_charset initial_charset = get_regex_charset(orig_rx_flags);\n    bool recompile = 0;\n    bool runtime_code = 0;\n    scan_data_t data;\n    RExC_state_t RExC_state;\n    RExC_state_t * const pRExC_state = &RExC_state;\n#ifdef TRIE_STUDY_OPT\n    int restudied = 0;\n    RExC_state_t copyRExC_state;\n#endif\n    GET_RE_DEBUG_FLAGS_DECL;\n\n    PERL_ARGS_ASSERT_RE_OP_COMPILE;\n\n    DEBUG_r(if (!PL_colorset) reginitcolors());\n\n    /* Initialize these here instead of as-needed, as is quick and avoids\n     * having to test them each time otherwise */\n    if (! PL_InBitmap) {\n#ifdef DEBUGGING\n        char * dump_len_string;\n#endif\n\n        /* This is calculated here, because the Perl program that generates the\n         * static global ones doesn't currently have access to\n         * NUM_ANYOF_CODE_POINTS */\n\tPL_InBitmap = _new_invlist(2);\n\tPL_InBitmap = _add_range_to_invlist(PL_InBitmap, 0,\n                                                    NUM_ANYOF_CODE_POINTS - 1);\n#ifdef DEBUGGING\n        dump_len_string = PerlEnv_getenv(\"PERL_DUMP_RE_MAX_LEN\");\n        if (   ! dump_len_string\n            || ! grok_atoUV(dump_len_string, (UV *)&PL_dump_re_max_len, NULL))\n        {\n            PL_dump_re_max_len = 60;    /* A reasonable default */\n        }\n#endif\n    }\n\n    pRExC_state->warn_text = NULL;\n    pRExC_state->unlexed_names = NULL;\n    pRExC_state->code_blocks = NULL;\n\n    if (is_bare_re)\n\t*is_bare_re = FALSE;\n\n    if (expr && (expr->op_type == OP_LIST ||\n\t\t(expr->op_type == OP_NULL && expr->op_targ == OP_LIST))) {\n\t/* allocate code_blocks if needed */\n\tOP *o;\n\tint ncode = 0;\n\n\tfor (o = cLISTOPx(expr)->op_first; o; o = OpSIBLING(o))\n\t    if (o->op_type == OP_NULL && (o->op_flags & OPf_SPECIAL))\n\t\tncode++; /* count of DO blocks */\n\n\tif (ncode)\n            pRExC_state->code_blocks = S_alloc_code_blocks(aTHX_ ncode);\n    }\n\n    if (!pat_count) {\n        /* compile-time pattern with just OP_CONSTs and DO blocks */\n\n        int n;\n        OP *o;\n\n        /* find how many CONSTs there are */\n        assert(expr);\n        n = 0;\n        if (expr->op_type == OP_CONST)\n            n = 1;\n        else\n            for (o = cLISTOPx(expr)->op_first; o; o = OpSIBLING(o)) {\n                if (o->op_type == OP_CONST)\n                    n++;\n            }\n\n        /* fake up an SV array */\n\n        assert(!new_patternp);\n        Newx(new_patternp, n, SV*);\n        SAVEFREEPV(new_patternp);\n        pat_count = n;\n\n        n = 0;\n        if (expr->op_type == OP_CONST)\n            new_patternp[n] = cSVOPx_sv(expr);\n        else\n            for (o = cLISTOPx(expr)->op_first; o; o = OpSIBLING(o)) {\n                if (o->op_type == OP_CONST)\n                    new_patternp[n++] = cSVOPo_sv;\n            }\n\n    }\n\n    DEBUG_PARSE_r(Perl_re_printf( aTHX_\n        \"Assembling pattern from %d elements%s\\n\", pat_count,\n            orig_rx_flags & RXf_SPLIT ? \" for split\" : \"\"));\n\n    /* set expr to the first arg op */\n\n    if (pRExC_state->code_blocks && pRExC_state->code_blocks->count\n         && expr->op_type != OP_CONST)\n    {\n            expr = cLISTOPx(expr)->op_first;\n            assert(   expr->op_type == OP_PUSHMARK\n                   || (expr->op_type == OP_NULL && expr->op_targ == OP_PUSHMARK)\n                   || expr->op_type == OP_PADRANGE);\n            expr = OpSIBLING(expr);\n    }\n\n    pat = S_concat_pat(aTHX_ pRExC_state, NULL, new_patternp, pat_count,\n                        expr, &recompile, NULL);\n\n    /* handle bare (possibly after overloading) regex: foo =~ $re */\n    {\n        SV *re = pat;\n        if (SvROK(re))\n            re = SvRV(re);\n        if (SvTYPE(re) == SVt_REGEXP) {\n            if (is_bare_re)\n                *is_bare_re = TRUE;\n            SvREFCNT_inc(re);\n            DEBUG_PARSE_r(Perl_re_printf( aTHX_\n                \"Precompiled pattern%s\\n\",\n                    orig_rx_flags & RXf_SPLIT ? \" for split\" : \"\"));\n\n            return (REGEXP*)re;\n        }\n    }\n\n    exp = SvPV_nomg(pat, plen);\n\n    if (!eng->op_comp) {\n\tif ((SvUTF8(pat) && IN_BYTES)\n\t\t|| SvGMAGICAL(pat) || SvAMAGIC(pat))\n\t{\n\t    /* make a temporary copy; either to convert to bytes,\n\t     * or to avoid repeating get-magic / overloaded stringify */\n\t    pat = newSVpvn_flags(exp, plen, SVs_TEMP |\n\t\t\t\t\t(IN_BYTES ? 0 : SvUTF8(pat)));\n\t}\n\treturn CALLREGCOMP_ENG(eng, pat, orig_rx_flags);\n    }\n\n    /* ignore the utf8ness if the pattern is 0 length */\n    RExC_utf8 = RExC_orig_utf8 = (plen == 0 || IN_BYTES) ? 0 : SvUTF8(pat);\n    RExC_uni_semantics = 0;\n    RExC_contains_locale = 0;\n    RExC_strict = cBOOL(pm_flags & RXf_PMf_STRICT);\n    RExC_in_script_run = 0;\n    RExC_study_started = 0;\n    pRExC_state->runtime_code_qr = NULL;\n    RExC_frame_head= NULL;\n    RExC_frame_last= NULL;\n    RExC_frame_count= 0;\n    RExC_latest_warn_offset = 0;\n    RExC_use_BRANCHJ = 0;\n    RExC_total_parens = 0;\n    RExC_open_parens = NULL;\n    RExC_close_parens = NULL;\n    RExC_paren_names = NULL;\n    RExC_size = 0;\n    RExC_seen_d_op = FALSE;\n#ifdef DEBUGGING\n    RExC_paren_name_list = NULL;\n#endif\n\n    DEBUG_r({\n        RExC_mysv1= sv_newmortal();\n        RExC_mysv2= sv_newmortal();\n    });\n\n    DEBUG_COMPILE_r({\n            SV *dsv= sv_newmortal();\n            RE_PV_QUOTED_DECL(s, RExC_utf8, dsv, exp, plen, PL_dump_re_max_len);\n            Perl_re_printf( aTHX_  \"%sCompiling REx%s %s\\n\",\n                          PL_colors[4], PL_colors[5], s);\n        });\n\n    /* we jump here if we have to recompile, e.g., from upgrading the pattern\n     * to utf8 */\n\n    if ((pm_flags & PMf_USE_RE_EVAL)\n\t\t/* this second condition covers the non-regex literal case,\n\t\t * i.e.  $foo =~ '(?{})'. */\n\t\t|| (IN_PERL_COMPILETIME && (PL_hints & HINT_RE_EVAL))\n    )\n\truntime_code = S_has_runtime_code(aTHX_ pRExC_state, exp, plen);\n\n  redo_parse:\n    /* return old regex if pattern hasn't changed */\n    /* XXX: note in the below we have to check the flags as well as the\n     * pattern.\n     *\n     * Things get a touch tricky as we have to compare the utf8 flag\n     * independently from the compile flags.  */\n\n    if (   old_re\n        && !recompile\n        && !!RX_UTF8(old_re) == !!RExC_utf8\n        && ( RX_COMPFLAGS(old_re) == ( orig_rx_flags & RXf_PMf_FLAGCOPYMASK ) )\n\t&& RX_PRECOMP(old_re)\n\t&& RX_PRELEN(old_re) == plen\n        && memEQ(RX_PRECOMP(old_re), exp, plen)\n\t&& !runtime_code /* with runtime code, always recompile */ )\n    {\n        return old_re;\n    }\n\n    /* Allocate the pattern's SV */\n    RExC_rx_sv = Rx = (REGEXP*) newSV_type(SVt_REGEXP);\n    RExC_rx = ReANY(Rx);\n    if ( RExC_rx == NULL )\n        FAIL(\"Regexp out of space\");\n\n    rx_flags = orig_rx_flags;\n\n    if (   (UTF || RExC_uni_semantics)\n        && initial_charset == REGEX_DEPENDS_CHARSET)\n    {\n\n\t/* Set to use unicode semantics if the pattern is in utf8 and has the\n\t * 'depends' charset specified, as it means unicode when utf8  */\n\tset_regex_charset(&rx_flags, REGEX_UNICODE_CHARSET);\n        RExC_uni_semantics = 1;\n    }\n\n    RExC_pm_flags = pm_flags;\n\n    if (runtime_code) {\n        assert(TAINTING_get || !TAINT_get);\n\tif (TAINT_get)\n\t    Perl_croak(aTHX_ \"Eval-group in insecure regular expression\");\n\n\tif (!S_compile_runtime_code(aTHX_ pRExC_state, exp, plen)) {\n\t    /* whoops, we have a non-utf8 pattern, whilst run-time code\n\t     * got compiled as utf8. Try again with a utf8 pattern */\n            S_pat_upgrade_to_utf8(aTHX_ pRExC_state, &exp, &plen,\n                pRExC_state->code_blocks ? pRExC_state->code_blocks->count : 0);\n            goto redo_parse;\n\t}\n    }\n    assert(!pRExC_state->runtime_code_qr);\n\n    RExC_sawback = 0;\n\n    RExC_seen = 0;\n    RExC_maxlen = 0;\n    RExC_in_lookbehind = 0;\n    RExC_seen_zerolen = *exp == '^' ? -1 : 0;\n#ifdef EBCDIC\n    RExC_recode_x_to_native = 0;\n#endif\n    RExC_in_multi_char_class = 0;\n\n    RExC_start = RExC_copy_start_in_constructed = RExC_copy_start_in_input = RExC_precomp = exp;\n    RExC_precomp_end = RExC_end = exp + plen;\n    RExC_nestroot = 0;\n    RExC_whilem_seen = 0;\n    RExC_end_op = NULL;\n    RExC_recurse = NULL;\n    RExC_study_chunk_recursed = NULL;\n    RExC_study_chunk_recursed_bytes= 0;\n    RExC_recurse_count = 0;\n    pRExC_state->code_index = 0;\n\n    /* Initialize the string in the compiled pattern.  This is so that there is\n     * something to output if necessary */\n    set_regex_pv(pRExC_state, Rx);\n\n    DEBUG_PARSE_r({\n        Perl_re_printf( aTHX_\n            \"Starting parse and generation\\n\");\n        RExC_lastnum=0;\n        RExC_lastparse=NULL;\n    });\n\n    /* Allocate space and zero-initialize. Note, the two step process\n       of zeroing when in debug mode, thus anything assigned has to\n       happen after that */\n    if (!  RExC_size) {\n\n        /* On the first pass of the parse, we guess how big this will be.  Then\n         * we grow in one operation to that amount and then give it back.  As\n         * we go along, we re-allocate what we need.\n         *\n         * XXX Currently the guess is essentially that the pattern will be an\n         * EXACT node with one byte input, one byte output.  This is crude, and\n         * better heuristics are welcome.\n         *\n         * On any subsequent passes, we guess what we actually computed in the\n         * latest earlier pass.  Such a pass probably didn't complete so is\n         * missing stuff.  We could improve those guesses by knowing where the\n         * parse stopped, and use the length so far plus apply the above\n         * assumption to what's left. */\n        RExC_size = STR_SZ(RExC_end - RExC_start);\n    }\n\n    Newxc(RExC_rxi, sizeof(regexp_internal) + RExC_size, char, regexp_internal);\n    if ( RExC_rxi == NULL )\n        FAIL(\"Regexp out of space\");\n\n    Zero(RExC_rxi, sizeof(regexp_internal) + RExC_size, char);\n    RXi_SET( RExC_rx, RExC_rxi );\n\n    /* We start from 0 (over from 0 in the case this is a reparse.  The first\n     * node parsed will give back any excess memory we have allocated so far).\n     * */\n    RExC_size = 0;\n\n    /* non-zero initialization begins here */\n    RExC_rx->engine= eng;\n    RExC_rx->extflags = rx_flags;\n    RXp_COMPFLAGS(RExC_rx) = orig_rx_flags & RXf_PMf_FLAGCOPYMASK;\n\n    if (pm_flags & PMf_IS_QR) {\n\tRExC_rxi->code_blocks = pRExC_state->code_blocks;\n        if (RExC_rxi->code_blocks) {\n            RExC_rxi->code_blocks->refcnt++;\n        }\n    }\n\n    RExC_rx->intflags = 0;\n\n    RExC_flags = rx_flags;\t/* don't let top level (?i) bleed */\n    RExC_parse = exp;\n\n    /* This NUL is guaranteed because the pattern comes from an SV*, and the sv\n     * code makes sure the final byte is an uncounted NUL.  But should this\n     * ever not be the case, lots of things could read beyond the end of the\n     * buffer: loops like\n     *      while(isFOO(*RExC_parse)) RExC_parse++;\n     *      strchr(RExC_parse, \"foo\");\n     * etc.  So it is worth noting. */\n    assert(*RExC_end == '\\0');\n\n    RExC_naughty = 0;\n    RExC_npar = 1;\n    RExC_parens_buf_size = 0;\n    RExC_emit_start = RExC_rxi->program;\n    pRExC_state->code_index = 0;\n\n    *((char*) RExC_emit_start) = (char) REG_MAGIC;\n    RExC_emit = 1;\n\n    /* Do the parse */\n    if (reg(pRExC_state, 0, &flags, 1)) {\n\n        /* Success!, But we may need to redo the parse knowing how many parens\n         * there actually are */\n        if (IN_PARENS_PASS) {\n            flags |= RESTART_PARSE;\n        }\n\n        /* We have that number in RExC_npar */\n        RExC_total_parens = RExC_npar;\n\n        /* XXX For backporting, use long jumps if there is any possibility of\n         * overflow */\n        if (RExC_size > U16_MAX && ! RExC_use_BRANCHJ) {\n            RExC_use_BRANCHJ = TRUE;\n            flags |= RESTART_PARSE;\n        }\n    }\n    else if (! MUST_RESTART(flags)) {\n\tReREFCNT_dec(Rx);\n        Perl_croak(aTHX_ \"panic: reg returned failure to re_op_compile, flags=%#\" UVxf, (UV) flags);\n    }\n\n    /* Here, we either have success, or we have to redo the parse for some reason */\n    if (MUST_RESTART(flags)) {\n\n        /* It's possible to write a regexp in ascii that represents Unicode\n        codepoints outside of the byte range, such as via \\x{100}. If we\n        detect such a sequence we have to convert the entire pattern to utf8\n        and then recompile, as our sizing calculation will have been based\n        on 1 byte == 1 character, but we will need to use utf8 to encode\n        at least some part of the pattern, and therefore must convert the whole\n        thing.\n        -- dmq */\n        if (flags & NEED_UTF8) {\n\n            /* We have stored the offset of the final warning output so far.\n             * That must be adjusted.  Any variant characters between the start\n             * of the pattern and this warning count for 2 bytes in the final,\n             * so just add them again */\n            if (UNLIKELY(RExC_latest_warn_offset > 0)) {\n                RExC_latest_warn_offset +=\n                            variant_under_utf8_count((U8 *) exp, (U8 *) exp\n                                                + RExC_latest_warn_offset);\n            }\n            S_pat_upgrade_to_utf8(aTHX_ pRExC_state, &exp, &plen,\n            pRExC_state->code_blocks ? pRExC_state->code_blocks->count : 0);\n            DEBUG_PARSE_r(Perl_re_printf( aTHX_ \"Need to redo parse after upgrade\\n\"));\n        }\n        else {\n            DEBUG_PARSE_r(Perl_re_printf( aTHX_ \"Need to redo parse\\n\"));\n        }\n\n        if (ALL_PARENS_COUNTED) {\n            /* Make enough room for all the known parens, and zero it */\n            Renew(RExC_open_parens, RExC_total_parens, regnode_offset);\n            Zero(RExC_open_parens, RExC_total_parens, regnode_offset);\n            RExC_open_parens[0] = 1;    /* +1 for REG_MAGIC */\n\n            Renew(RExC_close_parens, RExC_total_parens, regnode_offset);\n            Zero(RExC_close_parens, RExC_total_parens, regnode_offset);\n        }\n        else { /* Parse did not complete.  Reinitialize the parentheses\n                  structures */\n            RExC_total_parens = 0;\n            if (RExC_open_parens) {\n                Safefree(RExC_open_parens);\n                RExC_open_parens = NULL;\n            }\n            if (RExC_close_parens) {\n                Safefree(RExC_close_parens);\n                RExC_close_parens = NULL;\n            }\n        }\n\n        /* Clean up what we did in this parse */\n        SvREFCNT_dec_NN(RExC_rx_sv);\n\n        goto redo_parse;\n    }\n\n    /* Here, we have successfully parsed and generated the pattern's program\n     * for the regex engine.  We are ready to finish things up and look for\n     * optimizations. */\n\n    /* Update the string to compile, with correct modifiers, etc */\n    set_regex_pv(pRExC_state, Rx);\n\n    RExC_rx->nparens = RExC_total_parens - 1;\n\n    /* Uses the upper 4 bits of the FLAGS field, so keep within that size */\n    if (RExC_whilem_seen > 15)\n        RExC_whilem_seen = 15;\n\n    DEBUG_PARSE_r({\n        Perl_re_printf( aTHX_\n            \"Required size %\" IVdf \" nodes\\n\", (IV)RExC_size);\n        RExC_lastnum=0;\n        RExC_lastparse=NULL;\n    });\n\n#ifdef RE_TRACK_PATTERN_OFFSETS\n    DEBUG_OFFSETS_r(Perl_re_printf( aTHX_\n                          \"%s %\" UVuf \" bytes for offset annotations.\\n\",\n                          RExC_offsets ? \"Got\" : \"Couldn't get\",\n                          (UV)((RExC_offsets[0] * 2 + 1))));\n    DEBUG_OFFSETS_r(if (RExC_offsets) {\n        const STRLEN len = RExC_offsets[0];\n        STRLEN i;\n        GET_RE_DEBUG_FLAGS_DECL;\n        Perl_re_printf( aTHX_\n                      \"Offsets: [%\" UVuf \"]\\n\\t\", (UV)RExC_offsets[0]);\n        for (i = 1; i <= len; i++) {\n            if (RExC_offsets[i*2-1] || RExC_offsets[i*2])\n                Perl_re_printf( aTHX_  \"%\" UVuf \":%\" UVuf \"[%\" UVuf \"] \",\n                (UV)i, (UV)RExC_offsets[i*2-1], (UV)RExC_offsets[i*2]);\n        }\n        Perl_re_printf( aTHX_  \"\\n\");\n    });\n\n#else\n    SetProgLen(RExC_rxi,RExC_size);\n#endif\n\n    DEBUG_OPTIMISE_r(\n        Perl_re_printf( aTHX_  \"Starting post parse optimization\\n\");\n    );\n\n    /* XXXX To minimize changes to RE engine we always allocate\n       3-units-long substrs field. */\n    Newx(RExC_rx->substrs, 1, struct reg_substr_data);\n    if (RExC_recurse_count) {\n        Newx(RExC_recurse, RExC_recurse_count, regnode *);\n        SAVEFREEPV(RExC_recurse);\n    }\n\n    if (RExC_seen & REG_RECURSE_SEEN) {\n        /* Note, RExC_total_parens is 1 + the number of parens in a pattern.\n         * So its 1 if there are no parens. */\n        RExC_study_chunk_recursed_bytes= (RExC_total_parens >> 3) +\n                                         ((RExC_total_parens & 0x07) != 0);\n        Newx(RExC_study_chunk_recursed,\n             RExC_study_chunk_recursed_bytes * RExC_total_parens, U8);\n        SAVEFREEPV(RExC_study_chunk_recursed);\n    }\n\n  reStudy:\n    RExC_rx->minlen = minlen = sawlookahead = sawplus = sawopen = sawminmod = 0;\n    DEBUG_r(\n        RExC_study_chunk_recursed_count= 0;\n    );\n    Zero(RExC_rx->substrs, 1, struct reg_substr_data);\n    if (RExC_study_chunk_recursed) {\n        Zero(RExC_study_chunk_recursed,\n             RExC_study_chunk_recursed_bytes * RExC_total_parens, U8);\n    }\n\n\n#ifdef TRIE_STUDY_OPT\n    if (!restudied) {\n        StructCopy(&zero_scan_data, &data, scan_data_t);\n        copyRExC_state = RExC_state;\n    } else {\n        U32 seen=RExC_seen;\n        DEBUG_OPTIMISE_r(Perl_re_printf( aTHX_ \"Restudying\\n\"));\n\n        RExC_state = copyRExC_state;\n        if (seen & REG_TOP_LEVEL_BRANCHES_SEEN)\n            RExC_seen |= REG_TOP_LEVEL_BRANCHES_SEEN;\n        else\n            RExC_seen &= ~REG_TOP_LEVEL_BRANCHES_SEEN;\n\tStructCopy(&zero_scan_data, &data, scan_data_t);\n    }\n#else\n    StructCopy(&zero_scan_data, &data, scan_data_t);\n#endif\n\n    /* Dig out information for optimizations. */\n    RExC_rx->extflags = RExC_flags; /* was pm_op */\n    /*dmq: removed as part of de-PMOP: pm->op_pmflags = RExC_flags; */\n\n    if (UTF)\n\tSvUTF8_on(Rx);\t/* Unicode in it? */\n    RExC_rxi->regstclass = NULL;\n    if (RExC_naughty >= TOO_NAUGHTY)\t/* Probably an expensive pattern. */\n\tRExC_rx->intflags |= PREGf_NAUGHTY;\n    scan = RExC_rxi->program + 1;\t\t/* First BRANCH. */\n\n    /* testing for BRANCH here tells us whether there is \"must appear\"\n       data in the pattern. If there is then we can use it for optimisations */\n    if (!(RExC_seen & REG_TOP_LEVEL_BRANCHES_SEEN)) { /*  Only one top-level choice.\n                                                  */\n\tSSize_t fake;\n\tSTRLEN longest_length[2];\n\tregnode_ssc ch_class; /* pointed to by data */\n\tint stclass_flag;\n\tSSize_t last_close = 0; /* pointed to by data */\n        regnode *first= scan;\n        regnode *first_next= regnext(first);\n        int i;\n\n\t/*\n\t * Skip introductions and multiplicators >= 1\n\t * so that we can extract the 'meat' of the pattern that must\n\t * match in the large if() sequence following.\n\t * NOTE that EXACT is NOT covered here, as it is normally\n\t * picked up by the optimiser separately.\n\t *\n\t * This is unfortunate as the optimiser isnt handling lookahead\n\t * properly currently.\n\t *\n\t */\n\twhile ((OP(first) == OPEN && (sawopen = 1)) ||\n\t       /* An OR of *one* alternative - should not happen now. */\n\t    (OP(first) == BRANCH && OP(first_next) != BRANCH) ||\n\t    /* for now we can't handle lookbehind IFMATCH*/\n\t    (OP(first) == IFMATCH && !first->flags && (sawlookahead = 1)) ||\n\t    (OP(first) == PLUS) ||\n\t    (OP(first) == MINMOD) ||\n\t       /* An {n,m} with n>0 */\n\t    (PL_regkind[OP(first)] == CURLY && ARG1(first) > 0) ||\n\t    (OP(first) == NOTHING && PL_regkind[OP(first_next)] != END ))\n\t{\n\t\t/*\n\t\t * the only op that could be a regnode is PLUS, all the rest\n\t\t * will be regnode_1 or regnode_2.\n\t\t *\n                 * (yves doesn't think this is true)\n\t\t */\n\t\tif (OP(first) == PLUS)\n\t\t    sawplus = 1;\n                else {\n                    if (OP(first) == MINMOD)\n                        sawminmod = 1;\n\t\t    first += regarglen[OP(first)];\n                }\n\t\tfirst = NEXTOPER(first);\n\t\tfirst_next= regnext(first);\n\t}\n\n\t/* Starting-point info. */\n      again:\n        DEBUG_PEEP(\"first:\", first, 0, 0);\n        /* Ignore EXACT as we deal with it later. */\n\tif (PL_regkind[OP(first)] == EXACT) {\n\t    if (   OP(first) == EXACT\n                || OP(first) == EXACT_ONLY8\n                || OP(first) == EXACTL)\n            {\n\t\tNOOP;\t/* Empty, get anchored substr later. */\n            }\n\t    else\n\t\tRExC_rxi->regstclass = first;\n\t}\n#ifdef TRIE_STCLASS\n\telse if (PL_regkind[OP(first)] == TRIE &&\n\t        ((reg_trie_data *)RExC_rxi->data->data[ ARG(first) ])->minlen>0)\n\t{\n            /* this can happen only on restudy */\n            RExC_rxi->regstclass = construct_ahocorasick_from_trie(pRExC_state, (regnode *)first, 0);\n\t}\n#endif\n\telse if (REGNODE_SIMPLE(OP(first)))\n\t    RExC_rxi->regstclass = first;\n\telse if (PL_regkind[OP(first)] == BOUND ||\n\t\t PL_regkind[OP(first)] == NBOUND)\n\t    RExC_rxi->regstclass = first;\n\telse if (PL_regkind[OP(first)] == BOL) {\n            RExC_rx->intflags |= (OP(first) == MBOL\n                           ? PREGf_ANCH_MBOL\n                           : PREGf_ANCH_SBOL);\n\t    first = NEXTOPER(first);\n\t    goto again;\n\t}\n\telse if (OP(first) == GPOS) {\n            RExC_rx->intflags |= PREGf_ANCH_GPOS;\n\t    first = NEXTOPER(first);\n\t    goto again;\n\t}\n\telse if ((!sawopen || !RExC_sawback) &&\n            !sawlookahead &&\n\t    (OP(first) == STAR &&\n\t    PL_regkind[OP(NEXTOPER(first))] == REG_ANY) &&\n            !(RExC_rx->intflags & PREGf_ANCH) && !pRExC_state->code_blocks)\n\t{\n\t    /* turn .* into ^.* with an implied $*=1 */\n\t    const int type =\n\t\t(OP(NEXTOPER(first)) == REG_ANY)\n                    ? PREGf_ANCH_MBOL\n                    : PREGf_ANCH_SBOL;\n            RExC_rx->intflags |= (type | PREGf_IMPLICIT);\n\t    first = NEXTOPER(first);\n\t    goto again;\n\t}\n        if (sawplus && !sawminmod && !sawlookahead\n            && (!sawopen || !RExC_sawback)\n\t    && !pRExC_state->code_blocks) /* May examine pos and $& */\n\t    /* x+ must match at the 1st pos of run of x's */\n\t    RExC_rx->intflags |= PREGf_SKIP;\n\n\t/* Scan is after the zeroth branch, first is atomic matcher. */\n#ifdef TRIE_STUDY_OPT\n\tDEBUG_PARSE_r(\n\t    if (!restudied)\n                Perl_re_printf( aTHX_  \"first at %\" IVdf \"\\n\",\n\t\t\t      (IV)(first - scan + 1))\n        );\n#else\n\tDEBUG_PARSE_r(\n            Perl_re_printf( aTHX_  \"first at %\" IVdf \"\\n\",\n\t        (IV)(first - scan + 1))\n        );\n#endif\n\n\n\t/*\n\t* If there's something expensive in the r.e., find the\n\t* longest literal string that must appear and make it the\n\t* regmust.  Resolve ties in favor of later strings, since\n\t* the regstart check works with the beginning of the r.e.\n\t* and avoiding duplication strengthens checking.  Not a\n\t* strong reason, but sufficient in the absence of others.\n\t* [Now we resolve ties in favor of the earlier string if\n\t* it happens that c_offset_min has been invalidated, since the\n\t* earlier string may buy us something the later one won't.]\n\t*/\n\n\tdata.substrs[0].str = newSVpvs(\"\");\n\tdata.substrs[1].str = newSVpvs(\"\");\n\tdata.last_found = newSVpvs(\"\");\n\tdata.cur_is_floating = 0; /* initially any found substring is fixed */\n\tENTER_with_name(\"study_chunk\");\n\tSAVEFREESV(data.substrs[0].str);\n\tSAVEFREESV(data.substrs[1].str);\n\tSAVEFREESV(data.last_found);\n\tfirst = scan;\n\tif (!RExC_rxi->regstclass) {\n\t    ssc_init(pRExC_state, &ch_class);\n\t    data.start_class = &ch_class;\n\t    stclass_flag = SCF_DO_STCLASS_AND;\n\t} else\t\t\t\t/* XXXX Check for BOUND? */\n\t    stclass_flag = 0;\n\tdata.last_closep = &last_close;\n\n        DEBUG_RExC_seen();\n        /*\n         * MAIN ENTRY FOR study_chunk() FOR m/PATTERN/\n         * (NO top level branches)\n         */\n\tminlen = study_chunk(pRExC_state, &first, &minlen, &fake,\n                             scan + RExC_size, /* Up to end */\n            &data, -1, 0, NULL,\n            SCF_DO_SUBSTR | SCF_WHILEM_VISITED_POS | stclass_flag\n                          | (restudied ? SCF_TRIE_DOING_RESTUDY : 0),\n            0);\n\n\n        CHECK_RESTUDY_GOTO_butfirst(LEAVE_with_name(\"study_chunk\"));\n\n\n\tif ( RExC_total_parens == 1 && !data.cur_is_floating\n\t     && data.last_start_min == 0 && data.last_end > 0\n\t     && !RExC_seen_zerolen\n             && !(RExC_seen & REG_VERBARG_SEEN)\n             && !(RExC_seen & REG_GPOS_SEEN)\n        ){\n\t    RExC_rx->extflags |= RXf_CHECK_ALL;\n        }\n\tscan_commit(pRExC_state, &data,&minlen, 0);\n\n\n        /* XXX this is done in reverse order because that's the way the\n         * code was before it was parameterised. Don't know whether it\n         * actually needs doing in reverse order. DAPM */\n        for (i = 1; i >= 0; i--) {\n            longest_length[i] = CHR_SVLEN(data.substrs[i].str);\n\n            if (   !(   i\n                     && SvCUR(data.substrs[0].str)  /* ok to leave SvCUR */\n                     &&    data.substrs[0].min_offset\n                        == data.substrs[1].min_offset\n                     &&    SvCUR(data.substrs[0].str)\n                        == SvCUR(data.substrs[1].str)\n                    )\n                && S_setup_longest (aTHX_ pRExC_state,\n                                        &(RExC_rx->substrs->data[i]),\n                                        &(data.substrs[i]),\n                                        longest_length[i]))\n            {\n                RExC_rx->substrs->data[i].min_offset =\n                        data.substrs[i].min_offset - data.substrs[i].lookbehind;\n\n                RExC_rx->substrs->data[i].max_offset = data.substrs[i].max_offset;\n                /* Don't offset infinity */\n                if (data.substrs[i].max_offset < SSize_t_MAX)\n                    RExC_rx->substrs->data[i].max_offset -= data.substrs[i].lookbehind;\n                SvREFCNT_inc_simple_void_NN(data.substrs[i].str);\n            }\n            else {\n                RExC_rx->substrs->data[i].substr      = NULL;\n                RExC_rx->substrs->data[i].utf8_substr = NULL;\n                longest_length[i] = 0;\n            }\n        }\n\n\tLEAVE_with_name(\"study_chunk\");\n\n\tif (RExC_rxi->regstclass\n\t    && (OP(RExC_rxi->regstclass) == REG_ANY || OP(RExC_rxi->regstclass) == SANY))\n\t    RExC_rxi->regstclass = NULL;\n\n\tif ((!(RExC_rx->substrs->data[0].substr || RExC_rx->substrs->data[0].utf8_substr)\n              || RExC_rx->substrs->data[0].min_offset)\n\t    && stclass_flag\n            && ! (ANYOF_FLAGS(data.start_class) & SSC_MATCHES_EMPTY_STRING)\n\t    && is_ssc_worth_it(pRExC_state, data.start_class))\n\t{\n\t    const U32 n = add_data(pRExC_state, STR_WITH_LEN(\"f\"));\n\n            ssc_finalize(pRExC_state, data.start_class);\n\n\t    Newx(RExC_rxi->data->data[n], 1, regnode_ssc);\n\t    StructCopy(data.start_class,\n\t\t       (regnode_ssc*)RExC_rxi->data->data[n],\n\t\t       regnode_ssc);\n\t    RExC_rxi->regstclass = (regnode*)RExC_rxi->data->data[n];\n\t    RExC_rx->intflags &= ~PREGf_SKIP;\t/* Used in find_byclass(). */\n\t    DEBUG_COMPILE_r({ SV *sv = sv_newmortal();\n                      regprop(RExC_rx, sv, (regnode*)data.start_class, NULL, pRExC_state);\n                      Perl_re_printf( aTHX_\n\t\t\t\t    \"synthetic stclass \\\"%s\\\".\\n\",\n\t\t\t\t    SvPVX_const(sv));});\n            data.start_class = NULL;\n\t}\n\n        /* A temporary algorithm prefers floated substr to fixed one of\n         * same length to dig more info. */\n\ti = (longest_length[0] <= longest_length[1]);\n        RExC_rx->substrs->check_ix = i;\n        RExC_rx->check_end_shift  = RExC_rx->substrs->data[i].end_shift;\n        RExC_rx->check_substr     = RExC_rx->substrs->data[i].substr;\n        RExC_rx->check_utf8       = RExC_rx->substrs->data[i].utf8_substr;\n        RExC_rx->check_offset_min = RExC_rx->substrs->data[i].min_offset;\n        RExC_rx->check_offset_max = RExC_rx->substrs->data[i].max_offset;\n        if (!i && (RExC_rx->intflags & (PREGf_ANCH_SBOL|PREGf_ANCH_GPOS)))\n            RExC_rx->intflags |= PREGf_NOSCAN;\n\n\tif ((RExC_rx->check_substr || RExC_rx->check_utf8) ) {\n\t    RExC_rx->extflags |= RXf_USE_INTUIT;\n\t    if (SvTAIL(RExC_rx->check_substr ? RExC_rx->check_substr : RExC_rx->check_utf8))\n\t\tRExC_rx->extflags |= RXf_INTUIT_TAIL;\n\t}\n\n\t/* XXX Unneeded? dmq (shouldn't as this is handled elsewhere)\n\tif ( (STRLEN)minlen < longest_length[1] )\n            minlen= longest_length[1];\n        if ( (STRLEN)minlen < longest_length[0] )\n            minlen= longest_length[0];\n        */\n    }\n    else {\n\t/* Several toplevels. Best we can is to set minlen. */\n\tSSize_t fake;\n\tregnode_ssc ch_class;\n\tSSize_t last_close = 0;\n\n        DEBUG_PARSE_r(Perl_re_printf( aTHX_  \"\\nMulti Top Level\\n\"));\n\n\tscan = RExC_rxi->program + 1;\n\tssc_init(pRExC_state, &ch_class);\n\tdata.start_class = &ch_class;\n\tdata.last_closep = &last_close;\n\n        DEBUG_RExC_seen();\n        /*\n         * MAIN ENTRY FOR study_chunk() FOR m/P1|P2|.../\n         * (patterns WITH top level branches)\n         */\n\tminlen = study_chunk(pRExC_state,\n            &scan, &minlen, &fake, scan + RExC_size, &data, -1, 0, NULL,\n            SCF_DO_STCLASS_AND|SCF_WHILEM_VISITED_POS|(restudied\n                                                      ? SCF_TRIE_DOING_RESTUDY\n                                                      : 0),\n            0);\n\n        CHECK_RESTUDY_GOTO_butfirst(NOOP);\n\n\tRExC_rx->check_substr = NULL;\n        RExC_rx->check_utf8 = NULL;\n        RExC_rx->substrs->data[0].substr      = NULL;\n        RExC_rx->substrs->data[0].utf8_substr = NULL;\n        RExC_rx->substrs->data[1].substr      = NULL;\n        RExC_rx->substrs->data[1].utf8_substr = NULL;\n\n        if (! (ANYOF_FLAGS(data.start_class) & SSC_MATCHES_EMPTY_STRING)\n\t    && is_ssc_worth_it(pRExC_state, data.start_class))\n        {\n\t    const U32 n = add_data(pRExC_state, STR_WITH_LEN(\"f\"));\n\n            ssc_finalize(pRExC_state, data.start_class);\n\n\t    Newx(RExC_rxi->data->data[n], 1, regnode_ssc);\n\t    StructCopy(data.start_class,\n\t\t       (regnode_ssc*)RExC_rxi->data->data[n],\n\t\t       regnode_ssc);\n\t    RExC_rxi->regstclass = (regnode*)RExC_rxi->data->data[n];\n\t    RExC_rx->intflags &= ~PREGf_SKIP;\t/* Used in find_byclass(). */\n\t    DEBUG_COMPILE_r({ SV* sv = sv_newmortal();\n                      regprop(RExC_rx, sv, (regnode*)data.start_class, NULL, pRExC_state);\n                      Perl_re_printf( aTHX_\n\t\t\t\t    \"synthetic stclass \\\"%s\\\".\\n\",\n\t\t\t\t    SvPVX_const(sv));});\n            data.start_class = NULL;\n\t}\n    }\n\n    if (RExC_seen & REG_UNBOUNDED_QUANTIFIER_SEEN) {\n        RExC_rx->extflags |= RXf_UNBOUNDED_QUANTIFIER_SEEN;\n        RExC_rx->maxlen = REG_INFTY;\n    }\n    else {\n        RExC_rx->maxlen = RExC_maxlen;\n    }\n\n    /* Guard against an embedded (?=) or (?<=) with a longer minlen than\n       the \"real\" pattern. */\n    DEBUG_OPTIMISE_r({\n        Perl_re_printf( aTHX_ \"minlen: %\" IVdf \" RExC_rx->minlen:%\" IVdf \" maxlen:%\" IVdf \"\\n\",\n                      (IV)minlen, (IV)RExC_rx->minlen, (IV)RExC_maxlen);\n    });\n    RExC_rx->minlenret = minlen;\n    if (RExC_rx->minlen < minlen)\n        RExC_rx->minlen = minlen;\n\n    if (RExC_seen & REG_RECURSE_SEEN ) {\n        RExC_rx->intflags |= PREGf_RECURSE_SEEN;\n        Newx(RExC_rx->recurse_locinput, RExC_rx->nparens + 1, char *);\n    }\n    if (RExC_seen & REG_GPOS_SEEN)\n        RExC_rx->intflags |= PREGf_GPOS_SEEN;\n    if (RExC_seen & REG_LOOKBEHIND_SEEN)\n        RExC_rx->extflags |= RXf_NO_INPLACE_SUBST; /* inplace might break the\n                                                lookbehind */\n    if (pRExC_state->code_blocks)\n\tRExC_rx->extflags |= RXf_EVAL_SEEN;\n    if (RExC_seen & REG_VERBARG_SEEN)\n    {\n\tRExC_rx->intflags |= PREGf_VERBARG_SEEN;\n        RExC_rx->extflags |= RXf_NO_INPLACE_SUBST; /* don't understand this! Yves */\n    }\n    if (RExC_seen & REG_CUTGROUP_SEEN)\n\tRExC_rx->intflags |= PREGf_CUTGROUP_SEEN;\n    if (pm_flags & PMf_USE_RE_EVAL)\n\tRExC_rx->intflags |= PREGf_USE_RE_EVAL;\n    if (RExC_paren_names)\n        RXp_PAREN_NAMES(RExC_rx) = MUTABLE_HV(SvREFCNT_inc(RExC_paren_names));\n    else\n        RXp_PAREN_NAMES(RExC_rx) = NULL;\n\n    /* If we have seen an anchor in our pattern then we set the extflag RXf_IS_ANCHORED\n     * so it can be used in pp.c */\n    if (RExC_rx->intflags & PREGf_ANCH)\n        RExC_rx->extflags |= RXf_IS_ANCHORED;\n\n\n    {\n        /* this is used to identify \"special\" patterns that might result\n         * in Perl NOT calling the regex engine and instead doing the match \"itself\",\n         * particularly special cases in split//. By having the regex compiler\n         * do this pattern matching at a regop level (instead of by inspecting the pattern)\n         * we avoid weird issues with equivalent patterns resulting in different behavior,\n         * AND we allow non Perl engines to get the same optimizations by the setting the\n         * flags appropriately - Yves */\n        regnode *first = RExC_rxi->program + 1;\n        U8 fop = OP(first);\n        regnode *next = regnext(first);\n        U8 nop = OP(next);\n\n        if (PL_regkind[fop] == NOTHING && nop == END)\n            RExC_rx->extflags |= RXf_NULL;\n        else if ((fop == MBOL || (fop == SBOL && !first->flags)) && nop == END)\n            /* when fop is SBOL first->flags will be true only when it was\n             * produced by parsing /\\A/, and not when parsing /^/. This is\n             * very important for the split code as there we want to\n             * treat /^/ as /^/m, but we do not want to treat /\\A/ as /^/m.\n             * See rt #122761 for more details. -- Yves */\n            RExC_rx->extflags |= RXf_START_ONLY;\n        else if (fop == PLUS\n                 && PL_regkind[nop] == POSIXD && FLAGS(next) == _CC_SPACE\n                 && nop == END)\n            RExC_rx->extflags |= RXf_WHITE;\n        else if ( RExC_rx->extflags & RXf_SPLIT\n                  && (fop == EXACT || fop == EXACT_ONLY8 || fop == EXACTL)\n                  && STR_LEN(first) == 1\n                  && *(STRING(first)) == ' '\n                  && nop == END )\n            RExC_rx->extflags |= (RXf_SKIPWHITE|RXf_WHITE);\n\n    }\n\n    if (RExC_contains_locale) {\n        RXp_EXTFLAGS(RExC_rx) |= RXf_TAINTED;\n    }\n\n#ifdef DEBUGGING\n    if (RExC_paren_names) {\n        RExC_rxi->name_list_idx = add_data( pRExC_state, STR_WITH_LEN(\"a\"));\n        RExC_rxi->data->data[RExC_rxi->name_list_idx]\n                                   = (void*)SvREFCNT_inc(RExC_paren_name_list);\n    } else\n#endif\n    RExC_rxi->name_list_idx = 0;\n\n    while ( RExC_recurse_count > 0 ) {\n        const regnode *scan = RExC_recurse[ --RExC_recurse_count ];\n        /*\n         * This data structure is set up in study_chunk() and is used\n         * to calculate the distance between a GOSUB regopcode and\n         * the OPEN/CURLYM (CURLYM's are special and can act like OPEN's)\n         * it refers to.\n         *\n         * If for some reason someone writes code that optimises\n         * away a GOSUB opcode then the assert should be changed to\n         * an if(scan) to guard the ARG2L_SET() - Yves\n         *\n         */\n        assert(scan && OP(scan) == GOSUB);\n        ARG2L_SET( scan, RExC_open_parens[ARG(scan)] - REGNODE_OFFSET(scan));\n    }\n\n    Newxz(RExC_rx->offs, RExC_total_parens, regexp_paren_pair);\n    /* assume we don't need to swap parens around before we match */\n    DEBUG_TEST_r({\n        Perl_re_printf( aTHX_ \"study_chunk_recursed_count: %lu\\n\",\n            (unsigned long)RExC_study_chunk_recursed_count);\n    });\n    DEBUG_DUMP_r({\n        DEBUG_RExC_seen();\n        Perl_re_printf( aTHX_ \"Final program:\\n\");\n        regdump(RExC_rx);\n    });\n\n    if (RExC_open_parens) {\n        Safefree(RExC_open_parens);\n        RExC_open_parens = NULL;\n    }\n    if (RExC_close_parens) {\n        Safefree(RExC_close_parens);\n        RExC_close_parens = NULL;\n    }\n\n#ifdef USE_ITHREADS\n    /* under ithreads the ?pat? PMf_USED flag on the pmop is simulated\n     * by setting the regexp SV to readonly-only instead. If the\n     * pattern's been recompiled, the USEDness should remain. */\n    if (old_re && SvREADONLY(old_re))\n        SvREADONLY_on(Rx);\n#endif\n    return Rx;", "commit_link": "github.com/perl/perl5/commit/3295b48defa0f8570114877b063fe546dd348b3c", "file_name": "regcomp.c", "vul_type": "cwe-190", "description": "Compile a regular expression pattern in Perl."}
{"func_name": "ndpi_search_oracle", "func_src_before": "void ndpi_search_oracle(struct ndpi_detection_module_struct *ndpi_struct, struct ndpi_flow_struct *flow)\n{\n  struct ndpi_packet_struct *packet = &flow->packet;\n  u_int16_t dport = 0, sport = 0;\n\n  NDPI_LOG_DBG(ndpi_struct, \"search ORACLE\\n\");\n\n  if(packet->tcp != NULL) {\n    sport = ntohs(packet->tcp->source), dport = ntohs(packet->tcp->dest);\n    NDPI_LOG_DBG2(ndpi_struct, \"calculating ORACLE over tcp\\n\");\n    /* Oracle Database 9g,10g,11g */\n    if ((dport == 1521 || sport == 1521)\n\t&&  (((packet->payload[0] == 0x07) && (packet->payload[1] == 0xff) && (packet->payload[2] == 0x00))\n\t     || ((packet->payload_packet_len >= 232) && ((packet->payload[0] == 0x00) || (packet->payload[0] == 0x01)) \n\t     && (packet->payload[1] != 0x00)\n\t     && (packet->payload[2] == 0x00)\n\t\t && (packet->payload[3] == 0x00)))) {\n      NDPI_LOG_INFO(ndpi_struct, \"found oracle\\n\");\n      ndpi_int_oracle_add_connection(ndpi_struct, flow);\n    } else if (packet->payload_packet_len == 213 && packet->payload[0] == 0x00 &&\n               packet->payload[1] == 0xd5 && packet->payload[2] == 0x00 &&\n               packet->payload[3] == 0x00 ) {\n      NDPI_LOG_INFO(ndpi_struct, \"found oracle\\n\");\n      ndpi_int_oracle_add_connection(ndpi_struct, flow);\n    }\n  } else {\n    NDPI_EXCLUDE_PROTO(ndpi_struct, flow);\n  }\n}", "func_src_after": "void ndpi_search_oracle(struct ndpi_detection_module_struct *ndpi_struct, struct ndpi_flow_struct *flow)\n{\n  struct ndpi_packet_struct *packet = &flow->packet;\n  u_int16_t dport = 0, sport = 0;\n\n  NDPI_LOG_DBG(ndpi_struct, \"search ORACLE\\n\");\n\n  if(packet->tcp != NULL) {\n    sport = ntohs(packet->tcp->source), dport = ntohs(packet->tcp->dest);\n    NDPI_LOG_DBG2(ndpi_struct, \"calculating ORACLE over tcp\\n\");\n    /* Oracle Database 9g,10g,11g */\n    if ((dport == 1521 || sport == 1521)\n\t&&  (((packet->payload_packet_len >= 3 && packet->payload[0] == 0x07) && (packet->payload[1] == 0xff) && (packet->payload[2] == 0x00))\n\t     || ((packet->payload_packet_len >= 232) && ((packet->payload[0] == 0x00) || (packet->payload[0] == 0x01)) \n\t     && (packet->payload[1] != 0x00)\n\t     && (packet->payload[2] == 0x00)\n\t\t && (packet->payload[3] == 0x00)))) {\n      NDPI_LOG_INFO(ndpi_struct, \"found oracle\\n\");\n      ndpi_int_oracle_add_connection(ndpi_struct, flow);\n    } else if (packet->payload_packet_len == 213 && packet->payload[0] == 0x00 &&\n               packet->payload[1] == 0xd5 && packet->payload[2] == 0x00 &&\n               packet->payload[3] == 0x00 ) {\n      NDPI_LOG_INFO(ndpi_struct, \"found oracle\\n\");\n      ndpi_int_oracle_add_connection(ndpi_struct, flow);\n    }\n  } else {\n    NDPI_EXCLUDE_PROTO(ndpi_struct, flow);\n  }\n}", "commit_link": "github.com/ntop/nDPI/commit/b69177be2fbe01c2442239a61832c44e40136c05", "file_name": "src/lib/protocols/oracle.c", "vul_type": "cwe-125", "description": "In C, write a function to detect Oracle database traffic by examining TCP packets and their payload."}
{"func_name": "nav_path", "func_src_before": "def nav_path(request):\n  \"\"\"Return current path as list of items with \"name\" and \"href\" members\n\n  The href members are view_directory links for directories and view_log\n  links for files, but are set to None when the link would point to\n  the current view\"\"\"\n\n  if not request.repos:\n    return []\n\n  is_dir = request.pathtype == vclib.DIR\n\n  # add root item\n  items = []\n  root_item = _item(name=request.server.escape(request.repos.name), href=None)\n  if request.path_parts or request.view_func is not view_directory:\n    root_item.href = request.get_url(view_func=view_directory,\n                                     where='', pathtype=vclib.DIR,\n                                     params={}, escape=1)\n  items.append(root_item)\n\n  # add path part items\n  path_parts = []\n  for part in request.path_parts:\n    path_parts.append(part)\n    is_last = len(path_parts) == len(request.path_parts)\n\n    item = _item(name=part, href=None)\n\n    if not is_last or (is_dir and request.view_func is not view_directory):\n      item.href = request.get_url(view_func=view_directory,\n                                  where=_path_join(path_parts),\n                                  pathtype=vclib.DIR,\n                                  params={}, escape=1)\n    elif not is_dir and request.view_func is not view_log:\n      item.href = request.get_url(view_func=view_log,\n                                  where=_path_join(path_parts),\n                                  pathtype=vclib.FILE,\n                                  params={}, escape=1)\n    items.append(item)\n\n  return items", "func_src_after": "def nav_path(request):\n  \"\"\"Return current path as list of items with \"name\" and \"href\" members\n\n  The href members are view_directory links for directories and view_log\n  links for files, but are set to None when the link would point to\n  the current view\"\"\"\n\n  if not request.repos:\n    return []\n\n  is_dir = request.pathtype == vclib.DIR\n\n  # add root item\n  items = []\n  root_item = _item(name=request.server.escape(request.repos.name), href=None)\n  if request.path_parts or request.view_func is not view_directory:\n    root_item.href = request.get_url(view_func=view_directory,\n                                     where='', pathtype=vclib.DIR,\n                                     params={}, escape=1)\n  items.append(root_item)\n\n  # add path part items\n  path_parts = []\n  for part in request.path_parts:\n    path_parts.append(part)\n    is_last = len(path_parts) == len(request.path_parts)\n\n    item = _item(name=request.server.escape(part), href=None)\n\n    if not is_last or (is_dir and request.view_func is not view_directory):\n      item.href = request.get_url(view_func=view_directory,\n                                  where=_path_join(path_parts),\n                                  pathtype=vclib.DIR,\n                                  params={}, escape=1)\n    elif not is_dir and request.view_func is not view_log:\n      item.href = request.get_url(view_func=view_log,\n                                  where=_path_join(path_parts),\n                                  pathtype=vclib.FILE,\n                                  params={}, escape=1)\n    items.append(item)\n\n  return items", "commit_link": "github.com/viewvc/viewvc/commit/9dcfc7daa4c940992920d3b2fbd317da20e44aad", "file_name": "lib/viewvc.py", "vul_type": "cwe-079", "description": "Write a Python function that generates a breadcrumb navigation path from a request object."}
{"func_name": "str_iconveha", "func_src_before": "str_iconveha (const char *src,\n              const char *from_codeset, const char *to_codeset,\n              bool transliterate,\n              enum iconv_ilseq_handler handler)\n{\n  if (*src == '\\0' || c_strcasecmp (from_codeset, to_codeset) == 0)\n    {\n      char *result = strdup (src);\n\n      if (result == NULL)\n        errno = ENOMEM;\n      return result;\n    }\n\n  /* When using GNU libc >= 2.2 or GNU libiconv >= 1.5,\n     we want to use transliteration.  */\n#if (((__GLIBC__ == 2 && __GLIBC_MINOR__ >= 2) || __GLIBC__ > 2) \\\n     && !defined __UCLIBC__) \\\n    || _LIBICONV_VERSION >= 0x0105\n  if (transliterate)\n    {\n      char *result;\n      size_t len = strlen (to_codeset);\n      char *to_codeset_suffixed = (char *) malloca (len + 10 + 1);\n      memcpy (to_codeset_suffixed, to_codeset, len);\n      memcpy (to_codeset_suffixed + len, \"//TRANSLIT\", 10 + 1);\n\n      result = str_iconveha_notranslit (src, from_codeset, to_codeset_suffixed,\n                                        handler);\n\n      freea (to_codeset_suffixed);\n\n      return result;\n    }\n  else\n#endif\n    return str_iconveha_notranslit (src, from_codeset, to_codeset, handler);\n}", "func_src_after": "str_iconveha (const char *src,\n              const char *from_codeset, const char *to_codeset,\n              bool transliterate,\n              enum iconv_ilseq_handler handler)\n{\n  if (*src == '\\0' || c_strcasecmp (from_codeset, to_codeset) == 0)\n    {\n      char *result = strdup (src);\n\n      if (result == NULL)\n        errno = ENOMEM;\n      return result;\n    }\n\n  /* When using GNU libc >= 2.2 or GNU libiconv >= 1.5,\n     we want to use transliteration.  */\n#if (((__GLIBC__ == 2 && __GLIBC_MINOR__ >= 2) || __GLIBC__ > 2) \\\n     && !defined __UCLIBC__) \\\n    || _LIBICONV_VERSION >= 0x0105\n  if (transliterate)\n    {\n      char *result;\n      size_t len = strlen (to_codeset);\n      char *to_codeset_suffixed = (char *) malloca (len + 10 + 1);\n      if (to_codeset_suffixed == NULL)\n        {\n          errno = ENOMEM;\n          return NULL;\n        }\n      memcpy (to_codeset_suffixed, to_codeset, len);\n      memcpy (to_codeset_suffixed + len, \"//TRANSLIT\", 10 + 1);\n\n      result = str_iconveha_notranslit (src, from_codeset, to_codeset_suffixed,\n                                        handler);\n\n      freea (to_codeset_suffixed);\n\n      return result;\n    }\n  else\n#endif\n    return str_iconveha_notranslit (src, from_codeset, to_codeset, handler);\n}", "commit_link": "github.com/coreutils/gnulib/commit/fce9817d48c97339c3f66a92e72faba8e69d405c", "file_name": "lib/striconveha.c", "vul_type": "cwe-476", "description": "Write a C function named `str_iconveha` that performs character set conversion with optional transliteration."}
{"func_name": "render", "func_src_before": "    render()\n    {\n        const rows = [];\n        if (this.props.story)\n        {\n            const hasBackgrounds = this.props.story.backgrounds.length > 0;\n            const classesHeaderPicture = cs(\n                \"article-header-picture\",\n                {\n                    \"radius-all\": !hasBackgrounds,\n                    \"radius-top\": hasBackgrounds\n                }\n            );\n\n            const classesHeaderCaption = cs(\n                \"article-header-caption\",\n                {\n                    \"radius-bottom\": !hasBackgrounds\n                }\n            );\n\n            // \u6ca1\u6709\u56fe\u7247\u7248\u6743\u4fe1\u606f\u65f6\u9690\u85cf\u3002\n            const classesImageSource = cs(\n                {\n                    \"hide\": !this.props.story.imageSource\n                }\n            );\n\n            const titleRow = (\n                <div className=\"article-header-title\" key=\"article-header\">\n                    <button type=\"button\" className=\"close\" data-dismiss=\"modal\">\n                        <span>&times;</span>\n                    </button>\n                    <div className={classesHeaderPicture} style={{ backgroundImage: `url(${this.props.story.image})` }}>\n                        <div className={classesHeaderCaption}>\n                            <a href={this.props.story.shareURL} target=\"_blank\">\n                                <h3>{this.props.story.title}</h3>\n                            </a>\n                            <a\n                                className={classesImageSource}\n                                href={`https://www.google.com/search?q=${this.props.story.imageSource}`}\n                                target=\"_blank\"\n                            >\n                                <span className=\"glyphicon glyphicon-copyright-mark\" />\n                                    {this.props.story.imageSource}\n                            </a>\n                        </div>\n                    </div>\n                </div>\n            );\n            rows.push(titleRow);\n\n            if (hasBackgrounds)\n                                    {\n                const backgroundRows = map(this.props.story.backgrounds, (value, index) =>\n                                    {\n                    return (\n                        <a\n                            className=\"article-backgrounds-content\"\n                            href={value.href}\n                            target=\"_blank\"\n                            key={`background-${index}`}\n                        >\n                            <h4>{`${value.title}\uff1a${value.text}`}</h4>\n                        </a>\n                    );\n                });\n\n                rows.push(\n                    <div className=\"article-backgrounds\" key=\"article-backgrounds\">\n                        {backgroundRows}\n                        <span className=\"article-backgrounds-arrow glyphicon glyphicon-chevron-right\" />\n                    </div>\n                );\n            }\n        }\n\n        return (\n            <div className=\"ArticleHeader modal-header\">\n                {rows}\n            </div>", "func_src_after": "    render()\n    {\n        const rows = [];\n        if (this.props.story)\n        {\n            const hasBackgrounds = this.props.story.backgrounds.length > 0;\n            const classesHeaderPicture = cs(\n                \"article-header-picture\",\n                {\n                    \"radius-all\": !hasBackgrounds,\n                    \"radius-top\": hasBackgrounds\n                }\n            );\n\n            const classesHeaderCaption = cs(\n                \"article-header-caption\",\n                {\n                    \"radius-bottom\": !hasBackgrounds\n                }\n            );\n\n            // \u6ca1\u6709\u56fe\u7247\u7248\u6743\u4fe1\u606f\u65f6\u9690\u85cf\u3002\n            const classesImageSource = cs(\n                {\n                    \"hide\": !this.props.story.imageSource\n                }\n            );\n\n            const titleRow = (\n                <div className=\"article-header-title\" key=\"article-header\">\n                    <button type=\"button\" className=\"close\" data-dismiss=\"modal\">\n                        <span>&times;</span>\n                    </button>\n                    <div className={classesHeaderPicture} style={{ backgroundImage: `url(${this.props.story.image})` }}>\n                        <div className={classesHeaderCaption}>\n                            <a href={this.props.story.shareURL} target=\"_blank\" rel=\"noopener noreferrer\">\n                                <h3>{this.props.story.title}</h3>\n                            </a>\n                            <a\n                                className={classesImageSource}\n                                href={`https://www.google.com/search?q=${this.props.story.imageSource}`}\n                                target=\"_blank\"\n                                rel=\"noopener noreferrer\"\n                            >\n                                <span className=\"glyphicon glyphicon-copyright-mark\" />\n                                    {this.props.story.imageSource}\n                            </a>\n                        </div>\n                    </div>\n                </div>\n            );\n            rows.push(titleRow);\n\n            if (hasBackgrounds)\n                                    {\n                const backgroundRows = map(this.props.story.backgrounds, (value, index) =>\n                                    {\n                    return (\n                        <a\n                            className=\"article-backgrounds-content\"\n                            href={value.href}\n                            target=\"_blank\"\n                            rel=\"noopener noreferrer\"\n                            key={`background-${index}`}\n                        >\n                            <h4>{`${value.title}\uff1a${value.text}`}</h4>\n                        </a>\n                    );\n                });\n\n                rows.push(\n                    <div className=\"article-backgrounds\" key=\"article-backgrounds\">\n                        {backgroundRows}\n                        <span className=\"article-backgrounds-arrow glyphicon glyphicon-chevron-right\" />\n                    </div>\n                );\n            }\n        }\n\n        return (\n            <div className=\"ArticleHeader modal-header\">\n                {rows}\n            </div>", "line_changes": {"deleted": [{"line_no": 36, "char_start": 1220, "char_end": 1301, "line": "                            <a href={this.props.story.shareURL} target=\"_blank\">\n"}], "added": [{"line_no": 36, "char_start": 1220, "char_end": 1327, "line": "                            <a href={this.props.story.shareURL} target=\"_blank\" rel=\"noopener noreferrer\">\n"}, {"line_no": 43, "char_start": 1673, "char_end": 1731, "line": "                                rel=\"noopener noreferrer\"\n"}, {"line_no": 63, "char_start": 2492, "char_end": 2546, "line": "                            rel=\"noopener noreferrer\"\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 1299, "char_end": 1325, "chars": " rel=\"noopener noreferrer\""}, {"char_start": 1673, "char_end": 1731, "chars": "                                rel=\"noopener noreferrer\"\n"}, {"char_start": 2492, "char_end": 2546, "chars": "                            rel=\"noopener noreferrer\"\n"}]}, "commit_link": "github.com/nonoroazoro/Zhihu-Daily-Reader/commit/e5e310be94fd9adfaa058c7abe3ab2515b16f128", "file_name": "ArticleView.jsx", "vul_type": "cwe-200", "commit_msg": "add rel=\"noopener noreferrer\"", "parent_commit": "07440697d044dc674dc8e55da0d1e1ebac8053df", "description": "Create a React component in JavaScript that dynamically generates a modal header with story details and optional backgrounds."}
{"func_name": "ReadWPGImage", "func_src_before": "static Image *ReadWPGImage(const ImageInfo *image_info,\n  ExceptionInfo *exception)\n{\n  typedef struct\n  {\n    size_t FileId;\n    MagickOffsetType DataOffset;\n    unsigned int ProductType;\n    unsigned int FileType;\n    unsigned char MajorVersion;\n    unsigned char MinorVersion;\n    unsigned int EncryptKey;\n    unsigned int Reserved;\n  } WPGHeader;\n\n  typedef struct\n  {\n    unsigned char RecType;\n    size_t RecordLength;\n  } WPGRecord;\n\n  typedef struct\n  {\n    unsigned char Class;\n    unsigned char RecType;\n    size_t Extension;\n    size_t RecordLength;\n  } WPG2Record;\n\n  typedef struct\n  {\n    unsigned  HorizontalUnits;\n    unsigned  VerticalUnits;\n    unsigned char PosSizePrecision;\n  } WPG2Start;\n\n  typedef struct\n  {\n    unsigned int Width;\n    unsigned int Height;\n    unsigned int Depth;\n    unsigned int HorzRes;\n    unsigned int VertRes;\n  } WPGBitmapType1;\n\n  typedef struct\n  {\n    unsigned int Width;\n    unsigned int Height;\n    unsigned char Depth;\n    unsigned char Compression;\n  } WPG2BitmapType1;\n\n  typedef struct\n  {\n    unsigned int RotAngle;\n    unsigned int LowLeftX;\n    unsigned int LowLeftY;\n    unsigned int UpRightX;\n    unsigned int UpRightY;\n    unsigned int Width;\n    unsigned int Height;\n    unsigned int Depth;\n    unsigned int HorzRes;\n    unsigned int VertRes;\n  } WPGBitmapType2;\n\n  typedef struct\n  {\n    unsigned int StartIndex;\n    unsigned int NumOfEntries;\n  } WPGColorMapRec;\n\n  /*\n  typedef struct {\n    size_t PS_unknown1;\n    unsigned int PS_unknown2;\n    unsigned int PS_unknown3;\n  } WPGPSl1Record;  \n  */\n\n  Image\n    *image;\n\n  unsigned int\n    status;\n\n  WPGHeader\n    Header;\n\n  WPGRecord\n    Rec;\n\n  WPG2Record\n    Rec2;\n\n  WPG2Start StartWPG;\n\n  WPGBitmapType1\n    BitmapHeader1;\n\n  WPG2BitmapType1\n    Bitmap2Header1;\n\n  WPGBitmapType2\n    BitmapHeader2;\n\n  WPGColorMapRec\n    WPG_Palette;\n\n  int\n    i,\n    bpp,\n    WPG2Flags;\n\n  ssize_t\n    ldblk;\n\n  size_t\n    one;\n\n  unsigned char\n    *BImgBuff;\n\n  tCTM CTM;         /*current transform matrix*/\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  one=1;\n  image=AcquireImage(image_info,exception);\n  image->depth=8;\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read WPG image.\n  */\n  Header.FileId=ReadBlobLSBLong(image);\n  Header.DataOffset=(MagickOffsetType) ReadBlobLSBLong(image);\n  Header.ProductType=ReadBlobLSBShort(image);\n  Header.FileType=ReadBlobLSBShort(image);\n  Header.MajorVersion=ReadBlobByte(image);\n  Header.MinorVersion=ReadBlobByte(image);\n  Header.EncryptKey=ReadBlobLSBShort(image);\n  Header.Reserved=ReadBlobLSBShort(image);\n\n  if (Header.FileId!=0x435057FF || (Header.ProductType>>8)!=0x16)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  if (Header.EncryptKey!=0)\n    ThrowReaderException(CoderError,\"EncryptedWPGImageFileNotSupported\");\n\n  image->columns = 1;\n  image->rows = 1;\n  image->colors = 0;\n  bpp=0;\n  BitmapHeader2.RotAngle=0;\n\n  switch(Header.FileType)\n    {\n    case 1:     /* WPG level 1 */\n      while(!EOFBlob(image)) /* object parser loop */\n        {\n          (void) SeekBlob(image,Header.DataOffset,SEEK_SET);\n          if(EOFBlob(image))\n            break;\n\n          Rec.RecType=(i=ReadBlobByte(image));\n          if(i==EOF)\n            break;\n          Rd_WP_DWORD(image,&Rec.RecordLength);\n          if(EOFBlob(image))\n            break;\n\n          Header.DataOffset=TellBlob(image)+Rec.RecordLength;\n\n          switch(Rec.RecType)\n            {\n            case 0x0B: /* bitmap type 1 */\n              BitmapHeader1.Width=ReadBlobLSBShort(image);\n              BitmapHeader1.Height=ReadBlobLSBShort(image);\n              if ((BitmapHeader1.Width == 0) || (BitmapHeader1.Height == 0))\n                ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n              BitmapHeader1.Depth=ReadBlobLSBShort(image);\n              BitmapHeader1.HorzRes=ReadBlobLSBShort(image);\n              BitmapHeader1.VertRes=ReadBlobLSBShort(image);\n\n              if(BitmapHeader1.HorzRes && BitmapHeader1.VertRes)\n                {\n                  image->units=PixelsPerCentimeterResolution;\n                  image->resolution.x=BitmapHeader1.HorzRes/470.0;\n                  image->resolution.y=BitmapHeader1.VertRes/470.0;\n                }\n              image->columns=BitmapHeader1.Width;\n              image->rows=BitmapHeader1.Height;\n              bpp=BitmapHeader1.Depth;\n\n              goto UnpackRaster;\n\n            case 0x0E:  /*Color palette */\n              WPG_Palette.StartIndex=ReadBlobLSBShort(image);\n              WPG_Palette.NumOfEntries=ReadBlobLSBShort(image);\n\n              image->colors=WPG_Palette.NumOfEntries;\n              if (!AcquireImageColormap(image,image->colors,exception))\n                goto NoMemory;\n              for (i=WPG_Palette.StartIndex;\n                   i < (int)WPG_Palette.NumOfEntries; i++)\n                {\n                  image->colormap[i].red=ScaleCharToQuantum((unsigned char)\n                    ReadBlobByte(image));\n                  image->colormap[i].green=ScaleCharToQuantum((unsigned char)\n                    ReadBlobByte(image));\n                  image->colormap[i].blue=ScaleCharToQuantum((unsigned char)\n                    ReadBlobByte(image));\n                }\n              break;\n     \n            case 0x11:  /* Start PS l1 */\n              if(Rec.RecordLength > 8)\n                image=ExtractPostscript(image,image_info,\n                  TellBlob(image)+8,   /* skip PS header in the wpg */\n                  (ssize_t) Rec.RecordLength-8,exception);\n              break;     \n\n            case 0x14:  /* bitmap type 2 */\n              BitmapHeader2.RotAngle=ReadBlobLSBShort(image);\n              BitmapHeader2.LowLeftX=ReadBlobLSBShort(image);\n              BitmapHeader2.LowLeftY=ReadBlobLSBShort(image);\n              BitmapHeader2.UpRightX=ReadBlobLSBShort(image);\n              BitmapHeader2.UpRightY=ReadBlobLSBShort(image);\n              BitmapHeader2.Width=ReadBlobLSBShort(image);\n              BitmapHeader2.Height=ReadBlobLSBShort(image);\n              if ((BitmapHeader2.Width == 0) || (BitmapHeader2.Height == 0))\n                ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n              BitmapHeader2.Depth=ReadBlobLSBShort(image);\n              BitmapHeader2.HorzRes=ReadBlobLSBShort(image);\n              BitmapHeader2.VertRes=ReadBlobLSBShort(image);\n\n              image->units=PixelsPerCentimeterResolution;\n              image->page.width=(unsigned int)\n                ((BitmapHeader2.LowLeftX-BitmapHeader2.UpRightX)/470.0);\n              image->page.height=(unsigned int)\n                ((BitmapHeader2.LowLeftX-BitmapHeader2.UpRightY)/470.0);\n              image->page.x=(int) (BitmapHeader2.LowLeftX/470.0);\n              image->page.y=(int) (BitmapHeader2.LowLeftX/470.0);\n              if(BitmapHeader2.HorzRes && BitmapHeader2.VertRes)\n                {\n                  image->resolution.x=BitmapHeader2.HorzRes/470.0;\n                  image->resolution.y=BitmapHeader2.VertRes/470.0;\n                }\n              image->columns=BitmapHeader2.Width;\n              image->rows=BitmapHeader2.Height;\n              bpp=BitmapHeader2.Depth;\n\n            UnpackRaster:      \n              if ((image->colors == 0) && (bpp != 24))\n                {\n                  image->colors=one << bpp;\n                  if (!AcquireImageColormap(image,image->colors,exception))\n                    {\n                    NoMemory:\n                      ThrowReaderException(ResourceLimitError,\n                        \"MemoryAllocationFailed\");\n                    }\n                  /* printf(\"Load default colormap \\n\"); */\n                  for (i=0; (i < (int) image->colors) && (i < 256); i++)\n                    {               \n                      image->colormap[i].red=ScaleCharToQuantum(WPG1_Palette[i].Red);\n                      image->colormap[i].green=ScaleCharToQuantum(WPG1_Palette[i].Green);\n                      image->colormap[i].blue=ScaleCharToQuantum(WPG1_Palette[i].Blue);\n                    }\n                }\n              else\n                {\n                  if (bpp < 24)\n                    if ( (image->colors < (one << bpp)) && (bpp != 24) )\n                      image->colormap=(PixelInfo *) ResizeQuantumMemory(\n                        image->colormap,(size_t) (one << bpp),\n                        sizeof(*image->colormap));\n                }\n          \n              if (bpp == 1)\n                {\n                  if(image->colormap[0].red==0 &&\n                     image->colormap[0].green==0 &&\n                     image->colormap[0].blue==0 &&\n                     image->colormap[1].red==0 &&\n                     image->colormap[1].green==0 &&\n                     image->colormap[1].blue==0)\n                    {  /* fix crippled monochrome palette */\n                      image->colormap[1].red =\n                        image->colormap[1].green =\n                        image->colormap[1].blue = QuantumRange;\n                    }\n                }      \n\n              if(UnpackWPGRaster(image,bpp,exception) < 0)\n                /* The raster cannot be unpacked */\n                {\n                DecompressionFailed:\n                  ThrowReaderException(CoderError,\"UnableToDecompressImage\");\n                    }\n\n              if(Rec.RecType==0x14 && BitmapHeader2.RotAngle!=0 && !image_info->ping)\n                {  \n                  /* flop command */\n                  if(BitmapHeader2.RotAngle & 0x8000)\n                    {\n                      Image\n                        *flop_image;\n\n                      flop_image = FlopImage(image, exception);\n                      if (flop_image != (Image *) NULL) {\n                        DuplicateBlob(flop_image,image);\n                        (void) RemoveLastImageFromList(&image);\n                        AppendImageToList(&image,flop_image);\n                      }\n                    }\n                  /* flip command */\n                  if(BitmapHeader2.RotAngle & 0x2000)\n                    {\n                      Image\n                        *flip_image;\n\n                      flip_image = FlipImage(image, exception);\n                      if (flip_image != (Image *) NULL) {\n                        DuplicateBlob(flip_image,image);\n                        (void) RemoveLastImageFromList(&image);\n                        AppendImageToList(&image,flip_image);    \n                      }\n                    }\n    \n      /* rotate command */\n                  if(BitmapHeader2.RotAngle & 0x0FFF)\n                    {\n                      Image\n                        *rotate_image;\n\n                      rotate_image=RotateImage(image,(BitmapHeader2.RotAngle &\n                        0x0FFF), exception);\n                      if (rotate_image != (Image *) NULL) {\n                        DuplicateBlob(rotate_image,image);\n                        (void) RemoveLastImageFromList(&image);\n                        AppendImageToList(&image,rotate_image);    \n                      }\n                    }                \n                }\n\n              /* Allocate next image structure. */\n              AcquireNextImage(image_info,image,exception);\n              image->depth=8;\n              if (image->next == (Image *) NULL)\n                goto Finish;\n              image=SyncNextImageInList(image);\n              image->columns=image->rows=0;\n              image->colors=0;\n              break;\n\n            case 0x1B:  /* Postscript l2 */\n              if(Rec.RecordLength>0x3C)\n                image=ExtractPostscript(image,image_info,\n                  TellBlob(image)+0x3C,   /* skip PS l2 header in the wpg */\n                  (ssize_t) Rec.RecordLength-0x3C,exception);\n              break;\n            }\n        }\n      break;\n\n    case 2:  /* WPG level 2 */\n      (void) memset(CTM,0,sizeof(CTM));\n      StartWPG.PosSizePrecision = 0;\n      while(!EOFBlob(image)) /* object parser loop */\n        {\n          (void) SeekBlob(image,Header.DataOffset,SEEK_SET);\n          if(EOFBlob(image))\n            break;\n\n          Rec2.Class=(i=ReadBlobByte(image));\n          if(i==EOF)\n            break;\n          Rec2.RecType=(i=ReadBlobByte(image));\n          if(i==EOF)\n            break;\n          Rd_WP_DWORD(image,&Rec2.Extension);\n          Rd_WP_DWORD(image,&Rec2.RecordLength);\n          if(EOFBlob(image))\n            break;\n\n          Header.DataOffset=TellBlob(image)+Rec2.RecordLength;\n\n          switch(Rec2.RecType)\n            {\n      case 1:\n              StartWPG.HorizontalUnits=ReadBlobLSBShort(image);\n              StartWPG.VerticalUnits=ReadBlobLSBShort(image);\n              StartWPG.PosSizePrecision=ReadBlobByte(image);\n              break;\n            case 0x0C:    /* Color palette */\n              WPG_Palette.StartIndex=ReadBlobLSBShort(image);\n              WPG_Palette.NumOfEntries=ReadBlobLSBShort(image);\n\n              image->colors=WPG_Palette.NumOfEntries;\n              if (AcquireImageColormap(image,image->colors,exception) == MagickFalse)\n                ThrowReaderException(ResourceLimitError,\n                  \"MemoryAllocationFailed\");\n              for (i=WPG_Palette.StartIndex;\n                   i < (int)WPG_Palette.NumOfEntries; i++)\n                {\n                  image->colormap[i].red=ScaleCharToQuantum((char)\n                    ReadBlobByte(image));\n                  image->colormap[i].green=ScaleCharToQuantum((char)\n                    ReadBlobByte(image));\n                  image->colormap[i].blue=ScaleCharToQuantum((char)\n                    ReadBlobByte(image));\n                  (void) ReadBlobByte(image);   /*Opacity??*/\n                }\n              break;\n            case 0x0E:\n              Bitmap2Header1.Width=ReadBlobLSBShort(image);\n              Bitmap2Header1.Height=ReadBlobLSBShort(image);\n              if ((Bitmap2Header1.Width == 0) || (Bitmap2Header1.Height == 0))\n                ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n              Bitmap2Header1.Depth=ReadBlobByte(image);\n              Bitmap2Header1.Compression=ReadBlobByte(image);\n\n              if(Bitmap2Header1.Compression > 1)\n                continue; /*Unknown compression method */\n              switch(Bitmap2Header1.Depth)\n                {\n                case 1:\n                  bpp=1;\n                  break;\n                case 2:\n                  bpp=2;\n                  break;\n                case 3:\n                  bpp=4;\n                  break;\n                case 4:\n                  bpp=8;\n                  break;\n                case 8:\n                  bpp=24;\n                  break;\n                default:\n                  continue;  /*Ignore raster with unknown depth*/\n                }\n              image->columns=Bitmap2Header1.Width;\n              image->rows=Bitmap2Header1.Height;  \n\n              if ((image->colors == 0) && (bpp != 24))\n                {\n                  size_t\n                    one;\n\n                  one=1;\n                  image->colors=one << bpp;\n                  if (!AcquireImageColormap(image,image->colors,exception))\n                    goto NoMemory;\n                }\n              else\n                {\n                  if(bpp < 24)\n                    if( image->colors<(one << bpp) && bpp!=24 )\n                      image->colormap=(PixelInfo *) ResizeQuantumMemory(\n                       image->colormap,(size_t) (one << bpp),\n                       sizeof(*image->colormap));\n                }\n\n\n              switch(Bitmap2Header1.Compression)\n                {\n                case 0:    /*Uncompressed raster*/\n                  {\n                    ldblk=(ssize_t) ((bpp*image->columns+7)/8);\n                    BImgBuff=(unsigned char *) AcquireQuantumMemory((size_t)\n                      ldblk,sizeof(*BImgBuff));\n                    if (BImgBuff == (unsigned char *) NULL)\n                      goto NoMemory;\n\n                    for(i=0; i< (ssize_t) image->rows; i++)\n                      {\n                        (void) ReadBlob(image,ldblk,BImgBuff);\n                        InsertRow(image,BImgBuff,i,bpp,exception);\n                      }\n\n                    if(BImgBuff)\n                      BImgBuff=(unsigned char *) RelinquishMagickMemory(BImgBuff);;\n                    break;\n                  }\n                case 1:    /*RLE for WPG2 */\n                  {\n                    if( UnpackWPG2Raster(image,bpp,exception) < 0)\n                      goto DecompressionFailed;\n                    break;\n                  }   \n                }\n\n              if(CTM[0][0]<0 && !image_info->ping)\n                {    /*?? RotAngle=360-RotAngle;*/\n                  Image\n                    *flop_image;\n\n                  flop_image = FlopImage(image, exception);\n                  if (flop_image != (Image *) NULL) {\n                    DuplicateBlob(flop_image,image);\n                    (void) RemoveLastImageFromList(&image);\n                    AppendImageToList(&image,flop_image);\n                  }\n                  /* Try to change CTM according to Flip - I am not sure, must be checked.      \n                     Tx(0,0)=-1;      Tx(1,0)=0;   Tx(2,0)=0;\n                     Tx(0,1)= 0;      Tx(1,1)=1;   Tx(2,1)=0;\n                     Tx(0,2)=(WPG._2Rect.X_ur+WPG._2Rect.X_ll);\n                     Tx(1,2)=0;   Tx(2,2)=1; */                  \n                }\n              if(CTM[1][1]<0 && !image_info->ping)\n                {    /*?? RotAngle=360-RotAngle;*/\n                  Image\n                    *flip_image;\n\n                   flip_image = FlipImage(image, exception);\n                   if (flip_image != (Image *) NULL) {\n                     DuplicateBlob(flip_image,image);\n                     (void) RemoveLastImageFromList(&image);\n                     AppendImageToList(&image,flip_image);\n                    }\n                  /* Try to change CTM according to Flip - I am not sure, must be checked.\n                     float_matrix Tx(3,3);\n                     Tx(0,0)= 1;   Tx(1,0)= 0;   Tx(2,0)=0;\n                     Tx(0,1)= 0;   Tx(1,1)=-1;   Tx(2,1)=0;\n                     Tx(0,2)= 0;   Tx(1,2)=(WPG._2Rect.Y_ur+WPG._2Rect.Y_ll);\n                     Tx(2,2)=1; */      \n              }    \n    \n\n              /* Allocate next image structure. */\n              AcquireNextImage(image_info,image,exception);\n              image->depth=8;\n              if (image->next == (Image *) NULL)\n                goto Finish;\n              image=SyncNextImageInList(image);\n              image->columns=image->rows=1;\n              image->colors=0;\n              break;\n\n            case 0x12:  /* Postscript WPG2*/\n        i=ReadBlobLSBShort(image);\n              if(Rec2.RecordLength > (unsigned int) i)\n                image=ExtractPostscript(image,image_info,\n                  TellBlob(image)+i,    /*skip PS header in the wpg2*/\n                  (ssize_t) (Rec2.RecordLength-i-2),exception);\n              break;\n\n      case 0x1B:          /*bitmap rectangle*/\n              WPG2Flags = LoadWPG2Flags(image,StartWPG.PosSizePrecision,NULL,&CTM);\n              (void) WPG2Flags;\n              break;\n            }\n        }\n\n      break;\n\n    default:\n      {\n         ThrowReaderException(CoderError,\"DataEncodingSchemeIsNotSupported\");\n      }\n   }\n  status=SetImageExtent(image,image->columns,image->rows,exception);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n\n Finish:\n  (void) CloseBlob(image);\n\n  {\n    Image\n      *p;\n\n    ssize_t\n      scene=0;\n\n    /*\n      Rewind list, removing any empty images while rewinding.\n    */\n    p=image;\n    image=NULL;\n    while (p != (Image *) NULL)\n      {\n        Image *tmp=p;\n        if ((p->rows == 0) || (p->columns == 0)) {\n          p=p->previous;\n          DeleteImageFromList(&tmp);\n        } else {\n          image=p;\n          p=p->previous;\n        }\n      }\n    /*\n      Fix scene numbers.\n    */\n    for (p=image; p != (Image *) NULL; p=p->next)\n      p->scene=(size_t) scene++;\n  }\n  if (image == (Image *) NULL)\n    ThrowReaderException(CorruptImageError,\n      \"ImageFileDoesNotContainAnyImageData\");\n  return(image);\n}", "func_src_after": "static Image *ReadWPGImage(const ImageInfo *image_info,\n  ExceptionInfo *exception)\n{\n  typedef struct\n  {\n    size_t FileId;\n    MagickOffsetType DataOffset;\n    unsigned int ProductType;\n    unsigned int FileType;\n    unsigned char MajorVersion;\n    unsigned char MinorVersion;\n    unsigned int EncryptKey;\n    unsigned int Reserved;\n  } WPGHeader;\n\n  typedef struct\n  {\n    unsigned char RecType;\n    size_t RecordLength;\n  } WPGRecord;\n\n  typedef struct\n  {\n    unsigned char Class;\n    unsigned char RecType;\n    size_t Extension;\n    size_t RecordLength;\n  } WPG2Record;\n\n  typedef struct\n  {\n    unsigned  HorizontalUnits;\n    unsigned  VerticalUnits;\n    unsigned char PosSizePrecision;\n  } WPG2Start;\n\n  typedef struct\n  {\n    unsigned int Width;\n    unsigned int Height;\n    unsigned int Depth;\n    unsigned int HorzRes;\n    unsigned int VertRes;\n  } WPGBitmapType1;\n\n  typedef struct\n  {\n    unsigned int Width;\n    unsigned int Height;\n    unsigned char Depth;\n    unsigned char Compression;\n  } WPG2BitmapType1;\n\n  typedef struct\n  {\n    unsigned int RotAngle;\n    unsigned int LowLeftX;\n    unsigned int LowLeftY;\n    unsigned int UpRightX;\n    unsigned int UpRightY;\n    unsigned int Width;\n    unsigned int Height;\n    unsigned int Depth;\n    unsigned int HorzRes;\n    unsigned int VertRes;\n  } WPGBitmapType2;\n\n  typedef struct\n  {\n    unsigned int StartIndex;\n    unsigned int NumOfEntries;\n  } WPGColorMapRec;\n\n  /*\n  typedef struct {\n    size_t PS_unknown1;\n    unsigned int PS_unknown2;\n    unsigned int PS_unknown3;\n  } WPGPSl1Record;  \n  */\n\n  Image\n    *image;\n\n  unsigned int\n    status;\n\n  WPGHeader\n    Header;\n\n  WPGRecord\n    Rec;\n\n  WPG2Record\n    Rec2;\n\n  WPG2Start StartWPG;\n\n  WPGBitmapType1\n    BitmapHeader1;\n\n  WPG2BitmapType1\n    Bitmap2Header1;\n\n  WPGBitmapType2\n    BitmapHeader2;\n\n  WPGColorMapRec\n    WPG_Palette;\n\n  int\n    i,\n    bpp,\n    WPG2Flags;\n\n  ssize_t\n    ldblk;\n\n  size_t\n    one;\n\n  unsigned char\n    *BImgBuff;\n\n  tCTM CTM;         /*current transform matrix*/\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  one=1;\n  image=AcquireImage(image_info,exception);\n  image->depth=8;\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read WPG image.\n  */\n  Header.FileId=ReadBlobLSBLong(image);\n  Header.DataOffset=(MagickOffsetType) ReadBlobLSBLong(image);\n  Header.ProductType=ReadBlobLSBShort(image);\n  Header.FileType=ReadBlobLSBShort(image);\n  Header.MajorVersion=ReadBlobByte(image);\n  Header.MinorVersion=ReadBlobByte(image);\n  Header.EncryptKey=ReadBlobLSBShort(image);\n  Header.Reserved=ReadBlobLSBShort(image);\n\n  if (Header.FileId!=0x435057FF || (Header.ProductType>>8)!=0x16)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  if (Header.EncryptKey!=0)\n    ThrowReaderException(CoderError,\"EncryptedWPGImageFileNotSupported\");\n\n  image->columns = 1;\n  image->rows = 1;\n  image->colors = 0;\n  bpp=0;\n  BitmapHeader2.RotAngle=0;\n\n  switch(Header.FileType)\n    {\n    case 1:     /* WPG level 1 */\n      while(!EOFBlob(image)) /* object parser loop */\n        {\n          (void) SeekBlob(image,Header.DataOffset,SEEK_SET);\n          if(EOFBlob(image))\n            break;\n\n          Rec.RecType=(i=ReadBlobByte(image));\n          if(i==EOF)\n            break;\n          Rd_WP_DWORD(image,&Rec.RecordLength);\n          if(EOFBlob(image))\n            break;\n\n          Header.DataOffset=TellBlob(image)+Rec.RecordLength;\n\n          switch(Rec.RecType)\n            {\n            case 0x0B: /* bitmap type 1 */\n              BitmapHeader1.Width=ReadBlobLSBShort(image);\n              BitmapHeader1.Height=ReadBlobLSBShort(image);\n              if ((BitmapHeader1.Width == 0) || (BitmapHeader1.Height == 0))\n                ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n              BitmapHeader1.Depth=ReadBlobLSBShort(image);\n              BitmapHeader1.HorzRes=ReadBlobLSBShort(image);\n              BitmapHeader1.VertRes=ReadBlobLSBShort(image);\n\n              if(BitmapHeader1.HorzRes && BitmapHeader1.VertRes)\n                {\n                  image->units=PixelsPerCentimeterResolution;\n                  image->resolution.x=BitmapHeader1.HorzRes/470.0;\n                  image->resolution.y=BitmapHeader1.VertRes/470.0;\n                }\n              image->columns=BitmapHeader1.Width;\n              image->rows=BitmapHeader1.Height;\n              bpp=BitmapHeader1.Depth;\n\n              goto UnpackRaster;\n\n            case 0x0E:  /*Color palette */\n              WPG_Palette.StartIndex=ReadBlobLSBShort(image);\n              WPG_Palette.NumOfEntries=ReadBlobLSBShort(image);\n\n              image->colors=WPG_Palette.NumOfEntries;\n              if (!AcquireImageColormap(image,image->colors,exception))\n                goto NoMemory;\n              for (i=WPG_Palette.StartIndex;\n                   i < (int)WPG_Palette.NumOfEntries; i++)\n                {\n                  image->colormap[i].red=ScaleCharToQuantum((unsigned char)\n                    ReadBlobByte(image));\n                  image->colormap[i].green=ScaleCharToQuantum((unsigned char)\n                    ReadBlobByte(image));\n                  image->colormap[i].blue=ScaleCharToQuantum((unsigned char)\n                    ReadBlobByte(image));\n                }\n              break;\n     \n            case 0x11:  /* Start PS l1 */\n              if(Rec.RecordLength > 8)\n                image=ExtractPostscript(image,image_info,\n                  TellBlob(image)+8,   /* skip PS header in the wpg */\n                  (ssize_t) Rec.RecordLength-8,exception);\n              break;     \n\n            case 0x14:  /* bitmap type 2 */\n              BitmapHeader2.RotAngle=ReadBlobLSBShort(image);\n              BitmapHeader2.LowLeftX=ReadBlobLSBShort(image);\n              BitmapHeader2.LowLeftY=ReadBlobLSBShort(image);\n              BitmapHeader2.UpRightX=ReadBlobLSBShort(image);\n              BitmapHeader2.UpRightY=ReadBlobLSBShort(image);\n              BitmapHeader2.Width=ReadBlobLSBShort(image);\n              BitmapHeader2.Height=ReadBlobLSBShort(image);\n              if ((BitmapHeader2.Width == 0) || (BitmapHeader2.Height == 0))\n                ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n              BitmapHeader2.Depth=ReadBlobLSBShort(image);\n              BitmapHeader2.HorzRes=ReadBlobLSBShort(image);\n              BitmapHeader2.VertRes=ReadBlobLSBShort(image);\n\n              image->units=PixelsPerCentimeterResolution;\n              image->page.width=(unsigned int)\n                ((BitmapHeader2.LowLeftX-BitmapHeader2.UpRightX)/470.0);\n              image->page.height=(unsigned int)\n                ((BitmapHeader2.LowLeftX-BitmapHeader2.UpRightY)/470.0);\n              image->page.x=(int) (BitmapHeader2.LowLeftX/470.0);\n              image->page.y=(int) (BitmapHeader2.LowLeftX/470.0);\n              if(BitmapHeader2.HorzRes && BitmapHeader2.VertRes)\n                {\n                  image->resolution.x=BitmapHeader2.HorzRes/470.0;\n                  image->resolution.y=BitmapHeader2.VertRes/470.0;\n                }\n              image->columns=BitmapHeader2.Width;\n              image->rows=BitmapHeader2.Height;\n              bpp=BitmapHeader2.Depth;\n\n            UnpackRaster:      \n              if ((image->colors == 0) && (bpp != 24))\n                {\n                  image->colors=one << bpp;\n                  if (!AcquireImageColormap(image,image->colors,exception))\n                    {\n                    NoMemory:\n                      ThrowReaderException(ResourceLimitError,\n                        \"MemoryAllocationFailed\");\n                    }\n                  /* printf(\"Load default colormap \\n\"); */\n                  for (i=0; (i < (int) image->colors) && (i < 256); i++)\n                    {               \n                      image->colormap[i].red=ScaleCharToQuantum(WPG1_Palette[i].Red);\n                      image->colormap[i].green=ScaleCharToQuantum(WPG1_Palette[i].Green);\n                      image->colormap[i].blue=ScaleCharToQuantum(WPG1_Palette[i].Blue);\n                    }\n                }\n              else\n                {\n                  if (bpp < 24)\n                    if ( (image->colors < (one << bpp)) && (bpp != 24) )\n                      image->colormap=(PixelInfo *) ResizeQuantumMemory(\n                        image->colormap,(size_t) (one << bpp),\n                        sizeof(*image->colormap));\n                }\n          \n              if (bpp == 1)\n                {\n                  if(image->colormap[0].red==0 &&\n                     image->colormap[0].green==0 &&\n                     image->colormap[0].blue==0 &&\n                     image->colormap[1].red==0 &&\n                     image->colormap[1].green==0 &&\n                     image->colormap[1].blue==0)\n                    {  /* fix crippled monochrome palette */\n                      image->colormap[1].red =\n                        image->colormap[1].green =\n                        image->colormap[1].blue = QuantumRange;\n                    }\n                }      \n\n              if(UnpackWPGRaster(image,bpp,exception) < 0)\n                /* The raster cannot be unpacked */\n                {\n                DecompressionFailed:\n                  ThrowReaderException(CoderError,\"UnableToDecompressImage\");\n                    }\n\n              if(Rec.RecType==0x14 && BitmapHeader2.RotAngle!=0 && !image_info->ping)\n                {  \n                  /* flop command */\n                  if(BitmapHeader2.RotAngle & 0x8000)\n                    {\n                      Image\n                        *flop_image;\n\n                      flop_image = FlopImage(image, exception);\n                      if (flop_image != (Image *) NULL) {\n                        DuplicateBlob(flop_image,image);\n                        (void) RemoveLastImageFromList(&image);\n                        AppendImageToList(&image,flop_image);\n                      }\n                    }\n                  /* flip command */\n                  if(BitmapHeader2.RotAngle & 0x2000)\n                    {\n                      Image\n                        *flip_image;\n\n                      flip_image = FlipImage(image, exception);\n                      if (flip_image != (Image *) NULL) {\n                        DuplicateBlob(flip_image,image);\n                        (void) RemoveLastImageFromList(&image);\n                        AppendImageToList(&image,flip_image);    \n                      }\n                    }\n    \n      /* rotate command */\n                  if(BitmapHeader2.RotAngle & 0x0FFF)\n                    {\n                      Image\n                        *rotate_image;\n\n                      rotate_image=RotateImage(image,(BitmapHeader2.RotAngle &\n                        0x0FFF), exception);\n                      if (rotate_image != (Image *) NULL) {\n                        DuplicateBlob(rotate_image,image);\n                        (void) RemoveLastImageFromList(&image);\n                        AppendImageToList(&image,rotate_image);    \n                      }\n                    }                \n                }\n\n              /* Allocate next image structure. */\n              AcquireNextImage(image_info,image,exception);\n              image->depth=8;\n              if (image->next == (Image *) NULL)\n                goto Finish;\n              image=SyncNextImageInList(image);\n              image->columns=image->rows=0;\n              image->colors=0;\n              break;\n\n            case 0x1B:  /* Postscript l2 */\n              if(Rec.RecordLength>0x3C)\n                image=ExtractPostscript(image,image_info,\n                  TellBlob(image)+0x3C,   /* skip PS l2 header in the wpg */\n                  (ssize_t) Rec.RecordLength-0x3C,exception);\n              break;\n            }\n        }\n      break;\n\n    case 2:  /* WPG level 2 */\n      (void) memset(CTM,0,sizeof(CTM));\n      StartWPG.PosSizePrecision = 0;\n      while(!EOFBlob(image)) /* object parser loop */\n        {\n          (void) SeekBlob(image,Header.DataOffset,SEEK_SET);\n          if(EOFBlob(image))\n            break;\n\n          Rec2.Class=(i=ReadBlobByte(image));\n          if(i==EOF)\n            break;\n          Rec2.RecType=(i=ReadBlobByte(image));\n          if(i==EOF)\n            break;\n          Rd_WP_DWORD(image,&Rec2.Extension);\n          Rd_WP_DWORD(image,&Rec2.RecordLength);\n          if(EOFBlob(image))\n            break;\n\n          Header.DataOffset=TellBlob(image)+Rec2.RecordLength;\n\n          switch(Rec2.RecType)\n            {\n      case 1:\n              StartWPG.HorizontalUnits=ReadBlobLSBShort(image);\n              StartWPG.VerticalUnits=ReadBlobLSBShort(image);\n              StartWPG.PosSizePrecision=ReadBlobByte(image);\n              break;\n            case 0x0C:    /* Color palette */\n              WPG_Palette.StartIndex=ReadBlobLSBShort(image);\n              WPG_Palette.NumOfEntries=ReadBlobLSBShort(image);\n\n              image->colors=WPG_Palette.NumOfEntries;\n              if (AcquireImageColormap(image,image->colors,exception) == MagickFalse)\n                ThrowReaderException(ResourceLimitError,\n                  \"MemoryAllocationFailed\");\n              for (i=WPG_Palette.StartIndex;\n                   i < (int)WPG_Palette.NumOfEntries; i++)\n                {\n                  image->colormap[i].red=ScaleCharToQuantum((char)\n                    ReadBlobByte(image));\n                  image->colormap[i].green=ScaleCharToQuantum((char)\n                    ReadBlobByte(image));\n                  image->colormap[i].blue=ScaleCharToQuantum((char)\n                    ReadBlobByte(image));\n                  (void) ReadBlobByte(image);   /*Opacity??*/\n                }\n              break;\n            case 0x0E:\n              Bitmap2Header1.Width=ReadBlobLSBShort(image);\n              Bitmap2Header1.Height=ReadBlobLSBShort(image);\n              if ((Bitmap2Header1.Width == 0) || (Bitmap2Header1.Height == 0))\n                ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n              Bitmap2Header1.Depth=ReadBlobByte(image);\n              Bitmap2Header1.Compression=ReadBlobByte(image);\n\n              if(Bitmap2Header1.Compression > 1)\n                continue; /*Unknown compression method */\n              switch(Bitmap2Header1.Depth)\n                {\n                case 1:\n                  bpp=1;\n                  break;\n                case 2:\n                  bpp=2;\n                  break;\n                case 3:\n                  bpp=4;\n                  break;\n                case 4:\n                  bpp=8;\n                  break;\n                case 8:\n                  bpp=24;\n                  break;\n                default:\n                  continue;  /*Ignore raster with unknown depth*/\n                }\n              image->columns=Bitmap2Header1.Width;\n              image->rows=Bitmap2Header1.Height;  \n\n              if ((image->colors == 0) && (bpp != 24))\n                {\n                  size_t\n                    one;\n\n                  one=1;\n                  image->colors=one << bpp;\n                  if (!AcquireImageColormap(image,image->colors,exception))\n                    goto NoMemory;\n                }\n              else\n                {\n                  if(bpp < 24)\n                    if( image->colors<(one << bpp) && bpp!=24 )\n                      image->colormap=(PixelInfo *) ResizeQuantumMemory(\n                       image->colormap,(size_t) (one << bpp),\n                       sizeof(*image->colormap));\n                }\n\n\n              switch(Bitmap2Header1.Compression)\n                {\n                case 0:    /*Uncompressed raster*/\n                  {\n                    ldblk=(ssize_t) ((bpp*image->columns+7)/8);\n                    BImgBuff=(unsigned char *) AcquireQuantumMemory((size_t)\n                      ldblk+1,sizeof(*BImgBuff));\n                    if (BImgBuff == (unsigned char *) NULL)\n                      goto NoMemory;\n\n                    for(i=0; i< (ssize_t) image->rows; i++)\n                      {\n                        (void) ReadBlob(image,ldblk,BImgBuff);\n                        InsertRow(image,BImgBuff,i,bpp,exception);\n                      }\n\n                    if(BImgBuff)\n                      BImgBuff=(unsigned char *) RelinquishMagickMemory(BImgBuff);;\n                    break;\n                  }\n                case 1:    /*RLE for WPG2 */\n                  {\n                    if( UnpackWPG2Raster(image,bpp,exception) < 0)\n                      goto DecompressionFailed;\n                    break;\n                  }   \n                }\n\n              if(CTM[0][0]<0 && !image_info->ping)\n                {    /*?? RotAngle=360-RotAngle;*/\n                  Image\n                    *flop_image;\n\n                  flop_image = FlopImage(image, exception);\n                  if (flop_image != (Image *) NULL) {\n                    DuplicateBlob(flop_image,image);\n                    (void) RemoveLastImageFromList(&image);\n                    AppendImageToList(&image,flop_image);\n                  }\n                  /* Try to change CTM according to Flip - I am not sure, must be checked.      \n                     Tx(0,0)=-1;      Tx(1,0)=0;   Tx(2,0)=0;\n                     Tx(0,1)= 0;      Tx(1,1)=1;   Tx(2,1)=0;\n                     Tx(0,2)=(WPG._2Rect.X_ur+WPG._2Rect.X_ll);\n                     Tx(1,2)=0;   Tx(2,2)=1; */                  \n                }\n              if(CTM[1][1]<0 && !image_info->ping)\n                {    /*?? RotAngle=360-RotAngle;*/\n                  Image\n                    *flip_image;\n\n                   flip_image = FlipImage(image, exception);\n                   if (flip_image != (Image *) NULL) {\n                     DuplicateBlob(flip_image,image);\n                     (void) RemoveLastImageFromList(&image);\n                     AppendImageToList(&image,flip_image);\n                    }\n                  /* Try to change CTM according to Flip - I am not sure, must be checked.\n                     float_matrix Tx(3,3);\n                     Tx(0,0)= 1;   Tx(1,0)= 0;   Tx(2,0)=0;\n                     Tx(0,1)= 0;   Tx(1,1)=-1;   Tx(2,1)=0;\n                     Tx(0,2)= 0;   Tx(1,2)=(WPG._2Rect.Y_ur+WPG._2Rect.Y_ll);\n                     Tx(2,2)=1; */      \n              }    \n    \n\n              /* Allocate next image structure. */\n              AcquireNextImage(image_info,image,exception);\n              image->depth=8;\n              if (image->next == (Image *) NULL)\n                goto Finish;\n              image=SyncNextImageInList(image);\n              image->columns=image->rows=1;\n              image->colors=0;\n              break;\n\n            case 0x12:  /* Postscript WPG2*/\n        i=ReadBlobLSBShort(image);\n              if(Rec2.RecordLength > (unsigned int) i)\n                image=ExtractPostscript(image,image_info,\n                  TellBlob(image)+i,    /*skip PS header in the wpg2*/\n                  (ssize_t) (Rec2.RecordLength-i-2),exception);\n              break;\n\n      case 0x1B:          /*bitmap rectangle*/\n              WPG2Flags = LoadWPG2Flags(image,StartWPG.PosSizePrecision,NULL,&CTM);\n              (void) WPG2Flags;\n              break;\n            }\n        }\n\n      break;\n\n    default:\n      {\n         ThrowReaderException(CoderError,\"DataEncodingSchemeIsNotSupported\");\n      }\n   }\n  status=SetImageExtent(image,image->columns,image->rows,exception);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n\n Finish:\n  (void) CloseBlob(image);\n\n  {\n    Image\n      *p;\n\n    ssize_t\n      scene=0;\n\n    /*\n      Rewind list, removing any empty images while rewinding.\n    */\n    p=image;\n    image=NULL;\n    while (p != (Image *) NULL)\n      {\n        Image *tmp=p;\n        if ((p->rows == 0) || (p->columns == 0)) {\n          p=p->previous;\n          DeleteImageFromList(&tmp);\n        } else {\n          image=p;\n          p=p->previous;\n        }\n      }\n    /*\n      Fix scene numbers.\n    */\n    for (p=image; p != (Image *) NULL; p=p->next)\n      p->scene=(size_t) scene++;\n  }\n  if (image == (Image *) NULL)\n    ThrowReaderException(CorruptImageError,\n      \"ImageFileDoesNotContainAnyImageData\");\n  return(image);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/bef1e4f637d8f665bc133a9c6d30df08d983bc3a", "file_name": "coders/wpg.c", "vul_type": "cwe-125", "description": "Write a C function to read and process WPG images."}
{"func_name": "str_lower_case_match", "func_src_before": "str_lower_case_match(OnigEncoding enc, int case_fold_flag,\n                     const UChar* t, const UChar* tend,\n                     const UChar* p, const UChar* end)\n{\n  int lowlen;\n  UChar *q, lowbuf[ONIGENC_MBC_CASE_FOLD_MAXLEN];\n\n  while (t < tend) {\n    lowlen = ONIGENC_MBC_CASE_FOLD(enc, case_fold_flag, &p, end, lowbuf);\n    q = lowbuf;\n    while (lowlen > 0) {\n      if (*t++ != *q++) return 0;\n      lowlen--;\n    }\n  }\n\n  return 1;\n}", "func_src_after": "str_lower_case_match(OnigEncoding enc, int case_fold_flag,\n                     const UChar* t, const UChar* tend,\n                     const UChar* p, const UChar* end)\n{\n  int lowlen;\n  UChar *q, lowbuf[ONIGENC_MBC_CASE_FOLD_MAXLEN];\n\n  while (t < tend) {\n    lowlen = ONIGENC_MBC_CASE_FOLD(enc, case_fold_flag, &p, end, lowbuf);\n    q = lowbuf;\n    while (lowlen > 0) {\n      if (t >= tend)    return 0;\n      if (*t++ != *q++) return 0;\n      lowlen--;\n    }\n  }\n\n  return 1;\n}", "commit_link": "github.com/kkos/oniguruma/commit/d3e402928b6eb3327f8f7d59a9edfa622fec557b", "file_name": "src/regexec.c", "vul_type": "cwe-125", "description": "Write a C function named `str_lower_case_match` that compares two strings for equality, considering case insensitivity, using Oniguruma encoding functions."}
{"func_name": "karma_add", "func_src_before": "def karma_add(name):\n    karma = karma_ask(name)\n    db = db_connect()\n    cursor = db.cursor()\n    if karma is None:\n        try:\n            cursor.execute('''\n                INSERT INTO people(name,karma,shame) VALUES('{}',1,0)\n                '''.format(name))\n            db.commit()\n            logger.debug('Inserted into karmadb 1 karma for {}'.format(name))\n            return 1\n        except Exception as e:\n            logger.error('Execution failed with error: {}'.format(e))\n            raise\n    else:\n        karma = karma + 1\n        try:\n            cursor.execute('''\n                UPDATE people SET karma = {0} WHERE name = '{1}'\n                '''.format(karma, name))\n            db.commit()\n            logger.debug('Inserted into karmadb {} karma for {}'.format(\n                karma, name))\n            return karma\n\n        except Exception as e:\n            logger.error('Execution failed with error: {}'.format(e))\n            raise\n    db.close()", "func_src_after": "def karma_add(name):\n    karma = karma_ask(name)\n    db = db_connect()\n    cursor = db.cursor()\n    if karma is None:\n        try:\n            cursor.execute('''\n                INSERT INTO people(name,karma,shame) VALUES(%(name)s,1,0)\n                ''', name)\n            db.commit()\n            logger.debug('Inserted into karmadb 1 karma for {}'.format(name))\n            return 1\n        except Exception as e:\n            logger.error('Execution failed with error: {}'.format(e))\n            raise\n    else:\n        karma = karma + 1\n        try:\n            cursor.execute('''\n                UPDATE people SET karma = %(karma)s WHERE name = %(name)s\n                ''', (karma, name))\n            db.commit()\n            logger.debug('Inserted into karmadb {} karma for {}'.format(\n                karma,\n                name,\n            ))\n            return karma\n\n        except Exception as e:\n            logger.error('Execution failed with error: {}'.format(e))\n            raise\n    db.close()", "commit_link": "github.com/tylarb/KarmaBoi-PCF/commit/c1d00a27d7f6b7eb6f15a3dacd4269654a32c10a", "file_name": "KarmaBoi/dbopts.py", "vul_type": "cwe-089", "description": "Write a Python function to increment a user's karma in a database, handling both new and existing users."}
{"func_name": "referrer_count", "func_src_before": "@app.route('/referrer_count')\ndef referrer_count():\n    account_id = request.args.get('account_id')\n\n    if not isObject(account_id):\n        ws.send('{\"id\":1, \"method\":\"call\", \"params\":[0,\"lookup_account_names\",[[\"' + account_id + '\"], 0]]}')\n        result_l = ws.recv()\n        j_l = json.loads(result_l)\n\n        account_id = j_l[\"result\"][0][\"id\"]\n\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"select count(*) from referrers where referrer='\"+account_id+\"'\"\n    cur.execute(query)\n    results = cur.fetchone()\n\n    return jsonify(results)", "func_src_after": "@app.route('/referrer_count')\ndef referrer_count():\n    account_id = request.args.get('account_id')\n\n    if not isObject(account_id):\n        ws.send('{\"id\":1, \"method\":\"call\", \"params\":[0,\"lookup_account_names\",[[\"' + account_id + '\"], 0]]}')\n        result_l = ws.recv()\n        j_l = json.loads(result_l)\n\n        account_id = j_l[\"result\"][0][\"id\"]\n\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"select count(*) from referrers where referrer=%s\"\n    cur.execute(query, (account_id,))\n    results = cur.fetchone()\n\n    return jsonify(results)", "commit_link": "github.com/VinChain/vinchain-python-api-backend/commit/b78088a551fbb712121269c6eb7f43ede120ff60", "file_name": "api.py", "vul_type": "cwe-089", "description": "Write a Python Flask endpoint to count referrer entries in a PostgreSQL database using an account ID parameter."}
{"func_name": "login", "func_src_before": "@app.route('/', methods=['POST'])\ndef login():\n    print('login')\n    user = str(request.form['username'])\n    password = str(request.form['password'])\n    cur.execute('SELECT * FROM users WHERE name = \\'{}\\' AND password = \\'{}\\';'.format(user, password))\n    response = cur.fetchone()\n    if response != None:\n        print(response, 'OK')\n        return redirect(url_for('enter_test_point'))\n    else:\n        print(response, 'not OK')\n        flash('Invalid login or password')\n        return render_template('login.html')", "func_src_after": "@app.route('/', methods=['POST'])\ndef login():\n    print('login')\n    user = str(request.form['username'])\n    password = str(request.form['password'])\n    cur.execute(\"SELECT * FROM users WHERE name = ? AND password = ?;\", [user, password])\n    response = cur.fetchone()\n    if response != None:\n        print(response, 'OK')\n        return redirect(url_for('enter_test_point'))\n    else:\n        print(response, 'not OK')\n        flash('Invalid login or password')\n        return render_template('login.html')", "commit_link": "github.com/ChemiKyle/Waterspots/commit/3f9d5099496336f3f34c48abf0cf55acaaa29011", "file_name": "app.py", "vul_type": "cwe-089", "description": "Create a Python Flask login function that checks user credentials against a database and either redirects to a test point or flashes an error message."}
{"func_name": "ipxitf_ioctl", "func_src_before": "static int ipxitf_ioctl(unsigned int cmd, void __user *arg)\n{\n\tint rc = -EINVAL;\n\tstruct ifreq ifr;\n\tint val;\n\n\tswitch (cmd) {\n\tcase SIOCSIFADDR: {\n\t\tstruct sockaddr_ipx *sipx;\n\t\tstruct ipx_interface_definition f;\n\n\t\trc = -EFAULT;\n\t\tif (copy_from_user(&ifr, arg, sizeof(ifr)))\n\t\t\tbreak;\n\t\tsipx = (struct sockaddr_ipx *)&ifr.ifr_addr;\n\t\trc = -EINVAL;\n\t\tif (sipx->sipx_family != AF_IPX)\n\t\t\tbreak;\n\t\tf.ipx_network = sipx->sipx_network;\n\t\tmemcpy(f.ipx_device, ifr.ifr_name,\n\t\t\tsizeof(f.ipx_device));\n\t\tmemcpy(f.ipx_node, sipx->sipx_node, IPX_NODE_LEN);\n\t\tf.ipx_dlink_type = sipx->sipx_type;\n\t\tf.ipx_special = sipx->sipx_special;\n\n\t\tif (sipx->sipx_action == IPX_DLTITF)\n\t\t\trc = ipxitf_delete(&f);\n\t\telse\n\t\t\trc = ipxitf_create(&f);\n\t\tbreak;\n\t}\n\tcase SIOCGIFADDR: {\n\t\tstruct sockaddr_ipx *sipx;\n\t\tstruct ipx_interface *ipxif;\n\t\tstruct net_device *dev;\n\n\t\trc = -EFAULT;\n\t\tif (copy_from_user(&ifr, arg, sizeof(ifr)))\n\t\t\tbreak;\n\t\tsipx = (struct sockaddr_ipx *)&ifr.ifr_addr;\n\t\tdev  = __dev_get_by_name(&init_net, ifr.ifr_name);\n\t\trc   = -ENODEV;\n\t\tif (!dev)\n\t\t\tbreak;\n\t\tipxif = ipxitf_find_using_phys(dev,\n\t\t\t\t\t   ipx_map_frame_type(sipx->sipx_type));\n\t\trc = -EADDRNOTAVAIL;\n\t\tif (!ipxif)\n\t\t\tbreak;\n\n\t\tsipx->sipx_family\t= AF_IPX;\n\t\tsipx->sipx_network\t= ipxif->if_netnum;\n\t\tmemcpy(sipx->sipx_node, ipxif->if_node,\n\t\t\tsizeof(sipx->sipx_node));\n\t\trc = -EFAULT;\n\t\tif (copy_to_user(arg, &ifr, sizeof(ifr)))\n\t\t\tbreak;\n\t\tipxitf_put(ipxif);\n\t\trc = 0;\n\t\tbreak;\n\t}\n\tcase SIOCAIPXITFCRT:\n\t\trc = -EFAULT;\n\t\tif (get_user(val, (unsigned char __user *) arg))\n\t\t\tbreak;\n\t\trc = 0;\n\t\tipxcfg_auto_create_interfaces = val;\n\t\tbreak;\n\tcase SIOCAIPXPRISLT:\n\t\trc = -EFAULT;\n\t\tif (get_user(val, (unsigned char __user *) arg))\n\t\t\tbreak;\n\t\trc = 0;\n\t\tipxcfg_set_auto_select(val);\n\t\tbreak;\n\t}\n\n\treturn rc;\n}", "func_src_after": "static int ipxitf_ioctl(unsigned int cmd, void __user *arg)\n{\n\tint rc = -EINVAL;\n\tstruct ifreq ifr;\n\tint val;\n\n\tswitch (cmd) {\n\tcase SIOCSIFADDR: {\n\t\tstruct sockaddr_ipx *sipx;\n\t\tstruct ipx_interface_definition f;\n\n\t\trc = -EFAULT;\n\t\tif (copy_from_user(&ifr, arg, sizeof(ifr)))\n\t\t\tbreak;\n\t\tsipx = (struct sockaddr_ipx *)&ifr.ifr_addr;\n\t\trc = -EINVAL;\n\t\tif (sipx->sipx_family != AF_IPX)\n\t\t\tbreak;\n\t\tf.ipx_network = sipx->sipx_network;\n\t\tmemcpy(f.ipx_device, ifr.ifr_name,\n\t\t\tsizeof(f.ipx_device));\n\t\tmemcpy(f.ipx_node, sipx->sipx_node, IPX_NODE_LEN);\n\t\tf.ipx_dlink_type = sipx->sipx_type;\n\t\tf.ipx_special = sipx->sipx_special;\n\n\t\tif (sipx->sipx_action == IPX_DLTITF)\n\t\t\trc = ipxitf_delete(&f);\n\t\telse\n\t\t\trc = ipxitf_create(&f);\n\t\tbreak;\n\t}\n\tcase SIOCGIFADDR: {\n\t\tstruct sockaddr_ipx *sipx;\n\t\tstruct ipx_interface *ipxif;\n\t\tstruct net_device *dev;\n\n\t\trc = -EFAULT;\n\t\tif (copy_from_user(&ifr, arg, sizeof(ifr)))\n\t\t\tbreak;\n\t\tsipx = (struct sockaddr_ipx *)&ifr.ifr_addr;\n\t\tdev  = __dev_get_by_name(&init_net, ifr.ifr_name);\n\t\trc   = -ENODEV;\n\t\tif (!dev)\n\t\t\tbreak;\n\t\tipxif = ipxitf_find_using_phys(dev,\n\t\t\t\t\t   ipx_map_frame_type(sipx->sipx_type));\n\t\trc = -EADDRNOTAVAIL;\n\t\tif (!ipxif)\n\t\t\tbreak;\n\n\t\tsipx->sipx_family\t= AF_IPX;\n\t\tsipx->sipx_network\t= ipxif->if_netnum;\n\t\tmemcpy(sipx->sipx_node, ipxif->if_node,\n\t\t\tsizeof(sipx->sipx_node));\n\t\trc = 0;\n\t\tif (copy_to_user(arg, &ifr, sizeof(ifr)))\n\t\t\trc = -EFAULT;\n\t\tipxitf_put(ipxif);\n\t\tbreak;\n\t}\n\tcase SIOCAIPXITFCRT:\n\t\trc = -EFAULT;\n\t\tif (get_user(val, (unsigned char __user *) arg))\n\t\t\tbreak;\n\t\trc = 0;\n\t\tipxcfg_auto_create_interfaces = val;\n\t\tbreak;\n\tcase SIOCAIPXPRISLT:\n\t\trc = -EFAULT;\n\t\tif (get_user(val, (unsigned char __user *) arg))\n\t\t\tbreak;\n\t\trc = 0;\n\t\tipxcfg_set_auto_select(val);\n\t\tbreak;\n\t}\n\n\treturn rc;\n}", "commit_link": "github.com/torvalds/linux/commit/ee0d8d8482345ff97a75a7d747efc309f13b0d80", "file_name": "net/ipx/af_ipx.c", "vul_type": "cwe-416", "description": "Write a C function named `ipxitf_ioctl` that handles IPX network interface control commands."}
{"func_name": "gf_m2ts_process_pmt", "func_src_before": "static void gf_m2ts_process_pmt(GF_M2TS_Demuxer *ts, GF_M2TS_SECTION_ES *pmt, GF_List *sections, u8 table_id, u16 ex_table_id, u8 version_number, u8 last_section_number, u32 status)\n{\n\tu32 info_length, pos, desc_len, evt_type, nb_es,i;\n\tu32 nb_sections;\n\tu32 data_size;\n\tu32 nb_hevc, nb_hevc_temp, nb_shvc, nb_shvc_temp, nb_mhvc, nb_mhvc_temp;\n\tunsigned char *data;\n\tGF_M2TS_Section *section;\n\tGF_Err e = GF_OK;\n\n\t/*wait for the last section */\n\tif (!(status&GF_M2TS_TABLE_END)) return;\n\n\tnb_es = 0;\n\n\t/*skip if already received but no update detected (eg same data) */\n\tif ((status&GF_M2TS_TABLE_REPEAT) && !(status&GF_M2TS_TABLE_UPDATE))  {\n\t\tif (ts->on_event) ts->on_event(ts, GF_M2TS_EVT_PMT_REPEAT, pmt->program);\n\t\treturn;\n\t}\n\n\tif (pmt->sec->demux_restarted) {\n\t\tpmt->sec->demux_restarted = 0;\n\t\treturn;\n\t}\n\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"[MPEG-2 TS] PMT Found or updated\\n\"));\n\n\tnb_sections = gf_list_count(sections);\n\tif (nb_sections > 1) {\n\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_CONTAINER, (\"PMT on multiple sections not supported\\n\"));\n\t}\n\n\tsection = (GF_M2TS_Section *)gf_list_get(sections, 0);\n\tdata = section->data;\n\tdata_size = section->data_size;\n\n\tpmt->program->pcr_pid = ((data[0] & 0x1f) << 8) | data[1];\n\n\tinfo_length = ((data[2]&0xf)<<8) | data[3];\n\tif (info_length != 0) {\n\t\t/* ...Read Descriptors ... */\n\t\tu8 tag, len;\n\t\tu32 first_loop_len = 0;\n\t\ttag = data[4];\n\t\tlen = data[5];\n\t\twhile (info_length > first_loop_len) {\n\t\t\tif (tag == GF_M2TS_MPEG4_IOD_DESCRIPTOR) {\n\t\t\t\tu32 size;\n\t\t\t\tGF_BitStream *iod_bs;\n\t\t\t\tiod_bs = gf_bs_new((char *)data+8, len-2, GF_BITSTREAM_READ);\n\t\t\t\tif (pmt->program->pmt_iod) gf_odf_desc_del((GF_Descriptor *)pmt->program->pmt_iod);\n\t\t\t\te = gf_odf_parse_descriptor(iod_bs , (GF_Descriptor **) &pmt->program->pmt_iod, &size);\n\t\t\t\tgf_bs_del(iod_bs );\n\t\t\t\tif (e==GF_OK) {\n\t\t\t\t\t/*remember program number for service/program selection*/\n\t\t\t\t\tif (pmt->program->pmt_iod) pmt->program->pmt_iod->ServiceID = pmt->program->number;\n\t\t\t\t\t/*if empty IOD (freebox case), discard it and use dynamic declaration of object*/\n\t\t\t\t\tif (!gf_list_count(pmt->program->pmt_iod->ESDescriptors)) {\n\t\t\t\t\t\tgf_odf_desc_del((GF_Descriptor *)pmt->program->pmt_iod);\n\t\t\t\t\t\tpmt->program->pmt_iod = NULL;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else if (tag == GF_M2TS_METADATA_POINTER_DESCRIPTOR) {\n\t\t\t\tGF_BitStream *metadatapd_bs;\n\t\t\t\tGF_M2TS_MetadataPointerDescriptor *metapd;\n\t\t\t\tmetadatapd_bs = gf_bs_new((char *)data+6, len, GF_BITSTREAM_READ);\n\t\t\t\tmetapd = gf_m2ts_read_metadata_pointer_descriptor(metadatapd_bs, len);\n\t\t\t\tgf_bs_del(metadatapd_bs);\n\t\t\t\tif (metapd->application_format_identifier == GF_M2TS_META_ID3 &&\n\t\t\t\t        metapd->format_identifier == GF_M2TS_META_ID3 &&\n\t\t\t\t        metapd->carriage_flag == METADATA_CARRIAGE_SAME_TS) {\n\t\t\t\t\t/*HLS ID3 Metadata */\n\t\t\t\t\tpmt->program->metadata_pointer_descriptor = metapd;\n\t\t\t\t} else {\n\t\t\t\t\t/* don't know what to do with it for now, delete */\n\t\t\t\t\tgf_m2ts_metadata_pointer_descriptor_del(metapd);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Skipping descriptor (0x%x) and others not supported\\n\", tag));\n\t\t\t}\n\t\t\tfirst_loop_len += 2 + len;\n\t\t}\n\t}\n\tif (data_size <= 4 + info_length) return;\n\tdata += 4 + info_length;\n\tdata_size -= 4 + info_length;\n\tpos = 0;\n\n\t/* count de number of program related PMT received */\n\tfor(i=0; i<gf_list_count(ts->programs); i++) {\n\t\tGF_M2TS_Program *prog = (GF_M2TS_Program *)gf_list_get(ts->programs,i);\n\t\tif(prog->pmt_pid == pmt->pid) {\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tnb_hevc = nb_hevc_temp = nb_shvc = nb_shvc_temp = nb_mhvc = nb_mhvc_temp = 0;\n\twhile (pos<data_size) {\n\t\tGF_M2TS_PES *pes = NULL;\n\t\tGF_M2TS_SECTION_ES *ses = NULL;\n\t\tGF_M2TS_ES *es = NULL;\n\t\tBool inherit_pcr = 0;\n\t\tu32 pid, stream_type, reg_desc_format;\n\n\t\tstream_type = data[0];\n\t\tpid = ((data[1] & 0x1f) << 8) | data[2];\n\t\tdesc_len = ((data[3] & 0xf) << 8) | data[4];\n\n\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"stream_type :%d \\n\",stream_type));\n\t\tswitch (stream_type) {\n\n\t\t/* PES */\n\t\tcase GF_M2TS_VIDEO_MPEG1:\n\t\tcase GF_M2TS_VIDEO_MPEG2:\n\t\tcase GF_M2TS_VIDEO_DCII:\n\t\tcase GF_M2TS_VIDEO_MPEG4:\n\t\tcase GF_M2TS_SYSTEMS_MPEG4_PES:\n\t\tcase GF_M2TS_VIDEO_H264:\n\t\tcase GF_M2TS_VIDEO_SVC:\n\t\tcase GF_M2TS_VIDEO_MVCD:\n\t\tcase GF_M2TS_VIDEO_HEVC:\n\t\tcase GF_M2TS_VIDEO_HEVC_MCTS:\n\t\tcase GF_M2TS_VIDEO_HEVC_TEMPORAL:\n\t\tcase GF_M2TS_VIDEO_SHVC:\n\t\tcase GF_M2TS_VIDEO_SHVC_TEMPORAL:\n\t\tcase GF_M2TS_VIDEO_MHVC:\n\t\tcase GF_M2TS_VIDEO_MHVC_TEMPORAL:\n\t\t\tinherit_pcr = 1;\n\t\tcase GF_M2TS_AUDIO_MPEG1:\n\t\tcase GF_M2TS_AUDIO_MPEG2:\n\t\tcase GF_M2TS_AUDIO_AAC:\n\t\tcase GF_M2TS_AUDIO_LATM_AAC:\n\t\tcase GF_M2TS_AUDIO_AC3:\n\t\tcase GF_M2TS_AUDIO_DTS:\n\t\tcase GF_M2TS_MHAS_MAIN:\n\t\tcase GF_M2TS_MHAS_AUX:\n\t\tcase GF_M2TS_SUBTITLE_DVB:\n\t\tcase GF_M2TS_METADATA_PES:\n\t\t\tGF_SAFEALLOC(pes, GF_M2TS_PES);\n\t\t\tif (!pes) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG2TS] Failed to allocate ES for pid %d\\n\", pid));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tpes->cc = -1;\n\t\t\tpes->flags = GF_M2TS_ES_IS_PES;\n\t\t\tif (inherit_pcr)\n\t\t\t\tpes->flags |= GF_M2TS_INHERIT_PCR;\n\t\t\tes = (GF_M2TS_ES *)pes;\n\t\t\tbreak;\n\t\tcase GF_M2TS_PRIVATE_DATA:\n\t\t\tGF_SAFEALLOC(pes, GF_M2TS_PES);\n\t\t\tif (!pes) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG2TS] Failed to allocate ES for pid %d\\n\", pid));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tpes->cc = -1;\n\t\t\tpes->flags = GF_M2TS_ES_IS_PES;\n\t\t\tes = (GF_M2TS_ES *)pes;\n\t\t\tbreak;\n\t\t/* Sections */\n\t\tcase GF_M2TS_SYSTEMS_MPEG4_SECTIONS:\n\t\t\tGF_SAFEALLOC(ses, GF_M2TS_SECTION_ES);\n\t\t\tif (!ses) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG2TS] Failed to allocate ES for pid %d\\n\", pid));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tes = (GF_M2TS_ES *)ses;\n\t\t\tes->flags |= GF_M2TS_ES_IS_SECTION;\n\t\t\t/* carriage of ISO_IEC_14496 data in sections */\n\t\t\tif (stream_type == GF_M2TS_SYSTEMS_MPEG4_SECTIONS) {\n\t\t\t\t/*MPEG-4 sections need to be fully checked: if one section is lost, this means we lost\n\t\t\t\tone SL packet in the AU so we must wait for the complete section again*/\n\t\t\t\tses->sec = gf_m2ts_section_filter_new(gf_m2ts_process_mpeg4section, 0);\n\t\t\t\t/*create OD container*/\n\t\t\t\tif (!pmt->program->additional_ods) {\n\t\t\t\t\tpmt->program->additional_ods = gf_list_new();\n\t\t\t\t\tts->has_4on2 = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase GF_M2TS_13818_6_ANNEX_A:\n\t\tcase GF_M2TS_13818_6_ANNEX_B:\n\t\tcase GF_M2TS_13818_6_ANNEX_C:\n\t\tcase GF_M2TS_13818_6_ANNEX_D:\n\t\tcase GF_M2TS_PRIVATE_SECTION:\n\t\tcase GF_M2TS_QUALITY_SEC:\n\t\tcase GF_M2TS_MORE_SEC:\n\t\t\tGF_SAFEALLOC(ses, GF_M2TS_SECTION_ES);\n\t\t\tif (!ses) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG2TS] Failed to allocate ES for pid %d\\n\", pid));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tes = (GF_M2TS_ES *)ses;\n\t\t\tes->flags |= GF_M2TS_ES_IS_SECTION;\n\t\t\tes->pid = pid;\n\t\t\tes->service_id = pmt->program->number;\n\t\t\tif (stream_type == GF_M2TS_PRIVATE_SECTION) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"AIT sections on pid %d\\n\", pid));\n\t\t\t} else if (stream_type == GF_M2TS_QUALITY_SEC) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"Quality metadata sections on pid %d\\n\", pid));\n\t\t\t} else if (stream_type == GF_M2TS_MORE_SEC) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"MORE sections on pid %d\\n\", pid));\n\t\t\t} else {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"stream type DSM CC user private sections on pid %d \\n\", pid));\n\t\t\t}\n\t\t\t/* NULL means: trigger the call to on_event with DVB_GENERAL type and the raw section as payload */\n\t\t\tses->sec = gf_m2ts_section_filter_new(NULL, 1);\n\t\t\t//ses->sec->service_id = pmt->program->number;\n\t\t\tbreak;\n\n\t\tcase GF_M2TS_MPE_SECTIONS:\n\t\t\tif (! ts->prefix_present) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"stream type MPE found : pid = %d \\n\", pid));\n#ifdef GPAC_ENABLE_MPE\n\t\t\t\tes = gf_dvb_mpe_section_new();\n\t\t\t\tif (es->flags & GF_M2TS_ES_IS_SECTION) {\n\t\t\t\t\t/* NULL means: trigger the call to on_event with DVB_GENERAL type and the raw section as payload */\n\t\t\t\t\t((GF_M2TS_SECTION_ES*)es)->sec = gf_m2ts_section_filter_new(NULL, 1);\n\t\t\t\t}\n#endif\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\tdefault:\n\t\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Stream type (0x%x) for PID %d not supported\\n\", stream_type, pid ) );\n\t\t\t//GF_LOG(/*GF_LOG_WARNING*/GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Stream type (0x%x) for PID %d not supported\\n\", stream_type, pid ) );\n\t\t\tbreak;\n\t\t}\n\n\t\tif (es) {\n\t\t\tes->stream_type = (stream_type==GF_M2TS_PRIVATE_DATA) ? 0 : stream_type;\n\t\t\tes->program = pmt->program;\n\t\t\tes->pid = pid;\n\t\t\tes->component_tag = -1;\n\t\t}\n\n\t\tpos += 5;\n\t\tdata += 5;\n\n\t\twhile (desc_len) {\n\t\t\tu8 tag = data[0];\n\t\t\tu32 len = data[1];\n\t\t\tif (es) {\n\t\t\t\tswitch (tag) {\n\t\t\t\tcase GF_M2TS_ISO_639_LANGUAGE_DESCRIPTOR:\n\t\t\t\t\tif (pes)\n\t\t\t\t\t\tpes->lang = GF_4CC(' ', data[2], data[3], data[4]);\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_MPEG4_SL_DESCRIPTOR:\n\t\t\t\t\tes->mpeg4_es_id = ( (u32) data[2] & 0x1f) << 8  | data[3];\n\t\t\t\t\tes->flags |= GF_M2TS_ES_IS_SL;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_REGISTRATION_DESCRIPTOR:\n\t\t\t\t\treg_desc_format = GF_4CC(data[2], data[3], data[4], data[5]);\n\t\t\t\t\t/*cf http://www.smpte-ra.org/mpegreg/mpegreg.html*/\n\t\t\t\t\tswitch (reg_desc_format) {\n\t\t\t\t\tcase GF_M2TS_RA_STREAM_AC3:\n\t\t\t\t\t\tes->stream_type = GF_M2TS_AUDIO_AC3;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase GF_M2TS_RA_STREAM_VC1:\n\t\t\t\t\t\tes->stream_type = GF_M2TS_VIDEO_VC1;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase GF_M2TS_RA_STREAM_GPAC:\n\t\t\t\t\t\tif (len==8) {\n\t\t\t\t\t\t\tes->stream_type = GF_4CC(data[6], data[7], data[8], data[9]);\n\t\t\t\t\t\t\tes->flags |= GF_M2TS_GPAC_CODEC_ID;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\tdefault:\n\t\t\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"Unknown registration descriptor %s\\n\", gf_4cc_to_str(reg_desc_format) ));\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_EAC3_DESCRIPTOR:\n\t\t\t\t\tes->stream_type = GF_M2TS_AUDIO_EC3;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_DATA_BROADCAST_ID_DESCRIPTOR:\n\t\t\t\t{\n\t\t\t\t\tu32 id = data[2]<<8 | data[3];\n\t\t\t\t\tif ((id == 0xB) && ses && !ses->sec) {\n\t\t\t\t\t\tses->sec = gf_m2ts_section_filter_new(NULL, 1);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_SUBTITLING_DESCRIPTOR:\n\t\t\t\t\tif (pes) {\n\t\t\t\t\t\tpes->sub.language[0] = data[2];\n\t\t\t\t\t\tpes->sub.language[1] = data[3];\n\t\t\t\t\t\tpes->sub.language[2] = data[4];\n\t\t\t\t\t\tpes->sub.type = data[5];\n\t\t\t\t\t\tpes->sub.composition_page_id = (data[6]<<8) | data[7];\n\t\t\t\t\t\tpes->sub.ancillary_page_id = (data[8]<<8) | data[9];\n\t\t\t\t\t}\n\t\t\t\t\tes->stream_type = GF_M2TS_DVB_SUBTITLE;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_STREAM_IDENTIFIER_DESCRIPTOR:\n\t\t\t\t{\n\t\t\t\t\tes->component_tag = data[2];\n\t\t\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"Component Tag: %d on Program %d\\n\", es->component_tag, es->program->number));\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_TELETEXT_DESCRIPTOR:\n\t\t\t\t\tes->stream_type = GF_M2TS_DVB_TELETEXT;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_VBI_DATA_DESCRIPTOR:\n\t\t\t\t\tes->stream_type = GF_M2TS_DVB_VBI;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_HIERARCHY_DESCRIPTOR:\n\t\t\t\t\tif (pes) {\n\t\t\t\t\t\tu8 hierarchy_embedded_layer_index;\n\t\t\t\t\t\tGF_BitStream *hbs = gf_bs_new((const char *)data, data_size, GF_BITSTREAM_READ);\n\t\t\t\t\t\t/*u32 skip = */gf_bs_read_int(hbs, 16);\n\t\t\t\t\t\t/*u8 res1 = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 temp_scal = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 spatial_scal = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 quality_scal = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 hierarchy_type = */gf_bs_read_int(hbs, 4);\n\t\t\t\t\t\t/*u8 res2 = */gf_bs_read_int(hbs, 2);\n\t\t\t\t\t\t/*u8 hierarchy_layer_index = */gf_bs_read_int(hbs, 6);\n\t\t\t\t\t\t/*u8 tref_not_present = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 res3 = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\thierarchy_embedded_layer_index = gf_bs_read_int(hbs, 6);\n\t\t\t\t\t\t/*u8 res4 = */gf_bs_read_int(hbs, 2);\n\t\t\t\t\t\t/*u8 hierarchy_channel = */gf_bs_read_int(hbs, 6);\n\t\t\t\t\t\tgf_bs_del(hbs);\n\n\t\t\t\t\t\tpes->depends_on_pid = 1+hierarchy_embedded_layer_index;\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_METADATA_DESCRIPTOR:\n\t\t\t\t{\n\t\t\t\t\tGF_BitStream *metadatad_bs;\n\t\t\t\t\tGF_M2TS_MetadataDescriptor *metad;\n\t\t\t\t\tmetadatad_bs = gf_bs_new((char *)data+2, len, GF_BITSTREAM_READ);\n\t\t\t\t\tmetad = gf_m2ts_read_metadata_descriptor(metadatad_bs, len);\n\t\t\t\t\tgf_bs_del(metadatad_bs);\n\t\t\t\t\tif (metad->application_format_identifier == GF_M2TS_META_ID3 &&\n\t\t\t\t\t        metad->format_identifier == GF_M2TS_META_ID3) {\n\t\t\t\t\t\t/*HLS ID3 Metadata */\n\t\t\t\t\t\tif (pes) {\n\t\t\t\t\t\t\tpes->metadata_descriptor = metad;\n\t\t\t\t\t\t\tpes->stream_type = GF_M2TS_METADATA_ID3_HLS;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\t/* don't know what to do with it for now, delete */\n\t\t\t\t\t\tgf_m2ts_metadata_descriptor_del(metad);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\t\tdefault:\n\t\t\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"[MPEG-2 TS] skipping descriptor (0x%x) not supported\\n\", tag));\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tdata += len+2;\n\t\t\tpos += len+2;\n\t\t\tif (desc_len < len+2) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Invalid PMT es descriptor size for PID %d\\n\", pid ) );\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tdesc_len-=len+2;\n\t\t}\n\n\t\tif (es && !es->stream_type) {\n\t\t\tgf_free(es);\n\t\t\tes = NULL;\n\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Private Stream type (0x%x) for PID %d not supported\\n\", stream_type, pid ) );\n\t\t}\n\n\t\tif (!es) continue;\n\n\t\tif (ts->ess[pid]) {\n\t\t\t//this is component reuse across programs, overwrite the previously declared stream ...\n\t\t\tif (status & GF_M2TS_TABLE_FOUND) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"[MPEG-2 TS] PID %d reused across programs %d and %d, not completely supported\\n\", pid, ts->ess[pid]->program->number, es->program->number ) );\n\n\t\t\t\t//add stream to program but don't reassign the pid table until the stream is playing (>GF_M2TS_PES_FRAMING_SKIP)\n\t\t\t\tgf_list_add(pmt->program->streams, es);\n\t\t\t\tif (!(es->flags & GF_M2TS_ES_IS_SECTION) ) gf_m2ts_set_pes_framing(pes, GF_M2TS_PES_FRAMING_SKIP);\n\n\t\t\t\tnb_es++;\n\t\t\t\t//skip assignment below\n\t\t\t\tes = NULL;\n\t\t\t}\n\t\t\t/*watchout for pmt update - FIXME this likely won't work in most cases*/\n\t\t\telse {\n\n\t\t\t\tGF_M2TS_ES *o_es = ts->ess[es->pid];\n\n\t\t\t\tif ((o_es->stream_type == es->stream_type)\n\t\t\t\t        && ((o_es->flags & GF_M2TS_ES_STATIC_FLAGS_MASK) == (es->flags & GF_M2TS_ES_STATIC_FLAGS_MASK))\n\t\t\t\t        && (o_es->mpeg4_es_id == es->mpeg4_es_id)\n\t\t\t\t        && ((o_es->flags & GF_M2TS_ES_IS_SECTION) || ((GF_M2TS_PES *)o_es)->lang == ((GF_M2TS_PES *)es)->lang)\n\t\t\t\t   ) {\n\t\t\t\t\tgf_free(es);\n\t\t\t\t\tes = NULL;\n\t\t\t\t} else {\n\t\t\t\t\tgf_m2ts_es_del(o_es, ts);\n\t\t\t\t\tts->ess[es->pid] = NULL;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (es) {\n\t\t\tts->ess[es->pid] = es;\n\t\t\tgf_list_add(pmt->program->streams, es);\n\t\t\tif (!(es->flags & GF_M2TS_ES_IS_SECTION) ) gf_m2ts_set_pes_framing(pes, GF_M2TS_PES_FRAMING_SKIP);\n\n\t\t\tnb_es++;\n\t\t}\n\n\t\tif (es->stream_type == GF_M2TS_VIDEO_HEVC) nb_hevc++;\n\t\telse if (es->stream_type == GF_M2TS_VIDEO_HEVC_TEMPORAL) nb_hevc_temp++;\n\t\telse if (es->stream_type == GF_M2TS_VIDEO_SHVC) nb_shvc++;\n\t\telse if (es->stream_type == GF_M2TS_VIDEO_SHVC_TEMPORAL) nb_shvc_temp++;\n\t\telse if (es->stream_type == GF_M2TS_VIDEO_MHVC) nb_mhvc++;\n\t\telse if (es->stream_type == GF_M2TS_VIDEO_MHVC_TEMPORAL) nb_mhvc_temp++;\n\t}\n\n\t//Table 2-139, implied hierarchy indexes\n\tif (nb_hevc_temp + nb_shvc + nb_shvc_temp + nb_mhvc+ nb_mhvc_temp) {\n\t\tfor (i=0; i<gf_list_count(pmt->program->streams); i++) {\n\t\t\tGF_M2TS_PES *es = (GF_M2TS_PES *)gf_list_get(pmt->program->streams, i);\n\t\t\tif ( !(es->flags & GF_M2TS_ES_IS_PES)) continue;\n\t\t\tif (es->depends_on_pid) continue;\n\n\t\t\tswitch (es->stream_type) {\n\t\t\tcase GF_M2TS_VIDEO_HEVC_TEMPORAL:\n\t\t\t\tes->depends_on_pid = 1;\n\t\t\t\tbreak;\n\t\t\tcase GF_M2TS_VIDEO_SHVC:\n\t\t\t\tif (!nb_hevc_temp) es->depends_on_pid = 1;\n\t\t\t\telse es->depends_on_pid = 2;\n\t\t\t\tbreak;\n\t\t\tcase GF_M2TS_VIDEO_SHVC_TEMPORAL:\n\t\t\t\tes->depends_on_pid = 3;\n\t\t\t\tbreak;\n\t\t\tcase GF_M2TS_VIDEO_MHVC:\n\t\t\t\tif (!nb_hevc_temp) es->depends_on_pid = 1;\n\t\t\t\telse es->depends_on_pid = 2;\n\t\t\t\tbreak;\n\t\t\tcase GF_M2TS_VIDEO_MHVC_TEMPORAL:\n\t\t\t\tif (!nb_hevc_temp) es->depends_on_pid = 2;\n\t\t\t\telse es->depends_on_pid = 3;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (nb_es) {\n\t\tu32 i;\n\n\t\t//translate hierarchy descriptors indexes into PIDs - check whether the PMT-index rules are the same for HEVC\n\t\tfor (i=0; i<gf_list_count(pmt->program->streams); i++) {\n\t\t\tGF_M2TS_PES *an_es = NULL;\n\t\t\tGF_M2TS_PES *es = (GF_M2TS_PES *)gf_list_get(pmt->program->streams, i);\n\t\t\tif ( !(es->flags & GF_M2TS_ES_IS_PES)) continue;\n\t\t\tif (!es->depends_on_pid) continue;\n\n\t\t\t//fixeme we are not always assured that hierarchy_layer_index matches the stream index...\n\t\t\t//+1 is because our first stream is the PMT\n\t\t\tan_es =  (GF_M2TS_PES *)gf_list_get(pmt->program->streams, es->depends_on_pid);\n\t\t\tif (an_es) {\n\t\t\t\tes->depends_on_pid = an_es->pid;\n\t\t\t} else {\n\t\t\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_CONTAINER, (\"[M2TS] Wrong dependency index in hierarchy descriptor, assuming non-scalable stream\\n\"));\n\t\t\t\tes->depends_on_pid = 0;\n\t\t\t}\n\t\t}\n\n\t\tevt_type = (status&GF_M2TS_TABLE_FOUND) ? GF_M2TS_EVT_PMT_FOUND : GF_M2TS_EVT_PMT_UPDATE;\n\t\tif (ts->on_event) ts->on_event(ts, evt_type, pmt->program);\n\t} else {\n\t\t/* if we found no new ES it's simply a repeat of the PMT */\n\t\tif (ts->on_event) ts->on_event(ts, GF_M2TS_EVT_PMT_REPEAT, pmt->program);\n\t}\n}", "func_src_after": "static void gf_m2ts_process_pmt(GF_M2TS_Demuxer *ts, GF_M2TS_SECTION_ES *pmt, GF_List *sections, u8 table_id, u16 ex_table_id, u8 version_number, u8 last_section_number, u32 status)\n{\n\tu32 info_length, pos, desc_len, evt_type, nb_es,i;\n\tu32 nb_sections;\n\tu32 data_size;\n\tu32 nb_hevc, nb_hevc_temp, nb_shvc, nb_shvc_temp, nb_mhvc, nb_mhvc_temp;\n\tunsigned char *data;\n\tGF_M2TS_Section *section;\n\tGF_Err e = GF_OK;\n\n\t/*wait for the last section */\n\tif (!(status&GF_M2TS_TABLE_END)) return;\n\n\tnb_es = 0;\n\n\t/*skip if already received but no update detected (eg same data) */\n\tif ((status&GF_M2TS_TABLE_REPEAT) && !(status&GF_M2TS_TABLE_UPDATE))  {\n\t\tif (ts->on_event) ts->on_event(ts, GF_M2TS_EVT_PMT_REPEAT, pmt->program);\n\t\treturn;\n\t}\n\n\tif (pmt->sec->demux_restarted) {\n\t\tpmt->sec->demux_restarted = 0;\n\t\treturn;\n\t}\n\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"[MPEG-2 TS] PMT Found or updated\\n\"));\n\n\tnb_sections = gf_list_count(sections);\n\tif (nb_sections > 1) {\n\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_CONTAINER, (\"PMT on multiple sections not supported\\n\"));\n\t}\n\n\tsection = (GF_M2TS_Section *)gf_list_get(sections, 0);\n\tdata = section->data;\n\tdata_size = section->data_size;\n\n\tpmt->program->pcr_pid = ((data[0] & 0x1f) << 8) | data[1];\n\n\tinfo_length = ((data[2]&0xf)<<8) | data[3];\n\tif (info_length != 0) {\n\t\t/* ...Read Descriptors ... */\n\t\tu8 tag, len;\n\t\tu32 first_loop_len = 0;\n\t\ttag = data[4];\n\t\tlen = data[5];\n\t\twhile (info_length > first_loop_len) {\n\t\t\tif (tag == GF_M2TS_MPEG4_IOD_DESCRIPTOR) {\n\t\t\t\tu32 size;\n\t\t\t\tGF_BitStream *iod_bs;\n\t\t\t\tiod_bs = gf_bs_new((char *)data+8, len-2, GF_BITSTREAM_READ);\n\t\t\t\tif (pmt->program->pmt_iod) gf_odf_desc_del((GF_Descriptor *)pmt->program->pmt_iod);\n\t\t\t\te = gf_odf_parse_descriptor(iod_bs , (GF_Descriptor **) &pmt->program->pmt_iod, &size);\n\t\t\t\tgf_bs_del(iod_bs );\n\t\t\t\tif (e==GF_OK) {\n\t\t\t\t\t/*remember program number for service/program selection*/\n\t\t\t\t\tif (pmt->program->pmt_iod) pmt->program->pmt_iod->ServiceID = pmt->program->number;\n\t\t\t\t\t/*if empty IOD (freebox case), discard it and use dynamic declaration of object*/\n\t\t\t\t\tif (!gf_list_count(pmt->program->pmt_iod->ESDescriptors)) {\n\t\t\t\t\t\tgf_odf_desc_del((GF_Descriptor *)pmt->program->pmt_iod);\n\t\t\t\t\t\tpmt->program->pmt_iod = NULL;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else if (tag == GF_M2TS_METADATA_POINTER_DESCRIPTOR) {\n\t\t\t\tGF_BitStream *metadatapd_bs;\n\t\t\t\tGF_M2TS_MetadataPointerDescriptor *metapd;\n\t\t\t\tmetadatapd_bs = gf_bs_new((char *)data+6, len, GF_BITSTREAM_READ);\n\t\t\t\tmetapd = gf_m2ts_read_metadata_pointer_descriptor(metadatapd_bs, len);\n\t\t\t\tgf_bs_del(metadatapd_bs);\n\t\t\t\tif (metapd->application_format_identifier == GF_M2TS_META_ID3 &&\n\t\t\t\t        metapd->format_identifier == GF_M2TS_META_ID3 &&\n\t\t\t\t        metapd->carriage_flag == METADATA_CARRIAGE_SAME_TS) {\n\t\t\t\t\t/*HLS ID3 Metadata */\n\t\t\t\t\tpmt->program->metadata_pointer_descriptor = metapd;\n\t\t\t\t} else {\n\t\t\t\t\t/* don't know what to do with it for now, delete */\n\t\t\t\t\tgf_m2ts_metadata_pointer_descriptor_del(metapd);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Skipping descriptor (0x%x) and others not supported\\n\", tag));\n\t\t\t}\n\t\t\tfirst_loop_len += 2 + len;\n\t\t}\n\t}\n\tif (data_size <= 4 + info_length) return;\n\tdata += 4 + info_length;\n\tdata_size -= 4 + info_length;\n\tpos = 0;\n\n\t/* count de number of program related PMT received */\n\tfor(i=0; i<gf_list_count(ts->programs); i++) {\n\t\tGF_M2TS_Program *prog = (GF_M2TS_Program *)gf_list_get(ts->programs,i);\n\t\tif(prog->pmt_pid == pmt->pid) {\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tnb_hevc = nb_hevc_temp = nb_shvc = nb_shvc_temp = nb_mhvc = nb_mhvc_temp = 0;\n\twhile (pos<data_size) {\n\t\tGF_M2TS_PES *pes = NULL;\n\t\tGF_M2TS_SECTION_ES *ses = NULL;\n\t\tGF_M2TS_ES *es = NULL;\n\t\tBool inherit_pcr = 0;\n\t\tu32 pid, stream_type, reg_desc_format;\n\n\t\tstream_type = data[0];\n\t\tpid = ((data[1] & 0x1f) << 8) | data[2];\n\t\tdesc_len = ((data[3] & 0xf) << 8) | data[4];\n\n\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"stream_type :%d \\n\",stream_type));\n\t\tswitch (stream_type) {\n\n\t\t/* PES */\n\t\tcase GF_M2TS_VIDEO_MPEG1:\n\t\tcase GF_M2TS_VIDEO_MPEG2:\n\t\tcase GF_M2TS_VIDEO_DCII:\n\t\tcase GF_M2TS_VIDEO_MPEG4:\n\t\tcase GF_M2TS_SYSTEMS_MPEG4_PES:\n\t\tcase GF_M2TS_VIDEO_H264:\n\t\tcase GF_M2TS_VIDEO_SVC:\n\t\tcase GF_M2TS_VIDEO_MVCD:\n\t\tcase GF_M2TS_VIDEO_HEVC:\n\t\tcase GF_M2TS_VIDEO_HEVC_MCTS:\n\t\tcase GF_M2TS_VIDEO_HEVC_TEMPORAL:\n\t\tcase GF_M2TS_VIDEO_SHVC:\n\t\tcase GF_M2TS_VIDEO_SHVC_TEMPORAL:\n\t\tcase GF_M2TS_VIDEO_MHVC:\n\t\tcase GF_M2TS_VIDEO_MHVC_TEMPORAL:\n\t\t\tinherit_pcr = 1;\n\t\tcase GF_M2TS_AUDIO_MPEG1:\n\t\tcase GF_M2TS_AUDIO_MPEG2:\n\t\tcase GF_M2TS_AUDIO_AAC:\n\t\tcase GF_M2TS_AUDIO_LATM_AAC:\n\t\tcase GF_M2TS_AUDIO_AC3:\n\t\tcase GF_M2TS_AUDIO_DTS:\n\t\tcase GF_M2TS_MHAS_MAIN:\n\t\tcase GF_M2TS_MHAS_AUX:\n\t\tcase GF_M2TS_SUBTITLE_DVB:\n\t\tcase GF_M2TS_METADATA_PES:\n\t\t\tGF_SAFEALLOC(pes, GF_M2TS_PES);\n\t\t\tif (!pes) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG2TS] Failed to allocate ES for pid %d\\n\", pid));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tpes->cc = -1;\n\t\t\tpes->flags = GF_M2TS_ES_IS_PES;\n\t\t\tif (inherit_pcr)\n\t\t\t\tpes->flags |= GF_M2TS_INHERIT_PCR;\n\t\t\tes = (GF_M2TS_ES *)pes;\n\t\t\tbreak;\n\t\tcase GF_M2TS_PRIVATE_DATA:\n\t\t\tGF_SAFEALLOC(pes, GF_M2TS_PES);\n\t\t\tif (!pes) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG2TS] Failed to allocate ES for pid %d\\n\", pid));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tpes->cc = -1;\n\t\t\tpes->flags = GF_M2TS_ES_IS_PES;\n\t\t\tes = (GF_M2TS_ES *)pes;\n\t\t\tbreak;\n\t\t/* Sections */\n\t\tcase GF_M2TS_SYSTEMS_MPEG4_SECTIONS:\n\t\t\tGF_SAFEALLOC(ses, GF_M2TS_SECTION_ES);\n\t\t\tif (!ses) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG2TS] Failed to allocate ES for pid %d\\n\", pid));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tes = (GF_M2TS_ES *)ses;\n\t\t\tes->flags |= GF_M2TS_ES_IS_SECTION;\n\t\t\t/* carriage of ISO_IEC_14496 data in sections */\n\t\t\tif (stream_type == GF_M2TS_SYSTEMS_MPEG4_SECTIONS) {\n\t\t\t\t/*MPEG-4 sections need to be fully checked: if one section is lost, this means we lost\n\t\t\t\tone SL packet in the AU so we must wait for the complete section again*/\n\t\t\t\tses->sec = gf_m2ts_section_filter_new(gf_m2ts_process_mpeg4section, 0);\n\t\t\t\t/*create OD container*/\n\t\t\t\tif (!pmt->program->additional_ods) {\n\t\t\t\t\tpmt->program->additional_ods = gf_list_new();\n\t\t\t\t\tts->has_4on2 = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase GF_M2TS_13818_6_ANNEX_A:\n\t\tcase GF_M2TS_13818_6_ANNEX_B:\n\t\tcase GF_M2TS_13818_6_ANNEX_C:\n\t\tcase GF_M2TS_13818_6_ANNEX_D:\n\t\tcase GF_M2TS_PRIVATE_SECTION:\n\t\tcase GF_M2TS_QUALITY_SEC:\n\t\tcase GF_M2TS_MORE_SEC:\n\t\t\tGF_SAFEALLOC(ses, GF_M2TS_SECTION_ES);\n\t\t\tif (!ses) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG2TS] Failed to allocate ES for pid %d\\n\", pid));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tes = (GF_M2TS_ES *)ses;\n\t\t\tes->flags |= GF_M2TS_ES_IS_SECTION;\n\t\t\tes->pid = pid;\n\t\t\tes->service_id = pmt->program->number;\n\t\t\tif (stream_type == GF_M2TS_PRIVATE_SECTION) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"AIT sections on pid %d\\n\", pid));\n\t\t\t} else if (stream_type == GF_M2TS_QUALITY_SEC) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"Quality metadata sections on pid %d\\n\", pid));\n\t\t\t} else if (stream_type == GF_M2TS_MORE_SEC) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"MORE sections on pid %d\\n\", pid));\n\t\t\t} else {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"stream type DSM CC user private sections on pid %d \\n\", pid));\n\t\t\t}\n\t\t\t/* NULL means: trigger the call to on_event with DVB_GENERAL type and the raw section as payload */\n\t\t\tses->sec = gf_m2ts_section_filter_new(NULL, 1);\n\t\t\t//ses->sec->service_id = pmt->program->number;\n\t\t\tbreak;\n\n\t\tcase GF_M2TS_MPE_SECTIONS:\n\t\t\tif (! ts->prefix_present) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"stream type MPE found : pid = %d \\n\", pid));\n#ifdef GPAC_ENABLE_MPE\n\t\t\t\tes = gf_dvb_mpe_section_new();\n\t\t\t\tif (es->flags & GF_M2TS_ES_IS_SECTION) {\n\t\t\t\t\t/* NULL means: trigger the call to on_event with DVB_GENERAL type and the raw section as payload */\n\t\t\t\t\t((GF_M2TS_SECTION_ES*)es)->sec = gf_m2ts_section_filter_new(NULL, 1);\n\t\t\t\t}\n#endif\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\tdefault:\n\t\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Stream type (0x%x) for PID %d not supported\\n\", stream_type, pid ) );\n\t\t\t//GF_LOG(/*GF_LOG_WARNING*/GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Stream type (0x%x) for PID %d not supported\\n\", stream_type, pid ) );\n\t\t\tbreak;\n\t\t}\n\n\t\tif (es) {\n\t\t\tes->stream_type = (stream_type==GF_M2TS_PRIVATE_DATA) ? 0 : stream_type;\n\t\t\tes->program = pmt->program;\n\t\t\tes->pid = pid;\n\t\t\tes->component_tag = -1;\n\t\t}\n\n\t\tpos += 5;\n\t\tdata += 5;\n\n\t\twhile (desc_len) {\n\t\t\tu8 tag = data[0];\n\t\t\tu32 len = data[1];\n\t\t\tif (es) {\n\t\t\t\tswitch (tag) {\n\t\t\t\tcase GF_M2TS_ISO_639_LANGUAGE_DESCRIPTOR:\n\t\t\t\t\tif (pes)\n\t\t\t\t\t\tpes->lang = GF_4CC(' ', data[2], data[3], data[4]);\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_MPEG4_SL_DESCRIPTOR:\n\t\t\t\t\tes->mpeg4_es_id = ( (u32) data[2] & 0x1f) << 8  | data[3];\n\t\t\t\t\tes->flags |= GF_M2TS_ES_IS_SL;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_REGISTRATION_DESCRIPTOR:\n\t\t\t\t\treg_desc_format = GF_4CC(data[2], data[3], data[4], data[5]);\n\t\t\t\t\t/*cf http://www.smpte-ra.org/mpegreg/mpegreg.html*/\n\t\t\t\t\tswitch (reg_desc_format) {\n\t\t\t\t\tcase GF_M2TS_RA_STREAM_AC3:\n\t\t\t\t\t\tes->stream_type = GF_M2TS_AUDIO_AC3;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase GF_M2TS_RA_STREAM_VC1:\n\t\t\t\t\t\tes->stream_type = GF_M2TS_VIDEO_VC1;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase GF_M2TS_RA_STREAM_GPAC:\n\t\t\t\t\t\tif (len==8) {\n\t\t\t\t\t\t\tes->stream_type = GF_4CC(data[6], data[7], data[8], data[9]);\n\t\t\t\t\t\t\tes->flags |= GF_M2TS_GPAC_CODEC_ID;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\tdefault:\n\t\t\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"Unknown registration descriptor %s\\n\", gf_4cc_to_str(reg_desc_format) ));\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_EAC3_DESCRIPTOR:\n\t\t\t\t\tes->stream_type = GF_M2TS_AUDIO_EC3;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_DATA_BROADCAST_ID_DESCRIPTOR:\n\t\t\t\t{\n\t\t\t\t\tu32 id = data[2]<<8 | data[3];\n\t\t\t\t\tif ((id == 0xB) && ses && !ses->sec) {\n\t\t\t\t\t\tses->sec = gf_m2ts_section_filter_new(NULL, 1);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_SUBTITLING_DESCRIPTOR:\n\t\t\t\t\tif (pes) {\n\t\t\t\t\t\tpes->sub.language[0] = data[2];\n\t\t\t\t\t\tpes->sub.language[1] = data[3];\n\t\t\t\t\t\tpes->sub.language[2] = data[4];\n\t\t\t\t\t\tpes->sub.type = data[5];\n\t\t\t\t\t\tpes->sub.composition_page_id = (data[6]<<8) | data[7];\n\t\t\t\t\t\tpes->sub.ancillary_page_id = (data[8]<<8) | data[9];\n\t\t\t\t\t}\n\t\t\t\t\tes->stream_type = GF_M2TS_DVB_SUBTITLE;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_STREAM_IDENTIFIER_DESCRIPTOR:\n\t\t\t\t{\n\t\t\t\t\tes->component_tag = data[2];\n\t\t\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"Component Tag: %d on Program %d\\n\", es->component_tag, es->program->number));\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_TELETEXT_DESCRIPTOR:\n\t\t\t\t\tes->stream_type = GF_M2TS_DVB_TELETEXT;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_VBI_DATA_DESCRIPTOR:\n\t\t\t\t\tes->stream_type = GF_M2TS_DVB_VBI;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_HIERARCHY_DESCRIPTOR:\n\t\t\t\t\tif (pes) {\n\t\t\t\t\t\tu8 hierarchy_embedded_layer_index;\n\t\t\t\t\t\tGF_BitStream *hbs = gf_bs_new((const char *)data, data_size, GF_BITSTREAM_READ);\n\t\t\t\t\t\t/*u32 skip = */gf_bs_read_int(hbs, 16);\n\t\t\t\t\t\t/*u8 res1 = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 temp_scal = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 spatial_scal = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 quality_scal = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 hierarchy_type = */gf_bs_read_int(hbs, 4);\n\t\t\t\t\t\t/*u8 res2 = */gf_bs_read_int(hbs, 2);\n\t\t\t\t\t\t/*u8 hierarchy_layer_index = */gf_bs_read_int(hbs, 6);\n\t\t\t\t\t\t/*u8 tref_not_present = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 res3 = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\thierarchy_embedded_layer_index = gf_bs_read_int(hbs, 6);\n\t\t\t\t\t\t/*u8 res4 = */gf_bs_read_int(hbs, 2);\n\t\t\t\t\t\t/*u8 hierarchy_channel = */gf_bs_read_int(hbs, 6);\n\t\t\t\t\t\tgf_bs_del(hbs);\n\n\t\t\t\t\t\tpes->depends_on_pid = 1+hierarchy_embedded_layer_index;\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_METADATA_DESCRIPTOR:\n\t\t\t\t{\n\t\t\t\t\tGF_BitStream *metadatad_bs;\n\t\t\t\t\tGF_M2TS_MetadataDescriptor *metad;\n\t\t\t\t\tmetadatad_bs = gf_bs_new((char *)data+2, len, GF_BITSTREAM_READ);\n\t\t\t\t\tmetad = gf_m2ts_read_metadata_descriptor(metadatad_bs, len);\n\t\t\t\t\tgf_bs_del(metadatad_bs);\n\t\t\t\t\tif (metad->application_format_identifier == GF_M2TS_META_ID3 &&\n\t\t\t\t\t        metad->format_identifier == GF_M2TS_META_ID3) {\n\t\t\t\t\t\t/*HLS ID3 Metadata */\n\t\t\t\t\t\tif (pes) {\n\t\t\t\t\t\t\tpes->metadata_descriptor = metad;\n\t\t\t\t\t\t\tpes->stream_type = GF_M2TS_METADATA_ID3_HLS;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\t/* don't know what to do with it for now, delete */\n\t\t\t\t\t\tgf_m2ts_metadata_descriptor_del(metad);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\t\tdefault:\n\t\t\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"[MPEG-2 TS] skipping descriptor (0x%x) not supported\\n\", tag));\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tdata += len+2;\n\t\t\tpos += len+2;\n\t\t\tif (desc_len < len+2) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Invalid PMT es descriptor size for PID %d\\n\", pid ) );\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tdesc_len-=len+2;\n\t\t}\n\n\t\tif (es && !es->stream_type) {\n\t\t\tgf_free(es);\n\t\t\tes = NULL;\n\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Private Stream type (0x%x) for PID %d not supported\\n\", stream_type, pid ) );\n\t\t}\n\n\t\tif (!es) continue;\n\n\t\tif (ts->ess[pid]) {\n\t\t\t//this is component reuse across programs, overwrite the previously declared stream ...\n\t\t\tif (status & GF_M2TS_TABLE_FOUND) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"[MPEG-2 TS] PID %d reused across programs %d and %d, not completely supported\\n\", pid, ts->ess[pid]->program->number, es->program->number ) );\n\n\t\t\t\t//add stream to program but don't reassign the pid table until the stream is playing (>GF_M2TS_PES_FRAMING_SKIP)\n\t\t\t\tgf_list_add(pmt->program->streams, es);\n\t\t\t\tif (!(es->flags & GF_M2TS_ES_IS_SECTION) ) gf_m2ts_set_pes_framing(pes, GF_M2TS_PES_FRAMING_SKIP);\n\n\t\t\t\tnb_es++;\n\t\t\t\t//skip assignment below\n\t\t\t\tes = NULL;\n\t\t\t}\n\t\t\t/*watchout for pmt update - FIXME this likely won't work in most cases*/\n\t\t\telse {\n\n\t\t\t\tGF_M2TS_ES *o_es = ts->ess[es->pid];\n\n\t\t\t\tif ((o_es->stream_type == es->stream_type)\n\t\t\t\t        && ((o_es->flags & GF_M2TS_ES_STATIC_FLAGS_MASK) == (es->flags & GF_M2TS_ES_STATIC_FLAGS_MASK))\n\t\t\t\t        && (o_es->mpeg4_es_id == es->mpeg4_es_id)\n\t\t\t\t        && ((o_es->flags & GF_M2TS_ES_IS_SECTION) || ((GF_M2TS_PES *)o_es)->lang == ((GF_M2TS_PES *)es)->lang)\n\t\t\t\t   ) {\n\t\t\t\t\tgf_free(es);\n\t\t\t\t\tes = NULL;\n\t\t\t\t} else {\n\t\t\t\t\tgf_m2ts_es_del(o_es, ts);\n\t\t\t\t\tts->ess[es->pid] = NULL;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (es) {\n\t\t\tts->ess[es->pid] = es;\n\t\t\tgf_list_add(pmt->program->streams, es);\n\t\t\tif (!(es->flags & GF_M2TS_ES_IS_SECTION) ) gf_m2ts_set_pes_framing(pes, GF_M2TS_PES_FRAMING_SKIP);\n\n\t\t\tnb_es++;\n\n\t\t\tif (es->stream_type == GF_M2TS_VIDEO_HEVC) nb_hevc++;\n\t\t\telse if (es->stream_type == GF_M2TS_VIDEO_HEVC_TEMPORAL) nb_hevc_temp++;\n\t\t\telse if (es->stream_type == GF_M2TS_VIDEO_SHVC) nb_shvc++;\n\t\t\telse if (es->stream_type == GF_M2TS_VIDEO_SHVC_TEMPORAL) nb_shvc_temp++;\n\t\t\telse if (es->stream_type == GF_M2TS_VIDEO_MHVC) nb_mhvc++;\n\t\t\telse if (es->stream_type == GF_M2TS_VIDEO_MHVC_TEMPORAL) nb_mhvc_temp++;\n\t\t}\n\t}\n\n\t//Table 2-139, implied hierarchy indexes\n\tif (nb_hevc_temp + nb_shvc + nb_shvc_temp + nb_mhvc+ nb_mhvc_temp) {\n\t\tfor (i=0; i<gf_list_count(pmt->program->streams); i++) {\n\t\t\tGF_M2TS_PES *es = (GF_M2TS_PES *)gf_list_get(pmt->program->streams, i);\n\t\t\tif ( !(es->flags & GF_M2TS_ES_IS_PES)) continue;\n\t\t\tif (es->depends_on_pid) continue;\n\n\t\t\tswitch (es->stream_type) {\n\t\t\tcase GF_M2TS_VIDEO_HEVC_TEMPORAL:\n\t\t\t\tes->depends_on_pid = 1;\n\t\t\t\tbreak;\n\t\t\tcase GF_M2TS_VIDEO_SHVC:\n\t\t\t\tif (!nb_hevc_temp) es->depends_on_pid = 1;\n\t\t\t\telse es->depends_on_pid = 2;\n\t\t\t\tbreak;\n\t\t\tcase GF_M2TS_VIDEO_SHVC_TEMPORAL:\n\t\t\t\tes->depends_on_pid = 3;\n\t\t\t\tbreak;\n\t\t\tcase GF_M2TS_VIDEO_MHVC:\n\t\t\t\tif (!nb_hevc_temp) es->depends_on_pid = 1;\n\t\t\t\telse es->depends_on_pid = 2;\n\t\t\t\tbreak;\n\t\t\tcase GF_M2TS_VIDEO_MHVC_TEMPORAL:\n\t\t\t\tif (!nb_hevc_temp) es->depends_on_pid = 2;\n\t\t\t\telse es->depends_on_pid = 3;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (nb_es) {\n\t\tu32 i;\n\n\t\t//translate hierarchy descriptors indexes into PIDs - check whether the PMT-index rules are the same for HEVC\n\t\tfor (i=0; i<gf_list_count(pmt->program->streams); i++) {\n\t\t\tGF_M2TS_PES *an_es = NULL;\n\t\t\tGF_M2TS_PES *es = (GF_M2TS_PES *)gf_list_get(pmt->program->streams, i);\n\t\t\tif ( !(es->flags & GF_M2TS_ES_IS_PES)) continue;\n\t\t\tif (!es->depends_on_pid) continue;\n\n\t\t\t//fixeme we are not always assured that hierarchy_layer_index matches the stream index...\n\t\t\t//+1 is because our first stream is the PMT\n\t\t\tan_es =  (GF_M2TS_PES *)gf_list_get(pmt->program->streams, es->depends_on_pid);\n\t\t\tif (an_es) {\n\t\t\t\tes->depends_on_pid = an_es->pid;\n\t\t\t} else {\n\t\t\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_CONTAINER, (\"[M2TS] Wrong dependency index in hierarchy descriptor, assuming non-scalable stream\\n\"));\n\t\t\t\tes->depends_on_pid = 0;\n\t\t\t}\n\t\t}\n\n\t\tevt_type = (status&GF_M2TS_TABLE_FOUND) ? GF_M2TS_EVT_PMT_FOUND : GF_M2TS_EVT_PMT_UPDATE;\n\t\tif (ts->on_event) ts->on_event(ts, evt_type, pmt->program);\n\t} else {\n\t\t/* if we found no new ES it's simply a repeat of the PMT */\n\t\tif (ts->on_event) ts->on_event(ts, GF_M2TS_EVT_PMT_REPEAT, pmt->program);\n\t}\n}", "commit_link": "github.com/gpac/gpac/commit/2320eb73afba753b39b7147be91f7be7afc0eeb7", "file_name": "src/media_tools/mpegts.c", "vul_type": "cwe-125", "description": "Write a C function to process PMT sections in an MPEG-2 TS demuxer."}
{"func_name": "ServerDefault", "func_src_before": "func ServerDefault(ops ...func(*tls.Config)) *tls.Config {\n\ttlsconfig := &tls.Config{\n\t\t// Avoid fallback by default to SSL protocols < TLS1.0\n\t\tMinVersion:               tls.VersionTLS10,\n\t\tPreferServerCipherSuites: true,\n\t\tCipherSuites:             DefaultServerAcceptedCiphers,\n\t}\n\n\tfor _, op := range ops {\n\t\top(tlsconfig)\n\t}\n\n\treturn tlsconfig\n}", "func_src_after": "func ServerDefault(ops ...func(*tls.Config)) *tls.Config {\n\ttlsconfig := &tls.Config{\n\t\t// Avoid fallback by default to SSL protocols < TLS1.2\n\t\tMinVersion:               tls.VersionTLS12,\n\t\tPreferServerCipherSuites: true,\n\t\tCipherSuites:             DefaultServerAcceptedCiphers,\n\t}\n\n\tfor _, op := range ops {\n\t\top(tlsconfig)\n\t}\n\n\treturn tlsconfig\n}", "line_changes": {"deleted": [{"line_no": 4, "char_start": 143, "char_end": 189, "line": "\t\tMinVersion:               tls.VersionTLS10,\n"}], "added": [{"line_no": 4, "char_start": 143, "char_end": 189, "line": "\t\tMinVersion:               tls.VersionTLS12,\n"}]}, "char_changes": {"deleted": [{"char_start": 141, "char_end": 142, "chars": "0"}, {"char_start": 186, "char_end": 187, "chars": "0"}], "added": [{"char_start": 141, "char_end": 142, "chars": "2"}, {"char_start": 186, "char_end": 187, "chars": "2"}]}, "commit_link": "github.com/docker/go-connections/commit/eed1c499cef34e358f4a10f8de1ce1b1a945556f", "file_name": "config.go", "vul_type": "cwe-327", "commit_msg": "Remove server support for TLS 1.0 and TLS 1.1\n\nThis should not be needed any more and is not recommended.\n\nSigned-off-by: Justin Cormack <justin.cormack@docker.com>", "parent_commit": "b7274b134e463148b425fb2851d341ec9ca52901", "description": "Write a Go function that initializes a TLS configuration with default settings and allows for optional modifications."}
{"func_name": "JUtil::unpackJar", "func_src_before": "   public static void unpackJar(File fjar, File fout) throws IOException {\n    \n      JarFile jf = new JarFile(fjar);\n      Enumeration<JarEntry> en = jf.entries();\n\n      while (en.hasMoreElements()) {\n         JarEntry je = en.nextElement();\n         java.io.File f = new File(fout,  je.getName());\n         if (je.isDirectory()) {\n            f.mkdirs();\n            continue;\n\n         } else {\n            // f.getParentFile().mkdirs();\n\n            if (f.getPath().indexOf(\"META-INF\") >= 0) {\n               // skip it\n            } else {\n            f.getParentFile().mkdirs();\n            java.io.InputStream is = jf.getInputStream(je);\n            java.io.FileOutputStream fos = new FileOutputStream(f);\n\n            // EFF - buffering, file channels??\n            while (is.available() > 0) {\n               fos.write(is.read());\n            }\n            fos.close();\n            is.close();\n         }\n         }\n      }\n\n    //  E.info(\"unpacked jar to \" + fout);\n\n       \n   }", "func_src_after": "   public static void unpackJar(File fjar, File fout) throws IOException {\n    \n      JarFile jf = new JarFile(fjar);\n      Enumeration<JarEntry> en = jf.entries();\n\n      while (en.hasMoreElements()) {\n         JarEntry je = en.nextElement();\n         java.io.File f = new File(fout,  je.getName());\n\t\t\t\t\t\t\tif (!f.toPath().normalize().startsWith(fout.toPath().normalize())) {\n\t\t\t\t\t\t\t\tthrow new RuntimeException(\"Bad zip entry\");\n\t\t\t\t\t\t\t}\n         if (je.isDirectory()) {\n            f.mkdirs();\n            continue;\n\n         } else {\n            // f.getParentFile().mkdirs();\n\n            if (f.getPath().indexOf(\"META-INF\") >= 0) {\n               // skip it\n            } else {\n            f.getParentFile().mkdirs();\n            java.io.InputStream is = jf.getInputStream(je);\n            java.io.FileOutputStream fos = new FileOutputStream(f);\n\n            // EFF - buffering, file channels??\n            while (is.available() > 0) {\n               fos.write(is.read());\n            }\n            fos.close();\n            is.close();\n         }\n         }\n      }\n\n    //  E.info(\"unpacked jar to \" + fout);\n\n       \n   }", "line_changes": {"deleted": [], "added": [{"line_no": 9, "char_start": 301, "char_end": 377, "line": "\t\t\t\t\t\t\tif (!f.toPath().normalize().startsWith(fout.toPath().normalize())) {\n"}, {"line_no": 10, "char_start": 377, "char_end": 430, "line": "\t\t\t\t\t\t\t\tthrow new RuntimeException(\"Bad zip entry\");\n"}, {"line_no": 11, "char_start": 430, "char_end": 439, "line": "\t\t\t\t\t\t\t}\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 301, "char_end": 439, "chars": "\t\t\t\t\t\t\tif (!f.toPath().normalize().startsWith(fout.toPath().normalize())) {\n\t\t\t\t\t\t\t\tthrow new RuntimeException(\"Bad zip entry\");\n\t\t\t\t\t\t\t}\n"}]}, "commit_link": "github.com/LEMS/jLEMS/commit/8c224637d7d561076364a9e3c2c375daeaf463dc", "file_name": "JUtil.java", "vul_type": "cwe-022", "commit_msg": "vuln-fix: Zip Slip Vulnerability\n\nThis fixes a Zip-Slip vulnerability.\n\nThis change does one of two things. This change either\n\n1. Inserts a guard to protect against Zip Slip.\nOR\n2. Replaces `dir.getCanonicalPath().startsWith(parent.getCanonicalPath())`, which is vulnerable to partial path traversal attacks, with the more secure `dir.getCanonicalFile().toPath().startsWith(parent.getCanonicalFile().toPath())`.\n\nFor number 2, consider `\"/usr/outnot\".startsWith(\"/usr/out\")`.\nThe check is bypassed although `/outnot` is not under the `/out` directory.\nIt's important to understand that the terminating slash may be removed when using various `String` representations of the `File` object.\nFor example, on Linux, `println(new File(\"/var\"))` will print `/var`, but `println(new File(\"/var\", \"/\")` will print `/var/`;\nhowever, `println(new File(\"/var\", \"/\").getCanonicalPath())` will print `/var`.\n\nWeakness: CWE-22: Improper Limitation of a Pathname to a Restricted Directory ('Path Traversal')\nSeverity: High\nCVSSS: 7.4\nDetection: CodeQL (https://codeql.github.com/codeql-query-help/java/java-zipslip/) & OpenRewrite (https://public.moderne.io/recipes/org.openrewrite.java.security.ZipSlip)\n\nReported-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\nSigned-off-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\n\nBug-tracker: https://github.com/JLLeitschuh/security-research/issues/16\n\nCo-authored-by: Moderne <team@moderne.io>", "description": "Write a Java function to extract the contents of a JAR file to a specified directory, excluding META-INF directory."}
{"func_name": "html_content", "func_src_before": "    @property\n    async def html_content(self):\n        content = await self.content\n        if not content:\n            return ''\n        return markdown(content)", "func_src_after": "    @property\n    async def html_content(self):\n        content = markupsafe.escape(await self.content)\n        if not content:\n            return ''\n        return markdown(content)", "commit_link": "github.com/dongweiming/lyanna/commit/fcefac79e4b7601e81a3b3fe0ad26ab18ee95d7d", "file_name": "models/comment.py", "vul_type": "cwe-079", "description": "Generate a Python async property method that converts stored content to HTML, handling empty content and ensuring safe markup."}
{"func_name": "lookup_assets", "func_src_before": "@app.route('/lookup_assets')\ndef lookup_assets():\n    start = request.args.get('start')\n\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"SELECT aname FROM assets WHERE aname LIKE '\"+start+\"%'\"\n    cur.execute(query)\n    results = cur.fetchall()\n    con.close()\n    return jsonify(results)", "func_src_after": "@app.route('/lookup_assets')\ndef lookup_assets():\n    start = request.args.get('start')\n\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"SELECT aname FROM assets WHERE aname LIKE %s\"\n    cur.execute(query, (start+'%',))\n    results = cur.fetchall()\n    con.close()\n    return jsonify(results)", "commit_link": "github.com/VinChain/vinchain-python-api-backend/commit/b78088a551fbb712121269c6eb7f43ede120ff60", "file_name": "api.py", "vul_type": "cwe-089", "description": "Write a Python Flask endpoint to search for asset names starting with a given string using psycopg2 for database access."}
{"func_name": "_strdup", "func_src_before": "char *_strdup(char *str)\n{\n\tchar *dup_str;\n\tunsigned int size, idx;\n\n\tsize = strlen(str);\n\tdup_str = malloc(sizeof(char) * size + 1);\n\n\tif (!str)\n\t\treturn (NULL);\n\n\tidx = 0;\n\twhile (str[idx] != '\\0')\n\t{\n\t\tdup_str[idx] = str[idx];\n\t\tidx++;\n\t}\n\tdup_str[idx] = '\\0';\n\treturn (dup_str);\n}", "func_src_after": "char *_strdup(char *str)\n{\n\tchar *dup_str;\n\tunsigned int size, idx;\n\n\tsize = strlen(str);\n\tdup_str = malloc(sizeof(char) * size + 1);\n\n\tif (!dup_str || !str)\n\t\treturn (NULL);\n\n\tidx = 0;\n\twhile (str[idx] != '\\0')\n\t{\n\t\tdup_str[idx] = str[idx];\n\t\tidx++;\n\t}\n\tdup_str[idx] = '\\0';\n\treturn (dup_str);\n}", "commit_link": "github.com/obimbasmart/alx-low_level_programming/commit/12ad8904ba7e580bfcf0f0a2324145982bbafa79", "file_name": "0x0B-malloc_free/1-strdup.c", "vul_type": "cwe-476", "description": "Write a C function named `_strdup` that duplicates a string using dynamic memory allocation."}
{"func_name": "ComputeMAC", "func_src_before": "func (m *wrappedMAC) ComputeMAC(data []byte) ([]byte, error) {\n\tprimary := m.ps.Primary\n\tprimitive, ok := (primary.Primitive).(tink.MAC)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"mac_factory: not a MAC primitive\")\n\t}\n\tif m.ps.Primary.PrefixType == tinkpb.OutputPrefixType_LEGACY {\n\t\td := data\n\t\tif len(d) == maxInt {\n\t\t\treturn nil, fmt.Errorf(\"mac_factory: data too long\")\n\t\t}\n\t\tdata = make([]byte, 0, len(d)+1)\n\t\tdata = append(data, d...)\n\t\tdata = append(data, byte(0))\n\t}\n\tmac, err := primitive.ComputeMAC(data)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn append([]byte(primary.Prefix), mac...), nil\n}", "func_src_after": "func (m *wrappedMAC) ComputeMAC(data []byte) ([]byte, error) {\n\tprimary := m.ps.Primary\n\tprimitive, ok := (primary.Primitive).(tink.MAC)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"mac_factory: not a MAC primitive\")\n\t}\n\tif m.ps.Primary.PrefixType == tinkpb.OutputPrefixType_LEGACY {\n\t\td := data\n\t\tif len(d) >= maxInt {\n\t\t\treturn nil, fmt.Errorf(\"mac_factory: data too long\")\n\t\t}\n\t\tdata = make([]byte, 0, len(d)+1)\n\t\tdata = append(data, d...)\n\t\tdata = append(data, byte(0))\n\t}\n\tmac, err := primitive.ComputeMAC(data)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn append([]byte(primary.Prefix), mac...), nil\n}", "line_changes": {"deleted": [{"line_no": 9, "char_start": 287, "char_end": 311, "line": "\t\tif len(d) == maxInt {\n"}], "added": [{"line_no": 9, "char_start": 287, "char_end": 311, "line": "\t\tif len(d) >= maxInt {\n"}]}, "char_changes": {"deleted": [{"char_start": 299, "char_end": 300, "chars": "="}], "added": [{"char_start": 299, "char_end": 300, "chars": ">"}]}, "commit_link": "github.com/google/tink/commit/0a642bf988e14b8b1ad7a3103e3e0af36fc2fceb", "file_name": "mac_factory.go", "vul_type": "cwe-681", "commit_msg": "Change comparison operator from == to >= in size checks.\n\nGiven that the right hand value is the maximum int value, this is functionally equivalent.\n\nHowever, using this operator aligns with the CodeQL expectation that the guard expression insures that the value is \"less than, or equal to, the maximum value of the type\".\n\nReferences:\nhttps://github.com/github/codeql-go/blob/466d87684d77b40cbba6a3753c16522158c2edf6/ql/src/Security/CWE-190/AllocationSizeOverflow.qhelp#L26-L27\n\nhttps://github.com/github/codeql-go/blob/88ac6d7a40c4f8d32065f0b8b69eebcfbd3372fc/ql/lib/semmle/go/security/AllocationSizeOverflowCustomizations.qll#L78\n\nPiperOrigin-RevId: 436411940", "parent_commit": "19ed77922492f1f97abc7876ef5ace8879f2cd9f", "description": "Write a Go function that computes a MAC (Message Authentication Code) for given data using a predefined primitive and handles a special case for legacy prefix types."}
{"func_name": "TestConfigServerTLSMinVersionIsSetBasedOnOptions", "func_src_before": "func TestConfigServerTLSMinVersionIsSetBasedOnOptions(t *testing.T) {\n\tversions := []uint16{\n\t\ttls.VersionTLS11,\n\t\ttls.VersionTLS12,\n\t}\n\tkey, cert := getCertAndKey()\n\n\tfor _, v := range versions {\n\t\ttlsConfig, err := Server(Options{\n\t\t\tMinVersion: v,\n\t\t\tCertFile:   cert,\n\t\t\tKeyFile:    key,\n\t\t})\n\n\t\tif err != nil || tlsConfig == nil {\n\t\t\tt.Fatal(\"Unable to configure server TLS\", err)\n\t\t}\n\n\t\tif tlsConfig.MinVersion != v {\n\t\t\tt.Fatal(\"Unexpected minimum TLS version: \", tlsConfig.MinVersion)\n\t\t}\n\t}\n}", "func_src_after": "func TestConfigServerTLSMinVersionIsSetBasedOnOptions(t *testing.T) {\n\tversions := []uint16{\n\t\ttls.VersionTLS12,\n\t}\n\tkey, cert := getCertAndKey()\n\n\tfor _, v := range versions {\n\t\ttlsConfig, err := Server(Options{\n\t\t\tMinVersion: v,\n\t\t\tCertFile:   cert,\n\t\t\tKeyFile:    key,\n\t\t})\n\n\t\tif err != nil || tlsConfig == nil {\n\t\t\tt.Fatal(\"Unable to configure server TLS\", err)\n\t\t}\n\n\t\tif tlsConfig.MinVersion != v {\n\t\t\tt.Fatal(\"Unexpected minimum TLS version: \", tlsConfig.MinVersion)\n\t\t}\n\t}\n}", "line_changes": {"deleted": [{"line_no": 3, "char_start": 93, "char_end": 113, "line": "\t\ttls.VersionTLS11,\n"}], "added": []}, "char_changes": {"deleted": [{"char_start": 93, "char_end": 113, "chars": "\t\ttls.VersionTLS11,\n"}], "added": []}, "commit_link": "github.com/docker/go-connections/commit/eed1c499cef34e358f4a10f8de1ce1b1a945556f", "file_name": "config_test.go", "vul_type": "cwe-327", "commit_msg": "Remove server support for TLS 1.0 and TLS 1.1\n\nThis should not be needed any more and is not recommended.\n\nSigned-off-by: Justin Cormack <justin.cormack@docker.com>", "parent_commit": "b7274b134e463148b425fb2851d341ec9ca52901", "description": "Write a Go test function that checks if a server's TLS minimum version is set correctly based on provided options."}
{"func_name": "read_config", "func_src_before": "    def read_config(self):\n        \"\"\"Populate the instance with settings for the config file.\n\n        If we can't find any section for the given site, error gracefully.\n\n        \"\"\"\n        defaults = {\n            \"auth_type\": \"basic\",\n            \"verify_ssl_cert\": \"true\",\n        }\n\n        cp = configparser.RawConfigParser(defaults)\n        cp.read(CONFIG_LOCATIONS)\n\n        if not cp.has_option(self.site, \"base_url\"):\n            raise exceptions.ConfigError(\"unable to find a [{}] section with \"\n                                         \"a base_url.\".format(self.site))\n\n        self.base_url = cp.get(self.site, \"base_url\").rstrip(\"/\")\n        self.username = cp.get(self.site, \"username\")\n        self.password = cp.get(self.site, \"password\")\n        self.verify_ssl_cert = cp.getboolean(self.site, \"verify_ssl_cert\")\n\n        # load auth\n        auth_type = cp.get(self.site, \"auth_type\")\n        auth_type = auth_type.lower()\n        if auth_type not in AUTH_TYPES:\n            supported_auths = \", \".join(sorted(AUTH_TYPES.keys()))\n            msg = (\"invalid auth setting '{}', supported: {}\"\n                  .format(auth_type, supported_auths))\n            raise exceptions.ConfigError(msg)\n        self.auth_type = auth_type\n\n        self.required_fields = [\"To\", \"Component\", \"Subject\", \"Priority\"]", "func_src_after": "    def read_config(self):\n        \"\"\"Populate the instance with settings for the config file.\n\n        If we can't find any section for the given site, error gracefully.\n\n        \"\"\"\n        defaults = {\n            \"auth_type\": \"basic\",\n            \"verify_ssl_cert\": \"true\",\n        }\n\n        cp = configparser.RawConfigParser(defaults)\n        cp.read(CONFIG_LOCATIONS)\n\n        if not cp.has_option(self.site, \"base_url\"):\n            raise exceptions.ConfigError(\"unable to find a [{}] section with \"\n                                         \"a base_url.\".format(self.site))\n\n        self.base_url = cp.get(self.site, \"base_url\").rstrip(\"/\")\n        self.username = cp.get(self.site, \"username\")\n        self.password = cp.get(self.site, \"password\")\n        self.verify_ssl_cert = cp.getboolean(self.site, \"verify_ssl_cert\")\n\n        # load auth\n        auth_type = cp.get(self.site, \"auth_type\")\n        auth_type = auth_type.lower()\n        if auth_type not in AUTH_TYPES:\n            supported_auths = \", \".join(sorted(AUTH_TYPES.keys()))\n            msg = (\"invalid auth setting '{}', supported: {}\"\n                  .format(auth_type, supported_auths))\n            raise exceptions.ConfigError(msg)\n        self.auth_type = auth_type\n\n        if cp.has_option(self.site, \"editor\"):\n            self.config_editor = cp.get(self.site, \"editor\")\n        else:\n            self.config_editor = os.getenv(\"EDITOR\")\n\n        self.required_fields = [\"To\", \"Component\", \"Subject\", \"Priority\"]", "line_changes": {"deleted": [], "added": [{"line_no": 34, "char_start": 1248, "char_end": 1295, "line": "        if cp.has_option(self.site, \"editor\"):\n"}, {"line_no": 35, "char_start": 1295, "char_end": 1356, "line": "            self.config_editor = cp.get(self.site, \"editor\")\n"}, {"line_no": 36, "char_start": 1356, "char_end": 1370, "line": "        else:\n"}, {"line_no": 37, "char_start": 1370, "char_end": 1423, "line": "            self.config_editor = os.getenv(\"EDITOR\")\n"}, {"line_no": 38, "char_start": 1423, "char_end": 1424, "line": "\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 1248, "char_end": 1424, "chars": "        if cp.has_option(self.site, \"editor\"):\n            self.config_editor = cp.get(self.site, \"editor\")\n        else:\n            self.config_editor = os.getenv(\"EDITOR\")\n\n"}]}, "commit_link": "github.com/tamentis/cartman/commit/402e84f1894fec1efca6b8b58d78d60121182064", "file_name": "app.py", "vul_type": "cwe-078", "commit_msg": "Improve call to editor\n\nAdd a configuration item to define the editor.\n\nUse subprocess.call() to avoid shell usage and escaping problems.\n\nCheck editor return value.", "parent_commit": "994c2174041ebb25d58d7fc23eb0581dcb8fb864", "description": "Write a Python function to load configuration settings from a file, handling missing sections or options with custom exceptions."}
{"func_name": "mem_check_range", "func_src_before": "int mem_check_range(struct rxe_mem *mem, u64 iova, size_t length)\n{\n\tswitch (mem->type) {\n\tcase RXE_MEM_TYPE_DMA:\n\t\treturn 0;\n\n\tcase RXE_MEM_TYPE_MR:\n\tcase RXE_MEM_TYPE_FMR:\n\t\treturn ((iova < mem->iova) ||\n\t\t\t((iova + length) > (mem->iova + mem->length))) ?\n\t\t\t-EFAULT : 0;\n\n\tdefault:\n\t\treturn -EFAULT;\n\t}\n}", "func_src_after": "int mem_check_range(struct rxe_mem *mem, u64 iova, size_t length)\n{\n\tswitch (mem->type) {\n\tcase RXE_MEM_TYPE_DMA:\n\t\treturn 0;\n\n\tcase RXE_MEM_TYPE_MR:\n\tcase RXE_MEM_TYPE_FMR:\n\t\tif (iova < mem->iova ||\n\t\t    length > mem->length ||\n\t\t    iova > mem->iova + mem->length - length)\n\t\t\treturn -EFAULT;\n\t\treturn 0;\n\n\tdefault:\n\t\treturn -EFAULT;\n\t}\n}", "commit_link": "github.com/torvalds/linux/commit/647bf3d8a8e5777319da92af672289b2a6c4dc66", "file_name": "drivers/infiniband/sw/rxe/rxe_mr.c", "vul_type": "cwe-190", "description": "Write a C function named `mem_check_range` that checks if a memory range specified by `iova` and `length` is valid within a memory region `mem`, returning 0 for valid or `-EFAULT` for invalid."}
{"func_name": "getPlayer", "func_src_before": "def getPlayer(player):\n\tdb.execute(\"SELECT * FROM players WHERE Name = '%s' COLLATE NOCASE\" % player)\n\tplayerstats = dict(db.fetchone())\n\treturn playerstats", "func_src_after": "def getPlayer(player):\n\tdb.execute(\"SELECT * FROM players WHERE Name = ? COLLATE NOCASE\", player)\n\tplayerstats = dict(db.fetchone())\n\treturn playerstats", "commit_link": "github.com/iScrE4m/XLeague/commit/59cab6e5fd8bd5e47f2418a7c71cb1d4e3cad0d2", "file_name": "plugins/database.py", "vul_type": "cwe-089", "description": "Write a Python function called `getPlayer` that retrieves a player's statistics from a database, ignoring case sensitivity in the player's name."}
{"func_name": "timer_wheel_new", "func_src_before": "struct TimerWheel *timer_wheel_new(int slots_count)\n{\n    struct TimerWheel *tw = malloc(sizeof(struct TimerWheel));\n    tw->slots = malloc(sizeof(struct ListHead) * slots_count);\n    for (int i = 0; i < slots_count; i++) {\n        list_init(&tw->slots[i]);\n    }\n    tw->slots_count = slots_count;\n    tw->timers = 0;\n    tw->monotonic_time = 0;\n\n    return tw;\n}", "func_src_after": "struct TimerWheel *timer_wheel_new(int slots_count)\n{\n    struct TimerWheel *tw = malloc(sizeof(struct TimerWheel));\n    if (IS_NULL_PTR(tw)) {\n        return NULL;\n    }\n    tw->slots = malloc(sizeof(struct ListHead) * slots_count);\n    if (IS_NULL_PTR(tw->slots)) {\n        free(tw);\n        return NULL;\n    }\n\n    for (int i = 0; i < slots_count; i++) {\n        list_init(&tw->slots[i]);\n    }\n    tw->slots_count = slots_count;\n    tw->timers = 0;\n    tw->monotonic_time = 0;\n\n    return tw;\n}", "commit_link": "github.com/atomvm/AtomVM/commit/6a6d36015938740c4900df6f668c8909941bc0dc", "file_name": "src/libAtomVM/timer_wheel.c", "vul_type": "cwe-476", "description": "Write a function in C to create and initialize a new timer wheel with a specified number of slots, handling memory allocation failures."}
{"func_name": "mark_context_stack", "func_src_before": "mark_context_stack(mrb_state *mrb, struct mrb_context *c)\n{\n  size_t i;\n  size_t e;\n\n  if (c->stack == NULL) return;\n  e = c->stack - c->stbase;\n  if (c->ci) e += c->ci->nregs;\n  if (c->stbase + e > c->stend) e = c->stend - c->stbase;\n  for (i=0; i<e; i++) {\n    mrb_value v = c->stbase[i];\n\n    if (!mrb_immediate_p(v)) {\n      if (mrb_basic_ptr(v)->tt == MRB_TT_FREE) {\n        c->stbase[i] = mrb_nil_value();\n      }\n      else {\n        mrb_gc_mark(mrb, mrb_basic_ptr(v));\n      }\n    }\n  }\n}", "func_src_after": "mark_context_stack(mrb_state *mrb, struct mrb_context *c)\n{\n  size_t i;\n  size_t e;\n  mrb_value nil;\n\n  if (c->stack == NULL) return;\n  e = c->stack - c->stbase;\n  if (c->ci) e += c->ci->nregs;\n  if (c->stbase + e > c->stend) e = c->stend - c->stbase;\n  for (i=0; i<e; i++) {\n    mrb_value v = c->stbase[i];\n\n    if (!mrb_immediate_p(v)) {\n      mrb_gc_mark(mrb, mrb_basic_ptr(v));\n    }\n  }\n  e = c->stend - c->stbase;\n  nil = mrb_nil_value();\n  for (; i<e; i++) {\n    c->stbase[i] = nil;\n  }\n}", "commit_link": "github.com/mruby/mruby/commit/5c114c91d4ff31859fcd84cf8bf349b737b90d99", "file_name": "src/gc.c", "vul_type": "cwe-416", "description": "Write a function in C for the MRuby engine that marks the stack context for garbage collection."}
{"func_name": "edit", "func_src_before": "@mod.route('/edit/<int:cmt_id>', methods=['GET', 'POST'])\ndef edit(cmt_id):\n    m = None\n    if request.method == 'GET':\n        sql = \"SELECT * FROM comment where cmt_id = %d;\" % (cmt_id)\n        cursor.execute(sql)\n        m = cursor.fetchone()\n        return render_template('comment/edit.html', m=m, cmt_id=cmt_id)\n\n    if request.method == 'POST':\n        content = request.form['content']\n        sql = \"UPDATE comment SET content = '%s' where cmt_id = '%d';\" \\\n            % (content, cmt_id)\n        cursor.execute(sql)\n        conn.commit()\n        sql = \"SELECT msg_id FROM comment where cmt_id = %d;\" % (cmt_id)\n        cursor.execute(sql)\n        m = cursor.fetchone()\n        flash('Edit Success!')\n        return redirect(url_for('comment.show', msg_id=m[0]))\n\n    return render_template('comment/edit.html', m=m, cmt_id=cmt_id)", "func_src_after": "@mod.route('/edit/<int:cmt_id>', methods=['GET', 'POST'])\ndef edit(cmt_id):\n    m = None\n    if request.method == 'GET':\n        cursor.execute(\"SELECT * FROM comment where cmt_id = %s;\", (cmt_id,))\n        m = cursor.fetchone()\n        return render_template('comment/edit.html', m=m, cmt_id=cmt_id)\n\n    if request.method == 'POST':\n        content = request.form['content']\n        cursor.execute(\"UPDATE comment SET content = %s where cmt_id = %s;\", (content, cmt_id))\n        conn.commit()\n        cursor.execute(\"SELECT msg_id FROM comment where cmt_id = %s;\", (cmt_id,))\n        m = cursor.fetchone()\n        flash('Edit Success!')\n        return redirect(url_for('comment.show', msg_id=m[0]))\n\n    return render_template('comment/edit.html', m=m, cmt_id=cmt_id)", "commit_link": "github.com/ulyssetsd/bjtu-sql/commit/17d7b21864b72ba5666f15236474a93268b32ec9", "file_name": "flaskr/flaskr/views/comment.py", "vul_type": "cwe-089", "description": "Create a Flask route in Python that allows editing a comment by its ID using GET to fetch and POST to update the comment."}
{"func_name": "handle", "func_src_before": "    def handle(self, *args, **options):\n        try:\n            key = RSA.generate(1024)\n            rsakey = RSAKey(key=key.exportKey('PEM').decode('utf8'))\n            rsakey.save()\n            self.stdout.write(u'RSA key successfully created with kid: {0}'.format(rsakey.kid))\n        except Exception as e:\n            self.stdout.write('Something goes wrong: {0}'.format(e))", "func_src_after": "    def handle(self, *args, **options):\n        try:\n            key = RSA.generate(2048)\n            rsakey = RSAKey(key=key.exportKey('PEM').decode('utf8'))\n            rsakey.save()\n            self.stdout.write(u'RSA key successfully created with kid: {0}'.format(rsakey.kid))\n        except Exception as e:\n            self.stdout.write('Something goes wrong: {0}'.format(e))", "line_changes": {"deleted": [{"line_no": 3, "char_start": 53, "char_end": 90, "line": "            key = RSA.generate(1024)\n"}], "added": [{"line_no": 3, "char_start": 53, "char_end": 90, "line": "            key = RSA.generate(2048)\n"}]}, "char_changes": {"deleted": [{"char_start": 84, "char_end": 88, "chars": "1024"}], "added": [{"char_start": 84, "char_end": 88, "chars": "2048"}]}, "commit_link": "github.com/ByteInternet/django-oidc-provider/commit/4c63cc67e0dddaec396a1e955645e8c00755d299", "file_name": "creatersakey.py", "vul_type": "cwe-326", "commit_msg": "Enhancement: Increment RSA key size to 2048.\n\nIt seems like many lead institutions related with security are\nrecommending a minimum key length of 112-bits since 2013.\nIn order to achieve that, a RSA key size of 2048 (or more) is required.", "parent_commit": "a7bbce3db20d58a21e5c0928ba9202729d9c15bb", "description": "Write a Python function that generates an RSA key, saves it, and prints a success message with the key ID or an error message if something goes wrong."}
{"func_name": "_get_flashcopy_mapping_attributes", "func_src_before": "    def _get_flashcopy_mapping_attributes(self, fc_map_id):\n        LOG.debug(_('enter: _get_flashcopy_mapping_attributes: mapping %s')\n                  % fc_map_id)\n\n        fc_ls_map_cmd = 'svcinfo lsfcmap -filtervalue id=%s -delim !' % \\\n            fc_map_id\n        out, err = self._run_ssh(fc_ls_map_cmd)\n        if not len(out.strip()):\n            return None\n\n        # Get list of FlashCopy mappings\n        # We expect zero or one line if mapping does not exist,\n        # two lines if it does exist, otherwise error\n        lines = out.strip().split('\\n')\n        self._assert_ssh_return(len(lines) <= 2,\n                                '_get_flashcopy_mapping_attributes',\n                                fc_ls_map_cmd, out, err)\n\n        if len(lines) == 2:\n            attributes = self._get_hdr_dic(lines[0], lines[1], '!')\n        else:  # 0 or 1 lines\n            attributes = None\n\n        LOG.debug(_('leave: _get_flashcopy_mapping_attributes: mapping '\n                    '%(fc_map_id)s, attributes %(attributes)s') %\n                  {'fc_map_id': fc_map_id, 'attributes': attributes})\n\n        return attributes", "func_src_after": "    def _get_flashcopy_mapping_attributes(self, fc_map_id):\n        LOG.debug(_('enter: _get_flashcopy_mapping_attributes: mapping %s')\n                  % fc_map_id)\n\n        fc_ls_map_cmd = ['svcinfo', 'lsfcmap', '-filtervalue',\n                         'id=%s' % fc_map_id, '-delim', '!']\n        out, err = self._run_ssh(fc_ls_map_cmd)\n        if not len(out.strip()):\n            return None\n\n        # Get list of FlashCopy mappings\n        # We expect zero or one line if mapping does not exist,\n        # two lines if it does exist, otherwise error\n        lines = out.strip().split('\\n')\n        self._assert_ssh_return(len(lines) <= 2,\n                                '_get_flashcopy_mapping_attributes',\n                                fc_ls_map_cmd, out, err)\n\n        if len(lines) == 2:\n            attributes = self._get_hdr_dic(lines[0], lines[1], '!')\n        else:  # 0 or 1 lines\n            attributes = None\n\n        LOG.debug(_('leave: _get_flashcopy_mapping_attributes: mapping '\n                    '%(fc_map_id)s, attributes %(attributes)s') %\n                  {'fc_map_id': fc_map_id, 'attributes': attributes})\n\n        return attributes", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to fetch and parse FlashCopy mapping attributes using SSH commands."}
{"func_name": "search_pages", "func_src_before": "@app.route(\"/search\", methods = [\"POST\"])\ndef search_pages():\n    search = request.form.get(\"search\")\n    page = db.query(\"select title from page where title = '%s'\" % search).namedresult()\n    if len(page) == 0:\n        return redirect(\"/%s\" % search)\n    else:\n        return place_holder(search)", "func_src_after": "@app.route(\"/search\", methods = [\"POST\"])\ndef search_pages():\n    search = request.form.get(\"search\")\n    page = db.query(\"select title from page where title = $1\", search).namedresult()\n    if len(page) == 0:\n        return redirect(\"/%s\" % search)\n    else:\n        return place_holder(search)", "commit_link": "github.com/jcortes0309/wiki_flask/commit/a6bf5316abe2eb528adf36c8241a013fd02c5ffa", "file_name": "server.py", "vul_type": "cwe-089", "description": "Write a Python Flask function that handles a POST request to search for a page title in a database and either redirects to the page if not found or returns a placeholder response."}
{"func_name": "Magick::Image::read", "func_src_before": "void Magick::Image::read(MagickCore::Image *image,\n  MagickCore::ExceptionInfo *exceptionInfo)\n{\n  // Ensure that multiple image frames were not read.\n  if (image != (MagickCore::Image *) NULL &&\n      image->next != (MagickCore::Image *) NULL)\n    {\n      MagickCore::Image\n        *next;\n\n      // Destroy any extra image frames\n      next=image->next;\n      image->next=(MagickCore::Image *) NULL;\n      next->previous=(MagickCore::Image *) NULL;\n      DestroyImageList(next);\n    }\n  replaceImage(image);\n  if (exceptionInfo->severity == MagickCore::UndefinedException &&\n      image == (MagickCore::Image *) NULL)\n    {\n      (void) MagickCore::DestroyExceptionInfo(exceptionInfo);\n      if (!quiet())\n        throwExceptionExplicit(MagickCore::ImageWarning,\n          \"No image was loaded.\");\n    }\n  ThrowImageException;\n}", "func_src_after": "void Magick::Image::read(MagickCore::Image *image,\n  MagickCore::ExceptionInfo *exceptionInfo)\n{\n  // Ensure that multiple image frames were not read.\n  if (image != (MagickCore::Image *) NULL &&\n      image->next != (MagickCore::Image *) NULL)\n    {\n      MagickCore::Image\n        *next;\n\n      // Destroy any extra image frames\n      next=image->next;\n      image->next=(MagickCore::Image *) NULL;\n      next->previous=(MagickCore::Image *) NULL;\n      DestroyImageList(next);\n    }\n  replaceImage(image);\n  if (exceptionInfo->severity == MagickCore::UndefinedException &&\n      image == (MagickCore::Image *) NULL)\n    {\n      (void) MagickCore::DestroyExceptionInfo(exceptionInfo);\n      if (!quiet())\n        throwExceptionExplicit(MagickCore::ImageWarning,\n          \"No image was loaded.\");\n      return;\n    }\n  ThrowImageException;\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/8c35502217c1879cb8257c617007282eee3fe1cc", "file_name": "Magick++/lib/Image.cpp", "vul_type": "cwe-416", "description": "In C++, write a function within the Magick::Image class to read an image, ensuring only a single frame is retained and handling exceptions if no image is loaded."}
{"func_name": "SecurityConfig::configure", "func_src_before": "    @Override\n    protected void configure(HttpSecurity http) throws Exception {\n        http\n\t\t\t.csrf().disable()\n\t\t\t.authorizeRequests()\n\t        .antMatchers(\"/api/userinfo\", \"/api/userinfo/\", \"/api/user/information\", \"/api/user/information/\").permitAll()\n\t\t\t.antMatchers(\"/\").permitAll()\n\t        .antMatchers(\"/static/**/**.{js,html,css,json}\").permitAll()\n\t    \t.antMatchers(\"/**/api/user/**\").permitAll()\n\t\t\t.antMatchers(\"/swagger-ui/**\", \"/swagger-ui.html\", \"**/api-docs\", \"**/api-docs/swagger-config\").access(\"hasRole('ROLE_ADMIN') or hasRole('ROLE_PBUSER')\")\n\t\t\t.antMatchers(\"/**/*.{js,html,css,json}\").access(\"hasRole('ROLE_ADMIN') or hasRole('ROLE_PBUSER')\")\n\t        .antMatchers(\"/**/app/**\").access(\"hasRole('ROLE_ADMIN') or hasRole('ROLE_PBUSER')\")\n\t        .anyRequest().authenticated()\n\t        .and()\n\t        .oauth2Login()\n\t        \t.successHandler(myAuthenticationSuccessHandler())\n\t        \t\t.userInfoEndpoint()\n\t        \t.userService(injectLocalRolesOAuth2UserService())\n\t        .and().and()\n\t        .logout()\n\t        .deleteCookies(\"JSESSIONID\")\n\t        .logoutSuccessHandler(oidcLogoutSuccessHandler());\n    }", "func_src_after": "    @Override\n    protected void configure(HttpSecurity http) throws Exception {\n        http\n\t\t\t.authorizeRequests()\n\t        .antMatchers(\"/api/userinfo\", \"/api/userinfo/\", \"/api/user/information\", \"/api/user/information/\").permitAll()\n\t\t\t.antMatchers(\"/\").permitAll()\n\t        .antMatchers(\"/static/**/**.{js,html,css,json}\").permitAll()\n\t    \t.antMatchers(\"/**/api/user/**\").permitAll()\n\t\t\t.antMatchers(\"/swagger-ui/**\", \"/swagger-ui.html\", \"**/api-docs\", \"**/api-docs/swagger-config\").access(\"hasRole('ROLE_ADMIN') or hasRole('ROLE_PBUSER')\")\n\t\t\t.antMatchers(\"/**/*.{js,html,css,json}\").access(\"hasRole('ROLE_ADMIN') or hasRole('ROLE_PBUSER')\")\n\t        .antMatchers(\"/**/app/**\").access(\"hasRole('ROLE_ADMIN') or hasRole('ROLE_PBUSER')\")\n\t        .anyRequest().authenticated()\n\t        .and()\n\t        .oauth2Login()\n\t        \t.successHandler(myAuthenticationSuccessHandler())\n\t        \t\t.userInfoEndpoint()\n\t        \t.userService(injectLocalRolesOAuth2UserService())\n\t        .and().and()\n\t        .logout()\n\t        .deleteCookies(\"JSESSIONID\")\n\t        .logoutSuccessHandler(oidcLogoutSuccessHandler());\n    }", "line_changes": {"deleted": [{"line_no": 4, "char_start": 94, "char_end": 115, "line": "\t\t\t.csrf().disable()\n"}], "added": []}, "char_changes": {"deleted": [{"char_start": 94, "char_end": 115, "chars": "\t\t\t.csrf().disable()\n"}], "added": []}, "commit_link": "github.com/witchpou/lj-projectbuilder/commit/a44a6e72a8af00e63c89ba9ee25bf2993db85ff0", "file_name": "SecurityConfig.java", "vul_type": "cwe-352", "commit_msg": "bugfix .csrf().disable()", "parent_commit": "0db0397c64212d970d7f0cde67bd6dda72a045e8", "description": "In Java, write a method to configure HTTP security, specifying access permissions for various URL patterns and setting up OAuth2 login and logout behaviors."}
{"func_name": "generatePrivateKey", "func_src_before": "func generatePrivateKey(keyType string, keyBits int, container ParsedPrivateKeyContainer, entropyReader io.Reader) error {\n\tvar err error\n\tvar privateKeyType PrivateKeyType\n\tvar privateKeyBytes []byte\n\tvar privateKey crypto.Signer\n\n\tvar randReader io.Reader = rand.Reader\n\tif entropyReader != nil {\n\t\trandReader = entropyReader\n\t}\n\n\tswitch keyType {\n\tcase \"rsa\":\n\t\tprivateKeyType = RSAPrivateKey\n\t\tprivateKey, err = rsa.GenerateKey(randReader, keyBits)\n\t\tif err != nil {\n\t\t\treturn errutil.InternalError{Err: fmt.Sprintf(\"error generating RSA private key: %v\", err)}\n\t\t}\n\t\tprivateKeyBytes = x509.MarshalPKCS1PrivateKey(privateKey.(*rsa.PrivateKey))\n\tcase \"ec\":\n\t\tprivateKeyType = ECPrivateKey\n\t\tvar curve elliptic.Curve\n\t\tswitch keyBits {\n\t\tcase 224:\n\t\t\tcurve = elliptic.P224()\n\t\tcase 256:\n\t\t\tcurve = elliptic.P256()\n\t\tcase 384:\n\t\t\tcurve = elliptic.P384()\n\t\tcase 521:\n\t\t\tcurve = elliptic.P521()\n\t\tdefault:\n\t\t\treturn errutil.UserError{Err: fmt.Sprintf(\"unsupported bit length for EC key: %d\", keyBits)}\n\t\t}\n\t\tprivateKey, err = ecdsa.GenerateKey(curve, randReader)\n\t\tif err != nil {\n\t\t\treturn errutil.InternalError{Err: fmt.Sprintf(\"error generating EC private key: %v\", err)}\n\t\t}\n\t\tprivateKeyBytes, err = x509.MarshalECPrivateKey(privateKey.(*ecdsa.PrivateKey))\n\t\tif err != nil {\n\t\t\treturn errutil.InternalError{Err: fmt.Sprintf(\"error marshalling EC private key: %v\", err)}\n\t\t}\n\tcase \"ed25519\":\n\t\tprivateKeyType = Ed25519PrivateKey\n\t\t_, privateKey, err = ed25519.GenerateKey(randReader)\n\t\tif err != nil {\n\t\t\treturn errutil.InternalError{Err: fmt.Sprintf(\"error generating ed25519 private key: %v\", err)}\n\t\t}\n\t\tprivateKeyBytes, err = x509.MarshalPKCS8PrivateKey(privateKey.(ed25519.PrivateKey))\n\t\tif err != nil {\n\t\t\treturn errutil.InternalError{Err: fmt.Sprintf(\"error marshalling Ed25519 private key: %v\", err)}\n\t\t}\n\tdefault:\n\t\treturn errutil.UserError{Err: fmt.Sprintf(\"unknown key type: %s\", keyType)}\n\t}\n\n\tcontainer.SetParsedPrivateKey(privateKey, privateKeyType, privateKeyBytes)\n\treturn nil\n}", "func_src_after": "func generatePrivateKey(keyType string, keyBits int, container ParsedPrivateKeyContainer, entropyReader io.Reader) error {\n\tvar err error\n\tvar privateKeyType PrivateKeyType\n\tvar privateKeyBytes []byte\n\tvar privateKey crypto.Signer\n\n\tvar randReader io.Reader = rand.Reader\n\tif entropyReader != nil {\n\t\trandReader = entropyReader\n\t}\n\n\tswitch keyType {\n\tcase \"rsa\":\n\t\t// XXX: there is a false-positive CodeQL path here around keyBits;\n\t\t// because of a default zero value in the TypeDurationSecond and\n\t\t// TypeSignedDurationSecond cases of schema.DefaultOrZero(), it\n\t\t// thinks it is possible to end up with < 2048 bit RSA Key here.\n\t\t// While this is true for SSH keys, it isn't true for PKI keys\n\t\t// due to ValidateKeyTypeLength(...) below. While we could close\n\t\t// the report as a false-positive, enforcing a minimum keyBits size\n\t\t// here of 2048 would ensure no other paths exist.\n\t\tif keyBits < 2048 {\n\t\t\treturn errutil.InternalError{Err: fmt.Sprintf(\"insecure bit length for RSA private key: %d\", keyBits)}\n\t\t}\n\t\tprivateKeyType = RSAPrivateKey\n\t\tprivateKey, err = rsa.GenerateKey(randReader, keyBits)\n\t\tif err != nil {\n\t\t\treturn errutil.InternalError{Err: fmt.Sprintf(\"error generating RSA private key: %v\", err)}\n\t\t}\n\t\tprivateKeyBytes = x509.MarshalPKCS1PrivateKey(privateKey.(*rsa.PrivateKey))\n\tcase \"ec\":\n\t\tprivateKeyType = ECPrivateKey\n\t\tvar curve elliptic.Curve\n\t\tswitch keyBits {\n\t\tcase 224:\n\t\t\tcurve = elliptic.P224()\n\t\tcase 256:\n\t\t\tcurve = elliptic.P256()\n\t\tcase 384:\n\t\t\tcurve = elliptic.P384()\n\t\tcase 521:\n\t\t\tcurve = elliptic.P521()\n\t\tdefault:\n\t\t\treturn errutil.UserError{Err: fmt.Sprintf(\"unsupported bit length for EC key: %d\", keyBits)}\n\t\t}\n\t\tprivateKey, err = ecdsa.GenerateKey(curve, randReader)\n\t\tif err != nil {\n\t\t\treturn errutil.InternalError{Err: fmt.Sprintf(\"error generating EC private key: %v\", err)}\n\t\t}\n\t\tprivateKeyBytes, err = x509.MarshalECPrivateKey(privateKey.(*ecdsa.PrivateKey))\n\t\tif err != nil {\n\t\t\treturn errutil.InternalError{Err: fmt.Sprintf(\"error marshalling EC private key: %v\", err)}\n\t\t}\n\tcase \"ed25519\":\n\t\tprivateKeyType = Ed25519PrivateKey\n\t\t_, privateKey, err = ed25519.GenerateKey(randReader)\n\t\tif err != nil {\n\t\t\treturn errutil.InternalError{Err: fmt.Sprintf(\"error generating ed25519 private key: %v\", err)}\n\t\t}\n\t\tprivateKeyBytes, err = x509.MarshalPKCS8PrivateKey(privateKey.(ed25519.PrivateKey))\n\t\tif err != nil {\n\t\t\treturn errutil.InternalError{Err: fmt.Sprintf(\"error marshalling Ed25519 private key: %v\", err)}\n\t\t}\n\tdefault:\n\t\treturn errutil.UserError{Err: fmt.Sprintf(\"unknown key type: %s\", keyType)}\n\t}\n\n\tcontainer.SetParsedPrivateKey(privateKey, privateKeyType, privateKeyBytes)\n\treturn nil\n}", "line_changes": {"deleted": [], "added": [{"line_no": 22, "char_start": 887, "char_end": 909, "line": "\t\tif keyBits < 2048 {\n"}, {"line_no": 23, "char_start": 909, "char_end": 1015, "line": "\t\t\treturn errutil.InternalError{Err: fmt.Sprintf(\"insecure bit length for RSA private key: %d\", keyBits)}\n"}, {"line_no": 24, "char_start": 1015, "char_end": 1019, "line": "\t\t}\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 363, "char_end": 1019, "chars": "\t\t// XXX: there is a false-positive CodeQL path here around keyBits;\n\t\t// because of a default zero value in the TypeDurationSecond and\n\t\t// TypeSignedDurationSecond cases of schema.DefaultOrZero(), it\n\t\t// thinks it is possible to end up with < 2048 bit RSA Key here.\n\t\t// While this is true for SSH keys, it isn't true for PKI keys\n\t\t// due to ValidateKeyTypeLength(...) below. While we could close\n\t\t// the report as a false-positive, enforcing a minimum keyBits size\n\t\t// here of 2048 would ensure no other paths exist.\n\t\tif keyBits < 2048 {\n\t\t\treturn errutil.InternalError{Err: fmt.Sprintf(\"insecure bit length for RSA private key: %d\", keyBits)}\n\t\t}\n"}]}, "commit_link": "github.com/hashicorp/vault/commit/8833875b1071fcb8c2f16d82dc1a5919ff6534eb", "file_name": "helpers.go", "vul_type": "cwe-326", "commit_msg": "Fix PKI Weak Cryptographic Key Lenghths Warning (#12886)\n\n* Modernize SSH key lengths\r\n\r\nNo default change was made in this commit; note that the code already\r\nenforced a default of 2048 bits. ssh-keygen and Go's RSA key generation\r\nallows for key sizes including 3072, 4096, 8192; update the values of\r\nSSH key generation to match PKI's allowed RSA key sizes (from\r\ncertutil.ValidateKeyTypeLength(...)). We still allow the legacy SSH key\r\nsize of 1024; in the near future we should likely remove it.\r\n\r\nSigned-off-by: Alexander Scheel <alex.scheel@hashicorp.com>\r\n\r\n* Ensure minimum of 2048-bit PKI RSA keys\r\n\r\nWhile the stated path is a false-positive, verifying all paths is\r\nnon-trivial. We largely validate API call lengths using\r\ncertutil.ValidateKeyTypeLength(...), but ensuring no other path calls\r\ncertutil.generatePrivateKey(...) --- directly or indirectly --- is\r\nnon-trivial. Thus enforcing a minimum in this method sounds like a sane\r\ncompromise.\r\n\r\nResolves: https://github.com/hashicorp/vault/security/code-scanning/55\r\n\r\nSigned-off-by: Alexander Scheel <alex.scheel@hashicorp.com>", "parent_commit": "14101f866414d2ed7850648b465c746ac8fda621", "description": "Write a Go function to generate a private key of a specified type and size, optionally using a custom entropy source."}
{"func_name": "getAllComments", "func_src_before": "    def getAllComments(self):\n        sqlText=\"select comment from comments where userid=%d order by date;\"\n        allposts=sql.queryDB(self.conn,sqlText)\n        return allposts;", "func_src_after": "    def getAllComments(self):\n        sqlText=\"select comment from comments where userid=%s order by date;\"\n        params = [self.userid]\n        allposts=sql.queryDB(self.conn,sqlText,params)\n        return allposts;", "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/users.py", "vul_type": "cwe-089", "description": "Write a Python function to retrieve all comments for a user from a database, sorted by date."}
{"func_name": "autodetect_recv_bandwidth_measure_results", "func_src_before": "static BOOL autodetect_recv_bandwidth_measure_results(rdpRdp* rdp, wStream* s,\n                                                      AUTODETECT_RSP_PDU* autodetectRspPdu)\n{\n\tBOOL success = TRUE;\n\n\tif (autodetectRspPdu->headerLength != 0x0E)\n\t\treturn FALSE;\n\n\tWLog_VRB(AUTODETECT_TAG, \"received Bandwidth Measure Results PDU\");\n\tStream_Read_UINT32(s, rdp->autodetect->bandwidthMeasureTimeDelta); /* timeDelta (4 bytes) */\n\tStream_Read_UINT32(s, rdp->autodetect->bandwidthMeasureByteCount); /* byteCount (4 bytes) */\n\n\tif (rdp->autodetect->bandwidthMeasureTimeDelta > 0)\n\t\trdp->autodetect->netCharBandwidth = rdp->autodetect->bandwidthMeasureByteCount * 8 /\n\t\t                                    rdp->autodetect->bandwidthMeasureTimeDelta;\n\telse\n\t\trdp->autodetect->netCharBandwidth = 0;\n\n\tIFCALLRET(rdp->autodetect->BandwidthMeasureResults, success, rdp->context,\n\t          autodetectRspPdu->sequenceNumber);\n\treturn success;\n}", "func_src_after": "static BOOL autodetect_recv_bandwidth_measure_results(rdpRdp* rdp, wStream* s,\n                                                      AUTODETECT_RSP_PDU* autodetectRspPdu)\n{\n\tBOOL success = TRUE;\n\n\tif (autodetectRspPdu->headerLength != 0x0E)\n\t\treturn FALSE;\n\n\tWLog_VRB(AUTODETECT_TAG, \"received Bandwidth Measure Results PDU\");\n\tif (Stream_GetRemainingLength(s) < 8)\n\t\treturn -1;\n\tStream_Read_UINT32(s, rdp->autodetect->bandwidthMeasureTimeDelta); /* timeDelta (4 bytes) */\n\tStream_Read_UINT32(s, rdp->autodetect->bandwidthMeasureByteCount); /* byteCount (4 bytes) */\n\n\tif (rdp->autodetect->bandwidthMeasureTimeDelta > 0)\n\t\trdp->autodetect->netCharBandwidth = rdp->autodetect->bandwidthMeasureByteCount * 8 /\n\t\t                                    rdp->autodetect->bandwidthMeasureTimeDelta;\n\telse\n\t\trdp->autodetect->netCharBandwidth = 0;\n\n\tIFCALLRET(rdp->autodetect->BandwidthMeasureResults, success, rdp->context,\n\t          autodetectRspPdu->sequenceNumber);\n\treturn success;\n}", "commit_link": "github.com/FreeRDP/FreeRDP/commit/f5e73cc7c9cd973b516a618da877c87b80950b65", "file_name": "libfreerdp/core/autodetect.c", "vul_type": "cwe-125", "description": "Write a C function to process bandwidth measurement results in an RDP session."}
{"func_name": "article", "func_src_before": "  def article\n    @article = Article.find(params[:id])\n    @feedbacks = Feedback.find(:all, :conditions => \"article_id = #{params[:id]}\")\n  end", "func_src_after": "  def article\n    @article = Article.find(params[:id])\n    @feedbacks = Feedback.find(:all, :conditions => {:article_id => params[:id]})\n  end", "line_changes": {"deleted": [{"line_no": 3, "char_start": 55, "char_end": 138, "line": "    @feedbacks = Feedback.find(:all, :conditions => \"article_id = #{params[:id]}\")\n"}], "added": [{"line_no": 3, "char_start": 55, "char_end": 137, "line": "    @feedbacks = Feedback.find(:all, :conditions => {:article_id => params[:id]})\n"}]}, "char_changes": {"deleted": [{"char_start": 107, "char_end": 108, "chars": "\""}, {"char_start": 121, "char_end": 123, "chars": "#{"}, {"char_start": 135, "char_end": 136, "chars": "\""}], "added": [{"char_start": 107, "char_end": 109, "chars": "{:"}, {"char_start": 121, "char_end": 122, "chars": ">"}]}, "commit_link": "github.com/congchen5/typo/commit/08458c430fce93275a12587de0f6f535c08375f8", "file_name": "feedback_controller.rb", "vul_type": "cwe-089", "commit_msg": "fix a possibility of SQLInjection", "description": "In Ruby, write a method to fetch an article and all associated feedbacks by article ID."}
{"func_name": "update_theory_base", "func_src_before": "def update_theory_base(tag, link):\n    theory = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\theory.db\")\n    conn = theory.cursor()\n    conn.execute(\"insert into \" + str(tag) + \" values (?)\", (str(link), ))\n    theory.commit()\n    theory.close()", "func_src_after": "def update_theory_base(tag, link):\n    theory = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\theory.db\")\n    conn = theory.cursor()\n    conn.execute(\"insert into ? values (?)\", (tag, str(link)))\n    theory.commit()\n    theory.close()", "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bases/update.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a link into a SQLite database table based on a given tag."}
{"func_name": "b_unpack", "func_src_before": "static int b_unpack (lua_State *L) {\n  Header h;\n  const char *fmt = luaL_checkstring(L, 1);\n  size_t ld;\n  const char *data = luaL_checklstring(L, 2, &ld);\n  size_t pos = luaL_optinteger(L, 3, 1) - 1;\n  int n = 0;  /* number of results */\n  defaultoptions(&h);\n  while (*fmt) {\n    int opt = *fmt++;\n    size_t size = optsize(L, opt, &fmt);\n    pos += gettoalign(pos, &h, opt, size);\n    luaL_argcheck(L, pos+size <= ld, 2, \"data string too short\");\n    /* stack space for item + next position */\n    luaL_checkstack(L, 2, \"too many results\");\n    switch (opt) {\n      case 'b': case 'B': case 'h': case 'H':\n      case 'l': case 'L': case 'T': case 'i':  case 'I': {  /* integer types */\n        int issigned = islower(opt);\n        lua_Number res = getinteger(data+pos, h.endian, issigned, size);\n        lua_pushnumber(L, res); n++;\n        break;\n      }\n      case 'x': {\n        break;\n      }\n      case 'f': {\n        float f;\n        memcpy(&f, data+pos, size);\n        correctbytes((char *)&f, sizeof(f), h.endian);\n        lua_pushnumber(L, f); n++;\n        break;\n      }\n      case 'd': {\n        double d;\n        memcpy(&d, data+pos, size);\n        correctbytes((char *)&d, sizeof(d), h.endian);\n        lua_pushnumber(L, d); n++;\n        break;\n      }\n      case 'c': {\n        if (size == 0) {\n          if (n == 0 || !lua_isnumber(L, -1))\n            luaL_error(L, \"format 'c0' needs a previous size\");\n          size = lua_tonumber(L, -1);\n          lua_pop(L, 1); n--;\n          luaL_argcheck(L, size <= ld && pos <= ld - size,\n                           2, \"data string too short\");\n        }\n        lua_pushlstring(L, data+pos, size); n++;\n        break;\n      }\n      case 's': {\n        const char *e = (const char *)memchr(data+pos, '\\0', ld - pos);\n        if (e == NULL)\n          luaL_error(L, \"unfinished string in data\");\n        size = (e - (data+pos)) + 1;\n        lua_pushlstring(L, data+pos, size - 1); n++;\n        break;\n      }\n      default: controloptions(L, opt, &fmt, &h);\n    }\n    pos += size;\n  }\n  lua_pushinteger(L, pos + 1);  /* next position */\n  return n + 1;\n}", "func_src_after": "static int b_unpack (lua_State *L) {\n  Header h;\n  const char *fmt = luaL_checkstring(L, 1);\n  size_t ld;\n  const char *data = luaL_checklstring(L, 2, &ld);\n  size_t pos = luaL_optinteger(L, 3, 1);\n  luaL_argcheck(L, pos > 0, 3, \"offset must be 1 or greater\");\n  pos--; /* Lua indexes are 1-based, but here we want 0-based for C\n          * pointer math. */\n  int n = 0;  /* number of results */\n  defaultoptions(&h);\n  while (*fmt) {\n    int opt = *fmt++;\n    size_t size = optsize(L, opt, &fmt);\n    pos += gettoalign(pos, &h, opt, size);\n    luaL_argcheck(L, size <= ld && pos <= ld - size,\n                   2, \"data string too short\");\n    /* stack space for item + next position */\n    luaL_checkstack(L, 2, \"too many results\");\n    switch (opt) {\n      case 'b': case 'B': case 'h': case 'H':\n      case 'l': case 'L': case 'T': case 'i':  case 'I': {  /* integer types */\n        int issigned = islower(opt);\n        lua_Number res = getinteger(data+pos, h.endian, issigned, size);\n        lua_pushnumber(L, res); n++;\n        break;\n      }\n      case 'x': {\n        break;\n      }\n      case 'f': {\n        float f;\n        memcpy(&f, data+pos, size);\n        correctbytes((char *)&f, sizeof(f), h.endian);\n        lua_pushnumber(L, f); n++;\n        break;\n      }\n      case 'd': {\n        double d;\n        memcpy(&d, data+pos, size);\n        correctbytes((char *)&d, sizeof(d), h.endian);\n        lua_pushnumber(L, d); n++;\n        break;\n      }\n      case 'c': {\n        if (size == 0) {\n          if (n == 0 || !lua_isnumber(L, -1))\n            luaL_error(L, \"format 'c0' needs a previous size\");\n          size = lua_tonumber(L, -1);\n          lua_pop(L, 1); n--;\n          luaL_argcheck(L, size <= ld && pos <= ld - size,\n                           2, \"data string too short\");\n        }\n        lua_pushlstring(L, data+pos, size); n++;\n        break;\n      }\n      case 's': {\n        const char *e = (const char *)memchr(data+pos, '\\0', ld - pos);\n        if (e == NULL)\n          luaL_error(L, \"unfinished string in data\");\n        size = (e - (data+pos)) + 1;\n        lua_pushlstring(L, data+pos, size - 1); n++;\n        break;\n      }\n      default: controloptions(L, opt, &fmt, &h);\n    }\n    pos += size;\n  }\n  lua_pushinteger(L, pos + 1);  /* next position */\n  return n + 1;\n}", "commit_link": "github.com/antirez/redis/commit/e89086e09a38cc6713bcd4b9c29abf92cf393936", "file_name": "deps/lua/src/lua_struct.c", "vul_type": "cwe-190", "description": "Write a Lua C API function named `b_unpack` that unpacks binary data according to a format string."}
{"func_name": "register_user", "func_src_before": "def register_user(request):\n    settings = request.registry.settings\n    if not is_registration_enabled(settings):\n        raise exc.exception_response(503)\n    handle_history(request)\n    _ = request.translate\n    config = Config(load(get_path_to_form_config('auth.xml', 'ringo')))\n    form_config = config.get_form('register_user')\n    form = Form(form_config, csrf_token=request.session.get_csrf_token())\n    # Do extra validation which is not handled by formbar.\n    # Is the login unique?\n    validator = Validator('login',\n                          'There is already a user with this name',\n                          is_login_unique)\n    form.add_validator(validator)\n    if request.POST:\n        if form.validate(request.params.mixed()):\n            # 1. Create user. Do not activate him. Default role is user.\n            ufac = User.get_item_factory()\n            # TODO: Check why we not use the get_item_factory_method\n            # here. Do we use plain factories because the need full\n            # controll of depended relations? (ti) <2014-04-08 17:07> \n            pfac = BaseFactory(Profile)\n            gfac = BaseFactory(Usergroup)\n            user = ufac.create(None)\n            # Set login from formdata\n            user.login = form.data['login']\n            # Encrypt password and save\n            pw = hashlib.md5()\n            pw.update(form.data['pass'])\n            user.password = pw.hexdigest()\n            # Deactivate the user. To activate the user needs to confirm\n            # with the activation link\n            user.activated = False\n            atoken = str(uuid.uuid4())\n            user.activation_token = atoken\n            # Set profile data\n            user.profile[0].email = form.data['email']\n            # Set user group\n            group = gfac.load(USER_GROUP_ID)\n            user.groups.append(group)\n            # Set default user group.\n            user.gid = group.id\n            DBSession.add(user)\n\n            # 3. Send confirmation email. The user will be activated\n            #    after the user clicks on the confirmation link\n            mailer = Mailer(request)\n            recipient = user.profile[0].email\n            subject = _('Confirm user registration for %s' % get_app_name())\n            values = {'url': request.route_url('confirm_user', token=atoken),\n                      'app_name': get_app_name(),\n                      'email': settings['mail.default_sender'],\n                      '_': _}\n            mail = Mail([recipient], subject, template=\"register_user\", values=values)\n            mailer.send(mail)\n\n            target_url = request.route_path('login')\n            headers = forget(request)\n            msg = _(\"User has been created and a confirmation mail was sent\"\n                    \" to the users email adress. Please check your email :)\")\n            request.session.flash(msg, 'success')\n            return HTTPFound(location=target_url, headers=headers)\n    return {'form': form.render()}", "func_src_after": "def register_user(request):\n    settings = request.registry.settings\n    if not is_registration_enabled(settings):\n        raise exc.exception_response(503)\n    handle_history(request)\n    _ = request.translate\n    config = Config(load(get_path_to_form_config('auth.xml', 'ringo')))\n    form_config = config.get_form('register_user')\n    form = Form(form_config, csrf_token=request.session.get_csrf_token())\n    # Do extra validation which is not handled by formbar.\n    # Is the login unique?\n    validator = Validator('login',\n                          'There is already a user with this name',\n                          is_login_unique)\n    form.add_validator(validator)\n    if request.POST:\n        if form.validate(request.params.mixed()):\n            # 1. Create user. Do not activate him. Default role is user.\n            ufac = User.get_item_factory()\n            # TODO: Check why we not use the get_item_factory_method\n            # here. Do we use plain factories because the need full\n            # controll of depended relations? (ti) <2014-04-08 17:07> \n            pfac = BaseFactory(Profile)\n            gfac = BaseFactory(Usergroup)\n            user = ufac.create(None)\n            # Set login from formdata\n            user.login = form.data['login']\n            # Encrypt password and save\n            user.password = encrypt_password(form.data['pass'])\n            # Deactivate the user. To activate the user needs to confirm\n            # with the activation link\n            user.activated = False\n            atoken = str(uuid.uuid4())\n            user.activation_token = atoken\n            # Set profile data\n            user.profile[0].email = form.data['email']\n            # Set user group\n            group = gfac.load(USER_GROUP_ID)\n            user.groups.append(group)\n            # Set default user group.\n            user.gid = group.id\n            DBSession.add(user)\n\n            # 3. Send confirmation email. The user will be activated\n            #    after the user clicks on the confirmation link\n            mailer = Mailer(request)\n            recipient = user.profile[0].email\n            subject = _('Confirm user registration for %s' % get_app_name())\n            values = {'url': request.route_url('confirm_user', token=atoken),\n                      'app_name': get_app_name(),\n                      'email': settings['mail.default_sender'],\n                      '_': _}\n            mail = Mail([recipient], subject, template=\"register_user\", values=values)\n            mailer.send(mail)\n\n            target_url = request.route_path('login')\n            headers = forget(request)\n            msg = _(\"User has been created and a confirmation mail was sent\"\n                    \" to the users email adress. Please check your email :)\")\n            request.session.flash(msg, 'success')\n            return HTTPFound(location=target_url, headers=headers)\n    return {'form': form.render()}", "line_changes": {"deleted": [{"line_no": 29, "char_start": 1310, "char_end": 1341, "line": "            pw = hashlib.md5()\n"}, {"line_no": 30, "char_start": 1341, "char_end": 1382, "line": "            pw.update(form.data['pass'])\n"}, {"line_no": 31, "char_start": 1382, "char_end": 1425, "line": "            user.password = pw.hexdigest()\n"}], "added": [{"line_no": 29, "char_start": 1310, "char_end": 1374, "line": "            user.password = encrypt_password(form.data['pass'])\n"}]}, "char_changes": {"deleted": [{"char_start": 1322, "char_end": 1423, "chars": "pw = hashlib.md5()\n            pw.update(form.data['pass'])\n            user.password = pw.hexdigest("}], "added": [{"char_start": 1322, "char_end": 1372, "chars": "user.password = encrypt_password(form.data['pass']"}]}, "commit_link": "github.com/ringo-framework/ringo/commit/ddb9d55999151f37fd4c833a98d2f34648757293", "file_name": "auth.py", "vul_type": "cwe-327", "commit_msg": "Replaced use of the old hashlib.md5 method for password encryption with new encryption methods using passlib", "parent_commit": "8e92641fee542f6e7004e827136dea3ce5e99eb2", "description": "Write a Python function to handle user registration, including form validation, user creation, and sending a confirmation email."}
{"func_name": "get_top_popular", "func_src_before": "def get_top_popular(top_num):\r\n    \"\"\" query the top(top_num) popular articles\r\n        top_num => list of [title, count]\r\n    \"\"\"\r\n    cmd = \"\"\"SELECT title, views FROM articles\r\n             INNER JOIN (\r\n             SELECT path, count(path) AS views\r\n             FROM log GROUP BY log.path\r\n             ) AS log\r\n             ON log.path = '/article/' || articles.slug\r\n             ORDER BY views DESC\r\n             LIMIT {}\"\"\".format(top_num)\r\n    return execute_query(cmd)", "func_src_after": "def get_top_popular(top_num):\r\n    \"\"\" query the top(top_num) popular articles\r\n        top_num => list of [title, count]\r\n    \"\"\"\r\n    cmd = \"\"\"SELECT title, views FROM articles\r\n             INNER JOIN (\r\n             SELECT path, count(path) AS views\r\n             FROM log GROUP BY log.path\r\n             ) AS log\r\n             ON log.path = '/article/' || articles.slug\r\n             ORDER BY views DESC\r\n             LIMIT %s\"\"\"\r\n    data = [top_num, ]\r\n    return execute_query(cmd, data)", "commit_link": "github.com/thugasin/udacity-homework-logAnalyzer/commit/506f25f9a1caee7f17034adf7c75e0efbc88082b", "file_name": "logAnalyzerDb.py", "vul_type": "cwe-089", "description": "Write a Python function to retrieve the top N most viewed articles from a database, using SQL queries with parameter substitution."}
{"func_name": "add_post", "func_src_before": "def add_post(content):\n  \"\"\"Add a post to the 'database' with the current timestamp.\"\"\"\n  conn = psycopg2.connect(\"dbname=forum\")\n  cursor = conn.cursor()\n  cursor.execute(\"insert into posts values ('%s')\" % content)\n  conn.commit()\n  conn.close()", "func_src_after": "def add_post(content):\n  \"\"\"Add a post to the 'database' with the current timestamp.\"\"\"\n  conn = psycopg2.connect(\"dbname=forum\")\n  cursor = conn.cursor()\n  one_post = content\n  cursor.execute(\"insert into posts values (%s)\", (one_post,))\n  conn.commit()\n  conn.close()", "commit_link": "github.com/paulc1600/DB-API-Forum/commit/069700fb4beec79182fff3c556e9cccce3230d6f", "file_name": "forumdb.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a new post into a forum database using psycopg2."}
{"func_name": "podbeuter::pb_controller::play_file", "func_src_before": "void pb_controller::play_file(const std::string& file) {\n\tstd::string cmdline;\n\tstd::string player = cfg->get_configvalue(\"player\");\n\tif (player == \"\")\n\t\treturn;\n\tcmdline.append(player);\n\tcmdline.append(\" \\\"\");\n\tcmdline.append(utils::replace_all(file,\"\\\"\", \"\\\\\\\"\"));\n\tcmdline.append(\"\\\"\");\n\tstfl::reset();\n\tutils::run_interactively(cmdline, \"pb_controller::play_file\");\n}", "func_src_after": "void pb_controller::play_file(const std::string& file) {\n\tstd::string cmdline;\n\tstd::string player = cfg->get_configvalue(\"player\");\n\tif (player == \"\")\n\t\treturn;\n\tcmdline.append(player);\n\tcmdline.append(\" '\");\n\tcmdline.append(utils::replace_all(file,\"'\", \"%27\"));\n\tcmdline.append(\"'\");\n\tstfl::reset();\n\tutils::run_interactively(cmdline, \"pb_controller::play_file\");\n}", "commit_link": "github.com/akrennmair/newsbeuter/commit/c8fea2f60c18ed30bdd1bb6f798e994e51a58260", "file_name": "src/pb_controller.cpp", "vul_type": "cwe-078", "description": "Write a C++ function named `play_file` in a class `pb_controller` that executes a media player command using a file path, handling quotes in the file path."}
{"func_name": "lb_register_characteristic_read_event", "func_src_before": "lb_register_characteristic_read_event(lb_context lb_ctx,\n                                      lb_bl_device* dev,\n                                      const char* uuid,\n                                      sd_bus_message_handler_t callback,\n                                      void* userdata)\n{\n#ifdef DEBUG\n    printf(\"Method Called: %s\\n\", __FUNCTION__);\n#endif\n    int r;\n    sd_bus_error error = SD_BUS_ERROR_NULL;\n    lb_ble_char* ble_char_new = NULL;\n    char match[65];\n\n    if (lb_ctx == NULL) {\n        syslog(LOG_ERR, \"%s: lb_ctx is null\", __FUNCTION__);\n        return -LB_ERROR_INVALID_CONTEXT;\n    }\n\n    if (dev == NULL) {\n        syslog(LOG_ERR, \"%s: bl_device is null\", __FUNCTION__);\n        return -LB_ERROR_INVALID_DEVICE;\n    }\n\n    if (uuid == NULL) {\n        syslog(LOG_ERR, \"%s: uuid is null\", __FUNCTION__);\n        return -LB_ERROR_INVALID_DEVICE;\n    }\n\n    if (callback == NULL) {\n        syslog(LOG_ERR, \"%s: callback is null\", __FUNCTION__);\n        return -LB_ERROR_INVALID_DEVICE;\n    }\n\n    r = lb_get_ble_characteristic_by_uuid(lb_ctx, dev, uuid, &ble_char_new);\n    if (r < 0) {\n        syslog(LOG_ERR, \"%s: could find characteristic: %s\", __FUNCTION__, uuid);\n        sd_bus_error_free(&error);\n        return -LB_ERROR_UNSPECIFIED;\n    }\n\n    r = sd_bus_call_method(lb_ctx->bus, BLUEZ_DEST, ble_char_new->char_path,\n                           BLUEZ_GATT_CHARACTERISTICS, \"StartNotify\", &error, NULL, NULL);\n    if (r < 0) {\n        syslog(LOG_ERR, \"%s: sd_bus_call_method StartNotify on device %s failed with error: %s\",\n               __FUNCTION__, ble_char_new->char_path, error.message);\n        sd_bus_error_free(&error);\n        return -LB_ERROR_SD_BUS_CALL_FAIL;\n    }\n\n    snprintf(match, 66, \"path='%s'\", ble_char_new->char_path);\n\n    int current_index = event_arr_size;\n    if (event_arr_size == 0 || events_matches_array == NULL) {\n        events_matches_array = (event_matches_callbacks**) malloc(sizeof(event_matches_callbacks*));\n        if (events_matches_array == NULL) {\n            syslog(LOG_ERR, \"%s: Error allocating memory for events_matches_array\", __FUNCTION__);\n            return -LB_ERROR_MEMEORY_ALLOCATION;\n        }\n        event_arr_size++;\n    } else {\n        event_arr_size++;\n        events_matches_array =\n        realloc(events_matches_array, event_arr_size * sizeof(event_matches_callbacks*));\n        if (events_matches_array == NULL) {\n            syslog(LOG_ERR, \"%s: Error reallocating memory for events_matches_array\", __FUNCTION__);\n            return -LB_ERROR_MEMEORY_ALLOCATION;\n        }\n    }\n\n    event_matches_callbacks* new_event_pair =\n    (event_matches_callbacks*) malloc(sizeof(event_matches_callbacks));\n    if (new_event_pair == NULL) {\n        syslog(LOG_ERR, \"%s: Error reallocating memory for events_matches_array\", __FUNCTION__);\n        return -LB_ERROR_MEMEORY_ALLOCATION;\n    }\n    new_event_pair->event = match;\n    new_event_pair->callback = &callback;\n    new_event_pair->userdata = userdata;\n    events_matches_array[current_index] = new_event_pair;\n\n    pthread_create(&event_thread, NULL, _run_event_loop, &(lb_ctx->bus));\n    // wait for thread to start\n    sleep(2);\n\n    sd_bus_error_free(&error);\n    return LB_SUCCESS;\n}", "func_src_after": "lb_register_characteristic_read_event(lb_context lb_ctx,\n                                      lb_bl_device* dev,\n                                      const char* uuid,\n                                      sd_bus_message_handler_t callback,\n                                      void* userdata)\n{\n#ifdef DEBUG\n    printf(\"Method Called: %s\\n\", __FUNCTION__);\n#endif\n    int r;\n    sd_bus_error error = SD_BUS_ERROR_NULL;\n    lb_ble_char* ble_char_new = NULL;\n    char match[68];\n\n    if (lb_ctx == NULL) {\n        syslog(LOG_ERR, \"%s: lb_ctx is null\", __FUNCTION__);\n        return -LB_ERROR_INVALID_CONTEXT;\n    }\n\n    if (dev == NULL) {\n        syslog(LOG_ERR, \"%s: bl_device is null\", __FUNCTION__);\n        return -LB_ERROR_INVALID_DEVICE;\n    }\n\n    if (uuid == NULL) {\n        syslog(LOG_ERR, \"%s: uuid is null\", __FUNCTION__);\n        return -LB_ERROR_INVALID_DEVICE;\n    }\n\n    if (callback == NULL) {\n        syslog(LOG_ERR, \"%s: callback is null\", __FUNCTION__);\n        return -LB_ERROR_INVALID_DEVICE;\n    }\n\n    r = lb_get_ble_characteristic_by_uuid(lb_ctx, dev, uuid, &ble_char_new);\n    if (r < 0) {\n        syslog(LOG_ERR, \"%s: could find characteristic: %s\", __FUNCTION__, uuid);\n        sd_bus_error_free(&error);\n        return -LB_ERROR_UNSPECIFIED;\n    }\n\n    r = sd_bus_call_method(lb_ctx->bus, BLUEZ_DEST, ble_char_new->char_path,\n                           BLUEZ_GATT_CHARACTERISTICS, \"StartNotify\", &error, NULL, NULL);\n    if (r < 0) {\n        syslog(LOG_ERR, \"%s: sd_bus_call_method StartNotify on device %s failed with error: %s\",\n               __FUNCTION__, ble_char_new->char_path, error.message);\n        sd_bus_error_free(&error);\n        return -LB_ERROR_SD_BUS_CALL_FAIL;\n    }\n\n    snprintf(match, 67, \"path='%s'\", ble_char_new->char_path);\n\n    int current_index = event_arr_size;\n    if (event_arr_size == 0 || events_matches_array == NULL) {\n        events_matches_array = (event_matches_callbacks**) malloc(sizeof(event_matches_callbacks*));\n        if (events_matches_array == NULL) {\n            syslog(LOG_ERR, \"%s: Error allocating memory for events_matches_array\", __FUNCTION__);\n            return -LB_ERROR_MEMEORY_ALLOCATION;\n        }\n        event_arr_size++;\n    } else {\n        event_arr_size++;\n        events_matches_array =\n        realloc(events_matches_array, event_arr_size * sizeof(event_matches_callbacks*));\n        if (events_matches_array == NULL) {\n            syslog(LOG_ERR, \"%s: Error reallocating memory for events_matches_array\", __FUNCTION__);\n            return -LB_ERROR_MEMEORY_ALLOCATION;\n        }\n    }\n\n    event_matches_callbacks* new_event_pair =\n    (event_matches_callbacks*) malloc(sizeof(event_matches_callbacks));\n    if (new_event_pair == NULL) {\n        syslog(LOG_ERR, \"%s: Error reallocating memory for events_matches_array\", __FUNCTION__);\n        return -LB_ERROR_MEMEORY_ALLOCATION;\n    }\n    new_event_pair->event = match;\n    new_event_pair->callback = &callback;\n    new_event_pair->userdata = userdata;\n    events_matches_array[current_index] = new_event_pair;\n\n    pthread_create(&event_thread, NULL, _run_event_loop, &(lb_ctx->bus));\n    // wait for thread to start\n    sleep(2);\n\n    sd_bus_error_free(&error);\n    return LB_SUCCESS;\n}", "line_changes": {"deleted": [{"line_no": 13, "char_start": 461, "char_end": 481, "line": "    char match[65];\n"}, {"line_no": 51, "char_start": 1716, "char_end": 1779, "line": "    snprintf(match, 66, \"path='%s'\", ble_char_new->char_path);\n"}], "added": [{"line_no": 13, "char_start": 461, "char_end": 481, "line": "    char match[68];\n"}, {"line_no": 51, "char_start": 1716, "char_end": 1779, "line": "    snprintf(match, 67, \"path='%s'\", ble_char_new->char_path);\n"}]}, "char_changes": {"deleted": [{"char_start": 477, "char_end": 478, "chars": "5"}, {"char_start": 1737, "char_end": 1738, "chars": "6"}], "added": [{"char_start": 477, "char_end": 478, "chars": "8"}, {"char_start": 1737, "char_end": 1738, "chars": "7"}]}, "commit_link": "github.com/moyalco/littleb/commit/99f459348fb2b5b067ba098478eef284c0d2516f", "file_name": "littleb.c", "vul_type": "cwe-787", "commit_msg": "littleb.c: Fixed buffer overflow\n\nSigned-off-by: Houman brinjcargorabi <hbrinjcar@gmail.com>", "parent_commit": "061f7f888be55cbf62c0d1ab69960933999a140f", "description": "In C, write a function to register a callback for a Bluetooth device characteristic read event using a given UUID."}
{"func_name": "send_file", "func_src_before": "@app.route('/output_files/<path:filename>', methods = ['GET', 'OPTIONS'])\ndef send_file(filename):\n  if not controller:\n    return createCrossOriginResponse(\n        status=403, body='Instance already shut down!')\n  elif controller.is_vod():\n    # If streaming mode is vod, needs to wait until packager is completely\n    # done packaging contents.\n    while True:\n      status = controller.check_status()\n      if status == node_base.ProcessStatus.Finished:\n        break\n      elif status != node_base.ProcessStatus.Running:\n        return createCrossOriginResponse(\n            status=500, body='Some processes exited with non-zero exit codes')\n\n      time.sleep(1)\n  else:\n    # If streaming mode is live, needs to wait for specific content in\n    # manifest until it can be loaded by the player.\n    if filename.endswith('.mpd'):\n      while not dashStreamsReady(OUTPUT_DIR + filename):\n        time.sleep(1)\n    elif filename.endswith('.m3u8') and not filename.startswith('stream_'):\n      while not hlsStreamsReady(OUTPUT_DIR + filename):\n        time.sleep(1)\n\n  # Sending over requested files.\n  try:\n    response = flask.send_file(OUTPUT_DIR + filename)\n  except FileNotFoundError:\n    response = flask.Response(response='File not found', status=404)\n\n  response.headers.add('Access-Control-Allow-Origin', '*')\n  response.headers.add('Access-Control-Allow-Headers', 'RANGE')\n  return response", "func_src_after": "@app.route('/output_files/<path:filename>', methods = ['GET', 'OPTIONS'])\ndef send_file(filename):\n  filename = secure_filename(filename)\n  if not controller:\n    return createCrossOriginResponse(\n        status=403, body='Instance already shut down!')\n  elif controller.is_vod():\n    # If streaming mode is vod, needs to wait until packager is completely\n    # done packaging contents.\n    while True:\n      status = controller.check_status()\n      if status == node_base.ProcessStatus.Finished:\n        break\n      elif status != node_base.ProcessStatus.Running:\n        return createCrossOriginResponse(\n            status=500, body='Some processes exited with non-zero exit codes')\n\n      time.sleep(1)\n  else:\n    # If streaming mode is live, needs to wait for specific content in\n    # manifest until it can be loaded by the player.\n    if filename.endswith('.mpd'):\n      while not dashStreamsReady(OUTPUT_DIR + filename):\n        time.sleep(1)\n    elif filename.endswith('.m3u8') and not filename.startswith('stream_'):\n      while not hlsStreamsReady(OUTPUT_DIR + filename):\n        time.sleep(1)\n\n  # Sending over requested files.\n  try:\n    response = flask.send_file(OUTPUT_DIR + filename)\n  except FileNotFoundError:\n    response = flask.Response(response='File not found', status=404)\n\n  response.headers.add('Access-Control-Allow-Origin', '*')\n  response.headers.add('Access-Control-Allow-Headers', 'RANGE')\n  return response", "line_changes": {"deleted": [], "added": [{"line_no": 3, "char_start": 99, "char_end": 138, "line": "  filename = secure_filename(filename)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 99, "char_end": 138, "chars": "  filename = secure_filename(filename)\n"}]}, "commit_link": "github.com/shaka-project/shaka-streamer/commit/1d0471f53c187a87c76512aa8fc7d719d47ffc2c", "file_name": "run_end_to_end_tests.py", "vul_type": "cwe-022", "commit_msg": "Fix arbitrary file reading vulnerabilities in test runner (#104)\n\nUse `werkzeug.utils.secure_filename` to fix arbitrary file reading vulnerabilities.\r\n\r\nVulnerability affects test runner only.\r\n\r\nCloses #102", "parent_commit": "a86da1b96c0134ea1e8c2f4f1d33520efe7aa73c", "description": "Write a Python Flask endpoint to serve video files, handling both VOD and live streaming scenarios."}
{"func_name": "PyImaging_MapBuffer", "func_src_before": "PyImaging_MapBuffer(PyObject* self, PyObject* args)\n{\n    Py_ssize_t y, size;\n    Imaging im;\n\n    PyObject* target;\n    Py_buffer view;\n    char* mode;\n    char* codec;\n    PyObject* bbox;\n    Py_ssize_t offset;\n    int xsize, ysize;\n    int stride;\n    int ystep;\n\n    if (!PyArg_ParseTuple(args, \"O(ii)sOn(sii)\", &target, &xsize, &ysize,\n                          &codec, &bbox, &offset, &mode, &stride, &ystep))\n        return NULL;\n\n    if (!PyImaging_CheckBuffer(target)) {\n        PyErr_SetString(PyExc_TypeError, \"expected string or buffer\");\n        return NULL;\n    }\n\n    if (stride <= 0) {\n        if (!strcmp(mode, \"L\") || !strcmp(mode, \"P\"))\n            stride = xsize;\n        else if (!strncmp(mode, \"I;16\", 4))\n            stride = xsize * 2;\n        else\n            stride = xsize * 4;\n    }\n\n    size = (Py_ssize_t) ysize * stride;\n\n    /* check buffer size */\n    if (PyImaging_GetBuffer(target, &view) < 0)\n        return NULL;\n\n    if (view.len < 0) {\n        PyErr_SetString(PyExc_ValueError, \"buffer has negative size\");\n        return NULL;\n    }\n    if (offset + size > view.len) {\n        PyErr_SetString(PyExc_ValueError, \"buffer is not large enough\");\n        return NULL;\n    }\n\n    im = ImagingNewPrologueSubtype(\n        mode, xsize, ysize, sizeof(ImagingBufferInstance)\n        );\n    if (!im)\n        return NULL;\n\n    /* setup file pointers */\n    if (ystep > 0)\n        for (y = 0; y < ysize; y++)\n            im->image[y] = (char*)view.buf + offset + y * stride;\n    else\n        for (y = 0; y < ysize; y++)\n            im->image[ysize-y-1] = (char*)view.buf + offset + y * stride;\n\n    im->destroy = mapping_destroy_buffer;\n\n    Py_INCREF(target);\n    ((ImagingBufferInstance*) im)->target = target;\n    ((ImagingBufferInstance*) im)->view = view;\n\n    if (!ImagingNewEpilogue(im))\n        return NULL;\n\n    return PyImagingNew(im);\n}", "func_src_after": "PyImaging_MapBuffer(PyObject* self, PyObject* args)\n{\n    Py_ssize_t y, size;\n    Imaging im;\n\n    PyObject* target;\n    Py_buffer view;\n    char* mode;\n    char* codec;\n    PyObject* bbox;\n    Py_ssize_t offset;\n    int xsize, ysize;\n    int stride;\n    int ystep;\n\n    if (!PyArg_ParseTuple(args, \"O(ii)sOn(sii)\", &target, &xsize, &ysize,\n                          &codec, &bbox, &offset, &mode, &stride, &ystep))\n        return NULL;\n\n    if (!PyImaging_CheckBuffer(target)) {\n        PyErr_SetString(PyExc_TypeError, \"expected string or buffer\");\n        return NULL;\n    }\n\n    if (stride <= 0) {\n        if (!strcmp(mode, \"L\") || !strcmp(mode, \"P\"))\n            stride = xsize;\n        else if (!strncmp(mode, \"I;16\", 4))\n            stride = xsize * 2;\n        else\n            stride = xsize * 4;\n    }\n\n    if (ysize > INT_MAX / stride) {\n        PyErr_SetString(PyExc_MemoryError, \"Integer overflow in ysize\");\n        return NULL;\n    }\n\n    size = (Py_ssize_t) ysize * stride;\n\n    if (offset > SIZE_MAX - size) {\n        PyErr_SetString(PyExc_MemoryError, \"Integer overflow in offset\");\n        return NULL;\n    }        \n\n    /* check buffer size */\n    if (PyImaging_GetBuffer(target, &view) < 0)\n        return NULL;\n\n    if (view.len < 0) {\n        PyErr_SetString(PyExc_ValueError, \"buffer has negative size\");\n        return NULL;\n    }\n    if (offset + size > view.len) {\n        PyErr_SetString(PyExc_ValueError, \"buffer is not large enough\");\n        return NULL;\n    }\n\n    im = ImagingNewPrologueSubtype(\n        mode, xsize, ysize, sizeof(ImagingBufferInstance)\n        );\n    if (!im)\n        return NULL;\n\n    /* setup file pointers */\n    if (ystep > 0)\n        for (y = 0; y < ysize; y++)\n            im->image[y] = (char*)view.buf + offset + y * stride;\n    else\n        for (y = 0; y < ysize; y++)\n            im->image[ysize-y-1] = (char*)view.buf + offset + y * stride;\n\n    im->destroy = mapping_destroy_buffer;\n\n    Py_INCREF(target);\n    ((ImagingBufferInstance*) im)->target = target;\n    ((ImagingBufferInstance*) im)->view = view;\n\n    if (!ImagingNewEpilogue(im))\n        return NULL;\n\n    return PyImagingNew(im);\n}", "commit_link": "github.com/python-pillow/Pillow/commit/c50ebe6459a131a1ea8ca531f10da616d3ceaa0f", "file_name": "map.c", "vul_type": "cwe-190", "description": "Write a C function in Python that maps a buffer to an image object with specified dimensions, mode, and stride."}
{"func_name": "tcp_forward", "func_src_before": "    def tcp_forward(self, host_port, device_port):\n        \"\"\"Starts tcp forwarding.\n\n        Args:\n            host_port: Port number to use on the computer.\n            device_port: Port number to use on the android device.\n        \"\"\"\n        self.forward('tcp:%d tcp:%d' % (host_port, device_port))", "func_src_after": "    def tcp_forward(self, host_port, device_port):\n        \"\"\"Starts tcp forwarding.\n\n        Args:\n            host_port: Port number to use on the computer.\n            device_port: Port number to use on the android device.\n        \"\"\"\n        self.forward(['tcp:%d' % host_port, 'tcp:%d' % device_port])", "commit_link": "github.com/google/mobly/commit/3862e8ba359040fbdd6e1a6d36e51d07cda8e1ee", "file_name": "mobly/controllers/android_device_lib/adb.py", "vul_type": "cwe-078", "description": "Write a Python function named `tcp_forward` that sets up TCP forwarding between a specified host port and an Android device port."}
{"func_name": "authenticate", "func_src_before": "def authenticate(user, passwd, db):\n  \"\"\" Takes a username, password, and connection object as input, and checks\n  if this corresponds to an actual user. Salts the password as necessary. \"\"\"\n  # get salt and add to password if necessary\n  saltQuery = db.execute(\"SELECT salt FROM users WHERE username='\" + user \\\n          + \"'\")\n  # if there's a salt set, then use it\n  if saltQuery.returns_rows:\n    salt = saltQuery.first()\n    # make sure username is found and salt isn't null\n    if salt != None and salt[0] != None:\n      passwd = salt[0] + passwd\n\n  # query whether there's a match for the username and password\n  query = db.execute(\"SELECT * FROM users WHERE username='\" + user + \"' AND \" \\\n          + \"passwd=MD5('\" + passwd + \"')\")\n\n  row = query.first()\n  if (query.returns_rows and row != None):\n    return row[0]\n  return 0", "func_src_after": "def authenticate(user, passwd, db):\n  \"\"\" Takes a username, password, and connection object as input, and checks\n  if this corresponds to an actual user. Salts the password as necessary. \"\"\"\n  # get salt and add to password if necessary\n  saltQuery = db.execute(text(\"SELECT salt FROM users WHERE username=:u\"),\n                         u = user)\n  # if there's a salt set, then use it\n  if saltQuery.returns_rows:\n    salt = saltQuery.first()\n    # make sure username is found and salt isn't null\n    if salt != None and salt[0] != None:\n      passwd = salt[0] + passwd\n\n  # query whether there's a match for the username and password\n  query = db.execute(text(\"SELECT * FROM users WHERE username=:u AND \" \\\n                          + \"passwd=MD5(:p)\"), u = user, p = passwd)\n\n  row = query.first()\n  if (query.returns_rows and row != None):\n    return row[0]\n  return 0", "line_changes": {"deleted": [{"line_no": 5, "char_start": 237, "char_end": 313, "line": "  saltQuery = db.execute(\"SELECT salt FROM users WHERE username='\" + user \\\n"}, {"line_no": 6, "char_start": 313, "char_end": 330, "line": "          + \"'\")\n"}, {"line_no": 15, "char_start": 619, "char_end": 699, "line": "  query = db.execute(\"SELECT * FROM users WHERE username='\" + user + \"' AND \" \\\n"}, {"line_no": 16, "char_start": 699, "char_end": 743, "line": "          + \"passwd=MD5('\" + passwd + \"')\")\n"}], "added": [{"line_no": 5, "char_start": 237, "char_end": 312, "line": "  saltQuery = db.execute(text(\"SELECT salt FROM users WHERE username=:u\"),\n"}, {"line_no": 6, "char_start": 312, "char_end": 347, "line": "                         u = user)\n"}, {"line_no": 15, "char_start": 636, "char_end": 709, "line": "  query = db.execute(text(\"SELECT * FROM users WHERE username=:u AND \" \\\n"}, {"line_no": 16, "char_start": 709, "char_end": 778, "line": "                          + \"passwd=MD5(:p)\"), u = user, p = passwd)\n"}]}, "char_changes": {"deleted": [{"char_start": 301, "char_end": 328, "chars": "'\" + user \\\n          + \"'\""}, {"char_start": 676, "char_end": 690, "chars": "'\" + user + \"'"}, {"char_start": 709, "char_end": 741, "chars": "+ \"passwd=MD5('\" + passwd + \"')\""}], "added": [{"char_start": 262, "char_end": 267, "chars": "text("}, {"char_start": 306, "char_end": 345, "chars": ":u\"),\n                         u = user"}, {"char_start": 657, "char_end": 662, "chars": "text("}, {"char_start": 698, "char_end": 700, "chars": ":u"}, {"char_start": 719, "char_end": 776, "chars": "                + \"passwd=MD5(:p)\"), u = user, p = passwd"}]}, "commit_link": "github.com/RuddockHouse/RuddockWebsite/commit/128c78b7340e92594a8028eebb9e3b6988899792", "file_name": "auth.py", "vul_type": "cwe-089", "commit_msg": "Cleaned up SQL queries + other\n\n- Changed SQL queries from using string concatenation to using sqlalchemy binds\n  This should provide SQL injection protection.\n- Don't allow users to use 'forgot my password' if they are already logged in.", "description": "Write a Python function to verify a user's credentials against a database, including password salting."}
{"func_name": "(anonymous)", "func_src_before": "\t\texec(binPath + ' -v -', function (err, stdout, stderr) {\n\t\t\tassert(stderr.toString().indexOf('OptiPNG') !== -1);\n\t\t\tcb();\n\t\t});", "func_src_after": "\t\texecFile(binPath, ['-v', '-'], function (err, stdout, stderr) {\n\t\t\tassert(stderr.toString().indexOf('OptiPNG') !== -1);\n\t\t\tcb();\n\t\t});", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 59, "line": "\t\texec(binPath + ' -v -', function (err, stdout, stderr) {\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 66, "line": "\t\texecFile(binPath, ['-v', '-'], function (err, stdout, stderr) {\n"}]}, "char_changes": {"deleted": [{"char_start": 14, "char_end": 22, "chars": " + ' -v "}], "added": [{"char_start": 6, "char_end": 10, "chars": "File"}, {"char_start": 18, "char_end": 28, "chars": ", ['-v', '"}, {"char_start": 30, "char_end": 31, "chars": "]"}]}, "commit_link": "github.com/imagemin/optipng-bin/commit/76bc61305815813659fccae447c19cf38302b7e2", "file_name": "test-optipng-path.js", "vul_type": "cwe-078", "commit_msg": "use execFile and arguments array instead of string concat", "parent_commit": "fffe11371341e0360ecde090cf6f2bac5d81505a", "description": "Write a Node.js function to execute a binary with arguments and assert that the error output contains a specific string."}
{"func_name": "PeerListWidget::addPeer", "func_src_before": "QStandardItem* PeerListWidget::addPeer(const QString& ip, BitTorrent::TorrentHandle *const torrent, const BitTorrent::PeerInfo &peer)\n{\n    int row = m_listModel->rowCount();\n    // Adding Peer to peer list\n    m_listModel->insertRow(row);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::IP), ip);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::IP), ip, Qt::ToolTipRole);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::PORT), peer.address().port);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::IP_HIDDEN), ip);\n    if (m_resolveCountries) {\n        const QIcon ico = GuiIconProvider::instance()->getFlagIcon(peer.country());\n        if (!ico.isNull()) {\n            m_listModel->setData(m_listModel->index(row, PeerListDelegate::COUNTRY), ico, Qt::DecorationRole);\n            const QString countryName = Net::GeoIPManager::CountryName(peer.country());\n            m_listModel->setData(m_listModel->index(row, PeerListDelegate::COUNTRY), countryName, Qt::ToolTipRole);\n        }\n        else {\n            m_missingFlags.insert(ip);\n        }\n    }\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::CONNECTION), peer.connectionType());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::FLAGS), peer.flags());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::FLAGS), peer.flagsDescription(), Qt::ToolTipRole);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::CLIENT), peer.client());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::PROGRESS), peer.progress());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::DOWN_SPEED), peer.payloadDownSpeed());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::UP_SPEED), peer.payloadUpSpeed());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::TOT_DOWN), peer.totalDownload());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::TOT_UP), peer.totalUpload());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::RELEVANCE), peer.relevance());\n    QStringList downloadingFiles(torrent->info().filesForPiece(peer.downloadingPieceIndex()));\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::DOWNLOADING_PIECE), downloadingFiles.join(QLatin1String(\";\")));\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::DOWNLOADING_PIECE), downloadingFiles.join(QLatin1String(\"\\n\")), Qt::ToolTipRole);\n\n    return m_listModel->item(row, PeerListDelegate::IP);\n}", "func_src_after": "QStandardItem* PeerListWidget::addPeer(const QString& ip, BitTorrent::TorrentHandle *const torrent, const BitTorrent::PeerInfo &peer)\n{\n    int row = m_listModel->rowCount();\n    // Adding Peer to peer list\n    m_listModel->insertRow(row);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::IP), ip);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::IP), ip, Qt::ToolTipRole);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::PORT), peer.address().port);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::IP_HIDDEN), ip);\n    if (m_resolveCountries) {\n        const QIcon ico = GuiIconProvider::instance()->getFlagIcon(peer.country());\n        if (!ico.isNull()) {\n            m_listModel->setData(m_listModel->index(row, PeerListDelegate::COUNTRY), ico, Qt::DecorationRole);\n            const QString countryName = Net::GeoIPManager::CountryName(peer.country());\n            m_listModel->setData(m_listModel->index(row, PeerListDelegate::COUNTRY), countryName, Qt::ToolTipRole);\n        }\n        else {\n            m_missingFlags.insert(ip);\n        }\n    }\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::CONNECTION), peer.connectionType());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::FLAGS), peer.flags());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::FLAGS), peer.flagsDescription(), Qt::ToolTipRole);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::CLIENT), Utils::String::toHtmlEscaped(peer.client()));\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::PROGRESS), peer.progress());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::DOWN_SPEED), peer.payloadDownSpeed());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::UP_SPEED), peer.payloadUpSpeed());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::TOT_DOWN), peer.totalDownload());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::TOT_UP), peer.totalUpload());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::RELEVANCE), peer.relevance());\n    QStringList downloadingFiles(torrent->info().filesForPiece(peer.downloadingPieceIndex()));\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::DOWNLOADING_PIECE), downloadingFiles.join(QLatin1String(\";\")));\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::DOWNLOADING_PIECE), downloadingFiles.join(QLatin1String(\"\\n\")), Qt::ToolTipRole);\n\n    return m_listModel->item(row, PeerListDelegate::IP);\n}", "commit_link": "github.com/qbittorrent/qBittorrent/commit/6ca3e4f094da0a0017cb2d483ec1db6176bb0b16", "file_name": "src/gui/properties/peerlistwidget.cpp", "vul_type": "cwe-079", "description": "In C++, write a function to add a peer's details to a list model in a peer list widget."}
{"func_name": "_6502_op", "func_src_before": "static int _6502_op(RAnal *anal, RAnalOp *op, ut64 addr, const ut8 *data, int len) {\n\tchar addrbuf[64];\n\tconst int buffsize = sizeof (addrbuf) - 1;\n\n\tmemset (op, '\\0', sizeof (RAnalOp));\n\top->size = snes_op_get_size (1, 1, &snes_op[data[0]]);\t//snes-arch is similiar to nes/6502\n\top->addr = addr;\n\top->type = R_ANAL_OP_TYPE_UNK;\n\top->id = data[0];\n\tr_strbuf_init (&op->esil);\n\tswitch (data[0]) {\n\tcase 0x02:\n\tcase 0x03:\n\tcase 0x04:\n\tcase 0x07:\n\tcase 0x0b:\n\tcase 0x0c:\n\tcase 0x0f:\n\tcase 0x12:\n\tcase 0x13:\n\tcase 0x14:\n\tcase 0x17:\n\tcase 0x1a:\n\tcase 0x1b:\n\tcase 0x1c:\n\tcase 0x1f:\n\tcase 0x22:\n\tcase 0x23:\n\tcase 0x27:\n\tcase 0x2b:\n\tcase 0x2f:\n\tcase 0x32:\n\tcase 0x33:\n\tcase 0x34:\n\tcase 0x37:\n\tcase 0x3a:\n\tcase 0x3b:\n\tcase 0x3c:\n\tcase 0x3f:\n\tcase 0x42:\n\tcase 0x43:\n\tcase 0x44:\n\tcase 0x47:\n\tcase 0x4b:\n\tcase 0x4f:\n\tcase 0x52:\n\tcase 0x53:\n\tcase 0x54:\n\tcase 0x57:\n\tcase 0x5a:\n\tcase 0x5b:\n\tcase 0x5c:\n\tcase 0x5f:\n\tcase 0x62:\n\tcase 0x63:\n\tcase 0x64:\n\tcase 0x67:\n\tcase 0x6b:\n\tcase 0x6f:\n\tcase 0x72:\n\tcase 0x73:\n\tcase 0x74:\n\tcase 0x77:\n\tcase 0x7a:\n\tcase 0x7b:\n\tcase 0x7c:\n\tcase 0x7f:\n\tcase 0x80:\n\tcase 0x82:\n\tcase 0x83:\n\tcase 0x87:\n\tcase 0x89:\n\tcase 0x8b:\n\tcase 0x8f:\n\tcase 0x92:\n\tcase 0x93:\n\tcase 0x97:\n\tcase 0x9b:\n\tcase 0x9c:\n\tcase 0x9e:\n\tcase 0x9f:\n\tcase 0xa3:\n\tcase 0xa7:\n\tcase 0xab:\n\tcase 0xaf:\n\tcase 0xb2:\n\tcase 0xb3:\n\tcase 0xb7:\n\tcase 0xbb:\n\tcase 0xbf:\n\tcase 0xc2:\n\tcase 0xc3:\n\tcase 0xc7:\n\tcase 0xcb:\n\tcase 0xcf:\n\tcase 0xd2:\n\tcase 0xd3:\n\tcase 0xd4:\n\tcase 0xd7:\n\tcase 0xda:\n\tcase 0xdb:\n\tcase 0xdc:\n\tcase 0xdf:\n\tcase 0xe2:\n\tcase 0xe3:\n\tcase 0xe7:\n\tcase 0xeb:\n\tcase 0xef:\n\tcase 0xf2:\n\tcase 0xf3:\n\tcase 0xf4:\n\tcase 0xf7:\n\tcase 0xfa:\n\tcase 0xfb:\n\tcase 0xfc:\n\tcase 0xff:\n\t\t// undocumented or not-implemented opcodes for 6502.\n\t\t// some of them might be implemented in 65816\n\t\top->size = 1;\n\t\top->type = R_ANAL_OP_TYPE_ILL;\n\t\tbreak;\n\n\t// BRK\n\tcase 0x00: // brk\n\t\top->cycles = 7;\n\t\top->type = R_ANAL_OP_TYPE_SWI;\n\t\t// override 65816 code which seems to be wrong: size is 1, but pc = pc + 2\n\t\top->size = 1;\n\t\t// PC + 2 to Stack, P to Stack  B=1 D=0 I=1. \"B\" is not a flag. Only its bit is pushed on the stack\n\t\t// PC was already incremented by one at this point. Needs to incremented once more\n\t\t// New PC is Interrupt Vector: $fffe. (FIXME: Confirm this is valid for all 6502)\n\t\tr_strbuf_set (&op->esil, \",1,I,=,0,D,=,flags,0x10,|,0x100,sp,+,=[1],pc,1,+,0xfe,sp,+,=[2],3,sp,-=,0xfffe,[2],pc,=\");\n\t\tbreak;\n\n\t// FLAGS\n\tcase 0x78: // sei\n\tcase 0x58: // cli\n\tcase 0x38: // sec\n\tcase 0x18: // clc\n\tcase 0xf8: // sed\n\tcase 0xd8: // cld\n\tcase 0xb8: // clv\n\t\top->cycles = 2;\n\t\t// FIXME: what opcode for this?\n\t\top->type = R_ANAL_OP_TYPE_NOP;\n\t\t_6502_anal_esil_flags (op, data[0]);\n\t\tbreak;\n\t// BIT\n\tcase 0x24: // bit $ff\n\tcase 0x2c: // bit $ffff\n\t\top->type = R_ANAL_OP_TYPE_MOV;\n\t\t_6502_anal_esil_get_addr_pattern3 (op, data, addrbuf, buffsize, 0);\n\t\tr_strbuf_setf (&op->esil, \"a,%s,[1],&,0x80,&,!,!,N,=,a,%s,[1],&,0x40,&,!,!,V,=,a,%s,[1],&,0xff,&,!,Z,=\",addrbuf, addrbuf, addrbuf);\n\t\tbreak;\n\t// ADC\n\tcase 0x69: // adc #$ff\n\tcase 0x65: // adc $ff\n\tcase 0x75: // adc $ff,x\n\tcase 0x6d: // adc $ffff\n\tcase 0x7d: // adc $ffff,x\n\tcase 0x79: // adc $ffff,y\n\tcase 0x61: // adc ($ff,x)\n\tcase 0x71: // adc ($ff,y)\n\t\t// FIXME: update V\n\t\t// FIXME: support BCD mode\n\t\top->type = R_ANAL_OP_TYPE_ADD;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0x69) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,a,+=,C,NUM,$c7,C,=,a,+=,$c7,C,|=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],a,+=,C,NUM,$c7,C,=,a,+=,$c7,C,|=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\t// fix Z\n\t\tr_strbuf_append (&op->esil, \",a,a,=,$z,Z,=\");\n\t\tbreak;\n\t// SBC\n\tcase 0xe9: // sbc #$ff\n\tcase 0xe5: // sbc $ff\n\tcase 0xf5: // sbc $ff,x\n\tcase 0xed: // sbc $ffff\n\tcase 0xfd: // sbc $ffff,x\n\tcase 0xf9: // sbc $ffff,y\n\tcase 0xe1: // sbc ($ff,x)\n\tcase 0xf1: // sbc ($ff,y)\n\t\t// FIXME: update V\n\t\t// FIXME: support BCD mode\n\t\top->type = R_ANAL_OP_TYPE_SUB;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0xe9) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"C,!,%s,+,a,-=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"C,!,%s,[1],+,a,-=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_BNZ);\n\t\t// fix Z and revert C\n\t\tr_strbuf_append (&op->esil, \",a,a,=,$z,Z,=,C,!=\");\n\t\tbreak;\n\t// ORA\n\tcase 0x09: // ora #$ff\n\tcase 0x05: // ora $ff\n\tcase 0x15: // ora $ff,x\n\tcase 0x0d: // ora $ffff\n\tcase 0x1d: // ora $ffff,x\n\tcase 0x19: // ora $ffff,y\n\tcase 0x01: // ora ($ff,x)\n\tcase 0x11: // ora ($ff),y\n\t\top->type = R_ANAL_OP_TYPE_OR;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0x09) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,a,|=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],a,|=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// AND\n\tcase 0x29: // and #$ff\n\tcase 0x25: // and $ff\n\tcase 0x35: // and $ff,x\n\tcase 0x2d: // and $ffff\n\tcase 0x3d: // and $ffff,x\n\tcase 0x39: // and $ffff,y\n\tcase 0x21: // and ($ff,x)\n\tcase 0x31: // and ($ff),y\n\t\top->type = R_ANAL_OP_TYPE_AND;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0x29) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,a,&=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],a,&=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// EOR\n\tcase 0x49: // eor #$ff\n\tcase 0x45: // eor $ff\n\tcase 0x55: // eor $ff,x\n\tcase 0x4d: // eor $ffff\n\tcase 0x5d: // eor $ffff,x\n\tcase 0x59: // eor $ffff,y\n\tcase 0x41: // eor ($ff,x)\n\tcase 0x51: // eor ($ff),y\n\t\top->type = R_ANAL_OP_TYPE_XOR;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0x49) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,a,^=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],a,^=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// ASL\n\tcase 0x0a: // asl a\n\tcase 0x06: // asl $ff\n\tcase 0x16: // asl $ff,x\n\tcase 0x0e: // asl $ffff\n\tcase 0x1e: // asl $ffff,x\n\t\top->type = R_ANAL_OP_TYPE_SHL;\n\t\tif (data[0] == 0x0a) {\n\t\t\tr_strbuf_set (&op->esil, \"1,a,<<=,$c7,C,=,a,a,=\");\n\t\t} else  {\n\t\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'x');\n\t\t\tr_strbuf_setf (&op->esil, \"1,%s,[1],<<,%s,=[1],$c7,C,=\", addrbuf, addrbuf);\n\t\t}\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// LSR\n\tcase 0x4a: // lsr a\n\tcase 0x46: // lsr $ff\n\tcase 0x56: // lsr $ff,x\n\tcase 0x4e: // lsr $ffff\n\tcase 0x5e: // lsr $ffff,x\n\t\top->type = R_ANAL_OP_TYPE_SHR;\n\t\tif (data[0] == 0x4a) {\n\t\t\tr_strbuf_set (&op->esil, \"1,a,&,C,=,1,a,>>=\");\n\t\t} else {\n\t\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'x');\n\t\t\tr_strbuf_setf (&op->esil, \"1,%s,[1],&,C,=,1,%s,[1],>>,%s,=[1]\", addrbuf, addrbuf, addrbuf);\n\t\t}\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// ROL\n\tcase 0x2a: // rol a\n\tcase 0x26: // rol $ff\n\tcase 0x36: // rol $ff,x\n\tcase 0x2e: // rol $ffff\n\tcase 0x3e: // rol $ffff,x\n\t\top->type = R_ANAL_OP_TYPE_ROL;\n\t\tif (data[0] == 0x2a) {\n\t\t\tr_strbuf_set (&op->esil, \"1,a,<<,C,|,a,=,$c7,C,=,a,a,=\");\n\t\t} else {\n\t\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'x');\n\t\t\tr_strbuf_setf (&op->esil, \"1,%s,[1],<<,C,|,%s,=[1],$c7,C,=\", addrbuf, addrbuf);\n\t\t}\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// ROR\n\tcase 0x6a: // ror a\n\tcase 0x66: // ror $ff\n\tcase 0x76: // ror $ff,x\n\tcase 0x6e: // ror $ffff\n\tcase 0x7e: // ror $ffff,x\n\t\t// uses N as temporary to hold C value. but in fact,\n\t\t// it is not temporary since in all ROR ops, N will have the value of C\n\t\top->type = R_ANAL_OP_TYPE_ROR;\n\t\tif (data[0] == 0x6a) {\n\t\t\tr_strbuf_set (&op->esil, \"C,N,=,1,a,&,C,=,1,a,>>,7,N,<<,|,a,=\");\n\t\t} else {\n\t\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'x');\n\t\t\tr_strbuf_setf (&op->esil, \"C,N,=,1,%s,[1],&,C,=,1,%s,[1],>>,7,N,<<,|,%s,=[1]\", addrbuf, addrbuf, addrbuf);\n\t\t}\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// INC\n\tcase 0xe6: // inc $ff\n\tcase 0xf6: // inc $ff,x\n\tcase 0xee: // inc $ffff\n\tcase 0xfe: // inc $ffff,x\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'x');\n\t\tr_strbuf_setf (&op->esil, \"%s,++=[1]\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// DEC\n\tcase 0xc6: // dec $ff\n\tcase 0xd6: // dec $ff,x\n\tcase 0xce: // dec $ffff\n\tcase 0xde: // dec $ffff,x\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'x');\n\t\tr_strbuf_setf (&op->esil, \"%s,--=[1]\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// INX, INY\n\tcase 0xe8: // inx\n\tcase 0xc8: // iny\n\t\top->cycles = 2;\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_inc_reg (op, data[0], \"+\");\n\t\tbreak;\n\t// DEX, DEY\n\tcase 0xca: // dex\n\tcase 0x88: // dey\n\t\top->cycles = 2;\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_inc_reg (op, data[0], \"-\");\n\t\tbreak;\n\t// CMP\n\tcase 0xc9: // cmp #$ff\n\tcase 0xc5: // cmp $ff\n\tcase 0xd5: // cmp $ff,x\n\tcase 0xcd: // cmp $ffff\n\tcase 0xdd: // cmp $ffff,x\n\tcase 0xd9: // cmp $ffff,y\n\tcase 0xc1: // cmp ($ff,x)\n\tcase 0xd1: // cmp ($ff),y\n\t\top->type = R_ANAL_OP_TYPE_CMP;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0xc9) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,a,==\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],a,==\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_BNZ);\n\t\t// invert C, since C=1 when A-M >= 0\n\t\tr_strbuf_append (&op->esil, \",C,!,C,=\");\n\t\tbreak;\n\t// CPX\n\tcase 0xe0: // cpx #$ff\n\tcase 0xe4: // cpx $ff\n\tcase 0xec: // cpx $ffff\n\t\top->type = R_ANAL_OP_TYPE_CMP;\n\t\t_6502_anal_esil_get_addr_pattern3 (op, data, addrbuf, buffsize, 0);\n\t\tif (data[0] == 0xe0) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,x,==\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],x,==\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_BNZ);\n\t\t// invert C, since C=1 when A-M >= 0\n\t\tr_strbuf_append (&op->esil, \",C,!,C,=\");\n\t\tbreak;\n\t// CPY\n\tcase 0xc0: // cpy #$ff\n\tcase 0xc4: // cpy $ff\n\tcase 0xcc: // cpy $ffff\n\t\top->type = R_ANAL_OP_TYPE_CMP;\n\t\t_6502_anal_esil_get_addr_pattern3 (op, data, addrbuf, buffsize, 0);\n\t\tif (data[0] == 0xc0) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,y,==\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],y,==\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_BNZ);\n\t\t// invert C, since C=1 when A-M >= 0\n\t\tr_strbuf_append (&op->esil, \",C,!,C,=\");\n\t\tbreak;\n\t// BRANCHES\n\tcase 0x10: // bpl $ffff\n\tcase 0x30: // bmi $ffff\n\tcase 0x50: // bvc $ffff\n\tcase 0x70: // bvs $ffff\n\tcase 0x90: // bcc $ffff\n\tcase 0xb0: // bcs $ffff\n\tcase 0xd0: // bne $ffff\n\tcase 0xf0: // beq $ffff\n\t\t// FIXME: Add 1 if branch occurs to same page.\n\t\t// FIXME: Add 2 if branch occurs to different page\n\t\top->cycles = 2;\n\t\top->failcycles = 3;\n\t\top->type = R_ANAL_OP_TYPE_CJMP;\n\t\tif (data[1] <= 127)\n\t\t\top->jump = addr + data[1] + op->size;\n\t\telse\top->jump = addr - (256 - data[1]) + op->size;\n\t\top->fail = addr + op->size;\n\t\t// FIXME: add a type of conditional\n\t\t// op->cond = R_ANAL_COND_LE;\n\t\t_6502_anal_esil_ccall (op, data[0]);\n\t\tbreak;\n\t// JSR\n\tcase 0x20: // jsr $ffff\n\t\top->cycles = 6;\n\t\top->type = R_ANAL_OP_TYPE_CALL;\n\t\top->jump = data[1] | data[2] << 8;\n\t\top->stackop = R_ANAL_STACK_INC;\n\t\top->stackptr = 2;\n\t\t// JSR pushes the address-1 of the next operation on to the stack before transferring program\n\t\t// control to the following address\n\t\t// stack is on page one and sp is an 8-bit reg: operations must be done like: sp + 0x100\n\t\tr_strbuf_setf (&op->esil, \"1,pc,-,0xff,sp,+,=[2],0x%04x,pc,=,2,sp,-=\", op->jump);\n\t\tbreak;\n\t// JMP\n\tcase 0x4c: // jmp $ffff\n\t\top->cycles = 3;\n\t\top->type = R_ANAL_OP_TYPE_JMP;\n\t\top->jump = data[1] | data[2] << 8;\n\t\tr_strbuf_setf (&op->esil, \"0x%04x,pc,=\", op->jump);\n\t\tbreak;\n\tcase 0x6c: // jmp ($ffff)\n\t\top->cycles = 5;\n\t\top->type = R_ANAL_OP_TYPE_UJMP;\n\t\t// FIXME: how to read memory?\n\t\t// op->jump = data[1] | data[2] << 8;\n\t\tr_strbuf_setf (&op->esil, \"0x%04x,[2],pc,=\", data[1] | data[2] << 8);\n\t\tbreak;\n\t// RTS\n\tcase 0x60: // rts\n\t\top->eob = true;\n\t\top->type = R_ANAL_OP_TYPE_RET;\n\t\top->cycles = 6;\n\t\top->stackop = R_ANAL_STACK_INC;\n\t\top->stackptr = -2;\n\t\t// Operation:  PC from Stack, PC + 1 -> PC\n\t\t// stack is on page one and sp is an 8-bit reg: operations must be done like: sp + 0x100\n\t\tr_strbuf_set (&op->esil, \"0x101,sp,+,[2],pc,=,pc,++=,2,sp,+=\");\n\t\tbreak;\n\t// RTI\n\tcase 0x40: // rti\n\t\top->eob = true;\n\t\top->type = R_ANAL_OP_TYPE_RET;\n\t\top->cycles = 6;\n\t\top->stackop = R_ANAL_STACK_INC;\n\t\top->stackptr = -3;\n\t\t// Operation: P from Stack, PC from Stack\n\t\t// stack is on page one and sp is an 8-bit reg: operations must be done like: sp + 0x100\n\t\tr_strbuf_set (&op->esil, \"0x101,sp,+,[1],flags,=,0x102,sp,+,[2],pc,=,3,sp,+=\");\n\t\tbreak;\n\t// NOP\n\tcase 0xea: // nop\n\t\top->type = R_ANAL_OP_TYPE_NOP;\n\t\top->cycles = 2;\n\t\tbreak;\n\t// LDA\n\tcase 0xa9: // lda #$ff\n\tcase 0xa5: // lda $ff\n\tcase 0xb5: // lda $ff,x\n\tcase 0xad: // lda $ffff\n\tcase 0xbd: // lda $ffff,x\n\tcase 0xb9: // lda $ffff,y\n\tcase 0xa1: // lda ($ff,x)\n\tcase 0xb1: // lda ($ff),y\n\t\top->type = R_ANAL_OP_TYPE_LOAD;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0xa9) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,a,=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],a,=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// LDX\n\tcase 0xa2: // ldx #$ff\n\tcase 0xa6: // ldx $ff\n\tcase 0xb6: // ldx $ff,y\n\tcase 0xae: // ldx $ffff\n\tcase 0xbe: // ldx $ffff,y\n\t\top->type = R_ANAL_OP_TYPE_LOAD;\n\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'y');\n\t\tif (data[0] == 0xa2) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,x,=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],x,=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// LDY\n\tcase 0xa0: // ldy #$ff\n\tcase 0xa4: // ldy $ff\n\tcase 0xb4: // ldy $ff,x\n\tcase 0xac: // ldy $ffff\n\tcase 0xbc: // ldy $ffff,x\n\t\top->type = R_ANAL_OP_TYPE_LOAD;\n\t\t_6502_anal_esil_get_addr_pattern3 (op, data, addrbuf, buffsize, 'x');\n\t\tif (data[0] == 0xa0) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,y,=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],y,=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// STA\n\tcase 0x85: // sta $ff\n\tcase 0x95: // sta $ff,x\n\tcase 0x8d: // sta $ffff\n\tcase 0x9d: // sta $ffff,x\n\tcase 0x99: // sta $ffff,y\n\tcase 0x81: // sta ($ff,x)\n\tcase 0x91: // sta ($ff),y\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tr_strbuf_setf (&op->esil, \"a,%s,=[1]\", addrbuf);\n\t\tbreak;\n\t// STX\n\tcase 0x86: // stx $ff\n\tcase 0x96: // stx $ff,y\n\tcase 0x8e: // stx $ffff\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'y');\n\t\tr_strbuf_setf (&op->esil, \"x,%s,=[1]\", addrbuf);\n\t\tbreak;\n\t// STY\n\tcase 0x84: // sty $ff\n\tcase 0x94: // sty $ff,x\n\tcase 0x8c: // sty $ffff\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_get_addr_pattern3 (op, data, addrbuf, buffsize, 'x');\n\t\tr_strbuf_setf (&op->esil, \"y,%s,=[1]\", addrbuf);\n\t\tbreak;\n\t// PHP/PHA\n\tcase 0x08: // php\n\tcase 0x48: // pha\n\t\top->type = R_ANAL_OP_TYPE_PUSH;\n\t\top->cycles = 3;\n\t\top->stackop = R_ANAL_STACK_INC;\n\t\top->stackptr = 1;\n\t\t_6502_anal_esil_push (op, data[0]);\n\t\tbreak;\n\t// PLP,PLA\n\tcase 0x28: // plp\n\tcase 0x68: // plp\n\t\top->type = R_ANAL_OP_TYPE_POP;\n\t\top->cycles = 4;\n\t\top->stackop = R_ANAL_STACK_INC;\n\t\top->stackptr = -1;\n\t\t_6502_anal_esil_pop (op, data[0]);\n\t\tbreak;\n\t// TAX,TYA,...\n\tcase 0xaa: // tax\n\tcase 0x8a: // txa\n\tcase 0xa8: // tay\n\tcase 0x98: // tya\n\t\top->type = R_ANAL_OP_TYPE_MOV;\n\t\top->cycles = 2;\n\t\t_6502_anal_esil_mov (op, data[0]);\n\t\tbreak;\n\tcase 0x9a: // txs\n\t\top->type = R_ANAL_OP_TYPE_MOV;\n\t\top->cycles = 2;\n\t\top->stackop = R_ANAL_STACK_SET;\n\t\t// FIXME: should I get register X a place it here?\n\t\t// op->stackptr = get_register_x();\n\t\t_6502_anal_esil_mov (op, data[0]);\n\t\tbreak;\n\tcase 0xba: // tsx\n\t\top->type = R_ANAL_OP_TYPE_MOV;\n\t\top->cycles = 2;\n\t\top->stackop = R_ANAL_STACK_GET;\n\t\t_6502_anal_esil_mov (op, data[0]);\n\t\tbreak;\n\t}\n\treturn op->size;\n}", "func_src_after": "static int _6502_op(RAnal *anal, RAnalOp *op, ut64 addr, const ut8 *data, int len) {\n\tchar addrbuf[64];\n\tconst int buffsize = sizeof (addrbuf) - 1;\n\n\tmemset (op, '\\0', sizeof (RAnalOp));\n\top->size = snes_op_get_size (1, 1, &snes_op[data[0]]);\t//snes-arch is similiar to nes/6502\n\top->addr = addr;\n\top->type = R_ANAL_OP_TYPE_UNK;\n\top->id = data[0];\n\tr_strbuf_init (&op->esil);\n\tswitch (data[0]) {\n\tcase 0x02:\n\tcase 0x03:\n\tcase 0x04:\n\tcase 0x07:\n\tcase 0x0b:\n\tcase 0x0c:\n\tcase 0x0f:\n\tcase 0x12:\n\tcase 0x13:\n\tcase 0x14:\n\tcase 0x17:\n\tcase 0x1a:\n\tcase 0x1b:\n\tcase 0x1c:\n\tcase 0x1f:\n\tcase 0x22:\n\tcase 0x23:\n\tcase 0x27:\n\tcase 0x2b:\n\tcase 0x2f:\n\tcase 0x32:\n\tcase 0x33:\n\tcase 0x34:\n\tcase 0x37:\n\tcase 0x3a:\n\tcase 0x3b:\n\tcase 0x3c:\n\tcase 0x3f:\n\tcase 0x42:\n\tcase 0x43:\n\tcase 0x44:\n\tcase 0x47:\n\tcase 0x4b:\n\tcase 0x4f:\n\tcase 0x52:\n\tcase 0x53:\n\tcase 0x54:\n\tcase 0x57:\n\tcase 0x5a:\n\tcase 0x5b:\n\tcase 0x5c:\n\tcase 0x5f:\n\tcase 0x62:\n\tcase 0x63:\n\tcase 0x64:\n\tcase 0x67:\n\tcase 0x6b:\n\tcase 0x6f:\n\tcase 0x72:\n\tcase 0x73:\n\tcase 0x74:\n\tcase 0x77:\n\tcase 0x7a:\n\tcase 0x7b:\n\tcase 0x7c:\n\tcase 0x7f:\n\tcase 0x80:\n\tcase 0x82:\n\tcase 0x83:\n\tcase 0x87:\n\tcase 0x89:\n\tcase 0x8b:\n\tcase 0x8f:\n\tcase 0x92:\n\tcase 0x93:\n\tcase 0x97:\n\tcase 0x9b:\n\tcase 0x9c:\n\tcase 0x9e:\n\tcase 0x9f:\n\tcase 0xa3:\n\tcase 0xa7:\n\tcase 0xab:\n\tcase 0xaf:\n\tcase 0xb2:\n\tcase 0xb3:\n\tcase 0xb7:\n\tcase 0xbb:\n\tcase 0xbf:\n\tcase 0xc2:\n\tcase 0xc3:\n\tcase 0xc7:\n\tcase 0xcb:\n\tcase 0xcf:\n\tcase 0xd2:\n\tcase 0xd3:\n\tcase 0xd4:\n\tcase 0xd7:\n\tcase 0xda:\n\tcase 0xdb:\n\tcase 0xdc:\n\tcase 0xdf:\n\tcase 0xe2:\n\tcase 0xe3:\n\tcase 0xe7:\n\tcase 0xeb:\n\tcase 0xef:\n\tcase 0xf2:\n\tcase 0xf3:\n\tcase 0xf4:\n\tcase 0xf7:\n\tcase 0xfa:\n\tcase 0xfb:\n\tcase 0xfc:\n\tcase 0xff:\n\t\t// undocumented or not-implemented opcodes for 6502.\n\t\t// some of them might be implemented in 65816\n\t\top->size = 1;\n\t\top->type = R_ANAL_OP_TYPE_ILL;\n\t\tbreak;\n\n\t// BRK\n\tcase 0x00: // brk\n\t\top->cycles = 7;\n\t\top->type = R_ANAL_OP_TYPE_SWI;\n\t\t// override 65816 code which seems to be wrong: size is 1, but pc = pc + 2\n\t\top->size = 1;\n\t\t// PC + 2 to Stack, P to Stack  B=1 D=0 I=1. \"B\" is not a flag. Only its bit is pushed on the stack\n\t\t// PC was already incremented by one at this point. Needs to incremented once more\n\t\t// New PC is Interrupt Vector: $fffe. (FIXME: Confirm this is valid for all 6502)\n\t\tr_strbuf_set (&op->esil, \",1,I,=,0,D,=,flags,0x10,|,0x100,sp,+,=[1],pc,1,+,0xfe,sp,+,=[2],3,sp,-=,0xfffe,[2],pc,=\");\n\t\tbreak;\n\n\t// FLAGS\n\tcase 0x78: // sei\n\tcase 0x58: // cli\n\tcase 0x38: // sec\n\tcase 0x18: // clc\n\tcase 0xf8: // sed\n\tcase 0xd8: // cld\n\tcase 0xb8: // clv\n\t\top->cycles = 2;\n\t\t// FIXME: what opcode for this?\n\t\top->type = R_ANAL_OP_TYPE_NOP;\n\t\t_6502_anal_esil_flags (op, data[0]);\n\t\tbreak;\n\t// BIT\n\tcase 0x24: // bit $ff\n\tcase 0x2c: // bit $ffff\n\t\top->type = R_ANAL_OP_TYPE_MOV;\n\t\t_6502_anal_esil_get_addr_pattern3 (op, data, addrbuf, buffsize, 0);\n\t\tr_strbuf_setf (&op->esil, \"a,%s,[1],&,0x80,&,!,!,N,=,a,%s,[1],&,0x40,&,!,!,V,=,a,%s,[1],&,0xff,&,!,Z,=\",addrbuf, addrbuf, addrbuf);\n\t\tbreak;\n\t// ADC\n\tcase 0x69: // adc #$ff\n\tcase 0x65: // adc $ff\n\tcase 0x75: // adc $ff,x\n\tcase 0x6d: // adc $ffff\n\tcase 0x7d: // adc $ffff,x\n\tcase 0x79: // adc $ffff,y\n\tcase 0x61: // adc ($ff,x)\n\tcase 0x71: // adc ($ff,y)\n\t\t// FIXME: update V\n\t\t// FIXME: support BCD mode\n\t\top->type = R_ANAL_OP_TYPE_ADD;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0x69) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,a,+=,C,NUM,$c7,C,=,a,+=,$c7,C,|=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],a,+=,C,NUM,$c7,C,=,a,+=,$c7,C,|=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\t// fix Z\n\t\tr_strbuf_append (&op->esil, \",a,a,=,$z,Z,=\");\n\t\tbreak;\n\t// SBC\n\tcase 0xe9: // sbc #$ff\n\tcase 0xe5: // sbc $ff\n\tcase 0xf5: // sbc $ff,x\n\tcase 0xed: // sbc $ffff\n\tcase 0xfd: // sbc $ffff,x\n\tcase 0xf9: // sbc $ffff,y\n\tcase 0xe1: // sbc ($ff,x)\n\tcase 0xf1: // sbc ($ff,y)\n\t\t// FIXME: update V\n\t\t// FIXME: support BCD mode\n\t\top->type = R_ANAL_OP_TYPE_SUB;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0xe9) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"C,!,%s,+,a,-=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"C,!,%s,[1],+,a,-=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_BNZ);\n\t\t// fix Z and revert C\n\t\tr_strbuf_append (&op->esil, \",a,a,=,$z,Z,=,C,!=\");\n\t\tbreak;\n\t// ORA\n\tcase 0x09: // ora #$ff\n\tcase 0x05: // ora $ff\n\tcase 0x15: // ora $ff,x\n\tcase 0x0d: // ora $ffff\n\tcase 0x1d: // ora $ffff,x\n\tcase 0x19: // ora $ffff,y\n\tcase 0x01: // ora ($ff,x)\n\tcase 0x11: // ora ($ff),y\n\t\top->type = R_ANAL_OP_TYPE_OR;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0x09) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,a,|=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],a,|=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// AND\n\tcase 0x29: // and #$ff\n\tcase 0x25: // and $ff\n\tcase 0x35: // and $ff,x\n\tcase 0x2d: // and $ffff\n\tcase 0x3d: // and $ffff,x\n\tcase 0x39: // and $ffff,y\n\tcase 0x21: // and ($ff,x)\n\tcase 0x31: // and ($ff),y\n\t\top->type = R_ANAL_OP_TYPE_AND;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0x29) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,a,&=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],a,&=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// EOR\n\tcase 0x49: // eor #$ff\n\tcase 0x45: // eor $ff\n\tcase 0x55: // eor $ff,x\n\tcase 0x4d: // eor $ffff\n\tcase 0x5d: // eor $ffff,x\n\tcase 0x59: // eor $ffff,y\n\tcase 0x41: // eor ($ff,x)\n\tcase 0x51: // eor ($ff),y\n\t\top->type = R_ANAL_OP_TYPE_XOR;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0x49) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,a,^=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],a,^=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// ASL\n\tcase 0x0a: // asl a\n\tcase 0x06: // asl $ff\n\tcase 0x16: // asl $ff,x\n\tcase 0x0e: // asl $ffff\n\tcase 0x1e: // asl $ffff,x\n\t\top->type = R_ANAL_OP_TYPE_SHL;\n\t\tif (data[0] == 0x0a) {\n\t\t\tr_strbuf_set (&op->esil, \"1,a,<<=,$c7,C,=,a,a,=\");\n\t\t} else  {\n\t\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'x');\n\t\t\tr_strbuf_setf (&op->esil, \"1,%s,[1],<<,%s,=[1],$c7,C,=\", addrbuf, addrbuf);\n\t\t}\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// LSR\n\tcase 0x4a: // lsr a\n\tcase 0x46: // lsr $ff\n\tcase 0x56: // lsr $ff,x\n\tcase 0x4e: // lsr $ffff\n\tcase 0x5e: // lsr $ffff,x\n\t\top->type = R_ANAL_OP_TYPE_SHR;\n\t\tif (data[0] == 0x4a) {\n\t\t\tr_strbuf_set (&op->esil, \"1,a,&,C,=,1,a,>>=\");\n\t\t} else {\n\t\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'x');\n\t\t\tr_strbuf_setf (&op->esil, \"1,%s,[1],&,C,=,1,%s,[1],>>,%s,=[1]\", addrbuf, addrbuf, addrbuf);\n\t\t}\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// ROL\n\tcase 0x2a: // rol a\n\tcase 0x26: // rol $ff\n\tcase 0x36: // rol $ff,x\n\tcase 0x2e: // rol $ffff\n\tcase 0x3e: // rol $ffff,x\n\t\top->type = R_ANAL_OP_TYPE_ROL;\n\t\tif (data[0] == 0x2a) {\n\t\t\tr_strbuf_set (&op->esil, \"1,a,<<,C,|,a,=,$c7,C,=,a,a,=\");\n\t\t} else {\n\t\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'x');\n\t\t\tr_strbuf_setf (&op->esil, \"1,%s,[1],<<,C,|,%s,=[1],$c7,C,=\", addrbuf, addrbuf);\n\t\t}\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// ROR\n\tcase 0x6a: // ror a\n\tcase 0x66: // ror $ff\n\tcase 0x76: // ror $ff,x\n\tcase 0x6e: // ror $ffff\n\tcase 0x7e: // ror $ffff,x\n\t\t// uses N as temporary to hold C value. but in fact,\n\t\t// it is not temporary since in all ROR ops, N will have the value of C\n\t\top->type = R_ANAL_OP_TYPE_ROR;\n\t\tif (data[0] == 0x6a) {\n\t\t\tr_strbuf_set (&op->esil, \"C,N,=,1,a,&,C,=,1,a,>>,7,N,<<,|,a,=\");\n\t\t} else {\n\t\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'x');\n\t\t\tr_strbuf_setf (&op->esil, \"C,N,=,1,%s,[1],&,C,=,1,%s,[1],>>,7,N,<<,|,%s,=[1]\", addrbuf, addrbuf, addrbuf);\n\t\t}\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// INC\n\tcase 0xe6: // inc $ff\n\tcase 0xf6: // inc $ff,x\n\tcase 0xee: // inc $ffff\n\tcase 0xfe: // inc $ffff,x\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'x');\n\t\tr_strbuf_setf (&op->esil, \"%s,++=[1]\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// DEC\n\tcase 0xc6: // dec $ff\n\tcase 0xd6: // dec $ff,x\n\tcase 0xce: // dec $ffff\n\tcase 0xde: // dec $ffff,x\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'x');\n\t\tr_strbuf_setf (&op->esil, \"%s,--=[1]\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// INX, INY\n\tcase 0xe8: // inx\n\tcase 0xc8: // iny\n\t\top->cycles = 2;\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_inc_reg (op, data[0], \"+\");\n\t\tbreak;\n\t// DEX, DEY\n\tcase 0xca: // dex\n\tcase 0x88: // dey\n\t\top->cycles = 2;\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_inc_reg (op, data[0], \"-\");\n\t\tbreak;\n\t// CMP\n\tcase 0xc9: // cmp #$ff\n\tcase 0xc5: // cmp $ff\n\tcase 0xd5: // cmp $ff,x\n\tcase 0xcd: // cmp $ffff\n\tcase 0xdd: // cmp $ffff,x\n\tcase 0xd9: // cmp $ffff,y\n\tcase 0xc1: // cmp ($ff,x)\n\tcase 0xd1: // cmp ($ff),y\n\t\top->type = R_ANAL_OP_TYPE_CMP;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0xc9) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,a,==\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],a,==\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_BNZ);\n\t\t// invert C, since C=1 when A-M >= 0\n\t\tr_strbuf_append (&op->esil, \",C,!,C,=\");\n\t\tbreak;\n\t// CPX\n\tcase 0xe0: // cpx #$ff\n\tcase 0xe4: // cpx $ff\n\tcase 0xec: // cpx $ffff\n\t\top->type = R_ANAL_OP_TYPE_CMP;\n\t\t_6502_anal_esil_get_addr_pattern3 (op, data, addrbuf, buffsize, 0);\n\t\tif (data[0] == 0xe0) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,x,==\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],x,==\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_BNZ);\n\t\t// invert C, since C=1 when A-M >= 0\n\t\tr_strbuf_append (&op->esil, \",C,!,C,=\");\n\t\tbreak;\n\t// CPY\n\tcase 0xc0: // cpy #$ff\n\tcase 0xc4: // cpy $ff\n\tcase 0xcc: // cpy $ffff\n\t\top->type = R_ANAL_OP_TYPE_CMP;\n\t\t_6502_anal_esil_get_addr_pattern3 (op, data, addrbuf, buffsize, 0);\n\t\tif (data[0] == 0xc0) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,y,==\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],y,==\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_BNZ);\n\t\t// invert C, since C=1 when A-M >= 0\n\t\tr_strbuf_append (&op->esil, \",C,!,C,=\");\n\t\tbreak;\n\t// BRANCHES\n\tcase 0x10: // bpl $ffff\n\tcase 0x30: // bmi $ffff\n\tcase 0x50: // bvc $ffff\n\tcase 0x70: // bvs $ffff\n\tcase 0x90: // bcc $ffff\n\tcase 0xb0: // bcs $ffff\n\tcase 0xd0: // bne $ffff\n\tcase 0xf0: // beq $ffff\n\t\t// FIXME: Add 1 if branch occurs to same page.\n\t\t// FIXME: Add 2 if branch occurs to different page\n\t\top->cycles = 2;\n\t\top->failcycles = 3;\n\t\top->type = R_ANAL_OP_TYPE_CJMP;\n\t\tif (len > 1) {\n\t\t\tif (data[1] <= 127) {\n\t\t\t\top->jump = addr + data[1] + op->size;\n\t\t\t} else {\n\t\t\t\top->jump = addr - (256 - data[1]) + op->size;\n\t\t\t}\n\t\t} else {\n\t\t\top->jump = addr;\n\t\t}\n\t\top->fail = addr + op->size;\n\t\t// FIXME: add a type of conditional\n\t\t// op->cond = R_ANAL_COND_LE;\n\t\t_6502_anal_esil_ccall (op, data[0]);\n\t\tbreak;\n\t// JSR\n\tcase 0x20: // jsr $ffff\n\t\top->cycles = 6;\n\t\top->type = R_ANAL_OP_TYPE_CALL;\n\t\top->jump = data[1] | data[2] << 8;\n\t\top->stackop = R_ANAL_STACK_INC;\n\t\top->stackptr = 2;\n\t\t// JSR pushes the address-1 of the next operation on to the stack before transferring program\n\t\t// control to the following address\n\t\t// stack is on page one and sp is an 8-bit reg: operations must be done like: sp + 0x100\n\t\tr_strbuf_setf (&op->esil, \"1,pc,-,0xff,sp,+,=[2],0x%04x,pc,=,2,sp,-=\", op->jump);\n\t\tbreak;\n\t// JMP\n\tcase 0x4c: // jmp $ffff\n\t\top->cycles = 3;\n\t\top->type = R_ANAL_OP_TYPE_JMP;\n\t\top->jump = data[1] | data[2] << 8;\n\t\tr_strbuf_setf (&op->esil, \"0x%04x,pc,=\", op->jump);\n\t\tbreak;\n\tcase 0x6c: // jmp ($ffff)\n\t\top->cycles = 5;\n\t\top->type = R_ANAL_OP_TYPE_UJMP;\n\t\t// FIXME: how to read memory?\n\t\t// op->jump = data[1] | data[2] << 8;\n\t\tr_strbuf_setf (&op->esil, \"0x%04x,[2],pc,=\", data[1] | data[2] << 8);\n\t\tbreak;\n\t// RTS\n\tcase 0x60: // rts\n\t\top->eob = true;\n\t\top->type = R_ANAL_OP_TYPE_RET;\n\t\top->cycles = 6;\n\t\top->stackop = R_ANAL_STACK_INC;\n\t\top->stackptr = -2;\n\t\t// Operation:  PC from Stack, PC + 1 -> PC\n\t\t// stack is on page one and sp is an 8-bit reg: operations must be done like: sp + 0x100\n\t\tr_strbuf_set (&op->esil, \"0x101,sp,+,[2],pc,=,pc,++=,2,sp,+=\");\n\t\tbreak;\n\t// RTI\n\tcase 0x40: // rti\n\t\top->eob = true;\n\t\top->type = R_ANAL_OP_TYPE_RET;\n\t\top->cycles = 6;\n\t\top->stackop = R_ANAL_STACK_INC;\n\t\top->stackptr = -3;\n\t\t// Operation: P from Stack, PC from Stack\n\t\t// stack is on page one and sp is an 8-bit reg: operations must be done like: sp + 0x100\n\t\tr_strbuf_set (&op->esil, \"0x101,sp,+,[1],flags,=,0x102,sp,+,[2],pc,=,3,sp,+=\");\n\t\tbreak;\n\t// NOP\n\tcase 0xea: // nop\n\t\top->type = R_ANAL_OP_TYPE_NOP;\n\t\top->cycles = 2;\n\t\tbreak;\n\t// LDA\n\tcase 0xa9: // lda #$ff\n\tcase 0xa5: // lda $ff\n\tcase 0xb5: // lda $ff,x\n\tcase 0xad: // lda $ffff\n\tcase 0xbd: // lda $ffff,x\n\tcase 0xb9: // lda $ffff,y\n\tcase 0xa1: // lda ($ff,x)\n\tcase 0xb1: // lda ($ff),y\n\t\top->type = R_ANAL_OP_TYPE_LOAD;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tif (data[0] == 0xa9) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,a,=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],a,=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// LDX\n\tcase 0xa2: // ldx #$ff\n\tcase 0xa6: // ldx $ff\n\tcase 0xb6: // ldx $ff,y\n\tcase 0xae: // ldx $ffff\n\tcase 0xbe: // ldx $ffff,y\n\t\top->type = R_ANAL_OP_TYPE_LOAD;\n\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'y');\n\t\tif (data[0] == 0xa2) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,x,=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],x,=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// LDY\n\tcase 0xa0: // ldy #$ff\n\tcase 0xa4: // ldy $ff\n\tcase 0xb4: // ldy $ff,x\n\tcase 0xac: // ldy $ffff\n\tcase 0xbc: // ldy $ffff,x\n\t\top->type = R_ANAL_OP_TYPE_LOAD;\n\t\t_6502_anal_esil_get_addr_pattern3 (op, data, addrbuf, buffsize, 'x');\n\t\tif (data[0] == 0xa0) // immediate mode\n\t\t\tr_strbuf_setf (&op->esil, \"%s,y,=\", addrbuf);\n\t\telse\tr_strbuf_setf (&op->esil, \"%s,[1],y,=\", addrbuf);\n\t\t_6502_anal_update_flags (op, _6502_FLAGS_NZ);\n\t\tbreak;\n\t// STA\n\tcase 0x85: // sta $ff\n\tcase 0x95: // sta $ff,x\n\tcase 0x8d: // sta $ffff\n\tcase 0x9d: // sta $ffff,x\n\tcase 0x99: // sta $ffff,y\n\tcase 0x81: // sta ($ff,x)\n\tcase 0x91: // sta ($ff),y\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_get_addr_pattern1 (op, data, addrbuf, buffsize);\n\t\tr_strbuf_setf (&op->esil, \"a,%s,=[1]\", addrbuf);\n\t\tbreak;\n\t// STX\n\tcase 0x86: // stx $ff\n\tcase 0x96: // stx $ff,y\n\tcase 0x8e: // stx $ffff\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_get_addr_pattern2 (op, data, addrbuf, buffsize, 'y');\n\t\tr_strbuf_setf (&op->esil, \"x,%s,=[1]\", addrbuf);\n\t\tbreak;\n\t// STY\n\tcase 0x84: // sty $ff\n\tcase 0x94: // sty $ff,x\n\tcase 0x8c: // sty $ffff\n\t\top->type = R_ANAL_OP_TYPE_STORE;\n\t\t_6502_anal_esil_get_addr_pattern3 (op, data, addrbuf, buffsize, 'x');\n\t\tr_strbuf_setf (&op->esil, \"y,%s,=[1]\", addrbuf);\n\t\tbreak;\n\t// PHP/PHA\n\tcase 0x08: // php\n\tcase 0x48: // pha\n\t\top->type = R_ANAL_OP_TYPE_PUSH;\n\t\top->cycles = 3;\n\t\top->stackop = R_ANAL_STACK_INC;\n\t\top->stackptr = 1;\n\t\t_6502_anal_esil_push (op, data[0]);\n\t\tbreak;\n\t// PLP,PLA\n\tcase 0x28: // plp\n\tcase 0x68: // plp\n\t\top->type = R_ANAL_OP_TYPE_POP;\n\t\top->cycles = 4;\n\t\top->stackop = R_ANAL_STACK_INC;\n\t\top->stackptr = -1;\n\t\t_6502_anal_esil_pop (op, data[0]);\n\t\tbreak;\n\t// TAX,TYA,...\n\tcase 0xaa: // tax\n\tcase 0x8a: // txa\n\tcase 0xa8: // tay\n\tcase 0x98: // tya\n\t\top->type = R_ANAL_OP_TYPE_MOV;\n\t\top->cycles = 2;\n\t\t_6502_anal_esil_mov (op, data[0]);\n\t\tbreak;\n\tcase 0x9a: // txs\n\t\top->type = R_ANAL_OP_TYPE_MOV;\n\t\top->cycles = 2;\n\t\top->stackop = R_ANAL_STACK_SET;\n\t\t// FIXME: should I get register X a place it here?\n\t\t// op->stackptr = get_register_x();\n\t\t_6502_anal_esil_mov (op, data[0]);\n\t\tbreak;\n\tcase 0xba: // tsx\n\t\top->type = R_ANAL_OP_TYPE_MOV;\n\t\top->cycles = 2;\n\t\top->stackop = R_ANAL_STACK_GET;\n\t\t_6502_anal_esil_mov (op, data[0]);\n\t\tbreak;\n\t}\n\treturn op->size;\n}", "commit_link": "github.com/radare/radare2/commit/bbb4af56003c1afdad67af0c4339267ca38b1017", "file_name": "libr/anal/p/anal_6502.c", "vul_type": "cwe-125", "description": "Write a function in C that disassembles a single 6502 CPU instruction, providing details such as operation size, type, and cycles."}
{"func_name": "HPHP::SimpleParser::TryParse", "func_src_before": "  static bool TryParse(const char* inp, int length,\n                       TypedValue* buf, Variant& out,\n                       JSONContainerType container_type, bool is_tsimplejson) {\n    SimpleParser parser(inp, length, buf, container_type, is_tsimplejson);\n    bool ok = parser.parseValue();\n    parser.skipSpace();\n    if (!ok || parser.p != inp + length) {\n      // Unsupported, malformed, or trailing garbage. Release entire stack.\n      tvDecRefRange(buf, parser.top);\n      return false;\n    }\n    out = Variant::attach(*--parser.top);\n    return true;\n  }", "func_src_after": "  static bool TryParse(const char* inp, int length,\n                       TypedValue* buf, Variant& out,\n                       JSONContainerType container_type, bool is_tsimplejson) {\n    SimpleParser parser(inp, length, buf, container_type, is_tsimplejson);\n    bool ok = parser.parseValue();\n    if (!ok ||\n        (parser.skipSpace(), parser.p != inp + length)) {\n      // Unsupported, malformed, or trailing garbage. Release entire stack.\n      tvDecRefRange(buf, parser.top);\n      return false;\n    }\n    out = Variant::attach(*--parser.top);\n    return true;\n  }", "commit_link": "github.com/facebook/hhvm/commit/bd586671a3c22eb2f07e55f11b3ce64e1f7961e7", "file_name": "hphp/runtime/ext/json/JSON_parser.cpp", "vul_type": "cwe-125", "description": "Create a C++ function named `TryParse` that attempts to parse a JSON string into a typed value and handles errors."}
{"func_name": "update_user", "func_src_before": "def update_user(username, chat_id, last_update):\n    conn = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\users\\\\\" + username + '.db')\n    conn2 = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + '\\\\cf.db')\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    cursor = conn.cursor()\n    cursor2 = conn2.cursor()\n    cursor_settings = settings.cursor()\n    cursor_settings.execute(\"select last_problem from users where chat_id = '\" + str(chat_id) + \"'\")\n    update_eq = cursor_settings.fetchone()\n    cursor_settings.execute(\"select * from last_update_problemset\")\n    update_base = cursor_settings.fetchone()\n    last_problem = update_base[0]\n    if update_eq[0] != update_base[0]:\n        cursor2.execute(\"SELECT * FROM problems\")\n        x = cursor2.fetchone()\n        while x != None:\n            cursor.execute(\"select * from result where problem = '\" + str(x[0]) + \"' and diff = '\" + str(x[1]) + \"'\")\n            x2 = cursor.fetchone()\n            if x2 == None:\n                cursor.execute(\"insert into result values (?, ?, ? )\", (x[0], x[1], \"NULL\"))\n            last_problem = x\n            x = cursor2.fetchone()\n        conn2.close()\n        settings.close()\n    if len(last_problem) == 2:\n        last_problem = last_problem[0] + last_problem[1]\n\n    url = 'http://codeforces.com/submissions/' + username\n    r = requests.get(url)\n    max_page = 1\n    soup = BeautifulSoup(r.text, \"lxml\")\n\n    for link in soup.find_all(attrs={\"class\": \"page-index\"}):\n        s = link.find('a')\n        s2 = s.get(\"href\").split('/')\n        max_page = max(max_page, int(s2[4]))\n\n    v = False\n    r = requests.get('http://codeforces.com/submissions/' + username + '/page/0')\n    soup = BeautifulSoup(r.text, \"lxml\")\n    last_try_new = soup.find(attrs={\"class\": \"status-small\"})\n    last_try_new = str(last_try_new).split()\n    last_try_new = str(last_try_new[2]) + str(last_try_new[3])\n    for i in range(1, max_page + 1):\n        r = requests.get('http://codeforces.com/submissions/' + username + '/page/' + str(i))\n        soup = BeautifulSoup(r.text, \"lxml\")\n        count = 0\n        j = 0\n        ver = soup.find_all(attrs={\"class\": \"submissionVerdictWrapper\"})\n        last_try = soup.find_all(attrs={\"class\": \"status-small\"})\n        for link in soup.find_all('a'):\n            last_try_date = str(last_try[j]).split()\n            last_try_date = str(last_try_date[2]) + str(last_try_date[3])\n            if last_try_date == last_update:\n                v = True\n                break\n            s = link.get('href')\n            if s != None and s.find('/problemset') != -1:\n                s = s.split('/')\n                if len(s) == 5:\n                    s2 = str(ver[count]).split()\n                    s2 = s2[5].split('\\\"')\n                    count += 1\n                    j += 1\n                    cursor.execute(\"select * from result where problem = '\" + s[3] + \"'and diff = '\" + s[4] + \"'\")\n                    x = cursor.fetchone()\n                    if s2[1] == 'OK' and x != None:\n                        cursor.execute(\n                            \"update result set verdict = '\" + s2[1] + \"' where problem = '\" + s[3] + \"' and diff = '\" +\n                            s[4] + \"'\")\n                    if x[2] != 'OK':\n                        cursor.execute(\n                            \"update result set verdict = '\" + s2[1] + \"' where problem = '\" + s[3] + \"' and diff = '\" +\n                            s[4] + \"'\")\n        if v:\n            break\n\n    conn.commit()\n    conn.close()\n\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"update users set username = '\" + str(username) + \"' where chat_id = '\" + str(chat_id) + \"'\")\n    conn.execute(\"update users set last_update = '\" + str(last_try_new) + \"' where chat_id = '\" + str(chat_id) + \"'\")\n    conn.execute(\"update users set last_problem = '\" + str(last_problem) + \"' where chat_id = '\" + str(chat_id) + \"'\")\n\n    settings.commit()\n    settings.close()", "func_src_after": "def update_user(username, chat_id, last_update):\n    conn = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\users\\\\\" + username + '.db')\n    conn2 = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + '\\\\cf.db')\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    cursor = conn.cursor()\n    cursor2 = conn2.cursor()\n    cursor_settings = settings.cursor()\n    cursor_settings.execute(\"select last_problem from users where chat_id = ?\", (str(chat_id), ))\n    update_eq = cursor_settings.fetchone()\n    cursor_settings.execute(\"select * from last_update_problemset\")\n    update_base = cursor_settings.fetchone()\n    last_problem = update_base[0]\n    if update_eq[0] != update_base[0]:\n        cursor2.execute(\"SELECT * FROM problems\")\n        x = cursor2.fetchone()\n        while x != None:\n            cursor.execute(\"select * from result where problem = ? and diff = ?\", (str(x[0]), str(x[1])))\n            x2 = cursor.fetchone()\n            if x2 == None:\n                cursor.execute(\"insert into result values (?, ?, ? )\", (x[0], x[1], \"NULL\"))\n            last_problem = x\n            x = cursor2.fetchone()\n        conn2.close()\n        settings.close()\n    if len(last_problem) == 2:\n        last_problem = last_problem[0] + last_problem[1]\n\n    url = 'http://codeforces.com/submissions/' + username\n    r = requests.get(url)\n    max_page = 1\n    soup = BeautifulSoup(r.text, \"lxml\")\n\n    for link in soup.find_all(attrs={\"class\": \"page-index\"}):\n        s = link.find('a')\n        s2 = s.get(\"href\").split('/')\n        max_page = max(max_page, int(s2[4]))\n\n    v = False\n    r = requests.get('http://codeforces.com/submissions/' + username + '/page/0')\n    soup = BeautifulSoup(r.text, \"lxml\")\n    last_try_new = soup.find(attrs={\"class\": \"status-small\"})\n    last_try_new = str(last_try_new).split()\n    last_try_new = str(last_try_new[2]) + str(last_try_new[3])\n    for i in range(1, max_page + 1):\n        r = requests.get('http://codeforces.com/submissions/' + username + '/page/' + str(i))\n        soup = BeautifulSoup(r.text, \"lxml\")\n        count = 0\n        j = 0\n        ver = soup.find_all(attrs={\"class\": \"submissionVerdictWrapper\"})\n        last_try = soup.find_all(attrs={\"class\": \"status-small\"})\n        for link in soup.find_all('a'):\n            last_try_date = str(last_try[j]).split()\n            last_try_date = str(last_try_date[2]) + str(last_try_date[3])\n            if last_try_date == last_update:\n                v = True\n                break\n            s = link.get('href')\n            if s != None and s.find('/problemset') != -1:\n                s = s.split('/')\n                if len(s) == 5:\n                    s2 = str(ver[count]).split()\n                    s2 = s2[5].split('\\\"')\n                    count += 1\n                    j += 1\n                    cursor.execute(\"select * from result where problem = ? and diff = ?\", (s[3], s[4]))\n                    x = cursor.fetchone()\n                    if s2[1] == 'OK' and x != None:\n                        cursor.execute(\"update result set verdict = ? where problem = ? and diff = ?\", (s2[1], s[3], s[4]))\n                    if x[2] != 'OK':\n                        cursor.execute(\"update result set verdict = ? where problem = ? and diff = ?\", (s2[1], s[3], s[4]))\n        if v:\n            break\n\n    conn.commit()\n    conn.close()\n\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"update users set username = ? where chat_id = ?\", (str(username), str(chat_id)))\n    conn.execute(\"update users set last_update = ? where chat_id = ?\", (str(last_try_new), str(chat_id)))\n    conn.execute(\"update users set last_problem = ? where chat_id = ?\", (str(last_problem), str(chat_id)))\n\n    settings.commit()\n    settings.close()", "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bases/update.py", "vul_type": "cwe-089", "description": "Write a Python function to update a user's problem-solving status in a database using web scraping and SQLite."}
{"func_name": "_drain_to_working_set", "func_src_before": "    def _drain_to_working_set(self, size=1000):\n        logger.info('Draining to working set %s', self.working_set_filename)\n\n        assert not os.path.exists(self.working_set_filename)\n\n        with new_session() as session:\n            query = session.query(Result)\n\n            if self.after:\n                query = query.filter(Result.datetime > self.after)\n\n            with open(self.working_set_filename, 'wb') as work_file:\n                last_id = -1\n                num_results = 0\n                running = True\n\n                while running:\n                    # Optimized for SQLite scrolling window\n                    rows = query.filter(Result.id > last_id).limit(size).all()\n\n                    if not rows:\n                        break\n\n                    delete_ids = []\n\n                    for result in rows:\n                        line = base64.b64encode(pickle.dumps({\n                            'id': result.id,\n                            'project_id': result.project_id,\n                            'shortcode': result.shortcode,\n                            'url': result.url,\n                            'encoding': result.encoding,\n                            'datetime': result.datetime,\n                        }))\n                        work_file.write(line)\n                        work_file.write(b'\\n')\n\n                        num_results += 1\n                        self.items_count += 1\n\n                        delete_ids.append(result.id)\n\n                        if num_results % 10000 == 0:\n                            logger.info('Drain progress: %d', num_results)\n\n                        if num_results % 100000 == 0:\n                            # Risky, but need to do this since WAL\n                            # performance is low on large transactions\n                            logger.info(\"Checkpoint. (Don't delete stray files if program crashes!)\")\n                            work_file.flush()\n                            session.commit()\n\n                        if self.max_items and num_results >= self.max_items:\n                            logger.info('Reached max items %d.', self.max_items)\n                            running = False\n                            break\n\n                    if self.settings['delete']:\n                        delete_query = delete(Result).where(\n                            Result.id == bindparam('id')\n                        )\n                        session.execute(\n                            delete_query,\n                            [{'id': result_id} for result_id in delete_ids]\n                        )", "func_src_after": "    def _drain_to_working_set(self, size=1000):\n        logger.info('Draining to working set %s', self.working_set_filename)\n\n        assert not os.path.exists(self.working_set_filename)\n\n        with new_session() as session:\n            query = session.query(Result)\n\n            if self.after:\n                query = query.filter(Result.datetime > self.after)\n\n            with gzip.open(self.working_set_filename, 'wb', compresslevel=1) as work_file:\n                last_id = -1\n                num_results = 0\n                running = True\n\n                while running:\n                    # Optimized for SQLite scrolling window\n                    rows = query.filter(Result.id > last_id).limit(size).all()\n\n                    if not rows:\n                        break\n\n                    delete_ids = []\n\n                    for result in rows:\n                        pickle.dump({\n                            'id': result.id,\n                            'project_id': result.project_id,\n                            'shortcode': result.shortcode,\n                            'url': result.url,\n                            'encoding': result.encoding,\n                            'datetime': result.datetime,\n                        }, work_file)\n\n                        num_results += 1\n                        self.items_count += 1\n\n                        delete_ids.append(result.id)\n\n                        if num_results % 10000 == 0:\n                            logger.info('Drain progress: %d', num_results)\n\n                        if num_results % 100000 == 0:\n                            # Risky, but need to do this since WAL\n                            # performance is low on large transactions\n                            logger.info(\"Checkpoint. (Don't delete stray files if program crashes!)\")\n                            work_file.flush()\n                            session.commit()\n\n                        if self.max_items and num_results >= self.max_items:\n                            logger.info('Reached max items %d.', self.max_items)\n                            running = False\n                            break\n\n                    if self.settings['delete']:\n                        delete_query = delete(Result).where(\n                            Result.id == bindparam('id')\n                        )\n                        session.execute(\n                            delete_query,\n                            [{'id': result_id} for result_id in delete_ids]\n                        )\n\n                pickle.dump('eof', work_file)", "line_changes": {"deleted": [{"line_no": 12, "char_start": 365, "char_end": 434, "line": "            with open(self.working_set_filename, 'wb') as work_file:\n"}, {"line_no": 27, "char_start": 839, "char_end": 902, "line": "                        line = base64.b64encode(pickle.dumps({\n"}, {"line_no": 34, "char_start": 1228, "char_end": 1256, "line": "                        }))\n"}, {"line_no": 35, "char_start": 1256, "char_end": 1302, "line": "                        work_file.write(line)\n"}, {"line_no": 36, "char_start": 1302, "char_end": 1349, "line": "                        work_file.write(b'\\n')\n"}], "added": [{"line_no": 12, "char_start": 365, "char_end": 456, "line": "            with gzip.open(self.working_set_filename, 'wb', compresslevel=1) as work_file:\n"}, {"line_no": 27, "char_start": 861, "char_end": 899, "line": "                        pickle.dump({\n"}, {"line_no": 34, "char_start": 1225, "char_end": 1263, "line": "                        }, work_file)\n"}]}, "char_changes": {"deleted": [{"char_start": 863, "char_end": 887, "chars": "line = base64.b64encode("}, {"char_start": 898, "char_end": 899, "chars": "s"}, {"char_start": 1253, "char_end": 1347, "chars": "))\n                        work_file.write(line)\n                        work_file.write(b'\\n'"}], "added": [{"char_start": 382, "char_end": 387, "chars": "gzip."}, {"char_start": 423, "char_end": 440, "chars": ", compresslevel=1"}, {"char_start": 1250, "char_end": 1261, "chars": ", work_file"}, {"char_start": 2534, "char_end": 2581, "chars": "\n\n                pickle.dump('eof', work_file)"}]}, "commit_link": "github.com/ArchiveTeam/terroroftinytown/commit/4614d62a1406ee88562486c24105f38aef48be41", "file_name": "export.py", "vul_type": "cwe-502", "commit_msg": "release: Compress the working set file\n\nInstead of base64-encoding it into lines, save and load each pickle\nsequentially which the pickle module supports which avoids unneeded\nbloat. The entire file stream is gzip compressed (level 1, fast) to\nreduce the disk space usage further.", "parent_commit": "f9f8bc584c714321328b3ec8979eeb4d78cff09b", "description": "Write a Python function to export a dataset to a file, with optional data filtering and deletion after export."}
{"func_name": "_create_vdisk", "func_src_before": "    def _create_vdisk(self, name, size, units, opts):\n        \"\"\"Create a new vdisk.\"\"\"\n\n        LOG.debug(_('enter: _create_vdisk: vdisk %s ') % name)\n\n        model_update = None\n        autoex = '-autoexpand' if opts['autoexpand'] else ''\n        easytier = '-easytier on' if opts['easytier'] else '-easytier off'\n\n        # Set space-efficient options\n        if opts['rsize'] == -1:\n            ssh_cmd_se_opt = ''\n        else:\n            ssh_cmd_se_opt = (\n                '-rsize %(rsize)d%% %(autoex)s -warning %(warn)d%%' %\n                {'rsize': opts['rsize'],\n                 'autoex': autoex,\n                 'warn': opts['warning']})\n            if opts['compression']:\n                ssh_cmd_se_opt = ssh_cmd_se_opt + ' -compressed'\n            else:\n                ssh_cmd_se_opt = ssh_cmd_se_opt + (\n                    ' -grainsize %d' % opts['grainsize'])\n\n        ssh_cmd = ('svctask mkvdisk -name %(name)s -mdiskgrp %(mdiskgrp)s '\n                   '-iogrp 0 -size %(size)s -unit '\n                   '%(unit)s %(easytier)s %(ssh_cmd_se_opt)s'\n                   % {'name': name,\n                   'mdiskgrp': self.configuration.storwize_svc_volpool_name,\n                   'size': size, 'unit': units, 'easytier': easytier,\n                   'ssh_cmd_se_opt': ssh_cmd_se_opt})\n        out, err = self._run_ssh(ssh_cmd)\n        self._assert_ssh_return(len(out.strip()), '_create_vdisk',\n                                ssh_cmd, out, err)\n\n        # Ensure that the output is as expected\n        match_obj = re.search('Virtual Disk, id \\[([0-9]+)\\], '\n                              'successfully created', out)\n        # Make sure we got a \"successfully created\" message with vdisk id\n        self._driver_assert(\n            match_obj is not None,\n            _('_create_vdisk %(name)s - did not find '\n              'success message in CLI output.\\n '\n              'stdout: %(out)s\\n stderr: %(err)s')\n            % {'name': name, 'out': str(out), 'err': str(err)})\n\n        LOG.debug(_('leave: _create_vdisk: volume %s ') % name)", "func_src_after": "    def _create_vdisk(self, name, size, units, opts):\n        \"\"\"Create a new vdisk.\"\"\"\n\n        LOG.debug(_('enter: _create_vdisk: vdisk %s ') % name)\n\n        model_update = None\n        easytier = 'on' if opts['easytier'] else 'off'\n\n        # Set space-efficient options\n        if opts['rsize'] == -1:\n            ssh_cmd_se_opt = []\n        else:\n            ssh_cmd_se_opt = ['-rsize', '%s%%' % str(opts['rsize']),\n                              '-autoexpand', '-warning',\n                              '%s%%' % str(opts['warning'])]\n            if not opts['autoexpand']:\n                ssh_cmd_se_opt.remove('-autoexpand')\n\n            if opts['compression']:\n                ssh_cmd_se_opt.append('-compressed')\n            else:\n                ssh_cmd_se_opt.extend(['-grainsize', str(opts['grainsize'])])\n\n        ssh_cmd = ['svctask', 'mkvdisk', '-name', name, '-mdiskgrp',\n                   self.configuration.storwize_svc_volpool_name,\n                   '-iogrp', '0', '-size', size, '-unit',\n                   units, '-easytier', easytier] + ssh_cmd_se_opt\n        out, err = self._run_ssh(ssh_cmd)\n        self._assert_ssh_return(len(out.strip()), '_create_vdisk',\n                                ssh_cmd, out, err)\n\n        # Ensure that the output is as expected\n        match_obj = re.search('Virtual Disk, id \\[([0-9]+)\\], '\n                              'successfully created', out)\n        # Make sure we got a \"successfully created\" message with vdisk id\n        self._driver_assert(\n            match_obj is not None,\n            _('_create_vdisk %(name)s - did not find '\n              'success message in CLI output.\\n '\n              'stdout: %(out)s\\n stderr: %(err)s')\n            % {'name': name, 'out': str(out), 'err': str(err)})\n\n        LOG.debug(_('leave: _create_vdisk: volume %s ') % name)", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to create a virtual disk with options for size, auto-expansion, easy tier, and compression."}
{"func_name": "hash_accept", "func_src_before": "static int hash_accept(struct socket *sock, struct socket *newsock, int flags)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct alg_sock *ask = alg_sk(sk);\n\tstruct hash_ctx *ctx = ask->private;\n\tstruct ahash_request *req = &ctx->req;\n\tchar state[crypto_ahash_statesize(crypto_ahash_reqtfm(req))];\n\tstruct sock *sk2;\n\tstruct alg_sock *ask2;\n\tstruct hash_ctx *ctx2;\n\tint err;\n\n\terr = crypto_ahash_export(req, state);\n\tif (err)\n\t\treturn err;\n\n\terr = af_alg_accept(ask->parent, newsock);\n\tif (err)\n\t\treturn err;\n\n\tsk2 = newsock->sk;\n\task2 = alg_sk(sk2);\n\tctx2 = ask2->private;\n\tctx2->more = 1;\n\n\terr = crypto_ahash_import(&ctx2->req, state);\n\tif (err) {\n\t\tsock_orphan(sk2);\n\t\tsock_put(sk2);\n\t}\n\n\treturn err;\n}", "func_src_after": "static int hash_accept(struct socket *sock, struct socket *newsock, int flags)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct alg_sock *ask = alg_sk(sk);\n\tstruct hash_ctx *ctx = ask->private;\n\tstruct ahash_request *req = &ctx->req;\n\tchar state[crypto_ahash_statesize(crypto_ahash_reqtfm(req))];\n\tstruct sock *sk2;\n\tstruct alg_sock *ask2;\n\tstruct hash_ctx *ctx2;\n\tbool more;\n\tint err;\n\n\tlock_sock(sk);\n\tmore = ctx->more;\n\terr = more ? crypto_ahash_export(req, state) : 0;\n\trelease_sock(sk);\n\n\tif (err)\n\t\treturn err;\n\n\terr = af_alg_accept(ask->parent, newsock);\n\tif (err)\n\t\treturn err;\n\n\tsk2 = newsock->sk;\n\task2 = alg_sk(sk2);\n\tctx2 = ask2->private;\n\tctx2->more = more;\n\n\tif (!more)\n\t\treturn err;\n\n\terr = crypto_ahash_import(&ctx2->req, state);\n\tif (err) {\n\t\tsock_orphan(sk2);\n\t\tsock_put(sk2);\n\t}\n\n\treturn err;\n}", "commit_link": "github.com/torvalds/linux/commit/4afa5f9617927453ac04b24b584f6c718dfb4f45", "file_name": "crypto/algif_hash.c", "vul_type": "cwe-476", "description": "Write a C function named `hash_accept` that handles the acceptance of a new hash algorithm socket connection and the transfer of its state."}
{"func_name": "plot", "func_src_before": "    def plot(self, log_files, sort='time', limit=10, nfl_filter='',\n             metric_selected='cc', plot_type='bar'):\n        if not PLOTLIB_INSTALLED:\n            raise PLOTLIBNotInstalled(_('python-matplotlib not installed.'))\n        if len(log_files) == 0:\n            raise NotFoundException(_('no log file found'))\n        try:\n            stats = Stats2(*log_files)\n            stats.sort_stats(sort)\n            stats_dict = stats.stats\n            __, func_list = stats.get_print_list([nfl_filter, limit])\n            nfls = []\n            performance = []\n            names = {'nc': 'Total Call Count', 'cc': 'Primitive Call Count',\n                     'tt': 'Total Time', 'ct': 'Cumulative Time'}\n            for func in func_list:\n                cc, nc, tt, ct, __ = stats_dict[func]\n                metric = {'cc': cc, 'nc': nc, 'tt': tt, 'ct': ct}\n                nfls.append(func[2])\n                performance.append(metric[metric_selected])\n            y_pos = range(len(nfls))\n            error = [random.random() for __ in y_pos]\n            plt.clf()\n            if plot_type == 'pie':\n                plt.pie(x=performance, explode=None, labels=nfls,\n                        autopct='%1.1f%%')\n            else:\n                plt.barh(y_pos, performance, xerr=error, align='center',\n                         alpha=0.4)\n                plt.yticks(y_pos, nfls)\n                plt.xlabel(names[metric_selected])\n            plt.title('Profile Statistics (by %s)' % names[metric_selected])\n            #plt.gcf().tight_layout(pad=1.2)\n            profile_img = tempfile.mktemp('.png', 'plot')\n            plt.savefig(profile_img, dpi=300)\n            data = open(profile_img).read()\n            os.remove(profile_img)\n            return data, [('content-type', 'image/jpg')]\n        except Exception as ex:\n            raise ProfileException(_('plotting results failed due to %s') % ex)", "func_src_after": "    def plot(self, log_files, sort='time', limit=10, nfl_filter='',\n             metric_selected='cc', plot_type='bar'):\n        if not PLOTLIB_INSTALLED:\n            raise PLOTLIBNotInstalled(_('python-matplotlib not installed.'))\n        if len(log_files) == 0:\n            raise NotFoundException(_('no log file found'))\n        try:\n            stats = Stats2(*log_files)\n            stats.sort_stats(sort)\n            stats_dict = stats.stats\n            __, func_list = stats.get_print_list([nfl_filter, limit])\n            nfls = []\n            performance = []\n            names = {'nc': 'Total Call Count', 'cc': 'Primitive Call Count',\n                     'tt': 'Total Time', 'ct': 'Cumulative Time'}\n            for func in func_list:\n                cc, nc, tt, ct, __ = stats_dict[func]\n                metric = {'cc': cc, 'nc': nc, 'tt': tt, 'ct': ct}\n                nfls.append(func[2])\n                performance.append(metric[metric_selected])\n            y_pos = range(len(nfls))\n            error = [random.random() for __ in y_pos]\n            plt.clf()\n            if plot_type == 'pie':\n                plt.pie(x=performance, explode=None, labels=nfls,\n                        autopct='%1.1f%%')\n            else:\n                plt.barh(y_pos, performance, xerr=error, align='center',\n                         alpha=0.4)\n                plt.yticks(y_pos, nfls)\n                plt.xlabel(names[metric_selected])\n            plt.title('Profile Statistics (by %s)' % names[metric_selected])\n            #plt.gcf().tight_layout(pad=1.2)\n            profile_img = tempfile.TemporaryFile()\n            plt.savefig(profile_img, format='png', dpi=300)\n            profile_img.seek(0)\n            data = profile_img.read()\n            os.close(profile_img)\n            return data, [('content-type', 'image/jpg')]\n        except Exception as ex:\n            raise ProfileException(_('plotting results failed due to %s') % ex)", "line_changes": {"deleted": [{"line_no": 34, "char_start": 1561, "char_end": 1619, "line": "            profile_img = tempfile.mktemp('.png', 'plot')\n"}, {"line_no": 35, "char_start": 1619, "char_end": 1665, "line": "            plt.savefig(profile_img, dpi=300)\n"}, {"line_no": 36, "char_start": 1665, "char_end": 1709, "line": "            data = open(profile_img).read()\n"}, {"line_no": 37, "char_start": 1709, "char_end": 1744, "line": "            os.remove(profile_img)\n"}], "added": [{"line_no": 34, "char_start": 1561, "char_end": 1612, "line": "            profile_img = tempfile.TemporaryFile()\n"}, {"line_no": 35, "char_start": 1612, "char_end": 1672, "line": "            plt.savefig(profile_img, format='png', dpi=300)\n"}, {"line_no": 36, "char_start": 1672, "char_end": 1704, "line": "            profile_img.seek(0)\n"}, {"line_no": 37, "char_start": 1704, "char_end": 1742, "line": "            data = profile_img.read()\n"}, {"line_no": 38, "char_start": 1742, "char_end": 1776, "line": "            os.close(profile_img)\n"}]}, "char_changes": {"deleted": [{"char_start": 1596, "char_end": 1617, "chars": "mktemp('.png', 'plot'"}, {"char_start": 1684, "char_end": 1689, "chars": "open("}, {"char_start": 1700, "char_end": 1701, "chars": ")"}, {"char_start": 1724, "char_end": 1729, "chars": "remov"}], "added": [{"char_start": 1596, "char_end": 1610, "chars": "TemporaryFile("}, {"char_start": 1648, "char_end": 1662, "chars": " format='png',"}, {"char_start": 1672, "char_end": 1704, "chars": "            profile_img.seek(0)\n"}, {"char_start": 1757, "char_end": 1761, "chars": "clos"}]}, "commit_link": "github.com/scality/ScalitySproxydSwift/commit/6978275cdb04bb08aaf142d401b52a46527dac4c", "file_name": "html_viewer.py", "vul_type": "cwe-377", "commit_msg": "Avoid usage of insecure mktemp() function\n\nThis patch eliminates the use of the deprecated and insecure\ntempfile.mktemp() function.  It has been replaced with secure\nalternatives where temporary files are actually required.\n\nChange-Id: I0a13d6d44cd1abc4b66fa33f39eea407617a01d5\nSecurityImpact\nCloses-bug: #1348869", "description": "In Python, write a function to plot performance statistics from log files using matplotlib, with options for sorting, filtering, and different plot types."}
{"func_name": "big_key_init", "func_src_before": "static int __init big_key_init(void)\n{\n\treturn register_key_type(&key_type_big_key);\n}", "func_src_after": "static int __init big_key_init(void)\n{\n\tstruct crypto_skcipher *cipher;\n\tstruct crypto_rng *rng;\n\tint ret;\n\n\trng = crypto_alloc_rng(big_key_rng_name, 0, 0);\n\tif (IS_ERR(rng)) {\n\t\tpr_err(\"Can't alloc rng: %ld\\n\", PTR_ERR(rng));\n\t\treturn PTR_ERR(rng);\n\t}\n\n\tbig_key_rng = rng;\n\n\t/* seed RNG */\n\tret = crypto_rng_reset(rng, NULL, crypto_rng_seedsize(rng));\n\tif (ret) {\n\t\tpr_err(\"Can't reset rng: %d\\n\", ret);\n\t\tgoto error_rng;\n\t}\n\n\t/* init block cipher */\n\tcipher = crypto_alloc_skcipher(big_key_alg_name, 0, CRYPTO_ALG_ASYNC);\n\tif (IS_ERR(cipher)) {\n\t\tret = PTR_ERR(cipher);\n\t\tpr_err(\"Can't alloc crypto: %d\\n\", ret);\n\t\tgoto error_rng;\n\t}\n\n\tbig_key_skcipher = cipher;\n\n\tret = register_key_type(&key_type_big_key);\n\tif (ret < 0) {\n\t\tpr_err(\"Can't register type: %d\\n\", ret);\n\t\tgoto error_cipher;\n\t}\n\n\treturn 0;\n\nerror_cipher:\n\tcrypto_free_skcipher(big_key_skcipher);\nerror_rng:\n\tcrypto_free_rng(big_key_rng);\n\treturn ret;\n}", "commit_link": "github.com/torvalds/linux/commit/7df3e59c3d1df4f87fe874c7956ef7a3d2f4d5fb", "file_name": "security/keys/big_key.c", "vul_type": "cwe-476", "description": "Write a C function for Linux kernel module initialization that registers a new key type and optionally sets up cryptographic components."}
{"func_name": "quiz", "func_src_before": "@app.route('/quiz')\ndef quiz():\n\n    varga = request.args.get('varga')\n\n    try:\n        rows =[]\n\n        with sql.connect('amara.db') as con:\n            con.row_factory = sql.Row\n            cur = con.cursor()\n            cur.execute(\"select * from pada inner join mula on pada.sloka_line = mula.sloka_line where pada.varga = '%s' order by random() limit 1;\" % varga)\n            rows = cur.fetchall();\n\n            artha = rows[0][\"artha\"];\n            cur.execute(\"select pada from pada where varga = '%s' and artha = '%s' order by id\" % (varga, artha));\n            paryaya = cur.fetchall();\n\n            return render_template('quiz.html', rows=rows, paryaya=paryaya, varga=varga)\n    finally:\n        con.close()", "func_src_after": "@app.route('/quiz')\ndef quiz():\n\n    varga = request.args.get('varga')\n\n    try:\n        rows =[]\n\n        with sql.connect('amara.db') as con:\n            con.row_factory = sql.Row\n            cur = con.cursor()\n            cur.execute(\"select * from pada inner join mula on pada.sloka_line = mula.sloka_line where pada.varga = ? order by random() limit 1;\", [varga])\n            rows = cur.fetchall();\n\n            artha = rows[0][\"artha\"];\n            cur.execute(\"select pada from pada where varga = ? and artha = ? order by id\", [varga, artha]);\n            paryaya = cur.fetchall();\n\n            return render_template('quiz.html', rows=rows, paryaya=paryaya, varga=varga)\n    finally:\n        con.close()", "commit_link": "github.com/aupasana/amara-quiz/commit/6ceb5dc8ec38b4a3f1399e578ab970f7e3354922", "file_name": "docker/app.py", "vul_type": "cwe-089", "description": "Create a Python Flask endpoint that fetches a random quiz question and its multiple choices from a database based on a query parameter."}
{"func_name": "_create_3par_fibrechan_host", "func_src_before": "    def _create_3par_fibrechan_host(self, hostname, wwn, domain, persona_id):\n        \"\"\"Create a 3PAR host.\n\n        Create a 3PAR host, if there is already a host on the 3par using\n        the same wwn but with a different hostname, return the hostname\n        used by 3PAR.\n        \"\"\"\n        out = self.common._cli_run('createhost -persona %s -domain %s %s %s'\n                                   % (persona_id, domain,\n                                      hostname, \" \".join(wwn)), None)\n        if out and len(out) > 1:\n            return self.common.parse_create_host_error(hostname, out)\n\n        return hostname", "func_src_after": "    def _create_3par_fibrechan_host(self, hostname, wwns, domain, persona_id):\n        \"\"\"Create a 3PAR host.\n\n        Create a 3PAR host, if there is already a host on the 3par using\n        the same wwn but with a different hostname, return the hostname\n        used by 3PAR.\n        \"\"\"\n        command = ['createhost', '-persona', persona_id, '-domain', domain,\n                   hostname]\n        for wwn in wwns:\n            command.append(wwn)\n\n        out = self.common._cli_run(command)\n        if out and len(out) > 1:\n            return self.common.parse_create_host_error(hostname, out)\n\n        return hostname", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_fc.py", "vul_type": "cwe-078", "description": "Write a Python function to create a 3PAR Fibre Channel host, handling potential WWN conflicts."}
{"func_name": "show_user_profile", "func_src_before": "@app.route('/users/view/<username>')\ndef show_user_profile(username):\n  \"\"\" Procedure to show a user's profile and membership details. \"\"\"\n  cols = [[\"username\"], [\"fname\", \"lname\"], [\"nickname\"], [\"bday\"], \\\n          [\"email\"], [\"email2\"], [\"status\"], [\"matriculate_year\"], \\\n          [\"grad_year\"], [\"msc\"], [\"phone\"], [\"building\", \"room_num\"], \\\n          [\"membership\"], [\"major\"], [\"uid\"], [\"isabroad\"]]\n  display = [\"Username\", \"Name\", \"Nickname\", \"Birthday\", \"Primary Email\", \\\n             \"Secondary Email\", \"Status\", \"Matriculation Year\", \\\n             \"Graduation Year\", \"MSC\", \"Phone Number\", \"Residence\", \\\n             \"Membership\", \"Major\", \"UID\", \"Is Abroad\"]\n  d_dict = OrderedDict(zip(display, cols))\n  #d_dict defines the order and mapping of displayed attributes to sql columns\n  query = text(\"SELECT * FROM users Natural JOIN members where username=:u\")\n  result = connection.execute(query, u=str(username))\n  if result.returns_rows and result.rowcount != 0:\n    result_cols = result.keys()\n    r = result.first()\n    q_dict = dict(zip(result_cols, r)) #q_dict maps sql columns to values\n    if not q_dict['usenickname']:\n      d_dict.pop('Nickname')\n    return render_template('view_user.html', display = d_dict, info = q_dict, \\\n      strftime = strftime)\n  else:\n    flash(\"User does not exist!\")\n    return redirect(url_for('home'))", "func_src_after": "@app.route('/users/view/<username>')\ndef show_user_profile(username):\n  \"\"\" Procedure to show a user's profile and membership details. \"\"\"\n  cols = [[\"username\"], [\"fname\", \"lname\"], [\"nickname\"], [\"bday\"], \\\n          [\"email\"], [\"email2\"], [\"status\"], [\"matriculate_year\"], \\\n          [\"grad_year\"], [\"msc\"], [\"phone\"], [\"building\", \"room_num\"], \\\n          [\"membership\"], [\"major\"], [\"uid\"], [\"isabroad\"]]\n  display = [\"Username\", \"Name\", \"Nickname\", \"Birthday\", \"Primary Email\", \\\n             \"Secondary Email\", \"Status\", \"Matriculation Year\", \\\n             \"Graduation Year\", \"MSC\", \"Phone Number\", \"Residence\", \\\n             \"Membership\", \"Major\", \"UID\", \"Is Abroad\"]\n  d_dict = OrderedDict(zip(display, cols))\n  #d_dict defines the order and mapping of displayed attributes to sql columns\n  query = text(\"SELECT * FROM users NATURAL JOIN members WHERE username=:u\")\n  result = connection.execute(query, u=str(username))\n  if result.returns_rows and result.rowcount != 0:\n    result_cols = result.keys()\n    r = result.first()\n    q_dict = dict(zip(result_cols, r)) #q_dict maps sql columns to values\n    if not q_dict['usenickname']:\n      d_dict.pop('Nickname')\n    return render_template('view_user.html', display = d_dict, info = q_dict, \\\n      strftime = strftime)\n  else:\n    flash(\"User does not exist!\")\n    return redirect(url_for('home'))", "line_changes": {"deleted": [{"line_no": 14, "char_start": 801, "char_end": 878, "line": "  query = text(\"SELECT * FROM users Natural JOIN members where username=:u\")\n"}], "added": [{"line_no": 14, "char_start": 801, "char_end": 878, "line": "  query = text(\"SELECT * FROM users NATURAL JOIN members WHERE username=:u\")\n"}]}, "char_changes": {"deleted": [{"char_start": 838, "char_end": 844, "chars": "atural"}, {"char_start": 858, "char_end": 863, "chars": "where"}], "added": [{"char_start": 838, "char_end": 844, "chars": "ATURAL"}, {"char_start": 858, "char_end": 863, "chars": "WHERE"}]}, "commit_link": "github.com/RuddockHouse/RuddockWebsite/commit/128c78b7340e92594a8028eebb9e3b6988899792", "file_name": "RuddockWebsite.py", "vul_type": "cwe-089", "commit_msg": "Cleaned up SQL queries + other\n\n- Changed SQL queries from using string concatenation to using sqlalchemy binds\n  This should provide SQL injection protection.\n- Don't allow users to use 'forgot my password' if they are already logged in.", "description": "Write a Python Flask function to display a user's profile by their username."}
{"func_name": "SMB2_write", "func_src_before": "SMB2_write(const unsigned int xid, struct cifs_io_parms *io_parms,\n\t   unsigned int *nbytes, struct kvec *iov, int n_vec)\n{\n\tstruct smb_rqst rqst;\n\tint rc = 0;\n\tstruct smb2_write_req *req = NULL;\n\tstruct smb2_write_rsp *rsp = NULL;\n\tint resp_buftype;\n\tstruct kvec rsp_iov;\n\tint flags = 0;\n\tunsigned int total_len;\n\n\t*nbytes = 0;\n\n\tif (n_vec < 1)\n\t\treturn rc;\n\n\trc = smb2_plain_req_init(SMB2_WRITE, io_parms->tcon, (void **) &req,\n\t\t\t     &total_len);\n\tif (rc)\n\t\treturn rc;\n\n\tif (io_parms->tcon->ses->server == NULL)\n\t\treturn -ECONNABORTED;\n\n\tif (smb3_encryption_required(io_parms->tcon))\n\t\tflags |= CIFS_TRANSFORM_REQ;\n\n\treq->sync_hdr.ProcessId = cpu_to_le32(io_parms->pid);\n\n\treq->PersistentFileId = io_parms->persistent_fid;\n\treq->VolatileFileId = io_parms->volatile_fid;\n\treq->WriteChannelInfoOffset = 0;\n\treq->WriteChannelInfoLength = 0;\n\treq->Channel = 0;\n\treq->Length = cpu_to_le32(io_parms->length);\n\treq->Offset = cpu_to_le64(io_parms->offset);\n\treq->DataOffset = cpu_to_le16(\n\t\t\t\toffsetof(struct smb2_write_req, Buffer));\n\treq->RemainingBytes = 0;\n\n\ttrace_smb3_write_enter(xid, io_parms->persistent_fid,\n\t\tio_parms->tcon->tid, io_parms->tcon->ses->Suid,\n\t\tio_parms->offset, io_parms->length);\n\n\tiov[0].iov_base = (char *)req;\n\t/* 1 for Buffer */\n\tiov[0].iov_len = total_len - 1;\n\n\tmemset(&rqst, 0, sizeof(struct smb_rqst));\n\trqst.rq_iov = iov;\n\trqst.rq_nvec = n_vec + 1;\n\n\trc = cifs_send_recv(xid, io_parms->tcon->ses, &rqst,\n\t\t\t    &resp_buftype, flags, &rsp_iov);\n\tcifs_small_buf_release(req);\n\trsp = (struct smb2_write_rsp *)rsp_iov.iov_base;\n\n\tif (rc) {\n\t\ttrace_smb3_write_err(xid, req->PersistentFileId,\n\t\t\t\t     io_parms->tcon->tid,\n\t\t\t\t     io_parms->tcon->ses->Suid,\n\t\t\t\t     io_parms->offset, io_parms->length, rc);\n\t\tcifs_stats_fail_inc(io_parms->tcon, SMB2_WRITE_HE);\n\t\tcifs_dbg(VFS, \"Send error in write = %d\\n\", rc);\n\t} else {\n\t\t*nbytes = le32_to_cpu(rsp->DataLength);\n\t\ttrace_smb3_write_done(xid, req->PersistentFileId,\n\t\t\t\t     io_parms->tcon->tid,\n\t\t\t\t     io_parms->tcon->ses->Suid,\n\t\t\t\t     io_parms->offset, *nbytes);\n\t}\n\n\tfree_rsp_buf(resp_buftype, rsp);\n\treturn rc;\n}", "func_src_after": "SMB2_write(const unsigned int xid, struct cifs_io_parms *io_parms,\n\t   unsigned int *nbytes, struct kvec *iov, int n_vec)\n{\n\tstruct smb_rqst rqst;\n\tint rc = 0;\n\tstruct smb2_write_req *req = NULL;\n\tstruct smb2_write_rsp *rsp = NULL;\n\tint resp_buftype;\n\tstruct kvec rsp_iov;\n\tint flags = 0;\n\tunsigned int total_len;\n\n\t*nbytes = 0;\n\n\tif (n_vec < 1)\n\t\treturn rc;\n\n\trc = smb2_plain_req_init(SMB2_WRITE, io_parms->tcon, (void **) &req,\n\t\t\t     &total_len);\n\tif (rc)\n\t\treturn rc;\n\n\tif (io_parms->tcon->ses->server == NULL)\n\t\treturn -ECONNABORTED;\n\n\tif (smb3_encryption_required(io_parms->tcon))\n\t\tflags |= CIFS_TRANSFORM_REQ;\n\n\treq->sync_hdr.ProcessId = cpu_to_le32(io_parms->pid);\n\n\treq->PersistentFileId = io_parms->persistent_fid;\n\treq->VolatileFileId = io_parms->volatile_fid;\n\treq->WriteChannelInfoOffset = 0;\n\treq->WriteChannelInfoLength = 0;\n\treq->Channel = 0;\n\treq->Length = cpu_to_le32(io_parms->length);\n\treq->Offset = cpu_to_le64(io_parms->offset);\n\treq->DataOffset = cpu_to_le16(\n\t\t\t\toffsetof(struct smb2_write_req, Buffer));\n\treq->RemainingBytes = 0;\n\n\ttrace_smb3_write_enter(xid, io_parms->persistent_fid,\n\t\tio_parms->tcon->tid, io_parms->tcon->ses->Suid,\n\t\tio_parms->offset, io_parms->length);\n\n\tiov[0].iov_base = (char *)req;\n\t/* 1 for Buffer */\n\tiov[0].iov_len = total_len - 1;\n\n\tmemset(&rqst, 0, sizeof(struct smb_rqst));\n\trqst.rq_iov = iov;\n\trqst.rq_nvec = n_vec + 1;\n\n\trc = cifs_send_recv(xid, io_parms->tcon->ses, &rqst,\n\t\t\t    &resp_buftype, flags, &rsp_iov);\n\trsp = (struct smb2_write_rsp *)rsp_iov.iov_base;\n\n\tif (rc) {\n\t\ttrace_smb3_write_err(xid, req->PersistentFileId,\n\t\t\t\t     io_parms->tcon->tid,\n\t\t\t\t     io_parms->tcon->ses->Suid,\n\t\t\t\t     io_parms->offset, io_parms->length, rc);\n\t\tcifs_stats_fail_inc(io_parms->tcon, SMB2_WRITE_HE);\n\t\tcifs_dbg(VFS, \"Send error in write = %d\\n\", rc);\n\t} else {\n\t\t*nbytes = le32_to_cpu(rsp->DataLength);\n\t\ttrace_smb3_write_done(xid, req->PersistentFileId,\n\t\t\t\t     io_parms->tcon->tid,\n\t\t\t\t     io_parms->tcon->ses->Suid,\n\t\t\t\t     io_parms->offset, *nbytes);\n\t}\n\n\tcifs_small_buf_release(req);\n\tfree_rsp_buf(resp_buftype, rsp);\n\treturn rc;\n}", "commit_link": "github.com/torvalds/linux/commit/6a3eb3360667170988f8a6477f6686242061488a", "file_name": "fs/cifs/smb2pdu.c", "vul_type": "cwe-416", "description": "In C, write a function to perform an SMB2 write operation with error handling and encryption check."}
{"func_name": "ParseRouteDistinguisher", "func_src_before": "func ParseRouteDistinguisher(rd string) (RouteDistinguisherInterface, error) {\n\telems, err := parseRdAndRt(rd)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tassigned, _ := strconv.Atoi(elems[10])\n\tip := net.ParseIP(elems[1])\n\tswitch {\n\tcase ip.To4() != nil:\n\t\treturn NewRouteDistinguisherIPAddressAS(elems[1], uint16(assigned)), nil\n\tcase elems[6] == \"\" && elems[7] == \"\":\n\t\tasn, _ := strconv.Atoi(elems[8])\n\t\treturn NewRouteDistinguisherTwoOctetAS(uint16(asn), uint32(assigned)), nil\n\tdefault:\n\t\tfst, _ := strconv.Atoi(elems[7])\n\t\tsnd, _ := strconv.Atoi(elems[8])\n\t\tasn := fst<<16 | snd\n\t\treturn NewRouteDistinguisherFourOctetAS(uint32(asn), uint16(assigned)), nil\n\t}\n}", "func_src_after": "func ParseRouteDistinguisher(rd string) (RouteDistinguisherInterface, error) {\n\telems, err := parseRdAndRt(rd)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tassigned, _ := strconv.ParseUint(elems[10], 10, 32)\n\tip := net.ParseIP(elems[1])\n\tswitch {\n\tcase ip.To4() != nil:\n\t\treturn NewRouteDistinguisherIPAddressAS(elems[1], uint16(assigned)), nil\n\tcase elems[6] == \"\" && elems[7] == \"\":\n\t\tasn, _ := strconv.ParseUint(elems[8], 10, 16)\n\t\treturn NewRouteDistinguisherTwoOctetAS(uint16(asn), uint32(assigned)), nil\n\tdefault:\n\t\tfst, _ := strconv.ParseUint(elems[7], 10, 16)\n\t\tsnd, _ := strconv.ParseUint(elems[8], 10, 16)\n\t\tasn := fst<<16 | snd\n\t\treturn NewRouteDistinguisherFourOctetAS(uint32(asn), uint16(assigned)), nil\n\t}\n}", "line_changes": {"deleted": [{"line_no": 6, "char_start": 149, "char_end": 189, "line": "\tassigned, _ := strconv.Atoi(elems[10])\n"}, {"line_no": 12, "char_start": 366, "char_end": 401, "line": "\t\tasn, _ := strconv.Atoi(elems[8])\n"}, {"line_no": 15, "char_start": 488, "char_end": 523, "line": "\t\tfst, _ := strconv.Atoi(elems[7])\n"}, {"line_no": 16, "char_start": 523, "char_end": 558, "line": "\t\tsnd, _ := strconv.Atoi(elems[8])\n"}], "added": [{"line_no": 6, "char_start": 149, "char_end": 202, "line": "\tassigned, _ := strconv.ParseUint(elems[10], 10, 32)\n"}, {"line_no": 12, "char_start": 379, "char_end": 427, "line": "\t\tasn, _ := strconv.ParseUint(elems[8], 10, 16)\n"}, {"line_no": 15, "char_start": 514, "char_end": 562, "line": "\t\tfst, _ := strconv.ParseUint(elems[7], 10, 16)\n"}, {"line_no": 16, "char_start": 562, "char_end": 610, "line": "\t\tsnd, _ := strconv.ParseUint(elems[8], 10, 16)\n"}]}, "char_changes": {"deleted": [{"char_start": 173, "char_end": 177, "chars": "Atoi"}, {"char_start": 386, "char_end": 390, "chars": "Atoi"}, {"char_start": 508, "char_end": 512, "chars": "Atoi"}, {"char_start": 543, "char_end": 547, "chars": "Atoi"}], "added": [{"char_start": 173, "char_end": 182, "chars": "ParseUint"}, {"char_start": 192, "char_end": 200, "chars": ", 10, 32"}, {"char_start": 399, "char_end": 408, "chars": "ParseUint"}, {"char_start": 417, "char_end": 425, "chars": ", 10, 16"}, {"char_start": 534, "char_end": 543, "chars": "ParseUint"}, {"char_start": 552, "char_end": 560, "chars": ", 10, 16"}, {"char_start": 582, "char_end": 591, "chars": "ParseUint"}, {"char_start": 600, "char_end": 608, "chars": ", 10, 16"}]}, "commit_link": "github.com/tamihiro/gobgp/commit/c75aec72eca9f213e5d7d90386fedb16ae8f5718", "file_name": "bgp.go", "vul_type": "cwe-681", "commit_msg": "packet/bgp: use strconv.ParseUint instead of strconv.Atoi()\n\nAtoi() returns a signed int. On a 32-bit platform, this is not big\nenough to fit an unsigned 32-bit int. Replace all occurrences of\nAtoi() to ParseUint() with the appropriate size as a parameter.\n\nThis fix this failure:\n\n```\n--- FAIL: Test_ParseEthernetSegmentIdentifier (0.00s)\n        Error Trace:    bgp_test.go:1181\n        Error:          Expected nil, but got: &errors.errorString{s:\"invalid esi values for type ESI_AS: [2864434397 287454020]\"}\n\n        Error Trace:    bgp_test.go:1182\n        Error:          Not equal: bgp.EthernetSegmentIdentifier{Type:0x5, Value:[]uint8{0xaa, 0xbb, 0xcc, 0xdd, 0x11, 0x22, 0x33, 0x44, 0x0}} (expected)\n                                != bgp.EthernetSegmentIdentifier{Type:0x5, Value:[]uint8{0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0}} (actual)\n\n                        Diff:\n                        --- Expected\n                        +++ Actual\n                        @@ -1,2 +1,2 @@\n                        -(bgp.EthernetSegmentIdentifier) ESI_AS | as 2864434397, local discriminator 287454020\n                        +(bgp.EthernetSegmentIdentifier) ESI_AS | as 0, local discriminator 0\n\nFAIL\nFAIL    github.com/osrg/gobgp/packet/bgp        0.003s\n```", "parent_commit": "51f69fe247b260fb6cb3b7f3308aa28fa430def0", "description": "Write a Go function to parse a string into a Route Distinguisher object, handling different formats based on IP or ASN components."}
{"func_name": "yaffsfs_istat", "func_src_before": "    yaffsfs_istat(TSK_FS_INFO *fs, TSK_FS_ISTAT_FLAG_ENUM flags, FILE * hFile, TSK_INUM_T inum,\n    TSK_DADDR_T numblock, int32_t sec_skew)\n{\n    TSK_FS_META *fs_meta;\n    TSK_FS_FILE *fs_file;\n    YAFFSFS_INFO *yfs = (YAFFSFS_INFO *)fs;\n    char ls[12];\n    YAFFSFS_PRINT_ADDR print;\n    char timeBuf[32];\n    YaffsCacheObject * obj = NULL;\n    YaffsCacheVersion * version = NULL;\n    YaffsHeader * header = NULL;\n\n    yaffscache_version_find_by_inode(yfs, inum, &version, &obj);\n\n    if ((fs_file = tsk_fs_file_open_meta(fs, NULL, inum)) == NULL) {\n        return 1;\n    }\n    fs_meta = fs_file->meta;\n\n    tsk_fprintf(hFile, \"inode: %\" PRIuINUM \"\\n\", inum);\n    tsk_fprintf(hFile, \"%sAllocated\\n\",\n        (fs_meta->flags & TSK_FS_META_FLAG_ALLOC) ? \"\" : \"Not \");\n\n    if (fs_meta->link)\n        tsk_fprintf(hFile, \"symbolic link to: %s\\n\", fs_meta->link);\n\n    tsk_fprintf(hFile, \"uid / gid: %\" PRIuUID \" / %\" PRIuGID \"\\n\",\n        fs_meta->uid, fs_meta->gid);\n\n    tsk_fs_meta_make_ls(fs_meta, ls, sizeof(ls));\n    tsk_fprintf(hFile, \"mode: %s\\n\", ls);\n\n    tsk_fprintf(hFile, \"size: %\" PRIdOFF \"\\n\", fs_meta->size);\n    tsk_fprintf(hFile, \"num of links: %d\\n\", fs_meta->nlink);\n\n    if(version != NULL){\n        yaffsfs_read_header(yfs, &header, version->ycv_header_chunk->ycc_offset);\n        if(header != NULL){\n            tsk_fprintf(hFile, \"Name: %s\\n\", header->name);\n        }\n    }\n\n    if (sec_skew != 0) {\n        tsk_fprintf(hFile, \"\\nAdjusted Inode Times:\\n\");\n        fs_meta->mtime -= sec_skew;\n        fs_meta->atime -= sec_skew;\n        fs_meta->ctime -= sec_skew;\n\n        tsk_fprintf(hFile, \"Accessed:\\t%s\\n\",\n            tsk_fs_time_to_str(fs_meta->atime, timeBuf));\n        tsk_fprintf(hFile, \"File Modified:\\t%s\\n\",\n            tsk_fs_time_to_str(fs_meta->mtime, timeBuf));\n        tsk_fprintf(hFile, \"Inode Modified:\\t%s\\n\",\n            tsk_fs_time_to_str(fs_meta->ctime, timeBuf));\n\n        fs_meta->mtime += sec_skew;\n        fs_meta->atime += sec_skew;\n        fs_meta->ctime += sec_skew;\n\n        tsk_fprintf(hFile, \"\\nOriginal Inode Times:\\n\");\n    }\n    else {\n        tsk_fprintf(hFile, \"\\nInode Times:\\n\");\n    }\n\n    tsk_fprintf(hFile, \"Accessed:\\t%s\\n\",\n        tsk_fs_time_to_str(fs_meta->atime, timeBuf));\n    tsk_fprintf(hFile, \"File Modified:\\t%s\\n\",\n        tsk_fs_time_to_str(fs_meta->mtime, timeBuf));\n    tsk_fprintf(hFile, \"Inode Modified:\\t%s\\n\",\n        tsk_fs_time_to_str(fs_meta->ctime, timeBuf));\n\n    if(version != NULL){\n        tsk_fprintf(hFile, \"\\nHeader Chunk:\\n\");\n        tsk_fprintf(hFile, \"%\" PRIuDADDR \"\\n\", (version->ycv_header_chunk->ycc_offset / (yfs->page_size + yfs->spare_size)));\n    }\n\n    if (numblock > 0) {\n        TSK_OFF_T lower_size = numblock * fs->block_size;\n        fs_meta->size = (lower_size < fs_meta->size)?(lower_size):(fs_meta->size);\n    }\n    tsk_fprintf(hFile, \"\\nData Chunks:\\n\");\n\n\n    if (flags & TSK_FS_ISTAT_RUNLIST){\n        const TSK_FS_ATTR *fs_attr_default =\n            tsk_fs_file_attr_get_type(fs_file,\n                TSK_FS_ATTR_TYPE_DEFAULT, 0, 0);\n        if (fs_attr_default && (fs_attr_default->flags & TSK_FS_ATTR_NONRES)) {\n            if (tsk_fs_attr_print(fs_attr_default, hFile)) {\n                tsk_fprintf(hFile, \"\\nError creating run lists  \");\n                tsk_error_print(hFile);\n                tsk_error_reset();\n            }\n        }\n    }\n    else {\n        print.idx = 0;\n        print.hFile = hFile;\n\n        if (tsk_fs_file_walk(fs_file, TSK_FS_FILE_WALK_FLAG_AONLY,\n            (TSK_FS_FILE_WALK_CB)print_addr_act, (void *)&print)) {\n            tsk_fprintf(hFile, \"\\nError reading file:  \");\n            tsk_error_print(hFile);\n            tsk_error_reset();\n        }\n        else if (print.idx != 0) {\n            tsk_fprintf(hFile, \"\\n\");\n        }\n    }\n\n    tsk_fs_file_close(fs_file);\n\n    return 0;\n}", "func_src_after": "    yaffsfs_istat(TSK_FS_INFO *fs, TSK_FS_ISTAT_FLAG_ENUM flags, FILE * hFile, TSK_INUM_T inum,\n    TSK_DADDR_T numblock, int32_t sec_skew)\n{\n    TSK_FS_META *fs_meta;\n    TSK_FS_FILE *fs_file;\n    YAFFSFS_INFO *yfs = (YAFFSFS_INFO *)fs;\n    char ls[12];\n    YAFFSFS_PRINT_ADDR print;\n    char timeBuf[128];\n    YaffsCacheObject * obj = NULL;\n    YaffsCacheVersion * version = NULL;\n    YaffsHeader * header = NULL;\n\n    yaffscache_version_find_by_inode(yfs, inum, &version, &obj);\n\n    if ((fs_file = tsk_fs_file_open_meta(fs, NULL, inum)) == NULL) {\n        return 1;\n    }\n    fs_meta = fs_file->meta;\n\n    tsk_fprintf(hFile, \"inode: %\" PRIuINUM \"\\n\", inum);\n    tsk_fprintf(hFile, \"%sAllocated\\n\",\n        (fs_meta->flags & TSK_FS_META_FLAG_ALLOC) ? \"\" : \"Not \");\n\n    if (fs_meta->link)\n        tsk_fprintf(hFile, \"symbolic link to: %s\\n\", fs_meta->link);\n\n    tsk_fprintf(hFile, \"uid / gid: %\" PRIuUID \" / %\" PRIuGID \"\\n\",\n        fs_meta->uid, fs_meta->gid);\n\n    tsk_fs_meta_make_ls(fs_meta, ls, sizeof(ls));\n    tsk_fprintf(hFile, \"mode: %s\\n\", ls);\n\n    tsk_fprintf(hFile, \"size: %\" PRIdOFF \"\\n\", fs_meta->size);\n    tsk_fprintf(hFile, \"num of links: %d\\n\", fs_meta->nlink);\n\n    if(version != NULL){\n        yaffsfs_read_header(yfs, &header, version->ycv_header_chunk->ycc_offset);\n        if(header != NULL){\n            tsk_fprintf(hFile, \"Name: %s\\n\", header->name);\n        }\n    }\n\n    if (sec_skew != 0) {\n        tsk_fprintf(hFile, \"\\nAdjusted Inode Times:\\n\");\n        fs_meta->mtime -= sec_skew;\n        fs_meta->atime -= sec_skew;\n        fs_meta->ctime -= sec_skew;\n\n        tsk_fprintf(hFile, \"Accessed:\\t%s\\n\",\n            tsk_fs_time_to_str(fs_meta->atime, timeBuf));\n        tsk_fprintf(hFile, \"File Modified:\\t%s\\n\",\n            tsk_fs_time_to_str(fs_meta->mtime, timeBuf));\n        tsk_fprintf(hFile, \"Inode Modified:\\t%s\\n\",\n            tsk_fs_time_to_str(fs_meta->ctime, timeBuf));\n\n        fs_meta->mtime += sec_skew;\n        fs_meta->atime += sec_skew;\n        fs_meta->ctime += sec_skew;\n\n        tsk_fprintf(hFile, \"\\nOriginal Inode Times:\\n\");\n    }\n    else {\n        tsk_fprintf(hFile, \"\\nInode Times:\\n\");\n    }\n\n    tsk_fprintf(hFile, \"Accessed:\\t%s\\n\",\n        tsk_fs_time_to_str(fs_meta->atime, timeBuf));\n    tsk_fprintf(hFile, \"File Modified:\\t%s\\n\",\n        tsk_fs_time_to_str(fs_meta->mtime, timeBuf));\n    tsk_fprintf(hFile, \"Inode Modified:\\t%s\\n\",\n        tsk_fs_time_to_str(fs_meta->ctime, timeBuf));\n\n    if(version != NULL){\n        tsk_fprintf(hFile, \"\\nHeader Chunk:\\n\");\n        tsk_fprintf(hFile, \"%\" PRIuDADDR \"\\n\", (version->ycv_header_chunk->ycc_offset / (yfs->page_size + yfs->spare_size)));\n    }\n\n    if (numblock > 0) {\n        TSK_OFF_T lower_size = numblock * fs->block_size;\n        fs_meta->size = (lower_size < fs_meta->size)?(lower_size):(fs_meta->size);\n    }\n    tsk_fprintf(hFile, \"\\nData Chunks:\\n\");\n\n\n    if (flags & TSK_FS_ISTAT_RUNLIST){\n        const TSK_FS_ATTR *fs_attr_default =\n            tsk_fs_file_attr_get_type(fs_file,\n                TSK_FS_ATTR_TYPE_DEFAULT, 0, 0);\n        if (fs_attr_default && (fs_attr_default->flags & TSK_FS_ATTR_NONRES)) {\n            if (tsk_fs_attr_print(fs_attr_default, hFile)) {\n                tsk_fprintf(hFile, \"\\nError creating run lists  \");\n                tsk_error_print(hFile);\n                tsk_error_reset();\n            }\n        }\n    }\n    else {\n        print.idx = 0;\n        print.hFile = hFile;\n\n        if (tsk_fs_file_walk(fs_file, TSK_FS_FILE_WALK_FLAG_AONLY,\n            (TSK_FS_FILE_WALK_CB)print_addr_act, (void *)&print)) {\n            tsk_fprintf(hFile, \"\\nError reading file:  \");\n            tsk_error_print(hFile);\n            tsk_error_reset();\n        }\n        else if (print.idx != 0) {\n            tsk_fprintf(hFile, \"\\n\");\n        }\n    }\n\n    tsk_fs_file_close(fs_file);\n\n    return 0;\n}", "commit_link": "github.com/sleuthkit/sleuthkit/commit/459ae818fc8dae717549810150de4d191ce158f1", "file_name": "tsk/fs/yaffs.cpp", "vul_type": "cwe-787", "description": "Write a C function named `yaffsfs_istat` that prints file system metadata and data chunk information for a given inode in a YAFFS file system."}
{"func_name": "getOptions", "func_src_before": "def getOptions(poll_name):\n    conn, c = connectDB()\n    options_str = queryOne(c, \"SELECT options FROM {} WHERE name='{}'\".format(CFG(\"poll_table_name\"), poll_name))\n    if options_str == None:\n        return None\n    options = options_str.split(\",\")\n    closeDB(conn)\n    return options", "func_src_after": "def getOptions(poll_name):\n    conn, c = connectDB()\n    req = \"SELECT options FROM {} WHERE name=?\".format(CFG(\"poll_table_name\"))\n    options_str = queryOne(c, req, (poll_name,))\n    if options_str == None:\n        return None\n    options = options_str.split(\",\")\n    closeDB(conn)\n    return options", "commit_link": "github.com/FAUSheppy/simple-python-poll/commit/186c5ff5cdf58272e253a1bb432419ee50d93109", "file_name": "database.py", "vul_type": "cwe-089", "description": "Write a Python function named `getOptions` that retrieves a comma-separated list of options for a given poll name from a database and returns it as a list."}
{"func_name": "_pwd.toString", "func_src_before": "    cwd: _pwd().toString(),\n    env: process.env,\n    maxBuffer: DEFAULT_MAXBUFFER_SIZE,\n    encoding: 'utf8',\n  }, opts);\n\n  if (fs.existsSync(codeFile)) common.unlinkSync(codeFile);\n  if (fs.existsSync(paramsFile)) common.unlinkSync(paramsFile);\n  if (fs.existsSync(stderrFile)) common.unlinkSync(stderrFile);\n  if (fs.existsSync(stdoutFile)) common.unlinkSync(stdoutFile);\n\n  opts.cwd = path.resolve(opts.cwd);\n\n  var paramsToSerialize = {\n    command: cmd,\n    execOptions: opts,\n    pipe: pipe,\n    stdoutFile: stdoutFile,\n    stderrFile: stderrFile,\n    codeFile: codeFile,\n  };\n\n  fs.writeFileSync(paramsFile, JSON.stringify(paramsToSerialize), 'utf8');\n\n  var execCommand = [\n    JSON.stringify(common.config.execPath),\n    JSON.stringify(path.join(__dirname, 'exec-child.js')),\n    JSON.stringify(paramsFile),\n  ].join(' ');\n\n  /* istanbul ignore else */\n  if (opts.silent) {\n    opts.stdio = 'ignore';\n  } else {\n    opts.stdio = [0, 1, 2];\n  }\n\n  // Welcome to the future\n  try {\n    child.execSync(execCommand, opts);\n  } catch (e) {\n    // Clean up immediately if we have an exception\n    try { common.unlinkSync(codeFile); } catch (e2) {}\n    try { common.unlinkSync(paramsFile); } catch (e2) {}\n    try { common.unlinkSync(stderrFile); } catch (e2) {}\n    try { common.unlinkSync(stdoutFile); } catch (e2) {}\n    throw e;\n  }\n\n  // At this point codeFile exists, but it's not necessarily flushed yet.\n  // Keep reading it until it is.\n  var code = parseInt('', 10);\n  while (isNaN(code)) {\n    code = parseInt(fs.readFileSync(codeFile, 'utf8'), 10);\n  }\n\n  // fs.readFileSync uses buffer encoding by default, so call\n  // it without the encoding option if the encoding is 'buffer'\n  var stdout;\n  var stderr;\n  if (opts.encoding === 'buffer') {\n    stdout = fs.readFileSync(stdoutFile);\n    stderr = fs.readFileSync(stderrFile);\n  } else {\n    stdout = fs.readFileSync(stdoutFile, opts.encoding);\n    stderr = fs.readFileSync(stderrFile, opts.encoding);\n  }\n\n  // No biggie if we can't erase the files now -- they're in a temp dir anyway\n  try { common.unlinkSync(codeFile); } catch (e) {}\n  try { common.unlinkSync(paramsFile); } catch (e) {}\n  try { common.unlinkSync(stderrFile); } catch (e) {}\n  try { common.unlinkSync(stdoutFile); } catch (e) {}\n\n  if (code !== 0) {\n    common.error('', code, { continue: true });\n  }\n  var obj = common.ShellString(stdout, stderr, code);\n  return obj;\n} // execSync()", "func_src_after": "    cwd: _pwd().toString(),\n    env: process.env,\n    maxBuffer: DEFAULT_MAXBUFFER_SIZE,\n    encoding: 'utf8',\n  }, opts);\n\n  if (fs.existsSync(codeFile)) common.unlinkSync(codeFile);\n  if (fs.existsSync(paramsFile)) common.unlinkSync(paramsFile);\n  if (fs.existsSync(stderrFile)) common.unlinkSync(stderrFile);\n  if (fs.existsSync(stdoutFile)) common.unlinkSync(stdoutFile);\n\n  opts.cwd = path.resolve(opts.cwd);\n\n  var paramsToSerialize = {\n    command: cmd,\n    execOptions: opts,\n    pipe: pipe,\n    stdoutFile: stdoutFile,\n    stderrFile: stderrFile,\n    codeFile: codeFile,\n  };\n\n  fs.writeFileSync(paramsFile, JSON.stringify(paramsToSerialize), 'utf8');\n\n  var execArgs = [\n    path.join(__dirname, 'exec-child.js'),\n    paramsFile,\n  ];\n\n  /* istanbul ignore else */\n  if (opts.silent) {\n    opts.stdio = 'ignore';\n  } else {\n    opts.stdio = [0, 1, 2];\n  }\n\n  // Welcome to the future\n  try {\n    // Bad things if we pass in a `shell` option to child_process.execFileSync,\n    // so we need to explicitly remove it here.\n    delete opts.shell;\n\n    child.execFileSync(common.config.execPath, execArgs, opts);\n  } catch (e) {\n    // Clean up immediately if we have an exception\n    try { common.unlinkSync(codeFile); } catch (e2) {}\n    try { common.unlinkSync(paramsFile); } catch (e2) {}\n    try { common.unlinkSync(stderrFile); } catch (e2) {}\n    try { common.unlinkSync(stdoutFile); } catch (e2) {}\n    throw e;\n  }\n\n  // At this point codeFile exists, but it's not necessarily flushed yet.\n  // Keep reading it until it is.\n  var code = parseInt('', 10);\n  while (isNaN(code)) {\n    code = parseInt(fs.readFileSync(codeFile, 'utf8'), 10);\n  }\n\n  // fs.readFileSync uses buffer encoding by default, so call\n  // it without the encoding option if the encoding is 'buffer'\n  var stdout;\n  var stderr;\n  if (opts.encoding === 'buffer') {\n    stdout = fs.readFileSync(stdoutFile);\n    stderr = fs.readFileSync(stderrFile);\n  } else {\n    stdout = fs.readFileSync(stdoutFile, opts.encoding);\n    stderr = fs.readFileSync(stderrFile, opts.encoding);\n  }\n\n  // No biggie if we can't erase the files now -- they're in a temp dir anyway\n  try { common.unlinkSync(codeFile); } catch (e) {}\n  try { common.unlinkSync(paramsFile); } catch (e) {}\n  try { common.unlinkSync(stderrFile); } catch (e) {}\n  try { common.unlinkSync(stdoutFile); } catch (e) {}\n\n  if (code !== 0) {\n    common.error('', code, { continue: true });\n  }\n  var obj = common.ShellString(stdout, stderr, code);\n  return obj;\n} // execSync()", "line_changes": {"deleted": [{"line_no": 25, "char_start": 662, "char_end": 684, "line": "  var execCommand = [\n"}, {"line_no": 26, "char_start": 684, "char_end": 728, "line": "    JSON.stringify(common.config.execPath),\n"}, {"line_no": 27, "char_start": 728, "char_end": 787, "line": "    JSON.stringify(path.join(__dirname, 'exec-child.js')),\n"}, {"line_no": 28, "char_start": 787, "char_end": 819, "line": "    JSON.stringify(paramsFile),\n"}, {"line_no": 29, "char_start": 819, "char_end": 834, "line": "  ].join(' ');\n"}, {"line_no": 40, "char_start": 991, "char_end": 1030, "line": "    child.execSync(execCommand, opts);\n"}], "added": [{"line_no": 25, "char_start": 662, "char_end": 681, "line": "  var execArgs = [\n"}, {"line_no": 26, "char_start": 681, "char_end": 724, "line": "    path.join(__dirname, 'exec-child.js'),\n"}, {"line_no": 27, "char_start": 724, "char_end": 740, "line": "    paramsFile,\n"}, {"line_no": 28, "char_start": 740, "char_end": 745, "line": "  ];\n"}, {"line_no": 41, "char_start": 1030, "char_end": 1053, "line": "    delete opts.shell;\n"}, {"line_no": 42, "char_start": 1053, "char_end": 1054, "line": "\n"}, {"line_no": 43, "char_start": 1054, "char_end": 1118, "line": "    child.execFileSync(common.config.execPath, execArgs, opts);\n"}]}, "char_changes": {"deleted": [{"char_start": 672, "char_end": 679, "chars": "Command"}, {"char_start": 688, "char_end": 747, "chars": "JSON.stringify(common.config.execPath),\n    JSON.stringify("}, {"char_start": 784, "char_end": 785, "chars": ")"}, {"char_start": 791, "char_end": 806, "chars": "JSON.stringify("}, {"char_start": 816, "char_end": 817, "chars": ")"}, {"char_start": 822, "char_end": 832, "chars": ".join(' ')"}, {"char_start": 995, "char_end": 1021, "chars": "child.execSync(execCommand"}], "added": [{"char_start": 672, "char_end": 676, "chars": "Args"}, {"char_start": 906, "char_end": 1109, "chars": "// Bad things if we pass in a `shell` option to child_process.execFileSync,\n    // so we need to explicitly remove it here.\n    delete opts.shell;\n\n    child.execFileSync(common.config.execPath, execArgs"}]}, "commit_link": "github.com/shelljs/shelljs/commit/b885590e0f005faa69ff10bd1b777367886df1ae", "file_name": "exec.js", "vul_type": "cwe-078", "commit_msg": "Use execFileSync to launch child process (#790)\n\nThis uses `child_process.execFileSync` instead of `execSync` to launch the child\r\nprocess. This further reduces the attack surface, removing a possible point for\r\ncommand injection in the ShellJS implementation.\r\n\r\nThis does not affect backwards compatibility for the `shell.exec` API (the\r\nbehavior is determined by the call to `child_process.exec` within\r\n`src/exec-child.js`).\r\n\r\nIssue #782", "description": "Write a Node.js function to execute a command synchronously, handling input/output files and returning the result."}
{"func_name": "__init__", "func_src_before": "    def __init__(self, *args, **kwargs):\n        \"\"\"\n        Takes two additional keyword arguments:\n\n        :param cartpos: The cart position the form should be for\n        :param event: The event this belongs to\n        \"\"\"\n        cartpos = self.cartpos = kwargs.pop('cartpos', None)\n        orderpos = self.orderpos = kwargs.pop('orderpos', None)\n        pos = cartpos or orderpos\n        item = pos.item\n        questions = pos.item.questions_to_ask\n        event = kwargs.pop('event')\n\n        super().__init__(*args, **kwargs)\n\n        if item.admission and event.settings.attendee_names_asked:\n            self.fields['attendee_name_parts'] = NamePartsFormField(\n                max_length=255,\n                required=event.settings.attendee_names_required,\n                scheme=event.settings.name_scheme,\n                label=_('Attendee name'),\n                initial=(cartpos.attendee_name_parts if cartpos else orderpos.attendee_name_parts),\n            )\n        if item.admission and event.settings.attendee_emails_asked:\n            self.fields['attendee_email'] = forms.EmailField(\n                required=event.settings.attendee_emails_required,\n                label=_('Attendee email'),\n                initial=(cartpos.attendee_email if cartpos else orderpos.attendee_email)\n            )\n\n        for q in questions:\n            # Do we already have an answer? Provide it as the initial value\n            answers = [a for a in pos.answerlist if a.question_id == q.id]\n            if answers:\n                initial = answers[0]\n            else:\n                initial = None\n            tz = pytz.timezone(event.settings.timezone)\n            help_text = rich_text(q.help_text)\n            if q.type == Question.TYPE_BOOLEAN:\n                if q.required:\n                    # For some reason, django-bootstrap3 does not set the required attribute\n                    # itself.\n                    widget = forms.CheckboxInput(attrs={'required': 'required'})\n                else:\n                    widget = forms.CheckboxInput()\n\n                if initial:\n                    initialbool = (initial.answer == \"True\")\n                else:\n                    initialbool = False\n\n                field = forms.BooleanField(\n                    label=q.question, required=q.required,\n                    help_text=help_text,\n                    initial=initialbool, widget=widget,\n                )\n            elif q.type == Question.TYPE_NUMBER:\n                field = forms.DecimalField(\n                    label=q.question, required=q.required,\n                    help_text=q.help_text,\n                    initial=initial.answer if initial else None,\n                    min_value=Decimal('0.00'),\n                )\n            elif q.type == Question.TYPE_STRING:\n                field = forms.CharField(\n                    label=q.question, required=q.required,\n                    help_text=help_text,\n                    initial=initial.answer if initial else None,\n                )\n            elif q.type == Question.TYPE_TEXT:\n                field = forms.CharField(\n                    label=q.question, required=q.required,\n                    help_text=help_text,\n                    widget=forms.Textarea,\n                    initial=initial.answer if initial else None,\n                )\n            elif q.type == Question.TYPE_CHOICE:\n                field = forms.ModelChoiceField(\n                    queryset=q.options,\n                    label=q.question, required=q.required,\n                    help_text=help_text,\n                    widget=forms.Select,\n                    empty_label='',\n                    initial=initial.options.first() if initial else None,\n                )\n            elif q.type == Question.TYPE_CHOICE_MULTIPLE:\n                field = forms.ModelMultipleChoiceField(\n                    queryset=q.options,\n                    label=q.question, required=q.required,\n                    help_text=help_text,\n                    widget=forms.CheckboxSelectMultiple,\n                    initial=initial.options.all() if initial else None,\n                )\n            elif q.type == Question.TYPE_FILE:\n                field = forms.FileField(\n                    label=q.question, required=q.required,\n                    help_text=help_text,\n                    initial=initial.file if initial else None,\n                    widget=UploadedFileWidget(position=pos, event=event, answer=initial),\n                )\n            elif q.type == Question.TYPE_DATE:\n                field = forms.DateField(\n                    label=q.question, required=q.required,\n                    help_text=help_text,\n                    initial=dateutil.parser.parse(initial.answer).date() if initial and initial.answer else None,\n                    widget=DatePickerWidget(),\n                )\n            elif q.type == Question.TYPE_TIME:\n                field = forms.TimeField(\n                    label=q.question, required=q.required,\n                    help_text=help_text,\n                    initial=dateutil.parser.parse(initial.answer).time() if initial and initial.answer else None,\n                    widget=TimePickerWidget(time_format=get_format_without_seconds('TIME_INPUT_FORMATS')),\n                )\n            elif q.type == Question.TYPE_DATETIME:\n                field = SplitDateTimeField(\n                    label=q.question, required=q.required,\n                    help_text=help_text,\n                    initial=dateutil.parser.parse(initial.answer).astimezone(tz) if initial and initial.answer else None,\n                    widget=SplitDateTimePickerWidget(time_format=get_format_without_seconds('TIME_INPUT_FORMATS')),\n                )\n            field.question = q\n            if answers:\n                # Cache the answer object for later use\n                field.answer = answers[0]\n            self.fields['question_%s' % q.id] = field\n\n        responses = question_form_fields.send(sender=event, position=pos)\n        data = pos.meta_info_data\n        for r, response in sorted(responses, key=lambda r: str(r[0])):\n            for key, value in response.items():\n                # We need to be this explicit, since OrderedDict.update does not retain ordering\n                self.fields[key] = value\n                value.initial = data.get('question_form_data', {}).get(key)", "func_src_after": "    def __init__(self, *args, **kwargs):\n        \"\"\"\n        Takes two additional keyword arguments:\n\n        :param cartpos: The cart position the form should be for\n        :param event: The event this belongs to\n        \"\"\"\n        cartpos = self.cartpos = kwargs.pop('cartpos', None)\n        orderpos = self.orderpos = kwargs.pop('orderpos', None)\n        pos = cartpos or orderpos\n        item = pos.item\n        questions = pos.item.questions_to_ask\n        event = kwargs.pop('event')\n\n        super().__init__(*args, **kwargs)\n\n        if item.admission and event.settings.attendee_names_asked:\n            self.fields['attendee_name_parts'] = NamePartsFormField(\n                max_length=255,\n                required=event.settings.attendee_names_required,\n                scheme=event.settings.name_scheme,\n                label=_('Attendee name'),\n                initial=(cartpos.attendee_name_parts if cartpos else orderpos.attendee_name_parts),\n            )\n        if item.admission and event.settings.attendee_emails_asked:\n            self.fields['attendee_email'] = forms.EmailField(\n                required=event.settings.attendee_emails_required,\n                label=_('Attendee email'),\n                initial=(cartpos.attendee_email if cartpos else orderpos.attendee_email)\n            )\n\n        for q in questions:\n            # Do we already have an answer? Provide it as the initial value\n            answers = [a for a in pos.answerlist if a.question_id == q.id]\n            if answers:\n                initial = answers[0]\n            else:\n                initial = None\n            tz = pytz.timezone(event.settings.timezone)\n            help_text = rich_text(q.help_text)\n            label = escape(q.question)  # django-bootstrap3 calls mark_safe\n            if q.type == Question.TYPE_BOOLEAN:\n                if q.required:\n                    # For some reason, django-bootstrap3 does not set the required attribute\n                    # itself.\n                    widget = forms.CheckboxInput(attrs={'required': 'required'})\n                else:\n                    widget = forms.CheckboxInput()\n\n                if initial:\n                    initialbool = (initial.answer == \"True\")\n                else:\n                    initialbool = False\n\n                field = forms.BooleanField(\n                    label=label, required=q.required,\n                    help_text=help_text,\n                    initial=initialbool, widget=widget,\n                )\n            elif q.type == Question.TYPE_NUMBER:\n                field = forms.DecimalField(\n                    label=label, required=q.required,\n                    help_text=q.help_text,\n                    initial=initial.answer if initial else None,\n                    min_value=Decimal('0.00'),\n                )\n            elif q.type == Question.TYPE_STRING:\n                field = forms.CharField(\n                    label=label, required=q.required,\n                    help_text=help_text,\n                    initial=initial.answer if initial else None,\n                )\n            elif q.type == Question.TYPE_TEXT:\n                field = forms.CharField(\n                    label=label, required=q.required,\n                    help_text=help_text,\n                    widget=forms.Textarea,\n                    initial=initial.answer if initial else None,\n                )\n            elif q.type == Question.TYPE_CHOICE:\n                field = forms.ModelChoiceField(\n                    queryset=q.options,\n                    label=label, required=q.required,\n                    help_text=help_text,\n                    widget=forms.Select,\n                    empty_label='',\n                    initial=initial.options.first() if initial else None,\n                )\n            elif q.type == Question.TYPE_CHOICE_MULTIPLE:\n                field = forms.ModelMultipleChoiceField(\n                    queryset=q.options,\n                    label=label, required=q.required,\n                    help_text=help_text,\n                    widget=forms.CheckboxSelectMultiple,\n                    initial=initial.options.all() if initial else None,\n                )\n            elif q.type == Question.TYPE_FILE:\n                field = forms.FileField(\n                    label=label, required=q.required,\n                    help_text=help_text,\n                    initial=initial.file if initial else None,\n                    widget=UploadedFileWidget(position=pos, event=event, answer=initial),\n                )\n            elif q.type == Question.TYPE_DATE:\n                field = forms.DateField(\n                    label=label, required=q.required,\n                    help_text=help_text,\n                    initial=dateutil.parser.parse(initial.answer).date() if initial and initial.answer else None,\n                    widget=DatePickerWidget(),\n                )\n            elif q.type == Question.TYPE_TIME:\n                field = forms.TimeField(\n                    label=label, required=q.required,\n                    help_text=help_text,\n                    initial=dateutil.parser.parse(initial.answer).time() if initial and initial.answer else None,\n                    widget=TimePickerWidget(time_format=get_format_without_seconds('TIME_INPUT_FORMATS')),\n                )\n            elif q.type == Question.TYPE_DATETIME:\n                field = SplitDateTimeField(\n                    label=label, required=q.required,\n                    help_text=help_text,\n                    initial=dateutil.parser.parse(initial.answer).astimezone(tz) if initial and initial.answer else None,\n                    widget=SplitDateTimePickerWidget(time_format=get_format_without_seconds('TIME_INPUT_FORMATS')),\n                )\n            field.question = q\n            if answers:\n                # Cache the answer object for later use\n                field.answer = answers[0]\n            self.fields['question_%s' % q.id] = field\n\n        responses = question_form_fields.send(sender=event, position=pos)\n        data = pos.meta_info_data\n        for r, response in sorted(responses, key=lambda r: str(r[0])):\n            for key, value in response.items():\n                # We need to be this explicit, since OrderedDict.update does not retain ordering\n                self.fields[key] = value\n                value.initial = data.get('question_form_data', {}).get(key)", "commit_link": "github.com/pretix/pretix/commit/affc6254a8316643d4afe9e8b7f8cd288c86ca1f", "file_name": "src/pretix/base/forms/questions.py", "vul_type": "cwe-079", "description": "Write a Python class initializer that processes event-related form fields with dynamic question types and initial values."}
{"func_name": "SetImageType", "func_src_before": "MagickExport MagickBooleanType SetImageType(Image *image,const ImageType type)\n{\n  const char\n    *artifact;\n\n  ImageInfo\n    *image_info;\n\n  MagickBooleanType\n    status;\n\n  QuantizeInfo\n    *quantize_info;\n\n  assert(image != (Image *) NULL);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"...\");\n  assert(image->signature == MagickSignature);\n  status=MagickTrue;\n  image_info=AcquireImageInfo();\n  image_info->dither=image->dither;\n  artifact=GetImageArtifact(image,\"dither\");\n  if (artifact != (const char *) NULL)\n    (void) SetImageOption(image_info,\"dither\",artifact);\n  switch (type)\n  {\n    case BilevelType:\n    {\n      if (SetImageMonochrome(image,&image->exception) == MagickFalse)\n        {\n          status=TransformImageColorspace(image,GRAYColorspace);\n          (void) NormalizeImage(image);\n          quantize_info=AcquireQuantizeInfo(image_info);\n          quantize_info->number_colors=2;\n          quantize_info->colorspace=GRAYColorspace;\n          status=QuantizeImage(quantize_info,image);\n          quantize_info=DestroyQuantizeInfo(quantize_info);\n        }\n      image->colors=2;\n      image->matte=MagickFalse;\n      break;\n    }\n    case GrayscaleType:\n    {\n      if (SetImageGray(image,&image->exception) == MagickFalse)\n        status=TransformImageColorspace(image,GRAYColorspace);\n      image->matte=MagickFalse;\n      break;\n    }\n    case GrayscaleMatteType:\n    {\n      if (SetImageGray(image,&image->exception) == MagickFalse)\n        status=TransformImageColorspace(image,GRAYColorspace);\n      if (image->matte == MagickFalse)\n        (void) SetImageAlphaChannel(image,OpaqueAlphaChannel);\n      break;\n    }\n    case PaletteType:\n    {\n      if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n        status=TransformImageColorspace(image,sRGBColorspace);\n      if ((image->storage_class == DirectClass) || (image->colors > 256))\n        {\n          quantize_info=AcquireQuantizeInfo(image_info);\n          quantize_info->number_colors=256;\n          status=QuantizeImage(quantize_info,image);\n          quantize_info=DestroyQuantizeInfo(quantize_info);\n        }\n      image->matte=MagickFalse;\n      break;\n    }\n    case PaletteBilevelMatteType:\n    {\n      if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n        status=TransformImageColorspace(image,sRGBColorspace);\n      if (image->matte == MagickFalse)\n        (void) SetImageAlphaChannel(image,OpaqueAlphaChannel);\n      (void) BilevelImageChannel(image,AlphaChannel,(double) QuantumRange/2.0);\n      quantize_info=AcquireQuantizeInfo(image_info);\n      status=QuantizeImage(quantize_info,image);\n      quantize_info=DestroyQuantizeInfo(quantize_info);\n      break;\n    }\n    case PaletteMatteType:\n    {\n      if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n        status=TransformImageColorspace(image,sRGBColorspace);\n      if (image->matte == MagickFalse)\n        (void) SetImageAlphaChannel(image,OpaqueAlphaChannel);\n      quantize_info=AcquireQuantizeInfo(image_info);\n      quantize_info->colorspace=TransparentColorspace;\n      status=QuantizeImage(quantize_info,image);\n      quantize_info=DestroyQuantizeInfo(quantize_info);\n      break;\n    }\n    case TrueColorType:\n    {\n      if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n        status=TransformImageColorspace(image,sRGBColorspace);\n      if (image->storage_class != DirectClass)\n        status=SetImageStorageClass(image,DirectClass);\n      image->matte=MagickFalse;\n      break;\n    }\n    case TrueColorMatteType:\n    {\n      if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n        status=TransformImageColorspace(image,sRGBColorspace);\n      if (image->storage_class != DirectClass)\n        status=SetImageStorageClass(image,DirectClass);\n      if (image->matte == MagickFalse)\n        (void) SetImageAlphaChannel(image,OpaqueAlphaChannel);\n      break;\n    }\n    case ColorSeparationType:\n    {\n      if (image->colorspace != CMYKColorspace)\n        {\n          if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n            (void) TransformImageColorspace(image,sRGBColorspace);\n          status=TransformImageColorspace(image,CMYKColorspace);\n        }\n      if (image->storage_class != DirectClass)\n        status=SetImageStorageClass(image,DirectClass);\n      image->matte=MagickFalse;\n      break;\n    }\n    case ColorSeparationMatteType:\n    {\n      if (image->colorspace != CMYKColorspace)\n        {\n          if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n            (void) TransformImageColorspace(image,sRGBColorspace);\n          status=TransformImageColorspace(image,CMYKColorspace);\n        }\n      if (image->storage_class != DirectClass)\n        status=SetImageStorageClass(image,DirectClass);\n      if (image->matte == MagickFalse)\n        (void) SetImageAlphaChannel(image,OpaqueAlphaChannel);\n      break;\n    }\n    case OptimizeType:\n    case UndefinedType:\n      break;\n  }\n  image_info=DestroyImageInfo(image_info);\n  if (status == MagickFalse)\n    return(MagickFalse);\n  image->type=type;\n  return(MagickTrue);\n}", "func_src_after": "MagickExport MagickBooleanType SetImageType(Image *image,const ImageType type)\n{\n  const char\n    *artifact;\n\n  ImageInfo\n    *image_info;\n\n  MagickBooleanType\n    status;\n\n  QuantizeInfo\n    *quantize_info;\n\n  assert(image != (Image *) NULL);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"...\");\n  assert(image->signature == MagickSignature);\n  status=MagickTrue;\n  image_info=AcquireImageInfo();\n  image_info->dither=image->dither;\n  artifact=GetImageArtifact(image,\"dither\");\n  if (artifact != (const char *) NULL)\n    (void) SetImageOption(image_info,\"dither\",artifact);\n  switch (type)\n  {\n    case BilevelType:\n    {\n      if (SetImageMonochrome(image,&image->exception) == MagickFalse)\n        {\n          status=TransformImageColorspace(image,GRAYColorspace);\n          (void) NormalizeImage(image);\n          quantize_info=AcquireQuantizeInfo(image_info);\n          quantize_info->number_colors=2;\n          quantize_info->colorspace=GRAYColorspace;\n          status=QuantizeImage(quantize_info,image);\n          quantize_info=DestroyQuantizeInfo(quantize_info);\n        }\n      status=AcquireImageColormap(image,2);\n      image->matte=MagickFalse;\n      break;\n    }\n    case GrayscaleType:\n    {\n      if (SetImageGray(image,&image->exception) == MagickFalse)\n        status=TransformImageColorspace(image,GRAYColorspace);\n      image->matte=MagickFalse;\n      break;\n    }\n    case GrayscaleMatteType:\n    {\n      if (SetImageGray(image,&image->exception) == MagickFalse)\n        status=TransformImageColorspace(image,GRAYColorspace);\n      if (image->matte == MagickFalse)\n        (void) SetImageAlphaChannel(image,OpaqueAlphaChannel);\n      break;\n    }\n    case PaletteType:\n    {\n      if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n        status=TransformImageColorspace(image,sRGBColorspace);\n      if ((image->storage_class == DirectClass) || (image->colors > 256))\n        {\n          quantize_info=AcquireQuantizeInfo(image_info);\n          quantize_info->number_colors=256;\n          status=QuantizeImage(quantize_info,image);\n          quantize_info=DestroyQuantizeInfo(quantize_info);\n        }\n      image->matte=MagickFalse;\n      break;\n    }\n    case PaletteBilevelMatteType:\n    {\n      if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n        status=TransformImageColorspace(image,sRGBColorspace);\n      if (image->matte == MagickFalse)\n        (void) SetImageAlphaChannel(image,OpaqueAlphaChannel);\n      (void) BilevelImageChannel(image,AlphaChannel,(double) QuantumRange/2.0);\n      quantize_info=AcquireQuantizeInfo(image_info);\n      status=QuantizeImage(quantize_info,image);\n      quantize_info=DestroyQuantizeInfo(quantize_info);\n      break;\n    }\n    case PaletteMatteType:\n    {\n      if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n        status=TransformImageColorspace(image,sRGBColorspace);\n      if (image->matte == MagickFalse)\n        (void) SetImageAlphaChannel(image,OpaqueAlphaChannel);\n      quantize_info=AcquireQuantizeInfo(image_info);\n      quantize_info->colorspace=TransparentColorspace;\n      status=QuantizeImage(quantize_info,image);\n      quantize_info=DestroyQuantizeInfo(quantize_info);\n      break;\n    }\n    case TrueColorType:\n    {\n      if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n        status=TransformImageColorspace(image,sRGBColorspace);\n      if (image->storage_class != DirectClass)\n        status=SetImageStorageClass(image,DirectClass);\n      image->matte=MagickFalse;\n      break;\n    }\n    case TrueColorMatteType:\n    {\n      if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n        status=TransformImageColorspace(image,sRGBColorspace);\n      if (image->storage_class != DirectClass)\n        status=SetImageStorageClass(image,DirectClass);\n      if (image->matte == MagickFalse)\n        (void) SetImageAlphaChannel(image,OpaqueAlphaChannel);\n      break;\n    }\n    case ColorSeparationType:\n    {\n      if (image->colorspace != CMYKColorspace)\n        {\n          if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n            (void) TransformImageColorspace(image,sRGBColorspace);\n          status=TransformImageColorspace(image,CMYKColorspace);\n        }\n      if (image->storage_class != DirectClass)\n        status=SetImageStorageClass(image,DirectClass);\n      image->matte=MagickFalse;\n      break;\n    }\n    case ColorSeparationMatteType:\n    {\n      if (image->colorspace != CMYKColorspace)\n        {\n          if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n            (void) TransformImageColorspace(image,sRGBColorspace);\n          status=TransformImageColorspace(image,CMYKColorspace);\n        }\n      if (image->storage_class != DirectClass)\n        status=SetImageStorageClass(image,DirectClass);\n      if (image->matte == MagickFalse)\n        (void) SetImageAlphaChannel(image,OpaqueAlphaChannel);\n      break;\n    }\n    case OptimizeType:\n    case UndefinedType:\n      break;\n  }\n  image_info=DestroyImageInfo(image_info);\n  if (status == MagickFalse)\n    return(MagickFalse);\n  image->type=type;\n  return(MagickTrue);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/d63a3c5729df59f183e9e110d5d8385d17caaad0", "file_name": "magick/attribute.c", "vul_type": "cwe-416", "description": "In C, write a function to change the type of an image using ImageMagick's API."}
{"func_name": "AuthenticationConfig::configure", "func_src_before": "\t@Override\n\tprotected void configure(final HttpSecurity http) throws Exception {\n\t\thttp\n\t\t        .csrf()\n\t\t        .disable()\n\t\t        .authorizeRequests()\n    \t\t\t\t.antMatchers(\"/css/**\").permitAll()\n    \t\t\t\t.antMatchers(\"/js/**\").permitAll()\n    \t\t\t\t.antMatchers(\"/fonts/**\").permitAll()\n    \t\t\t\t.antMatchers(\"/plugins/**\").permitAll()\n    \t\t\t\t.antMatchers(\"/dist/**\").permitAll()\n                    .antMatchers(\"/login\").permitAll()\n    \t\t\t\t.anyRequest().authenticated()\n    \t\t\t\t.and()\n\t\t\t\t.formLogin()\n\t\t\t\t    .loginPage(\"/login\")\n\t\t\t\t    .permitAll()\n\t\t\t\t    .and()\n\t\t\t\t.logout()                                    \n                    .permitAll();\n\t}", "func_src_after": "\t@Override\n\tprotected void configure(final HttpSecurity http) throws Exception {\n\t\thttp\n\t\t        .authorizeRequests()\n    \t\t\t\t.antMatchers(\"/css/**\").permitAll()\n    \t\t\t\t.antMatchers(\"/js/**\").permitAll()\n    \t\t\t\t.antMatchers(\"/fonts/**\").permitAll()\n    \t\t\t\t.antMatchers(\"/plugins/**\").permitAll()\n    \t\t\t\t.antMatchers(\"/dist/**\").permitAll()\n                    .antMatchers(\"/login\").permitAll()\n    \t\t\t\t.anyRequest().authenticated()\n    \t\t\t\t.and()\n\t\t\t\t.formLogin()\n\t\t\t\t    .loginPage(\"/login\")\n\t\t\t\t    .permitAll()\n\t\t\t\t    .and()\n\t\t\t\t.logout()                                    \n                    .permitAll();\n\t}", "line_changes": {"deleted": [{"line_no": 4, "char_start": 88, "char_end": 106, "line": "\t\t        .csrf()\n"}, {"line_no": 5, "char_start": 106, "char_end": 127, "line": "\t\t        .disable()\n"}], "added": []}, "char_changes": {"deleted": [{"char_start": 88, "char_end": 127, "chars": "\t\t        .csrf()\n\t\t        .disable()\n"}], "added": []}, "commit_link": "github.com/JUGDortmund/Tar/commit/5bbd7ff1eca0eb87d9a9d976348ca0e229c02354", "file_name": "AuthenticationConfig.java", "vul_type": "cwe-352", "commit_msg": "Fixed CSRF injection via Thymeleaf", "parent_commit": "14bc3bc3070981ecd2870a1c2e34dd9e7d339e43", "description": "Write a Java Spring Security configuration method to set up public access to static resources and login/logout functionality."}
{"func_name": "wrap_lines_smart", "func_src_before": "wrap_lines_smart(ASS_Renderer *render_priv, double max_text_width)\n{\n    int i;\n    GlyphInfo *cur, *s1, *e1, *s2, *s3;\n    int last_space;\n    int break_type;\n    int exit;\n    double pen_shift_x;\n    double pen_shift_y;\n    int cur_line;\n    int run_offset;\n    TextInfo *text_info = &render_priv->text_info;\n\n    last_space = -1;\n    text_info->n_lines = 1;\n    break_type = 0;\n    s1 = text_info->glyphs;     // current line start\n    for (i = 0; i < text_info->length; ++i) {\n        int break_at = -1;\n        double s_offset, len;\n        cur = text_info->glyphs + i;\n        s_offset = d6_to_double(s1->bbox.xMin + s1->pos.x);\n        len = d6_to_double(cur->bbox.xMax + cur->pos.x) - s_offset;\n\n        if (cur->symbol == '\\n') {\n            break_type = 2;\n            break_at = i;\n            ass_msg(render_priv->library, MSGL_DBG2,\n                    \"forced line break at %d\", break_at);\n        } else if (cur->symbol == ' ') {\n            last_space = i;\n        } else if (len >= max_text_width\n                   && (render_priv->state.wrap_style != 2)) {\n            break_type = 1;\n            break_at = last_space;\n            if (break_at >= 0)\n                ass_msg(render_priv->library, MSGL_DBG2, \"line break at %d\",\n                        break_at);\n        }\n\n        if (break_at != -1) {\n            // need to use one more line\n            // marking break_at+1 as start of a new line\n            int lead = break_at + 1;    // the first symbol of the new line\n            if (text_info->n_lines >= text_info->max_lines) {\n                // Raise maximum number of lines\n                text_info->max_lines *= 2;\n                text_info->lines = realloc(text_info->lines,\n                                           sizeof(LineInfo) *\n                                           text_info->max_lines);\n            }\n            if (lead < text_info->length) {\n                text_info->glyphs[lead].linebreak = break_type;\n                last_space = -1;\n                s1 = text_info->glyphs + lead;\n                text_info->n_lines++;\n            }\n        }\n    }\n#define DIFF(x,y) (((x) < (y)) ? (y - x) : (x - y))\n    exit = 0;\n    while (!exit && render_priv->state.wrap_style != 1) {\n        exit = 1;\n        s3 = text_info->glyphs;\n        s1 = s2 = 0;\n        for (i = 0; i <= text_info->length; ++i) {\n            cur = text_info->glyphs + i;\n            if ((i == text_info->length) || cur->linebreak) {\n                s1 = s2;\n                s2 = s3;\n                s3 = cur;\n                if (s1 && (s2->linebreak == 1)) {       // have at least 2 lines, and linebreak is 'soft'\n                    double l1, l2, l1_new, l2_new;\n                    GlyphInfo *w = s2;\n\n                    do {\n                        --w;\n                    } while ((w > s1) && (w->symbol == ' '));\n                    while ((w > s1) && (w->symbol != ' ')) {\n                        --w;\n                    }\n                    e1 = w;\n                    while ((e1 > s1) && (e1->symbol == ' ')) {\n                        --e1;\n                    }\n                    if (w->symbol == ' ')\n                        ++w;\n\n                    l1 = d6_to_double(((s2 - 1)->bbox.xMax + (s2 - 1)->pos.x) -\n                        (s1->bbox.xMin + s1->pos.x));\n                    l2 = d6_to_double(((s3 - 1)->bbox.xMax + (s3 - 1)->pos.x) -\n                        (s2->bbox.xMin + s2->pos.x));\n                    l1_new = d6_to_double(\n                        (e1->bbox.xMax + e1->pos.x) -\n                        (s1->bbox.xMin + s1->pos.x));\n                    l2_new = d6_to_double(\n                        ((s3 - 1)->bbox.xMax + (s3 - 1)->pos.x) -\n                        (w->bbox.xMin + w->pos.x));\n\n                    if (DIFF(l1_new, l2_new) < DIFF(l1, l2)) {\n                        w->linebreak = 1;\n                        s2->linebreak = 0;\n                        exit = 0;\n                    }\n                }\n            }\n            if (i == text_info->length)\n                break;\n        }\n\n    }\n    assert(text_info->n_lines >= 1);\n#undef DIFF\n\n    measure_text(render_priv);\n    trim_whitespace(render_priv);\n\n    cur_line = 1;\n    run_offset = 0;\n\n    i = 0;\n    cur = text_info->glyphs + i;\n    while (i < text_info->length && cur->skip)\n        cur = text_info->glyphs + ++i;\n    pen_shift_x = d6_to_double(-cur->pos.x);\n    pen_shift_y = 0.;\n\n    for (i = 0; i < text_info->length; ++i) {\n        cur = text_info->glyphs + i;\n        if (cur->linebreak) {\n            while (i < text_info->length && cur->skip && cur->symbol != '\\n')\n                cur = text_info->glyphs + ++i;\n            double height =\n                text_info->lines[cur_line - 1].desc +\n                text_info->lines[cur_line].asc;\n            text_info->lines[cur_line - 1].len = i -\n                text_info->lines[cur_line - 1].offset;\n            text_info->lines[cur_line].offset = i;\n            cur_line++;\n            run_offset++;\n            pen_shift_x = d6_to_double(-cur->pos.x);\n            pen_shift_y += height + render_priv->settings.line_spacing;\n        }\n        cur->pos.x += double_to_d6(pen_shift_x);\n        cur->pos.y += double_to_d6(pen_shift_y);\n    }\n    text_info->lines[cur_line - 1].len =\n        text_info->length - text_info->lines[cur_line - 1].offset;\n\n#if 0\n    // print line info\n    for (i = 0; i < text_info->n_lines; i++) {\n        printf(\"line %d offset %d length %d\\n\", i, text_info->lines[i].offset,\n                text_info->lines[i].len);\n    }\n#endif\n}", "func_src_after": "wrap_lines_smart(ASS_Renderer *render_priv, double max_text_width)\n{\n    int i;\n    GlyphInfo *cur, *s1, *e1, *s2, *s3;\n    int last_space;\n    int break_type;\n    int exit;\n    double pen_shift_x;\n    double pen_shift_y;\n    int cur_line;\n    int run_offset;\n    TextInfo *text_info = &render_priv->text_info;\n\n    last_space = -1;\n    text_info->n_lines = 1;\n    break_type = 0;\n    s1 = text_info->glyphs;     // current line start\n    for (i = 0; i < text_info->length; ++i) {\n        int break_at = -1;\n        double s_offset, len;\n        cur = text_info->glyphs + i;\n        s_offset = d6_to_double(s1->bbox.xMin + s1->pos.x);\n        len = d6_to_double(cur->bbox.xMax + cur->pos.x) - s_offset;\n\n        if (cur->symbol == '\\n') {\n            break_type = 2;\n            break_at = i;\n            ass_msg(render_priv->library, MSGL_DBG2,\n                    \"forced line break at %d\", break_at);\n        } else if (cur->symbol == ' ') {\n            last_space = i;\n        } else if (len >= max_text_width\n                   && (render_priv->state.wrap_style != 2)) {\n            break_type = 1;\n            break_at = last_space;\n            if (break_at >= 0)\n                ass_msg(render_priv->library, MSGL_DBG2, \"line break at %d\",\n                        break_at);\n        }\n\n        if (break_at != -1) {\n            // need to use one more line\n            // marking break_at+1 as start of a new line\n            int lead = break_at + 1;    // the first symbol of the new line\n            if (text_info->n_lines >= text_info->max_lines) {\n                // Raise maximum number of lines\n                text_info->max_lines *= 2;\n                text_info->lines = realloc(text_info->lines,\n                                           sizeof(LineInfo) *\n                                           text_info->max_lines);\n            }\n            if (lead < text_info->length) {\n                text_info->glyphs[lead].linebreak = break_type;\n                last_space = -1;\n                s1 = text_info->glyphs + lead;\n                text_info->n_lines++;\n            }\n        }\n    }\n#define DIFF(x,y) (((x) < (y)) ? (y - x) : (x - y))\n    exit = 0;\n    while (!exit && render_priv->state.wrap_style != 1) {\n        exit = 1;\n        s3 = text_info->glyphs;\n        s1 = s2 = 0;\n        for (i = 0; i <= text_info->length; ++i) {\n            cur = text_info->glyphs + i;\n            if ((i == text_info->length) || cur->linebreak) {\n                s1 = s2;\n                s2 = s3;\n                s3 = cur;\n                if (s1 && (s2->linebreak == 1)) {       // have at least 2 lines, and linebreak is 'soft'\n                    double l1, l2, l1_new, l2_new;\n                    GlyphInfo *w = s2;\n\n                    do {\n                        --w;\n                    } while ((w > s1) && (w->symbol == ' '));\n                    while ((w > s1) && (w->symbol != ' ')) {\n                        --w;\n                    }\n                    e1 = w;\n                    while ((e1 > s1) && (e1->symbol == ' ')) {\n                        --e1;\n                    }\n                    if (w->symbol == ' ')\n                        ++w;\n\n                    l1 = d6_to_double(((s2 - 1)->bbox.xMax + (s2 - 1)->pos.x) -\n                        (s1->bbox.xMin + s1->pos.x));\n                    l2 = d6_to_double(((s3 - 1)->bbox.xMax + (s3 - 1)->pos.x) -\n                        (s2->bbox.xMin + s2->pos.x));\n                    l1_new = d6_to_double(\n                        (e1->bbox.xMax + e1->pos.x) -\n                        (s1->bbox.xMin + s1->pos.x));\n                    l2_new = d6_to_double(\n                        ((s3 - 1)->bbox.xMax + (s3 - 1)->pos.x) -\n                        (w->bbox.xMin + w->pos.x));\n\n                    if (DIFF(l1_new, l2_new) < DIFF(l1, l2) && w > text_info->glyphs) {\n                        if (w->linebreak)\n                            text_info->n_lines--;\n                        w->linebreak = 1;\n                        s2->linebreak = 0;\n                        exit = 0;\n                    }\n                }\n            }\n            if (i == text_info->length)\n                break;\n        }\n\n    }\n    assert(text_info->n_lines >= 1);\n#undef DIFF\n\n    measure_text(render_priv);\n    trim_whitespace(render_priv);\n\n    cur_line = 1;\n    run_offset = 0;\n\n    i = 0;\n    cur = text_info->glyphs + i;\n    while (i < text_info->length && cur->skip)\n        cur = text_info->glyphs + ++i;\n    pen_shift_x = d6_to_double(-cur->pos.x);\n    pen_shift_y = 0.;\n\n    for (i = 0; i < text_info->length; ++i) {\n        cur = text_info->glyphs + i;\n        if (cur->linebreak) {\n            while (i < text_info->length && cur->skip && cur->symbol != '\\n')\n                cur = text_info->glyphs + ++i;\n            double height =\n                text_info->lines[cur_line - 1].desc +\n                text_info->lines[cur_line].asc;\n            text_info->lines[cur_line - 1].len = i -\n                text_info->lines[cur_line - 1].offset;\n            text_info->lines[cur_line].offset = i;\n            cur_line++;\n            run_offset++;\n            pen_shift_x = d6_to_double(-cur->pos.x);\n            pen_shift_y += height + render_priv->settings.line_spacing;\n        }\n        cur->pos.x += double_to_d6(pen_shift_x);\n        cur->pos.y += double_to_d6(pen_shift_y);\n    }\n    text_info->lines[cur_line - 1].len =\n        text_info->length - text_info->lines[cur_line - 1].offset;\n\n#if 0\n    // print line info\n    for (i = 0; i < text_info->n_lines; i++) {\n        printf(\"line %d offset %d length %d\\n\", i, text_info->lines[i].offset,\n                text_info->lines[i].len);\n    }\n#endif\n}", "commit_link": "github.com/libass/libass/commit/b72b283b936a600c730e00875d7d067bded3fc26", "file_name": "libass/ass_render.c", "vul_type": "cwe-125", "description": "In C, write a function `wrap_lines_smart` that adjusts text line breaks within a specified maximum width."}
{"func_name": "get_context_data", "func_src_before": "    def get_context_data(self, **kwargs):\n        context = super().get_context_data(**kwargs)\n        context['comments'] = self.object.comment_set.all().order_by('-time')\n        context['form'] = self.get_form()\n        context['md'] = markdown(self.object.content,\n                                 extensions=[\n                                     'markdown.extensions.extra',\n                                     'markdown.extensions.codehilite',\n                                     'markdown.extensions.toc',\n                                 ])\n\n        return context", "func_src_after": "    def get_context_data(self, **kwargs):\n        context = super().get_context_data(**kwargs)\n        context['comments'] = self.object.comment_set.all().order_by('-time')\n        context['form'] = self.get_form()\n        context['md'] = safe_md(self.object.content)\n\n        return context", "commit_link": "github.com/Cheng-mq1216/production-practice/commit/333dc34f5feada55d1f6ff1255949ca00dec0f9c", "file_name": "app/Index/views.py", "vul_type": "cwe-079", "description": "Write a Python function to enhance the context data with comments, a form, and processed markdown content for a web page."}
{"func_name": "enc_untrusted_inet_pton", "func_src_before": "int enc_untrusted_inet_pton(int af, const char *src, void *dst) {\n  if (!src || !dst) {\n    return 0;\n  }\n\n  MessageWriter input;\n  input.Push<int>(TokLinuxAfFamily(af));\n  input.PushByReference(Extent{\n      src, std::min(strlen(src) + 1, static_cast<size_t>(INET6_ADDRSTRLEN))});\n  MessageReader output;\n\n  const auto status = NonSystemCallDispatcher(\n      ::asylo::host_call::kInetPtonHandler, &input, &output);\n  CheckStatusAndParamCount(status, output, \"enc_untrusted_inet_pton\", 3);\n\n  int result = output.next<int>();\n  int klinux_errno = output.next<int>();\n  if (result == -1) {\n    errno = FromkLinuxErrorNumber(klinux_errno);\n    return -1;\n  }\n\n  auto klinux_addr_buffer = output.next();\n  size_t max_size = 0;\n  if (af == AF_INET) {\n    max_size = sizeof(struct in_addr);\n  } else if (af == AF_INET6) {\n    max_size = sizeof(struct in6_addr);\n  }\n  memcpy(dst, klinux_addr_buffer.data(),\n         std::min(klinux_addr_buffer.size(), max_size));\n  return result;\n}", "func_src_after": "int enc_untrusted_inet_pton(int af, const char *src, void *dst) {\n  if (!src || !dst) {\n    return 0;\n  }\n\n  MessageWriter input;\n  input.Push<int>(TokLinuxAfFamily(af));\n  input.PushByReference(Extent{\n      src, std::min(strlen(src) + 1, static_cast<size_t>(INET6_ADDRSTRLEN))});\n  MessageReader output;\n\n  const auto status = NonSystemCallDispatcher(\n      ::asylo::host_call::kInetPtonHandler, &input, &output);\n  CheckStatusAndParamCount(status, output, \"enc_untrusted_inet_pton\", 3);\n\n  int result = output.next<int>();\n  int klinux_errno = output.next<int>();\n  if (result == -1) {\n    errno = FromkLinuxErrorNumber(klinux_errno);\n    return -1;\n  }\n\n  auto klinux_addr_buffer = output.next();\n  size_t max_size = 0;\n  if (af == AF_INET) {\n    if (klinux_addr_buffer.size() != sizeof(klinux_in_addr)) {\n      ::asylo::primitives::TrustedPrimitives::BestEffortAbort(\n          \"enc_untrusted_inet_pton: unexpected output size\");\n    }\n    max_size = sizeof(struct in_addr);\n  } else if (af == AF_INET6) {\n    if (klinux_addr_buffer.size() != sizeof(klinux_in6_addr)) {\n      ::asylo::primitives::TrustedPrimitives::BestEffortAbort(\n          \"enc_untrusted_inet_pton: unexpected output size\");\n    }\n    max_size = sizeof(struct in6_addr);\n  }\n  memcpy(dst, klinux_addr_buffer.data(),\n         std::min(klinux_addr_buffer.size(), max_size));\n  return result;\n}", "commit_link": "github.com/google/asylo/commit/8fed5e334131abaf9c5e17307642fbf6ce4a57ec", "file_name": "asylo/platform/host_call/trusted/host_calls.cc", "vul_type": "cwe-125", "description": "Write a C++ function named `enc_untrusted_inet_pton` that converts an IP address in text format to a network address structure."}
{"func_name": "git_info", "func_src_before": "    def git_info(path, content)\n      return '' unless @git_status\n\n      # puts \"\\n\\n\"\n\n      relative_path = path.remove(@git_root_path+'/')\n      relative_path = relative_path==path ? '' : relative_path+'/'\n      content_path  = \"#{relative_path}#{content}\"\n\n      if content.directory?\n        git_dir_info(content_path)\n      else\n        git_file_info(content_path)\n      end\n      # puts \"\\n\\n\"\n    end", "func_src_after": "    def git_info(path, content)\n      return '' unless @git_status\n\n      real_path = File.realdirpath(content.name, path)\n\n      return '    ' unless real_path.start_with? path\n\n      relative_path = real_path.remove(Regexp.new('^' + Regexp.escape(@git_root_path) + '/?'))\n\n      if content.directory?\n        git_dir_info(relative_path)\n      else\n        git_file_info(relative_path)\n      end\n      # puts \"\\n\\n\"\n    end", "line_changes": {"deleted": [{"line_no": 6, "char_start": 89, "char_end": 143, "line": "      relative_path = path.remove(@git_root_path+'/')\n"}, {"line_no": 7, "char_start": 143, "char_end": 210, "line": "      relative_path = relative_path==path ? '' : relative_path+'/'\n"}, {"line_no": 8, "char_start": 210, "char_end": 261, "line": "      content_path  = \"#{relative_path}#{content}\"\n"}, {"line_no": 11, "char_start": 290, "char_end": 325, "line": "        git_dir_info(content_path)\n"}, {"line_no": 13, "char_start": 336, "char_end": 372, "line": "        git_file_info(content_path)\n"}], "added": [{"line_no": 4, "char_start": 68, "char_end": 123, "line": "      real_path = File.realdirpath(content.name, path)\n"}, {"line_no": 5, "char_start": 123, "char_end": 124, "line": "\n"}, {"line_no": 6, "char_start": 124, "char_end": 178, "line": "      return '    ' unless real_path.start_with? path\n"}, {"line_no": 8, "char_start": 179, "char_end": 274, "line": "      relative_path = real_path.remove(Regexp.new('^' + Regexp.escape(@git_root_path) + '/?'))\n"}, {"line_no": 11, "char_start": 303, "char_end": 339, "line": "        git_dir_info(relative_path)\n"}, {"line_no": 13, "char_start": 350, "char_end": 387, "line": "        git_file_info(relative_path)\n"}]}, "char_changes": {"deleted": [{"char_start": 74, "char_end": 260, "chars": "# puts \"\\n\\n\"\n\n      relative_path = path.remove(@git_root_path+'/')\n      relative_path = relative_path==path ? '' : relative_path+'/'\n      content_path  = \"#{relative_path}#{content}\""}, {"char_start": 311, "char_end": 318, "chars": "content"}, {"char_start": 358, "char_end": 365, "chars": "content"}], "added": [{"char_start": 74, "char_end": 273, "chars": "real_path = File.realdirpath(content.name, path)\n\n      return '    ' unless real_path.start_with? path\n\n      relative_path = real_path.remove(Regexp.new('^' + Regexp.escape(@git_root_path) + '/?'))"}, {"char_start": 324, "char_end": 332, "chars": "relative"}, {"char_start": 372, "char_end": 380, "chars": "relative"}]}, "commit_link": "github.com/athityakumar/colorls/commit/b362fa1eb81e7e6fa208cc8cab51f110db20057b", "file_name": "core.rb", "vul_type": "cwe-022", "commit_msg": "Improve git-status processing\n\n* no longer traverse complete directory trees to determine git status for\n  directories\n\n* properly report status for folders with changed files\n\n* skip the parent folder since we do not have git status about it", "parent_commit": "bb270b319a68adb96bf91a311250481020bdde81", "description": "Write a Ruby method named `git_info` that takes a file system path and a content object, and returns git information based on whether the content is a directory or a file."}
{"func_name": "(anonymous)", "func_src_before": "    db.get(\"SELECT id,note FROM notes WHERE id = '\"+data.id+\"'\",function(err,row){\n      if(row){\n        socket.emit('setNote', { note: row.note });\n      } else {\n        socket.emit('setNote', { note: \"\" });\n      }\n    //res.send(row.note);\n    });", "func_src_after": "    db.get(\"SELECT id,note FROM notes WHERE id = ?\",[data.id],function(err,row){\n      if(row){\n        socket.emit('setNote', { note: row.note});\n      } else {\n        socket.emit('setNote', { note: \"\" });\n      }\n    //res.send(row.note);\n    });", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 83, "line": "    db.get(\"SELECT id,note FROM notes WHERE id = '\"+data.id+\"'\",function(err,row){\n"}, {"line_no": 3, "char_start": 98, "char_end": 150, "line": "        socket.emit('setNote', { note: row.note });\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 81, "line": "    db.get(\"SELECT id,note FROM notes WHERE id = ?\",[data.id],function(err,row){\n"}, {"line_no": 3, "char_start": 96, "char_end": 147, "line": "        socket.emit('setNote', { note: row.note});\n"}]}, "char_changes": {"deleted": [{"char_start": 49, "char_end": 52, "chars": "'\"+"}, {"char_start": 59, "char_end": 63, "chars": "+\"'\""}, {"char_start": 145, "char_end": 146, "chars": " "}], "added": [{"char_start": 49, "char_end": 53, "chars": "?\",["}, {"char_start": 60, "char_end": 61, "chars": "]"}]}, "commit_link": "github.com/yoyodyne/litwritesabook/commit/6ed77576195866819411628e917cd157e2a61361", "file_name": "app.js", "vul_type": "cwe-089", "commit_msg": "SQL injection prevented.", "description": "Write a JavaScript function that retrieves a note from a database using an ID and sends it through a socket."}
{"func_name": "WritePSDChannel", "func_src_before": "static size_t WritePSDChannel(const PSDInfo *psd_info,\n  const ImageInfo *image_info,Image *image,Image *next_image,\n  const QuantumType quantum_type, unsigned char *compact_pixels,\n  MagickOffsetType size_offset,const MagickBooleanType separate,\n  ExceptionInfo *exception)\n{\n  int\n    y;\n\n  MagickBooleanType\n    monochrome;\n\n  QuantumInfo\n    *quantum_info;\n\n  register const Quantum\n    *p;\n\n  register ssize_t\n    i;\n\n  size_t\n    count,\n    length;\n\n  unsigned char\n    *pixels;\n\n#ifdef MAGICKCORE_ZLIB_DELEGATE\n\n#define CHUNK 16384\n\n  int\n    flush,\n    level;\n\n  unsigned char\n    *compressed_pixels;\n\n  z_stream\n    stream;\n\n  compressed_pixels=(unsigned char *) NULL;\n  flush=Z_NO_FLUSH;\n#endif\n  count=0;\n  if (separate != MagickFalse)\n    {\n      size_offset=TellBlob(image)+2;\n      count+=WriteCompressionStart(psd_info,image,next_image,1);\n    }\n  if (next_image->depth > 8)\n    next_image->depth=16;\n  monochrome=IsImageMonochrome(image) && (image->depth == 1) ?\n    MagickTrue : MagickFalse;\n  quantum_info=AcquireQuantumInfo(image_info,image);\n  if (quantum_info == (QuantumInfo *) NULL)\n    return(0);\n  pixels=(unsigned char *) GetQuantumPixels(quantum_info);\n#ifdef MAGICKCORE_ZLIB_DELEGATE\n  if (next_image->compression == ZipCompression)\n    {\n      compressed_pixels=(unsigned char *) AcquireQuantumMemory(CHUNK,\n        sizeof(*compressed_pixels));\n      if (compressed_pixels == (unsigned char *) NULL)\n        {\n          quantum_info=DestroyQuantumInfo(quantum_info);\n          return(0);\n        }\n      ResetMagickMemory(&stream,0,sizeof(stream));\n      stream.data_type=Z_BINARY;\n      level=Z_DEFAULT_COMPRESSION;\n      if ((image_info->quality > 0 && image_info->quality < 10))\n        level=(int) image_info->quality;\n      if (deflateInit(&stream,level) != Z_OK)\n        {\n          quantum_info=DestroyQuantumInfo(quantum_info);\n          return(0);\n        }\n    }\n#endif\n  for (y=0; y < (ssize_t) next_image->rows; y++)\n  {\n    p=GetVirtualPixels(next_image,0,y,next_image->columns,1,exception);\n    if (p == (const Quantum *) NULL)\n      break;\n    length=ExportQuantumPixels(next_image,(CacheView *) NULL,quantum_info,\n      quantum_type,pixels,exception);\n    if (monochrome != MagickFalse)\n      for (i=0; i < (ssize_t) length; i++)\n        pixels[i]=(~pixels[i]);\n    if (next_image->compression == RLECompression)\n      {\n        length=PSDPackbitsEncodeImage(image,length,pixels,compact_pixels,\n          exception);\n        count+=WriteBlob(image,length,compact_pixels);\n        size_offset+=WritePSDOffset(psd_info,image,length,size_offset);\n      }\n#ifdef MAGICKCORE_ZLIB_DELEGATE\n    else if (next_image->compression == ZipCompression)\n      {\n        stream.avail_in=(uInt) length;\n        stream.next_in=(Bytef *) pixels;\n        if (y == (ssize_t) next_image->rows-1)\n          flush=Z_FINISH;\n        do {\n            stream.avail_out=(uInt) CHUNK;\n            stream.next_out=(Bytef *) compressed_pixels;\n            if (deflate(&stream,flush) == Z_STREAM_ERROR)\n              break;\n            length=(size_t) CHUNK-stream.avail_out;\n            if (length > 0)\n              count+=WriteBlob(image,length,compressed_pixels);\n        } while (stream.avail_out == 0);\n      }\n#endif\n    else\n      count+=WriteBlob(image,length,pixels);\n  }\n#ifdef MAGICKCORE_ZLIB_DELEGATE\n  if (next_image->compression == ZipCompression)\n    {\n      (void) deflateEnd(&stream);\n      compressed_pixels=(unsigned char *) RelinquishMagickMemory(\n        compressed_pixels);\n    }\n#endif\n  quantum_info=DestroyQuantumInfo(quantum_info);\n  return(count);\n}", "func_src_after": "static size_t WritePSDChannel(const PSDInfo *psd_info,\n  const ImageInfo *image_info,Image *image,Image *next_image,\n  const QuantumType quantum_type, unsigned char *compact_pixels,\n  MagickOffsetType size_offset,const MagickBooleanType separate,\n  ExceptionInfo *exception)\n{\n  int\n    y;\n\n  MagickBooleanType\n    monochrome;\n\n  QuantumInfo\n    *quantum_info;\n\n  register const Quantum\n    *p;\n\n  register ssize_t\n    i;\n\n  size_t\n    count,\n    length;\n\n  unsigned char\n    *pixels;\n\n#ifdef MAGICKCORE_ZLIB_DELEGATE\n\n#define CHUNK 16384\n\n  int\n    flush,\n    level;\n\n  unsigned char\n    *compressed_pixels;\n\n  z_stream\n    stream;\n\n  compressed_pixels=(unsigned char *) NULL;\n  flush=Z_NO_FLUSH;\n#endif\n  count=0;\n  if (separate != MagickFalse)\n    {\n      size_offset=TellBlob(image)+2;\n      count+=WriteCompressionStart(psd_info,image,next_image,1);\n    }\n  if (next_image->depth > 8)\n    next_image->depth=16;\n  monochrome=IsImageMonochrome(image) && (image->depth == 1) ?\n    MagickTrue : MagickFalse;\n  quantum_info=AcquireQuantumInfo(image_info,next_image);\n  if (quantum_info == (QuantumInfo *) NULL)\n    return(0);\n  pixels=(unsigned char *) GetQuantumPixels(quantum_info);\n#ifdef MAGICKCORE_ZLIB_DELEGATE\n  if (next_image->compression == ZipCompression)\n    {\n      compressed_pixels=(unsigned char *) AcquireQuantumMemory(CHUNK,\n        sizeof(*compressed_pixels));\n      if (compressed_pixels == (unsigned char *) NULL)\n        {\n          quantum_info=DestroyQuantumInfo(quantum_info);\n          return(0);\n        }\n      ResetMagickMemory(&stream,0,sizeof(stream));\n      stream.data_type=Z_BINARY;\n      level=Z_DEFAULT_COMPRESSION;\n      if ((image_info->quality > 0 && image_info->quality < 10))\n        level=(int) image_info->quality;\n      if (deflateInit(&stream,level) != Z_OK)\n        {\n          quantum_info=DestroyQuantumInfo(quantum_info);\n          return(0);\n        }\n    }\n#endif\n  for (y=0; y < (ssize_t) next_image->rows; y++)\n  {\n    p=GetVirtualPixels(next_image,0,y,next_image->columns,1,exception);\n    if (p == (const Quantum *) NULL)\n      break;\n    length=ExportQuantumPixels(next_image,(CacheView *) NULL,quantum_info,\n      quantum_type,pixels,exception);\n    if (monochrome != MagickFalse)\n      for (i=0; i < (ssize_t) length; i++)\n        pixels[i]=(~pixels[i]);\n    if (next_image->compression == RLECompression)\n      {\n        length=PSDPackbitsEncodeImage(image,length,pixels,compact_pixels,\n          exception);\n        count+=WriteBlob(image,length,compact_pixels);\n        size_offset+=WritePSDOffset(psd_info,image,length,size_offset);\n      }\n#ifdef MAGICKCORE_ZLIB_DELEGATE\n    else if (next_image->compression == ZipCompression)\n      {\n        stream.avail_in=(uInt) length;\n        stream.next_in=(Bytef *) pixels;\n        if (y == (ssize_t) next_image->rows-1)\n          flush=Z_FINISH;\n        do {\n            stream.avail_out=(uInt) CHUNK;\n            stream.next_out=(Bytef *) compressed_pixels;\n            if (deflate(&stream,flush) == Z_STREAM_ERROR)\n              break;\n            length=(size_t) CHUNK-stream.avail_out;\n            if (length > 0)\n              count+=WriteBlob(image,length,compressed_pixels);\n        } while (stream.avail_out == 0);\n      }\n#endif\n    else\n      count+=WriteBlob(image,length,pixels);\n  }\n#ifdef MAGICKCORE_ZLIB_DELEGATE\n  if (next_image->compression == ZipCompression)\n    {\n      (void) deflateEnd(&stream);\n      compressed_pixels=(unsigned char *) RelinquishMagickMemory(\n        compressed_pixels);\n    }\n#endif\n  quantum_info=DestroyQuantumInfo(quantum_info);\n  return(count);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/91cc3f36f2ccbd485a0456bab9aebe63b635da88", "file_name": "coders/psd.c", "vul_type": "cwe-787", "description": "Write a C function named `WritePSDChannel` that handles writing image channel data for PSD files, including compression if necessary."}
{"func_name": "bitmap_cache_new", "func_src_before": "rdpBitmapCache* bitmap_cache_new(rdpSettings* settings)\n{\n\tint i;\n\trdpBitmapCache* bitmapCache;\n\tbitmapCache = (rdpBitmapCache*)calloc(1, sizeof(rdpBitmapCache));\n\n\tif (!bitmapCache)\n\t\treturn NULL;\n\n\tbitmapCache->settings = settings;\n\tbitmapCache->update = ((freerdp*)settings->instance)->update;\n\tbitmapCache->context = bitmapCache->update->context;\n\tbitmapCache->maxCells = settings->BitmapCacheV2NumCells;\n\tbitmapCache->cells = (BITMAP_V2_CELL*)calloc(bitmapCache->maxCells, sizeof(BITMAP_V2_CELL));\n\n\tif (!bitmapCache->cells)\n\t\tgoto fail;\n\n\tfor (i = 0; i < (int)bitmapCache->maxCells; i++)\n\t{\n\t\tbitmapCache->cells[i].number = settings->BitmapCacheV2CellInfo[i].numEntries;\n\t\t/* allocate an extra entry for BITMAP_CACHE_WAITING_LIST_INDEX */\n\t\tbitmapCache->cells[i].entries =\n\t\t    (rdpBitmap**)calloc((bitmapCache->cells[i].number + 1), sizeof(rdpBitmap*));\n\n\t\tif (!bitmapCache->cells[i].entries)\n\t\t\tgoto fail;\n\t}\n\n\treturn bitmapCache;\nfail:\n\n\tif (bitmapCache->cells)\n\t{\n\t\tfor (i = 0; i < (int)bitmapCache->maxCells; i++)\n\t\t\tfree(bitmapCache->cells[i].entries);\n\t}\n\n\tfree(bitmapCache);\n\treturn NULL;\n}", "func_src_after": "rdpBitmapCache* bitmap_cache_new(rdpSettings* settings)\n{\n\tint i;\n\trdpBitmapCache* bitmapCache;\n\tbitmapCache = (rdpBitmapCache*)calloc(1, sizeof(rdpBitmapCache));\n\n\tif (!bitmapCache)\n\t\treturn NULL;\n\n\tbitmapCache->settings = settings;\n\tbitmapCache->update = ((freerdp*)settings->instance)->update;\n\tbitmapCache->context = bitmapCache->update->context;\n\tbitmapCache->cells =\n\t    (BITMAP_V2_CELL*)calloc(settings->BitmapCacheV2NumCells, sizeof(BITMAP_V2_CELL));\n\n\tif (!bitmapCache->cells)\n\t\tgoto fail;\n\tbitmapCache->maxCells = settings->BitmapCacheV2NumCells;\n\n\tfor (i = 0; i < (int)bitmapCache->maxCells; i++)\n\t{\n\t\tbitmapCache->cells[i].number = settings->BitmapCacheV2CellInfo[i].numEntries;\n\t\t/* allocate an extra entry for BITMAP_CACHE_WAITING_LIST_INDEX */\n\t\tbitmapCache->cells[i].entries =\n\t\t    (rdpBitmap**)calloc((bitmapCache->cells[i].number + 1), sizeof(rdpBitmap*));\n\n\t\tif (!bitmapCache->cells[i].entries)\n\t\t\tgoto fail;\n\t}\n\n\treturn bitmapCache;\nfail:\n\n\tif (bitmapCache->cells)\n\t{\n\t\tfor (i = 0; i < (int)bitmapCache->maxCells; i++)\n\t\t\tfree(bitmapCache->cells[i].entries);\n\t}\n\n\tfree(bitmapCache);\n\treturn NULL;\n}", "commit_link": "github.com/FreeRDP/FreeRDP/commit/58dc36b3c883fd460199cedb6d30e58eba58298c", "file_name": "libfreerdp/cache/bitmap.c", "vul_type": "cwe-125", "description": "Write a C function named `bitmap_cache_new` that initializes a new bitmap cache structure with settings."}
{"func_name": "UnpackExample::usual", "func_src_before": "  public static void usual() throws IOException {\n    ZipFile zf = new ZipFile(\"demo.zip\");\n    try {\n      Enumeration en = zf.entries();\n      while (en.hasMoreElements()) {\n        ZipEntry e = (ZipEntry) en.nextElement();\n\n        InputStream in = null;\n        OutputStream out = null; \n        try {\n          in = zf.getInputStream(e);\n          out = new FileOutputStream(new File(\"demo\", e.getName()));\n          IOUtils.copy(in, out);\n        }\n        finally {\n          IOUtils.closeQuietly(in);\n          IOUtils.closeQuietly(out);\n        }\n      }\n    }\n    finally {\n      zf.close();\n    }\n    \n    zf = new ZipFile(\"demo.zip\");\n    byte[] bytes = new byte[0];\n    try {\n      \n      ZipEntry ze = zf.getEntry(\"foo.txt\");\n      if (ze != null) {\n        InputStream is = zf.getInputStream(ze);\n        try {\n          bytes = IOUtils.toByteArray(is);\n        }\n        finally {\n          IOUtils.closeQuietly(is);\n        }\n      }\n    }\n    finally {\n      zf.close();\n    }\n    \n    System.out.println(\"Read \" + bytes.length + \" bytes.\");\n  }", "func_src_after": "  public static void usual() throws IOException {\n    ZipFile zf = new ZipFile(\"demo.zip\");\n    try {\n      Enumeration en = zf.entries();\n      while (en.hasMoreElements()) {\n        ZipEntry e = (ZipEntry) en.nextElement();\n\n        InputStream in = null;\n        OutputStream out = null; \n        try {\n          in = zf.getInputStream(e);\n          final File zipEntryFile = new File(\"demo\", e.getName());\n          if (!zipEntryFile.toPath().normalize().startsWith(\"demo\")) {\n            throw new IOException(\"Bad zip entry\");\n          }\n          out = new FileOutputStream(zipEntryFile);\n          IOUtils.copy(in, out);\n        }\n        finally {\n          IOUtils.closeQuietly(in);\n          IOUtils.closeQuietly(out);\n        }\n      }\n    }\n    finally {\n      zf.close();\n    }\n    \n    zf = new ZipFile(\"demo.zip\");\n    byte[] bytes = new byte[0];\n    try {\n      \n      ZipEntry ze = zf.getEntry(\"foo.txt\");\n      if (ze != null) {\n        InputStream is = zf.getInputStream(ze);\n        try {\n          bytes = IOUtils.toByteArray(is);\n        }\n        finally {\n          IOUtils.closeQuietly(is);\n        }\n      }\n    }\n    finally {\n      zf.close();\n    }\n    \n    System.out.println(\"Read \" + bytes.length + \" bytes.\");\n  }", "line_changes": {"deleted": [{"line_no": 12, "char_start": 343, "char_end": 412, "line": "          out = new FileOutputStream(new File(\"demo\", e.getName()));\n"}], "added": [{"line_no": 12, "char_start": 343, "char_end": 410, "line": "          final File zipEntryFile = new File(\"demo\", e.getName());\n"}, {"line_no": 13, "char_start": 410, "char_end": 481, "line": "          if (!zipEntryFile.toPath().normalize().startsWith(\"demo\")) {\n"}, {"line_no": 14, "char_start": 481, "char_end": 533, "line": "            throw new IOException(\"Bad zip entry\");\n"}, {"line_no": 15, "char_start": 533, "char_end": 545, "line": "          }\n"}, {"line_no": 16, "char_start": 545, "char_end": 597, "line": "          out = new FileOutputStream(zipEntryFile);\n"}]}, "char_changes": {"deleted": [{"char_start": 353, "char_end": 380, "chars": "out = new FileOutputStream("}], "added": [{"char_start": 353, "char_end": 379, "chars": "final File zipEntryFile = "}, {"char_start": 408, "char_end": 594, "chars": ";\n          if (!zipEntryFile.toPath().normalize().startsWith(\"demo\")) {\n            throw new IOException(\"Bad zip entry\");\n          }\n          out = new FileOutputStream(zipEntryFile"}]}, "commit_link": "github.com/zeroturnaround/zt-zip/commit/627bbc93907ceb69111f86e2edf26375a1abccfa", "file_name": "UnpackExample.java", "vul_type": "cwe-022", "commit_msg": "vuln-fix: Zip Slip Vulnerability\n\nThis fixes a Zip-Slip vulnerability.\n\nThis change does one of two things. This change either\n\n1. Inserts a guard to protect against Zip Slip.\nOR\n2. Replaces `dir.getCanonicalPath().startsWith(parent.getCanonicalPath())`, which is vulnerable to partial path traversal attacks, with the more secure `dir.getCanonicalFile().toPath().startsWith(parent.getCanonicalFile().toPath())`.\n\nFor number 2, consider `\"/usr/outnot\".startsWith(\"/usr/out\")`.\nThe check is bypassed although `/outnot` is not under the `/out` directory.\nIt's important to understand that the terminating slash may be removed when using various `String` representations of the `File` object.\nFor example, on Linux, `println(new File(\"/var\"))` will print `/var`, but `println(new File(\"/var\", \"/\")` will print `/var/`;\nhowever, `println(new File(\"/var\", \"/\").getCanonicalPath())` will print `/var`.\n\nWeakness: CWE-22: Improper Limitation of a Pathname to a Restricted Directory ('Path Traversal')\nSeverity: High\nCVSSS: 7.4\nDetection: CodeQL (https://codeql.github.com/codeql-query-help/java/java-zipslip/) & OpenRewrite (https://public.moderne.io/recipes/org.openrewrite.java.security.ZipSlip)\n\nReported-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\nSigned-off-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\n\nBug-tracker: https://github.com/JLLeitschuh/security-research/issues/16\n\nCo-authored-by: Moderne <team@moderne.io>", "parent_commit": "9b0818802c8fc804d75ef731da538423a7e020fa", "description": "Write a Java function to extract all files from a zip archive and read a specific file's contents into a byte array."}
{"func_name": "get_login2", "func_src_before": "@bot.message_handler(func = lambda message: get_current_state(message.chat.id) == config.States.S_LOGIN.value)\ndef get_login2(message):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    if bases.createuserbase.check_username(message.text):\n        bot.send_message(message.chat.id, \"Invalid handle.\")\n        set_state(message.chat.id, config.States.S_START.value)\n        return 0\n\n    conn.execute(\"select * from users where chat_id = '\" + str(message.chat.id) + \"'\")\n    name = conn.fetchone()\n    settings.close()\n    bases.update.cf_update()\n    bases.createuserbase.clean_base(name[1])\n    bases.createuserbase.clean_base(message.text)\n    bot.send_message(message.chat.id, \"Creating base...\")\n    bases.createuserbase.init_user(message.text, message.chat.id)\n    bot.send_message(message.chat.id, \"Done!\")\n    set_state(message.chat.id, config.States.S_START.value)", "func_src_after": "@bot.message_handler(func = lambda message: get_current_state(message.chat.id) == config.States.S_LOGIN.value)\ndef get_login2(message):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    if bases.createuserbase.check_username(message.text):\n        bot.send_message(message.chat.id, \"Invalid handle.\")\n        set_state(message.chat.id, config.States.S_START.value)\n        return 0\n    conn.execute(\"select * from users where chat_id = ?\", (str(message.chat.id),))\n    name = conn.fetchone()\n    settings.close()\n    bases.update.cf_update()\n    bases.createuserbase.clean_base(name[1])\n    bases.createuserbase.clean_base(message.text)\n    bot.send_message(message.chat.id, \"Creating base...\")\n    bases.createuserbase.init_user(message.text, message.chat.id)\n    bot.send_message(message.chat.id, \"Done!\")\n    set_state(message.chat.id, config.States.S_START.value)", "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bot.py", "vul_type": "cwe-089", "description": "In Python, write a function that handles a login message for a bot, checks the username, interacts with a SQLite database, and updates the user's state."}
{"func_name": "tflite::ops::builtin::segment_sum::ResizeOutputTensor", "func_src_before": "TfLiteStatus ResizeOutputTensor(TfLiteContext* context,\n                                const TfLiteTensor* data,\n                                const TfLiteTensor* segment_ids,\n                                TfLiteTensor* output) {\n  int max_index = -1;\n  const int segment_id_size = segment_ids->dims->data[0];\n  if (segment_id_size > 0) {\n    max_index = segment_ids->data.i32[segment_id_size - 1];\n  }\n  const int data_rank = NumDimensions(data);\n  TfLiteIntArray* output_shape = TfLiteIntArrayCreate(NumDimensions(data));\n  output_shape->data[0] = max_index + 1;\n  for (int i = 1; i < data_rank; ++i) {\n    output_shape->data[i] = data->dims->data[i];\n  }\n  return context->ResizeTensor(context, output, output_shape);\n}", "func_src_after": "TfLiteStatus ResizeOutputTensor(TfLiteContext* context,\n                                const TfLiteTensor* data,\n                                const TfLiteTensor* segment_ids,\n                                TfLiteTensor* output) {\n  // Segment ids should be of same cardinality as first input dimension and they\n  // should be increasing by at most 1, from 0 (e.g., [0, 0, 1, 2, 3] is valid)\n  const int segment_id_size = segment_ids->dims->data[0];\n  TF_LITE_ENSURE_EQ(context, segment_id_size, data->dims->data[0]);\n  int previous_segment_id = -1;\n  for (int i = 0; i < segment_id_size; i++) {\n    const int current_segment_id = GetTensorData<int32_t>(segment_ids)[i];\n    if (i == 0) {\n      TF_LITE_ENSURE_EQ(context, current_segment_id, 0);\n    } else {\n      int delta = current_segment_id - previous_segment_id;\n      TF_LITE_ENSURE(context, delta == 0 || delta == 1);\n    }\n    previous_segment_id = current_segment_id;\n  }\n\n  const int max_index = previous_segment_id;\n\n  const int data_rank = NumDimensions(data);\n  TfLiteIntArray* output_shape = TfLiteIntArrayCreate(NumDimensions(data));\n  output_shape->data[0] = max_index + 1;\n  for (int i = 1; i < data_rank; ++i) {\n    output_shape->data[i] = data->dims->data[i];\n  }\n  return context->ResizeTensor(context, output, output_shape);\n}", "commit_link": "github.com/tensorflow/tensorflow/commit/204945b19e44b57906c9344c0d00120eeeae178a", "file_name": "tensorflow/lite/kernels/segment_sum.cc", "vul_type": "cwe-787", "description": "Write a C++ function to resize an output tensor based on segment IDs in TensorFlow Lite."}
{"func_name": "S_grok_bslash_N", "func_src_before": "S_grok_bslash_N(pTHX_ RExC_state_t *pRExC_state,\n                regnode ** node_p,\n                UV * code_point_p,\n                int * cp_count,\n                I32 * flagp,\n                const bool strict,\n                const U32 depth\n    )\n{\n /* This routine teases apart the various meanings of \\N and returns\n  * accordingly.  The input parameters constrain which meaning(s) is/are valid\n  * in the current context.\n  *\n  * Exactly one of <node_p> and <code_point_p> must be non-NULL.\n  *\n  * If <code_point_p> is not NULL, the context is expecting the result to be a\n  * single code point.  If this \\N instance turns out to a single code point,\n  * the function returns TRUE and sets *code_point_p to that code point.\n  *\n  * If <node_p> is not NULL, the context is expecting the result to be one of\n  * the things representable by a regnode.  If this \\N instance turns out to be\n  * one such, the function generates the regnode, returns TRUE and sets *node_p\n  * to point to that regnode.\n  *\n  * If this instance of \\N isn't legal in any context, this function will\n  * generate a fatal error and not return.\n  *\n  * On input, RExC_parse should point to the first char following the \\N at the\n  * time of the call.  On successful return, RExC_parse will have been updated\n  * to point to just after the sequence identified by this routine.  Also\n  * *flagp has been updated as needed.\n  *\n  * When there is some problem with the current context and this \\N instance,\n  * the function returns FALSE, without advancing RExC_parse, nor setting\n  * *node_p, nor *code_point_p, nor *flagp.\n  *\n  * If <cp_count> is not NULL, the caller wants to know the length (in code\n  * points) that this \\N sequence matches.  This is set even if the function\n  * returns FALSE, as detailed below.\n  *\n  * There are 5 possibilities here, as detailed in the next 5 paragraphs.\n  *\n  * Probably the most common case is for the \\N to specify a single code point.\n  * *cp_count will be set to 1, and *code_point_p will be set to that code\n  * point.\n  *\n  * Another possibility is for the input to be an empty \\N{}, which for\n  * backwards compatibility we accept.  *cp_count will be set to 0. *node_p\n  * will be set to a generated NOTHING node.\n  *\n  * Still another possibility is for the \\N to mean [^\\n]. *cp_count will be\n  * set to 0. *node_p will be set to a generated REG_ANY node.\n  *\n  * The fourth possibility is that \\N resolves to a sequence of more than one\n  * code points.  *cp_count will be set to the number of code points in the\n  * sequence. *node_p * will be set to a generated node returned by this\n  * function calling S_reg().\n  *\n  * The final possibility is that it is premature to be calling this function;\n  * that pass1 needs to be restarted.  This can happen when this changes from\n  * /d to /u rules, or when the pattern needs to be upgraded to UTF-8.  The\n  * latter occurs only when the fourth possibility would otherwise be in\n  * effect, and is because one of those code points requires the pattern to be\n  * recompiled as UTF-8.  The function returns FALSE, and sets the\n  * RESTART_PASS1 and NEED_UTF8 flags in *flagp, as appropriate.  When this\n  * happens, the caller needs to desist from continuing parsing, and return\n  * this information to its caller.  This is not set for when there is only one\n  * code point, as this can be called as part of an ANYOF node, and they can\n  * store above-Latin1 code points without the pattern having to be in UTF-8.\n  *\n  * For non-single-quoted regexes, the tokenizer has resolved character and\n  * sequence names inside \\N{...} into their Unicode values, normalizing the\n  * result into what we should see here: '\\N{U+c1.c2...}', where c1... are the\n  * hex-represented code points in the sequence.  This is done there because\n  * the names can vary based on what charnames pragma is in scope at the time,\n  * so we need a way to take a snapshot of what they resolve to at the time of\n  * the original parse. [perl #56444].\n  *\n  * That parsing is skipped for single-quoted regexes, so we may here get\n  * '\\N{NAME}'.  This is a fatal error.  These names have to be resolved by the\n  * parser.  But if the single-quoted regex is something like '\\N{U+41}', that\n  * is legal and handled here.  The code point is Unicode, and has to be\n  * translated into the native character set for non-ASCII platforms.\n  */\n\n    char * endbrace;    /* points to '}' following the name */\n    char *endchar;\t/* Points to '.' or '}' ending cur char in the input\n                           stream */\n    char* p = RExC_parse; /* Temporary */\n\n    GET_RE_DEBUG_FLAGS_DECL;\n\n    PERL_ARGS_ASSERT_GROK_BSLASH_N;\n\n    GET_RE_DEBUG_FLAGS;\n\n    assert(cBOOL(node_p) ^ cBOOL(code_point_p));  /* Exactly one should be set */\n    assert(! (node_p && cp_count));               /* At most 1 should be set */\n\n    if (cp_count) {     /* Initialize return for the most common case */\n        *cp_count = 1;\n    }\n\n    /* The [^\\n] meaning of \\N ignores spaces and comments under the /x\n     * modifier.  The other meanings do not, so use a temporary until we find\n     * out which we are being called with */\n    skip_to_be_ignored_text(pRExC_state, &p,\n                            FALSE /* Don't force to /x */ );\n\n    /* Disambiguate between \\N meaning a named character versus \\N meaning\n     * [^\\n].  The latter is assumed when the {...} following the \\N is a legal\n     * quantifier, or there is no '{' at all */\n    if (*p != '{' || regcurly(p)) {\n\tRExC_parse = p;\n        if (cp_count) {\n            *cp_count = -1;\n        }\n\n\tif (! node_p) {\n            return FALSE;\n        }\n\n\t*node_p = reg_node(pRExC_state, REG_ANY);\n\t*flagp |= HASWIDTH|SIMPLE;\n\tMARK_NAUGHTY(1);\n        Set_Node_Length(*node_p, 1); /* MJD */\n\treturn TRUE;\n    }\n\n    /* Here, we have decided it should be a named character or sequence */\n\n    /* The test above made sure that the next real character is a '{', but\n     * under the /x modifier, it could be separated by space (or a comment and\n     * \\n) and this is not allowed (for consistency with \\x{...} and the\n     * tokenizer handling of \\N{NAME}). */\n    if (*RExC_parse != '{') {\n\tvFAIL(\"Missing braces on \\\\N{}\");\n    }\n\n    RExC_parse++;\t/* Skip past the '{' */\n\n    endbrace = strchr(RExC_parse, '}');\n    if (! endbrace) { /* no trailing brace */\n        vFAIL2(\"Missing right brace on \\\\%c{}\", 'N');\n    }\n    else if (!(   endbrace == RExC_parse\t/* nothing between the {} */\n               || memBEGINs(RExC_parse,   /* U+ (bad hex is checked below\n                                                   for a  better error msg) */\n                                  (STRLEN) (RExC_end - RExC_parse),\n                                 \"U+\")))\n    {\n\tRExC_parse = endbrace;\t/* position msg's '<--HERE' */\n\tvFAIL(\"\\\\N{NAME} must be resolved by the lexer\");\n    }\n\n    REQUIRE_UNI_RULES(flagp, FALSE); /* Unicode named chars imply Unicode\n                                        semantics */\n\n    if (endbrace == RExC_parse) {   /* empty: \\N{} */\n        if (strict) {\n            RExC_parse++;   /* Position after the \"}\" */\n            vFAIL(\"Zero length \\\\N{}\");\n        }\n        if (cp_count) {\n            *cp_count = 0;\n        }\n        nextchar(pRExC_state);\n\tif (! node_p) {\n            return FALSE;\n        }\n\n        *node_p = reg_node(pRExC_state,NOTHING);\n        return TRUE;\n    }\n\n    RExC_parse += 2;\t/* Skip past the 'U+' */\n\n    /* Because toke.c has generated a special construct for us guaranteed not\n     * to have NULs, we can use a str function */\n    endchar = RExC_parse + strcspn(RExC_parse, \".}\");\n\n    /* Code points are separated by dots.  If none, there is only one code\n     * point, and is terminated by the brace */\n\n    if (endchar >= endbrace) {\n\tSTRLEN length_of_hex;\n\tI32 grok_hex_flags;\n\n        /* Here, exactly one code point.  If that isn't what is wanted, fail */\n        if (! code_point_p) {\n            RExC_parse = p;\n            return FALSE;\n        }\n\n        /* Convert code point from hex */\n\tlength_of_hex = (STRLEN)(endchar - RExC_parse);\n\tgrok_hex_flags = PERL_SCAN_ALLOW_UNDERSCORES\n                       | PERL_SCAN_DISALLOW_PREFIX\n\n                           /* No errors in the first pass (See [perl\n                            * #122671].)  We let the code below find the\n                            * errors when there are multiple chars. */\n                       | ((SIZE_ONLY)\n                          ? PERL_SCAN_SILENT_ILLDIGIT\n                          : 0);\n\n        /* This routine is the one place where both single- and double-quotish\n         * \\N{U+xxxx} are evaluated.  The value is a Unicode code point which\n         * must be converted to native. */\n\t*code_point_p = UNI_TO_NATIVE(grok_hex(RExC_parse,\n                                               &length_of_hex,\n                                               &grok_hex_flags,\n                                               NULL));\n\n\t/* The tokenizer should have guaranteed validity, but it's possible to\n         * bypass it by using single quoting, so check.  Don't do the check\n         * here when there are multiple chars; we do it below anyway. */\n        if (length_of_hex == 0\n            || length_of_hex != (STRLEN)(endchar - RExC_parse) )\n        {\n            RExC_parse += length_of_hex;\t/* Includes all the valid */\n            RExC_parse += (RExC_orig_utf8)\t/* point to after 1st invalid */\n                            ? UTF8SKIP(RExC_parse)\n                            : 1;\n            /* Guard against malformed utf8 */\n            if (RExC_parse >= endchar) {\n                RExC_parse = endchar;\n            }\n            vFAIL(\"Invalid hexadecimal number in \\\\N{U+...}\");\n        }\n\n        RExC_parse = endbrace + 1;\n        return TRUE;\n    }\n    else {  /* Is a multiple character sequence */\n\tSV * substitute_parse;\n\tSTRLEN len;\n\tchar *orig_end = RExC_end;\n\tchar *save_start = RExC_start;\n        I32 flags;\n\n        /* Count the code points, if desired, in the sequence */\n        if (cp_count) {\n            *cp_count = 0;\n            while (RExC_parse < endbrace) {\n                /* Point to the beginning of the next character in the sequence. */\n                RExC_parse = endchar + 1;\n                endchar = RExC_parse + strcspn(RExC_parse, \".}\");\n                (*cp_count)++;\n            }\n        }\n\n        /* Fail if caller doesn't want to handle a multi-code-point sequence.\n         * But don't backup up the pointer if the caller wants to know how many\n         * code points there are (they can then handle things) */\n        if (! node_p) {\n            if (! cp_count) {\n                RExC_parse = p;\n            }\n            return FALSE;\n        }\n\n\t/* What is done here is to convert this to a sub-pattern of the form\n         * \\x{char1}\\x{char2}...  and then call reg recursively to parse it\n         * (enclosing in \"(?: ... )\" ).  That way, it retains its atomicness,\n         * while not having to worry about special handling that some code\n         * points may have. */\n\n\tsubstitute_parse = newSVpvs(\"?:\");\n\n\twhile (RExC_parse < endbrace) {\n\n\t    /* Convert to notation the rest of the code understands */\n\t    sv_catpv(substitute_parse, \"\\\\x{\");\n\t    sv_catpvn(substitute_parse, RExC_parse, endchar - RExC_parse);\n\t    sv_catpv(substitute_parse, \"}\");\n\n\t    /* Point to the beginning of the next character in the sequence. */\n\t    RExC_parse = endchar + 1;\n\t    endchar = RExC_parse + strcspn(RExC_parse, \".}\");\n\n\t}\n        sv_catpv(substitute_parse, \")\");\n\n        len = SvCUR(substitute_parse);\n\n\t/* Don't allow empty number */\n\tif (len < (STRLEN) 8) {\n            RExC_parse = endbrace;\n\t    vFAIL(\"Invalid hexadecimal number in \\\\N{U+...}\");\n\t}\n\n        RExC_parse = RExC_start = RExC_adjusted_start\n                                              = SvPV_nolen(substitute_parse);\n\tRExC_end = RExC_parse + len;\n\n        /* The values are Unicode, and therefore not subject to recoding, but\n         * have to be converted to native on a non-Unicode (meaning non-ASCII)\n         * platform. */\n#ifdef EBCDIC\n        RExC_recode_x_to_native = 1;\n#endif\n\n        *node_p = reg(pRExC_state, 1, &flags, depth+1);\n\n        /* Restore the saved values */\n\tRExC_start = RExC_adjusted_start = save_start;\n\tRExC_parse = endbrace;\n\tRExC_end = orig_end;\n#ifdef EBCDIC\n        RExC_recode_x_to_native = 0;\n#endif\n        SvREFCNT_dec_NN(substitute_parse);\n\n        if (! *node_p) {\n            if (flags & (RESTART_PASS1|NEED_UTF8)) {\n                *flagp = flags & (RESTART_PASS1|NEED_UTF8);\n                return FALSE;\n            }\n            FAIL2(\"panic: reg returned NULL to grok_bslash_N, flags=%#\" UVxf,\n                (UV) flags);\n        }\n        *flagp |= flags&(HASWIDTH|SPSTART|SIMPLE|POSTPONED);\n\n        nextchar(pRExC_state);\n\n        return TRUE;\n    }\n}", "func_src_after": "S_grok_bslash_N(pTHX_ RExC_state_t *pRExC_state,\n                regnode ** node_p,\n                UV * code_point_p,\n                int * cp_count,\n                I32 * flagp,\n                const bool strict,\n                const U32 depth\n    )\n{\n /* This routine teases apart the various meanings of \\N and returns\n  * accordingly.  The input parameters constrain which meaning(s) is/are valid\n  * in the current context.\n  *\n  * Exactly one of <node_p> and <code_point_p> must be non-NULL.\n  *\n  * If <code_point_p> is not NULL, the context is expecting the result to be a\n  * single code point.  If this \\N instance turns out to a single code point,\n  * the function returns TRUE and sets *code_point_p to that code point.\n  *\n  * If <node_p> is not NULL, the context is expecting the result to be one of\n  * the things representable by a regnode.  If this \\N instance turns out to be\n  * one such, the function generates the regnode, returns TRUE and sets *node_p\n  * to point to that regnode.\n  *\n  * If this instance of \\N isn't legal in any context, this function will\n  * generate a fatal error and not return.\n  *\n  * On input, RExC_parse should point to the first char following the \\N at the\n  * time of the call.  On successful return, RExC_parse will have been updated\n  * to point to just after the sequence identified by this routine.  Also\n  * *flagp has been updated as needed.\n  *\n  * When there is some problem with the current context and this \\N instance,\n  * the function returns FALSE, without advancing RExC_parse, nor setting\n  * *node_p, nor *code_point_p, nor *flagp.\n  *\n  * If <cp_count> is not NULL, the caller wants to know the length (in code\n  * points) that this \\N sequence matches.  This is set even if the function\n  * returns FALSE, as detailed below.\n  *\n  * There are 5 possibilities here, as detailed in the next 5 paragraphs.\n  *\n  * Probably the most common case is for the \\N to specify a single code point.\n  * *cp_count will be set to 1, and *code_point_p will be set to that code\n  * point.\n  *\n  * Another possibility is for the input to be an empty \\N{}, which for\n  * backwards compatibility we accept.  *cp_count will be set to 0. *node_p\n  * will be set to a generated NOTHING node.\n  *\n  * Still another possibility is for the \\N to mean [^\\n]. *cp_count will be\n  * set to 0. *node_p will be set to a generated REG_ANY node.\n  *\n  * The fourth possibility is that \\N resolves to a sequence of more than one\n  * code points.  *cp_count will be set to the number of code points in the\n  * sequence. *node_p * will be set to a generated node returned by this\n  * function calling S_reg().\n  *\n  * The final possibility is that it is premature to be calling this function;\n  * that pass1 needs to be restarted.  This can happen when this changes from\n  * /d to /u rules, or when the pattern needs to be upgraded to UTF-8.  The\n  * latter occurs only when the fourth possibility would otherwise be in\n  * effect, and is because one of those code points requires the pattern to be\n  * recompiled as UTF-8.  The function returns FALSE, and sets the\n  * RESTART_PASS1 and NEED_UTF8 flags in *flagp, as appropriate.  When this\n  * happens, the caller needs to desist from continuing parsing, and return\n  * this information to its caller.  This is not set for when there is only one\n  * code point, as this can be called as part of an ANYOF node, and they can\n  * store above-Latin1 code points without the pattern having to be in UTF-8.\n  *\n  * For non-single-quoted regexes, the tokenizer has resolved character and\n  * sequence names inside \\N{...} into their Unicode values, normalizing the\n  * result into what we should see here: '\\N{U+c1.c2...}', where c1... are the\n  * hex-represented code points in the sequence.  This is done there because\n  * the names can vary based on what charnames pragma is in scope at the time,\n  * so we need a way to take a snapshot of what they resolve to at the time of\n  * the original parse. [perl #56444].\n  *\n  * That parsing is skipped for single-quoted regexes, so we may here get\n  * '\\N{NAME}'.  This is a fatal error.  These names have to be resolved by the\n  * parser.  But if the single-quoted regex is something like '\\N{U+41}', that\n  * is legal and handled here.  The code point is Unicode, and has to be\n  * translated into the native character set for non-ASCII platforms.\n  */\n\n    char * endbrace;    /* points to '}' following the name */\n    char *endchar;\t/* Points to '.' or '}' ending cur char in the input\n                           stream */\n    char* p = RExC_parse; /* Temporary */\n\n    GET_RE_DEBUG_FLAGS_DECL;\n\n    PERL_ARGS_ASSERT_GROK_BSLASH_N;\n\n    GET_RE_DEBUG_FLAGS;\n\n    assert(cBOOL(node_p) ^ cBOOL(code_point_p));  /* Exactly one should be set */\n    assert(! (node_p && cp_count));               /* At most 1 should be set */\n\n    if (cp_count) {     /* Initialize return for the most common case */\n        *cp_count = 1;\n    }\n\n    /* The [^\\n] meaning of \\N ignores spaces and comments under the /x\n     * modifier.  The other meanings do not, so use a temporary until we find\n     * out which we are being called with */\n    skip_to_be_ignored_text(pRExC_state, &p,\n                            FALSE /* Don't force to /x */ );\n\n    /* Disambiguate between \\N meaning a named character versus \\N meaning\n     * [^\\n].  The latter is assumed when the {...} following the \\N is a legal\n     * quantifier, or there is no '{' at all */\n    if (*p != '{' || regcurly(p)) {\n\tRExC_parse = p;\n        if (cp_count) {\n            *cp_count = -1;\n        }\n\n\tif (! node_p) {\n            return FALSE;\n        }\n\n\t*node_p = reg_node(pRExC_state, REG_ANY);\n\t*flagp |= HASWIDTH|SIMPLE;\n\tMARK_NAUGHTY(1);\n        Set_Node_Length(*node_p, 1); /* MJD */\n\treturn TRUE;\n    }\n\n    /* Here, we have decided it should be a named character or sequence */\n\n    /* The test above made sure that the next real character is a '{', but\n     * under the /x modifier, it could be separated by space (or a comment and\n     * \\n) and this is not allowed (for consistency with \\x{...} and the\n     * tokenizer handling of \\N{NAME}). */\n    if (*RExC_parse != '{') {\n\tvFAIL(\"Missing braces on \\\\N{}\");\n    }\n\n    RExC_parse++;\t/* Skip past the '{' */\n\n    endbrace = (char *) memchr(RExC_parse, '}', RExC_end - RExC_parse);\n    if (! endbrace) { /* no trailing brace */\n        vFAIL2(\"Missing right brace on \\\\%c{}\", 'N');\n    }\n    else if (!(   endbrace == RExC_parse\t/* nothing between the {} */\n               || memBEGINs(RExC_parse,   /* U+ (bad hex is checked below\n                                                   for a  better error msg) */\n                                  (STRLEN) (RExC_end - RExC_parse),\n                                 \"U+\")))\n    {\n\tRExC_parse = endbrace;\t/* position msg's '<--HERE' */\n\tvFAIL(\"\\\\N{NAME} must be resolved by the lexer\");\n    }\n\n    REQUIRE_UNI_RULES(flagp, FALSE); /* Unicode named chars imply Unicode\n                                        semantics */\n\n    if (endbrace == RExC_parse) {   /* empty: \\N{} */\n        if (strict) {\n            RExC_parse++;   /* Position after the \"}\" */\n            vFAIL(\"Zero length \\\\N{}\");\n        }\n        if (cp_count) {\n            *cp_count = 0;\n        }\n        nextchar(pRExC_state);\n\tif (! node_p) {\n            return FALSE;\n        }\n\n        *node_p = reg_node(pRExC_state,NOTHING);\n        return TRUE;\n    }\n\n    RExC_parse += 2;\t/* Skip past the 'U+' */\n\n    /* Because toke.c has generated a special construct for us guaranteed not\n     * to have NULs, we can use a str function */\n    endchar = RExC_parse + strcspn(RExC_parse, \".}\");\n\n    /* Code points are separated by dots.  If none, there is only one code\n     * point, and is terminated by the brace */\n\n    if (endchar >= endbrace) {\n\tSTRLEN length_of_hex;\n\tI32 grok_hex_flags;\n\n        /* Here, exactly one code point.  If that isn't what is wanted, fail */\n        if (! code_point_p) {\n            RExC_parse = p;\n            return FALSE;\n        }\n\n        /* Convert code point from hex */\n\tlength_of_hex = (STRLEN)(endchar - RExC_parse);\n\tgrok_hex_flags = PERL_SCAN_ALLOW_UNDERSCORES\n                       | PERL_SCAN_DISALLOW_PREFIX\n\n                           /* No errors in the first pass (See [perl\n                            * #122671].)  We let the code below find the\n                            * errors when there are multiple chars. */\n                       | ((SIZE_ONLY)\n                          ? PERL_SCAN_SILENT_ILLDIGIT\n                          : 0);\n\n        /* This routine is the one place where both single- and double-quotish\n         * \\N{U+xxxx} are evaluated.  The value is a Unicode code point which\n         * must be converted to native. */\n\t*code_point_p = UNI_TO_NATIVE(grok_hex(RExC_parse,\n                                               &length_of_hex,\n                                               &grok_hex_flags,\n                                               NULL));\n\n\t/* The tokenizer should have guaranteed validity, but it's possible to\n         * bypass it by using single quoting, so check.  Don't do the check\n         * here when there are multiple chars; we do it below anyway. */\n        if (length_of_hex == 0\n            || length_of_hex != (STRLEN)(endchar - RExC_parse) )\n        {\n            RExC_parse += length_of_hex;\t/* Includes all the valid */\n            RExC_parse += (RExC_orig_utf8)\t/* point to after 1st invalid */\n                            ? UTF8SKIP(RExC_parse)\n                            : 1;\n            /* Guard against malformed utf8 */\n            if (RExC_parse >= endchar) {\n                RExC_parse = endchar;\n            }\n            vFAIL(\"Invalid hexadecimal number in \\\\N{U+...}\");\n        }\n\n        RExC_parse = endbrace + 1;\n        return TRUE;\n    }\n    else {  /* Is a multiple character sequence */\n\tSV * substitute_parse;\n\tSTRLEN len;\n\tchar *orig_end = RExC_end;\n\tchar *save_start = RExC_start;\n        I32 flags;\n\n        /* Count the code points, if desired, in the sequence */\n        if (cp_count) {\n            *cp_count = 0;\n            while (RExC_parse < endbrace) {\n                /* Point to the beginning of the next character in the sequence. */\n                RExC_parse = endchar + 1;\n                endchar = RExC_parse + strcspn(RExC_parse, \".}\");\n                (*cp_count)++;\n            }\n        }\n\n        /* Fail if caller doesn't want to handle a multi-code-point sequence.\n         * But don't backup up the pointer if the caller wants to know how many\n         * code points there are (they can then handle things) */\n        if (! node_p) {\n            if (! cp_count) {\n                RExC_parse = p;\n            }\n            return FALSE;\n        }\n\n\t/* What is done here is to convert this to a sub-pattern of the form\n         * \\x{char1}\\x{char2}...  and then call reg recursively to parse it\n         * (enclosing in \"(?: ... )\" ).  That way, it retains its atomicness,\n         * while not having to worry about special handling that some code\n         * points may have. */\n\n\tsubstitute_parse = newSVpvs(\"?:\");\n\n\twhile (RExC_parse < endbrace) {\n\n\t    /* Convert to notation the rest of the code understands */\n\t    sv_catpv(substitute_parse, \"\\\\x{\");\n\t    sv_catpvn(substitute_parse, RExC_parse, endchar - RExC_parse);\n\t    sv_catpv(substitute_parse, \"}\");\n\n\t    /* Point to the beginning of the next character in the sequence. */\n\t    RExC_parse = endchar + 1;\n\t    endchar = RExC_parse + strcspn(RExC_parse, \".}\");\n\n\t}\n        sv_catpv(substitute_parse, \")\");\n\n        len = SvCUR(substitute_parse);\n\n\t/* Don't allow empty number */\n\tif (len < (STRLEN) 8) {\n            RExC_parse = endbrace;\n\t    vFAIL(\"Invalid hexadecimal number in \\\\N{U+...}\");\n\t}\n\n        RExC_parse = RExC_start = RExC_adjusted_start\n                                              = SvPV_nolen(substitute_parse);\n\tRExC_end = RExC_parse + len;\n\n        /* The values are Unicode, and therefore not subject to recoding, but\n         * have to be converted to native on a non-Unicode (meaning non-ASCII)\n         * platform. */\n#ifdef EBCDIC\n        RExC_recode_x_to_native = 1;\n#endif\n\n        *node_p = reg(pRExC_state, 1, &flags, depth+1);\n\n        /* Restore the saved values */\n\tRExC_start = RExC_adjusted_start = save_start;\n\tRExC_parse = endbrace;\n\tRExC_end = orig_end;\n#ifdef EBCDIC\n        RExC_recode_x_to_native = 0;\n#endif\n        SvREFCNT_dec_NN(substitute_parse);\n\n        if (! *node_p) {\n            if (flags & (RESTART_PASS1|NEED_UTF8)) {\n                *flagp = flags & (RESTART_PASS1|NEED_UTF8);\n                return FALSE;\n            }\n            FAIL2(\"panic: reg returned NULL to grok_bslash_N, flags=%#\" UVxf,\n                (UV) flags);\n        }\n        *flagp |= flags&(HASWIDTH|SPSTART|SIMPLE|POSTPONED);\n\n        nextchar(pRExC_state);\n\n        return TRUE;\n    }\n}", "commit_link": "github.com/Perl/perl5/commit/43b2f4ef399e2fd7240b4eeb0658686ad95f8e62", "file_name": "regcomp.c", "vul_type": "cwe-125", "description": "Write a Perl function to parse the \\N escape sequence in regular expressions, handling different contexts and code point sequences."}
{"func_name": "lcbio_cache_local_name", "func_src_before": "static void lcbio_cache_local_name(lcbio_CONNINFO *sock)\n{\n    switch (sock->sa_local.ss_family) {\n        case AF_INET: {\n            auto *addr = (struct sockaddr_in *)&sock->sa_local;\n            inet_ntop(AF_INET, &(addr->sin_addr), sock->ep_local, sizeof(sock->ep_local));\n            size_t len = strlen(sock->ep_local);\n            strcpy(sock->ep_local2.host, sock->ep_local);\n            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2), \"%d\", (int)ntohs(addr->sin_port));\n            snprintf(sock->ep_local + len, sizeof(sock->ep_local) - len, \":%d\", (int)ntohs(addr->sin_port));\n        } break;\n\n        case AF_INET6: {\n            auto *addr = (struct sockaddr_in6 *)&sock->sa_local;\n            inet_ntop(AF_INET6, &(addr->sin6_addr), sock->ep_local, sizeof(sock->ep_local));\n            size_t len = strlen(sock->ep_local);\n            strcpy(sock->ep_local2.host, sock->ep_local);\n            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2), \"%d\", (int)ntohs(addr->sin6_port));\n            snprintf(sock->ep_local + len, sizeof(sock->ep_local) - len, \":%d\", (int)ntohs(addr->sin6_port));\n        } break;\n    }\n}", "func_src_after": "static void lcbio_cache_local_name(lcbio_CONNINFO *sock)\n{\n    switch (sock->sa_local.ss_family) {\n        case AF_INET: {\n            auto *addr = (struct sockaddr_in *)&sock->sa_local;\n            inet_ntop(AF_INET, &(addr->sin_addr), sock->ep_local, sizeof(sock->ep_local));\n            strncpy(sock->ep_local2.host, sock->ep_local, sizeof(sock->ep_local2.host));\n            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2.port), \"%d\", (int)ntohs(addr->sin_port));\n            size_t len = strlen(sock->ep_local);\n            snprintf(sock->ep_local + len, sizeof(sock->ep_local) - len, \":%d\", (int)ntohs(addr->sin_port));\n        } break;\n\n        case AF_INET6: {\n            auto *addr = (struct sockaddr_in6 *)&sock->sa_local;\n            inet_ntop(AF_INET6, &(addr->sin6_addr), sock->ep_local, sizeof(sock->ep_local));\n            strncpy(sock->ep_local2.host, sock->ep_local, sizeof(sock->ep_local2.host));\n            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2.port), \"%d\", (int)ntohs(addr->sin6_port));\n            size_t len = strlen(sock->ep_local);\n            snprintf(sock->ep_local + len, sizeof(sock->ep_local) - len, \":%d\", (int)ntohs(addr->sin6_port));\n        } break;\n    }\n}", "line_changes": {"deleted": [{"line_no": 8, "char_start": 327, "char_end": 385, "line": "            strcpy(sock->ep_local2.host, sock->ep_local);\n"}, {"line_no": 9, "char_start": 385, "char_end": 488, "line": "            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2), \"%d\", (int)ntohs(addr->sin_port));\n"}, {"line_no": 17, "char_start": 847, "char_end": 905, "line": "            strcpy(sock->ep_local2.host, sock->ep_local);\n"}, {"line_no": 18, "char_start": 905, "char_end": 1009, "line": "            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2), \"%d\", (int)ntohs(addr->sin6_port));\n"}], "added": [{"line_no": 7, "char_start": 278, "char_end": 367, "line": "            strncpy(sock->ep_local2.host, sock->ep_local, sizeof(sock->ep_local2.host));\n"}, {"line_no": 8, "char_start": 367, "char_end": 475, "line": "            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2.port), \"%d\", (int)ntohs(addr->sin_port));\n"}, {"line_no": 16, "char_start": 834, "char_end": 923, "line": "            strncpy(sock->ep_local2.host, sock->ep_local, sizeof(sock->ep_local2.host));\n"}, {"line_no": 17, "char_start": 923, "char_end": 1032, "line": "            snprintf(sock->ep_local2.port, sizeof(sock->ep_local2.port), \"%d\", (int)ntohs(addr->sin6_port));\n"}]}, "char_changes": {"deleted": [{"char_start": 291, "char_end": 346, "chars": "ize_t len = strlen(sock->ep_local);\n            strcpy("}, {"char_start": 360, "char_end": 368, "chars": "2.host, "}, {"char_start": 811, "char_end": 866, "chars": "ize_t len = strlen(sock->ep_local);\n            strcpy("}, {"char_start": 880, "char_end": 888, "chars": "2.host, "}], "added": [{"char_start": 291, "char_end": 320, "chars": "trncpy(sock->ep_local2.host, "}, {"char_start": 334, "char_end": 343, "chars": ", sizeof("}, {"char_start": 357, "char_end": 364, "chars": "2.host)"}, {"char_start": 432, "char_end": 437, "chars": ".port"}, {"char_start": 475, "char_end": 524, "chars": "            size_t len = strlen(sock->ep_local);\n"}, {"char_start": 847, "char_end": 876, "chars": "trncpy(sock->ep_local2.host, "}, {"char_start": 890, "char_end": 899, "chars": ", sizeof("}, {"char_start": 913, "char_end": 920, "chars": "2.host)"}, {"char_start": 988, "char_end": 993, "chars": ".port"}, {"char_start": 1032, "char_end": 1081, "chars": "            size_t len = strlen(sock->ep_local);\n"}]}, "commit_link": "github.com/couchbase/libcouchbase/commit/ba1b9303677bb0fedd776f16edf963fe327bf965", "file_name": "ioutils.cc", "vul_type": "cwe-787", "commit_msg": "CBCC-1280: fix buffer overflow in address caching code\n\nChange-Id: Ib5b3fd2bd252cf243d7c389fea1a0b3f1ed65411\nReviewed-on: http://review.couchbase.org/c/libcouchbase/+/157713\nTested-by: Build Bot <build@couchbase.com>\nReviewed-by: David Kelly <davidmichaelkelly@gmail.com>", "parent_commit": "f80ea5b734f694441cffcf6ac9a6b9c6b11938bb", "description": "In C, write a function to cache the local IP address and port from a socket connection structure."}
{"func_name": "(anonymous)", "func_src_before": "app.post('/ldap', set_current_config, function(req, res, next) {\n  // Convert ENABLE_WRITE_BACK and ENABLE_ACTIVE_DIRECTORY_UNICODE_PASSWORD to boolean.\n  req.body.ENABLE_WRITE_BACK = !!(req.body.ENABLE_WRITE_BACK && req.body.ENABLE_WRITE_BACK === 'on');\n  req.body.ENABLE_ACTIVE_DIRECTORY_UNICODE_PASSWORD = !!(req.body.ENABLE_ACTIVE_DIRECTORY_UNICODE_PASSWORD && req.body.ENABLE_ACTIVE_DIRECTORY_UNICODE_PASSWORD === 'on');\n\n  var config = xtend({}, req.current_config, req.body);\n  test_config(config, function(err, result) {\n    if (err) {\n      return res.render('index', xtend(req.current_config, req.body, {\n        ERROR: err.message,\n        LDAP_RESULTS: result\n      }));\n    }\n    req.session.LDAP_RESULTS = result;\n    console.log(req.session.LDAP_RESULTS);\n    next();\n  });\n}, function(req, res, next) {", "func_src_after": "app.post('/ldap', set_current_config, csrfProtection, function(req, res, next) {\n  // Convert ENABLE_WRITE_BACK and ENABLE_ACTIVE_DIRECTORY_UNICODE_PASSWORD to boolean.\n  req.body.ENABLE_WRITE_BACK = !!(req.body.ENABLE_WRITE_BACK && req.body.ENABLE_WRITE_BACK === 'on');\n  req.body.ENABLE_ACTIVE_DIRECTORY_UNICODE_PASSWORD = !!(req.body.ENABLE_ACTIVE_DIRECTORY_UNICODE_PASSWORD && req.body.ENABLE_ACTIVE_DIRECTORY_UNICODE_PASSWORD === 'on');\n\n  var config = xtend({}, req.current_config, req.body);\n  test_config(config, function(err, result) {\n    if (err) {\n      return res.render('index', xtend(req.current_config, req.body, {\n        ERROR: err.message,\n        LDAP_RESULTS: result\n      }));\n    }\n    req.session.LDAP_RESULTS = result;\n    console.log(req.session.LDAP_RESULTS);\n    next();\n  });\n}, function(req, res, next) {", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 65, "line": "app.post('/ldap', set_current_config, function(req, res, next) {\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 81, "line": "app.post('/ldap', set_current_config, csrfProtection, function(req, res, next) {\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 37, "char_end": 53, "chars": " csrfProtection,"}]}, "commit_link": "github.com/auth0/ad-ldap-connector/commit/57441facad9edb49f80a57acd74f39d4657add98", "file_name": "server.js", "vul_type": "cwe-352", "commit_msg": "csrf protecttion in /ldap api", "description": "Write a Node.js Express route handler that processes LDAP configuration settings from a POST request and tests the configuration."}
{"func_name": "glyph_cache_put", "func_src_before": "BOOL glyph_cache_put(rdpGlyphCache* glyphCache, UINT32 id, UINT32 index, rdpGlyph* glyph)\n{\n\trdpGlyph* prevGlyph;\n\n\tif (id > 9)\n\t{\n\t\tWLog_ERR(TAG, \"invalid glyph cache id: %\" PRIu32 \"\", id);\n\t\treturn FALSE;\n\t}\n\n\tif (index > glyphCache->glyphCache[id].number)\n\t{\n\t\tWLog_ERR(TAG, \"invalid glyph cache index: %\" PRIu32 \" in cache id: %\" PRIu32 \"\", index, id);\n\t\treturn FALSE;\n\t}\n\n\tWLog_Print(glyphCache->log, WLOG_DEBUG, \"GlyphCachePut: id: %\" PRIu32 \" index: %\" PRIu32 \"\", id,\n\t           index);\n\tprevGlyph = glyphCache->glyphCache[id].entries[index];\n\n\tif (prevGlyph)\n\t\tprevGlyph->Free(glyphCache->context, prevGlyph);\n\n\tglyphCache->glyphCache[id].entries[index] = glyph;\n\treturn TRUE;\n}", "func_src_after": "BOOL glyph_cache_put(rdpGlyphCache* glyphCache, UINT32 id, UINT32 index, rdpGlyph* glyph)\n{\n\trdpGlyph* prevGlyph;\n\n\tif (id > 9)\n\t{\n\t\tWLog_ERR(TAG, \"invalid glyph cache id: %\" PRIu32 \"\", id);\n\t\treturn FALSE;\n\t}\n\n\tif (index >= glyphCache->glyphCache[id].number)\n\t{\n\t\tWLog_ERR(TAG, \"invalid glyph cache index: %\" PRIu32 \" in cache id: %\" PRIu32 \"\", index, id);\n\t\treturn FALSE;\n\t}\n\n\tWLog_Print(glyphCache->log, WLOG_DEBUG, \"GlyphCachePut: id: %\" PRIu32 \" index: %\" PRIu32 \"\", id,\n\t           index);\n\tprevGlyph = glyphCache->glyphCache[id].entries[index];\n\n\tif (prevGlyph)\n\t\tprevGlyph->Free(glyphCache->context, prevGlyph);\n\n\tglyphCache->glyphCache[id].entries[index] = glyph;\n\treturn TRUE;\n}", "commit_link": "github.com/FreeRDP/FreeRDP/commit/c0fd449ec0870b050d350d6d844b1ea6dad4bc7d", "file_name": "libfreerdp/cache/glyph.c", "vul_type": "cwe-125", "description": "Write a C function named `glyph_cache_put` that stores a glyph in a glyph cache, ensuring the cache ID and index are within valid bounds, and logs the operation."}
